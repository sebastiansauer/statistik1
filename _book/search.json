[
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Lernsteuerung\nAbb. Abbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#lernsteuerung",
    "href": "040-verbildlichen.html#lernsteuerung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Lernziele\n\nSie können erläutern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arte von Datendiagrammen.\nSie können typische Datendiagramme mit R visualisieren.\nSie können zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\nlibrary(ggpubr)  # optional\nlibrary(ggstatsplot)  # optional\n\n\n5.1.3 Benötigte Daten\nZuerst definieren wir den Pfad, wo wir die Daten finden, s. Listing 5.1. Dann importieren wir die Mariokart-Daten.\n\n\n\nListing 5.1: Pfad zu den Mariokart-Daten\n\nmariokart_path &lt;- paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets\",\n  \"/csv/openintro/mariokart.csv\")\n\nmariokart &lt;- read.csv(mariokart_path)\n\n\n\n\n\n5.1.4 R-Code zum Copy-Pasten\nSie finden den R-Code für jedes Kapitel hier. \\(\\square\\)\n\n5.1.5 Quiz zum Einstieg\n\n\n\n\n\n\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwas mittels der Plattform antworte.jetzt. Alternativ überlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.6 Wozu das alles?\n\n\nGroße Aufgaben warten … (imgflip, 2024)\n\n\n🥷 Wir müssen die Galaxis retten, Kermit.\n\n\n🐸 Schlock",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heißt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte, s. Abbildung 5.1. In Abbildung 5.1 sieht man verschiedene “Bilder”, also Datensätze: etwa einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschiedene sind, sind die zentralen statistischen Kennwerte (praktisch) identisch. In die gleiche Bresche schlägt “Anscombes Quartett” (Anscombe, 1973), s. Abbildung 5.2: Es zeigt vier Datensätze, in denen die zentralen Statistiken fast identisch sind,\nalso Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthüllt, was der Statistik (als Kennzahl) verhüllt bleibt.\n\n\n\n\n\nAbbildung 5.1: Dinosaurier und Kreis: Gleiche statistischen Kennwerte (Fitzmaurice, 2017)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Diagramme können Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier Datensätzen\n\n\nUnter visueller Cortex ist sehr leistungsfähig. Wir können ohne Mühe eine große Anzahl an Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen.\n\n\n\n\n\n\nTipp\n\n\n\nNutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mächtig.\n\n\n\n5.2.1 Datendiagramm\nEin Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwändiges (und ansprechendes) Datendiagramm)  \n\n\n\n\n\n\nAuf Basis des Korruptionsindex von Transparency International (2017) erstellt Wilke (2019/2024) ein Diagramm zum Zusammenhang vom Entwicklungsindex (Lebenserwartung, Bildung, Einkommen; vgl. Hou et al. (2015)) und Korruption, jeweils auf Landesebene, s. Abbildung 5.3.\nEs finden sich in der Literatur (im Internet) viele weitere Beispiele für handwerklich meisterhaft erstelle Datendiagramme, die in vielen Fällen mit R erstellt werden (vgl. Scherer et al., 2019).\n\n\n \n\n\n\n\n\n\n\nAbbildung 5.3: Der Zusammenhang von Entwicklungindex und und Korruption\n\n\n\n\n\n\n\n5.2.2 Ein Bild hat nicht so viele Dimensionen\nAbbildung 5.4 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer “Dimension” entsprechen. Wie man (nicht) sieht, wird es langsam unübersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die “Dimensionalität” eines Diagramms hat ihre Grenzen, vielleicht bei 4-6 Variablen.\n\n\n\n\n\n\n\nAbbildung 5.4: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\nMöchten wir den Zusammenhang von vielen Variablen, z.B. mehr als 5, verstehen, kommen wir mit Bildern nicht weiter. Dann brauchen wir andere Werkzeuge: statistics to the rescue.\n\n\n\n\n\n\nHinweis\n\n\n\nBei klaren Zusammenhängen und wenig Variablen braucht man keine (aufwändige) Statistik. Ein Bild (Datendiagramm) ist dann (oft) ausreichend. Man könnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. 4-6 Variablen nicht gleichzeitig umgehen kann.\n\n\n\nÜbungsaufgabe 5.1 Wie viele Variablen sind in Abbildung 5.4 dargestellt?1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelle 5.1 zeigt eine – sehr kurze Nomenklatur – an Datendiagrammen. Weitere Nomenklaturen sind möglich, aber wir halten hier die Sache einfach. Wer an Vertiefung interessiert ist, findet bei data-to-vis einen Überblick über verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur: https://www.data-to-viz.com/.\n\n\n\nTabelle 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefülltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefülltes Balkendiagramm\nBoxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir arbeiten hier mit dem Datensatz mariokart. Hilfe bzw. ein Data-Dictionary (Codebook) finden Sie hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung: nominale Variable\n\nDefinition 5.1 (Verteilung) Eine (Häufigkeits-)Verteilung einer Variablen \\(X\\) schlüsselt auf, wie häufig jede Ausprägung von \\(X\\) ist.\\(\\square\\)\n\n\nBeispiel 5.2 Tabelle 5.2 zeigt die Häufigkeitsverteilung von cond (condition, also der Zustand des Artikels, neu oder gebraucht) aus dem Datensatz mariokart. Die Variable hat 5 Ausprägungen; z.B. kommt die Ausprägung new 59 mal vor.\\(\\square\\)\n\n\n\n\nTabelle 5.2: Häufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. Abbildung 5.5. Wie man sieht, besteht so ein Diagramm als Balken, daher heißt es Balkendiagramm (synonym: Säulendiagramm). Man kann so ein Diagramm um 90° drehen; keine Ausrichtung ist unbedingt besser als die andere.\n\nDefinition 5.2 (Balkendiagramm) Ein Balkendiagramm ist eine grafische Darstellung von Werten, zumeist für die Häufigkeiten bestimmter Kategorien (Ausprägungen nominaler Variablen). Dabei werden rechteckige Balken verwendet werden, und die Länge eines Balkens ist proportional zur dargestellten Häufigkeit. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) horizontale Balken\n\n\n\n\n\n\n\n\n\n(b) vertikale Balken\n\n\n\n\n\n\nAbbildung 5.5: Häufigkeitsverteilung der Variable cond\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. Abbildung 5.5; wir betrachten gleich die Syntax.\nZuerst importieren wir die Daten, s. ?lst-mariokart-path.\nAußerdem nicht vergessen, das Paket DataExplorer mit dem Befehle library zu starten. (Natürlich müssen Sie das Paket einmalig installiert haben, bevor Sie es starten können.) In diesem Paket “wohnen” die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden. Listing 5.2 zeigt die Syntax, um ein Balkendiagramm zu erstellen. Auf der Hilfeseite der Funktion finden Sie weitere Details zur Funktion.\n\n\n\nListing 5.2: Syntax zur Erstellung eines Balkendiagramms\n\nlibrary(DataExplorer)\nmariokart &lt;- read.csv(mariokart_path)\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\n\n\n\n\n\n\nAbbildung 5.6: Ein Balkendiagramm. Unglaublich.\n\n\n\n\nDie Syntax ist in Listing 5.2 abgedruckt (Zur Erinnerung: %&gt;% nennt man die “Pfeife und lässt sich als”und dann” übersetzen, vgl. Kapitel 4.4). Übersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz mariokart *und dann*\n  wähle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm.\n\nÜbungsaufgabe 5.2 (Spalten wählen für das Balkendiagramm) Hätten wir andere Spalten ausgewählt, so würde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie können auch mehrere Variablen auf einmal auswählen. Probieren Sie das doch mal aus!\n\n\nÜbungsaufgabe 5.3 (Visualisieren Sie die Verteilung von stock_photo!)  \n\nmariokart |&gt; \n  select(stock_photo) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\n\n\n\n5.4.2 Verteilung: quantitative Variable\n\n5.4.2.1 Histogramm\nBei einer quantitativen Variablen mit vielen Ausprägungen wäre ein Balkendiagramm nicht so aussagekräftig, s. Abbildung 5.7 (links). Es gibt einfach zu viele Ausprägungen.\nDie Lösung: Wir reduzieren die Anzahl der Ausprägungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger Ausprägungen zu bekommen, können wir einfach Gruppen definieren, z.B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 2: 11-15 Dollar …\n\nIn Abbildung 5.7 (rechts) sind z.B. die Ausprägungen des Verkaufspreis (total_pr) in in Gruppen der Breite von 5 Dollar aufgeteilt worden. Zusätzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\n\n\n(a) Balkendiagramm\n\n\n\n\n\n\n\n\n\n(b) Histogramm\n\n\n\n\n\n\nAbbildung 5.7: Balkendiagramm vs. Histogramm für den Gesamtpreis (total_pr)\n\n\n\nDefinition 5.3 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der Häufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt sind. Die Höhe der Balken zeigt die Häufigkeit der Daten in dieser Gruppe/in diesem Balken (bei konstanter Balkenbreite).\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten nicht sehr viele und nicht sehr wenig sein, s. Abbildung 5.8 links bzw. Abbildung 5.8, rechts.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildung 5.8: Nicht zu wenig und nicht zu viele Balken im Balkendiagramm\n\n\nZur Erstellung eines Histogramms können Sie die Syntax Listing 5.3 nützen, vgl. Abbildung 5.9, links.\n\n\nListing 5.3: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 5.9: Eine stetige Verteilung verbildlichen\n\n\n\nÜbungsaufgabe 5.4 (Visualisieren Sie die Verteilung von ship_pr anhand eines Histogramms!)  \n\nmariokart |&gt; \n  select(ship_pr) |&gt; \n  plot_histogram()\n\n\n\n\n\n\n\n\n\n5.4.2.2 Dichtediagramm\nAbbildung 5.10 fügt zu ?fig-balken-total-pr-hist ein Dichtediagramm hinzu (rote Linie). Ein Dichtediagramm ähnelt einem “glattgeschmirgeltem” Histogramm.\n\nDefinition 5.4 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglättet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden. (Mit Dichte ist die Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.)\n\n\n\n\n\n\n\n\nAbbildung 5.10: Histogramm (graue Balken) und Dichtediagramm (orange Linie) für total_pr\n\n\n\n\n\nÜbungsaufgabe 5.5 Erstellen Sie das Diagramm Abbildung 5.9, rechtes Teildiagramm!2\\(\\square\\)\n\n\n5.4.2.3 Eigenschaften von Verteilungen\nVerteilungen unterscheiden sich z.B. einerseits in ihrem “typischen” oder “mittleren” Wert (vgl. Kapitel 6.5) und anderseits in ihrer Streuung (vgl. Kapitel 7.4.) (Diagramme von) Verteilungen können symmetrisch oder schief (nicht symmetrisch) sein, s. Abbildung 5.11.\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildung 5.11: Symmetrische vs. schiefe Verteilung, verbildlicht\n\n\nAbbildung 5.12 zeigt verschiedene Formen von Verteilungen. “Bimodal” meint “zweigipflig” und “multimodal” entsprechend “mehrgipflig”.3\n\n\n\n\n\n\n\nAbbildung 5.12: Verschiedene Verteilungsformen\n\n\n\n\n\nÜbungsaufgabe 5.6 (Verteilungform von total_pr?) Benennen Sie die am besten passende Verteilungsform für die Variable total_pr.\nLösung\nDie Verteilung ist rechtsschief.\n\nmariokart |&gt; \n  select(total_pr) |&gt; \n  plot_density()\n\n\n\n\n\n\n\n\n\n5.4.3 Normalverteilung\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer quantitativen Variablen. Aber sie ist besonders wichtig, und ist daher hier herausgestellt.\nEine Normalverteilung sehen Sie in Abbildung 5.11, links. Sie hat u.a. folgende Eigenschaften:\n\nsymmetrisch\nglockenförmig\nstetig\neingipflig (unimodal)\nMittelwert, Median und Modus sind identisch\n\n\nBeispiel 5.3 Beispiele für normalverteilte Variablen sind Körpergröße von Männern oder Frauen, IQ-Werte, Prüfungsergebnisse, Messfehler, Lebensdauer von Glühbirnen, Gewichte von Brotlaiben, Milchproduktion von Kühen, Brustumfang schottischer Soldaten (Lyon, 2014).\\(\\square\\)\n\n\nDefinition 5.5 (Normalverteilung) Eine Normalverteilung ist eine spezielle Art von Verteilung einer quantitativen Variablen. Sie ist symmetrisch, glockenförmig, stetig, unimodal und hat Mittelwert, Median und Modus identisch. Sie lässt sich durch zwei Parameter vollständig beschreiben: Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)). \\(\\square\\)\n\nDie Normalverteilung ist von hoher Bedeutung, da sich diese Verteilung unter (recht häufigen) Bedingungen zwangsläufig ergeben muss.\n\nDefinition 5.6 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhängiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\n\n\n\n\n\n\nDieses Phänomen kann man gut anhand des Galton-Bretts veranschaulichen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter der Normalverteilung\n\n\n\nEine Normalverteilung lässt sich exakt beschreiben anhand zweier Parameter: ihres zentralen Werts (Mittelwerts), \\(\\mu\\), und ihrer Streuung (Standardabweichung), \\(\\sigma\\). \\(\\square\\)\n\n\nAbbildung 5.13 zeigt interaktive Beispiele für Normalverteilung. Wählen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler.4\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\nshow_curve = true\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.13: Interaktives Beispiel für Normalverteilungen.\n\n\nKennt man diese beiden Parameter, so kann man einfach angeben, welcher Anteil der Fläche sich in einem bestimmten Bereich befindet, s. Abbildung 5.14.\nDavon leitet sich die “68-95-99.7-Prozentregel” ab:\n\n\n\\(68\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{,}7\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildung 5.14: Die Flächeninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in Abhängigkeit der SD-Einheiten (Ainali, 2007)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.5 Zusammenhänge verbildlichen",
    "text": "5.5 Zusammenhänge verbildlichen\n\n5.5.1 Zusammenhang: nominale Variablen\n\nBeispiel 5.4 (Beispiele für Zusammenhänge bei nominalen Variablen)  \n\nHängt Berufserfolg (Führungskraft ja/nein) mit dem Geschlecht zusammen?\nHängt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen Automarke und politische Präferenz einer Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primär bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. Abbildung 5.15.\n\n\n\n\n\n\n\n\n\n(a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten\n\n\n\n\n\n\n\n\n\n(b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\n\n\n\nAbbildung 5.15: Zusammenhang zwischen nominalskalierten Variablen verbildlichen\n\n\nTatsächlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (Abbildung 5.15, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der Hälfte der Fälle.\nAnders sieht es aus für die Frage, ob ein (oder mehrere) Lenkräder dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach “Foto des Produkts dabei” betraf (Abbildung 5.15, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten).\nAnders gesagt: Unterscheiden sich die “Füllhöhe” in den Diagrammen, so gibt es einen Unterschied hinsichtlich “Foto ist dabei” zwischen den beiden Gruppen (linker vs. rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs. gebrauchte Spiele), so spielt z.B. die Variable “Foto dabei” offenbar eine Rolle. Dann hängen Neuwertigkeit und “Foto dabei” also zusammen!\nSo können Sie sich in R ein gefülltes Balkendiagramm ausgeben lassen, s. Abbildung 5.16. Diese Darstellung eignet sich, um Zusammenhänge zwischen zwei zweistufigen nominal skalierten Variablen zu verbildlichen. Die verschiedenen Werte der Füllfarbe werden den Stufen der Variablen cond zugewiesen, s. Listing 5.4.\n\n\n\nListing 5.4: R-Syntax für ein gefülltes Balkendiagramm\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\n\n\n\nAbbildung 5.16: Ein gefülltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nGefüllte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei Ausprägungen aufweisen, sonst sind die Zusammenhänge nicht mehr so gut zu erkennen.\\(\\square\\)\n\n\n\nÜbungsaufgabe 5.7 (Zusammenhang visualisieren) Aufgabe Visualisieren Sie den Zusammenhang der beiden nominalen Variablen cond und wheels!\nLösung\nwheels ist als metrische Variable (int: Integer, d.h. Ganzzahl) formatiert im Datensatz mariokart. Wir müssen Sie zunächst als Faktorvariable umformatieren, damit R sie als nominal skalierte Variable erkennt.\n\nmariokart |&gt; \n  # Mache aus einer metrischen eine nominale Variable: \n  mutate(wheels = factor(wheels)) |&gt; \n  select(cond, wheels) |&gt; \n  plot_bar(by = \"cond\")\n\n\n\n\n\n\n\n\n\n5.5.2 Zusammenhang: metrisch\nDen (etwaigen) Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). Abbildung 5.17 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine “Trendgerade” (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schließen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je höher der Startpreis, desto höher der Abschlusspreis, zumindest tendenziell. Diese Gerade liegt “mittig” in den Daten (wir definieren dies später genauer). Diese Trendgerade gibt Aufschluss über “typische” Werte: Welcher Y-Wert ist “typisch” für einen bestimmten X-Wert?\nAbbildung 5.17 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis. Das erkennt man an der sinkenden Trendgeraden.\nDie Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. Abbildung 5.19.\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) negativer, eher schwacher Zusammenhang\n\n\n\n\n\n\nAbbildung 5.17: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\nDefinition 5.7 (Linearer Zusammenhang) Lässt sich die Beziehung zwischen zwei Variablen mit einer Gerade visualisieren, so spricht man von einem linearen Zusammenhang. Ändert man eine der beiden Variablen um einen bestimmten Wert (z.B. 1), so ändert sich die andere um einen proportionalen Wert (z.B. 0.5). \\(\\square\\)\n\nNatürlich könnte man auch nicht-lineare Zusammenhänge untersuchen, aber der Einfachheit halber konzentrieren wir uns hier mit linearen; Beispiele für nicht-lineare Zusammenhänge sind in Abbildung 5.18 zu sehen.\n\n\n\n\n\n\n\nAbbildung 5.18: Beispiele nichtlinearer Zusammenhänge\n\n\n\n\n\nDefinition 5.8 (Richtung und Stärke eines Zusammenhang) Gleichsinnige (positive) Zusammenhänge erkennt man an aufsteigenden Trendgeraden \\(\\nearrow\\); gegensinnige (negative) Zusammenhänge an absteigenden Trendgeraden \\(\\searrow\\). \\(\\square\\)\n\nStarke Zusammenhänge erkennt man an schmalen Ellipsen (“Baguette” 🥖); schwache Zusammenhänge an breiten Ellipsen (“Torte” 🥮). Abbildung 5.19 bietet einen Überblick über verschiedene Beispiele von Richtung und Stärke von Zusammenhängen.5\n\n\n\n\n\n\n\nAbbildung 5.19: Lineare Zusammenhänge verschiedener Stärke und Richtung\n\n\n\n\nIn Abbildung 5.19 ist für jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und Stärke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht für einen positiven Zusammenhang, ein negatives Vorzeichen für einen negativen Zusammenhang. Der (Absolut-)Wert gibt die Stärke des linearen Zusammenhangs an (Cohen, 1992):\n\n±0: Kein Zusammenhang\n±0.1: schwacher Zusammenhang\n±0.3: mittlerer Zusammenhang\n±0.5: starker Zusammenhang\n±1: perfekter Zusammenhang\n\nAbbildung 5.20 hat die gleiche Aussage wie Abbildung 5.19, ist aber plakativer, indem Stärke (schwach, stark) und Richtung (positiv, negativ) gegenübergestellt sind.\n\n\n\n\n\n\n\nAbbildung 5.20: Überblick über starke vs. schwache bzw. positive vs. negative Zusammenhänge\n\n\n\n\nMan sieht in Abbildung 5.19 und Abbildung 5.20, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade (synonym: Regressionsgerade; blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke Zusammenhänge mit einer schmaler Ellipse einhergehen und schwache Zusammenhänge mit einer breiten Ellipse einhergehen.\nAbbildung 5.21 zeigt interaktive Beispiele für (lineare) Zusammenhänge.6\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.21: Interaktives Beispiel für Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und manchmal gehört Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhängen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. Außerdem müssen wir noch die Daten importieren, falls noch nicht getan, s. Listing 5.1.\nSo, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf metrische Variablen konzentrieren wollen, wählen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewählten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primär interessiert. Das Ergebnis sieht man in Abbildung 5.22 bzw. Listing 5.5. \\(\\square\\)\n\n\n\n\nListing 5.5: Streudiagramm erstellen mit dem R-Paket ‘DataExplorer’\n\nmariokart %&gt;% \n  select(duration, n_bids, start_pr,\n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\n\n\n\nAbbildung 5.22: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nAha… Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafür sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur Verkäufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100). Das Ergebnis ist in Abbildung 5.23 zu sehen.\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nmariokart_no_extreme %&gt;% \n  select(duration, n_bids, start_pr, \n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildung 5.23: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nOhne Extremwerte schält sich ein deutlicheres Bild (Abbildung 5.23) hervor: Startpreis (start_pr) und Anzahl der Räder (wheels) scheinen am stärksten mit dem Abschlusspreis zusammenzuhängen.\nDas Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle übrigen Variablen kommen jeweils einmal als X-Variable vor.\\(\\square\\)\n\nÜbungsaufgabe 5.8  \n\n\nAufgabe\nLösung\n\n\n\nVisualisieren Sie den Zusammenhang der beiden metrischen Variablen start_pr und total_pr. Verwenden Sie den Datensatz ohne Extremwerte wie oben definiert.\n\n\n\nmariokart_no_extreme |&gt; \n  select(start_pr, total_pr) |&gt; \n  plot_scatterplot(by = \"total_pr\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.6 Unterschiede verbildlichen",
    "text": "5.6 Unterschiede verbildlichen\n\n5.6.1 Unterschied: nominale Variablen\nGute Nachrichten: Für nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von Zusammenhängen als auch von Unterschieden an. Genau genommen zeigt ja Abbildung 5.15 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Photos beiliegen. Und wie man in Abbildung 5.15 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen höher als bei gebrauchten Spielen.7\n\n5.6.2 Unterschied: quantitative Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich unterscheiden. Genauer gesagt untersucht man z.B. oft, ob sich die Mittelwerte der beiden Gruppen zwischen der Zielvariablen deutlich unterscheiden. Das hört sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. Abbildung 5.24.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildung 5.24: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 5.24 zeigt das Histogramm von total_pr, getrennt für neue und gebrauchte Spiele, vgl. Abbildung 5.9. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsfrom, den Boxplot.8 Was ein “deutlicher” (“substanzieller”, “bedeutsamer”, “relevanter” oder “(inhaltlich) signifikanter”) Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\n\nDefinition 5.9 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms. Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar.\\(\\square\\)\n\nIn Abbildung 5.25 sieht man die “Übersetzung” von Histogramm (oben) zu einem Boxplot (unten). Ob der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack überlassen.\n\n\n\n\n\n\n\nAbbildung 5.25: Übersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die “Anatomie” des Boxplots näher an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto größer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie “Antennen” des Boxplots zeigen die Streuung in den kleinsten 25% der Werte (linke Antenne) bzw. die Streuung der größten 25% der Werte (rechte Antennen). Je länger die Antenne, desto größer die Streuung.\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, außerhalb der Antennen gezeigt werden. Daher ist die Antennenlänge auf die 1,5-fache Länge der Box beschränkt. Werte die außerhalb dieses Bereichs liegen (also mehr als das 1,5-fache der Boxlänge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.h. sie ist schief). Gleiches gilt für die Antennenlängen: Sind die Antennen gleich lang, so ist der äußere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der Lenkräder untersucht. Jetzt möchten Sie eine sehr ähnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten Lenkräder? Flink erstellen Sie dazu folgendes Diagramm, Abbildung 5.26, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl Lenkräder (by = \"wheels\"). \\(\\square\\)\n\nAber ganz glücklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wäre eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen würde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von Abbildung 5.26) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert. Vielleicht so, dass in jeder Gruppe gleich viele Wert sind?] Aber wir möchten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir möchten wheels als nominale Variable definieren. Das kann man mit dem Befehle factor(wheels) erreichen (verpackt in mutate), s. Abbildung 5.26 rechts.\n\nmariokart_no_extreme %&gt;% \n  select(total_pr, wheels) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\nmariokart_no_extreme %&gt;% \n  select(total_pr, wheels) %&gt;% \n  mutate(wheels = factor(wheels)) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildung 5.26: Abschlusspreis nach Anzahl von beigelegten Lenkrädern\n\n\nSie schließen aus dem Bild, dass Lenkräder und Preis (positiv) zusammenhängen. Allerdings scheint es wenig Daten für wheels == 4 zu geben. Das prüfen Sie nach:\n\nmariokart_no_extreme %&gt;% \n  count(wheels)\n\n\n\nwheels\nn\n\n\n\n0\n36\n\n\n1\n52\n\n\n2\n50\n\n\n3\n2\n\n\n4\n1\n\n\n\n\n\nTatsächlich gibt es (in mariokart_no_extreme) auch für 3 Lenkräder schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten.\nÜbrigens bezeichnet Sie Ihre Chefin nur noch als “Datengott”.\n\nÜbungsaufgabe 5.9 (Visualisieren Sie den Unterschied im Verkaufspreis zwischen gebrauchten und neuen Spielen.) Lösung\n\nmariokart_no_extreme |&gt; \n  select(cond, total_pr) |&gt; \n  plot_boxplot(by = \"cond\")\n\n\n\n\n\n\n\n\n\nÜbungsaufgabe 5.10 (Verkaufspreis im Vergleich) Visualisieren Sie den Unterschied im Verkaufspreis abhängig von ship_pr; betrachten Sie ship_pr als ein Gruppierungsvariable. Interpretieren Sie das Ergebnis.\nLösung\n\nmariokart_no_extreme |&gt; \n  select(ship_pr, total_pr) |&gt; \n  plot_boxplot(by = \"ship_pr\")\n\n\n\n\n\n\n\nplot_boxplot gruppiert metrische Variablen, wie ship_pr automatisch in fünf Gruppen (mit gleichen Ranges). Wir müssen also nichts tun, um die metrische Variable ship_pr in eine Gruppierungsvariable (Faktorvariable) umzuwandeln.\nEs sieht so aus, als würde der Median zwischen den Gruppen leicht steigen, mit Ausnahme der mittleren Gruppe.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.7 So lügt man mit Statistik",
    "text": "5.7 So lügt man mit Statistik\nDiagramme werden miunter eingesetzt, um die Wahrheit “aufzuhübschen”. Hier folgen einige gebräuchlichen Täuschungsmanöver.\n\n5.7.1 Achsen manipulieren\nAchsen zu stauchen ist ein einfacher Trick, s. Abbildung 5.27.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.27: Stauchen der Y-Achse, um mit Statistik zu lügen\n\n\nNatürlich kann man auch durch “Abschneiden” der Y-Achse einen eindrucksvollen Effekt erzielen, s. Abbildung 5.28.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.28: Abschneiden der Y-Achse, um mit Statistik zu lügen\n\n\n\n5.7.2 Scheinkorrelation\nMesserli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: Länder), s. Abbildung 5.29. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?)\n\n\n\n\n\nAbbildung 5.29: Schokolodenkonsum und Nobelpreise\n\n\nLeider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhängen, heißt das nicht, dass die Variable die Ursache und die andere die Wirkung sein muss. So könnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In höher entwickelten Ländern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu Ländern mit geringerem Entwicklungsstand.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.8 Praxisbezug",
    "text": "5.8 Praxisbezug\nEin, wie ich finde schlagendes Beispiel zur Stärke von Datendiagrammen ist Abbildung 5.30. Das Diagramm zeigt die Häufigkeit von Masern, vor und nach der Einführung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurück.\n\n\n\n\n\nAbbildung 5.30: Häufigkeit von Masern und Impfung in den USA [moore_recreating_2015]\n\n\nIn der “freien Wildbahn” findet man häufig sog. “Tortendiagramme”. Zwar sind sie beliebt, doch ist von ihrer Verwendung zumeist abzuraten; vgl. auch hier.9",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\n\n5.9.1 Animation\nEine weitere nützliche Art von Visualisierung sind Karten, 3D-Bilder und Animationen. So zeigt z.B. Abbildung 5.31 die Veränderung der Lebenserwartung (in Jahren) über die letzten Dekaden.10\n\n\n\n\n\nAbbildung 5.31: Animation zur Veränderung der Lebenserwartung\n\n\nIn einigen Situation können Animationen zweckdienlich sein. Außerdem sind sie mitunter nett anzuschauen, s. Abbildung 5.32.\n\n\n\n\n\nAbbildung 5.32: Veränderung des Zusammenhangs von Lebenswertung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\nUm den gemeinsamen Zusammenhang dreier metrischer Variablen darzustellen, bietet sich ein 3D-Streudiagramm an; s. Abbildung 5.33.\n\n\n\n\n\n\n\nAbbildung 5.33: 3D-Punktediagramm zum Datensatz mariokart\n\n\n\nLeider ist Abbildung 5.33 nicht sehr aufschlussreich.\nNatürlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animationen ziemlich beeindruckend. 11\n\n5.9.2 Schicke Diagramme\nEin Teil der Diagramm dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMöchte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median heraustellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.B.) mit ggpubr, s. Abbildung 5.34.\n\nggviolin(mariokart_no_extreme, \n         x = \"cond\", \n         y = \"total_pr\",\n         add = \"mean_sd\") \n\n\n\n\n\n\nAbbildung 5.34: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nEin “Violinenplot” hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die “Violine”, desto mehr Beobachtungen gibt es an dieser Stelle. Weitere Varianten zum Violinenplot mit ggpubr finden sich hier.12\nÜbrigens sind Modelle – und Diagramme sind Modelle – immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen. Dieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.13 Ein weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heißt ggstatsplot.14 Abbildung 5.35 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.15\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart_no_extreme,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrückt statist. Details\n)\n\n\n\n\n\n\nAbbildung 5.35: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. Möchte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE. (Weitere Hinweise finden sich auf der Hilfeseite der Funktion der Funktion.)\n\n👩‍🏫 Ich würde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\n🧑‍🎓 Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.16\n\n\n5.9.3 Farbwahl\nEinige Überlegungen zur Farbwahl findet sich bei Wilke (2019), s. Kap. 4.17 Die Farbpalette von Okabe und Ito ist (vgl. Ichihara et al., 2008) empfehlenswert, da sie auch bei Schwarz-Weiß-Druck und bei Sehschwächen die Farben noch recht gut unterscheiden lässt, s. Abbildung 5.36.\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\") +\n  scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 5.36: Die Farbskala von Okabe und Ito: Geeignet bei Farbseh-Schwächen und für Schwarz-Weiß-Druck. Außerdem nett anzuschauen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2\nvis-gapminder\nboxplots-de1a\ndiamonds-histogramm-vergleich\nwozu-balkendiagramm\ndiamonds-histogram\nn-vars-diagram\n\nNoch mehr Aufgaben zum Thema Datenvisualisierung finden Sie im Datenwerk unter dem Tag vis.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise",
    "href": "040-verbildlichen.html#literaturhinweise",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.11 Literaturhinweise",
    "text": "5.11 Literaturhinweise\nSowohl ggpubr als auch DataExplorer (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2016). Eine neuere, gute Einführung in Datenvisualisierung findet sich bei Wilke (2019). Beide Bücher sind kostenfrei online lesbar.\nWilke (2019) gibt einen hervorragenden Überblick über praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In ähnlicher Richtung geht Fisher & Meyer (2018).\nHier ist eine Liste von Büchern zum Thema; dort können Sie bei Interesse tiefer suchen.\n\n\n\n\nAinali. (2007). Standard Deviation Diagram Micro. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17–21.\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155–159.\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight (First edition). O’Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The Dynamics of Human Development Index. The Social Science Journal, 52(3), 331–347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206–213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024). Imageflip Meme. https://imgflip.com\n\n\nInternational, T. (2017, Januar 25). Corruption Perceptions Index 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nScherer, C., Radchuk, V., Staubach, C., Müller, S., Blaum, N., Thulke, H., & Kramer‐Schadt, S. (2019). Seasonal Host Life‐history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812–1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152–2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2016). Ggplot2: Elegant Graphics for Data Analysis (Second edition). Springer.\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures (First edition). O’Reilly Media. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/Practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg (Original work published 2019)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5↩︎\nGrob gesagt: mariokart %&gt;% plot_density().↩︎\nQuelle: ifes/FOM Hochschule, https://github.com/FOM-ifes/VL-Vorlesungsfolien↩︎\nQuelle: https://observablehq.com/@mcmcclur/the-normal-model↩︎\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgraf↩︎\nQuelle: https://observablehq.com/d/bb7ad3ecfb1ac2a6↩︎\nAber Freunde lassen Freunde keine Tortendiagramme verwenden: https://github.com/cxli233/FriendsDontLetFriends#10-friends-dont-let-friends-make-pie-chart.↩︎\nÜbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen: https://github.com/cxli233/FriendsDontLetFriends#1-friends-dont-let-friends-make-bar-plots-for-means-separation.↩︎\nhttps://www.data-to-viz.com/caveat/pie.html; https://github.com/cxli233/FriendsDontLetFriends#10-friends-dont-let-friends-make-pie-chart↩︎\nDer Quellcode der Animation ist hier zu finden: https://gist.github.com/rafapereirabr/0d68f7ccfc3af1680c4c8353cf9ab345.↩︎\nhttps://www.tylermw.com/wp-content/uploads/2019/06/featuredmeasles.mp4↩︎\nhttps://rpkgs.datanovia.com/ggpubr/reference/ggviolin.html↩︎\nhttps://www.autodesk.com/research/publications/same-stats-different-graphs↩︎\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md↩︎\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md#gghistostats↩︎\nhttps://flowingdata.com/category/visualization/ugly-visualization/↩︎\nSiehe auch: https://data-se.netlify.app/2023/06/30/farbpaletten/↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1 Lernsteuerung\nAbbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#lernsteuerung",
    "href": "050-zusammenfassen.html#lernsteuerung",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Lernziele\n\nSie können gängige Arten von Lagemaße definieren.\nSie können erläutern, inwiefern man ein Lagemaß als ein Modell hernehmen kann.\nSie können Lagemaße mit R berechnen.\n\n6.1.2 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n6.1.3 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer “klassische” Mittelwert (das arithmetisches Mittel) ist ein prototypisches Beispiel für ein Modell in der Statistik.\n\nÜbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hören, dass der “typische deutsche Mann” 1,80m groß ist (vgl. Roser et al., 2013)? (Ihr Vorstellung updatet sich in Definition 6.1.)\n\nDie Hälfte der Männer ist größer als 1,80 m, die andere Hälfte kleiner.\nDas arithmetische Mittel der Männer beträgt 1,80 m.\nDie meisten Männer sind 1,80 m groß.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÜbungsaufgabe 6.2 Laut dem Statistischen Bundesamt (2023-003-27) beträgt der Wert der mittleren Größe deutscher Frauen etwa 1,66m, also 14 cm weniger als bei Männern.1 \\(\\square\\)\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiß nicht \\(\\square\\)\n\n\n\n\nAuf dieser Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So könnte man z.B. sagen, “mehr als 5 cm sind viel”. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\), der Durchschnitt) beträgt: 2. \\(\\square\\)\n\n\n🧑‍🎓 Zu easy!\n\n\n🧑‍🏫 Schon gut! Chill mal. Wird gleich interessanter.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig. 😄\n\nEtwas abstrakter kann man Beispiel 6.1 in folgendem Schaubild darstellen, s. Gleichung 6.1.\n\\[\n\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} = 3 \\cdot \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}\n\\tag{6.1}\\]\nDer Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) für die “typische Note” im Statistikkurs, s. Gleichung 6.2.\n\\[\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} \\qquad \\leftrightarrow  \\qquad \\underbrace{\\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}}_{\\text{\"typischer Vertreter\"}} \\tag{6.2}\\]\n\n\n\n\n\n\nWichtig\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er eine Datenreihe zu einen “typischen Vertreter” zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller Merkmalsträger in gleichem Maße einfließen. Er gibt uns eine (mögliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen.\n\n\nEine nützliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. Abbildung 6.1.\n\n\n\n\n\nAbbildung 6.1: Mittelwert als ausbalancierte Wippe mit Mittelwert 3 (Maphry, 2009)\n\n\nIn “Mathe-Sprech” bezeichnet man den Mittelwert häufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. Gleichung 6.3.\n\\[\\bar {x} =\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.3}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert (MW, mean) der Variablen \\(X\\) (präziser: das arithmetische Mittel des Merkmal \\(X\\)) ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n\\). Den Mittelwert von \\(X\\) bezeichnet man auch mit \\(\\bar {x}\\). \\(\\square\\)\n\n\nBeispiel 6.2 Angenommen wir haben eine Reihe von Noten: 1,2,3. Der Mittelwert der Noten beträgt dann 2: \\(\\bar{X} = \\frac{1}{3}\\sum (1+2+3) = 6/3 = 2\\). \\(\\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. Abbildung 6.2 sehen wir die Noten von (dieses Mal) vier Studentis. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert.\nBezeichnen wir die Abweichung – auch als “Fehler”, “Rest” oder “Residuum” bezeichnet – der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, Fehler) und die \\(i\\)-te Note mit \\(\\color{ycol}{y_i}\\), so können wir mit Gleichung 6.4 festhalten:\n\\[\\color{ycol}{\\text{y}_i} \\color{black}{ = } \\color{modelcol}{\\;\\bar{x}\\;} + \\color{errorcol}{\\;\\text{e}_i} \\tag{6.4}\\]\nAnders ausgedrückt (s. Gleichung 6.5):\n\\[\\color{ycol}{\\text{Daten}} \\color{black}{ = }     \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}} \\tag{6.5}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe.\nUm Modelle darzustellen, wird in der Datenanalyse häufig folgende Art von Modellgleichung verwendet, s. Gleichung 6.6.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{ x}} \\tag{6.6}\\]\nLies: “Der Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)”. Der Kringel “~” soll also hier heißen “… ist eine Funktion von …”. Das “Kringel” oder die “Welle” “~” nennt man auch “Tilde”.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklärende Variable (synonym: AV, Output-Variable, Zielvariable) gemeint. Das “Dach” über dem \\(\\color{ycol}{\\text{y}}\\) bedeutet “vorhergesagter Y-Wert” oder “Y-Wert laut dem Modell”. Der tatsächliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\), s. Gleichung 6.7.\n\\[\\color{ycol}{y} \\color{black}{ = } \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}} \\tag{6.7}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (“y-Dach”). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir mit Gleichung 6.8 schreiben können:\n\\[\\color{ycol}{y}  \\color{black}{ = } \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e} \\tag{6.8}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklärt, außer gehen wir von einem Fehler \\(\\color{errorcol}e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In späteren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklären. Würden wir z.B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklären, so würden wir schreiben (s. Gleichung 6.9):\n\\[\\color{modelcol}{\\bar{y}} \\color{black}  { \\sim } \\color{xcol}{\\text{ x}} \\tag{6.9}\\]\nDa wir im Moment aber keine andere Variablen bemühen, um \\(\\color{ycol}{\\text{y}}\\) zu erklären, schreibt man mit Gleichung 6.10 auch:\n\\[\\color{modelcol}{\\bar{y}}\\;\\;  \\color{black}{\\sim \\; 1} \\tag{6.10}\\]\nDiese Schreibweise sieht verwirrend aus. Die \\(1\\) soll aber nur zeigen, dass wir keine andere Variable zur Erklärung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\). Der mathematische Hintergrund liegt in der Art, wie man Matrizen multipliziert.\n\nBeispiel 6.3 (Noten, Mittelwert und Abweichung) Vier Studentis – Anna, Berta, Carl, Dani – haben ihre Statistik-Klausur zurückbekommen (Schluck). Die Noten sehen Sie in Abbildung 6.2; gar nicht so schlecht ausgefallen. Außerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen der einzelnen Noten vom Mittelwert eingezeichnet.\\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken (Residuen, Fehler; häufig mit \\(e\\) wie error bezeichnet) in Abbildung 6.2 einmal genauer an.\n\n\n\n\n\n\n\nAbbildung 6.2: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\nJetzt stellen Sie sich vor, Sie würden die vom Mittelwert nach oben ragenden Balkenlängen aneinanderlegen (das sind die gestrichelten. Sehen Sie das vor Ihrem geistigen Auge? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht) jetzt, dass die Gesamtlänge der “Balken nach oben” identisch ist zur Gesamtlänge der nach “unten ragenden Balken”, vgl. Abbildung 6.1.\nPräziser ausgedrückt und ohne Ihre Phantasie zu strapazieren (Gleichung 6.11):\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.11}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDie Summe der Abweichungen vom Mittelwert ist Null.\n\n\n\nÜbungsaufgabe 6.3 Was schätzen Sie, wie hoch das mittlere Vermögen (arithmetisches Mittel) der Haushalte in Deutschland in etwa ist (im Jahr 2021 auf Basis einer Umfrage) (Bundesbank, 2023)?2 \\(\\square\\)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.000 Euro\n\n\n\nBeispiel 6.4 (Der wertvollste Fußballer der Welt in Ihrem Hörsaal) Kommt der wertvollste Fußballspieler der Welt in Ihren Hörsaal, sagen wir, es ist Kylian Mbappé3. Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro4.\n\n🦹 Hey Leute, wie geht’s denn so! Wie viel Kohle verdient ihr eigentlich so?\n\n\n🧑‍🎓 Äh, wir studieren und verdienen fast nix!\n\nDie 100 Studis im Hörsaal schauen verdattert aus der Wäsche: Was ist das für eine komische Frage!? Aber zumindest verteilt der Fußballspieler Autogramme.\n\n\nÜbungsaufgabe 6.4 (Mittleres Einkommen im Hörsaal, mit Kylian Mbappé) Schätzen Sie – im Kopf – das mittlere Vermögen im Hörsaal, gehen Sie davon aus, dass alle der 100 Studentis jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (präziser: das arithmetische Mittel des Einkommens) wie folgt berechnen, s. Listing 6.1. (Die Details der Syntax, z.B. der Befehl rep(), sind von geringer Bedeutung.)\n\n\nListing 6.1: Wir simulieren Einkommen von 100 Studis plus Mbappé.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100 Mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 Mbappé mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nuller hinter der führenden Eins: 1000000. In Taschenrechner- oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als “1 Mal 10 hoch 6, also mit 6 im Exponenten”.\n\n\nDer Mittelwert im Hörsaal beträgt also 1,189,109 Euro, etwas mehr als eine Million. Ist das ein gutes Modell für das “typische” Vermögen im Hörsaal?\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. Abbildung 6.3, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell verwendet eine Gerade als Modell der Daten. Es erklärt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildung 6.3: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\nAbbildung 6.3 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit (farbig markierten) Extremwerte (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (Ausreißer; outlier) ist eine Beobachtung, deren Wert deutlich vom Großteil der anderen Beobachtungen im Datensatz abweicht, z.B. viel größer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R mit dem Befehl lm.\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear modell\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl gibt als Koeffizient einen Wert zurück und zwar den Mittelwert von einkommen, vgl. auch Listing 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet, das wird verständlich, wenn man z.B. in Abbildung 6.3 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet. Die Syntax des Befehls lm() sieht etwas merkwürdig aus. Ignorieren Sie das fürs Erste, wir besprechen das später (Kapitel 9) ausführlich. lm steht übrigens für “lineares Modell”.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6  Punktmodelle 1",
    "section": "\n6.3 Median als Modell",
    "text": "6.3 Median als Modell\n\n🧑‍🎓 Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert für die Menschen im Hörsaal. Weder für den Mbappé, noch für uns Studis!\n\n\n🧑‍🏫 Ja, da habt ihr Recht.\n\n\n⚽ Die Welt ist schon ungerecht!\n\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. Abbildung 6.4) ist der Mittelwert (sehr) wenig aussagekräftig, da er nicht mehr “typische” Werte für die Merkmalsträger beschreibt.\n\n\nAbbildung 6.4 stellt die Verteilung des Einkommens einer mit “normal” skalierter Achse und einmal mit logarithmischer X-Achse. Zur Erinnerung: 4.0+e07 bedeutet \\(4 \\cdot 10^{07} = 40000000\\), eine 4 gefolgt von 7 Nullern. Die logarithmische X-Achse stellt den Unterschied von Mittelwert (MW) und Median deutlicher heraus als die normale (additive) Achse.\n\n\n\n\n\n\n\n\n\n(a) X-Achse in additiver Form\n\n\n\n\n\n\n\n\n\n\n\n(b) X-Achse in multiplikativer Form (logarithmische Darstellung)\n\n\n\n\n\n\nAbbildung 6.4: Die Einkommensverteilung im Hörsaal\n\n\nDer Mittelwert ist Hörsaal ist nicht typisch für die Menschen im Hörsaal: Weder für Mbappé, noch für die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Mittelwert ist empfänglich für Extremwerte: Gibt es einen Extremwert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wieder und weniger die Mehrheit der gemäßigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenüber Extremwerten).\n\n\n\nBeispiel 6.5 (Das Median-Einkommen einiger Studentinnen) Fünf Studentinnen tauschen sich über ihr Einkommen aus, s. Abbildung 6.5, links. Es handelt sich um eine schiefe Verteilung.\n\n\n\n\n\n\n\n\n\n(a) Einkommen auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n\n(b) Einkommen auf der X-Achse\n\n\n\n\n\n\nAbbildung 6.5: Das Median-Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\nWir könnten jetzt behaupten, dass Carla das typische Einkommen (für diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\nDefinition 6.4 (Median) Merkmalsausprägung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt. \\(\\square\\)\n\n\nÜbungsaufgabe 6.5 (Alle mal aufstehen) Auf Geheiß der Lehrkraft stehen jetzt alle Studis bitte auf und sortieren sich der Größe nach im Raum, schön in einer Reihe aufgestellt. Die Körpergröße der Person in der Mitte der Reihe, zu der also gleich viele Personen zu links wie zu rechts stehen, das ist der Medien dieser Datenreihe, vgl. Abbildung 6.6. \\(\\square\\)\n\nDer Median ist robust (gegenüber) Extremwerten: Fügt man Extremwerte zu einer Verteilung hinzu, ändert sich der Median zumeist (deutlich) weniger als der Mittelwert.\nAbbildung 6.6 stellt den Median schematisch dar.\n\n\n\n\n\n\n1,60m\n\n\n\n\n\n1,72m\n\n\n\n\n\n1,79m: Median!\n\n\n\n\n\n1,94\n\n\n\n\n\n2,12m\n\n\n\n\n\nAbbildung 6.6: Der Median als der Wert des “mittleren” Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert als der Median wie Objekte mit größerem Wert als der Median.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.6 Bei der Messreihe 1, 2, 3, 4, 5, 6, 8, 9 beträgt der Median 4.5.\\(\\square\\)\n\n\nÜbungsaufgabe 6.6 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhöht sich um das Hundertfache. Wie verändert sich der Median?5 \\(\\square\\)\n\n\nÜbungsaufgabe 6.7 (Wer ist mehr “mittel”? Median oder Mittelwert?)  \n\n🧑‍🎓 Das arithmetische Mittel sollte Mittelwert heißen, weil es die Mitte von zwei Messwerten widerspiegelt, also z.B. von 1 und 10 ist die Mitte 5,5 – also genau beim Mittelwert!\n\n\n👩 Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der Größe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion!\\(\\square\\)\n\n\nBeispiel 6.7 (Ein “mittlerer” Preis für Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median für das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist höher als der Median.\n\nmariokart &lt;- read.csv(mariokart_path)  # Der Pfad steht zu Beginn des Kapitels\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n  \n\n\n\nWie man sieht, ist der Mittelwert größer als der Median, s. Abbildung 6.7.\n\n\n\n\n\n\n\nAbbildung 6.7: Das Start-Gebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert größer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell für den “typischen Wert” vorzuziehen.\n\n\n\nÜbungsaufgabe 6.8 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die für einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis möglicherweise über die Gebühr. \\(\\square\\)\nAufgabe Entfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\nLösung\n\nmariokart_no_extreme &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# ohne Extremwerte:\nmariokart_no_extreme |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n\n\nÜbungsaufgabe 6.9 Was schätzen Sie, wie hoch das mediane Vermögen des Haushalte in Deutschland im Jahr 2021 in etwa war (Bundesbank, 2023)?6\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.00 Euro\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere Hälfte. Er markiert sozusagen eine “50-Prozent-Marke” (der aufsteigend sortierten Beobachtungen). Betrachten wir einmal nur alle Spiele, die für weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. Abbildung 6.8. 50% aller Spiele wurden für weniger als ca. 46 Euro verkauft; 50% aller Spiele für mehr als 46 Euro. Der Median beträgt als 46 Euro.\nJetzt könnten wir nur die günstigere Hälfte betrachten und wieder nach dem Median fragen (d.h. total_pr &lt; 46). Dieser “Median der günstigeren Hälfte” grenzt damit das insgesamt günstigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25%). Den Median nennt man das zweite Quartil (Q2, 50%). Entsprechend heißt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75%).\\(\\square\\)\n\n\nBeispiel 6.8 (Quartile des Verkaufsgebot) Abbildung 6.8 zeigt die Quartile für das Verkaufsgebot.\\(\\square\\)\n\nJetzt könnte man sagen, hey, warum nur in 25%-Stücke die Verteilung aufteilen? Warum nicht in 10%-Schritten?\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleiche Teile unterteilen, nennt man Dezile. \\(\\square\\)\n\nOder vielleicht in 1%-Schritten oder in sonstigen Schnitten? Wo die Quartile in 25%-Schritten aufteilen, teilt in Quantil in \\(p\\)-Prozent-Schritten auf. S. Abbildung 6.9 dazu.\n\nDefinition 6.7 (Quantile) Ein p-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht überschritten wird.\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Quantil ist ein Oberbegriff für Quartile, Dezile, etc. \\(\\square\\)\n\n\nAbbildung 6.8 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil für den Datensatz mariokart2.\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 3: Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)\n\n\n\n\nAbbildung 6.8\n\n\nVerschiedene Arten von Quantilen.\n::::\nQuantile kann man in R mit dem Befehl quantile() berechnen:\n\nmario_quantile &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(q25 = quantile(total_pr, .25),\n            q50 = quantile(total_pr, .50),\n            q75 = quantile(total_pr, .75))\n\nAbbildung 6.9 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildung 6.9: Verschiedenen Quantile animiert\n\n\nAbbildung 6.10 visualisiert verschiedene Quantile. Man beachte, dass alle Regionen gleichgroße Flächen (d.h. Wahrscheinlichkeitsmassen) aufweisen.\n\n\n\n\n\n\n\n\n\n(a) 25%-Schritte: Quartile\n\n\n\n\n\n\n\n\n\n(b) 10%-Schritte: Dezile\n\n\n\n\n\n\n\n\n\n(c) 1%-Schritte: Perzentile\n\n\n\n\n\n\nAbbildung 6.10: Verschiedene Quantile visualisiert. In jedem Diagramm sind die Regionen gleich groß, beinhalten also (ungefähr) die gleiche Anzahl von Beobachtungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6  Punktmodelle 1",
    "section": "\n6.5 Lagemaße",
    "text": "6.5 Lagemaße\n\n🧑‍🎓 Was ist der Oberbegriff für Median, Mittelwert und so weiter?\n\n\n🧑‍🏫 Gute Frage! Wie würden Sie ihn nennen?\n\n\nDefinition 6.8 (Lagemaß) Ein Lagemaß (synonym: Maß der zentralen Tendenz) für eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, erwartbar, repräsentativ oder “mittel” ansehen sollten.\\(\\square\\)\n\n\nBeispiel 6.9 Gebräuchliche Lagemaße sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuantile wie z.B. Quartile\nMinimum (kleinster Wert)\nMaximum (größter Wert)\nModus (häufigster Wert) \\(\\square\\)\n\n\n\nBerechnen wir Lagemaße für den Mariokart-Datensatz, s. Listing 6.2. Es ist übrigens egal, wie sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname – alles okay!\n\n\nListing 6.2: Syntax zur Berechnung von Lagemaßen\n\n\nmariokart_lagemaße_total_pr &lt;-\n  mariokart %&gt;% \n  summarise(mw = mean(total_pr),\n            md = median(total_pr),\n            q1 = quantile(total_pr, .25),\n            q2 = quantile(total_pr, .5),\n            q3 = quantile(total_pr, .75),\n            min = min(total_pr),\n            max = max(total_pr))\nmariokart_lagemaße_total_pr\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.1 Gruppierte Lagemaße\nHäufig möchte man Statistiken wie Lagemaße für mehrere Teilgruppen – z.B. Mittlere Körpergröße von Frauen vs. Mittlere Körpergröße von Männer – berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage könnte lauten:\n\nUnterscheidet sich die mittlere Körpergröße von Frauen und Männern?\n\nOder vielleicht:\n\nHat das Geschlecht einen Einfluss auf die Körpergröße?\n\nAnders ausgedrückt:\n\nKörpergröße \\(\\color{ycol}{\\text{y}}\\) ist eine Funktion des Geschlechts \\(\\color{xcol}{G}\\).\n\nDie Modellformel könnte also lauten:\n\\[\\color{ycol}{y} \\; \\color{black}{ \\sim } \\; \\color{xcol}{G}\\]\nGruppierte Lagemaße lassen sich in R z.B. so berechnen, s. Listing 6.3, also ähnlich wie in Listing 6.2.\n\n\nListing 6.3: Gruppierte Lagemaße\n\n\nmariokart_lagemaße_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\nmariokart_lagemaße_gruppiert\n\n\n  \n\n\n\n\n\n\nAbbildung 6.11 zeigt ein Beispiel für ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. Abbildung 6.3. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, “globalen” Mittelwert): Innerhalb der Gruppe ohne Lenkräder und innerhalb der Gruppe mit 2 Lenkrädern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering – im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\n\n\n\n\n\n\n\n\n(a) Mittelwert für Verkaufspreis (ungruppiert)\n\n\n\n\n\n\n\n\n\n(b) Mittelwert für Verkaufspreis gruppiert nach Anzahl der Lenkräder\n\n\n\n\n\n\nAbbildung 6.11: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches für alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heißt ein Punktmodell. Anders gesagt fasst ein Punktmodell eine Wertereihe (häufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem “Punkt” in diesem Sinne, s. Gleichung 6.12.\\(\\square\\)\n\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{6.12}\\]\nMittelwert, Median und Quartile sind Beispiele für Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein “Bild” der Daten, machen Sie uns verständlich - sie sind uns ein Modell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "title": "6  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lügt",
    "text": "6.6 Wie man mit Statistik lügt\nMit Statistik kann man vortrefflich lügen, heißt es. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lässt: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzuführen. Viele Wege führen nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und Unschärfen ohne böse Abwehr aufzudecken, gibt es ein probates Gegenmittel: Transparenz.\n\nStellen Sie hohe Anforderung an die Transparenz einer statistischen Analyse. Nur durch Nachprüfbarkeit können Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation überzeugen.\n\nHier ist eine (nicht abschließende!) Checkliste, was Sie nachprüfen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\nWurden ausreichend Daten gesammelt (z.B. mind. 20 Beobachtungen pro Gruppe)?\nWurden alle untersuchten Variablen berichtet?\nWurden alle durchgeführten Interventionen berichtet?\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) Begründung?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.10 (Survival-Tipp) Eine Studentin aus dem dem Bachelorstudiengang “Angewandte Medien- und Wirtschaftspsychologie” mit Schwerpunkt Data Science berichtet ihre “Survival-Tipps” für Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich während des Semesters neue Begriffe und ihre Erklärung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in höheren Semestern nach Tipps fragen.\\(\\square\\)\n\n\n\n\n🧑‍🎓 Irgendwie kann ich mir R-Code so schlecht merken.\n\n\n🧑‍🏫 Frag doch mal ChatGPT, oder einen anderen Chatbot, da bekommt man auch R-Code ausgegegeben.\n\n\nÜbungsaufgabe 6.10 (Übungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Übungsaufgaben.\nSie können sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\n🧑‍🎓 Ich bin ein Student in einem Bachelor-Studiengang für Psychologie. Gerade bereite ich mich auf die Klausur im Fach “Grundlagen der Statistik” vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die Prüfung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: Maße der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.B. Nominalskala vs. Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben.\n\n\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der folgenden Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber später kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekannte Stoff.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\n\n\n\n\n\n\nTipp\n\n\n\nSchauen Sie sich auch mal auf datenwerk.netlify.app die Aufgaben zu z.B. dem Tag EDA an. \\(\\square\\)\n\n\n\nÜbungsaufgabe 6.11 Mittlerweile verfügen Sie die wesentlichen Werkzeuge des Datenjudo. Hier finden Sie einen Überblick an Datensätze, die Sie nach Herzenslust analysieren können.7 \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele Lehrbücher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehören zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel für Lehrbücher sind Mittag & Schüller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Ein Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurückschreckt, ist mit Cetinkaya-Rundel & Hardin (2021) oder Poldrack (2022) gut beraten. Beide Bücher sind online verfügbar. Tipp: Mit dem Browser einfach auf Deutsch übersetzen.\n\n\n\n\nBortz, J., & Schuster, C. (2010). Statistik Für Human- Und Sozialwissenschaftler. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBundesamt, S. (2023-003-272023-003-27). Körpermaße nach Altersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household Wealth and Finances in Germany: Results of the 2021 Household Wealth Survey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMaphry. (2009). Seesaw with Mean. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und Spaß im Horrorfach nichttechnischer Studiengänge. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height. Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., Aert, R. C. M. van, & Assen, M. A. L. M. van. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Average_human_height_by_country↩︎\n316500€↩︎\nQuelle: https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop, Abruf 2023-03-19↩︎\nQuelle: https://www.einkommenmagazin.de/kylian-mbappe-einkommen/, Abruf 2023-03-19↩︎\nEr bleibt gleich, verändert sich also nicht: Der Median ist robust, er verändert sich nicht oder kaum, wenn Extremwerte vorliegen.↩︎\nca. 83600€↩︎\nhttps://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1 Lernsteuerung\nAbbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#lernsteuerung",
    "href": "060-modellguete.html#lernsteuerung",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1.1 Lernziele\n\nSie kennen gängige Maße der Streuung einer Stichprobe und können diese definieren und mit Beispielen erläutern.\nSie können gängige Maße der Streuung einer Stichprobe mit R berechnen.\nSie können die Bedeutung von Streuung für die Güte eines Modells erläutern.\n\n7.1.2 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)\n\n\n7.1.3 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n7.1.4 Zum Einstieg\n\nÜbungsaufgabe 7.1 (Freiwillige vor!) Für diese kleine Live-Demonstration brauchen wir einige Freiwillige. Die Lehrkraft teilt die Freiwilligen in zwei Gruppen, Gruppe Gleich-Groß und Gruppe Verschieden-Groß. Erkennen Sie, dass die Unterschiedlichkeit der Größe in Gruppe Gleich-Groß gering ist, aber in Gruppe Verschieden-Groß hoch? \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "href": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.2 Warum Sie die Streuung Ihrer Daten kennen sollten",
    "text": "7.2 Warum Sie die Streuung Ihrer Daten kennen sollten\n\n7.2.1 Die Schlankheitspille von Prof. Weiss-Ois\nProf. Weiss-Ois hat eine Erfindung gemacht, eine Schlankheitspille💊 (flaticon, 2024).\n\n\n\n\n\n\nWas er sagt: “Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!”\n\n\n\n \n\n\n\n\nWas er NICHT sagt: “Allerdings streuten die Werte der Gewichtsveränderung um 10kg um den Mittelwert herum.”\n\n\n\n\n\nAbbildung 7.1\n\n\n\nWürden Sie die Pille von Prof. I. Ch. Weiss-Ois nehmen?\n\nja, ich zahle 1000 Euro!\nja\nnein\nNur wenn ich 100 Euro bekomme\nOkay, für 1000 Euro\\(\\square\\)\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information.\\(\\square\\)\n\n\n\n7.2.2 Wie man seine Kuh über den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss überqueren, nur kann die Kuh nicht schwimmen (ob es Fritz kann, ist nicht überliefert).\n\n👨‍🌾 (Fritz): Sag mal, Karla, ist der Fluss tief?\n\n\n👩‍🌾 (Karla): Nö, im Schnitt nur einen Meter.\n\nAlso führt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, im Floß ersoffen, s. Abbildung 7.2.\n\n\n\n\n\nAbbildung 7.2: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\n👩‍🌾 (Karla): Übrigens, Lagemaße sagen nicht alles, Fritz.\n\n\n👨‍🌾 (Fritz): Läuft die Kuh durch den Fluss, kann sie schwimmen oder ’s ist Schluss.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Streuung ihrer Daten zu kennen ist eine wesentliche Information. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.3 Woran erkennt man ein gutes Modell?",
    "text": "7.3 Woran erkennt man ein gutes Modell?\nAbbildung 7.3 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen. Die vertikalen grauen Balken in Abbildung 7.3 kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale orange Linie). Je länger die vertikalen ‘Abstandsbalken’ insgesamt, desto größer die Streuung.”\n\n\n\n\n\n\n\nAbbildung 7.3: Wenig (links) vs. viel Streuung (rechts).\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsächlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groß.\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof. Weiss-Ois) In Abbildung 7.3 sind die Daten zu der Gewichtsveränderung nach Einnahme von “Schlankheitspillen” zweier verschiedener Präparate. Wie man sieht unterscheidet sich die typische (vorhergesagte) Gewichtsveränderung zwischen den beiden Präparaten kaum. Die Streuung allerdings schon. Links sieht man die Gewichtsveränderungen nach Einnahme des Präparats “Dickableibtin extra mild” (c) und rechts das Präparat von Prof. Weiss-Ois “Pfundafliptan Forte”. Welches Präparat würden Sie lieber einnehmen?\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nWir wollen ein präzises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklären, also wenig vom tatsächlichen Wert abweichen. Jedes Modell sollte Informationen über die Präzision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellgüte, d.h. der Präzision der Schätzung des Modellwerts, ist wenig nütze.\\(\\square\\)\n\n\n\n🧑‍🎓 Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\n🧑‍🏫 Die Frage ist, was wir mit “verbessern” meinen?\n\n\n🧑‍🎓 Naja, kürzere Fehlerbalken, ist doch klar!\n\nIm Beispiel von Marikoart: Da die Anzahl der Lenkräder mit dem Verkaufsgebot zusammenhängt, könnte es vielleicht sein, dass wir die Lenkräder-Anzahl da irgendwie nutzen könnten. Das sollten wir ausprobieren. Abbildung 7.4 zeigt, dass die Fehlerbalken kürzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 Lenkrädern vs. mit 0 Lenkrädern) sind die Fehlerbalken jeweils im Durchschnitt kürzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm). Aus Gründen der Übersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berücksichtigt und nur Spiele mit 0 oder mit 2 Lenkrädern.\n\n\n\n\n\n\n\n\n\n(a) Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt. y ~ 1\n\n\n\n\n\n\n\n\n\n(b) Fehlerbalken im komplexen Modell: Zwei Mittelwerte; weniger Streuung in jeder Gruppe. Das erkennt man daran, dass die vertikalen, grauen Abstandsbalken im Schnitt kürzer sind als im einfachen Modell (links). y ~ G\n\n\n\n\n\n\nAbbildung 7.4: Fehlerbalken in einem einfachen und komplexeren Modell\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.4 Streuungsmaße",
    "text": "7.4 Streuungsmaße\n\nDefinition 7.1 (Streuungsmaße) Ein Streuungsmaß quantifiziert die Variabilität (Unterschiedlichkeit, Streuung) eines Merkmals. \\(\\square\\)\n\n\nDefinition 7.2 Ein einfaches Streuungsmaß ist der Range \\(R\\), definiert als Abstand von größtem und kleinsten Wert eines Merkmals \\(X: R = X_{max} - X_{min}. \\square\\)\n\n\nBeispiel 7.2 Angenommen, wir haben einen Datensatz zum Merkmal “Alter” mit den Werte 1, 23, 42, 100. Dann beträgt der Range: \\(R = 100 - 1 = 99\\). Das bedeutet, dass die Werte des Merkmals über 99 Einheiten (Jahre in diesem Fall) verteilt sind. \\(\\square\\)\n\nDieses Mermals ist aber nicht robust (gegenüber Extremwerten) und sollte daher nur mit Einschränkung verwendet werden.\n\n7.4.1 Der mittlere Abweichungsbalken\n\n🧑‍🎓 Wir müssen jetzt mal präziser werden! Wie können wir die Streuung berechnen?\n\n\n🧑‍🏫 Gute Frage! Am einfachsten ist es, wenn wir die mittlere Länge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir wir den “mittleren Abweichungsbalken”, den wir mit \\(\\bar{e}\\) bezeichnen könnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als Mittlere Absolutabweichung (MAA). Er ist so definiert, s. Gleichung 7.1.\n\\[{\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}=\\bar{e}.} \\tag{7.1}\\]\n\nDefinition 7.3 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte. (Wenn man solche Sätze liest, fühlt sich die Formel fast einfacher an.)\\(\\square\\)\n\n\nBeispiel 7.3 Abbildung 7.5 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE für das Beispiel von Abbildung 7.5 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5 \\quad \\square\\)\n\n\n\n\n\n\n\n\nAbbildung 7.5: Abweichungsbalken und der MAE\n\n\n\n\nNatürlich können wir R auch die Rechenarbeit überlassen.\n\n🤖 Loving it!!\n\nSchauen Sie: Den Mittelwert (s. Abbildung 7.5) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? Schließlich erklären wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse ist).\nIn R gibt es einen Befehl für ein lineares Modell, er heißt lm.\nDie Syntax von lm() lautet:\nlm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur Erklärung von Y. Aber verwende keine andere Variable zur Erklärung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm1 &lt;- lm(y ~ 1, data = d)\n\nDen MAE können wir uns jetzt so ausgeben lassen:\n\nmae(lm1)\n## [1] 1.5\n\n\n7.4.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein Streuungsmaß, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.\n\nDefinition 7.4 (Interquartilsabstand) Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil: \\(IQR = Q_3-Q_1. \\; \\square\\)\n\n\nBeispiel 7.4 (IQR im Hörsaal) In einem Statistikkurs betragen die Quartile der Körpergröße: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR beträgt dann: \\(IQR = Q_3-Q_1 = 1.75m - 1.65m = 0.10m\\), d.h. 10 cm.\\(\\square\\)\n\nAbbildung 7.6 stellt den IQR (und einige Quantile) für den Verkaufspreise von Mariokart-Spielen dar.\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 7.6: IQR, Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)\n\n\n\n7.4.3 Streuungsmaße für Normalverteilungen\nNormalverteilungen sind recht häufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu überlegen, wie man diese Verteilungen gut zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett über ihren Mittelwert sowie ihre Standardabweichung beschreiben lässt (Lyon, 2014). Außerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), “verschiebt man den Berg” ja nur zur Seite, ohne seine Form zu verändern, s. Abbildung 7.11.\n\n\n\n\n\n\nHinweis\n\n\n\nHat man normalverteilte Variablen/Abweichungen/Residuen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma, s\\)) eine komfortable Maßeinheit der Streuung, denn damit lässt sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\\(\\square\\)\n\n\n\n🧑‍🎓 Aber wie berechnet man jetzt diese Standardabweichung?\n\n\n🧑‍🏫 Moment, noch ein kurzer Exkurs zur Varianz …\n\n\n🧑‍🎓 (seufzt)\n\n\n7.4.4 Varianz\n\n7.4.4.1 Intuition\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 7.9 illustriert die Varianz:\n\nMan gehe von der Häufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan bilde Quadrate für jeden Datenpunkt mit der Kantenlänge, die dem Abstand des Punktes zum Mittelwert entspricht.\nDie Quadrate quetscht man jetzt wo nötig in rechteckige Formen (ohne dass sich die Fläche ändern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit Seitenlänge \\(n\\) und \\(\\sigma^2\\) anordnen.\n\n\n\n\n\n\n\n\nAbbildung 7.7: Illustration zur Varianz als “mittlerer Quadratfehler” (Cmglee, 2015)\n\n\n\n\n\nAbbildung 7.8 visualisiert die Varianz für Beispiel 7.3.1\nLinks sind die Abweichungsquadrate dargestellt, rechts die Varianz als “typisches Abweichungsquadrat”.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz ist also ein Maß, das die typische Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als ‘typischer’ Fehlerbalken\n\n\n\n\n\n\nAbbildung 7.8: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\n\nBeispiel 7.5 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. Natürlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.\nDazu berechnen Sie die Streuung in den Verkaufspreisen, s. Listing 7.1. \\(\\square\\)\n\n\n\nListing 7.1: Berechnung der Streuung des Verkaufpreises als Indikatoren für die Modellgüte des Mittelwerts.\n\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  mariokart_no_extreme %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47.43\n12.99\n7.20\n83.06\n9.11\n\n\n\n\nStatistiken sind ja schön … aber Bilder sind auch gut, s. Abbildung 7.9. Datendiagramme eignen sich gut, um (grob) die Streuung einer Variable zu erfassen.\n\nmariokart %&gt;% \n  mariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_density()\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm mit MW±SD in roter Farbe\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm mit MW±SD in roter Farbe\n\n\n\n\n\n\nAbbildung 7.9: Die Verteilung des Verkaufspreises von Mariokart-Spielen\n\n\nWer sich die Berechnung von Hand für pr_maa sparen möchte (s. Listing 7.1), kann die Funktion MeanAD aus dem Paket DescTools nutzen.\n\n7.4.4.2 Kochrezept für die Varianz\nUm die Standardabweichung zu berechnen, berechnet man zunächst die Varianz, \\(s^2\\) abgekürzt. Hier ist ein “Kochrezept” (Algorithmus) zur Berechnung der Varianz:\n\nFür alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\)\n\nQuadriere diese Werte\nSummiere dann auf\nTeile durch die Anzahl \\(N\\) der Werte\n\nAls Formel ausgedrückt, lautet die Definition der Varianz einer Stichprobe wie folgt, s. Gleichung 7.2 (hier geht es um die sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehörigen Population zu schätzen, teilt man nicht durch \\(N\\), sondern durch \\(N-1\\)) .\n\\[{\\displaystyle s^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}e_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.5 (Varianz) Die Varianz (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen, \\(e_i^2\\), (vom Mittelwert).\\(\\square\\)\n\nDie Varianz steht im engen Verhältnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. Gleichung 7.3.\n\\[{\\displaystyle MSE={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(y_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.\n\n7.4.5 Die Standardabweichung\nKennt man die Varianz, so lässt sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.\n\nDefinition 7.6 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. Gleichung 7.4.\n\\[s := \\sqrt{s^2} \\square \\tag{7.4}\\]\n\nDurch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche Größenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groß werden kann).\nAus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(RMSE := \\sqrt{MSE}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.\\(\\square\\)\n\n\n\nBeispiel 7.6 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution, s. Tabelle 7.1.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n\n\nTabelle 7.1: Ausgabe der Funktion describe_distribution (Auszug)\n\n\n\n  \n\n\n\n\n\n\n\n🧑‍🎓 Ah! Das war einfach. Reicht auch mal für heute.\\(\\square\\)\n\n\n\nBeispiel 7.7 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. Bevor Sie nach Hause gehen, möchten Sie noch eine Sache anschauen. In einer früheren Analyse (s. Abbildung 7.4) fanden Sie heraus, dass die Fehlerbalken kürzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natürlich prüfen. Sie überlegen: “Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.”\nDas spezifizieren Sie so:\n\nlm1 &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm1)\n## [1] 10\n\nIm nächsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufpreis eine Funktion der Anzahl der Lenkräder ist (ähnlich wie in Abbildung 7.4):\n\nlm2 &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm2)\n## [1] 7.4\n\nAh! Sehr schön, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach Hause!\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.5 Streuung als Modellfehler",
    "text": "7.5 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellgüte auffassen.\nDefinieren wir zunächst als Punktmodell auf Errisch:\n\nlm_mario1 &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne Prädiktoren, sondern als Punktmodell, und zwar schätzen wir den Mittelwert mit den Daten mariokoart.\nDas (Meta-)Paket easystats bietet komfortable Befehle, um die Modellgüte zu berechnen:\n\nmae(lm_mario1)  # Mean absolute error\n## [1] 10\nmse(lm_mario1)  # Mean squared error\n## [1] 655\nrmse(lm_mario1)  # Root mean squared error\n## [1] 26",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#z-transformation",
    "href": "060-modellguete.html#z-transformation",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.6 z-Transformation",
    "text": "7.6 z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. mariokart_no_extreme.\n\nmariokart_no_extreme &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nAbbildung 7.10 (links) zeigt, dass es einige Streuung um den Mittelwert herum gibt. Abbildung 7.10 (rechts) zeigt die (um den Mittelwert) zentrierten Daten.\n\n\n\n\n\n\n\n\n\n(a) Wie nah drängen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert: zentrierte Daten\n\n\n\n\n\n\nAbbildung 7.10: Verteilung von mariokart_no_extreme\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell für die Daten, bzw. desto höher die Modellgüte.\\(\\square\\)\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie überlegen … und überlegen. Da! Eine Idee!\nMan könnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je größer diese Abweichung, desto schlechter die Modellgüte! Also rechnen Sie diese Abweichung aus.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw = 47.4 - total_pr)\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.7 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert abzuziehen. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 7.11: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt\n\n\n\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Überlegungen: Woher weiß man, ob 10 Euro oder 20 Euro “viel” Abweichung vom Verkaufspreis ist? Man müsste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man könnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, ähnlicher Kennwert zur mittlerer absolute Abweichung ist die SD. Sie haben gehört, dass die SD gebräuchlicher ist als die MAA. Um sich als Checker zu präsentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja ähnlich.\nAlso: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte, dann hätten wir eine “standardisierte” (abgekürzt manchmal mit std) Abweichung von 1, weil 10/10=1.\nBegeistert über Ihre Schlauheit machen Sie sich ans Werk.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. Abbildung 7.12. In Abbildung 7.12 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als standardisiert bezeichnen, da wir sie in Bezug zur “typischen Abweichung”, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildung 7.12: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (“Transformation”) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.8 (z-Werte) z-Werte sind das Resultat der z-Transformation. Für die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i = \\frac{x_i - \\bar{x}}{sd_x}.\\square\\)\n\nz-Werte sind nützlich, weil sie die “relative” Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.\nNach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, Ausreißern), wenn \\(z_i &gt; 2\\) oder \\(z_i &gt; 3\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#fazit",
    "href": "060-modellguete.html#fazit",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.7 Fazit",
    "text": "7.7 Fazit\nDer “gesunde Menschenverstand” würde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Das ist vernünftig, denn die MAA ist anschaulicher und damit nützlicher als die Varianz und die SD.\nWarum sollte man überhaupt ein unanschauliches Maß wie die Varianz verwenden? Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. Gründe, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:\n\nDie SD ist sehr nützlich zur Beschreibung der Normalverteilung\nDie Varianz wird häufig verwendet bzw. in Forschungsarbeiten berichtet, also müssen Sie die Varianz kennen.\n\nLiegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenüber Mittelwert basierten Streuungsmaßen (MAA, Varianz, SD).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\n7.8.1 Datenwerk\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nmariokart-sd2\nmariokart-sd3\nKennwert-robust\nsummarise04\nsummarise05\nvis-mariokart-variab\nsd-vergleich\nnasa01\nStreuung-Histogramm\nmariokart-sd1\nsummarise06\nmariokart-desk01\n\n\nÜbungsaufgabe 7.2 (Analysieren Sie den Datensatz zur Handynutzung)  \n\n\n\n\n\n\nDas ist die Forschungsfrage dieser Umfrage. Nehmen Sie ggf. an dieser Umfrage teil (sie ist anonym und dauert drei Minuten).\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaden Sie den Datensatz zur Handynutzung von Google-Docs herunter.2 Berechnen Sie dann gängige deskriptive Statistiken und visualisieren Sie sie. \\(\\square\\)\n\n7.8.2 Lösung: Daten importieren\nSie können die Daten entweder selber herunterladen oder aber die folgende Version des Datensatzes verwenden. In beiden Fällen ist es nützlich, den (absoluten oder relativen) Pfad anzugeben:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\n\nDann können Sie die Daten wie gewohnt importieren:\n\nsmartphone_raw &lt;- read.csv(data_path)\n\n\n7.8.3 Lösung: Daten aufbereiten\nDie Spaltennamen sind sehr unschön. Lassen Sie uns daher die Spaltennamen umbenennen (aber vorab sichern):\n\nitem_labels &lt;- names(smartphone_raw)\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:ncol(smartphone_raw))\n\nCheck:\n\nglimpse(smartphone_raw)\n## Rows: 70\n## Columns: 18\n## $ item1  &lt;chr&gt; \"21/03/2024 15:36:52\", \"05/04/2024 10:24:58\", \"05/04/2024 10…\n## $ item2  &lt;chr&gt; \"15:31:00\", \"10:23:00\", \"10:40:00\", \"11:14:00\", \"12:33:00\", …\n## $ item3  &lt;int&gt; 3, 4, 3, 3, 5, 5, 5, 5, 1, 2, 5, 3, 2, 2, 2, 5, 3, 1, 2, 4, …\n## $ item4  &lt;int&gt; 5, 3, 3, 3, 4, 3, 3, 6, 2, 4, 5, 1, 1, 2, 3, 3, 4, 3, 2, 4, …\n## $ item5  &lt;int&gt; 3, 3, 1, 5, 1, 3, 2, 4, 3, 2, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, …\n## $ item6  &lt;int&gt; 4, 2, 4, 3, 5, 4, 6, 3, 2, 5, 6, 4, 2, 6, 5, 5, 5, 5, 5, 4, …\n## $ item7  &lt;int&gt; 4, 3, 2, 3, 3, 1, 3, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 2, 2, 2, …\n## $ item8  &lt;int&gt; 1, 3, 1, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 4, 1, 1, 2, 2, 1, 2, …\n## $ item9  &lt;int&gt; 2, 6, 1, 3, 6, 5, 5, 2, 2, 5, 6, 1, 1, 5, 4, 6, 2, 4, 3, 4, …\n## $ item10 &lt;int&gt; 2, 5, 5, 3, 4, 3, 1, 5, 1, 5, 3, 4, 3, 5, 4, 4, 4, 5, 3, 2, …\n## $ item11 &lt;int&gt; 5, 6, 6, 5, 6, 6, 5, 6, 4, 3, 6, 4, 4, 5, 3, 6, 6, 4, 4, 5, …\n## $ item12 &lt;int&gt; 1, 3, 1, 2, 5, 2, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, …\n## $ item13 &lt;int&gt; 4, 3, 4, 2, 4, 2, 5, 3, 1, 1, 4, 1, 3, 4, 1, 3, 5, 2, 1, 4, …\n## $ item14 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item15 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item16 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ item17 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item18 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n7.8.4 Komplette Lösung\n😁\n\n\n\n7.8.5 Fallstudie zur Lebenszufriedenheit\nDie OECD führt eine weltweite Studie zur Lebenszufriedenheit durch.3 Arbeiten Sie die die Fallstudie “oecd-yacsda” im Datenwerk durch, um ein tieferes Verständnis für die Lebenszufriedenheit in verschiedenen Ländern der Welt zu bekommen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.9 Literaturhinweise",
    "text": "7.9 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnüglich zu lesenden Buch eine kurzweilige Einführung in die Statistik vor; auch Streuungsmaße haben dabei einen Auftritt. Wer mehr “Lehrbuch-Feeling” sucht, wird bei Cetinkaya-Rundel & Hardin (2021) fündig (das Buch ist online frei verfügbar). Es ist kein Geheimnis, dass Streuungsmaße keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne Streuungsmaße geht’s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonst wo) aus dem Regal ziehen, fündig werden zu diesem Thema. Die Bücher unterscheiden sich meist “nur” in ihrem Anspruch bzw. der didaktischen Aufmachung; für alle ist da was dabei.\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric Visualisation of the Variance of the Example Distribution (2, 4, 4, 4, 5, 5, 7, 9) on w:Standard Deviation. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nflaticon. (2024). Professor. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621–649. https://doi.org/10.1093/bjps/axs046",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine…↩︎\nhttps://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing↩︎\nhttps://www.oecd.org/wise/measuring-well-being-and-progress.htm↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#lernsteuerung",
    "href": "070-zusammenhaenge.html#lernsteuerung",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Standort im Lernpfad\nAbbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n8.1.2 Lernziele\n\nSie können die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenhänge erläutern.\nSie können die Stärke einer Korrelation einschätzen.\n\n8.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n8.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n8.1.5 Zum Einstieg\n\nBeispiel 8.1  \n\nSuchen Sie sich eine vertrauenwürdige Partnerin oder einen vertrauenswürdigen Partner. Im Zweifel reicht die Person, die neben Ihnen sitzt. 😁\n\nNennen Sie zwei Variablen, die wie folgt zusammenhängen:\n\n\ngleichsinnig (Viel von dem einen, viel von dem anderen)\ngegensinnig (viel von dem einen, wenig von dem anderen)\nScheinzusammenhang (hängt zusammen, ist aber nicht “echt” bzw. kausal)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl, zu einem “Punkt” sozusagen, zusammengefasst werden kann.\nIn diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. Gleichung 8.1.\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{8.1}\\]\nWo wir in Kapitel 6 eine Variable mit Hilfe eines Lagemaßes beschrieben (bzw. dargestellt, zusammengefasst, modelliert) haben, tun wir hier das Gleiche für zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen voneinander (statistisch) abhängen bzw. miteinander (in welcher Form auch immer) zusammenhängen. Wir begrenzen auf metrische Variablen.\n\n8.2.1 Beispiele für Zusammenhänge\n\nLernzeit und Klausurerfolg\nKörpergröße und Schuhgröße\nVerbrauchtes Benzin und zurückgelegte Strecke\nProduktionsmenge und Produktionskosten\nBildschirmzeit und Schlafqualität\nUmweltschutz und Biodiversifität \\(\\square\\)\n\nDie Verbildlichung (Visualisierung) zweier metrischer Variablen haben wir bereits in Kapitel 5.5.2 kennengelernt. Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal Abbildung 8.1.\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)\n\n\n\n\n\n\n\n\n\n(b) ‘Verwackeltes’ Streudiagramm, um die einzelnen Punkte besser zu erkennen\n\n\n\n\n\n\nAbbildung 8.1: Visualisierung des Zusammenhangs von wheels und total_pr",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\nDie Stärke des linearen Zusammenhangs zweier metrischer Variablen kann man gut mithilfe von Abweichungsrechtecken veranschaulichen. Los geht’s!\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.2 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurückbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhängen.1 Gar nicht so schlecht ausgefallen wie gedacht …, s. Tabelle 8.1.\\(\\square\\)\n\n\n\n\nTabelle 8.1: Punkte in der Statistikklausur (0-100) und Lernzeit (0-100)\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. Abbildung 8.2. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso für \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\).\nDie Fläche des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\).\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 8.2: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus Abbildung 8.2. Nennen wir das resultierende Rechteck das “Summenrechteck”. Ja, ich weiß, ich strapaziere mal wieder Ihre Phantasie. Jetzt kommt’s: Je größer die Fläche des Summenrechtecks, desto stärker der (lineare) Zusammenhang. Beachten Sie, dass die Flächen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die Füllfarben der Rechtecke verdeutlichen dies, s. Abbildung 8.2. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendl≥inie) ist. So zeigt Abbildung 8.3 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) überwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ überwiegt).\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten 1 und 3) überwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\n\n\n\n(b) Positive Vorzeichen (Quadranten 1 und 3) überwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildung 8.3: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die Flächen der Abweichungsrechtecke addiert.\n\n\nWir können das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das ändert nichts an der Aussage, aber der Mittelwert hat gegenüber der Summe den Vorteil, dass er unabhängig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck.\nEin Maß für den Zusammenhang von Lernzeit und Klausurpunkte ist also die Fläche des mittleren Abweichungsrechtecks, s. Abbildung 8.4.\n\n\n\n\n\nAbbildung 8.4: Die Kovarianz als mittleres Abweichungsrechteck. Die Fläche der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die Fläche des mittleren Abweichungsrechtecks. Sie ist ein Maß für die Stärke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. Abbildung 8.4.\\(\\square\\)\n\n\n🧑‍🎓 Zu viele Bilder! Ich brauch Zahlen.\n\n\n🧑‍🏫 Kommen gleich!\n\nTabelle 8.2 zeigt die Werte für die X- und Y-Abweichung und die resultierenden Flächen der Abweichungsrechtecke. Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv2\n\n\n\nTabelle 8.2: Werte der Abweichungsrechtecke. avg: average (Mittelwert), cov_sign: Vorzeichen der Kovarianz,_pos: positiver Wert auf der entsprechenden Achse (x/y), xy_area: Produkt von x_delta und y_delta\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51\n17\n20.8\n1\n353\n\n\n2\n44\n40\n53\n51\n-13\n-7.2\n1\n94\n\n\n3\n39\n35\n53\n51\n-18\n-12.2\n1\n220\n\n\n4\n50\n67\n53\n51\n14\n-1.2\n-1\n-18\n\n\n\n\n\n\n\n\nBerechnen wir als nächstes das mittlere Abweichungsrechteck, die Kovarianz:\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. Gleichung 8.2:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.2}\\]\nGleichung 8.2 in Worten ausgedrückt:\n\nRechne für jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne für jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere für alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die Flächen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.3 (Variablen mit positiver Kovarianz)  \n\nGröße und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf\\(\\square\\)\n\n\n\n\nBeispiel 8.4 (Variablen mit negativer Kovarianz)  \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und Depressivität\\(\\square\\)\n\n\n\nDrei Extrembeispiele für Kovarianz-Werte sind in Abbildung 8.5 dargestellt.\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\n\n\n\n(c) negativer Zusammenhang\n\n\n\n\n\n\nAbbildung 8.5: Verschiedene Werte der Kovarianz\n\n\nBei einer Kovarianz von (ungefähr) Null ist die Gesamt-Fläche der Abweichungsrechtecke, wenn man sie pro Quadrant aufsummiert, ungefähr gleich groß, s. Abbildung 8.6. Zur Erinnerung: Bei der Varianz waren es Quadrate; bei der Kovarianz sind es jetzt Rechtecke. Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so beträgt die Summe in etwa (oder genau) Null.\nDamit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null, s. Gleichung 8.3: Wenn die Summe der Aweichungsrechtecke Null ist, dann ist auch ihr Mittelwert (MW) Null. Damit ist die Kovarianz Null.\n\\[\\begin{aligned}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{MW} \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov}(X, Y) &= 0\n\\end{aligned} \\tag{8.3}\\]\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\n\n\n\nAbbildung 8.6: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhängig ist von der Skalierung. So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wünschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabhängig davon, ob man Einkommen in Euro, Cent oder Dollar misst. Außerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson löst das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nämlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so führt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) definieren wie in Definition 8.3.\n\nDefinition 8.3 (Korrelationskoeffizient r) Der Korrelationskoeffizient \\(r\\) (nach Pearson) ist definiert als das mittlere Produkt der z-Wert-Paare, s. Gleichung 8.4, vgl. Cohen et al. (2003). Er ist ein Maß des linearen Zusammenhangs zweier metrischer Variablen. Der Wertebereich ist \\([-1;1]\\), wobei 0 keinen Zusammenhang anzeigt und \\(|r|=1\\) perfekten Zusammenhang. \\(\\square\\)\n\n\\[r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i} \\tag{8.4}\\]\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur für metrische Variablen definiert ist.\n\n\n\n\n\n\nHinweis\n\n\n\nAus dem Korrelationskoeffizienten können Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert (Betrag) des Korrelationskoeffizienten gibt die Stärke des linearen Zusammenhangs an. Je näher der Wert bei 1 liegt, desto stärker ist der (lineare) Zusammenhang.\n\n\n\n\\(r = 0\\): kein linearer Zusammenhang\n\n\\(r = 1\\): perfekter linearer Zusammenhang\\(\\square\\)\n\n\n\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt Abbildung 8.7.\n\n\n\n\n\nAbbildung 8.7: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0\n\n\nDie untere Zeile von Abbildung 8.7 zeigt Beispiele für nicht-lineare Zusammenhänge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammhang besteht.\n\nÜbungsaufgabe 8.1 (Korrelationsspiel) Spielen Sie das Korrelationsspiel3: Sie Sehen ein Streudiagramm und müssen den richtigen Korrelationskoeffizienten eingeben.\\(\\square\\)\n\n\nÜbungsaufgabe 8.2 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist4 findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr Gefühl für die Stärke des Korrelationskoeffizienten zu entwickeln.\\(\\square\\)\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhängt? Schauen wir nach! Die Funktion correlation() (aus dem Paket easystats) erledigt das Rechnen für uns, s. Tabelle 8.3.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  |&gt;  # aus `easystats`\n  summary()\n\n\n\n\nTabelle 8.3: Korrelation berechnen mittels der Funktion correlation aus easystats\n\n\n\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\n\n\n\n\n\nSie können auch auf die letzte Zeile, also dem Befehl summary() verzichten. Dann ist die Ausgabe ausführlicher.\n\n8.4.3 Korrelation ≠ Kausation\nEine Studie fand eine starke Korrelation, zwischen der (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. Abbildung 8.8.\n\n\n\n\n\nAbbildung 8.8: Schoki futtern macht schlau?\n\n\nKorrelation (bzw. Zusammenhang) ist ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.5 (Scheinkorrelation: Störche und Babies) Eine Urban Myth besagt: Die Anzahl der Störche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis (vgl. Matthews, 2000).\nEine mögliche Erklärung für dieses (nur scheinbare) Paradoxon ist, dass die “Naturbelassenheit” des Landkreises die gemeinsame Ursache für Störche ist (Störche lieben Natur) und für Babies ist (die Gegebenheiten bei hoher Naturbelassenheit eine höhere Zahl von Kindern pro Frau begünstigt). Wir müssen die Erklärung keinesfalls glauben; sie soll das Beispiel nur konkreter machen. Uns geht es hier nur um die Erkennung von Scheinkorrelation.\n\n\nBeispiel 8.6 (Glatze macht Corona?) Kahle Männer aufgepasst! Macht eine Glatze krank? Männer mit Glatze bekommen häufiger Corona (Goren et al., 2020).\n\nBald men at higher risk of severe case of Covid-19, research finds5\n\nEine alternative Erklärung lautet, dass Alter einen Effekt hat auf Glatze (je älter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatz hat) und auf die Schwere des Corona-Verlaufs (ältere Menschen haben deutlich schwerere Corona-Verläufe). \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "title": "8  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lügt",
    "text": "8.5 Wie man mit Statistik lügt\n\n8.5.1 Range-Restriktion\nDurch (nicht-randomisierte) Einschränkung (Restriktion) des Ranges einer (oder beider) Variablen sinkt die Stärke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003) und Abbildung 8.9.\nErstellen wir uns dazu zwei Datensätze mit je zwei Variablen, \\(X\\) und \\(Y\\) und mit Umfang \\(n=100\\). Einer der beiden Datensätze sei mit Einschränkung des Ranges und einer ohne ohne. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in Listing 8.1. Man kann sich mit dem Befehl rnorm(n, m, sd) \\(n\\) normalverteilte Variablen mit Mittelwert \\(m\\) und Streuung \\(sd\\) von R erzeugen lassen. Wir schränken dann den Range von \\(X\\) ein auf, sagen wir, den Bereich von \\([-0.5, .5]\\) (Datensatz d_filtered), s. Listing 8.1.\n\n\nListing 8.1\n\n\nset.seed(42)\nn &lt;- 1e2\nd &lt;-\n  tibble(x = rnorm(n = n, mean = 0, sd = 1),\n         e = rnorm(n = n, mean = 0, sd = .5),\n         y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-\nd |&gt; filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne Einschränkung des Range: Starke Korrelation\n\n\n\n\n\n\n\n\n\n(b) Mit Einschränkung des Range: Schwächere Korrelation\n\n\n\n\n\n\nAbbildung 8.9: Schränkt man den Range einer (oder beider) Variablen ein, so sinkt die Stärke der Korrelation\n\n\n\nÜbungsaufgabe 8.3 (Berechnen Sie die Korrelation) Glauben Sie nicht, prüfen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhängen.\nFalls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, können Sie die Daten so (in mittlerweile gewohnter Manier) importieren, s. Listing 8.2.\n\n\n\nListing 8.2: Mariokart importieren, wenn die CSV-Datei im aktuellen Projektordner liegt.\n\nmariokart &lt;- read.csv(\"mariokart.csv\")\n\n\n\n\nFalls der Datensatz im Unterordner mit Namen “Mein_Unterordner” liegt, so würden Sie folgenden Pfad eingeben, s. Listing 8.3.\n\n\n\nListing 8.3: Den Datensatz Mariokart importieren, wenn die CSV-Datei im Unterordner Mein_Unterordner liegt.\n\nmariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\")\n\n\n\n\nMan beachte, dass solche sog. relativen Pfade, wie Mein_Unterordner/, die relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio, liegen, nicht mit einem Schrägstrich (Slash) beginnen.\nFalls Sie die Daten nicht auf Ihrem Computer haben, können Sie sie komfortable von z.B. der Webseite von Vincent Arel-Bundock herunterladen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wählen die Variablen von mariokart, die Sie in diesem Fall interessieren – natürlich nur die metrischen – und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\n\n\n\n\n\n\nNamensverwechslung (name clash)\n\n\n\nEs kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein, wie es mir oben in der Syntax passiert ist. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemäß sagt: “Hey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.” Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: “Hey R, nimm gefälligst select aus dem Paket dplyr, dort”wohnt” nämlich select. Auf Errisch spricht sich das so: dplyr::select(...).\\(\\square\\)\n\n\nEtwas schöner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. Tabelle 8.4.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nTabelle 8.4: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nwheels\nseller_rate\ntotal_pr\nship_pr\nstart_pr\nn_bids\n\n\n\nduration\n-0.30**\n-0.15\n-0.04\n0.27*\n0.13\n-0.12\n\n\nn_bids\n-0.08\n-0.11\n0.13\n0.03\n-0.63***\n\n\n\nstart_pr\n0.16\n0.28*\n0.07\n0.03\n\n\n\n\nship_pr\n0.05\n-0.02\n0.54***\n\n\n\n\n\ntotal_pr\n0.33**\n9.43e-03\n\n\n\n\n\n\nseller_rate\n-0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeben einigen Statistiken, die wir einfach geflissentlich ausblenden (t und p) beinhaltet die Tabelle eine interessante Information: den Schätzbereich für die Korrelation, gekennzeichnet als 95% CI. Grob gesagt können wir diese Information so interpretieren: “Mit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich.” (Das ist die sog. bayesianische Interpretation.)\nMöchte man nur einzelne Korrelationskoeffizienten ausrechnen, können wir die Idee des Zusammenfassens, s. Gleichung 8.1, nutzen:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels))\n\n\n  \n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nIm Falle von fehlenden Werte müssen Sie den Befehl cor() aus seiner schüchternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor.\n\n\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n  \n\n\n\n\n🧑‍🎓 Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket dataExplorer bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. Abbildung 8.10.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildung 8.10: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8  Punktmodelle 2",
    "section": "\n8.7 Aufgaben",
    "text": "8.7 Aufgaben\nSchauen Sie sich auch mal auf der Webseite Datenwerk6 die Aufgaben zu dem Tag association an.\n\nnasa02\nmariokart-korr1\nmariokart-korr2\nmariokart-korr3\nmariokart-korr4\nkorr01\nkorr02",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#halbzeitquiz",
    "href": "070-zusammenhaenge.html#halbzeitquiz",
    "title": "8  Punktmodelle 2",
    "section": "\n8.8 Halbzeitquiz",
    "text": "8.8 Halbzeitquiz\n\n\n\n\n\n\nTesten Sie Ihr Wissen mit diesem Quiz zur deskriptiven Statistik (Maße der zentralen Tendenz, Variabilität, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8  Punktmodelle 2",
    "section": "\n8.9 Fallstudien",
    "text": "8.9 Fallstudien\n\n\nYACSDA: EDA zu Flugverspätungen7 im Datenwerk unter dem Tag flights-yacsda-eda zu finden.\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Übungsaufgaben können theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer Lösung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.\\(\\square\\)\n\n\n\n\nYACSDA: Topgear8\n\n\nDatensatz flights: Finde den Tag mit den meisten Abflügen9\n\n\nTidyverse Case Study: Exploring the Billboard Charts10\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl. Es ist nicht nötig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Übung, dort, wo Sie es nötig haben.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8  Punktmodelle 2",
    "section": "\n8.10 Literaturhinweise",
    "text": "8.10 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erläutern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schönes, modernes Statistikbuch bietet der Psychologie-Prof Russel Poldrack von der Princeton University (2023); auch dieses Buch ist frei online verfügbar. Tipp: Nutzen Sie die Übersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas höheren Anspruchs. Was ist Scheinkorrelation und was ist “echte” Korrelation? Dieser Unterschied – der für die Wissenschaft zentral ist – wird von Pearl & Mackenzie (2018) auf entspannte Art erläutert; nebenbei lernt man einiges zur Geschichte der Wissenshaft. Hier finden Sie weitere Beispiele für Scheinkorrelationen.\nDieser TED-Vortrag informiert zum Thema Scheinkorrelation.\n\n\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGoren, A., Vaño-Galván, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain – A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545–1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPearl, J., & Mackenzie, D. (2018). The Book of Why: The New Science of Cause and Effect (First edition). Basic Books.\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "🧑‍🎓 Typisches Lehrerbeispiel!!↩︎\nhttps://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv↩︎\nhttps://gallery.shinyapps.io/correlation_game/↩︎\nhttps://rpsychologist.com/correlation/↩︎\nhttps://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/, Abruf 2023-03-24↩︎\nhttps://sebastiansauer.github.io/Datenwerk/↩︎\nhttps://sebastiansauer.github.io/Datenwerk/posts/flights-yacsda-eda↩︎\nhttps://data-se.netlify.app/2021/02/11/yacda-topgear/↩︎\nhttps://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/↩︎\nhttps://www.njtierney.com/post/2017/11/07/tidyverse-billboard/↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Lernsteuerung\nAbb. Abbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#lernsteuerung",
    "href": "080-regression1.html#lernsteuerung",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Lernziele\n\nSie können ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie können die Bestandteile eines Geradenmodells aufzählen und erläutern.\nSie können die Güte eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie können Geradenmodelle sowie ihre Modellgüte in R berechnen.\n\n9.1.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n9.1.3 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nützliche Sache, unter (mindestens) folgenden Voraussetzungen:\n\nSie sind präzise\nWir kennen die Präzision\nJemand interessiert sich für die Vorhersage\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne Prädiktor\n\nBeispiel 9.1 Nach intensiver Beschäftigung mit Statistik sind Sie allgemein als Checker bekannt. Viele jüngere Studis fragen Sie um Rat. eines Tages kommt eine Studentin, Toni, und fragt: “Welche Statistiknote kann ich in der Klausur erwarten?” Sie entgegnen: “Wie viel hast du denn gelernt?”. Die Antwort: “Sag ich nicht.”\nNach kurzem Überlegen geben sie den Notenschnitt der letzten Klausur als Prognose für diese Person. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in Listing 9.1 wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls müssen Sie die Daten erst herunterladen1:\n\n\n\nListing 9.1: Der Datensatz ‘noten2’ liegt im Unterordner ‘Noten.’\n\nnoten2 &lt;- read.csv(\"daten/noten2.csv\")\n\n\n\n\n Download \nDann rechnen Sie den Mittelwert aus:\n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n  \n\n\n\nIhre Antwort lautet also: “Im Schnitt haben die Studis bei der letzten Klausur gut 70% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!”\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Kenntnis eines Prädiktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert für jede Beobachtung, s. Abbildung 9.1. Wir nutzen den Mittelwert als Punktmodell für den Klausurerfolg.\\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\n9.2.2 Nullmodell (Punktmodell)\nModelle ohne Prädiktor, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null Prädiktoren hat, nennt man es auch manchmal “Nullmodell”.\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        71.1\n\nlm steht für “lineares Modell”, die 1 sagt, dass es keine Prädiktoren gibt. In dem Fall wird der Mittelwert als Gerade verwendet. Der zurückgemeldete Koeffizient (Intercept) ist hier der Modell des Punktmodells. Da es ein Punktmodell ist, sagt es für alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nDie Regressionsgleichung lautet demnach: y_pred = 71.08. In Worten: “Wir sagen für jede Beobachtung einen Wert von ca. 71 vorher”.\n\n9.2.3 Vorhersagen mit Prädiktor\n\nBeispiel 9.2 (Toni verrät die Lernzeit) Toni entschließt sich dann doch noch, die Lernzeit zu verraten: “Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.” Jetzt müssen Sie erstmal nachdenken: “Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?”\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. Abbildung 9.2, a).2\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: “Bei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. Könnte mit dem Bestehen eng werden.” Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.\\(\\square\\)\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen. Mit einem Lineal könnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. Abbildung 9.2, b).\n\n\n\n\n\n\n\n\n\n(a) Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)\n\n\n\n\n\n\n\n\n\n(b) Eine ‘Trendgerade’ (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt gekennzeichnet.\n\n\n\n\n\n\nAbbildung 9.2: Noten und Lernzeit: Rohdaten und Modell\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell für die Daten, s. Abbildung 9.2, b. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt für alle Beobachtungen den gleichen Wert vorher. Abbildung 9.1 und Abbildung 9.2 stellen ein Punktmodell einem Geradenmodell gegenüber.\nIn einem Geradenmodell wird nicht mehr (notwendig) für jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.1 (Gerade) Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). Häufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet:\n\n\\(f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + {\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + {b_1} \\color{xcol}{x}\\) .\nDie Nomenklatur mit \\(b_0, b_1\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, ...\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage über eine Population, nicht nur über eine Stichprobe, machen möchte.\nDas “Dach” über y, \\(\\color{modelcol}{\\hat{y}}\\), drückt aus, dass es sich den den geschätzten, bzw. vom Modell vorhergesagten (“modellierten”) Wert für \\(\\color{ycol}{y}\\) handelt, nicht das tatsächliche (empirische, beobachtete) \\(\\color{ycol}{y}\\). \\(\\square\\)\n\nAbbildung 9.3 skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n\n\n\n\n\nAbbildung 9.3: Achsenabschnitt und Steigung einer Regressionsgeraden (Menk, 2014)\n\n\n\n\n\n\n\n\n\nDas einfache lineare Modell\n\n\n\nDas einfache lineare Modell nimmt den Wert einer abhängigen metrischen Variablen, y als lineare Funktion von unabhängigen Variablen, x an, plus einem Fehlerterm, e. \\(\\square\\)\n\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}\\]\nMit:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschätzter y-Achsenabschnitt laut Modell\n\n\\(\\color{beta1col}{\\beta_1}\\): geschätzte Steigung laut Modell\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nJe nach Datenlage können sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. Abbildung 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildung 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher Modellgüte\n\n\nAbbildung 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie können Punkte per Klick/Touch hinzufügen.\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\nAbbildung 9.5: Interaktives Beispiel für eines lineares Modell. Fügen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, w erden Sie wieder konsultiert. “Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurück!”\nDas sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{X}=0\\) gibt der Achsenabschnitt zurück.\nSchnell skizzieren Sie dazu ein Diagramm, s. Abbildung 9.6. Puh, die Antwort wird Toni nicht gefallen …\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 9.6: Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf Abbildung 9.6 zu schauen, können Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n🧑‍🏫 Hey R, predicte mir mal auf Basis vom Modell “lm1” den Lernerfolg für Toni, wenn der x=0 Stunden lernt.\n\n\n🤖 Okay, ich predicte mit Modell “lm1” und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)  # `tibble` erstellt eine Tabelle\n\n\npredict(lm1, newdata = tonis_lernzeit)\n##   1 \n## 8.6\n\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. Gleichung 9.2 :\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.1}\\]\nLies: “Laut meinem Modell ist mein (geschätztes) \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)”.\nWir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist:\n\\[\\color{ycol}{AV} \\sim \\color{xcol}{UV} \\tag{9.2}\\]\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\nGleichung 9.2 können Sie so ins Errische übersetzen:\n\nlm(y ~ x, data = meine_daten)\n\nlm steht für “lineares Modell”, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade (an anderer Stelle in diesem Buch unscharf als “Trendgerade” bezeichnet).\n\nBeispiel 9.4 (Zahlen für Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: “Jetzt hör mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir präzise Zahlen!”.\n\n\nlm1 &lt;- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##       8.603        0.879\n\nR gibt Ihnen die beiden Koeffizienten für die Gerade aus. Den Namen des Objekts können Sie frei aussuchen, z.B. mein_erstes_lm.\nDie Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x\n8.6 ist der Achsenabschnitt, d.h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: Für jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 10 Stunden gelernt, würden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 10\ny_pred &lt;- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17\n\n\nBeispiel 9.5 (Vorhersage für Klausurerfolg, nächster Versuch) Sie versuchen, noch etwas Gutes für Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dürfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit2)\n##  1 \n## 73\n\nDie Syntax von predict lautet:\npredict(name_des_objekts, newdata = tabelle_mit_prädiktorwerten)\n\n\n\n\n\n\nHinweis\n\n\n\nMit predict bekommt man eine Vorhersage; im Standard eine “Punkt-Vorhersage”, eine einzelne Zahl.\\(\\square\\)\n\n\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagten Wert für eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, \\(e_i\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Residuen beim Geradenmodell (lm1)\n\n\n\n\n\n\n\n\n\n(b) Residuen beim Punktmodell (lm0)\n\n\n\n\n\n\nAbbildung 9.7: Vorhersagefehler als Abweichungsbalken\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket easystats):\n\nmae(lm0)\n## [1] 11\nmae(lm1)\n## [1] 8\n\nVergleichen wir MAE im Nullmodell mit MAE in lm1:\n\nverhaeltnis_fehler_mae &lt;- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm1 haben die mittlere (Absolut-)Länge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.2 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)).\\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngrößen wie MAE oder MSE.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist.\\(\\square\\)\n\n\nNatürlich können wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen. Wer mag, kann den MSE auch von Hand berechnen: mean((noten2$y-mean(noten2$y))^2).\n\nmse(lm0)\n## [1] 193\nmse(lm1)\n## [1] 106\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\nDie Regressionskoeffizienten (hier synonym: Modellparameter) b0 und b1 wählt man so, dass die Residuen minimal sind,\nAbbildung 9.8 veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildung 9.8: Bildquelle: Karsten Lübke, FOM Hochschule\n\n\nGenauer gesagt wird die Summe der quadrierten Residuen minimiert, s. Gleichung 9.3.\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene Möglichkeiten, um die Koeffizienten zu berechnen (die sind aber nicht in diesem Buch zu finden). Eine schöne Darstellung dazu findet sich bei Kaplan (2009).\n“Von Hand” können Sie die Optimierung von b0 und b1 in dieser App der FOM-Hochschule3 ausprobieren.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r-quadrat-als-maß-der-modellgüte",
    "href": "080-regression1.html#r-quadrat-als-maß-der-modellgüte",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.4 R-Quadrat als Maß der Modellgüte",
    "text": "9.4 R-Quadrat als Maß der Modellgüte\nAnders gesagt, wir haben uns um \\(1 - 0.55\\) verbessert:\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n\n\nDefinition 9.3 (R-Quadrat) Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen von lm0 zum gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). R-Quadrat (\\(R^2\\)) e ines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein Maß der Modellgüte: Je größer \\(R^2\\), desto besser die Vorhersage. Da es ein Anteilsmaß ist, liegt der Wertebereich zwischen 0 uns 1. Im Nullmodell liegt R-Quadrat per Definition bei 0. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable erklärt.\nWir können R-Quadrat (\\(R^2\\)) uns von R z.B. so ausgeben lassen:\n\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\). Das gilt bei Modellen mit einem Prädiktor; gibt es mehrere Prädiktoren gilt die Beziehung nur, wenn die Prädiktoren alle paarweise unabhängig sind, vgl. Abbildung 9.9.\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation, r ≅ 0 und R2 ≅ 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefähr) parallel zur X-Achse\n\n\n\n\n\n\n\n\n\n(b) Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert\n\n\n\n\n\n\nAbbildung 9.9: Extremfälle von R-Quadrat: 0 und 1\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man für jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\) , vorhersagen würde.\n\n\n\n\n\n\nHinweis\n\n\n\nJe größer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser “erklärt” das Modell die Daten (desto besser der “Fit”, sagt man).\n\n\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der Größe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 Modellgüte\nDie Residuen (Vorhersagefehler) bestimmen die Modellgüte: Sind die Residuen im Schnitt groß, so ist die Modellgüte gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur Verfügung: R-Quadrat, r (als Korrelation von tatsächlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)), MSE, RMSE, MAE, …\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\);lies: “beta Null”) und Steigung (\\(\\beta_1\\)) sind nur eingeschränkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abhängigkeiten nicht kennt. Nur aufgrund eines statistischen Zusammenhangs darf man keine kausalen Abhängigkeiten annehmen. Ohne eine guten Grund für eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der Modellgüte und den Vorhersagen begnügen. Was auch was wert ist.\n\n9.5.2.1 Achsenabschnitt (b0)\nIm Modell lm1 liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=8.6\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) können also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten.\n Leider ist es häufig so, dass Prädiktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nützt.\n\nBeispiel 9.6 (Regression Größe und Gewicht) Nutzt man Körpergröße und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von Körpergröße wenig nützlich, da es keine Menschen gibt der Größe 0.\\(\\square\\)\n\n\n9.5.2.2 Geradensteigung (b1)\n“Im Modell lm1 beträgt der Regressionskoeffizient b1 \\(0.88\\). Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von b1.”\n\n\n\n\n\n\nVorsicht\n\n\n\nHäufig liest man, der “Effekt des Prädiktors” auf die AV betrage z.B. \\(0.88\\). “Effekt” ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort “Effekt” mit Vorsicht genießen. Manche sprechen daher auch von einem “statistischen Effekt”.\\(\\square\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lügt",
    "href": "080-regression1.html#wie-man-mit-statistik-lügt",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lügt",
    "text": "9.6 Wie man mit Statistik lügt\nDer Unterschied in Modellgüte zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) Maß der Modellgüte und da \\(r = \\sqrt{R^2}\\), darf \\(r\\) nicht wie \\(R^2\\) als Maß der Modellgüte interpretiert werden. Abbildung 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildung 9.10: Der Zusammenhang von r und R-Quadrat ist nicht linear.\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dürfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie möchten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin. Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz. Auf geht’s!\nDaten laden (und die üblichen Pakete starten, nicht vergessen):\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloßem Rumprobieren überlegen Sie und schauen dann in Abbildung 8.10 nach, welche Variable am stärksten korreliert mit total_pr; es resultiert lm3:\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n\n\n\n\nTabelle 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in Tabelle 9.1 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut lm3 etwa 36 Euro finaler Verkaufspreis erwarten. Pro Euro an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro. (Die Spalte 95 CI gibt einen Schätzbereich für den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um Schätzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schließlich nur eine Stichprobe der Größe \\(n=143\\).)\nDie Regressionsgleichung von lm3 lautet demnach:\ntotal_pr_pred = 36.25 + 4.34*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36.25€ “Sockelbetrag” plus 4.34 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (“expectations”) des Verkaufspreises in Abhängigkeit vom Wert der UV (ship_pr) auch schätzen (“to estimate”) lassen, und zwar so:\n\nestimate_expectation(lm3) %&gt;%  # aus dem Paket 'easystats'\n  head()  # nur die ersten paar vorhergesagten Werte\n\n\n\n\nModel-based Expectation\n\nship_pr\nPredicted\nSE\n95% CI\nResiduals\n\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-2.04\n\n\n3.99\n53.55\n1.87\n(49.85, 57.25)\n-16.51\n\n\n3.50\n51.43\n1.82\n(47.82, 55.03)\n-5.93\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n7.75\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n34.75\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-8.59\n\n\n\nVariable predicted: total_pr\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\n🤖 Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert für total_pr für einen bestimmten Wert von ship_pr.\n\n\n🧑‍🎓 Kann ich auch predict benutzen? Ich würde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n\n🤖 Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n\n\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n\nAber nützlich wäre noch, das Modell (bzw. die Schätzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.B. so, s. Abbildung 10.10.\n\nestimate_expectation(lm3) %&gt;% plot()\n\n\n\n\n\n\nAbbildung 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heißt sinngemäß “schätze den zu erwartenden Wert”. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie “gut” das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13\n\nDas Modell erklärt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n\n\nmae(lm3)\n## [1] 13\n\nIm nächsten Meeting erzählen Sie Ihrem Chef “Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!”. Hört sich gut an. Allerdings hätte ihr Chef es gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie stellt die Prüfungsleistung “Prognosewettbewerb” einführend dar. Es empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten.\\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei Kaggle ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet.\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition Ames House Prices.4\n\n\nBeschreibung5\n\n\nZiel/Aufgabe6\n\n\nSpielregeln7\n\n\n9.8.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.8.3 Daten\nWenn Sie sich nicht bei Kaggle einloggen möchten, können Sie die Daten von Kaggle herunterladen und zwar hier.\nIm Einzelnen müssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Code book, d.h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\nSie können auch so auf die Daten zugreifen:\n\nd_train_path_online &lt;- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/\",\n    \"Lehre/main/data/ames-kaggle/train.csv\")\n\nd_test_path_online &lt;- paste0(\n  \"https://raw.githubusercontent.com/sebastiansauer/\",\n  \"Lehre/main/data/ames-kaggle/test.csv\")\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\nDas Code Book können Sie hier einsehen und herunterladen.8\n\n9.8.4 Prognosedatei\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthält. Sie soll prinzipiell so aussehen wie in Tabelle 9.2 dargestellt.\n\n\n\nTabelle 9.2: Beispiel den Aufbau der Prognose-Datei\n\n\n\n\n\n\nid\nSalePrice\n\n\n\n1461\n169277\n\n\n1462\n187758\n\n\n1463\n183584\n\n\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - für welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice ist Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar?\nLos geht’s!\n\n9.8.5 Daten importieren von der Festplatte\nWir können die Daten auch von der Festplatte importieren; oft müssen wir das auch - wenn die Daten nämlich nicht öffentlich zugreifbar auf einem Server liegen.\n\nd_train_path &lt;- \"daten/ames-kaggle/train.csv\"\nd_test_path &lt;- \"daten/ames-kaggle/test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\nIn diesem Beispiel gehen wir davon aus, dass die Dateien train.csv und test.csv in einem Unterordner namens daten/ames-kaggle liegen. Sie müssen sie dort abspeichern. Dieser Ordner muss ein Unterordner Ihres aktuellen R-Projekts sein.\\(\\square\\)\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn das Importieren von der Festplatte nicht klappt … Es ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.\\(\\square\\)\n\n\n\n9.8.6 Ein erster Blick in die Daten\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, Tabelle 9.3.\n\ndescribe_distribution(d_train)\n\n\n\n\nTabelle 9.3: Verteilung der metrischen Variablen im ames-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nId\n730.50\n421.61\n730.50\n(1.00, 1460.00)\n0.00\n-1.20\n1460\n0\n\n\nMSSubClass\n56.90\n42.30\n50.00\n(20.00, 190.00)\n1.41\n1.58\n1460\n0\n\n\nLotFrontage\n70.05\n24.28\n21.00\n(21.00, 313.00)\n2.16\n17.45\n1201\n259\n\n\nLotArea\n10516.83\n9981.26\n4060.00\n(1300.00, 2.15e+05)\n12.21\n203.24\n1460\n0\n\n\nOverallQual\n6.10\n1.38\n2.00\n(1.00, 10.00)\n0.22\n0.10\n1460\n0\n\n\nOverallCond\n5.58\n1.11\n1.00\n(1.00, 9.00)\n0.69\n1.11\n1460\n0\n\n\nYearBuilt\n1971.27\n30.20\n46.00\n(1872.00, 2010.00)\n-0.61\n-0.44\n1460\n0\n\n\nYearRemodAdd\n1984.87\n20.65\n37.00\n(1950.00, 2010.00)\n-0.50\n-1.27\n1460\n0\n\n\nMasVnrArea\n103.69\n181.07\n166.00\n(0.00, 1600.00)\n2.67\n10.08\n1452\n8\n\n\nBsmtFinSF1\n443.64\n456.10\n712.75\n(0.00, 5644.00)\n1.69\n11.12\n1460\n0\n\n\nBsmtFinSF2\n46.55\n161.32\n0.00\n(0.00, 1474.00)\n4.26\n20.11\n1460\n0\n\n\nBsmtUnfSF\n567.24\n441.87\n585.00\n(0.00, 2336.00)\n0.92\n0.47\n1460\n0\n\n\nTotalBsmtSF\n1057.43\n438.71\n503.50\n(0.00, 6110.00)\n1.52\n13.25\n1460\n0\n\n\nX1stFlrSF\n1162.63\n386.59\n509.75\n(334.00, 4692.00)\n1.38\n5.75\n1460\n0\n\n\nX2ndFlrSF\n346.99\n436.53\n728.00\n(0.00, 2065.00)\n0.81\n-0.55\n1460\n0\n\n\nLowQualFinSF\n5.84\n48.62\n0.00\n(0.00, 572.00)\n9.01\n83.23\n1460\n0\n\n\nGrLivArea\n1515.46\n525.48\n649.75\n(334.00, 5642.00)\n1.37\n4.90\n1460\n0\n\n\nBsmtFullBath\n0.43\n0.52\n1.00\n(0.00, 3.00)\n0.60\n-0.84\n1460\n0\n\n\nBsmtHalfBath\n0.06\n0.24\n0.00\n(0.00, 2.00)\n4.10\n16.40\n1460\n0\n\n\nFullBath\n1.57\n0.55\n1.00\n(0.00, 3.00)\n0.04\n-0.86\n1460\n0\n\n\nHalfBath\n0.38\n0.50\n1.00\n(0.00, 2.00)\n0.68\n-1.08\n1460\n0\n\n\nBedroomAbvGr\n2.87\n0.82\n1.00\n(0.00, 8.00)\n0.21\n2.23\n1460\n0\n\n\nKitchenAbvGr\n1.05\n0.22\n0.00\n(0.00, 3.00)\n4.49\n21.53\n1460\n0\n\n\nTotRmsAbvGrd\n6.52\n1.63\n2.00\n(2.00, 14.00)\n0.68\n0.88\n1460\n0\n\n\nFireplaces\n0.61\n0.64\n1.00\n(0.00, 3.00)\n0.65\n-0.22\n1460\n0\n\n\nGarageYrBlt\n1978.51\n24.69\n41.00\n(1900.00, 2010.00)\n-0.65\n-0.42\n1379\n81\n\n\nGarageCars\n1.77\n0.75\n1.00\n(0.00, 4.00)\n-0.34\n0.22\n1460\n0\n\n\nGarageArea\n472.98\n213.80\n244.50\n(0.00, 1418.00)\n0.18\n0.92\n1460\n0\n\n\nWoodDeckSF\n94.24\n125.34\n168.00\n(0.00, 857.00)\n1.54\n2.99\n1460\n0\n\n\nOpenPorchSF\n46.66\n66.26\n68.00\n(0.00, 547.00)\n2.36\n8.49\n1460\n0\n\n\nEnclosedPorch\n21.95\n61.12\n0.00\n(0.00, 552.00)\n3.09\n10.43\n1460\n0\n\n\nX3SsnPorch\n3.41\n29.32\n0.00\n(0.00, 508.00)\n10.30\n123.66\n1460\n0\n\n\nScreenPorch\n15.06\n55.76\n0.00\n(0.00, 480.00)\n4.12\n18.44\n1460\n0\n\n\nPoolArea\n2.76\n40.18\n0.00\n(0.00, 738.00)\n14.83\n223.27\n1460\n0\n\n\nMiscVal\n43.49\n496.12\n0.00\n(0.00, 15500.00)\n24.48\n701.00\n1460\n0\n\n\nMoSold\n6.32\n2.70\n3.00\n(1.00, 12.00)\n0.21\n-0.40\n1460\n0\n\n\nYrSold\n2007.82\n1.33\n2.00\n(2006.00, 2010.00)\n0.10\n-1.19\n1460\n0\n\n\nSalePrice\n1.81e+05\n79442.50\n84075.00\n(34900.00, 7.55e+05)\n1.88\n6.54\n1460\n0\n\n\n\n\n\n\n\n\n\n9.8.7 Ein erstes Vorhersagemodell\n\n9.8.7.1 Welche Variablen eignen sich zur Vorhersage?\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller Prädiktoren mit der abhängigen Variablen9 zu berechnen, s.  Listing 9.2.\n\n\n\nListing 9.2: Welche Variablen korrelieren stärker als .3?\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\n\n\nTabelle 9.4: Korrelation der Prädiktoren (UV) mit der AV\n\n\n\n\n\n\n\nAha! Ein Menge Information.10\nDiese Variablen sind einigermaßen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n9.8.7.2 Modell 1\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im Großen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stärksten mit der Zielvariable korreliert und ist daher ein guter Kandidat für die Vorhersage.\n\nm1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1458)\np\n\n\n\n(Intercept)\n-96206.08\n5756.41\n(-1.07e+05, -84914.35)\n-16.71\n&lt; .001\n\n\nOverallQual\n45435.80\n920.43\n(43630.29, 47241.31)\n49.36\n&lt; .001\n\n\n\n\n\nWie gut ist das Modell?\n\nrmse(m1)  # aus easystats\n## [1] 48589\n\nIm Schnitt liegen wir 4.54^{4} Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die Modellgüte:\n\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\n\n9.8.7.3 Model 2\nBerechnen wir als nächstes ein Modell mit mehreren UV, m2.\n\n\n\n\n\n\nHinweis\n\n\n\nMann kann mehrere UV (Prädiktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur “als UV nimm UV1 und UV2 und …”. \\(\\square\\)\n\n\n\nm2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n\nTabelle 9.5 zeigt die Koeffizienten von m2.\n\n\n\nTabelle 9.5: Modellparameter von m1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1456)\np\n\n\n\n(Intercept)\n-98832.49\n4842.90\n(-1.08e+05, -89332.69)\n-20.41\n&lt; .001\n\n\nOverallQual\n27104.83\n1072.18\n(25001.64, 29208.01)\n25.28\n&lt; .001\n\n\nGrLivArea\n50.67\n2.55\n(45.67, 55.68)\n19.86\n&lt; .001\n\n\nGarageCars\n21298.96\n1807.06\n(17754.23, 24843.69)\n11.79\n&lt; .001\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells m2 für die Daten von d_train?\n\nrmse(m2)\n## [1] 40566\n\nIm Schnitt liegen unsere Vorhersagen 2.71^{4} Dollar daneben. Ist das gut?\nBetrachten wir noch \\(R^2\\):\n\nr2(m2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n\n\n\n\n\n\n\nHinweis\n\n\n\nOb die Modellgüte (R-Quadrat, RMSE, etc.) “gut” oder “hoch” ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen. \\(\\square\\)\n\n\n\n9.8.7.4 Nullmodell\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Prädiktoren. Man nennt es das “Nullmodell”. In diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnomdells?\n\nrmse(m0)\n## [1] 79415\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.8 Vorhersagen im Test-Datensatz mit m2\n\nWir haben jetzt unseren Champion, m2. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample präzise sein werden? Oder himmelweit daneben? Enttäusche uns nicht!\nHier sind die Vorhersagen:\n\nm2_pred &lt;- predict(m2, newdata = d_test)\nhead(m2_pred)\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n\n\n1\n\npredicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus d_test\n\n2\n\nzeige den “Kopf” der Vorhersagen (m1_pred), d.h. die ersten paar Vorhersagen\n\n\n\n\nDie Vohersagen fügen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = m2_pred)\n\n\n9.8.9 Einreichen!\n\n9.8.9.1 Wir brauchen zwei Spalten: Id und SalePrice\n\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhersagen ein.\nFür die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten id und SalePrice:\n\nm2_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\nKaggle möchte keine fehlenden Werten in den Vorhersagen, also prüfen wir das mal:\n\nm2_subm %&gt;% \n  drop_na() %&gt;%\n  nrow()\n## [1] 1458\n\n\n1\n\nLass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2\n\nzähle die Anzahl der Zeilen (die noch verbleiben)\n\n\n\n\nDie Anzahl der Zeilen, die wir hier erhalten, ist gleich zu den Anzahl der Zeilen von d_test. Es gibt also keine fehlenden Werte.\n\nnrow(d_test)\n## [1] 1459\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.8.9.2 Hochladen\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.11\n\nwrite_csv(m2_subm, \"daten/ames-kaggle/m1-subm.csv\")\n\nUnd dann laden Sie diese Datei, m1_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn.\nDas Modell erzielte einen Score von 0.55521.\n\n9.8.10 Fazit\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele Ansätze, dieses Modell zu verbessern.\nHier sind einige Fragen, die Sie sich dazu stellen können:\n\nWelche Prädiktoren sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn ein Prädiktor schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche Prädiktoren quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n…\n\nViel Spielraum für Ihre Kreativität!",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nEine Aufgabe, die eine Einführung zum Kaggle-Wettbewerb Ames House Prices bietet12, finden Sie im Datenwerk.13\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\n\nSchauen Sie sich die Aufgaben beim Datenwerk an, vor allem die Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff; vielleicht können Sie einige Aufgaben nicht lösen. Ignorieren Sie einfach diese Aufgaben.\nBeachten Sie die Hinweise zu den Aufgaben.14",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere Einführung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte Einführung in Statistik inklusive der Regressionsanalyse findet sich bei Cetinkaya-Rundel & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003)\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMenk. (2014, Juli 29). Linear Regression. https://texample.net/tikz/examples/linear-regression/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv↩︎\nDie Daten stehen hier zum Download bereit: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten2.csv↩︎\nhttps://fomshinyapps.shinyapps.io/KleinsteQuadrate/↩︎\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview↩︎\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description↩︎\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation↩︎\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules↩︎\n&lt;ttps://github.com/sebastiansauer/Lehre/blob/main/data/ames-kaggle/data_description.txt&gt;↩︎\ndie vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt↩︎\nWenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: Führen Sie die Syntax schrittweise aus. Zuerst d_train ausführen und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausführen, wieder die Ausgabe betrachten, usw.↩︎\nEs bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.↩︎\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview↩︎\nhttps://sebastiansauer.github.io/Datenwerk/posts/ames-kaggle1/ames-kaggle1.html↩︎\nhttps://sebastiansauer.github.io/Datenwerk/hinweise↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#lernsteuerung",
    "href": "090-regression2.html#lernsteuerung",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Standort im Lernpfad\nAbb. Abbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n10.1.2 Lernziele\n\nSie können Regressionsmodelle für Forschungsfragen mit binärer, nominaler und metrischer UV erläutern und in R anwenden.\nSie können Interaktionseffekte in Regressionsmodellen erläutern und in R anwenden.\nSie können den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erläutern und in R anwenden.\nSie können Modelle nutzen, um Vorhersagen anhand neuer Daten zu erstellen.\n\n10.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(yardstick)  # für Modellgüte im Test-Sample\nlibrary(easystats)\nlibrary(ggpubr)  # Daten visualisieren\nlibrary(openintro)  # dataset mariokart\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n10.1.4 Benötigte Daten\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD.1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "href": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: Gläserne Kunden",
    "text": "10.2 Forschungsbezug: Gläserne Kunden\nLineare Modelle2 sind ein altes, aber mächtiges Werkzeug. Sie gehören immernoch zum Standard-Repertoire moderner Analystis.\n\nBeispiel 10.1 (Wie gut kann man Ihre Persönlchkeit auf Basis des Facebook-Profils vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Youyou et al. (2015), wie gut Persönlichkeitszüge durch Facebook-Daten (Likes etc.) vorhergesagt werden können. Die Autoren resümieren:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten über hohe Modellgüte (\\(r\\)) zwischen den tatsächlichen persönlichen Attributen und den vorhergesagten Werten Ihres Modells, s. Abbildung 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also ähnlich zu dem in diesem Kapitel vorgestellten Methoden.\nNeben der analytischen Stärke der Regressionsanalyse zeigt das Beispiel auch, wie gläsern Konsument:innen im Internet sind.\\(\\square\\)\n\n\n\n\n\n\nAbbildung 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach ewtas Abwechslung. Viel Geld verdienen und Ruhm und Anerkennung sind ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehören, und daher den schnöden Mammon nicht so hoch schätzen sollten. Sie entschließen sich, Ihre hochgeschätzten Analyse-Skills für etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels. \\(\\square\\)\n\nBeim Deutschen Wetterdienst, DWD haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen resultiert ein schöner Datensatz, den Sie jetzt analysieren wollen (Temperatur: Grad Celcius, Niederschlag (precip) mm Niederschlag pro Quadratmeter):\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\nEin Data-Dictionary für den Datensatz können Sie hier herunterladen.3\n\n\n\n\n\n\nHinweis\n\n\n\nEin Data-Dictionary (Codebook) erklärt einen Datensatz. Oft bedeutet das, das für jede Spalte der Datentabelle erklärt wird, was die Spalte bedeutet.\\(\\square\\)\n\n\n\nAbbildung 10.2 zeigen die Wetterdaten animiert.\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celcius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlage (mm) im Verlauf der Jahre\n\n\n\n\n\nVeränderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildung 10.2: Veränderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\nHervorragend! An die Arbeit!\n\n10.3.1 metrische UV\n\n10.3.1.1 Modell Wetter1\nSie stellen sich nun folgende Forschungsfrage:\n\n🧑‍🏫 Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in Tabelle 10.1 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelle 10.1: Modellparameter von lm_wetter1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n-14.25\n1.85\n(-17.87, -10.63)\n-7.71\n&lt; .001\n\n\nyear\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nLaut Ihrem Modell wurde es pro Jahr um 0.01 Grad wärmer, pro Jahrzehnt also 0.1 und pro Jahrhundert 1 Grad.\n\n🧑‍🎓 Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\n🧑‍🏫 Mit der Ruhe, das schauen Sie sich später an.\n\n\n10.3.1.2 Punkt- vs. Bereichsschätzung\nIn tbl-lm-wetter1 finden sich zwei Arten von Information für den Wert des Achsenabschnitts (b0) und des Regressionsgewichts von year(b1):\n\nPunktschätzungen In der Spalte Coefficient sehen Sie den “Best-Guess” für den entsprechenden Koeffizienten in der Population. Das is sozusagen der Wert für den sich das Modell festlegen würde, wenn es sonst nichts sagen dürfte.\nBereichschätzungen Cleverer als Punktschätzungen sind Bereichsschätzungen (Intervallschätzungen): Hier wird ein Bereich plausibler Werte für den entsprechenden Wert angegeben. Der “Bereich plausibler Werte” wird auch als Konfidenzintervall (engl. confidence intervall, CI) bezeichnet. Entsprechend gibt CI_low die Untergrenze des Bereichs plausibler Werte und CI_high die Obergrenze aus. So können wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschätzt wird.\n\n💡 Merke: Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschätzt.\n\n10.3.1.3 Modell Wetter1a\nDas Modell lm_wetter1, bzw. die Schätzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. Abbildung 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. Abbildung 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. für Niederschlag\n\nAuf dieser Basis erstellen wir ein neues lineares Modell, s. Tabelle 10.2.\n\nlm_wetter1a &lt;- lm(temp ~ year, data = wetter_summ)\nparameters(lm_wetter1a)\n\n\n\n\nTabelle 10.2: Modellparameter von lm_wetter1a\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(140)\np\n\n\n\n(Intercept)\n-14.14\n2.70\n(-19.48, -8.79)\n-5.23\n&lt; .001\n\n\nyear\n0.01\n1.38e-03\n(8.86e-03, 0.01)\n8.38\n&lt; .001\n\n\n\n\n\n\n\n\nplot(estimate_relation(lm_wetter1)) \nplot(estimate_relation(lm_wetter1a))\n\n\n\n\n\n\n\n\n\n(a) Jeder Punkt ist ein Tag (viel Overplotting, wenig nützlich)\n\n\n\n\n\n\n\n\n\n(b) Jeder Punkt ist ein Jahr (wetter_summ)\n\n\n\n\n\n\nAbbildung 10.3: Die Veränderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD)\n\n\n\n🧑‍🎓 Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der Y-Wert an der Stelle X=0, s. Kapitel 9.5.\nIn den Wetterdaten wäre Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extraplieren, ganz ohne dass wir dafür Daten haben, s. https://xkcd.com/605/.\n\n\n\n\n\nAbbildung 10.4: Du sollst nicht ein Modell weit außerhalb seines Datenbereichs extrapolieren\n\n\nSinnvoller ist es da, z.B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezöge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn für dieses Jahr haben wir Daten.\nHat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es üblich, z.B. den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten.\nSo zentriert man eine Verteilung:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist übrigens 1951:\n\nwetter %&gt;% \n  summarise(mean(year))\n\n\n  \n\n\n\nDie Steigung (d.h. der Regressionskoeffizient für year_c) bleibt unverändert, nur der Achsenabschnitt ändert sich, s. Tabelle 10.3.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert)\n\n\n\n\nTabelle 10.3: Modellparameter von lm_wetter1_zentriert\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n8.49\n0.04\n(8.42, 8.57)\n219.43\n&lt; .001\n\n\nyear c\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celcius. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\n\n\n\n\n\n\nReferenzwert entspricht Null\n\n\n\nDer Referenzwert bzw. der Wert der Referenzgruppe entspricht dem Y-Wert bei x=0 im Regressionsmodell.\\(\\square\\)\n\n\nWie gut erklärt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklärt das Modell mit year_c aber nicht. (year und year_c sind gleich stark mit temp korreliert, daher wird sich die Modellgüte nicht unterscheiden.). Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.B. die Jahreszeit eine große Rolle für die Temperatur. Das haben wir nicht berücksichtigt.\n\n🧑‍🎓 Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##   1 \n## 9.7\n\n\n🧑‍🎓 Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5° Celcius.4\n\n\n🧑‍🏫 Wir brauchen ein besseres Modell! Zum Glück haben wir ambitionierte Nachwuchs-Wissenschaftler:innen.\n\nDie Veränderung der auf fünf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in Abbildung 10.5 dargestellt. Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)5; rechts eine feinere (Daten ab 1881)6.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020 (Earth, 2021)\n\n\n\nAbbildung 10.5: \n\n\n10.3.3 Binäre UV\n\nDefinition 10.1 (Binäre Variable) Eine binäre UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei Ausprägungen: 0 und 1.\\(\\square\\)\n\n\nBeispiel 10.3 (Binäre Variablen) Das sind zum Beispiel weiblich mit den Ausprägungen 0 (nein) und 1 (ja) oder before_1950 mit 1 für Jahre früher als 1950 und 0 ansonsten.\\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\n🧑‍🎓 Ob es in der zweiten Hälfte des 20. Jahrhunderts wohl wärmer warm, im Durchschnitt, als vorher?\\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite Hälfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Überlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.7.4) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prüfe ob as Jahr größer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht größer als 1950, das dritte schon.\nJa, so könnte das klappen! Diese Syntax übertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten für Gesamt-Deutschland\n\nScheint zu klappen!\nJetzt ein lineares Modell dazu berechnen:\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\nDie Parameter des Modells lassen darauf schließen, dass es tatsächlich wärmer war nach 1950, und zwar im Schnitt offenbar ein gutes halbes Grad, s. Abbildung 10.6.\n\n\n\n\n\n\nDer Schätzbereich für den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied\n\n\n\n\n\nWie man sieht, überlappen die Temperaturen dennoch beträchtlich; aufgrund des starken Overplotting ist dieses Diagramm alles andere als ideal\n\n\n\n\n\nAbbildung 10.6: Modell temp ~ after_1950\n\n\nLeider zeigt ein Blick zum r2, dass die Vorhersagegüte des Modells zu wünschen übrig lässt7. \\(\\square\\)\n\n\n\n\n\n\nLineare Modelle verkraften nur metrische Variablen\n\n\n\nUm die Koeffizienten eines linearen Modells auszurechnen, benötigt man eine metrische X- und eine metrische Y-Variable. Hier haben wir aber keine richtige metrische X-Variable8, sondern eine logische Variable mit den Werten TRUE und FALSE.\\(\\square\\)\n\n\nUm die X-Variable in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R für uns ohne viel Ankündigung durchführt: Umwandling in mehrere binäre Variablen.\nHat ein nominaler Prädiktor zwei Stufen, so überführt (synonym: transformiert) lm() diese Variable in eine binäre Variable. Da eine binäre Variable metrisch ist, kann die Regression in gewohnter Weise durchgeführt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binäre Variable. Man beachte, dass der ursprüngliche Datensatz nicht geändert wird, nur während der Analyse von lm wird die Umwandlung der Variable 9 durchgeführt.\n\n🤖 Eine 1 kannst du als “Ja! Richtig!” verstehen und eine0 als “Nein! Falsch!”\n\nafter_1950 wird in eine Indikatorvariable umgewandelt:\n\n\n\n\n\n\n\n\n\n\nid\nafter_1950\n\n\n\n1\nTRUE\n\n\n2\nFALSE\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\nafter_1950TRUE\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\n\nBeispiel 10.5 (Beispiel: ‘Geschlecht’ in eine binäre Variable umwandeln.) Angenommen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umwandeln. Da “Frau” alphabetisch vor “Mann” kommt, nimmt R “Frau” als erste Stufe bzw. als Referenzgruppe. “Mann” ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann).\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\nEin lineares Modell mit binärer UV ist nichts anderes die Differenz der Gruppenmittelwerte zu berechnen:\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n  \n\n\n\nDie Interpretation eines linearen Modells mit binärer UV veranschaulicht Abbildung 10.7: Der Achsenabschnitt (b0) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (Abbildung 10.7 zeigt nur die Daten für den Monat Juli im Bundesland Bayern, der Einfachheit und Übersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildung 10.7: Sinnbild zur Interpretation eines linearen Modells mit binärer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten für das Modell mit binärer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (b0)\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (b0) + Steigung der Regressionsgeraden (b1)\n\n\nFür die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\nFür die Modellwerte \\({\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\({\\hat{y}} = {\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\({\\hat{y}} = {\\beta_0} + {\\beta_1}= {17.7} + {0.6} = 18.3\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nBei nominalen (und auch bei binären) Variablen ist \\({\\beta_1}\\) ein Schalter; bei metrischen Variablen ein Dimmer.10 \\(\\square\\)\n\n\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineare Modell )für uns synonym: Regressionsmodell) mit einer mehrstufigen (nominalskalierten) UV. So ein Modell ist von den Ergebnissen her praktisch identisch zu einer einfachen Varianzanalyse.\n\nBeispiel 10.6 Ob es wohl substanzielle (wie könnte man dieses Wort eigentlich definieren) Temperaturunterschiede zwischen den Bundesländern gibt?\n\nBefragen wir dazu ein lineares Modell, s. Tabelle 10.4.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\nparameters(lm_wetter_region)\n\n\n\n\nTabelle 10.4: Modellparameter für lm_wetter_region\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27152)\np\n\n\n\n(Intercept)\n8.25\n0.16\n(7.93, 8.56)\n51.62\n&lt; .001\n\n\nregion (Bayern)\n-0.63\n0.23\n(-1.07, -0.19)\n-2.79\n0.005\n\n\nregion (Brandenburg)\n0.57\n0.23\n(0.13, 1.02)\n2.53\n0.011\n\n\nregion (Brandenburg/Berlin)\n0.58\n0.23\n(0.14, 1.03)\n2.59\n0.010\n\n\nregion (Hessen)\n0.11\n0.23\n(-0.33, 0.56)\n0.51\n0.612\n\n\nregion (Mecklenburg-Vorpommern)\n0.08\n0.23\n(-0.37, 0.52)\n0.34\n0.732\n\n\nregion (Niedersachsen)\n0.52\n0.23\n(0.07, 0.96)\n2.29\n0.022\n\n\nregion (Niedersachsen/Hamburg/Bremen)\n0.52\n0.23\n(0.08, 0.96)\n2.31\n0.021\n\n\nregion (Nordrhein-Westfalen)\n0.80\n0.23\n(0.35, 1.24)\n3.53\n&lt; .001\n\n\nregion (Rheinland-Pfalz)\n0.46\n0.23\n(0.02, 0.90)\n2.03\n0.042\n\n\nregion (Saarland)\n0.71\n0.23\n(0.27, 1.16)\n3.16\n0.002\n\n\nregion (Sachsen)\n-0.04\n0.23\n(-0.48, 0.40)\n-0.18\n0.853\n\n\nregion (Sachsen-Anhalt)\n0.55\n0.23\n(0.11, 1.00)\n2.45\n0.014\n\n\nregion (Schleswig-Holstein)\n0.17\n0.23\n(-0.27, 0.62)\n0.76\n0.446\n\n\nregion (Thueringen)\n-0.48\n0.23\n(-0.92, -0.03)\n-2.11\n0.035\n\n\nregion (Thueringen/Sachsen-Anhalt)\n0.10\n0.23\n(-0.34, 0.54)\n0.43\n0.664\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariablen um. Genauer gesagt ist es immer eine Indikatorvariablen weniger als es Stufen in der nominalskalierten Variablen gibt.\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland – aus Gründen der Einfachheit hier nur mit drei Bundesländern. Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt:\n\n\n\n\n\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWü\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\n \n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\n\nAuch im Fall mehrerer Ausprägungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binären Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 1. Regressionsgeraden (b1)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 2. Regressionsgeraden (b2)\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts ausgewählt wurde) nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.\n\n\n\n\n\n\nHinweis\n\n\n\nBei einer Variable vom Typ character wählt R den alphabetisch ersten Wert als Referenzgruppe für ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. \\(\\square\\)\n\n\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-Württemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewählt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird.\\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. Abbildung 10.8.\n\n\n\n\n\n\n\nAbbildung 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). Die Achsen wurden um 90° gedreht, damit man die Namen der Bundesländer besser lessen kann.\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht außer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechnen!\n\n🤖 Endlich geht’s weiter! Ergebnisse in Tabelle 10.5! \\(\\square\\)\n\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelle 10.5: Modellparameter für lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschied im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. Abbildung 10.9, links.11 Oh nein: R betrachtet month als numerische Variable! Aber “Monat” bzw. “Jahreszeit” sollte nominal sein.\n\n🤖 Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\n👩 Okay, R, wir müssen month in eine nominale Zahl transformieren. Wie geht das?\n\n\n🤖 Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heißt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau.\\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. Tabelle 10.6.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor)\n\n\n\n\nTabelle 10.6: Modellparameter von lm_wetter_month_factor\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27156)\np\n\n\n\n(Intercept)\n56.95\n0.64\n(55.68, 58.21)\n88.56\n&lt; .001\n\n\nmonth factor (2)\n-9.95\n0.91\n(-11.73, -8.17)\n-10.94\n&lt; .001\n\n\nmonth factor (3)\n-7.78\n0.91\n(-9.56, -6.00)\n-8.56\n&lt; .001\n\n\nmonth factor (4)\n-8.49\n0.91\n(-10.27, -6.71)\n-9.34\n&lt; .001\n\n\nmonth factor (5)\n4.74\n0.91\n(2.96, 6.53)\n5.22\n&lt; .001\n\n\nmonth factor (6)\n14.34\n0.91\n(12.56, 16.12)\n15.77\n&lt; .001\n\n\nmonth factor (7)\n24.36\n0.91\n(22.57, 26.14)\n26.74\n&lt; .001\n\n\nmonth factor (8)\n17.52\n0.91\n(15.74, 19.31)\n19.24\n&lt; .001\n\n\nmonth factor (9)\n1.93\n0.91\n(0.15, 3.72)\n2.12\n0.034\n\n\nmonth factor (10)\n2.29\n0.91\n(0.51, 4.08)\n2.52\n0.012\n\n\nmonth factor (11)\n0.89\n0.91\n(-0.89, 2.68)\n0.98\n0.327\n\n\nmonth factor (12)\n5.20\n0.91\n(3.42, 6.99)\n5.71\n&lt; .001\n\n\n\n\n\n\n\n\nSehr schön! Jetzt haben wir eine Referenzgruppe (Monat 1, d.h. Januar) und 11 Unterschiede zum Januar, s. Abbildung 10.9, rechts.\n\n\n\n\n\n\nlm_wetter_month, Monat fälschlich als metrische Variable\n\n\n\n\n\nlm_wetter_month_text, Monat korrekt als nominale Variable (aber mit viel Overplotting, das müsste man besser machen)\n\n\n\n\n\nAbbildung 10.9: Niederschlagsunterschiede pro Monat (ein Punkt ist ein Jahr); aufgrund der vielen Datenpunkte ist das Diagramm wenig übersichtlich (Overplotting).\n\n\nMöchte man die Referenzgruppe eines Faktors ändern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geänderte Reihenfolge aus:12\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 Binäre plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binären) UV plus einer metrischen UV.13\n\nBeispiel 10.12 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\n🧑‍🏫 Ich muss mal kurz auf eine Sache hinweisen…\n\n\n\n\n\n\n\nFaktorvariable\n\n\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich für nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten Ausprägungen (“Faktorstufen”) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht.\nDas kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche Ausprägungen in Ihrer Variable möglich sind.\\(\\square\\)\n\n\n\nBeispiel 10.10 (Beispiel für eine Faktorvariable)  \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\n\nBeispiel 10.11 (Filtern verändert die Faktorstufen nicht) Wenn Sie von der Faktorvariablen14 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.B. nur die ersten beiden Elemente übrig bleiben mit allein der Ausprägung \"f\", merkt sich R trotzdem, dass es zwei Faktorstufen gibt (\"f\" und \"m\").\nGenaus so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. Möchten Sie die herausgefilterten Faktorstufen “löschen”, so können Sie einfach die Faktorvariable neu berechnen (mit factor).\\(\\square\\)\n\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  # Faktor (und damit die Faktorstufen) neu berechnen:\n  mutate(month_factor = factor(month))\n\nOkay. Wie spezifiziert man jetzt das lineare Modell?\\(\\square\\)\n\nHat man mehrere (“multiple”) X-Variablen (Prädiktoren, unabhängige Variablen, X-Variablen), so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.B. temp ~ year_c + month.\n\n\n\n\n\n\nMultiple Regression\n\n\n\nEine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y ~ x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\n\nDie Veränderung der monatlichen Temperatur (10-Jahres-Mittel) ist in Abbildung 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schöner aus).\n\n\n\n\n\n\nModellgleichung\n\n\n\nDas Pluszeichen hat in der Modellgleichung15 keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur “und noch folgende UV…”.\\(\\square\\)\n\n\nDie obige Modellgleichung liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, data = wetter_month_1_7)\n\nDie Modellparameter sind in Tabelle 10.7 zu sehen.\n\n\n\nTabelle 10.7: Modellparameter von lm_year_month\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4525)\np\n\n\n\n(Intercept)\n56.94\n0.68\n(55.60, 58.27)\n83.57\n&lt; .001\n\n\nyear c\n0.03\n0.01\n(5.59e-03, 0.05)\n2.43\n0.015\n\n\nmonth factor (7)\n24.37\n0.97\n(22.48, 26.27)\n25.25\n&lt; .001\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (b0, (Intercept)): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57 mm pro Quadratmeter.\nRegressionskoeffizient für Jahr (b1, year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.02 mm an (im Referenzmonat).\nRegressionskoeffizient für Monat (b2, month [7]) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25 mm über dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7.\nIm Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0.\n\n🧑‍🎓 Puh, kompliziert!\n\n\n🧑‍🏫 Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. Beispiel 10.13.\n\n\nBeispiel 10.13 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag für Januar im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"1\"))\npredict(lm_year_month, newdata = neue_daten)\n##  1 \n## 59\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nAlle Regressionskoeffizienten beziehen sich auf den Y-Wert unter der Annahme, dass alle übrigen Prädiktoren den Wert Null (bzw. Referenzwert) aufweisen.\\(\\square\\)\n\n\nVisualisieren wir uns die geschätzten Erwartungswert pro Prädiktorwert, s. Abbildung 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildung 10.10: Temperaturverlauf über die Jahre für zwei Monate. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von (Okabe & Ito, 2023) ersetzt16. Das ist nicht unbedingt nötig, aber robuster bei Schwarz-Weiß-Druck und bei Sehschwächen, vgl. Kapitel 5.9.3.\nDie erklärte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht würden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dürfen?\nNicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. Listing 10.1.\n\n\n\nListing 10.1: Ein Interaktionsmodell spezifiziert man in dieser Art: y ~ x1 + x2 + x1:x2\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\n\n\n\nVisualisiert ist das Modell in Abbildung 10.11.\n\nplot(estimate_expectation(lm_year_month_interaktion)) +\n  scale_color_okabeito()  # schönes Farbschema\n\n\n\n\n\n\n\n\nAbbildung 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die Veränderung im Verlauf der Jahre ist unterschiedlich für die Monate (Janur vs. Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator (:) fügt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\n\n\n\n\n\nWichtig\n\n\n\nEinen Interaktionseffekt von x1 und x2 kennzeichnet man in R mit dem Doppelpunkt-Operator, x1:x2:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\n\nIn Worten:\n\ny wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.\n\nWie man in Abbildung 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel.\n\n\n\n\n\n\nHinweis\n\n\n\nSind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor.\\(\\square\\)\n\n\n\nBeispiel 10.14 (Interaktionseffekt von Niederschlag und Monat) Wie ist die Veränderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich für die Monate: Im Juli nahm der Niederschlag ab, im Januar zu.\\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von “dem” (statistischen) Effekt eines Prädiktors (afu die Y-Variable) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.B. Monat) unterscheidet der Effekt. (“Effekt” ist hier immer statistisch, nie kausal gemeint.)\nBetrachten wir die Parameterwerte des Interaktionsmodells (parameters(lm_year_month_interaktion)), s. Tabelle 10.8.\n\n\n\nTabelle 10.8: Modellparameter von lm_year_month_interaktion\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4524)\np\n\n\n\n(Intercept)\n56.91\n0.68\n(55.59, 58.24)\n84.21\n&lt; .001\n\n\nyear c\n0.13\n0.02\n(0.10, 0.16)\n7.80\n&lt; .001\n\n\nmonth factor (7)\n24.37\n0.96\n(22.50, 26.25)\n25.45\n&lt; .001\n\n\nyear c × month factor (7)\n-0.20\n0.02\n(-0.25, -0.16)\n-8.62\n&lt; .001\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die Zeile year c × month factor [7]. Sie gibt die Stärke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre ändert: Im Monat \"7\" ist der Effekt von year_c um 0.20 mm geringer: Die Regressionsgerade neigt sich mehr nach “unten” im Monat Juli, da der Koeffizient kleiner als Null ist.\nDie Regressionsgleichung lautet: precip_pred = 56.91 + 0.13*year_c + 24.37*month_factor_7 - 0.20*year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert für Y an unter der Annahme, dass alle Prädiktoren den Wert Null aufweisen. In diesem Fall gibt der Achsenabschnitt also den Niederschlag für den Janur des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in Y an, wenn der jeweilige Prädiktorwert um 1 steigt, die übrigen Prädiktoren aber den Wert 0 aufweisen.\\(\\square\\)\n\n\nDas R-Quadrat von lm_year_month_interaktion beträgt übrigens nur geringfügig mehr als im Modell ohne Interaktion:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. Abbildung 10.12. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n3D-Animation\n3D-Diagramme für Modelle mit zwei Prädiktoren\n2D-Diagramm für 3D-Modell\n\n\n\n\n\n\n\n\n(a) Animation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklärt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.12\n\n\nGrundsätzlich kann man viele Prädiktoren in ein (lineares) Modell aufnehmen. Betrachten wir z. B. folgendes lineares Modell mit zwei metrischen UV.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\nAbbildung 10.13 visualisiert das Modell lm_mario2v in einem 3D-Diagramm.\n\n\n\n\n\n\n\nAbbildung 10.13: Das Modell lm_mario2v mit 2 metrischen UV (und 1 metrische AV) als 3D-Diagramm\n\n\n\nJedes der beiden Regressionsgewichte in lm_mario_2uv entspricht der Steigung in der beiden Achsen in Abbildung 10.13, d.h. die Steigung für start_pr bzw. die Steigung für ship_pr.\n\n10.4.2 Viele UV ins Modell?\nWir könnten im Prinzip alle Variablen unserer Datentabelle als Prädiktoren in das Regressionsmodell aufnehmen. Die Frage ist nur: Macht das Sinn?\nHier sind einige Richtlinien, die helfen, welche Prädiktoren (und wie viele) man in ein Modell aufnehmen sollte (Gelman et al., 2021), s. S. 199:\n\nMan sollte alle Prädiktoren aufnehmen, von denen anzunehmen ist, dass Sie Ursachen für die Zielvariablen sind\nBei Prädiktoren mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen\nPrädiktoren mit kleinem Schätzbereich (95 CI) sollten tendenziell im Modell belassen werden, da sie die Modellgüte verbessern",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.15 (Prognose des Verkaufspreis) Ganz können Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen möglichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld.\\(\\square\\)\n\n\n10.5.1 Modell “all-in”\nUm die Güte Ihrer Vorhersagen zu prüfen, teilt Ihr Chef den Datensatz in zwei zufällige Teile.\n\n🧔‍♂️ Ich teile den Datensatz mariokart zufällig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (“trainieren”) und ihre Güte zu prüfen. Den Teil nenne ich “Trainingssample”, hört sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die Güte deiner Vorhersagen in dem verbleibenden Teil, die übrigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten auf Ihrer Festplatte liegen, z.B. im Unterordner daten, dann könne Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"daten/mariokart_train.csv\")\n\nAlternativ können Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die “All-in-Strategie”: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.979\n\nDer Punkt in total_pr ~ . heißt “alle Variablen in der Tabelle (außer total_pr)”.\n\n👴 Hey! Das ist ja fast perfekte Modellgüte!\n\n\n🦹‍♀️️ Vorsicht: Wenn ein Angebot aussieht wie “too good to be true”, dann ist es meist auch too good to be true.\n\n\n\n\n\n\n\nOverfitting\n\n\n\nDer Grund für den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. Weiß man, welcher Titel zu welcher Auktion gehört, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nützen die Titel der Auktionen im Train-Sample nichts für andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stützen. Merke: Höchst idiografische Informationen wie Namen, Titel etc. sind nicht nützlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\\(\\square\\)\n\n\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in eval(predvars, data, env): object 'V1' not found\n\nOh nein! Was ist los!? Eine Fehlermeldung!\n\n\n\n\n\n\nVorsicht\n\n\n\nNominalskalierte Prädiktorvariablen mit vielen Ausprägungen, wie title sind problematisch. Kommt eine Ausprägung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. Häufig ist es sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting führen.\\(\\square\\)\n\n\n\n10.5.2 Modell “all-in”, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. Nächster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, V1, id))\n\nWir entfernen auch die Spalte V1 und id, da sie ebenfalls keine Informationen bergen.\n\nlm_allin_no_title &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist ja durchaus ordentlich. Schauen wir uns noch den rmse (die SD der Vorhersagefehler) an17:\n\n🤖 Gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title)\n## [1] 20\n\n\n\n\n\n\n\nName Clash\n\n\n\nIm Paket yardstick gibt es eine Funktion namens rmse und im Paket performance, Teil des Meta-Pakets easystats ebenfalls. Da sind Probleme vorprogrammiert. Das ist so als würde die Lehrerin rufen: “Schorsch, komm her!”. Dabei gibt es zwei Schorsche in der Klasse: Den Müllers Schorsch und den Meiers Schorsch. Sonst kommen beide, was die Lehrerin nicht will. Die Lehrerin müsste also rufen: “Müller Schorsch, komm her!”. Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den “Nachnamen” des Befehls: paketname::funktion ist wie Müller::Schorsch. In unserem Fall also: performance::rmse Endlich weiß R wieder, was zu tun ist!\\(\\square\\)\n\n\nSie rennen zu Ihrem Chef, der jetzt die Güte Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\n👴 Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das “Test-Sample”.\n\nIhr Chef schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n  \n\n\n\n\n👴️ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nHier sind Ihre Vorhersagen18:\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title, newdata = mariokart_test)\n\nHier sind Ihre ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##  1  2  3  4  5  6 \n## 29 54 53 54 42 47\n\nDies Vorhersagen fügen wir noch der Ordnung halber in die Tabelle mit den Test-Daten:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title, newdata = mariokart_test))\n\nOkay, was ist jetzt der mittlere Vorhersagefehler?\nUm die Vorhersagegüte im Test-Sample auszurechnen19, nutzen wir die Funktionen des R-Paketes yardstick20:\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nmae\nstandard\n10\n\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrmse\nstandard\n13\n\n\n\n\nIhr mittlerer Vorhersagefehler (RMSE) liegt bei ca. 13 Euro.^[Wir haben hier yardstick::rmse geschrieben und nicht nur rmse, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens rmse gibt. Name-Clash-Alarm! R könnte daher den anderen `rmse`` meinen als Sie, was garantiert zu Verwirrung führt.21\n\n👴 Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrsq\nstandard\n0.17\n\n\n\n\n\n👴️ 17%, nicht berauschend, aber immerhin!\n\n\n\n\n\n\n\nModellgüte im Test-Sample meist geringer als im Train-Sample\n\n\n\nWie das Beispiel zeigt, ist die Modellgüte im Test-Sample (leider) oft geringer als im Train-Sample. Die Modellgüte im Train-Sample ist mitunter übermäßig optimistisch. Dieses Phänomen bezeichnet man als Overfitting.\\(\\square\\)\n\n\n\n\n\n\n\n\nTipp\n\n\n\nBevor man Vorhersagen eines Modells einreicht, bietet es sich, die Modellgüte in einem neuen Datensatz, als einem Test-Sample, zu überprüfen.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste Schätzung der Güte Ihres Modells erfahren möchten, bietet sich folgendes Vorgehen an (vgl. Abbildung 10.14):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrüfen Sie die Modellgüte im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie können sie z.B. so bewerkstelligen:\n\nlibrary(rsample)\nmariokart &lt;- read_csv(\"daten/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"daten\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split bestimmt für jede Zeile (Beobachtung) zufällig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt22; das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafür, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wäre nämlich blöd für Ihr Modell, wenn im Train-Sample z.B. nur die teuren, und im Test-Sample nur die günstigen Spiele landen würde.23 In so einem Fall würde sich Ihr Modell unnötig schwer tun.\nIm nächsten Schritt können Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsächlich aufteilen.24\n\nmariokart_train &lt;- \n  training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- \n  testing(meine_aufteilung)  # Assessment-Sample\n\nIch persönliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kürzer zu tippen und einheitlich. Sie können aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, außerdem Kürze und aussagekräftige Namen.\n\n10.6.2 Train- vs. Test-Sample\n\nDefinition 10.2 (Trainsample) Den Datensatz, für die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\nDas Train-Sample stellt die bekannten Daten dar; aus denen können wir lernen, d.h. unser Modell berechnen.\n\nDefinition 10.3 (Testsample) Den Datensatz, für den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\nDas Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiß, was der Wert der AV ist.\nDer Zusammenhang dieser verschiedenen, aber zusammengehörigen Arten von Stichproben ist in Abbildung 10.14 dargestellt.\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildung 10.14: Verschiedene Arten von zusammengehörigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden “abwanderungsgefährdet” sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (“customer churn”). Es gibt eine ganze Reihe von Untersuchungen dazu, z.B. die von Lalwani et al. (2022). Die Forschis versuchen anhand von Daten und u.a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von über 80% in Ihrem (besten) Vorhersagemodell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lügt",
    "href": "090-regression2.html#wie-man-mit-statistik-lügt",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lügt",
    "text": "10.8 Wie man mit Statistik lügt\n\n10.8.1 Pinguine drehen durch\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von Schnabellänge (bill length) und Schnabeltiefe (bill depth) interessiert, s. Abbildung 10.15.\n\n\n\n\n\nAbbildung 10.15: Schnabellänge und Schnabeltiefe\n\n\nDas Team hat in schweißtreibender eiszapfentreibender Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und überlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von Schnabellänge und Schnabeltiefe. Das könnte einen Nobelpreis wert sein. Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")  # aus `ggpubr`\n\n\n\n\n\n\n\nHier sind die statistischen Details, s. Tabelle 10.9.\n\nlm1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelle 10.9: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(340)\np\n\n\n\n(Intercept)\n20.89\n0.84\n(19.23, 22.55)\n24.75\n&lt; .001\n\n\nbill length mm\n-0.09\n0.02\n(-0.12, -0.05)\n-4.46\n&lt; .001\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf veröffentlicht eine verfeindete Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von Schnabelllänge und Schnabeltiefe.\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\", color = \"species\")\n\n\n\n\n\n\n\nOh nein! Was ist hier nur los? Daten lügen nicht, oder doch?\nHier sind die statistischen Details der zweiten Analyse, s. Tabelle 10.10. Im zweiten Modell kam species als zweiter Prädiktor neu ins Modell (zusätlzich zur Schnabellänge).\n\nlm2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelle 10.10: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(338)\np\n\n\n\n(Intercept)\n10.59\n0.68\n(9.25, 11.94)\n15.51\n&lt; .001\n\n\nbill length mm\n0.20\n0.02\n(0.17, 0.23)\n11.43\n&lt; .001\n\n\nspecies (Chinstrap)\n-1.93\n0.22\n(-2.37, -1.49)\n-8.62\n&lt; .001\n\n\nspecies (Gentoo)\n-5.11\n0.19\n(-5.48, -4.73)\n-26.67\n&lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaten alleine reichen nicht\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse – Gesamtdaten oder Subgruppen – die richtige ist. Nicht-exprimentelle Studien können zu grundverschiedenen Ergebnissen führen, je nachdem ob Prädiktoren dem Modell hinzugefügt oder weggenommen werden. \\(\\square\\)\n\n\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere nie Modellkoeffizienten kausal ohne ein Kausalmodell.\\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lässt man besser die Finger von der Interpretation der Modellkoeffizienten und begnügt sich mit der Beschreibung der Modellgüte und mit Vorhersage25. Wer das nicht glaubt, der betrachte Abbildung 10.16, links.26 Ei Forschi stellt das Modell m1: y ~ x auf und interpretiert dann b1: “Ist ja klar, X hat einen starken positiven Effekt auf Y!”.\nIn der nächsten Studie nimmt dis Forschi dann eine zweite Variable, group (z.B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. Abbildung 10.16, rechts!\nDieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt “echt”, also kausal, ist. Handelt es sich aber um “nicht echte”, also nicht-kausale Zusammenhänge, um Scheinzusammenhänge also, so können sich die Modellkoeffizienten dramatisch verändern (sogar das Vorzeichen kann wechseln27), wenn man das Modell verändert, also Variablen hinzufügt oder aus dem Modell entfernt.\nWenn man die kausalen Abhängigkeiten nicht kennt, weiß man also nicht, ob die Zusammenhänge kausal oder nicht-kausal sind. Man weiß also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker Zusammenhang; b1 ist stark positiv\n\n\n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, in jeder der beiden Gruppen ist der Zusammenhang praktisch Null, b1 = 0\n\n\n\n\n\n\nAbbildung 10.16: Fügt man in ein Modell eine Variable hinzu, können sich die Koeffizienten massiv ändern. In beiden Diagrammen wurden die gleichen Daten verwendet.\n\n\nMan könnte höchstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.B. “Dort wo es viele Störche gibt, gibt es auch viele Babies”.28 Leider ist unser Gehirn auf kausale Zusammenhänge geprägt: Es fällt uns schwer, Zusammenhänge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulässig kausal interpretiert – von Laien und Wissenschaftlern auch.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fazit",
    "href": "090-regression2.html#fazit",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.9 Fazit",
    "text": "10.9 Fazit\nIn diesem Kapitel haben Sie lineare Modelle gelernt, die über einfache Modelle der Art y ~ x hinausgehen. Dazu gehören multiple Modelle, das sind Modelle mit mehr als einer UV (Prädiktor) und auch Interaktionsmodelle. Außerdem haben Sie sich mit einem Datensatz von gesamtgesellschaftlichen Nutzen beschäftigt – sehr schön. Das Fallbeispiel zum Schluss war vielleicht erhellend insofern, als dass ein gutes Modell im Train-Sample nicht (notwendig) zu guten Vorhersagen im Test-Sample führt.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. Abbildung 10.17. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) So ging es Ihnen gestern\n\n\n\n\n\n\n\n\n\n(b) So wird es Ihnen morgen ergehen, wenn Sie dran bleiben\n\n\n\n\n\n\nAbbildung 10.17: Statistik, Sie und Party: Gestern und (vielleicht) morgen.29",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausführlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker Flugverspätungen 2023\n\nSource\nVorhersage von Flugverspätungen\n\n10.10.2 Filmerlöse\nVorhersagen von Filmerlösen",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklärt die lineare Regression mit Hilfe von Drachen. 🐉 Sehenswert.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\nDie Webseite datenwerk.netlify.app30 stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1\nmario-compare-models",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nWenn es ein Standardwerk für Regressionsanalyse geben könnte, dann vielleicht das neueste Buch von Andrew Gelman, ein bekannter Statistiker (Gelman et al., 2021). Sein Buch ist für Sozialwissenschaftler geschrieben, also nicht für typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel.\n\n\n\n\nEarth, H. terrae;. K. links:. L. D. von B. (2021). Deutsch: Fünfjährig Gemittelte Abweichung Der Lufftemperatur in Deutschland Vom Langjährigem Mittel 1951 Bis 1980. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing, 104(2), 271–294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nYouyou, W., Kosinski, M., & Stillwell, D. (2015). Computer-Based Personality Judgments Are More Accurate than Those Made by Humans. Proceedings of the National Academy of Sciences, 112(4), 1036–1040. https://doi.org/10.1073/pnas.1418680112",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "Lizenzhinweis: Datenbasis: Deutscher Wetterdienst, eigene Elemente ergänzt.↩︎\nsynonym: Regressionsanalysen↩︎\nhttps://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/wetter-dwd-data-dict.md↩︎\nQuelle: Umweltbundesamt↩︎\nQuelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3↩︎\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/↩︎\nr2(lm_wetter_bin_uv)↩︎\nUV↩︎\nTransformation↩︎\nIch danke Karsten Lübke für diese Idee.↩︎\nplot(estimate_expectation(lm_wetter_month)↩︎\nZum Dollar-Operator s. Kapitel 3.12.3↩︎\nSo ein Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ancova) bezeichnet werden.↩︎\nsynonym: nominalskalierte Variable↩︎\nsynonym: Regressionsformel↩︎\ns. Hinweise hier: https://malcolmbarrett.github.io/ggokabeito/reference/palette_okabe_ito.html↩︎\nder Befehl wohnt im Paket performance, Teil des Metapakets easystats↩︎\nengl. predictions; to predict: vorhersagen↩︎\nwir verwenden dazu die Funktionen mae und rsq↩︎\nwelches Sie vielleicht noch installieren müssen.↩︎\nEntweder bei R oder bei Ihnen.↩︎\nvgl. help(initial_split)↩︎\nAnderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B.↩︎\ninitial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgeführt.↩︎\nsynonym: Prognose↩︎\nQuelle↩︎\ndas nennt man dann Simpsons Paradox↩︎\nDas Störche-Babies-Beispiel passt auch zu Abbildung 10.16.↩︎\nQuelle: imgflip, https://imgflip.com/memegenerator/Distracted-Boyfriend↩︎\nhttps://datenwerk.netlify.app↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Aden-Buie, G. (2018). Wide and long data. https://www.garrickadenbuie.com/project/tidyexplain/\n\n\nAinali. (2007). Standard deviation diagram micro. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American\nStatistician, 27(1), 17–21.\n\n\nBerger, G. (2019, December 10). The Jobs of\nTomorrow: LinkedIn’s 2020 Emerging Jobs\nReport. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nBortz, J., & Schuster, C. (2010). Statistik für\nHuman- und Sozialwissenschaftler.\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do,\nAccording to 35 Data Scientists. Harvard\nBusiness Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization\nin Spreadsheets. The American Statistician,\n72(1), 2–10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nBundesamt, S. (2023-003-272023-003-27). Körpermaße nach\nAltersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household wealth and finances in\nGermany: Results of the 2021 household wealth\nsurvey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to\nModern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric visualisation of the\nvariance of the example distribution (2, 4, 4, 4, 5, 5, 7, 9) on\nw:Standard deviation. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155–159.\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003).\nApplied multiple regression/correlation analysis for the behavioral\nsciences, 3rd ed (pp. xxviii, 703). Lawrence Erlbaum Associates\nPublishers.\n\n\nDowney, A. (2023). Probably overthinking it: How to use data to\nanswer questions, avoid statistical traps, and make better\ndecisions. The University of Chicago Press.\n\n\nEarth, H. terrae;. K. links:. L. D. von B. (2021). Deutsch:\nFünfjährig gemittelte Abweichung der\nLufftemperatur in Deutschland vom langjährigem\nMittel 1951 bis 1980. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nFisher, D., & Meyer, M. (2018). Making data visual: A practical\nguide to using visualization for insight (First edition). O’Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different\nGraphs: Generating Datasets with Varied\nAppearance and Identical Statistics through\nSimulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nflaticon. (2024). Professor. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoren, A., Vaño-Galván, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur,\nA., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H.,\nKovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K.\n(2020). A preliminary observation: Male pattern hair loss\namong hospitalized COVID-19 patients in Spain\n– A potential clue to the role of androgens in\nCOVID-19 severity. Journal of Cosmetic\nDermatology, 19(7), 1545–1547. https://doi.org/10.1111/jocd.13443\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., &\nSchaub, M. P. (2015). Smartphone use and smartphone addiction among\nyoung people in Switzerland. Journal of Behavioral\nAddictions, 4(4), 299–307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHorst, A. (2023). Tidy Data. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork. https://allisonhorst.com/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The dynamics of\nHuman Development Index. The Social Science\nJournal, 52(3), 331–347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito,\nK. (2008). Color universal design: The selection of four easily\ndistinguishable colors for all color vision types. Color\nImaging XIII: Processing,\nHardcopy, and Applications,\n6807, 206–213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024a). Imageflip Meme. https://imgflip.com\n\n\nimgflip. (2024b). Yoda Meme. https://imgflip.com\n\n\nInternational, T. (2017, January 25). Corruption Perceptions\nIndex 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via\ndata science: A ModernDive into R and the\nTidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nKaplan, D. T. (2009). Statistical modeling: A fresh approach.\nCreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The smartphone\naddiction scale: Development and validation of a short version for\nadolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022).\nCustomer churn prediction system: A machine learning approach.\nComputing, 104(2), 271–294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive\nTheory to Statistics Instruction. The American\nStatistician, 54(3), 196–206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nLyon, A. (2014). Why are Normal Distributions Normal?\nThe British Journal for the Philosophy of Science,\n65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific\nMethod, Statistical Method and the\nSpeed of Light. Statistical Science,\n15(3), 254–278. https://doi.org/10.1214/ss/1009212817\n\n\nMaphry. (2009). Seesaw with mean. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMarks‐Anglin, A., & Chen, Y. (2020). A historical review of\npublication bias. Research Synthesis Methods, 11(6),\n725–742. https://doi.org/10.1002/jrsm.1452\n\n\nMatthews, R. (2000). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nMenk. (2014, July 29). Linear regression. https://texample.net/tikz/examples/linear-regression/\n\n\nMesserli, F. H. (2012). Chocolate Consumption,\nCognitive Function, and Nobel Laureates.\nNew England Journal of Medicine, 367(16), 1562–1564.\nhttps://doi.org/10.1056/NEJMon1211064\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, &\nFarias, M. (2020). Psychological impact of COVID-19\npandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of Open Data and Computational\nReproducibility in Registered Reports in\nPsychology. Advances in Methods and Practices in\nPsychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!:\nErfolg und Spaß im Horrorfach nichttechnischer Studiengänge.\nSpringer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design\n(CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: The new\nscience of cause and effect (First edition). Basic Books.\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability:\nA Brief History of a Confused Terminology.\nFrontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPoldrack, R. A. (2023). Statistical thinking: Analyzing data in an\nuncertain world. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human height. Our\nWorld in Data. https://ourworldindata.org/human-height\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley\nStatsRef: Statistics Reference Online.\nJohn Wiley & Sons, Ltd. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen,\naufbereiten, visualisieren und modellieren (1. Auflage 2019).\nSpringer. https://www.springer.com/de/book/9783658215866\n\n\nScherer, C., Radchuk, V., Staubach, C., Müller, S., Blaum, N., Thulke,\nH., & Kramer‐Schadt, S. (2019). Seasonal host life‐history processes\nfuel disease dynamics at different spatial scales. Journal of Animal\nEcology, 88(11), 1812–1824. https://doi.org/10.1111/1365-2656.13070\n\n\nSchwaiger, E., & Tahir, R. (2022). The impact of nomophobia and\nsmartphone presence on fluid intelligence and attention.\nCyberpsychology: Journal of Psychosocial Research on\nCyberspace, 16(1). https://doi.org/10.5817/CP2022-1-5\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011).\nFalse-Positive Psychology: Undisclosed\nFlexibility in Data Collection and Analysis\nAllows Presenting Anything as Significant.\nPsychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nStigler, S. M. (2016). The seven pillars of statistical wisdom.\nHarvard University Press.\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross,\nA., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., &\nBurke, D. S. (2013). Contagious Diseases in the\nUnited States from 1888 to the Present.\nNew England Journal of Medicine, 369(22), 2152–2158.\nhttps://doi.org/10.1056/NEJMms1215400\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain\nDrain: The Mere Presence of One’s\nOwn Smartphone Reduces Available Cognitive Capacity.\nJournal of the Association for Consumer Research,\n2(2), 140–154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2016). Ggplot2: Elegant graphics for data analysis\n(Second edition). Springer.\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild. https://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., & Grolemund, G. (2018). R für Data Science: Daten\nimportieren, bereinigen, umformen, modellieren und visualisieren\n(F. Langenau, Trans.; 1. Auflage). O’Reilly. https://r4ds.had.co.nz/index.html\n\n\nWilke, C. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures (First edition). O’Reilly\nMedia. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg\n(Original work published 2019)\n\n\nYouyou, W., Kosinski, M., & Stillwell, D. (2015). Computer-based\npersonality judgments are more accurate than those made by humans.\nProceedings of the National Academy of Sciences,\n112(4), 1036–1040. https://doi.org/10.1073/pnas.1418680112",
    "crumbs": [
      "Abschluss",
      "Literatur"
    ]
  },
  {
    "objectID": "110-definitions.html",
    "href": "110-definitions.html",
    "title": "Anhang A — Definitionen",
    "section": "",
    "text": "Abweichungsrechteck: Definition 8.1\nArgumente einer Funktion: Definition 3.4\nAusprägung: Definition 2.8\nBalkendiagramm: Definition 5.2\nBeobachtungseinheit: Definition 2.6\nBinäre Variable: Definition 10.1\nBoxplot: Definition 5.9\nData-Dictionary: Definition 2.4\nDataframe: Definition 3.6\nHallo, Daten: Definition 2.3\nDatenjudo: Definition 4.1\nDezile: Definition 6.6\nDichtediagramm: Definition 5.4\nExtremwert: Definition 6.3\nFehlerstreuung: Definition 9.2\nFunktion: Definition 3.2\nGerade: Definition 9.1\nHistogramm: Definition 5.3\nInterquartilsabstand: Definition 7.4\nKovarianz: Definition 8.2\nLagemaß: Definition 6.8\nLinearer Zusammenhang: Definition 5.7\nLineares Modell: Definition 6.2\nMittlere Absolutabweichung: Definition 7.3\nMedian: Definition 6.4\nModelle: Definition 2.11\nMittelwert: Definition 6.1\nNormalverteilung: Definition 5.5\nEntstehung einer Normalverteilung: Definition 5.6\nPfeife: Definition 4.2\nPunktmodell: Definition 6.9\nQuantile: Definition 6.7\nQuartile: Definition 6.5\nKorrelationskoeffizient r: Definition 8.3\nR-Quadrat: Definition 9.3\nEin einfaches Streuungsmaß ist der Range \\(R\\), : Definition 7.2\nReproduzierbarkeit: Definition 3.1\nResiduum: Definition 2.2\nStandardabweichung: Definition 7.6\nSkalenniveau: Definition 2.10\nStatistik: Definition 2.1\nStreuungsmaße: Definition 7.1\nTestsample: Definition 10.3\nTidy Data: Definition 2.9\nTrainsample: Definition 10.2\nVariable: Definition 7.5\nVarianz: Definition 7.5\nVektorielles Rechnen: Definition 3.5\nVektor: Definition 3.3\nVerteilung: Definition 5.1\nWert: Definition 2.7\nz-Werte: Definition 7.8\nZentrieren: Definition 7.7\nRichtung und Stärke eines Zusammenhang: Definition 5.8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Definitionen</span>"
    ]
  }
]