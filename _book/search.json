[
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Lernsteuerung\nAbb. AbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#lernsteuerung",
    "href": "040-verbildlichen.html#lernsteuerung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Lernziele\n\nSie kÃ¶nnen erlÃ¤utern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arte von Datendiagrammen.\nSie kÃ¶nnen typische Datendiagramme mit R visualisieren.\nSie kÃ¶nnen zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\nlibrary(ggpubr)  # optional\nlibrary(ggstatsplot)  # optional\n\n\n5.1.3 BenÃ¶tigte Daten\nZuerst definieren wir den Pfad, wo wir die Daten finden, s. ListingÂ 5.1. Dann importieren wir die Mariokart-Daten.\n\n\n\nListingÂ 5.1: Pfad zu den Mariokart-Daten\n\nmariokart_path &lt;- paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets\",\n  \"/csv/openintro/mariokart.csv\")\n\nmariokart &lt;- read.csv(mariokart_path)\n\n\n\n\n\n5.1.4 R-Code zum Copy-Pasten\nSie finden den R-Code fÃ¼r jedes Kapitel hier. \\(\\square\\)\n\n5.1.5 Quiz zum Einstieg\n\n\n\n\n\n\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwas mittels der Plattform antworte.jetzt. Alternativ Ã¼berlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.6 Wozu das alles?\n\n\nGroÃŸe Aufgaben warten â€¦ (imgflip, 2024)\n\n\nğŸ¥· Wir mÃ¼ssen die Galaxis retten, Kermit.\n\n\nğŸ¸ Schlock",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heiÃŸt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte, s. AbbildungÂ 5.1. In AbbildungÂ 5.1 sieht man verschiedene â€œBilderâ€, also DatensÃ¤tze: etwa einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschiedene sind, sind die zentralen statistischen Kennwerte (praktisch) identisch. In die gleiche Bresche schlÃ¤gt â€œAnscombes Quartettâ€ (Anscombe, 1973), s. AbbildungÂ 5.2: Es zeigt vier DatensÃ¤tze, in denen die zentralen Statistiken fast identisch sind,\nalso Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthÃ¼llt, was der Statistik (als Kennzahl) verhÃ¼llt bleibt.\n\n\n\n\n\nAbbildungÂ 5.1: Dinosaurier und Kreis: Gleiche statistischen Kennwerte (Fitzmaurice, 2017)\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Diagramme kÃ¶nnen Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier DatensÃ¤tzen\n\n\nUnter visueller Cortex ist sehr leistungsfÃ¤hig. Wir kÃ¶nnen ohne MÃ¼he eine groÃŸe Anzahl an Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen.\n\n\n\n\n\n\nTipp\n\n\n\nNutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mÃ¤chtig.\n\n\n\n5.2.1 Datendiagramm\nEin Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwÃ¤ndiges (und ansprechendes) Datendiagramm) Â \n\n\n\n\n\n\nAuf Basis des Korruptionsindex von Transparency International (2017) erstellt Wilke (2019/2024) ein Diagramm zum Zusammenhang vom Entwicklungsindex (Lebenserwartung, Bildung, Einkommen; vgl. Hou et al. (2015)) und Korruption, jeweils auf Landesebene, s. AbbildungÂ 5.3.\nEs finden sich in der Literatur (im Internet) viele weitere Beispiele fÃ¼r handwerklich meisterhaft erstelle Datendiagramme, die in vielen FÃ¤llen mit R erstellt werden (vgl. Scherer et al., 2019).\n\n\nÂ \n\n\n\n\n\n\n\nAbbildungÂ 5.3: Der Zusammenhang von Entwicklungindex und und Korruption\n\n\n\n\n\n\n\n5.2.2 Ein Bild hat nicht so viele Dimensionen\nAbbildungÂ 5.4 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer â€œDimensionâ€ entsprechen. Wie man (nicht) sieht, wird es langsam unÃ¼bersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die â€œDimensionalitÃ¤tâ€ eines Diagramms hat ihre Grenzen, vielleicht bei 4-6 Variablen.\n\n\n\n\n\n\n\nAbbildungÂ 5.4: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\nMÃ¶chten wir den Zusammenhang von vielen Variablen, z.B. mehr als 5, verstehen, kommen wir mit Bildern nicht weiter. Dann brauchen wir andere Werkzeuge: statistics to the rescue.\n\n\n\n\n\n\nHinweis\n\n\n\nBei klaren ZusammenhÃ¤ngen und wenig Variablen braucht man keine (aufwÃ¤ndige) Statistik. Ein Bild (Datendiagramm) ist dann (oft) ausreichend. Man kÃ¶nnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. 4-6 Variablen nicht gleichzeitig umgehen kann.\n\n\n\nÃœbungsaufgabe 5.1 Wie viele Variablen sind in AbbildungÂ 5.4 dargestellt?1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelleÂ 5.1 zeigt eine â€“ sehr kurze Nomenklatur â€“ an Datendiagrammen. Weitere Nomenklaturen sind mÃ¶glich, aber wir halten hier die Sache einfach. Wer an Vertiefung interessiert ist, findet bei data-to-vis einen Ãœberblick Ã¼ber verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur: https://www.data-to-viz.com/.\n\n\n\nTabelleÂ 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefÃ¼lltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefÃ¼lltes Balkendiagramm\nBoxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir arbeiten hier mit dem Datensatz mariokart. Hilfe bzw. ein Data-Dictionary (Codebook) finden Sie hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung: nominale Variable\n\nDefinition 5.1 (Verteilung) Eine (HÃ¤ufigkeits-)Verteilung einer Variablen \\(X\\) schlÃ¼sselt auf, wie hÃ¤ufig jede AusprÃ¤gung von \\(X\\) ist.\\(\\square\\)\n\n\nBeispiel 5.2 TabelleÂ 5.2 zeigt die HÃ¤ufigkeitsverteilung von cond (condition, also der Zustand des Artikels, neu oder gebraucht) aus dem Datensatz mariokart. Die Variable hat 5 AusprÃ¤gungen; z.B. kommt die AusprÃ¤gung new 59 mal vor.\\(\\square\\)\n\n\n\n\nTabelleÂ 5.2: HÃ¤ufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. AbbildungÂ 5.5. Wie man sieht, besteht so ein Diagramm als Balken, daher heiÃŸt es Balkendiagramm (synonym: SÃ¤ulendiagramm). Man kann so ein Diagramm um 90Â° drehen; keine Ausrichtung ist unbedingt besser als die andere.\n\nDefinition 5.2 (Balkendiagramm) Ein Balkendiagramm ist eine grafische Darstellung von Werten, zumeist fÃ¼r die HÃ¤ufigkeiten bestimmter Kategorien (AusprÃ¤gungen nominaler Variablen). Dabei werden rechteckige Balken verwendet werden, und die LÃ¤nge eines Balkens ist proportional zur dargestellten HÃ¤ufigkeit. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) horizontale Balken\n\n\n\n\n\n\n\n\n\n(b) vertikale Balken\n\n\n\n\n\n\nAbbildungÂ 5.5: HÃ¤ufigkeitsverteilung der Variable cond\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. AbbildungÂ 5.5; wir betrachten gleich die Syntax.\nZuerst importieren wir die Daten, s. ?lst-mariokart-path.\nAuÃŸerdem nicht vergessen, das Paket DataExplorer mit dem Befehle library zu starten. (NatÃ¼rlich mÃ¼ssen Sie das Paket einmalig installiert haben, bevor Sie es starten kÃ¶nnen.) In diesem Paket â€œwohnenâ€ die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden. ListingÂ 5.2 zeigt die Syntax, um ein Balkendiagramm zu erstellen. Auf der Hilfeseite der Funktion finden Sie weitere Details zur Funktion.\n\n\n\nListingÂ 5.2: Syntax zur Erstellung eines Balkendiagramms\n\nlibrary(DataExplorer)\nmariokart &lt;- read.csv(mariokart_path)\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.6: Ein Balkendiagramm. Unglaublich.\n\n\n\n\nDie Syntax ist in ListingÂ 5.2 abgedruckt (Zur Erinnerung: %&gt;% nennt man die â€œPfeife und lÃ¤sst sich alsâ€und dannâ€ Ã¼bersetzen, vgl. Kapitel 4.4). Ãœbersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz mariokart *und dann*\n  wÃ¤hle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm.\n\nÃœbungsaufgabe 5.2 (Spalten wÃ¤hlen fÃ¼r das Balkendiagramm) HÃ¤tten wir andere Spalten ausgewÃ¤hlt, so wÃ¼rde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie kÃ¶nnen auch mehrere Variablen auf einmal auswÃ¤hlen. Probieren Sie das doch mal aus!\n\n\nÃœbungsaufgabe 5.3 (Visualisieren Sie die Verteilung von stock_photo!) Â \n\nmariokart |&gt; \n  select(stock_photo) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\n\n\n\n5.4.2 Verteilung: quantitative Variable\n\n5.4.2.1 Histogramm\nBei einer quantitativen Variablen mit vielen AusprÃ¤gungen wÃ¤re ein Balkendiagramm nicht so aussagekrÃ¤ftig, s. AbbildungÂ 5.7 (links). Es gibt einfach zu viele AusprÃ¤gungen.\nDie LÃ¶sung: Wir reduzieren die Anzahl der AusprÃ¤gungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger AusprÃ¤gungen zu bekommen, kÃ¶nnen wir einfach Gruppen definieren, z.B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 2: 11-15 Dollar â€¦\n\nIn AbbildungÂ 5.7 (rechts) sind z.B. die AusprÃ¤gungen des Verkaufspreis (total_pr) in in Gruppen der Breite von 5 Dollar aufgeteilt worden. ZusÃ¤tzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\n\n\n(a) Balkendiagramm\n\n\n\n\n\n\n\n\n\n(b) Histogramm\n\n\n\n\n\n\nAbbildungÂ 5.7: Balkendiagramm vs.Â Histogramm fÃ¼r den Gesamtpreis (total_pr)\n\n\n\nDefinition 5.3 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der HÃ¤ufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt sind. Die HÃ¶he der Balken zeigt die HÃ¤ufigkeit der Daten in dieser Gruppe/in diesem Balken (bei konstanter Balkenbreite).\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten nicht sehr viele und nicht sehr wenig sein, s. AbbildungÂ 5.8 links bzw. AbbildungÂ 5.8, rechts.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildungÂ 5.8: Nicht zu wenig und nicht zu viele Balken im Balkendiagramm\n\n\nZur Erstellung eines Histogramms kÃ¶nnen Sie die Syntax ListingÂ 5.3 nÃ¼tzen, vgl. AbbildungÂ 5.9, links.\n\n\nListingÂ 5.3: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 5.9: Eine stetige Verteilung verbildlichen\n\n\n\nÃœbungsaufgabe 5.4 (Visualisieren Sie die Verteilung von ship_pr anhand eines Histogramms!) Â \n\nmariokart |&gt; \n  select(ship_pr) |&gt; \n  plot_histogram()\n\n\n\n\n\n\n\n\n\n5.4.2.2 Dichtediagramm\nAbbildungÂ 5.10 fÃ¼gt zu ?fig-balken-total-pr-hist ein Dichtediagramm hinzu (rote Linie). Ein Dichtediagramm Ã¤hnelt einem â€œglattgeschmirgeltemâ€ Histogramm.\n\nDefinition 5.4 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglÃ¤ttet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden. (Mit Dichte ist die Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.)\n\n\n\n\n\n\n\n\nAbbildungÂ 5.10: Histogramm (graue Balken) und Dichtediagramm (orange Linie) fÃ¼r total_pr\n\n\n\n\n\nÃœbungsaufgabe 5.5 Erstellen Sie das Diagramm AbbildungÂ 5.9, rechtes Teildiagramm!2\\(\\square\\)\n\n\n5.4.2.3 Eigenschaften von Verteilungen\nVerteilungen unterscheiden sich z.B. einerseits in ihrem â€œtypischenâ€ oder â€œmittlerenâ€ Wert (vgl. Kapitel 6.5) und anderseits in ihrer Streuung (vgl. Kapitel 7.4.) (Diagramme von) Verteilungen kÃ¶nnen symmetrisch oder schief (nicht symmetrisch) sein, s. AbbildungÂ 5.11.\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildungÂ 5.11: Symmetrische vs.Â schiefe Verteilung, verbildlicht\n\n\nAbbildungÂ 5.12 zeigt verschiedene Formen von Verteilungen. â€œBimodalâ€ meint â€œzweigipfligâ€ und â€œmultimodalâ€ entsprechend â€œmehrgipfligâ€.3\n\n\n\n\n\n\n\nAbbildungÂ 5.12: Verschiedene Verteilungsformen\n\n\n\n\n\nÃœbungsaufgabe 5.6 (Verteilungform von total_pr?) Benennen Sie die am besten passende Verteilungsform fÃ¼r die Variable total_pr.\nLÃ¶sung\nDie Verteilung ist rechtsschief.\n\nmariokart |&gt; \n  select(total_pr) |&gt; \n  plot_density()\n\n\n\n\n\n\n\n\n\n5.4.3 Normalverteilung\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer quantitativen Variablen. Aber sie ist besonders wichtig, und ist daher hier herausgestellt.\nEine Normalverteilung sehen Sie in AbbildungÂ 5.11, links. Sie hat u.a. folgende Eigenschaften:\n\nsymmetrisch\nglockenfÃ¶rmig\nstetig\neingipflig (unimodal)\nMittelwert, Median und Modus sind identisch\n\n\nBeispiel 5.3 Beispiele fÃ¼r normalverteilte Variablen sind KÃ¶rpergrÃ¶ÃŸe von MÃ¤nnern oder Frauen, IQ-Werte, PrÃ¼fungsergebnisse, Messfehler, Lebensdauer von GlÃ¼hbirnen, Gewichte von Brotlaiben, Milchproduktion von KÃ¼hen, Brustumfang schottischer Soldaten (Lyon, 2014).\\(\\square\\)\n\n\nDefinition 5.5 (Normalverteilung) Eine Normalverteilung ist eine spezielle Art von Verteilung einer quantitativen Variablen. Sie ist symmetrisch, glockenfÃ¶rmig, stetig, unimodal und hat Mittelwert, Median und Modus identisch. Sie lÃ¤sst sich durch zwei Parameter vollstÃ¤ndig beschreiben: Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)). \\(\\square\\)\n\nDie Normalverteilung ist von hoher Bedeutung, da sich diese Verteilung unter (recht hÃ¤ufigen) Bedingungen zwangslÃ¤ufig ergeben muss.\n\nDefinition 5.6 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhÃ¤ngiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\n\n\n\n\n\n\nDieses PhÃ¤nomen kann man gut anhand des Galton-Bretts veranschaulichen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter der Normalverteilung\n\n\n\nEine Normalverteilung lÃ¤sst sich exakt beschreiben anhand zweier Parameter: ihres zentralen Werts (Mittelwerts), \\(\\mu\\), und ihrer Streuung (Standardabweichung), \\(\\sigma\\). \\(\\square\\)\n\n\nAbbildungÂ 5.13 zeigt interaktive Beispiele fÃ¼r Normalverteilung. WÃ¤hlen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler.4\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\nshow_curve = true\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.13: Interaktives Beispiel fÃ¼r Normalverteilungen.\n\n\nKennt man diese beiden Parameter, so kann man einfach angeben, welcher Anteil der FlÃ¤che sich in einem bestimmten Bereich befindet, s. AbbildungÂ 5.14.\nDavon leitet sich die â€œ68-95-99.7-Prozentregelâ€ ab:\n\n\n\\(68\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{,}7\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.14: Die FlÃ¤cheninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in AbhÃ¤ngigkeit der SD-Einheiten (Ainali, 2007)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.5 ZusammenhÃ¤nge verbildlichen",
    "text": "5.5 ZusammenhÃ¤nge verbildlichen\n\n5.5.1 Zusammenhang: nominale Variablen\n\nBeispiel 5.4 (Beispiele fÃ¼r ZusammenhÃ¤nge bei nominalen Variablen) Â \n\nHÃ¤ngt Berufserfolg (FÃ¼hrungskraft ja/nein) mit dem Geschlecht zusammen?\nHÃ¤ngt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen Automarke und politische PrÃ¤ferenz einer Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primÃ¤r bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. AbbildungÂ 5.15.\n\n\n\n\n\n\n\n\n\n(a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten\n\n\n\n\n\n\n\n\n\n(b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\n\n\n\nAbbildungÂ 5.15: Zusammenhang zwischen nominalskalierten Variablen verbildlichen\n\n\nTatsÃ¤chlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (AbbildungÂ 5.15, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der HÃ¤lfte der FÃ¤lle.\nAnders sieht es aus fÃ¼r die Frage, ob ein (oder mehrere) LenkrÃ¤der dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach â€œFoto des Produkts dabeiâ€ betraf (AbbildungÂ 5.15, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten).\nAnders gesagt: Unterscheiden sich die â€œFÃ¼llhÃ¶heâ€ in den Diagrammen, so gibt es einen Unterschied hinsichtlich â€œFoto ist dabeiâ€ zwischen den beiden Gruppen (linker vs.Â rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs.Â gebrauchte Spiele), so spielt z.B. die Variable â€œFoto dabeiâ€ offenbar eine Rolle. Dann hÃ¤ngen Neuwertigkeit und â€œFoto dabeiâ€ also zusammen!\nSo kÃ¶nnen Sie sich in R ein gefÃ¼lltes Balkendiagramm ausgeben lassen, s. AbbildungÂ 5.16. Diese Darstellung eignet sich, um ZusammenhÃ¤nge zwischen zwei zweistufigen nominal skalierten Variablen zu verbildlichen. Die verschiedenen Werte der FÃ¼llfarbe werden den Stufen der Variablen cond zugewiesen, s. ListingÂ 5.4.\n\n\n\nListingÂ 5.4: R-Syntax fÃ¼r ein gefÃ¼lltes Balkendiagramm\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.16: Ein gefÃ¼lltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nGefÃ¼llte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei AusprÃ¤gungen aufweisen, sonst sind die ZusammenhÃ¤nge nicht mehr so gut zu erkennen.\\(\\square\\)\n\n\n\nÃœbungsaufgabe 5.7 (Zusammenhang visualisieren) Aufgabe Visualisieren Sie den Zusammenhang der beiden nominalen Variablen cond und wheels!\nLÃ¶sung\nwheels ist als metrische Variable (int: Integer, d.h. Ganzzahl) formatiert im Datensatz mariokart. Wir mÃ¼ssen Sie zunÃ¤chst als Faktorvariable umformatieren, damit R sie als nominal skalierte Variable erkennt.\n\nmariokart |&gt; \n  # Mache aus einer metrischen eine nominale Variable: \n  mutate(wheels = factor(wheels)) |&gt; \n  select(cond, wheels) |&gt; \n  plot_bar(by = \"cond\")\n\n\n\n\n\n\n\n\n\n5.5.2 Zusammenhang: metrisch\nDen (etwaigen) Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). AbbildungÂ 5.17 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine â€œTrendgeradeâ€ (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schlieÃŸen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je hÃ¶her der Startpreis, desto hÃ¶her der Abschlusspreis, zumindest tendenziell. Diese Gerade liegt â€œmittigâ€ in den Daten (wir definieren dies spÃ¤ter genauer). Diese Trendgerade gibt Aufschluss Ã¼ber â€œtypischeâ€ Werte: Welcher Y-Wert ist â€œtypischâ€ fÃ¼r einen bestimmten X-Wert?\nAbbildungÂ 5.17 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis. Das erkennt man an der sinkenden Trendgeraden.\nDie Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. AbbildungÂ 5.19.\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) negativer, eher schwacher Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 5.17: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\nDefinition 5.7 (Linearer Zusammenhang) LÃ¤sst sich die Beziehung zwischen zwei Variablen mit einer Gerade visualisieren, so spricht man von einem linearen Zusammenhang. Ã„ndert man eine der beiden Variablen um einen bestimmten Wert (z.B. 1), so Ã¤ndert sich die andere um einen proportionalen Wert (z.B. 0.5). \\(\\square\\)\n\nNatÃ¼rlich kÃ¶nnte man auch nicht-lineare ZusammenhÃ¤nge untersuchen, aber der Einfachheit halber konzentrieren wir uns hier mit linearen; Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge sind in AbbildungÂ 5.18 zu sehen.\n\n\n\n\n\n\n\nAbbildungÂ 5.18: Beispiele nichtlinearer ZusammenhÃ¤nge\n\n\n\n\n\nDefinition 5.8 (Richtung und StÃ¤rke eines Zusammenhang) Gleichsinnige (positive) ZusammenhÃ¤nge erkennt man an aufsteigenden Trendgeraden \\(\\nearrow\\); gegensinnige (negative) ZusammenhÃ¤nge an absteigenden Trendgeraden \\(\\searrow\\). \\(\\square\\)\n\nStarke ZusammenhÃ¤nge erkennt man an schmalen Ellipsen (â€œBaguetteâ€ ğŸ¥–); schwache ZusammenhÃ¤nge an breiten Ellipsen (â€œTorteâ€ ğŸ¥®). AbbildungÂ 5.19 bietet einen Ãœberblick Ã¼ber verschiedene Beispiele von Richtung und StÃ¤rke von ZusammenhÃ¤ngen.5\n\n\n\n\n\n\n\nAbbildungÂ 5.19: Lineare ZusammenhÃ¤nge verschiedener StÃ¤rke und Richtung\n\n\n\n\nIn AbbildungÂ 5.19 ist fÃ¼r jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und StÃ¤rke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht fÃ¼r einen positiven Zusammenhang, ein negatives Vorzeichen fÃ¼r einen negativen Zusammenhang. Der (Absolut-)Wert gibt die StÃ¤rke des linearen Zusammenhangs an (Cohen, 1992):\n\nÂ±0: Kein Zusammenhang\nÂ±0.1: schwacher Zusammenhang\nÂ±0.3: mittlerer Zusammenhang\nÂ±0.5: starker Zusammenhang\nÂ±1: perfekter Zusammenhang\n\nAbbildungÂ 5.20 hat die gleiche Aussage wie AbbildungÂ 5.19, ist aber plakativer, indem StÃ¤rke (schwach, stark) und Richtung (positiv, negativ) gegenÃ¼bergestellt sind.\n\n\n\n\n\n\n\nAbbildungÂ 5.20: Ãœberblick Ã¼ber starke vs.Â schwache bzw. positive vs.Â negative ZusammenhÃ¤nge\n\n\n\n\nMan sieht in AbbildungÂ 5.19 und AbbildungÂ 5.20, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade (synonym: Regressionsgerade; blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke ZusammenhÃ¤nge mit einer schmaler Ellipse einhergehen und schwache ZusammenhÃ¤nge mit einer breiten Ellipse einhergehen.\nAbbildungÂ 5.21 zeigt interaktive Beispiele fÃ¼r (lineare) ZusammenhÃ¤nge.6\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.21: Interaktives Beispiel fÃ¼r Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und manchmal gehÃ¶rt Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhÃ¤ngen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. AuÃŸerdem mÃ¼ssen wir noch die Daten importieren, falls noch nicht getan, s. ListingÂ 5.1.\nSo, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf metrische Variablen konzentrieren wollen, wÃ¤hlen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewÃ¤hlten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primÃ¤r interessiert. Das Ergebnis sieht man in AbbildungÂ 5.22 bzw. ListingÂ 5.5. \\(\\square\\)\n\n\n\n\nListingÂ 5.5: Streudiagramm erstellen mit dem R-Paket â€˜DataExplorerâ€™\n\nmariokart %&gt;% \n  select(duration, n_bids, start_pr,\n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.22: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nAhaâ€¦ Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafÃ¼r sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur VerkÃ¤ufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100). Das Ergebnis ist in AbbildungÂ 5.23 zu sehen.\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nmariokart_no_extreme %&gt;% \n  select(duration, n_bids, start_pr, \n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildungÂ 5.23: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nOhne Extremwerte schÃ¤lt sich ein deutlicheres Bild (AbbildungÂ 5.23) hervor: Startpreis (start_pr) und Anzahl der RÃ¤der (wheels) scheinen am stÃ¤rksten mit dem Abschlusspreis zusammenzuhÃ¤ngen.\nDas Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle Ã¼brigen Variablen kommen jeweils einmal als X-Variable vor.\\(\\square\\)\n\nÃœbungsaufgabe 5.8 Â \n\n\nAufgabe\nLÃ¶sung\n\n\n\nVisualisieren Sie den Zusammenhang der beiden metrischen Variablen start_pr und total_pr. Verwenden Sie den Datensatz ohne Extremwerte wie oben definiert.\n\n\n\nmariokart_no_extreme |&gt; \n  select(start_pr, total_pr) |&gt; \n  plot_scatterplot(by = \"total_pr\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.6 Unterschiede verbildlichen",
    "text": "5.6 Unterschiede verbildlichen\n\n5.6.1 Unterschied: nominale Variablen\nGute Nachrichten: FÃ¼r nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von ZusammenhÃ¤ngen als auch von Unterschieden an. Genau genommen zeigt ja AbbildungÂ 5.15 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Photos beiliegen. Und wie man in AbbildungÂ 5.15 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen hÃ¶her als bei gebrauchten Spielen.7\n\n5.6.2 Unterschied: quantitative Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich unterscheiden. Genauer gesagt untersucht man z.B. oft, ob sich die Mittelwerte der beiden Gruppen zwischen der Zielvariablen deutlich unterscheiden. Das hÃ¶rt sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. AbbildungÂ 5.24.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildungÂ 5.24: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von AbbildungÂ 5.24 zeigt das Histogramm von total_pr, getrennt fÃ¼r neue und gebrauchte Spiele, vgl. AbbildungÂ 5.9. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsfrom, den Boxplot.8 Was ein â€œdeutlicherâ€ (â€œsubstanziellerâ€, â€œbedeutsamerâ€, â€œrelevanterâ€ oder â€œ(inhaltlich) signifikanterâ€) Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\n\nDefinition 5.9 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms. Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar.\\(\\square\\)\n\nIn AbbildungÂ 5.25 sieht man die â€œÃœbersetzungâ€ von Histogramm (oben) zu einem Boxplot (unten). Ob der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack Ã¼berlassen.\n\n\n\n\n\n\n\nAbbildungÂ 5.25: Ãœbersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die â€œAnatomieâ€ des Boxplots nÃ¤her an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto grÃ¶ÃŸer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie â€œAntennenâ€ des Boxplots zeigen die Streuung in den kleinsten 25% der Werte (linke Antenne) bzw. die Streuung der grÃ¶ÃŸten 25% der Werte (rechte Antennen). Je lÃ¤nger die Antenne, desto grÃ¶ÃŸer die Streuung.\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, auÃŸerhalb der Antennen gezeigt werden. Daher ist die AntennenlÃ¤nge auf die 1,5-fache LÃ¤nge der Box beschrÃ¤nkt. Werte die auÃŸerhalb dieses Bereichs liegen (also mehr als das 1,5-fache der BoxlÃ¤nge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.h. sie ist schief). Gleiches gilt fÃ¼r die AntennenlÃ¤ngen: Sind die Antennen gleich lang, so ist der Ã¤uÃŸere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der LenkrÃ¤der untersucht. Jetzt mÃ¶chten Sie eine sehr Ã¤hnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten LenkrÃ¤der? Flink erstellen Sie dazu folgendes Diagramm, AbbildungÂ 5.26, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl LenkrÃ¤der (by = \"wheels\"). \\(\\square\\)\n\nAber ganz glÃ¼cklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wÃ¤re eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen wÃ¼rde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von AbbildungÂ 5.26) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert. Vielleicht so, dass in jeder Gruppe gleich viele Wert sind?] Aber wir mÃ¶chten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir mÃ¶chten wheels als nominale Variable definieren. Das kann man mit dem Befehle factor(wheels) erreichen (verpackt in mutate), s. AbbildungÂ 5.26 rechts.\n\nmariokart_no_extreme %&gt;% \n  select(total_pr, wheels) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\nmariokart_no_extreme %&gt;% \n  select(total_pr, wheels) %&gt;% \n  mutate(wheels = factor(wheels)) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildungÂ 5.26: Abschlusspreis nach Anzahl von beigelegten LenkrÃ¤dern\n\n\nSie schlieÃŸen aus dem Bild, dass LenkrÃ¤der und Preis (positiv) zusammenhÃ¤ngen. Allerdings scheint es wenig Daten fÃ¼r wheels == 4 zu geben. Das prÃ¼fen Sie nach:\n\nmariokart_no_extreme %&gt;% \n  count(wheels)\n\n\n\nwheels\nn\n\n\n\n0\n36\n\n\n1\n52\n\n\n2\n50\n\n\n3\n2\n\n\n4\n1\n\n\n\n\n\nTatsÃ¤chlich gibt es (in mariokart_no_extreme) auch fÃ¼r 3 LenkrÃ¤der schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten.\nÃœbrigens bezeichnet Sie Ihre Chefin nur noch als â€œDatengottâ€.\n\nÃœbungsaufgabe 5.9 (Visualisieren Sie den Unterschied im Verkaufspreis zwischen gebrauchten und neuen Spielen.) LÃ¶sung\n\nmariokart_no_extreme |&gt; \n  select(cond, total_pr) |&gt; \n  plot_boxplot(by = \"cond\")\n\n\n\n\n\n\n\n\n\nÃœbungsaufgabe 5.10 (Verkaufspreis im Vergleich) Visualisieren Sie den Unterschied im Verkaufspreis abhÃ¤ngig von ship_pr; betrachten Sie ship_pr als ein Gruppierungsvariable. Interpretieren Sie das Ergebnis.\nLÃ¶sung\n\nmariokart_no_extreme |&gt; \n  select(ship_pr, total_pr) |&gt; \n  plot_boxplot(by = \"ship_pr\")\n\n\n\n\n\n\n\nplot_boxplot gruppiert metrische Variablen, wie ship_pr automatisch in fÃ¼nf Gruppen (mit gleichen Ranges). Wir mÃ¼ssen also nichts tun, um die metrische Variable ship_pr in eine Gruppierungsvariable (Faktorvariable) umzuwandeln.\nEs sieht so aus, als wÃ¼rde der Median zwischen den Gruppen leicht steigen, mit Ausnahme der mittleren Gruppe.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.7 So lÃ¼gt man mit Statistik",
    "text": "5.7 So lÃ¼gt man mit Statistik\nDiagramme werden miunter eingesetzt, um die Wahrheit â€œaufzuhÃ¼bschenâ€. Hier folgen einige gebrÃ¤uchlichen TÃ¤uschungsmanÃ¶ver.\n\n5.7.1 Achsen manipulieren\nAchsen zu stauchen ist ein einfacher Trick, s. AbbildungÂ 5.27.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.27: Stauchen der Y-Achse, um mit Statistik zu lÃ¼gen\n\n\nNatÃ¼rlich kann man auch durch â€œAbschneidenâ€ der Y-Achse einen eindrucksvollen Effekt erzielen, s. AbbildungÂ 5.28.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.28: Abschneiden der Y-Achse, um mit Statistik zu lÃ¼gen\n\n\n\n5.7.2 Scheinkorrelation\nMesserli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: LÃ¤nder), s. AbbildungÂ 5.29. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?)\n\n\n\n\n\nAbbildungÂ 5.29: Schokolodenkonsum und Nobelpreise\n\n\nLeider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhÃ¤ngen, heiÃŸt das nicht, dass die Variable die Ursache und die andere die Wirkung sein muss. So kÃ¶nnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In hÃ¶her entwickelten LÃ¤ndern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu LÃ¤ndern mit geringerem Entwicklungsstand.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.8 Praxisbezug",
    "text": "5.8 Praxisbezug\nEin, wie ich finde schlagendes Beispiel zur StÃ¤rke von Datendiagrammen ist AbbildungÂ 5.30. Das Diagramm zeigt die HÃ¤ufigkeit von Masern, vor und nach der EinfÃ¼hrung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurÃ¼ck.\n\n\n\n\n\nAbbildungÂ 5.30: HÃ¤ufigkeit von Masern und Impfung in den USA [moore_recreating_2015]\n\n\nIn der â€œfreien Wildbahnâ€ findet man hÃ¤ufig sog. â€œTortendiagrammeâ€. Zwar sind sie beliebt, doch ist von ihrer Verwendung zumeist abzuraten; vgl. auch hier.9",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\n\n5.9.1 Animation\nEine weitere nÃ¼tzliche Art von Visualisierung sind Karten, 3D-Bilder und Animationen. So zeigt z.B. AbbildungÂ 5.31 die VerÃ¤nderung der Lebenserwartung (in Jahren) Ã¼ber die letzten Dekaden.10\n\n\n\n\n\nAbbildungÂ 5.31: Animation zur VerÃ¤nderung der Lebenserwartung\n\n\nIn einigen Situation kÃ¶nnen Animationen zweckdienlich sein. AuÃŸerdem sind sie mitunter nett anzuschauen, s. AbbildungÂ 5.32.\n\n\n\n\n\nAbbildungÂ 5.32: VerÃ¤nderung des Zusammenhangs von Lebenswertung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\nUm den gemeinsamen Zusammenhang dreier metrischer Variablen darzustellen, bietet sich ein 3D-Streudiagramm an; s. AbbildungÂ 5.33.\n\n\n\n\n\n\n\nAbbildungÂ 5.33: 3D-Punktediagramm zum Datensatz mariokart\n\n\n\nLeider ist AbbildungÂ 5.33 nicht sehr aufschlussreich.\nNatÃ¼rlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animationen ziemlich beeindruckend. 11\n\n5.9.2 Schicke Diagramme\nEin Teil der Diagramm dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMÃ¶chte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median heraustellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.B.) mit ggpubr, s. AbbildungÂ 5.34.\n\nggviolin(mariokart_no_extreme, \n         x = \"cond\", \n         y = \"total_pr\",\n         add = \"mean_sd\") \n\n\n\n\n\n\nAbbildungÂ 5.34: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nEin â€œViolinenplotâ€ hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die â€œViolineâ€, desto mehr Beobachtungen gibt es an dieser Stelle. Weitere Varianten zum Violinenplot mit ggpubr finden sich hier.12\nÃœbrigens sind Modelle â€“ und Diagramme sind Modelle â€“ immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen. Dieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.13 Ein weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heiÃŸt ggstatsplot.14 AbbildungÂ 5.35 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.15\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart_no_extreme,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrÃ¼ckt statist. Details\n)\n\n\n\n\n\n\nAbbildungÂ 5.35: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. MÃ¶chte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE. (Weitere Hinweise finden sich auf der Hilfeseite der Funktion der Funktion.)\n\nğŸ‘©â€ğŸ« Ich wÃ¼rde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\nğŸ§‘â€ğŸ“ Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.16\n\n\n5.9.3 Farbwahl\nEinige Ãœberlegungen zur Farbwahl findet sich bei Wilke (2019), s. Kap. 4.17 Die Farbpalette von Okabe und Ito ist (vgl. Ichihara et al., 2008) empfehlenswert, da sie auch bei Schwarz-WeiÃŸ-Druck und bei SehschwÃ¤chen die Farben noch recht gut unterscheiden lÃ¤sst, s. AbbildungÂ 5.36.\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\") +\n  scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 5.36: Die Farbskala von Okabe und Ito: Geeignet bei Farbseh-SchwÃ¤chen und fÃ¼r Schwarz-WeiÃŸ-Druck. AuÃŸerdem nett anzuschauen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2\nvis-gapminder\nboxplots-de1a\ndiamonds-histogramm-vergleich\nwozu-balkendiagramm\ndiamonds-histogram\nn-vars-diagram\n\nNoch mehr Aufgaben zum Thema Datenvisualisierung finden Sie im Datenwerk unter dem Tag vis.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise",
    "href": "040-verbildlichen.html#literaturhinweise",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.11 Literaturhinweise",
    "text": "5.11 Literaturhinweise\nSowohl ggpubr als auch DataExplorer (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2016). Eine neuere, gute EinfÃ¼hrung in Datenvisualisierung findet sich bei Wilke (2019). Beide BÃ¼cher sind kostenfrei online lesbar.\nWilke (2019) gibt einen hervorragenden Ãœberblick Ã¼ber praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In Ã¤hnlicher Richtung geht Fisher & Meyer (2018).\nHier ist eine Liste von BÃ¼chern zum Thema; dort kÃ¶nnen Sie bei Interesse tiefer suchen.\n\n\n\n\nAinali. (2007). Standard Deviation Diagram Micro. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17â€“21.\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155â€“159.\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight (First edition). Oâ€™Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The Dynamics of Human Development Index. The Social Science Journal, 52(3), 331â€“347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206â€“213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024). Imageflip Meme. https://imgflip.com\n\n\nInternational, T. (2017, Januar 25). Corruption Perceptions Index 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nScherer, C., Radchuk, V., Staubach, C., MÃ¼ller, S., Blaum, N., Thulke, H., & Kramerâ€Schadt, S. (2019). Seasonal Host Lifeâ€history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812â€“1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152â€“2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2016). Ggplot2: Elegant Graphics for Data Analysis (Second edition). Springer.\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures (First edition). Oâ€™Reilly Media. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/Practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg (Original work published 2019)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5â†©ï¸\nGrob gesagt: mariokart %&gt;% plot_density().â†©ï¸\nQuelle: ifes/FOM Hochschule, https://github.com/FOM-ifes/VL-Vorlesungsfolienâ†©ï¸\nQuelle: https://observablehq.com/@mcmcclur/the-normal-modelâ†©ï¸\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgrafâ†©ï¸\nQuelle: https://observablehq.com/d/bb7ad3ecfb1ac2a6â†©ï¸\nAber Freunde lassen Freunde keine Tortendiagramme verwenden: https://github.com/cxli233/FriendsDontLetFriends#10-friends-dont-let-friends-make-pie-chart.â†©ï¸\nÃœbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen: https://github.com/cxli233/FriendsDontLetFriends#1-friends-dont-let-friends-make-bar-plots-for-means-separation.â†©ï¸\nhttps://www.data-to-viz.com/caveat/pie.html; https://github.com/cxli233/FriendsDontLetFriends#10-friends-dont-let-friends-make-pie-chartâ†©ï¸\nDer Quellcode der Animation ist hier zu finden: https://gist.github.com/rafapereirabr/0d68f7ccfc3af1680c4c8353cf9ab345.â†©ï¸\nhttps://www.tylermw.com/wp-content/uploads/2019/06/featuredmeasles.mp4â†©ï¸\nhttps://rpkgs.datanovia.com/ggpubr/reference/ggviolin.htmlâ†©ï¸\nhttps://www.autodesk.com/research/publications/same-stats-different-graphsâ†©ï¸\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.mdâ†©ï¸\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md#gghistostatsâ†©ï¸\nhttps://flowingdata.com/category/visualization/ugly-visualization/â†©ï¸\nSiehe auch: https://data-se.netlify.app/2023/06/30/farbpaletten/â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1 Lernsteuerung\nAbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#lernsteuerung",
    "href": "050-zusammenfassen.html#lernsteuerung",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Lernziele\n\nSie kÃ¶nnen gÃ¤ngige Arten von LagemaÃŸe definieren.\nSie kÃ¶nnen erlÃ¤utern, inwiefern man ein LagemaÃŸ als ein Modell hernehmen kann.\nSie kÃ¶nnen LagemaÃŸe mit R berechnen.\n\n6.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n6.1.3 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer â€œklassischeâ€ Mittelwert (das arithmetisches Mittel) ist ein prototypisches Beispiel fÃ¼r ein Modell in der Statistik.\n\nÃœbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hÃ¶ren, dass der â€œtypische deutsche Mannâ€ 1,80m groÃŸ ist (vgl. Roser et al., 2013)? (Ihr Vorstellung updatet sich in DefinitionÂ 6.1.)\n\nDie HÃ¤lfte der MÃ¤nner ist grÃ¶ÃŸer als 1,80â€‰m, die andere HÃ¤lfte kleiner.\nDas arithmetische Mittel der MÃ¤nner betrÃ¤gt 1,80â€‰m.\nDie meisten MÃ¤nner sind 1,80â€‰m groÃŸ.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 6.2 Laut dem Statistischen Bundesamt (2023-003-27) betrÃ¤gt der Wert der mittleren GrÃ¶ÃŸe deutscher Frauen etwa 1,66m, also 14â€‰cm weniger als bei MÃ¤nnern.1 \\(\\square\\)\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiÃŸ nicht \\(\\square\\)\n\n\n\n\nAuf dieser Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So kÃ¶nnte man z.B. sagen, â€œmehr als 5â€‰cm sind vielâ€. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\), der Durchschnitt) betrÃ¤gt: 2. \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Zu easy!\n\n\nğŸ§‘â€ğŸ« Schon gut! Chill mal. Wird gleich interessanter.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig. ğŸ˜„\n\nEtwas abstrakter kann man BeispielÂ 6.1 in folgendem Schaubild darstellen, s. GleichungÂ 6.1.\n\\[\n\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} = 3 \\cdot \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}\n\\tag{6.1}\\]\nDer Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) fÃ¼r die â€œtypische Noteâ€ im Statistikkurs, s. GleichungÂ 6.2.\n\\[\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} \\qquad \\leftrightarrow  \\qquad \\underbrace{\\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}}_{\\text{\"typischer Vertreter\"}} \\tag{6.2}\\]\n\n\n\n\n\n\nWichtig\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er eine Datenreihe zu einen â€œtypischen Vertreterâ€ zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller MerkmalstrÃ¤ger in gleichem MaÃŸe einflieÃŸen. Er gibt uns eine (mÃ¶gliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen.\n\n\nEine nÃ¼tzliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. AbbildungÂ 6.1.\n\n\n\n\n\nAbbildungÂ 6.1: Mittelwert als ausbalancierte Wippe mit Mittelwert 3 (Maphry, 2009)\n\n\nIn â€œMathe-Sprechâ€ bezeichnet man den Mittelwert hÃ¤ufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. GleichungÂ 6.3.\n\\[\\bar {x} =\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.3}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert (MW, mean) der Variablen \\(X\\) (prÃ¤ziser: das arithmetische Mittel des Merkmal \\(X\\)) ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n\\). Den Mittelwert von \\(X\\) bezeichnet man auch mit \\(\\bar {x}\\). \\(\\square\\)\n\n\nBeispiel 6.2 Angenommen wir haben eine Reihe von Noten: 1,2,3. Der Mittelwert der Noten betrÃ¤gt dann 2: \\(\\bar{X} = \\frac{1}{3}\\sum (1+2+3) = 6/3 = 2\\). \\(\\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. AbbildungÂ 6.2 sehen wir die Noten von (dieses Mal) vier Studentis. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert.\nBezeichnen wir die Abweichung â€“ auch als â€œFehlerâ€, â€œRestâ€ oder â€œResiduumâ€ bezeichnet â€“ der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, Fehler) und die \\(i\\)-te Note mit \\(\\color{ycol}{y_i}\\), so kÃ¶nnen wir mit GleichungÂ 6.4 festhalten:\n\\[\\color{ycol}{\\text{y}_i} \\color{black}{ = } \\color{modelcol}{\\;\\bar{x}\\;} + \\color{errorcol}{\\;\\text{e}_i} \\tag{6.4}\\]\nAnders ausgedrÃ¼ckt (s. GleichungÂ 6.5):\n\\[\\color{ycol}{\\text{Daten}} \\color{black}{ = }     \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}} \\tag{6.5}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe.\nUm Modelle darzustellen, wird in der Datenanalyse hÃ¤ufig folgende Art von Modellgleichung verwendet, s. GleichungÂ 6.6.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{ x}} \\tag{6.6}\\]\nLies: â€œDer Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)â€. Der Kringel â€œ~â€ soll also hier heiÃŸen â€œâ€¦ ist eine Funktion von â€¦â€. Das â€œKringelâ€ oder die â€œWelleâ€ â€œ~â€ nennt man auch â€œTildeâ€.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklÃ¤rende Variable (synonym: AV, Output-Variable, Zielvariable) gemeint. Das â€œDachâ€ Ã¼ber dem \\(\\color{ycol}{\\text{y}}\\) bedeutet â€œvorhergesagter Y-Wertâ€ oder â€œY-Wert laut dem Modellâ€. Der tatsÃ¤chliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\), s. GleichungÂ 6.7.\n\\[\\color{ycol}{y} \\color{black}{ = } \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}} \\tag{6.7}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (â€œy-Dachâ€). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir mit GleichungÂ 6.8 schreiben kÃ¶nnen:\n\\[\\color{ycol}{y}  \\color{black}{ = } \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e} \\tag{6.8}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklÃ¤rt, auÃŸer gehen wir von einem Fehler \\(\\color{errorcol}e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In spÃ¤teren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklÃ¤ren. WÃ¼rden wir z.B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklÃ¤ren, so wÃ¼rden wir schreiben (s. GleichungÂ 6.9):\n\\[\\color{modelcol}{\\bar{y}} \\color{black}  { \\sim } \\color{xcol}{\\text{ x}} \\tag{6.9}\\]\nDa wir im Moment aber keine andere Variablen bemÃ¼hen, um \\(\\color{ycol}{\\text{y}}\\) zu erklÃ¤ren, schreibt man mit GleichungÂ 6.10 auch:\n\\[\\color{modelcol}{\\bar{y}}\\;\\;  \\color{black}{\\sim \\; 1} \\tag{6.10}\\]\nDiese Schreibweise sieht verwirrend aus. Die \\(1\\) soll aber nur zeigen, dass wir keine andere Variable zur ErklÃ¤rung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\). Der mathematische Hintergrund liegt in der Art, wie man Matrizen multipliziert.\n\nBeispiel 6.3 (Noten, Mittelwert und Abweichung) Vier Studentis â€“ Anna, Berta, Carl, Dani â€“ haben ihre Statistik-Klausur zurÃ¼ckbekommen (Schluck). Die Noten sehen Sie in AbbildungÂ 6.2; gar nicht so schlecht ausgefallen. AuÃŸerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen der einzelnen Noten vom Mittelwert eingezeichnet.\\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken (Residuen, Fehler; hÃ¤ufig mit \\(e\\) wie error bezeichnet) in AbbildungÂ 6.2 einmal genauer an.\n\n\n\n\n\n\n\nAbbildungÂ 6.2: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\nJetzt stellen Sie sich vor, Sie wÃ¼rden die vom Mittelwert nach oben ragenden BalkenlÃ¤ngen aneinanderlegen (das sind die gestrichelten. Sehen Sie das vor Ihrem geistigen Auge? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht) jetzt, dass die GesamtlÃ¤nge der â€œBalken nach obenâ€ identisch ist zur GesamtlÃ¤nge der nach â€œunten ragenden Balkenâ€, vgl. AbbildungÂ 6.1.\nPrÃ¤ziser ausgedrÃ¼ckt und ohne Ihre Phantasie zu strapazieren (GleichungÂ 6.11):\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.11}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDie Summe der Abweichungen vom Mittelwert ist Null.\n\n\n\nÃœbungsaufgabe 6.3 Was schÃ¤tzen Sie, wie hoch das mittlere VermÃ¶gen (arithmetisches Mittel) der Haushalte in Deutschland in etwa ist (im Jahr 2021 auf Basis einer Umfrage) (Bundesbank, 2023)?2 \\(\\square\\)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.000 Euro\n\n\n\nBeispiel 6.4 (Der wertvollste FuÃŸballer der Welt in Ihrem HÃ¶rsaal) Kommt der wertvollste FuÃŸballspieler der Welt in Ihren HÃ¶rsaal, sagen wir, es ist Kylian MbappÃ©3. Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro4.\n\nğŸ¦¹ Hey Leute, wie gehtâ€™s denn so! Wie viel Kohle verdient ihr eigentlich so?\n\n\nğŸ§‘â€ğŸ“ Ã„h, wir studieren und verdienen fast nix!\n\nDie 100 Studis im HÃ¶rsaal schauen verdattert aus der WÃ¤sche: Was ist das fÃ¼r eine komische Frage!? Aber zumindest verteilt der FuÃŸballspieler Autogramme.\n\n\nÃœbungsaufgabe 6.4 (Mittleres Einkommen im HÃ¶rsaal, mit Kylian MbappÃ©) SchÃ¤tzen Sie â€“ im Kopf â€“ das mittlere VermÃ¶gen im HÃ¶rsaal, gehen Sie davon aus, dass alle der 100 Studentis jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (prÃ¤ziser: das arithmetische Mittel des Einkommens) wie folgt berechnen, s. ListingÂ 6.1. (Die Details der Syntax, z.B. der Befehl rep(), sind von geringer Bedeutung.)\n\n\nListingÂ 6.1: Wir simulieren Einkommen von 100 Studis plus MbappÃ©.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100 Mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 MbappÃ© mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nuller hinter der fÃ¼hrenden Eins: 1000000. In Taschenrechner- oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als â€œ1 Mal 10 hoch 6, also mit 6 im Exponentenâ€.\n\n\nDer Mittelwert im HÃ¶rsaal betrÃ¤gt also 1,189,109 Euro, etwas mehr als eine Million. Ist das ein gutes Modell fÃ¼r das â€œtypischeâ€ VermÃ¶gen im HÃ¶rsaal?\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. AbbildungÂ 6.3, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell verwendet eine Gerade als Modell der Daten. Es erklÃ¤rt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildungÂ 6.3: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\nAbbildungÂ 6.3 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit (farbig markierten) Extremwerte (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (AusreiÃŸer; outlier) ist eine Beobachtung, deren Wert deutlich vom GroÃŸteil der anderen Beobachtungen im Datensatz abweicht, z.B. viel grÃ¶ÃŸer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R mit dem Befehl lm.\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear modell\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl gibt als Koeffizient einen Wert zurÃ¼ck und zwar den Mittelwert von einkommen, vgl. auch ListingÂ 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet, das wird verstÃ¤ndlich, wenn man z.B. in AbbildungÂ 6.3 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet. Die Syntax des Befehls lm() sieht etwas merkwÃ¼rdig aus. Ignorieren Sie das fÃ¼rs Erste, wir besprechen das spÃ¤ter (Kapitel 9) ausfÃ¼hrlich. lm steht Ã¼brigens fÃ¼r â€œlineares Modellâ€.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.3 Median als Modell",
    "text": "6.3 Median als Modell\n\nğŸ§‘â€ğŸ“ Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert fÃ¼r die Menschen im HÃ¶rsaal. Weder fÃ¼r den MbappÃ©, noch fÃ¼r uns Studis!\n\n\nğŸ§‘â€ğŸ« Ja, da habt ihr Recht.\n\n\nâš½ Die Welt ist schon ungerecht!\n\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. AbbildungÂ 6.4) ist der Mittelwert (sehr) wenig aussagekrÃ¤ftig, da er nicht mehr â€œtypischeâ€ Werte fÃ¼r die MerkmalstrÃ¤ger beschreibt.\n\n\nAbbildungÂ 6.4 stellt die Verteilung des Einkommens einer mit â€œnormalâ€ skalierter Achse und einmal mit logarithmischer X-Achse. Zur Erinnerung: 4.0+e07 bedeutet \\(4 \\cdot 10^{07} = 40000000\\), eine 4 gefolgt von 7 Nullern. Die logarithmische X-Achse stellt den Unterschied von Mittelwert (MW) und Median deutlicher heraus als die normale (additive) Achse.\n\n\n\n\n\n\n\n\n\n(a) X-Achse in additiver Form\n\n\n\n\n\n\n\n\n\n\n\n(b) X-Achse in multiplikativer Form (logarithmische Darstellung)\n\n\n\n\n\n\nAbbildungÂ 6.4: Die Einkommensverteilung im HÃ¶rsaal\n\n\nDer Mittelwert ist HÃ¶rsaal ist nicht typisch fÃ¼r die Menschen im HÃ¶rsaal: Weder fÃ¼r MbappÃ©, noch fÃ¼r die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Mittelwert ist empfÃ¤nglich fÃ¼r Extremwerte: Gibt es einen Extremwert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wieder und weniger die Mehrheit der gemÃ¤ÃŸigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenÃ¼ber Extremwerten).\n\n\n\nBeispiel 6.5 (Das Median-Einkommen einiger Studentinnen) FÃ¼nf Studentinnen tauschen sich Ã¼ber ihr Einkommen aus, s. AbbildungÂ 6.5, links. Es handelt sich um eine schiefe Verteilung.\n\n\n\n\n\n\n\n\n\n(a) Einkommen auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n\n(b) Einkommen auf der X-Achse\n\n\n\n\n\n\nAbbildungÂ 6.5: Das Median-Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\nWir kÃ¶nnten jetzt behaupten, dass Carla das typische Einkommen (fÃ¼r diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\nDefinition 6.4 (Median) MerkmalsausprÃ¤gung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.5 (Alle mal aufstehen) Auf GeheiÃŸ der Lehrkraft stehen jetzt alle Studis bitte auf und sortieren sich der GrÃ¶ÃŸe nach im Raum, schÃ¶n in einer Reihe aufgestellt. Die KÃ¶rpergrÃ¶ÃŸe der Person in der Mitte der Reihe, zu der also gleich viele Personen zu links wie zu rechts stehen, das ist der Medien dieser Datenreihe, vgl. AbbildungÂ 6.6. \\(\\square\\)\n\nDer Median ist robust (gegenÃ¼ber) Extremwerten: FÃ¼gt man Extremwerte zu einer Verteilung hinzu, Ã¤ndert sich der Median zumeist (deutlich) weniger als der Mittelwert.\nAbbildungÂ 6.6 stellt den Median schematisch dar.\n\n\n\n\n\n\n1,60m\n\n\n\n\n\n1,72m\n\n\n\n\n\n1,79m: Median!\n\n\n\n\n\n1,94\n\n\n\n\n\n2,12m\n\n\n\n\n\nAbbildungÂ 6.6: Der Median als der Wert des â€œmittlerenâ€ Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert als der Median wie Objekte mit grÃ¶ÃŸerem Wert als der Median.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.6 Bei der Messreihe 1, 2, 3, 4, 5, 6, 8, 9 betrÃ¤gt der Median 4.5.\\(\\square\\)\n\n\nÃœbungsaufgabe 6.6 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhÃ¶ht sich um das Hundertfache. Wie verÃ¤ndert sich der Median?5 \\(\\square\\)\n\n\nÃœbungsaufgabe 6.7 (Wer ist mehr â€œmittelâ€? Median oder Mittelwert?) Â \n\nğŸ§‘â€ğŸ“ Das arithmetische Mittel sollte Mittelwert heiÃŸen, weil es die Mitte von zwei Messwerten widerspiegelt, also z.B. von 1 und 10 ist die Mitte 5,5 â€“ also genau beim Mittelwert!\n\n\nğŸ‘© Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der GrÃ¶ÃŸe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion!\\(\\square\\)\n\n\nBeispiel 6.7 (Ein â€œmittlererâ€ Preis fÃ¼r Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median fÃ¼r das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist hÃ¶her als der Median.\n\nmariokart &lt;- read.csv(mariokart_path)  # Der Pfad steht zu Beginn des Kapitels\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n  \n\n\n\nWie man sieht, ist der Mittelwert grÃ¶ÃŸer als der Median, s. AbbildungÂ 6.7.\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Das Start-Gebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert grÃ¶ÃŸer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell fÃ¼r den â€œtypischen Wertâ€ vorzuziehen.\n\n\n\nÃœbungsaufgabe 6.8 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die fÃ¼r einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis mÃ¶glicherweise Ã¼ber die GebÃ¼hr. \\(\\square\\)\nAufgabe Entfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\nLÃ¶sung\n\nmariokart_no_extreme &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# ohne Extremwerte:\nmariokart_no_extreme |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n\n\nÃœbungsaufgabe 6.9 Was schÃ¤tzen Sie, wie hoch das mediane VermÃ¶gen des Haushalte in Deutschland im Jahr 2021 in etwa war (Bundesbank, 2023)?6\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.00 Euro\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere HÃ¤lfte. Er markiert sozusagen eine â€œ50-Prozent-Markeâ€ (der aufsteigend sortierten Beobachtungen). Betrachten wir einmal nur alle Spiele, die fÃ¼r weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. AbbildungÂ 6.8. 50% aller Spiele wurden fÃ¼r weniger als ca. 46 Euro verkauft; 50% aller Spiele fÃ¼r mehr als 46 Euro. Der Median betrÃ¤gt als 46 Euro.\nJetzt kÃ¶nnten wir nur die gÃ¼nstigere HÃ¤lfte betrachten und wieder nach dem Median fragen (d.h. total_pr &lt; 46). Dieser â€œMedian der gÃ¼nstigeren HÃ¤lfteâ€ grenzt damit das insgesamt gÃ¼nstigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25%). Den Median nennt man das zweite Quartil (Q2, 50%). Entsprechend heiÃŸt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75%).\\(\\square\\)\n\n\nBeispiel 6.8 (Quartile des Verkaufsgebot) AbbildungÂ 6.8 zeigt die Quartile fÃ¼r das Verkaufsgebot.\\(\\square\\)\n\nJetzt kÃ¶nnte man sagen, hey, warum nur in 25%-StÃ¼cke die Verteilung aufteilen? Warum nicht in 10%-Schritten?\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleiche Teile unterteilen, nennt man Dezile. \\(\\square\\)\n\nOder vielleicht in 1%-Schritten oder in sonstigen Schnitten? Wo die Quartile in 25%-Schritten aufteilen, teilt in Quantil in \\(p\\)-Prozent-Schritten auf. S. AbbildungÂ 6.9 dazu.\n\nDefinition 6.7 (Quantile) Ein p-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht Ã¼berschritten wird.\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Quantil ist ein Oberbegriff fÃ¼r Quartile, Dezile, etc. \\(\\square\\)\n\n\nAbbildungÂ 6.8 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil fÃ¼r den Datensatz mariokart2.\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 3: Q1, Q2 und Q3 fÃ¼r das Schlussgebot (nur Spiele fÃ¼r weniger als 100 Euro)\n\n\n\n\nAbbildungÂ 6.8\n\n\nVerschiedene Arten von Quantilen.\n::::\nQuantile kann man in R mit dem Befehl quantile() berechnen:\n\nmario_quantile &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(q25 = quantile(total_pr, .25),\n            q50 = quantile(total_pr, .50),\n            q75 = quantile(total_pr, .75))\n\nAbbildungÂ 6.9 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildungÂ 6.9: Verschiedenen Quantile animiert\n\n\nAbbildungÂ 6.10 visualisiert verschiedene Quantile. Man beachte, dass alle Regionen gleichgroÃŸe FlÃ¤chen (d.h. Wahrscheinlichkeitsmassen) aufweisen.\n\n\n\n\n\n\n\n\n\n(a) 25%-Schritte: Quartile\n\n\n\n\n\n\n\n\n\n(b) 10%-Schritte: Dezile\n\n\n\n\n\n\n\n\n\n(c) 1%-Schritte: Perzentile\n\n\n\n\n\n\nAbbildungÂ 6.10: Verschiedene Quantile visualisiert. In jedem Diagramm sind die Regionen gleich groÃŸ, beinhalten also (ungefÃ¤hr) die gleiche Anzahl von Beobachtungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.5 LagemaÃŸe",
    "text": "6.5 LagemaÃŸe\n\nğŸ§‘â€ğŸ“ Was ist der Oberbegriff fÃ¼r Median, Mittelwert und so weiter?\n\n\nğŸ§‘â€ğŸ« Gute Frage! Wie wÃ¼rden Sie ihn nennen?\n\n\nDefinition 6.8 (LagemaÃŸ) Ein LagemaÃŸ (synonym: MaÃŸ der zentralen Tendenz) fÃ¼r eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, erwartbar, reprÃ¤sentativ oder â€œmittelâ€ ansehen sollten.\\(\\square\\)\n\n\nBeispiel 6.9 GebrÃ¤uchliche LagemaÃŸe sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuantile wie z.B. Quartile\nMinimum (kleinster Wert)\nMaximum (grÃ¶ÃŸter Wert)\nModus (hÃ¤ufigster Wert) \\(\\square\\)\n\n\n\nBerechnen wir LagemaÃŸe fÃ¼r den Mariokart-Datensatz, s. ListingÂ 6.2. Es ist Ã¼brigens egal, wie sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname â€“ alles okay!\n\n\nListingÂ 6.2: Syntax zur Berechnung von LagemaÃŸen\n\n\nmariokart_lagemaÃŸe_total_pr &lt;-\n  mariokart %&gt;% \n  summarise(mw = mean(total_pr),\n            md = median(total_pr),\n            q1 = quantile(total_pr, .25),\n            q2 = quantile(total_pr, .5),\n            q3 = quantile(total_pr, .75),\n            min = min(total_pr),\n            max = max(total_pr))\nmariokart_lagemaÃŸe_total_pr\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.1 Gruppierte LagemaÃŸe\nHÃ¤ufig mÃ¶chte man Statistiken wie LagemaÃŸe fÃ¼r mehrere Teilgruppen â€“ z.B. Mittlere KÃ¶rpergrÃ¶ÃŸe von Frauen vs.Â Mittlere KÃ¶rpergrÃ¶ÃŸe von MÃ¤nner â€“ berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage kÃ¶nnte lauten:\n\nUnterscheidet sich die mittlere KÃ¶rpergrÃ¶ÃŸe von Frauen und MÃ¤nnern?\n\nOder vielleicht:\n\nHat das Geschlecht einen Einfluss auf die KÃ¶rpergrÃ¶ÃŸe?\n\nAnders ausgedrÃ¼ckt:\n\nKÃ¶rpergrÃ¶ÃŸe \\(\\color{ycol}{\\text{y}}\\) ist eine Funktion des Geschlechts \\(\\color{xcol}{G}\\).\n\nDie Modellformel kÃ¶nnte also lauten:\n\\[\\color{ycol}{y} \\; \\color{black}{ \\sim } \\; \\color{xcol}{G}\\]\nGruppierte LagemaÃŸe lassen sich in R z.B. so berechnen, s. ListingÂ 6.3, also Ã¤hnlich wie in ListingÂ 6.2.\n\n\nListingÂ 6.3: Gruppierte LagemaÃŸe\n\n\nmariokart_lagemaÃŸe_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\nmariokart_lagemaÃŸe_gruppiert\n\n\n  \n\n\n\n\n\n\nAbbildungÂ 6.11 zeigt ein Beispiel fÃ¼r ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. AbbildungÂ 6.3. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, â€œglobalenâ€ Mittelwert): Innerhalb der Gruppe ohne LenkrÃ¤der und innerhalb der Gruppe mit 2 LenkrÃ¤dern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering â€“ im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\n\n\n\n\n\n\n\n\n(a) Mittelwert fÃ¼r Verkaufspreis (ungruppiert)\n\n\n\n\n\n\n\n\n\n(b) Mittelwert fÃ¼r Verkaufspreis gruppiert nach Anzahl der LenkrÃ¤der\n\n\n\n\n\n\nAbbildungÂ 6.11: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches fÃ¼r alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heiÃŸt ein Punktmodell. Anders gesagt fasst ein Punktmodell eine Wertereihe (hÃ¤ufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem â€œPunktâ€ in diesem Sinne, s. GleichungÂ 6.12.\\(\\square\\)\n\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{6.12}\\]\nMittelwert, Median und Quartile sind Beispiele fÃ¼r Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein â€œBildâ€ der Daten, machen Sie uns verstÃ¤ndlich - sie sind uns ein Modell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lÃ¼gt",
    "text": "6.6 Wie man mit Statistik lÃ¼gt\nMit Statistik kann man vortrefflich lÃ¼gen, heiÃŸt es. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lÃ¤sst: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzufÃ¼hren. Viele Wege fÃ¼hren nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und UnschÃ¤rfen ohne bÃ¶se Abwehr aufzudecken, gibt es ein probates Gegenmittel: Transparenz.\n\nStellen Sie hohe Anforderung an die Transparenz einer statistischen Analyse. Nur durch NachprÃ¼fbarkeit kÃ¶nnen Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation Ã¼berzeugen.\n\nHier ist eine (nicht abschlieÃŸende!) Checkliste, was Sie nachprÃ¼fen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\nWurden ausreichend Daten gesammelt (z.B. mind. 20 Beobachtungen pro Gruppe)?\nWurden alle untersuchten Variablen berichtet?\nWurden alle durchgefÃ¼hrten Interventionen berichtet?\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) BegrÃ¼ndung?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.10 (Survival-Tipp) Eine Studentin aus dem dem Bachelorstudiengang â€œAngewandte Medien- und Wirtschaftspsychologieâ€ mit Schwerpunkt Data Science berichtet ihre â€œSurvival-Tippsâ€ fÃ¼r Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich wÃ¤hrend des Semesters neue Begriffe und ihre ErklÃ¤rung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in hÃ¶heren Semestern nach Tipps fragen.\\(\\square\\)\n\n\n\n\nğŸ§‘â€ğŸ“ Irgendwie kann ich mir R-Code so schlecht merken.\n\n\nğŸ§‘â€ğŸ« Frag doch mal ChatGPT, oder einen anderen Chatbot, da bekommt man auch R-Code ausgegegeben.\n\n\nÃœbungsaufgabe 6.10 (Ãœbungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Ãœbungsaufgaben.\nSie kÃ¶nnen sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\nğŸ§‘â€ğŸ“ Ich bin ein Student in einem Bachelor-Studiengang fÃ¼r Psychologie. Gerade bereite ich mich auf die Klausur im Fach â€œGrundlagen der Statistikâ€ vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die PrÃ¼fung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: MaÃŸe der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.B. Nominalskala vs.Â Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben.\n\n\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der folgenden Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber spÃ¤ter kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekannte Stoff.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\n\n\n\n\n\n\nTipp\n\n\n\nSchauen Sie sich auch mal auf datenwerk.netlify.app die Aufgaben zu z.B. dem Tag EDA an. \\(\\square\\)\n\n\n\nÃœbungsaufgabe 6.11 Mittlerweile verfÃ¼gen Sie die wesentlichen Werkzeuge des Datenjudo. Hier finden Sie einen Ãœberblick an DatensÃ¤tze, die Sie nach Herzenslust analysieren kÃ¶nnen.7 \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele LehrbÃ¼cher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehÃ¶ren zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel fÃ¼r LehrbÃ¼cher sind Mittag & SchÃ¼ller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Ein Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurÃ¼ckschreckt, ist mit Cetinkaya-Rundel & Hardin (2021) oder Poldrack (2022) gut beraten. Beide BÃ¼cher sind online verfÃ¼gbar. Tipp: Mit dem Browser einfach auf Deutsch Ã¼bersetzen.\n\n\n\n\nBortz, J., & Schuster, C. (2010). Statistik FÃ¼r Human- Und Sozialwissenschaftler. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBundesamt, S. (2023-003-272023-003-27). KÃ¶rpermaÃŸe nach Altersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household Wealth and Finances in Germany: Results of the 2021 Household Wealth Survey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMaphry. (2009). Seesaw with Mean. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und SpaÃŸ im Horrorfach nichttechnischer StudiengÃ¤nge. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height. Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359â€“1366. https://doi.org/10.1177/0956797611417632\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., Aert, R. C. M. van, & Assen, M. A. L. M. van. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Average_human_height_by_countryâ†©ï¸\n316500â‚¬â†©ï¸\nQuelle: https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop, Abruf 2023-03-19â†©ï¸\nQuelle: https://www.einkommenmagazin.de/kylian-mbappe-einkommen/, Abruf 2023-03-19â†©ï¸\nEr bleibt gleich, verÃ¤ndert sich also nicht: Der Median ist robust, er verÃ¤ndert sich nicht oder kaum, wenn Extremwerte vorliegen.â†©ï¸\nca. 83600â‚¬â†©ï¸\nhttps://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1 Lernsteuerung\nAbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#lernsteuerung",
    "href": "060-modellguete.html#lernsteuerung",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1.1 Lernziele\n\nSie kennen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe und kÃ¶nnen diese definieren und mit Beispielen erlÃ¤utern.\nSie kÃ¶nnen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe mit R berechnen.\nSie kÃ¶nnen die Bedeutung von Streuung fÃ¼r die GÃ¼te eines Modells erlÃ¤utern.\n\n7.1.2 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)\n\n\n7.1.3 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n7.1.4 Zum Einstieg\n\nÃœbungsaufgabe 7.1 (Freiwillige vor!) FÃ¼r diese kleine Live-Demonstration brauchen wir einige Freiwillige. Die Lehrkraft teilt die Freiwilligen in zwei Gruppen, Gruppe Gleich-GroÃŸ und Gruppe Verschieden-GroÃŸ. Erkennen Sie, dass die Unterschiedlichkeit der GrÃ¶ÃŸe in Gruppe Gleich-GroÃŸ gering ist, aber in Gruppe Verschieden-GroÃŸ hoch? \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "href": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.2 Warum Sie die Streuung Ihrer Daten kennen sollten",
    "text": "7.2 Warum Sie die Streuung Ihrer Daten kennen sollten\n\n7.2.1 Die Schlankheitspille von Prof.Â Weiss-Ois\nProf.Â Weiss-Ois hat eine Erfindung gemacht, eine SchlankheitspilleğŸ’Š (flaticon, 2024).\n\n\n\n\n\n\nWas er sagt: â€œIch habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!â€\n\n\n\nÂ \n\n\n\n\nWas er NICHT sagt: â€œAllerdings streuten die Werte der GewichtsverÃ¤nderung um 10kg um den Mittelwert herum.â€\n\n\n\n\n\nAbbildungÂ 7.1\n\n\n\nWÃ¼rden Sie die Pille von Prof.Â I. Ch. Weiss-Ois nehmen?\n\nja, ich zahle 1000 Euro!\nja\nnein\nNur wenn ich 100 Euro bekomme\nOkay, fÃ¼r 1000 Euro\\(\\square\\)\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information.\\(\\square\\)\n\n\n\n7.2.2 Wie man seine Kuh Ã¼ber den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss Ã¼berqueren, nur kann die Kuh nicht schwimmen (ob es Fritz kann, ist nicht Ã¼berliefert).\n\nğŸ‘¨â€ğŸŒ¾ (Fritz): Sag mal, Karla, ist der Fluss tief?\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): NÃ¶, im Schnitt nur einen Meter.\n\nAlso fÃ¼hrt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, im FloÃŸ ersoffen, s. AbbildungÂ 7.2.\n\n\n\n\n\nAbbildungÂ 7.2: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): Ãœbrigens, LagemaÃŸe sagen nicht alles, Fritz.\n\n\nğŸ‘¨â€ğŸŒ¾ (Fritz): LÃ¤uft die Kuh durch den Fluss, kann sie schwimmen oder â€™s ist Schluss.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Streuung ihrer Daten zu kennen ist eine wesentliche Information. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.3 Woran erkennt man ein gutes Modell?",
    "text": "7.3 Woran erkennt man ein gutes Modell?\nAbbildungÂ 7.3 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs.Â ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen. Die vertikalen grauen Balken in AbbildungÂ 7.3 kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale orange Linie). Je lÃ¤nger die vertikalen â€˜Abstandsbalkenâ€™ insgesamt, desto grÃ¶ÃŸer die Streuung.â€\n\n\n\n\n\n\n\nAbbildungÂ 7.3: Wenig (links) vs.Â viel Streuung (rechts).\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsÃ¤chlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groÃŸ.\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof.Â Weiss-Ois) In AbbildungÂ 7.3 sind die Daten zu der GewichtsverÃ¤nderung nach Einnahme von â€œSchlankheitspillenâ€ zweier verschiedener PrÃ¤parate. Wie man sieht unterscheidet sich die typische (vorhergesagte) GewichtsverÃ¤nderung zwischen den beiden PrÃ¤paraten kaum. Die Streuung allerdings schon. Links sieht man die GewichtsverÃ¤nderungen nach Einnahme des PrÃ¤parats â€œDickableibtin extra mildâ€ (c) und rechts das PrÃ¤parat von Prof.Â Weiss-Ois â€œPfundafliptan Forteâ€. Welches PrÃ¤parat wÃ¼rden Sie lieber einnehmen?\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nWir wollen ein prÃ¤zises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklÃ¤ren, also wenig vom tatsÃ¤chlichen Wert abweichen. Jedes Modell sollte Informationen Ã¼ber die PrÃ¤zision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der ModellgÃ¼te, d.h. der PrÃ¤zision der SchÃ¤tzung des Modellwerts, ist wenig nÃ¼tze.\\(\\square\\)\n\n\n\nğŸ§‘â€ğŸ“ Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\nğŸ§‘â€ğŸ« Die Frage ist, was wir mit â€œverbessernâ€ meinen?\n\n\nğŸ§‘â€ğŸ“ Naja, kÃ¼rzere Fehlerbalken, ist doch klar!\n\nIm Beispiel von Marikoart: Da die Anzahl der LenkrÃ¤der mit dem Verkaufsgebot zusammenhÃ¤ngt, kÃ¶nnte es vielleicht sein, dass wir die LenkrÃ¤der-Anzahl da irgendwie nutzen kÃ¶nnten. Das sollten wir ausprobieren. AbbildungÂ 7.4 zeigt, dass die Fehlerbalken kÃ¼rzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 LenkrÃ¤dern vs.Â mit 0 LenkrÃ¤dern) sind die Fehlerbalken jeweils im Durchschnitt kÃ¼rzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm). Aus GrÃ¼nden der Ãœbersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berÃ¼cksichtigt und nur Spiele mit 0 oder mit 2 LenkrÃ¤dern.\n\n\n\n\n\n\n\n\n\n(a) Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt. y ~ 1\n\n\n\n\n\n\n\n\n\n(b) Fehlerbalken im komplexen Modell: Zwei Mittelwerte; weniger Streuung in jeder Gruppe. Das erkennt man daran, dass die vertikalen, grauen Abstandsbalken im Schnitt kÃ¼rzer sind als im einfachen Modell (links). y ~ G\n\n\n\n\n\n\nAbbildungÂ 7.4: Fehlerbalken in einem einfachen und komplexeren Modell\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.4 StreuungsmaÃŸe",
    "text": "7.4 StreuungsmaÃŸe\n\nDefinition 7.1 (StreuungsmaÃŸe) Ein StreuungsmaÃŸ quantifiziert die VariabilitÃ¤t (Unterschiedlichkeit, Streuung) eines Merkmals. \\(\\square\\)\n\n\nDefinition 7.2 Ein einfaches StreuungsmaÃŸ ist der Range \\(R\\), definiert als Abstand von grÃ¶ÃŸtem und kleinsten Wert eines Merkmals \\(X: R = X_{max} - X_{min}. \\square\\)\n\n\nBeispiel 7.2 Angenommen, wir haben einen Datensatz zum Merkmal â€œAlterâ€ mit den Werte 1, 23, 42, 100. Dann betrÃ¤gt der Range: \\(R = 100 - 1 = 99\\). Das bedeutet, dass die Werte des Merkmals Ã¼ber 99 Einheiten (Jahre in diesem Fall) verteilt sind. \\(\\square\\)\n\nDieses Mermals ist aber nicht robust (gegenÃ¼ber Extremwerten) und sollte daher nur mit EinschrÃ¤nkung verwendet werden.\n\n7.4.1 Der mittlere Abweichungsbalken\n\nğŸ§‘â€ğŸ“ Wir mÃ¼ssen jetzt mal prÃ¤ziser werden! Wie kÃ¶nnen wir die Streuung berechnen?\n\n\nğŸ§‘â€ğŸ« Gute Frage! Am einfachsten ist es, wenn wir die mittlere LÃ¤nge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir wir den â€œmittleren Abweichungsbalkenâ€, den wir mit \\(\\bar{e}\\) bezeichnen kÃ¶nnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als Mittlere Absolutabweichung (MAA). Er ist so definiert, s. GleichungÂ 7.1.\n\\[{\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}=\\bar{e}.} \\tag{7.1}\\]\n\nDefinition 7.3 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte. (Wenn man solche SÃ¤tze liest, fÃ¼hlt sich die Formel fast einfacher an.)\\(\\square\\)\n\n\nBeispiel 7.3 AbbildungÂ 7.5 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE fÃ¼r das Beispiel von AbbildungÂ 7.5 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5 \\quad \\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.5: Abweichungsbalken und der MAE\n\n\n\n\nNatÃ¼rlich kÃ¶nnen wir R auch die Rechenarbeit Ã¼berlassen.\n\nğŸ¤– Loving it!!\n\nSchauen Sie: Den Mittelwert (s. AbbildungÂ 7.5) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? SchlieÃŸlich erklÃ¤ren wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse ist).\nIn R gibt es einen Befehl fÃ¼r ein lineares Modell, er heiÃŸt lm.\nDie Syntax von lm() lautet:\nlm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur ErklÃ¤rung von Y. Aber verwende keine andere Variable zur ErklÃ¤rung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm1 &lt;- lm(y ~ 1, data = d)\n\nDen MAE kÃ¶nnen wir uns jetzt so ausgeben lassen:\n\nmae(lm1)\n## [1] 1.5\n\n\n7.4.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein StreuungsmaÃŸ, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.\n\nDefinition 7.4 (Interquartilsabstand) Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil: \\(IQR = Q_3-Q_1. \\; \\square\\)\n\n\nBeispiel 7.4 (IQR im HÃ¶rsaal) In einem Statistikkurs betragen die Quartile der KÃ¶rpergrÃ¶ÃŸe: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR betrÃ¤gt dann: \\(IQR = Q_3-Q_1 = 1.75m - 1.65m = 0.10m\\), d.h. 10 cm.\\(\\square\\)\n\nAbbildungÂ 7.6 stellt den IQR (und einige Quantile) fÃ¼r den Verkaufspreise von Mariokart-Spielen dar.\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 7.6: IQR, Q1, Q2 und Q3 fÃ¼r das Schlussgebot (nur Spiele fÃ¼r weniger als 100 Euro)\n\n\n\n7.4.3 StreuungsmaÃŸe fÃ¼r Normalverteilungen\nNormalverteilungen sind recht hÃ¤ufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu Ã¼berlegen, wie man diese Verteilungen gut zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett Ã¼ber ihren Mittelwert sowie ihre Standardabweichung beschreiben lÃ¤sst (Lyon, 2014). AuÃŸerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), â€œverschiebt man den Bergâ€ ja nur zur Seite, ohne seine Form zu verÃ¤ndern, s. AbbildungÂ 7.11.\n\n\n\n\n\n\nHinweis\n\n\n\nHat man normalverteilte Variablen/Abweichungen/Residuen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma, s\\)) eine komfortable MaÃŸeinheit der Streuung, denn damit lÃ¤sst sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\\(\\square\\)\n\n\n\nğŸ§‘â€ğŸ“ Aber wie berechnet man jetzt diese Standardabweichung?\n\n\nğŸ§‘â€ğŸ« Moment, noch ein kurzer Exkurs zur Varianz â€¦\n\n\nğŸ§‘â€ğŸ“ (seufzt)\n\n\n7.4.4 Varianz\n\n7.4.4.1 Intuition\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.9 illustriert die Varianz:\n\nMan gehe von der HÃ¤ufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan bilde Quadrate fÃ¼r jeden Datenpunkt mit der KantenlÃ¤nge, die dem Abstand des Punktes zum Mittelwert entspricht.\nDie Quadrate quetscht man jetzt wo nÃ¶tig in rechteckige Formen (ohne dass sich die FlÃ¤che Ã¤ndern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit SeitenlÃ¤nge \\(n\\) und \\(\\sigma^2\\) anordnen.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.7: Illustration zur Varianz als â€œmittlerer Quadratfehlerâ€ (Cmglee, 2015)\n\n\n\n\n\nAbbildungÂ 7.8 visualisiert die Varianz fÃ¼r BeispielÂ 7.3.1\nLinks sind die Abweichungsquadrate dargestellt, rechts die Varianz als â€œtypisches Abweichungsquadratâ€.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz ist also ein MaÃŸ, das die typische Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als â€˜typischerâ€™ Fehlerbalken\n\n\n\n\n\n\nAbbildungÂ 7.8: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\n\nBeispiel 7.5 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. NatÃ¼rlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.\nDazu berechnen Sie die Streuung in den Verkaufspreisen, s. ListingÂ 7.1. \\(\\square\\)\n\n\n\nListingÂ 7.1: Berechnung der Streuung des Verkaufpreises als Indikatoren fÃ¼r die ModellgÃ¼te des Mittelwerts.\n\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  mariokart_no_extreme %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47.43\n12.99\n7.20\n83.06\n9.11\n\n\n\n\nStatistiken sind ja schÃ¶n â€¦ aber Bilder sind auch gut, s. AbbildungÂ 7.9. Datendiagramme eignen sich gut, um (grob) die Streuung einer Variable zu erfassen.\n\nmariokart %&gt;% \n  mariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_density()\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm mit MWÂ±SD in roter Farbe\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm mit MWÂ±SD in roter Farbe\n\n\n\n\n\n\nAbbildungÂ 7.9: Die Verteilung des Verkaufspreises von Mariokart-Spielen\n\n\nWer sich die Berechnung von Hand fÃ¼r pr_maa sparen mÃ¶chte (s. ListingÂ 7.1), kann die Funktion MeanAD aus dem Paket DescTools nutzen.\n\n7.4.4.2 Kochrezept fÃ¼r die Varianz\nUm die Standardabweichung zu berechnen, berechnet man zunÃ¤chst die Varianz, \\(s^2\\) abgekÃ¼rzt. Hier ist ein â€œKochrezeptâ€ (Algorithmus) zur Berechnung der Varianz:\n\nFÃ¼r alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\)\n\nQuadriere diese Werte\nSummiere dann auf\nTeile durch die Anzahl \\(N\\) der Werte\n\nAls Formel ausgedrÃ¼ckt, lautet die Definition der Varianz einer Stichprobe wie folgt, s. GleichungÂ 7.2 (hier geht es um die sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehÃ¶rigen Population zu schÃ¤tzen, teilt man nicht durch \\(N\\), sondern durch \\(N-1\\)) .\n\\[{\\displaystyle s^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}e_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.5 (Varianz) Die Varianz (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen, \\(e_i^2\\), (vom Mittelwert).\\(\\square\\)\n\nDie Varianz steht im engen VerhÃ¤ltnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. GleichungÂ 7.3.\n\\[{\\displaystyle MSE={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(y_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.\n\n7.4.5 Die Standardabweichung\nKennt man die Varianz, so lÃ¤sst sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.\n\nDefinition 7.6 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. GleichungÂ 7.4.\n\\[s := \\sqrt{s^2} \\square \\tag{7.4}\\]\n\nDurch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche GrÃ¶ÃŸenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groÃŸ werden kann).\nAus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(RMSE := \\sqrt{MSE}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.\\(\\square\\)\n\n\n\nBeispiel 7.6 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution, s. TabelleÂ 7.1.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n\n\nTabelleÂ 7.1: Ausgabe der Funktion describe_distribution (Auszug)\n\n\n\n  \n\n\n\n\n\n\n\nğŸ§‘â€ğŸ“ Ah! Das war einfach. Reicht auch mal fÃ¼r heute.\\(\\square\\)\n\n\n\nBeispiel 7.7 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. Bevor Sie nach Hause gehen, mÃ¶chten Sie noch eine Sache anschauen. In einer frÃ¼heren Analyse (s. AbbildungÂ 7.4) fanden Sie heraus, dass die Fehlerbalken kÃ¼rzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natÃ¼rlich prÃ¼fen. Sie Ã¼berlegen: â€œOkay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.â€\nDas spezifizieren Sie so:\n\nlm1 &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm1)\n## [1] 10\n\nIm nÃ¤chsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufpreis eine Funktion der Anzahl der LenkrÃ¤der ist (Ã¤hnlich wie in AbbildungÂ 7.4):\n\nlm2 &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm2)\n## [1] 7.4\n\nAh! Sehr schÃ¶n, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach Hause!\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.5 Streuung als Modellfehler",
    "text": "7.5 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der ModellgÃ¼te auffassen.\nDefinieren wir zunÃ¤chst als Punktmodell auf Errisch:\n\nlm_mario1 &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne PrÃ¤diktoren, sondern als Punktmodell, und zwar schÃ¤tzen wir den Mittelwert mit den Daten mariokoart.\nDas (Meta-)Paket easystats bietet komfortable Befehle, um die ModellgÃ¼te zu berechnen:\n\nmae(lm_mario1)  # Mean absolute error\n## [1] 10\nmse(lm_mario1)  # Mean squared error\n## [1] 655\nrmse(lm_mario1)  # Root mean squared error\n## [1] 26",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#z-transformation",
    "href": "060-modellguete.html#z-transformation",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.6 z-Transformation",
    "text": "7.6 z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. mariokart_no_extreme.\n\nmariokart_no_extreme &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nAbbildungÂ 7.10 (links) zeigt, dass es einige Streuung um den Mittelwert herum gibt. AbbildungÂ 7.10 (rechts) zeigt die (um den Mittelwert) zentrierten Daten.\n\n\n\n\n\n\n\n\n\n(a) Wie nah drÃ¤ngen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert: zentrierte Daten\n\n\n\n\n\n\nAbbildungÂ 7.10: Verteilung von mariokart_no_extreme\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell fÃ¼r die Daten, bzw. desto hÃ¶her die ModellgÃ¼te.\\(\\square\\)\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie Ã¼berlegen â€¦ und Ã¼berlegen. Da! Eine Idee!\nMan kÃ¶nnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je grÃ¶ÃŸer diese Abweichung, desto schlechter die ModellgÃ¼te! Also rechnen Sie diese Abweichung aus.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw = 47.4 - total_pr)\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.7 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert abzuziehen. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.11: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt\n\n\n\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Ãœberlegungen: Woher weiÃŸ man, ob 10 Euro oder 20 Euro â€œvielâ€ Abweichung vom Verkaufspreis ist? Man mÃ¼sste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man kÃ¶nnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, Ã¤hnlicher Kennwert zur mittlerer absolute Abweichung ist die SD. Sie haben gehÃ¶rt, dass die SD gebrÃ¤uchlicher ist als die MAA. Um sich als Checker zu prÃ¤sentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja Ã¤hnlich.\nAlso: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte, dann hÃ¤tten wir eine â€œstandardisierteâ€ (abgekÃ¼rzt manchmal mit std) Abweichung von 1, weil 10/10=1.\nBegeistert Ã¼ber Ihre Schlauheit machen Sie sich ans Werk.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. AbbildungÂ 7.12. In AbbildungÂ 7.12 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als standardisiert bezeichnen, da wir sie in Bezug zur â€œtypischen Abweichungâ€, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildungÂ 7.12: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (â€œTransformationâ€) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.8 (z-Werte) z-Werte sind das Resultat der z-Transformation. FÃ¼r die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i = \\frac{x_i - \\bar{x}}{sd_x}.\\square\\)\n\nz-Werte sind nÃ¼tzlich, weil sie die â€œrelativeâ€ Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.\nNach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, AusreiÃŸern), wenn \\(z_i &gt; 2\\) oder \\(z_i &gt; 3\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#fazit",
    "href": "060-modellguete.html#fazit",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.7 Fazit",
    "text": "7.7 Fazit\nDer â€œgesunde Menschenverstandâ€ wÃ¼rde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Das ist vernÃ¼nftig, denn die MAA ist anschaulicher und damit nÃ¼tzlicher als die Varianz und die SD.\nWarum sollte man Ã¼berhaupt ein unanschauliches MaÃŸ wie die Varianz verwenden? Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. GrÃ¼nde, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:\n\nDie SD ist sehr nÃ¼tzlich zur Beschreibung der Normalverteilung\nDie Varianz wird hÃ¤ufig verwendet bzw. in Forschungsarbeiten berichtet, also mÃ¼ssen Sie die Varianz kennen.\n\nLiegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenÃ¼ber Mittelwert basierten StreuungsmaÃŸen (MAA, Varianz, SD).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\n7.8.1 Datenwerk\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nmariokart-sd2\nmariokart-sd3\nKennwert-robust\nsummarise04\nsummarise05\nvis-mariokart-variab\nsd-vergleich\nnasa01\nStreuung-Histogramm\nmariokart-sd1\nsummarise06\nmariokart-desk01\n\n\nÃœbungsaufgabe 7.2 (Analysieren Sie den Datensatz zur Handynutzung) Â \n\n\n\n\n\n\nDas ist die Forschungsfrage dieser Umfrage. Nehmen Sie ggf. an dieser Umfrage teil (sie ist anonym und dauert drei Minuten).\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaden Sie den Datensatz zur Handynutzung von Google-Docs herunter.2 Berechnen Sie dann gÃ¤ngige deskriptive Statistiken und visualisieren Sie sie. \\(\\square\\)\n\n7.8.2 LÃ¶sung: Daten importieren\nSie kÃ¶nnen die Daten entweder selber herunterladen oder aber die folgende Version des Datensatzes verwenden. In beiden FÃ¤llen ist es nÃ¼tzlich, den (absoluten oder relativen) Pfad anzugeben:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\n\nDann kÃ¶nnen Sie die Daten wie gewohnt importieren:\n\nsmartphone_raw &lt;- read.csv(data_path)\n\n\n7.8.3 LÃ¶sung: Daten aufbereiten\nDie Spaltennamen sind sehr unschÃ¶n. Lassen Sie uns daher die Spaltennamen umbenennen (aber vorab sichern):\n\nitem_labels &lt;- names(smartphone_raw)\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:ncol(smartphone_raw))\n\nCheck:\n\nglimpse(smartphone_raw)\n## Rows: 70\n## Columns: 18\n## $ item1  &lt;chr&gt; \"21/03/2024 15:36:52\", \"05/04/2024 10:24:58\", \"05/04/2024 10â€¦\n## $ item2  &lt;chr&gt; \"15:31:00\", \"10:23:00\", \"10:40:00\", \"11:14:00\", \"12:33:00\", â€¦\n## $ item3  &lt;int&gt; 3, 4, 3, 3, 5, 5, 5, 5, 1, 2, 5, 3, 2, 2, 2, 5, 3, 1, 2, 4, â€¦\n## $ item4  &lt;int&gt; 5, 3, 3, 3, 4, 3, 3, 6, 2, 4, 5, 1, 1, 2, 3, 3, 4, 3, 2, 4, â€¦\n## $ item5  &lt;int&gt; 3, 3, 1, 5, 1, 3, 2, 4, 3, 2, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, â€¦\n## $ item6  &lt;int&gt; 4, 2, 4, 3, 5, 4, 6, 3, 2, 5, 6, 4, 2, 6, 5, 5, 5, 5, 5, 4, â€¦\n## $ item7  &lt;int&gt; 4, 3, 2, 3, 3, 1, 3, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 2, 2, 2, â€¦\n## $ item8  &lt;int&gt; 1, 3, 1, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 4, 1, 1, 2, 2, 1, 2, â€¦\n## $ item9  &lt;int&gt; 2, 6, 1, 3, 6, 5, 5, 2, 2, 5, 6, 1, 1, 5, 4, 6, 2, 4, 3, 4, â€¦\n## $ item10 &lt;int&gt; 2, 5, 5, 3, 4, 3, 1, 5, 1, 5, 3, 4, 3, 5, 4, 4, 4, 5, 3, 2, â€¦\n## $ item11 &lt;int&gt; 5, 6, 6, 5, 6, 6, 5, 6, 4, 3, 6, 4, 4, 5, 3, 6, 6, 4, 4, 5, â€¦\n## $ item12 &lt;int&gt; 1, 3, 1, 2, 5, 2, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, â€¦\n## $ item13 &lt;int&gt; 4, 3, 4, 2, 4, 2, 5, 3, 1, 1, 4, 1, 3, 4, 1, 3, 5, 2, 1, 4, â€¦\n## $ item14 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item15 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item16 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦\n## $ item17 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item18 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦\n\n\n7.8.4 Komplette LÃ¶sung\nğŸ˜\n\n\n\n7.8.5 Fallstudie zur Lebenszufriedenheit\nDie OECD fÃ¼hrt eine weltweite Studie zur Lebenszufriedenheit durch.3 Arbeiten Sie die die Fallstudie â€œoecd-yacsdaâ€ im Datenwerk durch, um ein tieferes VerstÃ¤ndnis fÃ¼r die Lebenszufriedenheit in verschiedenen LÃ¤ndern der Welt zu bekommen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.9 Literaturhinweise",
    "text": "7.9 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnÃ¼glich zu lesenden Buch eine kurzweilige EinfÃ¼hrung in die Statistik vor; auch StreuungsmaÃŸe haben dabei einen Auftritt. Wer mehr â€œLehrbuch-Feelingâ€ sucht, wird bei Cetinkaya-Rundel & Hardin (2021) fÃ¼ndig (das Buch ist online frei verfÃ¼gbar). Es ist kein Geheimnis, dass StreuungsmaÃŸe keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne StreuungsmaÃŸe gehtâ€™s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonst wo) aus dem Regal ziehen, fÃ¼ndig werden zu diesem Thema. Die BÃ¼cher unterscheiden sich meist â€œnurâ€ in ihrem Anspruch bzw. der didaktischen Aufmachung; fÃ¼r alle ist da was dabei.\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric Visualisation of the Variance of the Example Distribution (2, 4, 4, 4, 5, 5, 7, 9) on w:Standard Deviation. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nflaticon. (2024). Professor. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meineâ€¦â†©ï¸\nhttps://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharingâ†©ï¸\nhttps://www.oecd.org/wise/measuring-well-being-and-progress.htmâ†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#lernsteuerung",
    "href": "070-zusammenhaenge.html#lernsteuerung",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Standort im Lernpfad\nAbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n8.1.2 Lernziele\n\nSie kÃ¶nnen die Begriffe Kovarianz und Korrelation definieren und ihren ZusammenhÃ¤nge erlÃ¤utern.\nSie kÃ¶nnen die StÃ¤rke einer Korrelation einschÃ¤tzen.\n\n8.1.3 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n8.1.4 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n8.1.5 Zum Einstieg\n\nBeispiel 8.1 Â \n\nSuchen Sie sich eine vertrauenwÃ¼rdige Partnerin oder einen vertrauenswÃ¼rdigen Partner. Im Zweifel reicht die Person, die neben Ihnen sitzt. ğŸ˜\n\nNennen Sie zwei Variablen, die wie folgt zusammenhÃ¤ngen:\n\n\ngleichsinnig (Viel von dem einen, viel von dem anderen)\ngegensinnig (viel von dem einen, wenig von dem anderen)\nScheinzusammenhang (hÃ¤ngt zusammen, ist aber nicht â€œechtâ€ bzw. kausal)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl, zu einem â€œPunktâ€ sozusagen, zusammengefasst werden kann.\nIn diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. GleichungÂ 8.1.\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{8.1}\\]\nWo wir in Kapitel 6 eine Variable mit Hilfe eines LagemaÃŸes beschrieben (bzw. dargestellt, zusammengefasst, modelliert) haben, tun wir hier das Gleiche fÃ¼r zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen voneinander (statistisch) abhÃ¤ngen bzw. miteinander (in welcher Form auch immer) zusammenhÃ¤ngen. Wir begrenzen auf metrische Variablen.\n\n8.2.1 Beispiele fÃ¼r ZusammenhÃ¤nge\n\nLernzeit und Klausurerfolg\nKÃ¶rpergrÃ¶ÃŸe und SchuhgrÃ¶ÃŸe\nVerbrauchtes Benzin und zurÃ¼ckgelegte Strecke\nProduktionsmenge und Produktionskosten\nBildschirmzeit und SchlafqualitÃ¤t\nUmweltschutz und BiodiversifitÃ¤t \\(\\square\\)\n\nDie Verbildlichung (Visualisierung) zweier metrischer Variablen haben wir bereits in Kapitel 5.5.2 kennengelernt. Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal AbbildungÂ 8.1.\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)\n\n\n\n\n\n\n\n\n\n(b) â€˜Verwackeltesâ€™ Streudiagramm, um die einzelnen Punkte besser zu erkennen\n\n\n\n\n\n\nAbbildungÂ 8.1: Visualisierung des Zusammenhangs von wheels und total_pr",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\nDie StÃ¤rke des linearen Zusammenhangs zweier metrischer Variablen kann man gut mithilfe von Abweichungsrechtecken veranschaulichen. Los gehtâ€™s!\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.2 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurÃ¼ckbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhÃ¤ngen.1 Gar nicht so schlecht ausgefallen wie gedacht â€¦, s. TabelleÂ 8.1.\\(\\square\\)\n\n\n\n\nTabelleÂ 8.1: Punkte in der Statistikklausur (0-100) und Lernzeit (0-100)\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. AbbildungÂ 8.2. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso fÃ¼r \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\).\nDie FlÃ¤che des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\).\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 8.2: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus AbbildungÂ 8.2. Nennen wir das resultierende Rechteck das â€œSummenrechteckâ€. Ja, ich weiÃŸ, ich strapaziere mal wieder Ihre Phantasie. Jetzt kommtâ€™s: Je grÃ¶ÃŸer die FlÃ¤che des Summenrechtecks, desto stÃ¤rker der (lineare) Zusammenhang. Beachten Sie, dass die FlÃ¤chen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die FÃ¼llfarben der Rechtecke verdeutlichen dies, s. AbbildungÂ 8.2. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlâ‰¥inie) ist. So zeigt AbbildungÂ 8.3 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) Ã¼berwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ Ã¼berwiegt).\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten 1 und 3) Ã¼berwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) Ã¼berwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\n\n\n\n(b) Positive Vorzeichen (Quadranten 1 und 3) Ã¼berwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) Ã¼berwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildungÂ 8.3: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die FlÃ¤chen der Abweichungsrechtecke addiert.\n\n\nWir kÃ¶nnen das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das Ã¤ndert nichts an der Aussage, aber der Mittelwert hat gegenÃ¼ber der Summe den Vorteil, dass er unabhÃ¤ngig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck.\nEin MaÃŸ fÃ¼r den Zusammenhang von Lernzeit und Klausurpunkte ist also die FlÃ¤che des mittleren Abweichungsrechtecks, s. AbbildungÂ 8.4.\n\n\n\n\n\nAbbildungÂ 8.4: Die Kovarianz als mittleres Abweichungsrechteck. Die FlÃ¤che der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die FlÃ¤che des mittleren Abweichungsrechtecks. Sie ist ein MaÃŸ fÃ¼r die StÃ¤rke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. AbbildungÂ 8.4.\\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Zu viele Bilder! Ich brauch Zahlen.\n\n\nğŸ§‘â€ğŸ« Kommen gleich!\n\nTabelleÂ 8.2 zeigt die Werte fÃ¼r die X- und Y-Abweichung und die resultierenden FlÃ¤chen der Abweichungsrechtecke. Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv2\n\n\n\nTabelleÂ 8.2: Werte der Abweichungsrechtecke. avg: average (Mittelwert), cov_sign: Vorzeichen der Kovarianz,_pos: positiver Wert auf der entsprechenden Achse (x/y), xy_area: Produkt von x_delta und y_delta\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51\n17\n20.8\n1\n353\n\n\n2\n44\n40\n53\n51\n-13\n-7.2\n1\n94\n\n\n3\n39\n35\n53\n51\n-18\n-12.2\n1\n220\n\n\n4\n50\n67\n53\n51\n14\n-1.2\n-1\n-18\n\n\n\n\n\n\n\n\nBerechnen wir als nÃ¤chstes das mittlere Abweichungsrechteck, die Kovarianz:\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. GleichungÂ 8.2:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.2}\\]\nGleichungÂ 8.2 in Worten ausgedrÃ¼ckt:\n\nRechne fÃ¼r jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne fÃ¼r jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere fÃ¼r alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die FlÃ¤chen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.3 (Variablen mit positiver Kovarianz) Â \n\nGrÃ¶ÃŸe und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf\\(\\square\\)\n\n\n\n\nBeispiel 8.4 (Variablen mit negativer Kovarianz) Â \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und DepressivitÃ¤t\\(\\square\\)\n\n\n\nDrei Extrembeispiele fÃ¼r Kovarianz-Werte sind in AbbildungÂ 8.5 dargestellt.\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\n\n\n\n(c) negativer Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 8.5: Verschiedene Werte der Kovarianz\n\n\nBei einer Kovarianz von (ungefÃ¤hr) Null ist die Gesamt-FlÃ¤che der Abweichungsrechtecke, wenn man sie pro Quadrant aufsummiert, ungefÃ¤hr gleich groÃŸ, s. AbbildungÂ 8.6. Zur Erinnerung: Bei der Varianz waren es Quadrate; bei der Kovarianz sind es jetzt Rechtecke. Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so betrÃ¤gt die Summe in etwa (oder genau) Null.\nDamit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null, s. GleichungÂ 8.3: Wenn die Summe der Aweichungsrechtecke Null ist, dann ist auch ihr Mittelwert (MW) Null. Damit ist die Kovarianz Null.\n\\[\\begin{aligned}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{MW} \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov}(X, Y) &= 0\n\\end{aligned} \\tag{8.3}\\]\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke, deren FlÃ¤che sich zu 0 addiert\n\n\n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke, deren FlÃ¤che sich zu 0 addiert\n\n\n\n\n\n\nAbbildungÂ 8.6: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhÃ¤ngig ist von der Skalierung. So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wÃ¼nschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabhÃ¤ngig davon, ob man Einkommen in Euro, Cent oder Dollar misst. AuÃŸerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson lÃ¶st das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nÃ¤mlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so fÃ¼hrt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) definieren wie in DefinitionÂ 8.3.\n\nDefinition 8.3 (Korrelationskoeffizient r) Der Korrelationskoeffizient \\(r\\) (nach Pearson) ist definiert als das mittlere Produkt der z-Wert-Paare, s. GleichungÂ 8.4, vgl. Cohen et al. (2003). Er ist ein MaÃŸ des linearen Zusammenhangs zweier metrischer Variablen. Der Wertebereich ist \\([-1;1]\\), wobei 0 keinen Zusammenhang anzeigt und \\(|r|=1\\) perfekten Zusammenhang. \\(\\square\\)\n\n\\[r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i} \\tag{8.4}\\]\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur fÃ¼r metrische Variablen definiert ist.\n\n\n\n\n\n\nHinweis\n\n\n\nAus dem Korrelationskoeffizienten kÃ¶nnen Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert (Betrag) des Korrelationskoeffizienten gibt die StÃ¤rke des linearen Zusammenhangs an. Je nÃ¤her der Wert bei 1 liegt, desto stÃ¤rker ist der (lineare) Zusammenhang.\n\n\n\n\\(r = 0\\): kein linearer Zusammenhang\n\n\\(r = 1\\): perfekter linearer Zusammenhang\\(\\square\\)\n\n\n\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt AbbildungÂ 8.7.\n\n\n\n\n\nAbbildungÂ 8.7: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0\n\n\nDie untere Zeile von AbbildungÂ 8.7 zeigt Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammhang besteht.\n\nÃœbungsaufgabe 8.1 (Korrelationsspiel) Spielen Sie das Korrelationsspiel3: Sie Sehen ein Streudiagramm und mÃ¼ssen den richtigen Korrelationskoeffizienten eingeben.\\(\\square\\)\n\n\nÃœbungsaufgabe 8.2 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist4 findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr GefÃ¼hl fÃ¼r die StÃ¤rke des Korrelationskoeffizienten zu entwickeln.\\(\\square\\)\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhÃ¤ngt? Schauen wir nach! Die Funktion correlation() (aus dem Paket easystats) erledigt das Rechnen fÃ¼r uns, s. TabelleÂ 8.3.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  |&gt;  # aus `easystats`\n  summary()\n\n\n\n\nTabelleÂ 8.3: Korrelation berechnen mittels der Funktion correlation aus easystats\n\n\n\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\n\n\n\n\n\nSie kÃ¶nnen auch auf die letzte Zeile, also dem Befehl summary() verzichten. Dann ist die Ausgabe ausfÃ¼hrlicher.\n\n8.4.3 Korrelation â‰  Kausation\nEine Studie fand eine starke Korrelation, zwischen der (HÃ¶he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. AbbildungÂ 8.8.\n\n\n\n\n\nAbbildungÂ 8.8: Schoki futtern macht schlau?\n\n\nKorrelation (bzw. Zusammenhang) ist ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.5 (Scheinkorrelation: StÃ¶rche und Babies) Eine Urban Myth besagt: Die Anzahl der StÃ¶rche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis (vgl. Matthews, 2000).\nEine mÃ¶gliche ErklÃ¤rung fÃ¼r dieses (nur scheinbare) Paradoxon ist, dass die â€œNaturbelassenheitâ€ des Landkreises die gemeinsame Ursache fÃ¼r StÃ¶rche ist (StÃ¶rche lieben Natur) und fÃ¼r Babies ist (die Gegebenheiten bei hoher Naturbelassenheit eine hÃ¶here Zahl von Kindern pro Frau begÃ¼nstigt). Wir mÃ¼ssen die ErklÃ¤rung keinesfalls glauben; sie soll das Beispiel nur konkreter machen. Uns geht es hier nur um die Erkennung von Scheinkorrelation.\n\n\nBeispiel 8.6 (Glatze macht Corona?) Kahle MÃ¤nner aufgepasst! Macht eine Glatze krank? MÃ¤nner mit Glatze bekommen hÃ¤ufiger Corona (Goren et al., 2020).\n\nBald men at higher risk of severe case of Covid-19, research finds5\n\nEine alternative ErklÃ¤rung lautet, dass Alter einen Effekt hat auf Glatze (je Ã¤lter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatz hat) und auf die Schwere des Corona-Verlaufs (Ã¤ltere Menschen haben deutlich schwerere Corona-VerlÃ¤ufe). \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lÃ¼gt",
    "text": "8.5 Wie man mit Statistik lÃ¼gt\n\n8.5.1 Range-Restriktion\nDurch (nicht-randomisierte) EinschrÃ¤nkung (Restriktion) des Ranges einer (oder beider) Variablen sinkt die StÃ¤rke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003) und AbbildungÂ 8.9.\nErstellen wir uns dazu zwei DatensÃ¤tze mit je zwei Variablen, \\(X\\) und \\(Y\\) und mit Umfang \\(n=100\\). Einer der beiden DatensÃ¤tze sei mit EinschrÃ¤nkung des Ranges und einer ohne ohne. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in ListingÂ 8.1. Man kann sich mit dem Befehl rnorm(n, m, sd) \\(n\\) normalverteilte Variablen mit Mittelwert \\(m\\) und Streuung \\(sd\\) von R erzeugen lassen. Wir schrÃ¤nken dann den Range von \\(X\\) ein auf, sagen wir, den Bereich von \\([-0.5, .5]\\) (Datensatz d_filtered), s. ListingÂ 8.1.\n\n\nListingÂ 8.1\n\n\nset.seed(42)\nn &lt;- 1e2\nd &lt;-\n  tibble(x = rnorm(n = n, mean = 0, sd = 1),\n         e = rnorm(n = n, mean = 0, sd = .5),\n         y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-\nd |&gt; filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne EinschrÃ¤nkung des Range: Starke Korrelation\n\n\n\n\n\n\n\n\n\n(b) Mit EinschrÃ¤nkung des Range: SchwÃ¤chere Korrelation\n\n\n\n\n\n\nAbbildungÂ 8.9: SchrÃ¤nkt man den Range einer (oder beider) Variablen ein, so sinkt die StÃ¤rke der Korrelation\n\n\n\nÃœbungsaufgabe 8.3 (Berechnen Sie die Korrelation) Glauben Sie nicht, prÃ¼fen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhÃ¤ngen.\nFalls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, kÃ¶nnen Sie die Daten so (in mittlerweile gewohnter Manier) importieren, s. ListingÂ 8.2.\n\n\n\nListingÂ 8.2: Mariokart importieren, wenn die CSV-Datei im aktuellen Projektordner liegt.\n\nmariokart &lt;- read.csv(\"mariokart.csv\")\n\n\n\n\nFalls der Datensatz im Unterordner mit Namen â€œMein_Unterordnerâ€ liegt, so wÃ¼rden Sie folgenden Pfad eingeben, s. ListingÂ 8.3.\n\n\n\nListingÂ 8.3: Den Datensatz Mariokart importieren, wenn die CSV-Datei im Unterordner Mein_Unterordner liegt.\n\nmariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\")\n\n\n\n\nMan beachte, dass solche sog. relativen Pfade, wie Mein_Unterordner/, die relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio, liegen, nicht mit einem SchrÃ¤gstrich (Slash) beginnen.\nFalls Sie die Daten nicht auf Ihrem Computer haben, kÃ¶nnen Sie sie komfortable von z.B. der Webseite von Vincent Arel-Bundock herunterladen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wÃ¤hlen die Variablen von mariokart, die Sie in diesem Fall interessieren â€“ natÃ¼rlich nur die metrischen â€“ und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\n\n\n\n\n\n\nNamensverwechslung (name clash)\n\n\n\nEs kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein, wie es mir oben in der Syntax passiert ist. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemÃ¤ÃŸ sagt: â€œHey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.â€ Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: â€œHey R, nimm gefÃ¤lligst select aus dem Paket dplyr, dortâ€wohntâ€ nÃ¤mlich select. Auf Errisch spricht sich das so: dplyr::select(...).\\(\\square\\)\n\n\nEtwas schÃ¶ner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. TabelleÂ 8.4.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nTabelleÂ 8.4: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nwheels\nseller_rate\ntotal_pr\nship_pr\nstart_pr\nn_bids\n\n\n\nduration\n-0.30**\n-0.15\n-0.04\n0.27*\n0.13\n-0.12\n\n\nn_bids\n-0.08\n-0.11\n0.13\n0.03\n-0.63***\n\n\n\nstart_pr\n0.16\n0.28*\n0.07\n0.03\n\n\n\n\nship_pr\n0.05\n-0.02\n0.54***\n\n\n\n\n\ntotal_pr\n0.33**\n9.43e-03\n\n\n\n\n\n\nseller_rate\n-0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\nNeben einigen Statistiken, die wir einfach geflissentlich ausblenden (t und p) beinhaltet die Tabelle eine interessante Information: den SchÃ¤tzbereich fÃ¼r die Korrelation, gekennzeichnet als 95% CI. Grob gesagt kÃ¶nnen wir diese Information so interpretieren: â€œMit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich.â€ (Das ist die sog. bayesianische Interpretation.)\nMÃ¶chte man nur einzelne Korrelationskoeffizienten ausrechnen, kÃ¶nnen wir die Idee des Zusammenfassens, s. GleichungÂ 8.1, nutzen:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels))\n\n\n  \n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nIm Falle von fehlenden Werte mÃ¼ssen Sie den Befehl cor() aus seiner schÃ¼chternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor.\n\n\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n  \n\n\n\n\nğŸ§‘â€ğŸ“ Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket dataExplorer bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. AbbildungÂ 8.10.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildungÂ 8.10: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.7 Aufgaben",
    "text": "8.7 Aufgaben\nSchauen Sie sich auch mal auf der Webseite Datenwerk6 die Aufgaben zu dem Tag association an.\n\nnasa02\nmariokart-korr1\nmariokart-korr2\nmariokart-korr3\nmariokart-korr4\nkorr01\nkorr02",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#halbzeitquiz",
    "href": "070-zusammenhaenge.html#halbzeitquiz",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.8 Halbzeitquiz",
    "text": "8.8 Halbzeitquiz\n\n\n\n\n\n\nTesten Sie Ihr Wissen mit diesem Quiz zur deskriptiven Statistik (MaÃŸe der zentralen Tendenz, VariabilitÃ¤t, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.9 Fallstudien",
    "text": "8.9 Fallstudien\n\n\nYACSDA: EDA zu FlugverspÃ¤tungen7 im Datenwerk unter dem Tag flights-yacsda-eda zu finden.\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Ãœbungsaufgaben kÃ¶nnen theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer LÃ¶sung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.\\(\\square\\)\n\n\n\n\nYACSDA: Topgear8\n\n\nDatensatz flights: Finde den Tag mit den meisten AbflÃ¼gen9\n\n\nTidyverse Case Study: Exploring the Billboard Charts10\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl. Es ist nicht nÃ¶tig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Ãœbung, dort, wo Sie es nÃ¶tig haben.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.10 Literaturhinweise",
    "text": "8.10 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erlÃ¤utern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schÃ¶nes, modernes Statistikbuch bietet der Psychologie-Prof Russel Poldrack von der Princeton University (2023); auch dieses Buch ist frei online verfÃ¼gbar. Tipp: Nutzen Sie die Ãœbersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas hÃ¶heren Anspruchs. Was ist Scheinkorrelation und was ist â€œechteâ€ Korrelation? Dieser Unterschied â€“ der fÃ¼r die Wissenschaft zentral ist â€“ wird von Pearl & Mackenzie (2018) auf entspannte Art erlÃ¤utert; nebenbei lernt man einiges zur Geschichte der Wissenshaft. Hier finden Sie weitere Beispiele fÃ¼r Scheinkorrelationen.\nDieser TED-Vortrag informiert zum Thema Scheinkorrelation.\n\n\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGoren, A., VaÃ±o-GalvÃ¡n, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain â€“ A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545â€“1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPearl, J., & Mackenzie, D. (2018). The Book of Why: The New Science of Cause and Effect (First edition). Basic Books.\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "ğŸ§‘â€ğŸ“ Typisches Lehrerbeispiel!!â†©ï¸\nhttps://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csvâ†©ï¸\nhttps://gallery.shinyapps.io/correlation_game/â†©ï¸\nhttps://rpsychologist.com/correlation/â†©ï¸\nhttps://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/, Abruf 2023-03-24â†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/â†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/posts/flights-yacsda-edaâ†©ï¸\nhttps://data-se.netlify.app/2021/02/11/yacda-topgear/â†©ï¸\nhttps://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/â†©ï¸\nhttps://www.njtierney.com/post/2017/11/07/tidyverse-billboard/â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Lernsteuerung\nAbb. AbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#lernsteuerung",
    "href": "080-regression1.html#lernsteuerung",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Lernziele\n\nSie kÃ¶nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie kÃ¶nnen die Bestandteile eines Geradenmodells aufzÃ¤hlen und erlÃ¤utern.\nSie kÃ¶nnen die GÃ¼te eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie kÃ¶nnen Geradenmodelle sowie ihre ModellgÃ¼te in R berechnen.\n\n9.1.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n9.1.3 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nÃ¼tzliche Sache, unter (mindestens) folgenden Voraussetzungen:\n\nSie sind prÃ¤zise\nWir kennen die PrÃ¤zision\nJemand interessiert sich fÃ¼r die Vorhersage\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne PrÃ¤diktor\n\nBeispiel 9.1 Nach intensiver BeschÃ¤ftigung mit Statistik sind Sie allgemein als Checker bekannt. Viele jÃ¼ngere Studis fragen Sie um Rat. eines Tages kommt eine Studentin, Toni, und fragt: â€œWelche Statistiknote kann ich in der Klausur erwarten?â€ Sie entgegnen: â€œWie viel hast du denn gelernt?â€. Die Antwort: â€œSag ich nicht.â€\nNach kurzem Ãœberlegen geben sie den Notenschnitt der letzten Klausur als Prognose fÃ¼r diese Person. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in ListingÂ 9.1 wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls mÃ¼ssen Sie die Daten erst herunterladen1:\n\n\n\nListingÂ 9.1: Der Datensatz â€˜noten2â€™ liegt im Unterordner â€˜Noten.â€™\n\nnoten2 &lt;- read.csv(\"daten/noten2.csv\")\n\n\n\n\n Download \nDann rechnen Sie den Mittelwert aus:\n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n  \n\n\n\nIhre Antwort lautet also: â€œIm Schnitt haben die Studis bei der letzten Klausur gut 70% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!â€\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Kenntnis eines PrÃ¤diktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert fÃ¼r jede Beobachtung, s. AbbildungÂ 9.1. Wir nutzen den Mittelwert als Punktmodell fÃ¼r den Klausurerfolg.\\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\n9.2.2 Nullmodell (Punktmodell)\nModelle ohne PrÃ¤diktor, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null PrÃ¤diktoren hat, nennt man es auch manchmal â€œNullmodellâ€.\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        71.1\n\nlm steht fÃ¼r â€œlineares Modellâ€, die 1 sagt, dass es keine PrÃ¤diktoren gibt. In dem Fall wird der Mittelwert als Gerade verwendet. Der zurÃ¼ckgemeldete Koeffizient (Intercept) ist hier der Modell des Punktmodells. Da es ein Punktmodell ist, sagt es fÃ¼r alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nDie Regressionsgleichung lautet demnach: y_pred = 71.08. In Worten: â€œWir sagen fÃ¼r jede Beobachtung einen Wert von ca. 71 vorherâ€.\n\n9.2.3 Vorhersagen mit PrÃ¤diktor\n\nBeispiel 9.2 (Toni verrÃ¤t die Lernzeit) Toni entschlieÃŸt sich dann doch noch, die Lernzeit zu verraten: â€œOkay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.â€ Jetzt mÃ¼ssen Sie erstmal nachdenken: â€œWie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?â€\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. AbbildungÂ 9.2, a).2\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: â€œBei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. KÃ¶nnte mit dem Bestehen eng werden.â€ Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.\\(\\square\\)\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen. Mit einem Lineal kÃ¶nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. AbbildungÂ 9.2, b).\n\n\n\n\n\n\n\n\n\n(a) Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)\n\n\n\n\n\n\n\n\n\n(b) Eine â€˜Trendgeradeâ€™ (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt gekennzeichnet.\n\n\n\n\n\n\nAbbildungÂ 9.2: Noten und Lernzeit: Rohdaten und Modell\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell fÃ¼r die Daten, s. AbbildungÂ 9.2, b. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt fÃ¼r alle Beobachtungen den gleichen Wert vorher. AbbildungÂ 9.1 und AbbildungÂ 9.2 stellen ein Punktmodell einem Geradenmodell gegenÃ¼ber.\nIn einem Geradenmodell wird nicht mehr (notwendig) fÃ¼r jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.1 (Gerade) Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). HÃ¤ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet:\n\n\\(f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + {\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + {b_1} \\color{xcol}{x}\\) .\nDie Nomenklatur mit \\(b_0, b_1\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, ...\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage Ã¼ber eine Population, nicht nur Ã¼ber eine Stichprobe, machen mÃ¶chte.\nDas â€œDachâ€ Ã¼ber y, \\(\\color{modelcol}{\\hat{y}}\\), drÃ¼ckt aus, dass es sich den den geschÃ¤tzten, bzw. vom Modell vorhergesagten (â€œmodelliertenâ€) Wert fÃ¼r \\(\\color{ycol}{y}\\) handelt, nicht das tatsÃ¤chliche (empirische, beobachtete) \\(\\color{ycol}{y}\\). \\(\\square\\)\n\nAbbildungÂ 9.3 skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n\n\n\n\n\nAbbildungÂ 9.3: Achsenabschnitt und Steigung einer Regressionsgeraden (Menk, 2014)\n\n\n\n\n\n\n\n\n\nDas einfache lineare Modell\n\n\n\nDas einfache lineare Modell nimmt den Wert einer abhÃ¤ngigen metrischen Variablen, y als lineare Funktion von unabhÃ¤ngigen Variablen, x an, plus einem Fehlerterm, e. \\(\\square\\)\n\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}\\]\nMit:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschÃ¤tzter y-Achsenabschnitt laut Modell\n\n\\(\\color{beta1col}{\\beta_1}\\): geschÃ¤tzte Steigung laut Modell\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nJe nach Datenlage kÃ¶nnen sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. AbbildungÂ 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildungÂ 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher ModellgÃ¼te\n\n\nAbbildungÂ 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie kÃ¶nnen Punkte per Klick/Touch hinzufÃ¼gen.\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"RÂ²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.5: Interaktives Beispiel fÃ¼r eines lineares Modell. FÃ¼gen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, w erden Sie wieder konsultiert. â€œOkay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurÃ¼ck!â€\nDas sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{X}=0\\) gibt der Achsenabschnitt zurÃ¼ck.\nSchnell skizzieren Sie dazu ein Diagramm, s. AbbildungÂ 9.6. Puh, die Antwort wird Toni nicht gefallen â€¦\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 9.6: Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf AbbildungÂ 9.6 zu schauen, kÃ¶nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\nğŸ§‘â€ğŸ« Hey R, predicte mir mal auf Basis vom Modell â€œlm1â€ den Lernerfolg fÃ¼r Toni, wenn der x=0 Stunden lernt.\n\n\nğŸ¤– Okay, ich predicte mit Modell â€œlm1â€ und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)  # `tibble` erstellt eine Tabelle\n\n\npredict(lm1, newdata = tonis_lernzeit)\n##   1 \n## 8.6\n\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. GleichungÂ 9.2 :\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.1}\\]\nLies: â€œLaut meinem Modell ist mein (geschÃ¤tztes) \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)â€.\nWir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist:\n\\[\\color{ycol}{AV} \\sim \\color{xcol}{UV} \\tag{9.2}\\]\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\nGleichungÂ 9.2 kÃ¶nnen Sie so ins Errische Ã¼bersetzen:\n\nlm(y ~ x, data = meine_daten)\n\nlm steht fÃ¼r â€œlineares Modellâ€, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade (an anderer Stelle in diesem Buch unscharf als â€œTrendgeradeâ€ bezeichnet).\n\nBeispiel 9.4 (Zahlen fÃ¼r Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: â€œJetzt hÃ¶r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir prÃ¤zise Zahlen!â€.\n\n\nlm1 &lt;- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##       8.603        0.879\n\nR gibt Ihnen die beiden Koeffizienten fÃ¼r die Gerade aus. Den Namen des Objekts kÃ¶nnen Sie frei aussuchen, z.B. mein_erstes_lm.\nDie Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x\n8.6 ist der Achsenabschnitt, d.h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: FÃ¼r jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 10 Stunden gelernt, wÃ¼rden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 10\ny_pred &lt;- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17\n\n\nBeispiel 9.5 (Vorhersage fÃ¼r Klausurerfolg, nÃ¤chster Versuch) Sie versuchen, noch etwas Gutes fÃ¼r Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dÃ¼rfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit2)\n##  1 \n## 73\n\nDie Syntax von predict lautet:\npredict(name_des_objekts, newdata = tabelle_mit_prÃ¤diktorwerten)\n\n\n\n\n\n\nHinweis\n\n\n\nMit predict bekommt man eine Vorhersage; im Standard eine â€œPunkt-Vorhersageâ€, eine einzelne Zahl.\\(\\square\\)\n\n\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagten Wert fÃ¼r eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsÃ¤chlichen Wert nennt man Vorhersagefehler (error, \\(e_i\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Residuen beim Geradenmodell (lm1)\n\n\n\n\n\n\n\n\n\n(b) Residuen beim Punktmodell (lm0)\n\n\n\n\n\n\nAbbildungÂ 9.7: Vorhersagefehler als Abweichungsbalken\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket easystats):\n\nmae(lm0)\n## [1] 11\nmae(lm1)\n## [1] 8\n\nVergleichen wir MAE im Nullmodell mit MAE in lm1:\n\nverhaeltnis_fehler_mae &lt;- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm1 haben die mittlere (Absolut-)LÃ¤nge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.2 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)).\\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere KenngrÃ¶ÃŸen wie MAE oder MSE.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist.\\(\\square\\)\n\n\nNatÃ¼rlich kÃ¶nnen wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen. Wer mag, kann den MSE auch von Hand berechnen: mean((noten2$y-mean(noten2$y))^2).\n\nmse(lm0)\n## [1] 193\nmse(lm1)\n## [1] 106\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\nDie Regressionskoeffizienten (hier synonym: Modellparameter) b0 und b1 wÃ¤hlt man so, dass die Residuen minimal sind,\nAbbildungÂ 9.8 veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildungÂ 9.8: Bildquelle: Karsten LÃ¼bke, FOM Hochschule\n\n\nGenauer gesagt wird die Summe der quadrierten Residuen minimiert, s. GleichungÂ 9.3.\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene MÃ¶glichkeiten, um die Koeffizienten zu berechnen (die sind aber nicht in diesem Buch zu finden). Eine schÃ¶ne Darstellung dazu findet sich bei Kaplan (2009).\nâ€œVon Handâ€ kÃ¶nnen Sie die Optimierung von b0 und b1 in dieser App der FOM-Hochschule3 ausprobieren.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r-quadrat-als-maÃŸ-der-modellgÃ¼te",
    "href": "080-regression1.html#r-quadrat-als-maÃŸ-der-modellgÃ¼te",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.4 R-Quadrat als MaÃŸ der ModellgÃ¼te",
    "text": "9.4 R-Quadrat als MaÃŸ der ModellgÃ¼te\nAnders gesagt, wir haben uns um \\(1 - 0.55\\) verbessert:\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n\n\nDefinition 9.3 (R-Quadrat) Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen von lm0 zum gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). R-Quadrat (\\(R^2\\)) e ines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein MaÃŸ der ModellgÃ¼te: Je grÃ¶ÃŸer \\(R^2\\), desto besser die Vorhersage. Da es ein AnteilsmaÃŸ ist, liegt der Wertebereich zwischen 0 uns 1. Im Nullmodell liegt R-Quadrat per Definition bei 0. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable erklÃ¤rt.\nWir kÃ¶nnen R-Quadrat (\\(R^2\\)) uns von R z.B. so ausgeben lassen:\n\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\). Das gilt bei Modellen mit einem PrÃ¤diktor; gibt es mehrere PrÃ¤diktoren gilt die Beziehung nur, wenn die PrÃ¤diktoren alle paarweise unabhÃ¤ngig sind, vgl. AbbildungÂ 9.9.\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation, r â‰… 0 und R2 â‰… 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefÃ¤hr) parallel zur X-Achse\n\n\n\n\n\n\n\n\n\n(b) Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert\n\n\n\n\n\n\nAbbildungÂ 9.9: ExtremfÃ¤lle von R-Quadrat: 0 und 1\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man fÃ¼r jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\) , vorhersagen wÃ¼rde.\n\n\n\n\n\n\nHinweis\n\n\n\nJe grÃ¶ÃŸer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser â€œerklÃ¤rtâ€ das Modell die Daten (desto besser der â€œFitâ€, sagt man).\n\n\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der GrÃ¶ÃŸe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 ModellgÃ¼te\nDie Residuen (Vorhersagefehler) bestimmen die ModellgÃ¼te: Sind die Residuen im Schnitt groÃŸ, so ist die ModellgÃ¼te gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur VerfÃ¼gung: R-Quadrat, r (als Korrelation von tatsÃ¤chlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)), MSE, RMSE, MAE, â€¦\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\);lies: â€œbeta Nullâ€) und Steigung (\\(\\beta_1\\)) sind nur eingeschrÃ¤nkt zu interpretieren, wenn man die zugrundeliegenden kausalen AbhÃ¤ngigkeiten nicht kennt. Nur aufgrund eines statistischen Zusammenhangs darf man keine kausalen AbhÃ¤ngigkeiten annehmen. Ohne eine guten Grund fÃ¼r eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der ModellgÃ¼te und den Vorhersagen begnÃ¼gen. Was auch was wert ist.\n\n9.5.2.1 Achsenabschnitt (b0)\nIm Modell lm1 liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=8.6\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) kÃ¶nnen also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten.\n Leider ist es hÃ¤ufig so, dass PrÃ¤diktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nÃ¼tzt.\n\nBeispiel 9.6 (Regression GrÃ¶ÃŸe und Gewicht) Nutzt man KÃ¶rpergrÃ¶ÃŸe und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von KÃ¶rpergrÃ¶ÃŸe wenig nÃ¼tzlich, da es keine Menschen gibt der GrÃ¶ÃŸe 0.\\(\\square\\)\n\n\n9.5.2.2 Geradensteigung (b1)\nâ€œIm Modell lm1 betrÃ¤gt der Regressionskoeffizient b1 \\(0.88\\). Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von b1.â€\n\n\n\n\n\n\nVorsicht\n\n\n\nHÃ¤ufig liest man, der â€œEffekt des PrÃ¤diktorsâ€ auf die AV betrage z.B. \\(0.88\\). â€œEffektâ€ ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort â€œEffektâ€ mit Vorsicht genieÃŸen. Manche sprechen daher auch von einem â€œstatistischen Effektâ€.\\(\\square\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lÃ¼gt",
    "text": "9.6 Wie man mit Statistik lÃ¼gt\nDer Unterschied in ModellgÃ¼te zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) MaÃŸ der ModellgÃ¼te und da \\(r = \\sqrt{R^2}\\), darf \\(r\\) nicht wie \\(R^2\\) als MaÃŸ der ModellgÃ¼te interpretiert werden. AbbildungÂ 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildungÂ 9.10: Der Zusammenhang von r und R-Quadrat ist nicht linear.\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dÃ¼rfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie mÃ¶chten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin. Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz. Auf gehtâ€™s!\nDaten laden (und die Ã¼blichen Pakete starten, nicht vergessen):\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloÃŸem Rumprobieren Ã¼berlegen Sie und schauen dann in AbbildungÂ 8.10 nach, welche Variable am stÃ¤rksten korreliert mit total_pr; es resultiert lm3:\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n\n\n\n\nTabelleÂ 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in TabelleÂ 9.1 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut lm3 etwa 36 Euro finaler Verkaufspreis erwarten. Pro Euro an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro. (Die Spalte 95 CI gibt einen SchÃ¤tzbereich fÃ¼r den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um SchÃ¤tzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schlieÃŸlich nur eine Stichprobe der GrÃ¶ÃŸe \\(n=143\\).)\nDie Regressionsgleichung von lm3 lautet demnach:\ntotal_pr_pred = 36.25 + 4.34*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36.25â‚¬ â€œSockelbetragâ€ plus 4.34 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (â€œexpectationsâ€) des Verkaufspreises in AbhÃ¤ngigkeit vom Wert der UV (ship_pr) auch schÃ¤tzen (â€œto estimateâ€) lassen, und zwar so:\n\nestimate_expectation(lm3) %&gt;%  # aus dem Paket 'easystats'\n  head()  # nur die ersten paar vorhergesagten Werte\n\n\n\n\nModel-based Expectation\n\nship_pr\nPredicted\nSE\n95% CI\nResiduals\n\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-2.04\n\n\n3.99\n53.55\n1.87\n(49.85, 57.25)\n-16.51\n\n\n3.50\n51.43\n1.82\n(47.82, 55.03)\n-5.93\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n7.75\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n34.75\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-8.59\n\n\n\nVariable predicted: total_pr\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\nğŸ¤– Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert fÃ¼r total_pr fÃ¼r einen bestimmten Wert von ship_pr.\n\n\nğŸ§‘â€ğŸ“ Kann ich auch predict benutzen? Ich wÃ¼rde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n\nğŸ¤– Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n\n\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n\nAber nÃ¼tzlich wÃ¤re noch, das Modell (bzw. die SchÃ¤tzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.B. so, s. AbbildungÂ 10.10.\n\nestimate_expectation(lm3) %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heiÃŸt sinngemÃ¤ÃŸ â€œschÃ¤tze den zu erwartenden Wertâ€. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie â€œgutâ€ das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13\n\nDas Modell erklÃ¤rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n\n\nmae(lm3)\n## [1] 13\n\nIm nÃ¤chsten Meeting erzÃ¤hlen Sie Ihrem Chef â€œIch kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!â€. HÃ¶rt sich gut an. Allerdings hÃ¤tte ihr Chef es gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie stellt die PrÃ¼fungsleistung â€œPrognosewettbewerbâ€ einfÃ¼hrend dar. Es empfiehlt sich fÃ¼r Sie, diese Fallstudie sorgsam zu bearbeiten.\\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei Kaggle ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet.\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition Ames House Prices.4\n\n\nBeschreibung5\n\n\nZiel/Aufgabe6\n\n\nSpielregeln7\n\n\n9.8.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.8.3 Daten\nWenn Sie sich nicht bei Kaggle einloggen mÃ¶chten, kÃ¶nnen Sie die Daten von Kaggle herunterladen und zwar hier.\nIm Einzelnen mÃ¼ssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Code book, d.h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von HÃ¤usern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von HÃ¤usern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\nSie kÃ¶nnen auch so auf die Daten zugreifen:\n\nd_train_path_online &lt;- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/\",\n    \"Lehre/main/data/ames-kaggle/train.csv\")\n\nd_test_path_online &lt;- paste0(\n  \"https://raw.githubusercontent.com/sebastiansauer/\",\n  \"Lehre/main/data/ames-kaggle/test.csv\")\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\nDas Code Book kÃ¶nnen Sie hier einsehen und herunterladen.8\n\n9.8.4 Prognosedatei\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthÃ¤lt. Sie soll prinzipiell so aussehen wie in TabelleÂ 9.2 dargestellt.\n\n\n\nTabelleÂ 9.2: Beispiel den Aufbau der Prognose-Datei\n\n\n\n\n\n\nid\nSalePrice\n\n\n\n1461\n169277\n\n\n1462\n187758\n\n\n1463\n183584\n\n\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - fÃ¼r welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice ist Ihre Vorhersage fÃ¼r den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar?\nLos gehtâ€™s!\n\n9.8.5 Daten importieren von der Festplatte\nWir kÃ¶nnen die Daten auch von der Festplatte importieren; oft mÃ¼ssen wir das auch - wenn die Daten nÃ¤mlich nicht Ã¶ffentlich zugreifbar auf einem Server liegen.\n\nd_train_path &lt;- \"daten/ames-kaggle/train.csv\"\nd_test_path &lt;- \"daten/ames-kaggle/test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\nIn diesem Beispiel gehen wir davon aus, dass die Dateien train.csv und test.csv in einem Unterordner namens daten/ames-kaggle liegen. Sie mÃ¼ssen sie dort abspeichern. Dieser Ordner muss ein Unterordner Ihres aktuellen R-Projekts sein.\\(\\square\\)\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn das Importieren von der Festplatte nicht klappt â€¦ Es ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fÃ¼rs Erste kÃ¶nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.\\(\\square\\)\n\n\n\n9.8.6 Ein erster Blick in die Daten\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, TabelleÂ 9.3.\n\ndescribe_distribution(d_train)\n\n\n\n\nTabelleÂ 9.3: Verteilung der metrischen Variablen im ames-Datensatz\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nId\n730.50\n421.61\n730.50\n(1.00, 1460.00)\n0.00\n-1.20\n1460\n0\n\n\nMSSubClass\n56.90\n42.30\n50.00\n(20.00, 190.00)\n1.41\n1.58\n1460\n0\n\n\nLotFrontage\n70.05\n24.28\n21.00\n(21.00, 313.00)\n2.16\n17.45\n1201\n259\n\n\nLotArea\n10516.83\n9981.26\n4060.00\n(1300.00, 2.15e+05)\n12.21\n203.24\n1460\n0\n\n\nOverallQual\n6.10\n1.38\n2.00\n(1.00, 10.00)\n0.22\n0.10\n1460\n0\n\n\nOverallCond\n5.58\n1.11\n1.00\n(1.00, 9.00)\n0.69\n1.11\n1460\n0\n\n\nYearBuilt\n1971.27\n30.20\n46.00\n(1872.00, 2010.00)\n-0.61\n-0.44\n1460\n0\n\n\nYearRemodAdd\n1984.87\n20.65\n37.00\n(1950.00, 2010.00)\n-0.50\n-1.27\n1460\n0\n\n\nMasVnrArea\n103.69\n181.07\n166.00\n(0.00, 1600.00)\n2.67\n10.08\n1452\n8\n\n\nBsmtFinSF1\n443.64\n456.10\n712.75\n(0.00, 5644.00)\n1.69\n11.12\n1460\n0\n\n\nBsmtFinSF2\n46.55\n161.32\n0.00\n(0.00, 1474.00)\n4.26\n20.11\n1460\n0\n\n\nBsmtUnfSF\n567.24\n441.87\n585.00\n(0.00, 2336.00)\n0.92\n0.47\n1460\n0\n\n\nTotalBsmtSF\n1057.43\n438.71\n503.50\n(0.00, 6110.00)\n1.52\n13.25\n1460\n0\n\n\nX1stFlrSF\n1162.63\n386.59\n509.75\n(334.00, 4692.00)\n1.38\n5.75\n1460\n0\n\n\nX2ndFlrSF\n346.99\n436.53\n728.00\n(0.00, 2065.00)\n0.81\n-0.55\n1460\n0\n\n\nLowQualFinSF\n5.84\n48.62\n0.00\n(0.00, 572.00)\n9.01\n83.23\n1460\n0\n\n\nGrLivArea\n1515.46\n525.48\n649.75\n(334.00, 5642.00)\n1.37\n4.90\n1460\n0\n\n\nBsmtFullBath\n0.43\n0.52\n1.00\n(0.00, 3.00)\n0.60\n-0.84\n1460\n0\n\n\nBsmtHalfBath\n0.06\n0.24\n0.00\n(0.00, 2.00)\n4.10\n16.40\n1460\n0\n\n\nFullBath\n1.57\n0.55\n1.00\n(0.00, 3.00)\n0.04\n-0.86\n1460\n0\n\n\nHalfBath\n0.38\n0.50\n1.00\n(0.00, 2.00)\n0.68\n-1.08\n1460\n0\n\n\nBedroomAbvGr\n2.87\n0.82\n1.00\n(0.00, 8.00)\n0.21\n2.23\n1460\n0\n\n\nKitchenAbvGr\n1.05\n0.22\n0.00\n(0.00, 3.00)\n4.49\n21.53\n1460\n0\n\n\nTotRmsAbvGrd\n6.52\n1.63\n2.00\n(2.00, 14.00)\n0.68\n0.88\n1460\n0\n\n\nFireplaces\n0.61\n0.64\n1.00\n(0.00, 3.00)\n0.65\n-0.22\n1460\n0\n\n\nGarageYrBlt\n1978.51\n24.69\n41.00\n(1900.00, 2010.00)\n-0.65\n-0.42\n1379\n81\n\n\nGarageCars\n1.77\n0.75\n1.00\n(0.00, 4.00)\n-0.34\n0.22\n1460\n0\n\n\nGarageArea\n472.98\n213.80\n244.50\n(0.00, 1418.00)\n0.18\n0.92\n1460\n0\n\n\nWoodDeckSF\n94.24\n125.34\n168.00\n(0.00, 857.00)\n1.54\n2.99\n1460\n0\n\n\nOpenPorchSF\n46.66\n66.26\n68.00\n(0.00, 547.00)\n2.36\n8.49\n1460\n0\n\n\nEnclosedPorch\n21.95\n61.12\n0.00\n(0.00, 552.00)\n3.09\n10.43\n1460\n0\n\n\nX3SsnPorch\n3.41\n29.32\n0.00\n(0.00, 508.00)\n10.30\n123.66\n1460\n0\n\n\nScreenPorch\n15.06\n55.76\n0.00\n(0.00, 480.00)\n4.12\n18.44\n1460\n0\n\n\nPoolArea\n2.76\n40.18\n0.00\n(0.00, 738.00)\n14.83\n223.27\n1460\n0\n\n\nMiscVal\n43.49\n496.12\n0.00\n(0.00, 15500.00)\n24.48\n701.00\n1460\n0\n\n\nMoSold\n6.32\n2.70\n3.00\n(1.00, 12.00)\n0.21\n-0.40\n1460\n0\n\n\nYrSold\n2007.82\n1.33\n2.00\n(2006.00, 2010.00)\n0.10\n-1.19\n1460\n0\n\n\nSalePrice\n1.81e+05\n79442.50\n84075.00\n(34900.00, 7.55e+05)\n1.88\n6.54\n1460\n0\n\n\n\n\n\n\n\n\n\n9.8.7 Ein erstes Vorhersagemodell\n\n9.8.7.1 Welche Variablen eignen sich zur Vorhersage?\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller PrÃ¤diktoren mit der abhÃ¤ngigen Variablen9 zu berechnen, s.  ListingÂ 9.2.\n\n\n\nListingÂ 9.2: Welche Variablen korrelieren stÃ¤rker als .3?\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der HÃ¶he des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\n\n\nTabelleÂ 9.4: Korrelation der PrÃ¤diktoren (UV) mit der AV\n\n\n\n\n\n\n\nAha! Ein Menge Information.10\nDiese Variablen sind einigermaÃŸen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n9.8.7.2 Modell 1\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im GroÃŸen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stÃ¤rksten mit der Zielvariable korreliert und ist daher ein guter Kandidat fÃ¼r die Vorhersage.\n\nm1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1458)\np\n\n\n\n(Intercept)\n-96206.08\n5756.41\n(-1.07e+05, -84914.35)\n-16.71\n&lt; .001\n\n\nOverallQual\n45435.80\n920.43\n(43630.29, 47241.31)\n49.36\n&lt; .001\n\n\n\n\n\nWie gut ist das Modell?\n\nrmse(m1)  # aus easystats\n## [1] 48589\n\nIm Schnitt liegen wir 4.54^{4} Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die ModellgÃ¼te:\n\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\n\n9.8.7.3 Model 2\nBerechnen wir als nÃ¤chstes ein Modell mit mehreren UV, m2.\n\n\n\n\n\n\nHinweis\n\n\n\nMann kann mehrere UV (PrÃ¤diktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur â€œals UV nimm UV1 und UV2 und â€¦â€. \\(\\square\\)\n\n\n\nm2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n\nTabelleÂ 9.5 zeigt die Koeffizienten von m2.\n\n\n\nTabelleÂ 9.5: Modellparameter von m1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1456)\np\n\n\n\n(Intercept)\n-98832.49\n4842.90\n(-1.08e+05, -89332.69)\n-20.41\n&lt; .001\n\n\nOverallQual\n27104.83\n1072.18\n(25001.64, 29208.01)\n25.28\n&lt; .001\n\n\nGrLivArea\n50.67\n2.55\n(45.67, 55.68)\n19.86\n&lt; .001\n\n\nGarageCars\n21298.96\n1807.06\n(17754.23, 24843.69)\n11.79\n&lt; .001\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells m2 fÃ¼r die Daten von d_train?\n\nrmse(m2)\n## [1] 40566\n\nIm Schnitt liegen unsere Vorhersagen 2.71^{4} Dollar daneben. Ist das gut?\nBetrachten wir noch \\(R^2\\):\n\nr2(m2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n\n\n\n\n\n\n\nHinweis\n\n\n\nOb die ModellgÃ¼te (R-Quadrat, RMSE, etc.) â€œgutâ€ oder â€œhochâ€ ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen. \\(\\square\\)\n\n\n\n9.8.7.4 Nullmodell\nZum Vergleich berechnen wir das maximal einfache Modell: ohne PrÃ¤diktoren. Man nennt es das â€œNullmodellâ€. In diesem Modell sagen wir fÃ¼r jedes Haus einfach den mittleren Preis aller HÃ¤user vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnomdells?\n\nrmse(m0)\n## [1] 79415\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.8 Vorhersagen im Test-Datensatz mit m2\n\nWir haben jetzt unseren Champion, m2. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample prÃ¤zise sein werden? Oder himmelweit daneben? EnttÃ¤usche uns nicht!\nHier sind die Vorhersagen:\n\nm2_pred &lt;- predict(m2, newdata = d_test)\nhead(m2_pred)\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n\n\n1\n\npredicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus d_test\n\n2\n\nzeige den â€œKopfâ€ der Vorhersagen (m1_pred), d.h. die ersten paar Vorhersagen\n\n\n\n\nDie Vohersagen fÃ¼gen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = m2_pred)\n\n\n9.8.9 Einreichen!\n\n9.8.9.1 Wir brauchen zwei Spalten: Id und SalePrice\n\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhersagen ein.\nFÃ¼r die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten id und SalePrice:\n\nm2_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\nKaggle mÃ¶chte keine fehlenden Werten in den Vorhersagen, also prÃ¼fen wir das mal:\n\nm2_subm %&gt;% \n  drop_na() %&gt;%\n  nrow()\n## [1] 1458\n\n\n1\n\nLass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2\n\nzÃ¤hle die Anzahl der Zeilen (die noch verbleiben)\n\n\n\n\nDie Anzahl der Zeilen, die wir hier erhalten, ist gleich zu den Anzahl der Zeilen von d_test. Es gibt also keine fehlenden Werte.\n\nnrow(d_test)\n## [1] 1459\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.8.9.2 Hochladen\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.11\n\nwrite_csv(m2_subm, \"daten/ames-kaggle/m1-subm.csv\")\n\nUnd dann laden Sie diese Datei, m1_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn.\nDas Modell erzielte einen Score von 0.55521.\n\n9.8.10 Fazit\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele AnsÃ¤tze, dieses Modell zu verbessern.\nHier sind einige Fragen, die Sie sich dazu stellen kÃ¶nnen:\n\nWelche PrÃ¤diktoren sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn ein PrÃ¤diktor schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche PrÃ¤diktoren quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\nâ€¦\n\nViel Spielraum fÃ¼r Ihre KreativitÃ¤t!",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nEine Aufgabe, die eine EinfÃ¼hrung zum Kaggle-Wettbewerb Ames House Prices bietet12, finden Sie im Datenwerk.13\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\n\nSchauen Sie sich die Aufgaben beim Datenwerk an, vor allem die Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff; vielleicht kÃ¶nnen Sie einige Aufgaben nicht lÃ¶sen. Ignorieren Sie einfach diese Aufgaben.\nBeachten Sie die Hinweise zu den Aufgaben.14",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere EinfÃ¼hrung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte EinfÃ¼hrung in Statistik inklusive der Regressionsanalyse findet sich bei Cetinkaya-Rundel & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003)\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMenk. (2014, Juli 29). Linear Regression. https://texample.net/tikz/examples/linear-regression/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csvâ†©ï¸\nDie Daten stehen hier zum Download bereit: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten2.csvâ†©ï¸\nhttps://fomshinyapps.shinyapps.io/KleinsteQuadrate/â†©ï¸\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overviewâ†©ï¸\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/descriptionâ†©ï¸\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluationâ†©ï¸\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rulesâ†©ï¸\n&lt;ttps://github.com/sebastiansauer/Lehre/blob/main/data/ames-kaggle/data_description.txt&gt;â†©ï¸\ndie vorherzusagende Variable, auch Ziel- oder Outcome-Variable genanntâ†©ï¸\nWenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: FÃ¼hren Sie die Syntax schrittweise aus. Zuerst d_train ausfÃ¼hren und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausfÃ¼hren, wieder die Ausgabe betrachten, usw.â†©ï¸\nEs bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfÃ¼gt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.â†©ï¸\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overviewâ†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/posts/ames-kaggle1/ames-kaggle1.htmlâ†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/hinweiseâ†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#lernsteuerung",
    "href": "090-regression2.html#lernsteuerung",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n10.1.2 Lernziele\n\nSie kÃ¶nnen Regressionsmodelle fÃ¼r Forschungsfragen mit binÃ¤rer, nominaler und metrischer UV erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen Interaktionseffekte in Regressionsmodellen erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen Modelle nutzen, um Vorhersagen anhand neuer Daten zu erstellen.\n\n10.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(yardstick)  # fÃ¼r ModellgÃ¼te im Test-Sample\nlibrary(easystats)\nlibrary(ggpubr)  # Daten visualisieren\nlibrary(openintro)  # dataset mariokart\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n10.1.4 BenÃ¶tigte Daten\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD.1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "href": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: GlÃ¤serne Kunden",
    "text": "10.2 Forschungsbezug: GlÃ¤serne Kunden\nLineare Modelle2 sind ein altes, aber mÃ¤chtiges Werkzeug. Sie gehÃ¶ren immernoch zum Standard-Repertoire moderner Analystis.\n\nBeispiel 10.1 (Wie gut kann man Ihre PersÃ¶nlchkeit auf Basis des Facebook-Profils vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Youyou et al. (2015), wie gut PersÃ¶nlichkeitszÃ¼ge durch Facebook-Daten (Likes etc.) vorhergesagt werden kÃ¶nnen. Die Autoren resÃ¼mieren:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten Ã¼ber hohe ModellgÃ¼te (\\(r\\)) zwischen den tatsÃ¤chlichen persÃ¶nlichen Attributen und den vorhergesagten Werten Ihres Modells, s. AbbildungÂ 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also Ã¤hnlich zu dem in diesem Kapitel vorgestellten Methoden.\nNeben der analytischen StÃ¤rke der Regressionsanalyse zeigt das Beispiel auch, wie glÃ¤sern Konsument:innen im Internet sind.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach ewtas Abwechslung. Viel Geld verdienen und Ruhm und Anerkennung sind ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehÃ¶ren, und daher den schnÃ¶den Mammon nicht so hoch schÃ¤tzen sollten. Sie entschlieÃŸen sich, Ihre hochgeschÃ¤tzten Analyse-Skills fÃ¼r etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels. \\(\\square\\)\n\nBeim Deutschen Wetterdienst, DWD haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen resultiert ein schÃ¶ner Datensatz, den Sie jetzt analysieren wollen (Temperatur: Grad Celcius, Niederschlag (precip) mm Niederschlag pro Quadratmeter):\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\nEin Data-Dictionary fÃ¼r den Datensatz kÃ¶nnen Sie hier herunterladen.3\n\n\n\n\n\n\nHinweis\n\n\n\nEin Data-Dictionary (Codebook) erklÃ¤rt einen Datensatz. Oft bedeutet das, das fÃ¼r jede Spalte der Datentabelle erklÃ¤rt wird, was die Spalte bedeutet.\\(\\square\\)\n\n\n\nAbbildungÂ 10.2 zeigen die Wetterdaten animiert.\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celcius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlage (mm) im Verlauf der Jahre\n\n\n\n\n\nVerÃ¤nderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildungÂ 10.2: VerÃ¤nderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\nHervorragend! An die Arbeit!\n\n10.3.1 metrische UV\n\n10.3.1.1 Modell Wetter1\nSie stellen sich nun folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ« Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in TabelleÂ 10.1 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelleÂ 10.1: Modellparameter von lm_wetter1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n-14.25\n1.85\n(-17.87, -10.63)\n-7.71\n&lt; .001\n\n\nyear\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nLaut Ihrem Modell wurde es pro Jahr um 0.01 Grad wÃ¤rmer, pro Jahrzehnt also 0.1 und pro Jahrhundert 1 Grad.\n\nğŸ§‘â€ğŸ“ Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\nğŸ§‘â€ğŸ« Mit der Ruhe, das schauen Sie sich spÃ¤ter an.\n\n\n10.3.1.2 Punkt- vs.Â BereichsschÃ¤tzung\nIn tbl-lm-wetter1 finden sich zwei Arten von Information fÃ¼r den Wert des Achsenabschnitts (b0) und des Regressionsgewichts von year(b1):\n\nPunktschÃ¤tzungen In der Spalte Coefficient sehen Sie den â€œBest-Guessâ€ fÃ¼r den entsprechenden Koeffizienten in der Population. Das is sozusagen der Wert fÃ¼r den sich das Modell festlegen wÃ¼rde, wenn es sonst nichts sagen dÃ¼rfte.\nBereichschÃ¤tzungen Cleverer als PunktschÃ¤tzungen sind BereichsschÃ¤tzungen (IntervallschÃ¤tzungen): Hier wird ein Bereich plausibler Werte fÃ¼r den entsprechenden Wert angegeben. Der â€œBereich plausibler Werteâ€ wird auch als Konfidenzintervall (engl. confidence intervall, CI) bezeichnet. Entsprechend gibt CI_low die Untergrenze des Bereichs plausibler Werte und CI_high die Obergrenze aus. So kÃ¶nnen wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschÃ¤tzt wird.\n\nğŸ’¡ Merke: Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschÃ¤tzt.\n\n10.3.1.3 Modell Wetter1a\nDas Modell lm_wetter1, bzw. die SchÃ¤tzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. AbbildungÂ 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. AbbildungÂ 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. fÃ¼r Niederschlag\n\nAuf dieser Basis erstellen wir ein neues lineares Modell, s. TabelleÂ 10.2.\n\nlm_wetter1a &lt;- lm(temp ~ year, data = wetter_summ)\nparameters(lm_wetter1a)\n\n\n\n\nTabelleÂ 10.2: Modellparameter von lm_wetter1a\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(140)\np\n\n\n\n(Intercept)\n-14.14\n2.70\n(-19.48, -8.79)\n-5.23\n&lt; .001\n\n\nyear\n0.01\n1.38e-03\n(8.86e-03, 0.01)\n8.38\n&lt; .001\n\n\n\n\n\n\n\n\nplot(estimate_relation(lm_wetter1)) \nplot(estimate_relation(lm_wetter1a))\n\n\n\n\n\n\n\n\n\n(a) Jeder Punkt ist ein Tag (viel Overplotting, wenig nÃ¼tzlich)\n\n\n\n\n\n\n\n\n\n(b) Jeder Punkt ist ein Jahr (wetter_summ)\n\n\n\n\n\n\nAbbildungÂ 10.3: Die VerÃ¤nderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD)\n\n\n\nğŸ§‘â€ğŸ“ Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der Y-Wert an der Stelle X=0, s. Kapitel 9.5.\nIn den Wetterdaten wÃ¤re Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extraplieren, ganz ohne dass wir dafÃ¼r Daten haben, s. https://xkcd.com/605/.\n\n\n\n\n\nAbbildungÂ 10.4: Du sollst nicht ein Modell weit auÃŸerhalb seines Datenbereichs extrapolieren\n\n\nSinnvoller ist es da, z.B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezÃ¶ge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn fÃ¼r dieses Jahr haben wir Daten.\nHat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es Ã¼blich, z.B. den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten.\nSo zentriert man eine Verteilung:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist Ã¼brigens 1951:\n\nwetter %&gt;% \n  summarise(mean(year))\n\n\n  \n\n\n\nDie Steigung (d.h. der Regressionskoeffizient fÃ¼r year_c) bleibt unverÃ¤ndert, nur der Achsenabschnitt Ã¤ndert sich, s. TabelleÂ 10.3.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert)\n\n\n\n\nTabelleÂ 10.3: Modellparameter von lm_wetter1_zentriert\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n8.49\n0.04\n(8.42, 8.57)\n219.43\n&lt; .001\n\n\nyear c\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celcius. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\n\n\n\n\n\n\nReferenzwert entspricht Null\n\n\n\nDer Referenzwert bzw. der Wert der Referenzgruppe entspricht dem Y-Wert bei x=0 im Regressionsmodell.\\(\\square\\)\n\n\nWie gut erklÃ¤rt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklÃ¤rt das Modell mit year_c aber nicht. (year und year_c sind gleich stark mit temp korreliert, daher wird sich die ModellgÃ¼te nicht unterscheiden.). Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.B. die Jahreszeit eine groÃŸe Rolle fÃ¼r die Temperatur. Das haben wir nicht berÃ¼cksichtigt.\n\nğŸ§‘â€ğŸ“ Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##   1 \n## 9.7\n\n\nğŸ§‘â€ğŸ“ Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5Â° Celcius.4\n\n\nğŸ§‘â€ğŸ« Wir brauchen ein besseres Modell! Zum GlÃ¼ck haben wir ambitionierte Nachwuchs-Wissenschaftler:innen.\n\nDie VerÃ¤nderung der auf fÃ¼nf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in AbbildungÂ 10.5 dargestellt. Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)5; rechts eine feinere (Daten ab 1881)6.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020 (Earth, 2021)\n\n\n\nAbbildungÂ 10.5: \n\n\n10.3.3 BinÃ¤re UV\n\nDefinition 10.1 (BinÃ¤re Variable) Eine binÃ¤re UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei AusprÃ¤gungen: 0 und 1.\\(\\square\\)\n\n\nBeispiel 10.3 (BinÃ¤re Variablen) Das sind zum Beispiel weiblich mit den AusprÃ¤gungen 0 (nein) und 1 (ja) oder before_1950 mit 1 fÃ¼r Jahre frÃ¼her als 1950 und 0 ansonsten.\\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ“ Ob es in der zweiten HÃ¤lfte des 20. Jahrhunderts wohl wÃ¤rmer warm, im Durchschnitt, als vorher?\\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite HÃ¤lfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Ãœberlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.7.4) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prÃ¼fe ob as Jahr grÃ¶ÃŸer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht grÃ¶ÃŸer als 1950, das dritte schon.\nJa, so kÃ¶nnte das klappen! Diese Syntax Ã¼bertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten fÃ¼r Gesamt-Deutschland\n\nScheint zu klappen!\nJetzt ein lineares Modell dazu berechnen:\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\nDie Parameter des Modells lassen darauf schlieÃŸen, dass es tatsÃ¤chlich wÃ¤rmer war nach 1950, und zwar im Schnitt offenbar ein gutes halbes Grad, s. AbbildungÂ 10.6.\n\n\n\n\n\n\nDer SchÃ¤tzbereich fÃ¼r den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied\n\n\n\n\n\nWie man sieht, Ã¼berlappen die Temperaturen dennoch betrÃ¤chtlich; aufgrund des starken Overplotting ist dieses Diagramm alles andere als ideal\n\n\n\n\n\nAbbildungÂ 10.6: Modell temp ~ after_1950\n\n\nLeider zeigt ein Blick zum r2, dass die VorhersagegÃ¼te des Modells zu wÃ¼nschen Ã¼brig lÃ¤sst7. \\(\\square\\)\n\n\n\n\n\n\nLineare Modelle verkraften nur metrische Variablen\n\n\n\nUm die Koeffizienten eines linearen Modells auszurechnen, benÃ¶tigt man eine metrische X- und eine metrische Y-Variable. Hier haben wir aber keine richtige metrische X-Variable8, sondern eine logische Variable mit den Werten TRUE und FALSE.\\(\\square\\)\n\n\nUm die X-Variable in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R fÃ¼r uns ohne viel AnkÃ¼ndigung durchfÃ¼hrt: Umwandling in mehrere binÃ¤re Variablen.\nHat ein nominaler PrÃ¤diktor zwei Stufen, so Ã¼berfÃ¼hrt (synonym: transformiert) lm() diese Variable in eine binÃ¤re Variable. Da eine binÃ¤re Variable metrisch ist, kann die Regression in gewohnter Weise durchgefÃ¼hrt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binÃ¤re Variable. Man beachte, dass der ursprÃ¼ngliche Datensatz nicht geÃ¤ndert wird, nur wÃ¤hrend der Analyse von lm wird die Umwandlung der Variable 9 durchgefÃ¼hrt.\n\nğŸ¤– Eine 1 kannst du als â€œJa! Richtig!â€ verstehen und eine0 als â€œNein! Falsch!â€\n\nafter_1950 wird in eine Indikatorvariable umgewandelt:\n\n\n\n\n\n\n\n\n\n\nid\nafter_1950\n\n\n\n1\nTRUE\n\n\n2\nFALSE\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\nafter_1950TRUE\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\n\nBeispiel 10.5 (Beispiel: â€˜Geschlechtâ€™ in eine binÃ¤re Variable umwandeln.) Angenommen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umwandeln. Da â€œFrauâ€ alphabetisch vor â€œMannâ€ kommt, nimmt R â€œFrauâ€ als erste Stufe bzw. als Referenzgruppe. â€œMannâ€ ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann).\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\nEin lineares Modell mit binÃ¤rer UV ist nichts anderes die Differenz der Gruppenmittelwerte zu berechnen:\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n  \n\n\n\nDie Interpretation eines linearen Modells mit binÃ¤rer UV veranschaulicht AbbildungÂ 10.7: Der Achsenabschnitt (b0) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (AbbildungÂ 10.7 zeigt nur die Daten fÃ¼r den Monat Juli im Bundesland Bayern, der Einfachheit und Ãœbersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildungÂ 10.7: Sinnbild zur Interpretation eines linearen Modells mit binÃ¤rer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten fÃ¼r das Modell mit binÃ¤rer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (b0)\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (b0) + Steigung der Regressionsgeraden (b1)\n\n\nFÃ¼r die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\nFÃ¼r die Modellwerte \\({\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\({\\hat{y}} = {\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\({\\hat{y}} = {\\beta_0} + {\\beta_1}= {17.7} + {0.6} = 18.3\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nBei nominalen (und auch bei binÃ¤ren) Variablen ist \\({\\beta_1}\\) ein Schalter; bei metrischen Variablen ein Dimmer.10 \\(\\square\\)\n\n\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineare Modell )fÃ¼r uns synonym: Regressionsmodell) mit einer mehrstufigen (nominalskalierten) UV. So ein Modell ist von den Ergebnissen her praktisch identisch zu einer einfachen Varianzanalyse.\n\nBeispiel 10.6 Ob es wohl substanzielle (wie kÃ¶nnte man dieses Wort eigentlich definieren) Temperaturunterschiede zwischen den BundeslÃ¤ndern gibt?\n\nBefragen wir dazu ein lineares Modell, s. TabelleÂ 10.4.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\nparameters(lm_wetter_region)\n\n\n\n\nTabelleÂ 10.4: Modellparameter fÃ¼r lm_wetter_region\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27152)\np\n\n\n\n(Intercept)\n8.25\n0.16\n(7.93, 8.56)\n51.62\n&lt; .001\n\n\nregion (Bayern)\n-0.63\n0.23\n(-1.07, -0.19)\n-2.79\n0.005\n\n\nregion (Brandenburg)\n0.57\n0.23\n(0.13, 1.02)\n2.53\n0.011\n\n\nregion (Brandenburg/Berlin)\n0.58\n0.23\n(0.14, 1.03)\n2.59\n0.010\n\n\nregion (Hessen)\n0.11\n0.23\n(-0.33, 0.56)\n0.51\n0.612\n\n\nregion (Mecklenburg-Vorpommern)\n0.08\n0.23\n(-0.37, 0.52)\n0.34\n0.732\n\n\nregion (Niedersachsen)\n0.52\n0.23\n(0.07, 0.96)\n2.29\n0.022\n\n\nregion (Niedersachsen/Hamburg/Bremen)\n0.52\n0.23\n(0.08, 0.96)\n2.31\n0.021\n\n\nregion (Nordrhein-Westfalen)\n0.80\n0.23\n(0.35, 1.24)\n3.53\n&lt; .001\n\n\nregion (Rheinland-Pfalz)\n0.46\n0.23\n(0.02, 0.90)\n2.03\n0.042\n\n\nregion (Saarland)\n0.71\n0.23\n(0.27, 1.16)\n3.16\n0.002\n\n\nregion (Sachsen)\n-0.04\n0.23\n(-0.48, 0.40)\n-0.18\n0.853\n\n\nregion (Sachsen-Anhalt)\n0.55\n0.23\n(0.11, 1.00)\n2.45\n0.014\n\n\nregion (Schleswig-Holstein)\n0.17\n0.23\n(-0.27, 0.62)\n0.76\n0.446\n\n\nregion (Thueringen)\n-0.48\n0.23\n(-0.92, -0.03)\n-2.11\n0.035\n\n\nregion (Thueringen/Sachsen-Anhalt)\n0.10\n0.23\n(-0.34, 0.54)\n0.43\n0.664\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariablen um. Genauer gesagt ist es immer eine Indikatorvariablen weniger als es Stufen in der nominalskalierten Variablen gibt.\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland â€“ aus GrÃ¼nden der Einfachheit hier nur mit drei BundeslÃ¤ndern. Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt:\n\n\n\n\n\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWÃ¼\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\n \n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\n\nAuch im Fall mehrerer AusprÃ¤gungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binÃ¤ren Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 1. Regressionsgeraden (b1)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 2. Regressionsgeraden (b2)\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts ausgewÃ¤hlt wurde) nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.\n\n\n\n\n\n\nHinweis\n\n\n\nBei einer Variable vom Typ character wÃ¤hlt R den alphabetisch ersten Wert als Referenzgruppe fÃ¼r ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. \\(\\square\\)\n\n\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-WÃ¼rttemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewÃ¤hlt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird.\\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. AbbildungÂ 10.8.\n\n\n\n\n\n\n\nAbbildungÂ 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). Die Achsen wurden um 90Â° gedreht, damit man die Namen der BundeslÃ¤nder besser lessen kann.\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht auÃŸer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechnen!\n\nğŸ¤– Endlich gehtâ€™s weiter! Ergebnisse in TabelleÂ 10.5! \\(\\square\\)\n\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelleÂ 10.5: Modellparameter fÃ¼r lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschied im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. AbbildungÂ 10.9, links.11 Oh nein: R betrachtet month als numerische Variable! Aber â€œMonatâ€ bzw. â€œJahreszeitâ€ sollte nominal sein.\n\nğŸ¤– Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\nğŸ‘© Okay, R, wir mÃ¼ssen month in eine nominale Zahl transformieren. Wie geht das?\n\n\nğŸ¤– Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heiÃŸt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau.\\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. TabelleÂ 10.6.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor)\n\n\n\n\nTabelleÂ 10.6: Modellparameter von lm_wetter_month_factor\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27156)\np\n\n\n\n(Intercept)\n56.95\n0.64\n(55.68, 58.21)\n88.56\n&lt; .001\n\n\nmonth factor (2)\n-9.95\n0.91\n(-11.73, -8.17)\n-10.94\n&lt; .001\n\n\nmonth factor (3)\n-7.78\n0.91\n(-9.56, -6.00)\n-8.56\n&lt; .001\n\n\nmonth factor (4)\n-8.49\n0.91\n(-10.27, -6.71)\n-9.34\n&lt; .001\n\n\nmonth factor (5)\n4.74\n0.91\n(2.96, 6.53)\n5.22\n&lt; .001\n\n\nmonth factor (6)\n14.34\n0.91\n(12.56, 16.12)\n15.77\n&lt; .001\n\n\nmonth factor (7)\n24.36\n0.91\n(22.57, 26.14)\n26.74\n&lt; .001\n\n\nmonth factor (8)\n17.52\n0.91\n(15.74, 19.31)\n19.24\n&lt; .001\n\n\nmonth factor (9)\n1.93\n0.91\n(0.15, 3.72)\n2.12\n0.034\n\n\nmonth factor (10)\n2.29\n0.91\n(0.51, 4.08)\n2.52\n0.012\n\n\nmonth factor (11)\n0.89\n0.91\n(-0.89, 2.68)\n0.98\n0.327\n\n\nmonth factor (12)\n5.20\n0.91\n(3.42, 6.99)\n5.71\n&lt; .001\n\n\n\n\n\n\n\n\nSehr schÃ¶n! Jetzt haben wir eine Referenzgruppe (Monat 1, d.h. Januar) und 11 Unterschiede zum Januar, s. AbbildungÂ 10.9, rechts.\n\n\n\n\n\n\nlm_wetter_month, Monat fÃ¤lschlich als metrische Variable\n\n\n\n\n\nlm_wetter_month_text, Monat korrekt als nominale Variable (aber mit viel Overplotting, das mÃ¼sste man besser machen)\n\n\n\n\n\nAbbildungÂ 10.9: Niederschlagsunterschiede pro Monat (ein Punkt ist ein Jahr); aufgrund der vielen Datenpunkte ist das Diagramm wenig Ã¼bersichtlich (Overplotting).\n\n\nMÃ¶chte man die Referenzgruppe eines Faktors Ã¤ndern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geÃ¤nderte Reihenfolge aus:12\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 BinÃ¤re plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binÃ¤ren) UV plus einer metrischen UV.13\n\nBeispiel 10.12 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\nğŸ§‘â€ğŸ« Ich muss mal kurz auf eine Sache hinweisenâ€¦\n\n\n\n\n\n\n\nFaktorvariable\n\n\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich fÃ¼r nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten AusprÃ¤gungen (â€œFaktorstufenâ€) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht.\nDas kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche AusprÃ¤gungen in Ihrer Variable mÃ¶glich sind.\\(\\square\\)\n\n\n\nBeispiel 10.10 (Beispiel fÃ¼r eine Faktorvariable) Â \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\n\nBeispiel 10.11 (Filtern verÃ¤ndert die Faktorstufen nicht) Wenn Sie von der Faktorvariablen14 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.B. nur die ersten beiden Elemente Ã¼brig bleiben mit allein der AusprÃ¤gung \"f\", merkt sich R trotzdem, dass es zwei Faktorstufen gibt (\"f\" und \"m\").\nGenaus so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. MÃ¶chten Sie die herausgefilterten Faktorstufen â€œlÃ¶schenâ€, so kÃ¶nnen Sie einfach die Faktorvariable neu berechnen (mit factor).\\(\\square\\)\n\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  # Faktor (und damit die Faktorstufen) neu berechnen:\n  mutate(month_factor = factor(month))\n\nOkay. Wie spezifiziert man jetzt das lineare Modell?\\(\\square\\)\n\nHat man mehrere (â€œmultipleâ€) X-Variablen (PrÃ¤diktoren, unabhÃ¤ngige Variablen, X-Variablen), so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.B. temp ~ year_c + month.\n\n\n\n\n\n\nMultiple Regression\n\n\n\nEine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y ~ x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\n\nDie VerÃ¤nderung der monatlichen Temperatur (10-Jahres-Mittel) ist in AbbildungÂ 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schÃ¶ner aus).\n\n\n\n\n\n\nModellgleichung\n\n\n\nDas Pluszeichen hat in der Modellgleichung15 keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur â€œund noch folgende UVâ€¦â€.\\(\\square\\)\n\n\nDie obige Modellgleichung liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, data = wetter_month_1_7)\n\nDie Modellparameter sind in TabelleÂ 10.7 zu sehen.\n\n\n\nTabelleÂ 10.7: Modellparameter von lm_year_month\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4525)\np\n\n\n\n(Intercept)\n56.94\n0.68\n(55.60, 58.27)\n83.57\n&lt; .001\n\n\nyear c\n0.03\n0.01\n(5.59e-03, 0.05)\n2.43\n0.015\n\n\nmonth factor (7)\n24.37\n0.97\n(22.48, 26.27)\n25.25\n&lt; .001\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (b0, (Intercept)): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57 mm pro Quadratmeter.\nRegressionskoeffizient fÃ¼r Jahr (b1, year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.02 mm an (im Referenzmonat).\nRegressionskoeffizient fÃ¼r Monat (b2, month [7]) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25 mm Ã¼ber dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7.\nIm Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0.\n\nğŸ§‘â€ğŸ“ Puh, kompliziert!\n\n\nğŸ§‘â€ğŸ« Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. BeispielÂ 10.13.\n\n\nBeispiel 10.13 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag fÃ¼r Januar im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"1\"))\npredict(lm_year_month, newdata = neue_daten)\n##  1 \n## 59\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nAlle Regressionskoeffizienten beziehen sich auf den Y-Wert unter der Annahme, dass alle Ã¼brigen PrÃ¤diktoren den Wert Null (bzw. Referenzwert) aufweisen.\\(\\square\\)\n\n\nVisualisieren wir uns die geschÃ¤tzten Erwartungswert pro PrÃ¤diktorwert, s. AbbildungÂ 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildungÂ 10.10: Temperaturverlauf Ã¼ber die Jahre fÃ¼r zwei Monate. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von (Okabe & Ito, 2023) ersetzt16. Das ist nicht unbedingt nÃ¶tig, aber robuster bei Schwarz-WeiÃŸ-Druck und bei SehschwÃ¤chen, vgl. Kapitel 5.9.3.\nDie erklÃ¤rte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht wÃ¼rden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dÃ¼rfen?\nNicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. ListingÂ 10.1.\n\n\n\nListingÂ 10.1: Ein Interaktionsmodell spezifiziert man in dieser Art: y ~ x1 + x2 + x1:x2\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\n\n\n\nVisualisiert ist das Modell in AbbildungÂ 10.11.\n\nplot(estimate_expectation(lm_year_month_interaktion)) +\n  scale_color_okabeito()  # schÃ¶nes Farbschema\n\n\n\n\n\n\n\n\nAbbildungÂ 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die VerÃ¤nderung im Verlauf der Jahre ist unterschiedlich fÃ¼r die Monate (Janur vs.Â Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator (:) fÃ¼gt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\n\n\n\n\n\nWichtig\n\n\n\nEinen Interaktionseffekt von x1 und x2 kennzeichnet man in R mit dem Doppelpunkt-Operator, x1:x2:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\n\nIn Worten:\n\ny wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.\n\nWie man in AbbildungÂ 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel.\n\n\n\n\n\n\nHinweis\n\n\n\nSind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor.\\(\\square\\)\n\n\n\nBeispiel 10.14 (Interaktionseffekt von Niederschlag und Monat) Wie ist die VerÃ¤nderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich fÃ¼r die Monate: Im Juli nahm der Niederschlag ab, im Januar zu.\\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von â€œdemâ€ (statistischen) Effekt eines PrÃ¤diktors (afu die Y-Variable) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.B. Monat) unterscheidet der Effekt. (â€œEffektâ€ ist hier immer statistisch, nie kausal gemeint.)\nBetrachten wir die Parameterwerte des Interaktionsmodells (parameters(lm_year_month_interaktion)), s. TabelleÂ 10.8.\n\n\n\nTabelleÂ 10.8: Modellparameter von lm_year_month_interaktion\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4524)\np\n\n\n\n(Intercept)\n56.91\n0.68\n(55.59, 58.24)\n84.21\n&lt; .001\n\n\nyear c\n0.13\n0.02\n(0.10, 0.16)\n7.80\n&lt; .001\n\n\nmonth factor (7)\n24.37\n0.96\n(22.50, 26.25)\n25.45\n&lt; .001\n\n\nyear c Ã— month factor (7)\n-0.20\n0.02\n(-0.25, -0.16)\n-8.62\n&lt; .001\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die Zeile year c Ã— month factor [7]. Sie gibt die StÃ¤rke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre Ã¤ndert: Im Monat \"7\" ist der Effekt von year_c um 0.20 mm geringer: Die Regressionsgerade neigt sich mehr nach â€œuntenâ€ im Monat Juli, da der Koeffizient kleiner als Null ist.\nDie Regressionsgleichung lautet: precip_pred = 56.91 + 0.13*year_c + 24.37*month_factor_7 - 0.20*year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert fÃ¼r Y an unter der Annahme, dass alle PrÃ¤diktoren den Wert Null aufweisen. In diesem Fall gibt der Achsenabschnitt also den Niederschlag fÃ¼r den Janur des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in Y an, wenn der jeweilige PrÃ¤diktorwert um 1 steigt, die Ã¼brigen PrÃ¤diktoren aber den Wert 0 aufweisen.\\(\\square\\)\n\n\nDas R-Quadrat von lm_year_month_interaktion betrÃ¤gt Ã¼brigens nur geringfÃ¼gig mehr als im Modell ohne Interaktion:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. AbbildungÂ 10.12. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n3D-Animation\n3D-Diagramme fÃ¼r Modelle mit zwei PrÃ¤diktoren\n2D-Diagramm fÃ¼r 3D-Modell\n\n\n\n\n\n\n\n\n(a) Animation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklÃ¤rt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.12\n\n\nGrundsÃ¤tzlich kann man viele PrÃ¤diktoren in ein (lineares) Modell aufnehmen. Betrachten wir z.â€‰B. folgendes lineares Modell mit zwei metrischen UV.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\nAbbildungÂ 10.13 visualisiert das Modell lm_mario2v in einem 3D-Diagramm.\n\n\n\n\n\n\n\nAbbildungÂ 10.13: Das Modell lm_mario2v mit 2 metrischen UV (und 1 metrische AV) als 3D-Diagramm\n\n\n\nJedes der beiden Regressionsgewichte in lm_mario_2uv entspricht der Steigung in der beiden Achsen in AbbildungÂ 10.13, d.h. die Steigung fÃ¼r start_pr bzw. die Steigung fÃ¼r ship_pr.\n\n10.4.2 Viele UV ins Modell?\nWir kÃ¶nnten im Prinzip alle Variablen unserer Datentabelle als PrÃ¤diktoren in das Regressionsmodell aufnehmen. Die Frage ist nur: Macht das Sinn?\nHier sind einige Richtlinien, die helfen, welche PrÃ¤diktoren (und wie viele) man in ein Modell aufnehmen sollte (Gelman et al., 2021), s. S. 199:\n\nMan sollte alle PrÃ¤diktoren aufnehmen, von denen anzunehmen ist, dass Sie Ursachen fÃ¼r die Zielvariablen sind\nBei PrÃ¤diktoren mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen\nPrÃ¤diktoren mit kleinem SchÃ¤tzbereich (95 CI) sollten tendenziell im Modell belassen werden, da sie die ModellgÃ¼te verbessern",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.15 (Prognose des Verkaufspreis) Ganz kÃ¶nnen Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen mÃ¶glichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld.\\(\\square\\)\n\n\n10.5.1 Modell â€œall-inâ€\nUm die GÃ¼te Ihrer Vorhersagen zu prÃ¼fen, teilt Ihr Chef den Datensatz in zwei zufÃ¤llige Teile.\n\nğŸ§”â€â™‚ï¸ Ich teile den Datensatz mariokart zufÃ¤llig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (â€œtrainierenâ€) und ihre GÃ¼te zu prÃ¼fen. Den Teil nenne ich â€œTrainingssampleâ€, hÃ¶rt sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die GÃ¼te deiner Vorhersagen in dem verbleibenden Teil, die Ã¼brigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten auf Ihrer Festplatte liegen, z.B. im Unterordner daten, dann kÃ¶nne Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"daten/mariokart_train.csv\")\n\nAlternativ kÃ¶nnen Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die â€œAll-in-Strategieâ€: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.979\n\nDer Punkt in total_pr ~ . heiÃŸt â€œalle Variablen in der Tabelle (auÃŸer total_pr)â€.\n\nğŸ‘´ Hey! Das ist ja fast perfekte ModellgÃ¼te!\n\n\nğŸ¦¹â€â™€ï¸ï¸ Vorsicht: Wenn ein Angebot aussieht wie â€œtoo good to be trueâ€, dann ist es meist auch too good to be true.\n\n\n\n\n\n\n\nOverfitting\n\n\n\nDer Grund fÃ¼r den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. WeiÃŸ man, welcher Titel zu welcher Auktion gehÃ¶rt, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nÃ¼tzen die Titel der Auktionen im Train-Sample nichts fÃ¼r andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stÃ¼tzen. Merke: HÃ¶chst idiografische Informationen wie Namen, Titel etc. sind nicht nÃ¼tzlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\\(\\square\\)\n\n\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in eval(predvars, data, env): object 'V1' not found\n\nOh nein! Was ist los!? Eine Fehlermeldung!\n\n\n\n\n\n\nVorsicht\n\n\n\nNominalskalierte PrÃ¤diktorvariablen mit vielen AusprÃ¤gungen, wie title sind problematisch. Kommt eine AusprÃ¤gung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. HÃ¤ufig ist es sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting fÃ¼hren.\\(\\square\\)\n\n\n\n10.5.2 Modell â€œall-inâ€, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. NÃ¤chster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, V1, id))\n\nWir entfernen auch die Spalte V1 und id, da sie ebenfalls keine Informationen bergen.\n\nlm_allin_no_title &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist ja durchaus ordentlich. Schauen wir uns noch den rmse (die SD der Vorhersagefehler) an17:\n\nğŸ¤– Gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title)\n## [1] 20\n\n\n\n\n\n\n\nName Clash\n\n\n\nIm Paket yardstick gibt es eine Funktion namens rmse und im Paket performance, Teil des Meta-Pakets easystats ebenfalls. Da sind Probleme vorprogrammiert. Das ist so als wÃ¼rde die Lehrerin rufen: â€œSchorsch, komm her!â€. Dabei gibt es zwei Schorsche in der Klasse: Den MÃ¼llers Schorsch und den Meiers Schorsch. Sonst kommen beide, was die Lehrerin nicht will. Die Lehrerin mÃ¼sste also rufen: â€œMÃ¼ller Schorsch, komm her!â€. Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den â€œNachnamenâ€ des Befehls: paketname::funktion ist wie MÃ¼ller::Schorsch. In unserem Fall also: performance::rmse Endlich weiÃŸ R wieder, was zu tun ist!\\(\\square\\)\n\n\nSie rennen zu Ihrem Chef, der jetzt die GÃ¼te Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\nğŸ‘´ Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das â€œTest-Sampleâ€.\n\nIhr Chef schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n  \n\n\n\n\nğŸ‘´ï¸ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nHier sind Ihre Vorhersagen18:\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title, newdata = mariokart_test)\n\nHier sind Ihre ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##  1  2  3  4  5  6 \n## 29 54 53 54 42 47\n\nDies Vorhersagen fÃ¼gen wir noch der Ordnung halber in die Tabelle mit den Test-Daten:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title, newdata = mariokart_test))\n\nOkay, was ist jetzt der mittlere Vorhersagefehler?\nUm die VorhersagegÃ¼te im Test-Sample auszurechnen19, nutzen wir die Funktionen des R-Paketes yardstick20:\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nmae\nstandard\n10\n\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrmse\nstandard\n13\n\n\n\n\nIhr mittlerer Vorhersagefehler (RMSE) liegt bei ca. 13 Euro.^[Wir haben hier yardstick::rmse geschrieben und nicht nur rmse, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens rmse gibt. Name-Clash-Alarm! R kÃ¶nnte daher den anderen `rmse`` meinen als Sie, was garantiert zu Verwirrung fÃ¼hrt.21\n\nğŸ‘´ Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrsq\nstandard\n0.17\n\n\n\n\n\nğŸ‘´ï¸ 17%, nicht berauschend, aber immerhin!\n\n\n\n\n\n\n\nModellgÃ¼te im Test-Sample meist geringer als im Train-Sample\n\n\n\nWie das Beispiel zeigt, ist die ModellgÃ¼te im Test-Sample (leider) oft geringer als im Train-Sample. Die ModellgÃ¼te im Train-Sample ist mitunter Ã¼bermÃ¤ÃŸig optimistisch. Dieses PhÃ¤nomen bezeichnet man als Overfitting.\\(\\square\\)\n\n\n\n\n\n\n\n\nTipp\n\n\n\nBevor man Vorhersagen eines Modells einreicht, bietet es sich, die ModellgÃ¼te in einem neuen Datensatz, als einem Test-Sample, zu Ã¼berprÃ¼fen.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste SchÃ¤tzung der GÃ¼te Ihres Modells erfahren mÃ¶chten, bietet sich folgendes Vorgehen an (vgl. AbbildungÂ 10.14):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrÃ¼fen Sie die ModellgÃ¼te im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie kÃ¶nnen sie z.B. so bewerkstelligen:\n\nlibrary(rsample)\nmariokart &lt;- read_csv(\"daten/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"daten\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split bestimmt fÃ¼r jede Zeile (Beobachtung) zufÃ¤llig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt22; das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafÃ¼r, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wÃ¤re nÃ¤mlich blÃ¶d fÃ¼r Ihr Modell, wenn im Train-Sample z.B. nur die teuren, und im Test-Sample nur die gÃ¼nstigen Spiele landen wÃ¼rde.23 In so einem Fall wÃ¼rde sich Ihr Modell unnÃ¶tig schwer tun.\nIm nÃ¤chsten Schritt kÃ¶nnen Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsÃ¤chlich aufteilen.24\n\nmariokart_train &lt;- \n  training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- \n  testing(meine_aufteilung)  # Assessment-Sample\n\nIch persÃ¶nliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kÃ¼rzer zu tippen und einheitlich. Sie kÃ¶nnen aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, auÃŸerdem KÃ¼rze und aussagekrÃ¤ftige Namen.\n\n10.6.2 Train- vs.Â Test-Sample\n\nDefinition 10.2 (Trainsample) Den Datensatz, fÃ¼r die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\nDas Train-Sample stellt die bekannten Daten dar; aus denen kÃ¶nnen wir lernen, d.h. unser Modell berechnen.\n\nDefinition 10.3 (Testsample) Den Datensatz, fÃ¼r den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\nDas Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiÃŸ, was der Wert der AV ist.\nDer Zusammenhang dieser verschiedenen, aber zusammengehÃ¶rigen Arten von Stichproben ist in AbbildungÂ 10.14 dargestellt.\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildungÂ 10.14: Verschiedene Arten von zusammengehÃ¶rigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden â€œabwanderungsgefÃ¤hrdetâ€ sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (â€œcustomer churnâ€). Es gibt eine ganze Reihe von Untersuchungen dazu, z.B. die von Lalwani et al. (2022). Die Forschis versuchen anhand von Daten und u.a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von Ã¼ber 80% in Ihrem (besten) Vorhersagemodell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lÃ¼gt",
    "text": "10.8 Wie man mit Statistik lÃ¼gt\n\n10.8.1 Pinguine drehen durch\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von SchnabellÃ¤nge (bill length) und Schnabeltiefe (bill depth) interessiert, s. AbbildungÂ 10.15.\n\n\n\n\n\nAbbildungÂ 10.15: SchnabellÃ¤nge und Schnabeltiefe\n\n\nDas Team hat in schweiÃŸtreibender eiszapfentreibender Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und Ã¼berlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von SchnabellÃ¤nge und Schnabeltiefe. Das kÃ¶nnte einen Nobelpreis wert sein. Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")  # aus `ggpubr`\n\n\n\n\n\n\n\nHier sind die statistischen Details, s. TabelleÂ 10.9.\n\nlm1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelleÂ 10.9: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(340)\np\n\n\n\n(Intercept)\n20.89\n0.84\n(19.23, 22.55)\n24.75\n&lt; .001\n\n\nbill length mm\n-0.09\n0.02\n(-0.12, -0.05)\n-4.46\n&lt; .001\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf verÃ¶ffentlicht eine verfeindete Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von SchnabelllÃ¤nge und Schnabeltiefe.\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\", color = \"species\")\n\n\n\n\n\n\n\nOh nein! Was ist hier nur los? Daten lÃ¼gen nicht, oder doch?\nHier sind die statistischen Details der zweiten Analyse, s. TabelleÂ 10.10. Im zweiten Modell kam species als zweiter PrÃ¤diktor neu ins Modell (zusÃ¤tlzich zur SchnabellÃ¤nge).\n\nlm2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelleÂ 10.10: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(338)\np\n\n\n\n(Intercept)\n10.59\n0.68\n(9.25, 11.94)\n15.51\n&lt; .001\n\n\nbill length mm\n0.20\n0.02\n(0.17, 0.23)\n11.43\n&lt; .001\n\n\nspecies (Chinstrap)\n-1.93\n0.22\n(-2.37, -1.49)\n-8.62\n&lt; .001\n\n\nspecies (Gentoo)\n-5.11\n0.19\n(-5.48, -4.73)\n-26.67\n&lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaten alleine reichen nicht\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse â€“ Gesamtdaten oder Subgruppen â€“ die richtige ist. Nicht-exprimentelle Studien kÃ¶nnen zu grundverschiedenen Ergebnissen fÃ¼hren, je nachdem ob PrÃ¤diktoren dem Modell hinzugefÃ¼gt oder weggenommen werden. \\(\\square\\)\n\n\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere nie Modellkoeffizienten kausal ohne ein Kausalmodell.\\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lÃ¤sst man besser die Finger von der Interpretation der Modellkoeffizienten und begnÃ¼gt sich mit der Beschreibung der ModellgÃ¼te und mit Vorhersage25. Wer das nicht glaubt, der betrachte AbbildungÂ 10.16, links.26 Ei Forschi stellt das Modell m1: y ~ x auf und interpretiert dann b1: â€œIst ja klar, X hat einen starken positiven Effekt auf Y!â€.\nIn der nÃ¤chsten Studie nimmt dis Forschi dann eine zweite Variable, group (z.B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. AbbildungÂ 10.16, rechts!\nDieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt â€œechtâ€, also kausal, ist. Handelt es sich aber um â€œnicht echteâ€, also nicht-kausale ZusammenhÃ¤nge, um ScheinzusammenhÃ¤nge also, so kÃ¶nnen sich die Modellkoeffizienten dramatisch verÃ¤ndern (sogar das Vorzeichen kann wechseln27), wenn man das Modell verÃ¤ndert, also Variablen hinzufÃ¼gt oder aus dem Modell entfernt.\nWenn man die kausalen AbhÃ¤ngigkeiten nicht kennt, weiÃŸ man also nicht, ob die ZusammenhÃ¤nge kausal oder nicht-kausal sind. Man weiÃŸ also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker Zusammenhang; b1 ist stark positiv\n\n\n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, in jeder der beiden Gruppen ist der Zusammenhang praktisch Null, b1 = 0\n\n\n\n\n\n\nAbbildungÂ 10.16: FÃ¼gt man in ein Modell eine Variable hinzu, kÃ¶nnen sich die Koeffizienten massiv Ã¤ndern. In beiden Diagrammen wurden die gleichen Daten verwendet.\n\n\nMan kÃ¶nnte hÃ¶chstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.B. â€œDort wo es viele StÃ¶rche gibt, gibt es auch viele Babiesâ€.28 Leider ist unser Gehirn auf kausale ZusammenhÃ¤nge geprÃ¤gt: Es fÃ¤llt uns schwer, ZusammenhÃ¤nge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulÃ¤ssig kausal interpretiert â€“ von Laien und Wissenschaftlern auch.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fazit",
    "href": "090-regression2.html#fazit",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.9 Fazit",
    "text": "10.9 Fazit\nIn diesem Kapitel haben Sie lineare Modelle gelernt, die Ã¼ber einfache Modelle der Art y ~ x hinausgehen. Dazu gehÃ¶ren multiple Modelle, das sind Modelle mit mehr als einer UV (PrÃ¤diktor) und auch Interaktionsmodelle. AuÃŸerdem haben Sie sich mit einem Datensatz von gesamtgesellschaftlichen Nutzen beschÃ¤ftigt â€“ sehr schÃ¶n. Das Fallbeispiel zum Schluss war vielleicht erhellend insofern, als dass ein gutes Modell im Train-Sample nicht (notwendig) zu guten Vorhersagen im Test-Sample fÃ¼hrt.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. AbbildungÂ 10.17. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) So ging es Ihnen gestern\n\n\n\n\n\n\n\n\n\n(b) So wird es Ihnen morgen ergehen, wenn Sie dran bleiben\n\n\n\n\n\n\nAbbildungÂ 10.17: Statistik, Sie und Party: Gestern und (vielleicht) morgen.29",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausfÃ¼hrlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker FlugverspÃ¤tungen 2023\n\nSource\nVorhersage von FlugverspÃ¤tungen\n\n10.10.2 FilmerlÃ¶se\nVorhersagen von FilmerlÃ¶sen",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklÃ¤rt die lineare Regression mit Hilfe von Drachen. ğŸ‰ Sehenswert.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\nDie Webseite datenwerk.netlify.app30 stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1\nmario-compare-models",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nWenn es ein Standardwerk fÃ¼r Regressionsanalyse geben kÃ¶nnte, dann vielleicht das neueste Buch von Andrew Gelman, ein bekannter Statistiker (Gelman et al., 2021). Sein Buch ist fÃ¼r Sozialwissenschaftler geschrieben, also nicht fÃ¼r typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel.\n\n\n\n\nEarth, H. terrae;. K. links:. L. D. von B. (2021). Deutsch: FÃ¼nfjÃ¤hrig Gemittelte Abweichung Der Lufftemperatur in Deutschland Vom LangjÃ¤hrigem Mittel 1951 Bis 1980. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing, 104(2), 271â€“294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nYouyou, W., Kosinski, M., & Stillwell, D. (2015). Computer-Based Personality Judgments Are More Accurate than Those Made by Humans. Proceedings of the National Academy of Sciences, 112(4), 1036â€“1040. https://doi.org/10.1073/pnas.1418680112",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "Lizenzhinweis: Datenbasis: Deutscher Wetterdienst, eigene Elemente ergÃ¤nzt.â†©ï¸\nsynonym: Regressionsanalysenâ†©ï¸\nhttps://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/wetter-dwd-data-dict.mdâ†©ï¸\nQuelle: Umweltbundesamtâ†©ï¸\nQuelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3â†©ï¸\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/â†©ï¸\nr2(lm_wetter_bin_uv)â†©ï¸\nUVâ†©ï¸\nTransformationâ†©ï¸\nIch danke Karsten LÃ¼bke fÃ¼r diese Idee.â†©ï¸\nplot(estimate_expectation(lm_wetter_month)â†©ï¸\nZum Dollar-Operator s. Kapitel 3.12.3â†©ï¸\nSo ein Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ancova) bezeichnet werden.â†©ï¸\nsynonym: nominalskalierte Variableâ†©ï¸\nsynonym: Regressionsformelâ†©ï¸\ns. Hinweise hier: https://malcolmbarrett.github.io/ggokabeito/reference/palette_okabe_ito.htmlâ†©ï¸\nder Befehl wohnt im Paket performance, Teil des Metapakets easystatsâ†©ï¸\nengl. predictions; to predict: vorhersagenâ†©ï¸\nwir verwenden dazu die Funktionen mae und rsqâ†©ï¸\nwelches Sie vielleicht noch installieren mÃ¼ssen.â†©ï¸\nEntweder bei R oder bei Ihnen.â†©ï¸\nvgl. help(initial_split)â†©ï¸\nAnderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B.â†©ï¸\ninitial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgefÃ¼hrt.â†©ï¸\nsynonym: Prognoseâ†©ï¸\nQuelleâ†©ï¸\ndas nennt man dann Simpsons Paradoxâ†©ï¸\nDas StÃ¶rche-Babies-Beispiel passt auch zu AbbildungÂ 10.16.â†©ï¸\nQuelle: imgflip, https://imgflip.com/memegenerator/Distracted-Boyfriendâ†©ï¸\nhttps://datenwerk.netlify.appâ†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Aden-Buie, G. (2018). Wide and long data. https://www.garrickadenbuie.com/project/tidyexplain/\n\n\nAinali. (2007). Standard deviation diagram micro. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American\nStatistician, 27(1), 17â€“21.\n\n\nBerger, G. (2019, December 10). The Jobs of\nTomorrow: LinkedInâ€™s 2020 Emerging Jobs\nReport. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nBortz, J., & Schuster, C. (2010). Statistik fÃ¼r\nHuman- und Sozialwissenschaftler.\nSpringer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do,\nAccording to 35 Data Scientists. Harvard\nBusiness Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization\nin Spreadsheets. The American Statistician,\n72(1), 2â€“10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nBundesamt, S. (2023-003-272023-003-27). KÃ¶rpermaÃŸe nach\nAltersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household wealth and finances in\nGermany: Results of the 2021 household wealth\nsurvey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to\nModern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric visualisation of the\nvariance of the example distribution (2, 4, 4, 4, 5, 5, 7, 9) on\nw:Standard deviation. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155â€“159.\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003).\nApplied multiple regression/correlation analysis for the behavioral\nsciences, 3rd ed (pp. xxviii, 703). Lawrence Erlbaum Associates\nPublishers.\n\n\nDowney, A. (2023). Probably overthinking it: How to use data to\nanswer questions, avoid statistical traps, and make better\ndecisions. The University of Chicago Press.\n\n\nEarth, H. terrae;. K. links:. L. D. von B. (2021). Deutsch:\nFÃ¼nfjÃ¤hrig gemittelte Abweichung der\nLufftemperatur in Deutschland vom langjÃ¤hrigem\nMittel 1951 bis 1980. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nFisher, D., & Meyer, M. (2018). Making data visual: A practical\nguide to using visualization for insight (First edition). Oâ€™Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different\nGraphs: Generating Datasets with Varied\nAppearance and Identical Statistics through\nSimulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nflaticon. (2024). Professor. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nForum, W. E. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoren, A., VaÃ±o-GalvÃ¡n, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur,\nA., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H.,\nKovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K.\n(2020). A preliminary observation: Male pattern hair loss\namong hospitalized COVID-19 patients in Spain\nâ€“ A potential clue to the role of androgens in\nCOVID-19 severity. Journal of Cosmetic\nDermatology, 19(7), 1545â€“1547. https://doi.org/10.1111/jocd.13443\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., &\nSchaub, M. P. (2015). Smartphone use and smartphone addiction among\nyoung people in Switzerland. Journal of Behavioral\nAddictions, 4(4), 299â€“307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHorst, A. (2023). Tidy Data. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork. https://allisonhorst.com/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The dynamics of\nHuman Development Index. The Social Science\nJournal, 52(3), 331â€“347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito,\nK. (2008). Color universal design: The selection of four easily\ndistinguishable colors for all color vision types. Color\nImaging XIII: Processing,\nHardcopy, and Applications,\n6807, 206â€“213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024a). Imageflip Meme. https://imgflip.com\n\n\nimgflip. (2024b). Yoda Meme. https://imgflip.com\n\n\nInternational, T. (2017, January 25). Corruption Perceptions\nIndex 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via\ndata science: A ModernDive into R and the\nTidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nKaplan, D. T. (2009). Statistical modeling: A fresh approach.\nCreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The smartphone\naddiction scale: Development and validation of a short version for\nadolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022).\nCustomer churn prediction system: A machine learning approach.\nComputing, 104(2), 271â€“294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive\nTheory to Statistics Instruction. The American\nStatistician, 54(3), 196â€“206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nLyon, A. (2014). Why are Normal Distributions Normal?\nThe British Journal for the Philosophy of Science,\n65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific\nMethod, Statistical Method and the\nSpeed of Light. Statistical Science,\n15(3), 254â€“278. https://doi.org/10.1214/ss/1009212817\n\n\nMaphry. (2009). Seesaw with mean. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMarksâ€Anglin, A., & Chen, Y. (2020). A historical review of\npublication bias. Research Synthesis Methods, 11(6),\n725â€“742. https://doi.org/10.1002/jrsm.1452\n\n\nMatthews, R. (2000). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nMenk. (2014, July 29). Linear regression. https://texample.net/tikz/examples/linear-regression/\n\n\nMesserli, F. H. (2012). Chocolate Consumption,\nCognitive Function, and Nobel Laureates.\nNew England Journal of Medicine, 367(16), 1562â€“1564.\nhttps://doi.org/10.1056/NEJMon1211064\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung\nmit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, &\nFarias, M. (2020). Psychological impact of COVID-19\npandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of Open Data and Computational\nReproducibility in Registered Reports in\nPsychology. Advances in Methods and Practices in\nPsychological Science, 3(2), 229â€“237. https://doi.org/10.1177/2515245920918872\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!:\nErfolg und SpaÃŸ im Horrorfach nichttechnischer StudiengÃ¤nge.\nSpringer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design\n(CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: The new\nscience of cause and effect (First edition). Basic Books.\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability:\nA Brief History of a Confused Terminology.\nFrontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st\nCentury. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nPoldrack, R. A. (2023). Statistical thinking: Analyzing data in an\nuncertain world. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human height. Our\nWorld in Data. https://ourworldindata.org/human-height\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley\nStatsRef: Statistics Reference Online.\nJohn Wiley & Sons, Ltd. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen,\naufbereiten, visualisieren und modellieren (1. Auflage 2019).\nSpringer. https://www.springer.com/de/book/9783658215866\n\n\nScherer, C., Radchuk, V., Staubach, C., MÃ¼ller, S., Blaum, N., Thulke,\nH., & Kramerâ€Schadt, S. (2019). Seasonal host lifeâ€history processes\nfuel disease dynamics at different spatial scales. Journal of Animal\nEcology, 88(11), 1812â€“1824. https://doi.org/10.1111/1365-2656.13070\n\n\nSchwaiger, E., & Tahir, R. (2022). The impact of nomophobia and\nsmartphone presence on fluid intelligence and attention.\nCyberpsychology: Journal of Psychosocial Research on\nCyberspace, 16(1). https://doi.org/10.5817/CP2022-1-5\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011).\nFalse-Positive Psychology: Undisclosed\nFlexibility in Data Collection and Analysis\nAllows Presenting Anything as Significant.\nPsychological Science, 22(11), 1359â€“1366. https://doi.org/10.1177/0956797611417632\n\n\nStigler, S. M. (2016). The seven pillars of statistical wisdom.\nHarvard University Press.\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross,\nA., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., &\nBurke, D. S. (2013). Contagious Diseases in the\nUnited States from 1888 to the Present.\nNew England Journal of Medicine, 369(22), 2152â€“2158.\nhttps://doi.org/10.1056/NEJMms1215400\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain\nDrain: The Mere Presence of Oneâ€™s\nOwn Smartphone Reduces Available Cognitive Capacity.\nJournal of the Association for Consumer Research,\n2(2), 140â€“154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2016). Ggplot2: Elegant graphics for data analysis\n(Second edition). Springer.\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild. https://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., & Grolemund, G. (2018). R fÃ¼r Data Science: Daten\nimportieren, bereinigen, umformen, modellieren und visualisieren\n(F. Langenau, Trans.; 1. Auflage). Oâ€™Reilly. https://r4ds.had.co.nz/index.html\n\n\nWilke, C. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures (First edition). Oâ€™Reilly\nMedia. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg\n(Original work published 2019)\n\n\nYouyou, W., Kosinski, M., & Stillwell, D. (2015). Computer-based\npersonality judgments are more accurate than those made by humans.\nProceedings of the National Academy of Sciences,\n112(4), 1036â€“1040. https://doi.org/10.1073/pnas.1418680112",
    "crumbs": [
      "Abschluss",
      "Literatur"
    ]
  },
  {
    "objectID": "110-definitions.html",
    "href": "110-definitions.html",
    "title": "Anhang A â€” Definitionen",
    "section": "",
    "text": "Abweichungsrechteck: DefinitionÂ 8.1\nArgumente einer Funktion: DefinitionÂ 3.4\nAusprÃ¤gung: DefinitionÂ 2.8\nBalkendiagramm: DefinitionÂ 5.2\nBeobachtungseinheit: DefinitionÂ 2.6\nBinÃ¤re Variable: DefinitionÂ 10.1\nBoxplot: DefinitionÂ 5.9\nData-Dictionary: DefinitionÂ 2.4\nDataframe: DefinitionÂ 3.6\nHallo, Daten: DefinitionÂ 2.3\nDatenjudo: DefinitionÂ 4.1\nDezile: DefinitionÂ 6.6\nDichtediagramm: DefinitionÂ 5.4\nExtremwert: DefinitionÂ 6.3\nFehlerstreuung: DefinitionÂ 9.2\nFunktion: DefinitionÂ 3.2\nGerade: DefinitionÂ 9.1\nHistogramm: DefinitionÂ 5.3\nInterquartilsabstand: DefinitionÂ 7.4\nKovarianz: DefinitionÂ 8.2\nLagemaÃŸ: DefinitionÂ 6.8\nLinearer Zusammenhang: DefinitionÂ 5.7\nLineares Modell: DefinitionÂ 6.2\nMittlere Absolutabweichung: DefinitionÂ 7.3\nMedian: DefinitionÂ 6.4\nModelle: DefinitionÂ 2.11\nMittelwert: DefinitionÂ 6.1\nNormalverteilung: DefinitionÂ 5.5\nEntstehung einer Normalverteilung: DefinitionÂ 5.6\nPfeife: DefinitionÂ 4.2\nPunktmodell: DefinitionÂ 6.9\nQuantile: DefinitionÂ 6.7\nQuartile: DefinitionÂ 6.5\nKorrelationskoeffizient r: DefinitionÂ 8.3\nR-Quadrat: DefinitionÂ 9.3\nEin einfaches StreuungsmaÃŸ ist der Range \\(R\\), : DefinitionÂ 7.2\nReproduzierbarkeit: DefinitionÂ 3.1\nResiduum: DefinitionÂ 2.2\nStandardabweichung: DefinitionÂ 7.6\nSkalenniveau: DefinitionÂ 2.10\nStatistik: DefinitionÂ 2.1\nStreuungsmaÃŸe: DefinitionÂ 7.1\nTestsample: DefinitionÂ 10.3\nTidy Data: DefinitionÂ 2.9\nTrainsample: DefinitionÂ 10.2\nVariable: DefinitionÂ 7.5\nVarianz: DefinitionÂ 7.5\nVektorielles Rechnen: DefinitionÂ 3.5\nVektor: DefinitionÂ 3.3\nVerteilung: DefinitionÂ 5.1\nWert: DefinitionÂ 2.7\nz-Werte: DefinitionÂ 7.8\nZentrieren: DefinitionÂ 7.7\nRichtung und StÃ¤rke eines Zusammenhang: DefinitionÂ 5.8",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Definitionen</span>"
    ]
  }
]