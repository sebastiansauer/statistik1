# Modellgüte


## Lernsteuerung


### Standort im Lernpfad

@fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.




### Lernziele


- Sie kennen gängige Maße der Streuung einer Stichprobe und können diese definieren und mit Beispielen erläutern.
- Sie können gängige Maße der Streuung einer Stichprobe mit R berechnen.
- Sie können die Bedeutung von Streuung für die Güte eines Modells erläutern.

### Benötigte R-Pakete

In diesem Kapitel benötigen Sie folgende R-Pakete.

```{r}
library(tidyverse)
library(easystats)
library(DataExplorer)
```

```{r libs-hideen}
#| echo: false
library(patchwork)
library(ggpubr)
```


```{r}
#| echo: false
source("_common.R")
```




### Benötigte Daten

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```





```{r}
#| echo: false
ggplot2::theme_set(theme_minimal())
```



### Zum Einstieg

:::{#exr-streuung-erkennen}
### Freiwillige vor! 
Für diese kleine Live-Demonstration brauchen wir einige Freiwillige. 
Die Lehrkraft teilt die Freiwilligen in zwei Gruppen, Gruppe *Gleich-Groß* und Gruppe *Verschieden-Groß*. 
Erkennen Sie, dass die *Unterschiedlichkeit* der Größe in Gruppe *Gleich-Groß* gering ist, aber in Gruppe *Verschieden-Groß* hoch? $\square$
:::


## Warum Sie die Streuung Ihrer Daten kennen sollten




### Die Schlankheitspille von Prof. Weiss-Ois  {#sec-weiss-ois}

Prof. Weiss-Ois hat eine Erfindung gemacht, eine Schlankheitspille 💊  ...

:::: {.columns}
::: {.column width="45%"}

#### Was er sagt

!["Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!"](img/teacher.png){width="25%"}

:::


::: {.column width="10%"}
<!-- empty column to create gap -->
:::


::: {.column width="45%"}
#### Was er NICHT sagt
!["Allerdings streuten die Werte der Gewichtsveränderung um 10kg um den Mittelwert herum."](img/teacher.png){width="25%"}

:::

::::


[Icon unter Flaticon licence, Autor: iconixar](https://www.flaticon.com/free-icons/professor)


:::{exr-weisoiss2}
Würden Sie die Pille von Prof. I. Ch. Weiss-Ois nehmen?^[Ich auf keinen Fall.]

a) ja
b) nein
c) Nur wenn ich 100 Euro bekomme
d) Okay, für 1000 Euro$\square$
:::


:::{.callout-important}
Wie sehr die Werte eines Modells streuen, ist eine wichtige Information.$\square$
:::


### Wie man seine Kuh über den Fluss bringt

Treffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack.
Fritz will mit seiner Kuh einen Fluss überqueren, nur kann die Kuh nicht schwimmen^[ob es Fritz kann, ist nicht überliefert.]. 


>    🧑‍🌾 (Fritz): Sag mal, Karla, ist der Fluss tief?

>    👩‍🌾 (Karla): Nö, im Schnitt nur einen Meter.


Also führt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, im Floß ersoffen, s. @fig-fluss-tief.

![Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.](img/fluss-tief.png){#fig-fluss-tief}


>    👩‍🌾 (Karla): Übrigens, Lagemaße sagen nicht alles, Fritz.

>    🧑‍🌾 (Fritz): Läuft die Kuh durch den Fluss, kann sie schwimmen oder 's ist Schluss.


:::{.callout-important}
Die Streuung ihrer Daten zu kennen ist eine wesentliche Information. $\square$
:::




## Woran erkennt man ein gutes Modell?








@fig-streuung zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts).
Links ist die Streuung der Schlankheitspille *Dicktableitin* und rechts von der Schlankheitspille *Pfundafliptan* abgetragen.

```{r viel-wenig-streuung}
#| echo: false
#| label: fig-streuung
#| fig-cap: "Ein Modell mit wenig Streuung (links) vs. ein Modell mit viel Streuung (rechts). Die vertikalen grauen Balken kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale orange Linie). Je länger die 'Abstandsbalken', desto größer die Streuung."
set.seed(42)
d <-
  tibble(
    id = 1:100,
    x1 = rnorm(100, 0, 1),
    x2 = rnorm(100, 0, 7)
  ) %>% 
  pivot_longer(-id) %>% 
  group_by(name) %>% 
  mutate(avg = mean(value),
         e = value - avg) %>% 
  ungroup()

d_sum <-
  d %>% 
  group_by(name) %>% 
  summarise(avg = mean(value))

group_names <-
  c(x1 = "wenig Streuung:\nDiktableibtin",
    x2 = "viel Streuung:\nPfundafliptan")

d %>% 
  ggplot(aes(x = id, y = value)) +
  geom_point() +
  facet_wrap(~ name, labeller = as_labeller(group_names)) +
  geom_hline(color = okabeito_colors()[1], yintercept = 0) +
  geom_segment(aes(x = id, xend = id, y = value, yend = avg), 
               alpha = .5, color = "grey") +
  theme_minimal() +
  geom_label(x = 0, y = 0, label = "MW", color = okabeito_colors()[1]) +
  scale_x_continuous(limits = c(-10,100))
```


Bei einem Modell mit *wenig* Streuung liegen die tatsächlichen, beobachtete Werte ($y$) nah an den Modellwerten (vorhergesagten Werten, $\hat{y}$); 
die Abweichungen $e = y - \hat{y}$ sind also gering (der Modellfehler ist klein).
Bei einem Modell mit *viel* Streuung ist der Modellfehler $e$ (im Vergleich dazu) groß.




<!-- >   🧑‍🎓  Immer diese Trivialitäten! -->

<!-- >   👩‍🏫 Wird gleich interessanter. -->

:::{#exm-weiss-ois}
### Daten zur Schlankheitskur von Prof. Weiss-Ois
In @fig-streuung sind die Daten zu der Gewichtsveränderung nach Einnahme von "Schlankheitspillen" zweier verschiedener Präparate. 
Wie man sieht unterscheidet sich die typische (vorhergesagte) Gewichtsveränderung zwischen den beiden Präparaten kaum. Die Streuung allerdings schon.
Links sieht man die Gewichtsveränderungen nach Einnahme des Präparats "Dickableibtin extra mild" (c) und rechts das Präparat von Prof. Weiss-Ois "Pfundafliptan Forte".
Welches Präparat würden Sie lieber einnehmen?$\square$
:::




:::{.callout-important}
Wir wollen ein präzises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklären, also wenig vom tatsächlichen Wert abweichen.
Jedes Modell sollte Informationen über die Präzision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellgüte, d.h. der Präzision der Schätzung des Modellwerts, ist wenig nütze.$\square$
:::






>   👩‍🎓 Ich frage mich, ob man so ein Modell nicht verbessern kann?

>   👩‍🏫 Die Frage ist, was wir mit "verbessern" meinen?

>    👩‍🎓 Naja, kürzere Fehlerbalken, ist doch klar!

Da die Anzahl der Lenkräder mit dem Verkaufsgebot zusammenhängt, könnte es vielleicht sein, dass wir die Lenkräder-Anzahl da irgendwie nutzen könnten.
Das sollten wir ausprobieren.


@fig-fehler-red zeigt, dass die Fehlerbalken *kürzer* werden, wenn wir ein (sinnvolles) komplexeres Modell finden.
Innerhalb jeder der beiden Gruppen (mit 2 Lenkrädern vs. mit 0 Lenkrädern) 
sind die Fehlerbalken jeweils im Durchschnitt kürzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm).^[Aus Gründen der Übersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berücksichtigt und nur Spiele mit 0 oder mit 2 Lenkrädern.]




```{r fehlerbalken}
#| echo: false
#| label: fig-fehler-red
#| fig-cap: Fehlerbalken in einem einfachen und komplexeren Modell
#| layout-ncol: 2
#| fig-subcap:
#|   - "Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt"
#|   - "Fehlerbalken im komplexen Modell: Zwei Mittelwerte; weniger Streuung in jeder Gruppe. Das erkennt man daran, dass die vertikalen, grauen Abstandsbalken im Schnitt kürzer sind als im einfachen Modell (links)"
data(mariokart, package = "openintro")
m <-
  mariokart %>%
  filter(total_pr < 100) %>% 
  filter(wheels %in% c(0, 2)) %>% 
  mutate(ID = 1:nrow(.),
         total_pr_resid = total_pr - mean(total_pr),
         total_pr_resid_quad = total_pr_resid^2) %>% 
  group_by(wheels) %>% 
  mutate(total_pr_mean_group = mean(total_pr)) %>% 
  ungroup()


m_sum <- 
  m %>% 
  group_by(wheels) %>% 
  summarise(total_pr = mean(total_pr)) %>% 
  ungroup()


m %>% 
  ggplot() +
  geom_hline(aes(yintercept = mean(total_pr))) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
                   ), color = "grey") +
  geom_point(aes(x = ID, y = total_pr)) +
  annotate("label", x = 0, y = 47, label = "MW", hjust = "left", size = 6)



m %>% 
  ggplot() +
  geom_segment(data = filter(m, wheels == 0),
               aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
               ), color = "grey") +
   geom_hline(data = m_sum,
     aes(yintercept = total_pr,
                 color = factor(wheels))) +
   geom_segment(data = filter(m, wheels == 2),
               aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
               ), color = "grey") +
  geom_point(
    aes(x = ID, y = total_pr, color = factor(wheels))) +
  labs(color = "wheels") +
  theme(legend.position = "none") +
  geom_label(data = m_sum,
    aes(label = paste0("MW bei ", wheels, " Räder"), y = total_pr, color = factor(wheels)), x = 3, size = 6) +
  scale_color_okabeito() +
  scale_x_continuous(limits = c(-10, 90))
```


:::{.callout-important}
Durch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.$\square$
:::


## Streuungsmaße {#sec-streuung}

:::{#def-streuungsmaße}
### Streuungsmaße
Ein Streuungsmaß quantifiziert die Variabilität eines Merkmals. $\square$
:::

Ein einfaches Streuungsmaß ist der *Range*, definiert als Abstand von größtem und kleinsten Wert eines Merkmals.
Dieses Mermals ist aber nicht robust (gegenüber Extremwerten) und sollte daher nur mit Einschränkung verwendet werden.


### Der mittlere Abweichungsbalken

>   🧑‍🎓 Wir müssen jetzt mal präziser werden! Wie können wir die Streuung berechnen?

>   👨‍🏫 Gute Frage! Am einfachsten ist es, wenn wir die mittlere Länge eines Abweichungsbalkens ausrechnen. 



Legen wir (gedanklich) alle Abweichungsbalken $e$ aneinander und teilen durch die Anzahl $n$ der Balken,
so erhalten wir wir den "mittleren Abweichungsbalken",
den wir mit $\varnothing e$ bezeichnen könnten.
Diesen Kennwert bezeichnet man als *Mean Absolute Error* (MAE) 
bzw. als *Mittlere Absolutabweichung* (MAA).
Er ist so definiert, s. @eq-mae.


$${\displaystyle \mathrm {MAE} ={\frac {\sum _{i=1}^{n}\left|y_{i}-\bar{y}\right|}{n}}={\frac {\sum _{i=1}^{n}\left|e_{i}\right|}{n}}.}$$ {#eq-mae}

:::{#def-mae}
### Mittlere Absolutabweichung
Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte.^[Wenn man solche Sätze liest, fühlt sich die Formel fast einfacher an.]$\square$
:::

:::{#exm-mae}
@fig-mae visualisiert ein einfaches Beispiel zum MAE.
Rechnen wir den MAE für das Beispiel von @fig-mae aus:

$MAE = \frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5$
:::

```{r mae-balken}
#| echo: false
#| label: fig-mae
#| fig-cap: "Abweichungsbalken und der MAE"
#| fig-asp: .5
d <-
  tibble(id = 1:4,
         y = c(1, -3, 1, 1))


ggplot(d) +
  aes(x = id, y = y) +
  geom_point(size = 5, alpha = .7, color = "red") +
  geom_segment(aes(x = id, xend = id, y = y, yend = mean(y))) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  annotate("label", x = 0.5, y = 0, label = "Mittelwert") +
  theme_minimal() +
  scale_x_continuous(limits = c(0, 4))
```

Natürlich können wir R auch die Rechenarbeit überlassen.


>   🤖 Loving it!!


Schauen Sie: Den Mittelwert (s. @fig-mae) kann man doch mit Fug und Recht als ein *lineares Modell*, eine Gerade, betrachten, oder nicht?
Schließlich erklären wir $y$ anhand einer Gerade (die parallel zur X-Achse ist).

In R gibt es einen Befehl für ein *l*ineares *M*odell, 
er heißt `lm`.

Die Syntax von `lm()` lautet:

`lm(y ~ 1, data = meine_daten)`.

In Worten: 

>   Hey R, berechne mit ein lineares Modell zur Erklärung von Y. Aber verwende keine andere Variable zur Erklärung von Y, sondern nimm den Mittelwert von Y.

```{r}
lm1 <- lm(y ~ 1, data = d)
```


Den MAE können wir uns jetzt so ausgeben lassen:

```{r}
mae(lm1)
```




### Der Interquartilsabstand


Der Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein Streuungsmaß, das nicht auf dem Mittelwert aufbaut.
Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.

:::{#def-iqr}
### Interquartilsabstand
Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil.$\square$
:::


:::{#exm-iqr}
### IQR im Hörsaal
In einem Statistikkurs betragen die Quartile der Körpergröße: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR beträgt dann: $IQR = Q3-Q1 = 1.75m - 1.65m = 0.10m$, d.h. 10 cm.$\square$
:::


@fig-iqr-mario stellt den IQR (und einige Quantile) für den Verkaufspreise von Mariokart-Spielen dar.

::: {#fig-iqr-mario}

:::{.panel-tabset}

### Histogramm

```{r}
#| echo: false
#| label: fig-mario-qs-iqr1
#| fig-cap: IQR, Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)
mario_quantile2 <- 
mariokart %>% 
  filter(total_pr < 100) %>% 
  summarise(q25 = quantile(total_pr, .25),
            q50 = quantile(total_pr, .50),
            q75 = quantile(total_pr, .75))

mario_quantile <- 
  mariokart %>% 
  filter(total_pr < 100) %>% 
  reframe(qs = quantile(total_pr, c(.25, .5, .75)))

mariokart %>% 
  filter(total_pr < 100) %>%  
  ggplot(aes(x = total_pr)) +
  geom_histogram() +
  geom_vline(xintercept = mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = 0, label =  mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = Inf, label =  c("Q1", "Median", "Q3"), vjust = 2) +
  labs(y = "Anzahl") +
  geom_segment( 
           aes(x = q25, xend = q75), 
           y = 5, yend = 5, color = "#56B4E9",
           data = mario_quantile2, size = 3) +
  annotate("label", x = mario_quantile2$q50, y = 5,
           label = "IQR", color = "#56B4E9")
```


### Dichtediagramm

```{r}
#| echo: false
#| label: fig-mario-iqr2
#| fig-cap: IQR, Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)

mariokart %>% 
  filter(total_pr < 100) %>%  
  ggplot(aes(x = total_pr)) +
  geom_density() +
  geom_vline(xintercept = mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = 0, label =  mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = Inf, label =  c("Q1", "Median", "Q3"), vjust = 2) +
  labs(y = "Anzahl") +
  geom_segment( 
           aes(x = q25, xend = q75), 
           y = 0.01, yend = 0.01, color = "#56B4E9",
           data = mario_quantile2, size = 3) +
  annotate("label", x = mario_quantile2$q50, y = .01,
           label = "IQR", color = "#56B4E9")
```

:::

Der IQR für den Verkaufspreis von Mariokart-Spielen.

:::



### Streuungsmaße für Normalverteilungen

Normalverteilungen sind recht häufig anzutreffen in der Praxis der Datenanalyse.
Daher lohnt es sich, zu überlegen,
wie man diese Verteilungen gut zusammenfasst.
Man kann zeigen, dass eine Normalverteilung sich komplett über ihren *Mittelwert* sowie ihre *Standardabweichung* beschreiben lässt.
Außerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt.
Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), "verschiebt man den Berg" ja nur zur Seite, ohne seine Form zu verändern, s. @fig-norm-dev.


:::callout-note
Hat man normalverteilte Variablen/Abweichungen/Residuen, so ist die *Standardabweichung* (engl. standard deviation, SD, $\sigma$, $s$) eine komfortable Maßeinheit der Streuung,
denn damit lässt sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.$\square$
:::


>   🧑‍🎓 Aber wie berechnet man jetzt diese Standardabweichung?

>    👨‍🏫 Moment, noch ein kurzer Exkurs zur Varianz ...

>    🧑‍🎓 (seufzt)


### Varianz


#### Intuition

:::{.callout-note}
Die Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.$\square$
:::



:::: {.columns}

::: {.column}

@fig-var illustriert die Varianz:

1. Man gehe von der Häufigkeitsverteilung der Daten aus.
2. Betrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.
3. Man bilde Quadrate für jeden Datenpunkt mit der Kantenlänge, die dem Abstand des Punktes zum Mittelwert entspricht.
4. Die Quadrate quetscht man jetzt wo nötig in rechteckige Formen (ohne dass sich die Fläche ändern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit Seitenlänge $n$ und $\sigma^2$ anordnen.

:::

:::: {.column}


![Illustration zur Varianz als "mittlerer Quadratfehler"](img/Variance_visualisation.svg.png){#fig-var}

[By Cmglee - Own work, CC BY-SA 3.0](https://commons.wikimedia.org/w/index.php?curid=39472834)

:::

::::






@fig-mse visualisiert die Varianz für @exm-mae.^[Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine...]

Links sind die *Abweichungsquadrate* dargestellt, rechts die Varianz als "*typisches Abweichungsquadrat*".

:::{.callout-note}
Die Varianz ist also ein Maß, das die typische Abweichung der Beobachtungen  vom Mittelwert in eine Zahl fasst.$\square$
:::


```{r delta-plot, echo = FALSE}
#| echo: false
#| label: fig-mse
#| fig-cap: "Sinnbild zur Varianz als typischer Fehlerbalken"
#| fig-subcap: 
#|   - Quadrierte Fehlerbalken
#|   - "Varianz als 'typischer' Fehlerbalken"
#| warning: false
#| layout-ncol: 2

library(viridis)

d <-
  tibble(id = 1:4,
         y = c(0.1, -.3, .1, .1)) %>% 
  mutate(y_avg = mean(y),
         delta = y - y_avg,
         delta_abs = abs(delta),
         pos = ifelse(delta > 0, "positiv", "negativ"),
         delta_sq = delta^2)

var_smpl <- mean(d$delta_sq)

p_deltas <- 
d %>%   
  ggplot(aes(x = id, y = y)) +
  geom_hline(yintercept = mean(d$y), linetype = "dashed", show.legend = FALSE) +
  geom_segment(aes(y = mean(d$y),
                   yend = y,
                   x = id,
                   xend = id,
                   linetype = pos), show.legend = FALSE) +
  annotate(geom = "label",
           x = 0,
           hjust = 0,
           y = mean(d$y), 
           label = paste0("MW = ", round(mean(d$y), 2)), show.legend = FALSE) +
  geom_rect(aes(ymin = y_avg,
                ymax = y,
                xmin = id,
                xmax = id+delta_abs),
            fill = "#E69F00FF" ,
            alpha = .5, show.legend = FALSE) +
  geom_text(aes(label=round(delta_sq,3)),
            hjust = "left", 
            nudge_x = 0.05,
            vjust = ifelse(d$pos == "positiv", "top", "bottom"),
            nudge_y = ifelse(d$pos == "positiv", -0.05, 0.05),
            color = "#E69F00FF",
            size = 6, show.legend = FALSE) +
  geom_point(size = 5, show.legend = FALSE) +
  labs(linetype = "",
       x = "",
       y = "")  +
  scale_y_continuous(limits = c(-.3, .1)) +
  scale_x_continuous(limits = c(0, 5)) +
  theme_minimal()

p_var <- 
  d %>%   
    ggplot(aes(x = id, y = y)) + 
    geom_hline(yintercept = mean(d$y), linetype = "dashed") +
     annotate(geom = "label",
             x = 0,
             hjust = 0,
             y = mean(d$y), 
             label = paste0("MW = ", round(mean(d$y), 2))) +
    annotate("rect", 
             xmin =  5, ymin = 0, xmax = 5.2, ymax = var_smpl, 
             fill = "#56B4E9FF") +
    scale_y_continuous(limits = c(-.3, .1)) +
    scale_x_continuous(limits = c(0, 6)) +
    annotate(geom = "label",
                  x = 5,
                  hjust = 0.5,
                  y = -0.01,
                  label = "Varianz") +
  theme_minimal() +
  annotate("label", x = 1, y = -0.1,
           hjust = 0,
           label = paste0(var_smpl, " = (0.01 + 0.01 + 0.01 + 0.09)/4"))

p_deltas
p_var
```





Bildquelle: FOM-ifes


:::{#exm-var}
Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen.
Natürlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.

Zunächst betrachten Sie die Streuung in den Verkaufspreisen:

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")

m <-
  mariokart %>%
  filter(total_pr < 100)  # ohne Extremwerte

m_summ <- 
  m %>% 
  summarise(
    pr_mw = mean(total_pr),
    pr_iqr = IQR(total_pr),
    pr_maa = mean(abs(total_pr - mean(total_pr))),
    pr_var = var(total_pr),
    pr_sd = sd(total_pr))
```


```{r}
#| echo: false
m_summ %>% print_md()
```



Statistiken sind ja schön ... aber Bilder sind auch gut, s. @fig-var. $\square$


```{r}
#| eval: false
mariokart %>% 
  mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  plot_density()
```



```{r}
#| echo: false
#| fig-cap: Die Verteilung des Verkaufspreises von Mariokart-Spielen 
#| label: fig-var
#| layout-ncol: 2
#| fig-subcap: 
#|   - Dichtediagramm mit MW±SD in roter Farbe
#|   - Violindiagramm mit MW±SD in roter Farbe
mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  ggplot() +
  geom_density(aes(x = total_pr)) +
  geom_rect(data = m_summ, 
               aes(
                 xmin = pr_mw - 0.5*(pr_sd),
                 xmax = pr_mw + 0.5*(pr_sd),
                 ymin = 0,
                 ymax = Inf
               ),
            alpha = .5,
            fill = "red")

mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  ggplot() +
  geom_violin(aes(
    x = 1,
    y = total_pr)) +
  geom_jitter(aes(
    x = 1,
    y = total_pr),
    width = 0.1) +
  scale_x_continuous(limits = c(0, 2)) +
  geom_rect(data = m_summ, 
               aes(
                 ymin = pr_mw - 0.5*(pr_sd),
                 ymax = pr_mw + 0.5*(pr_sd),
                 xmin = -Inf,
                 xmax = Inf
               ),
            alpha = .5,
            fill = "red")
```


:::


Wer sich die Berechnung von Hand für `pr_maa` sparen möchte, kann die [Funktion `MeanAD` aus dem Paket `DescTools`](https://rdrr.io/cran/DescTools/man/MeanAD.html) nutzen.


#### Kochrezept für die Varianz


Um die Standardabweichung zu berechnen, berechnet man zunächst die *Varianz*, $s^2$ abgekürzt. Hier ist ein "Kochrezept"^[Algorithmus] zur Berechnung der Varianz:

1. Für alle Datenpunkte $x_i$: Berechne die Abweichungen vom Mittelwert, $\bar{x}$
2. Quadriere diese Werte
3. Summiere dann auf
4. Teile durch die Anzahl $N$ der Werte


Als Formel ausgedrückt, lautet die Definition der Varianz^[sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehörigen Population zu schätzen, teilt man nicht durch $N$, sondern durch $N-1$] einer Stichprobe wie folgt, s. @eq-var.


$${\displaystyle s^{2}={\frac {1}{N}}\sum _{i=1}^{n}\left(y_{i}-{\bar {y}}\right)^{2}={\frac {1}{N}}\sum _{i=1}^{n}dy_i^{2}.}$$ {#eq-var}


:::{#def-var}
### Varianz
Die Varianz ($s^2, \sigma^2$) ist definiert als der Mittelwert der quadrierten Abweichungen, $dy_i^2$, (vom Mittelwert).$\square$
:::


Die Varianz steht im engen Verhältnis zur Kovarianz, s. @sec-cov.
Die Varianz kann auch verstehen als den *mittleren Quadratfehler* (Mean Squared Error, MSE) eines Modells, s. @eq-mse.



$${\displaystyle MSE={\frac {1}{N}}\sum _{i=1}^{N}\left(x_{i}-{\hat {y}}\right)^{2}.}$$ {#eq-mse}

Im Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.



### Die Standardabweichung

Kennt man die Varianz, so lässt sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.


:::{#def-sd}
### Standardabweichung
Die Standardabweichung (SD, s, $\sigma$) ist definiert als die Quadratwurzel der Varianz, s. @eq-sd.


$$s := \sqrt{s^2}$$ {#eq-sd}

$\square$
:::


Durch das Wurzelziehen besitzt die Standardabweichung wieder *in etwa* die gleiche Größenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groß werden kann).


Aus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE.
Dann nennt man sie *Root Mean Squared Error* (RMSE): $rmse := \sqrt{mse}$.


:::{.callout-note}
Die SD ist i.d.R. *un*gleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.$\square$
:::


:::{#exm-sd-mario}

Sie arbeiten weiter an Ihrem Mariokart-Projekt.
Da Sie heute keine Lust auf viel Tippen haben,
nutzen Sie das R-Paket `easystats` mit der Funktion `describe_distribution`.

```{r}
library(easystats)

mariokart %>% 
  select(total_pr) %>% 
  describe_distribution()
```

Ah! Das war einfach. Wird auch langsam Zeit für Feierabend.$\square$
:::



:::{#exm-gruppen-mw}

Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. 
Bevor Sie nach Hause gehen, möchten Sie noch eine Sache anschauen.
In einer früheren Analyse (s. @fig-fehler-red) fanden Sie heraus,
dass die Fehlerbalken kürzer werden, wenn man ein geschickteres und komplexeres Modell findet. 
Das wollen Sie natürlich prüfen.
Sie überlegen: "Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll."

Das spezifizieren Sie so:

```{r}
lm1 <- lm(total_pr ~ 1, data = mariokart)
mae(lm1)
```


Im nächsten Schritt spezifizieren Sie ein Modell,
in dem der Verkaufpreis eine Funktion der Anzahl der Lenkräder ist (ähnlich wie in @fig-fehler-red):

```{r}
lm2 <- lm(total_pr ~ wheels, data = mariokart)
mae(lm2)
```

Ah! Sehr schön, Sie haben mit `lm2` ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach hause!$\square$
:::


## Streuung als Modellfehler

Wenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellgüte auffassen.

Definieren wir zunächst als Punktmodell auf Errisch:

```{r}
lm_mario1 <- lm(total_pr ~ 1, data = mariokart)
```

Zur Erinnerung: Wir modellieren `total_pr` ohne Prädiktoren, sondern als Punktmodell,
und zwar schätzen wir den Mittelwert mit den Daten `mariokoart`.

Das (Meta-)Paket `easystats` bietet komfortable Befehle, um die Modellgüte zu berechnen:

```{r}
mae(lm_mario1)  # Mean absolute error
mse(lm_mario1)  # Mean squared error
rmse(lm_mario1)  # Root mean squared error
```



## z-Transformation

Sie arbeiten immer noch als Datenknecht, Moment, *Datenhecht* bei dem Online-Auktionshaus.
Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzeigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen.
Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen.
Schon ist das Leben leichter, s. `mariokart2`.

```{r}
mariokart2 <- 
  mariokart %>% 
  filter(total_pr < 100)
```


```{r}
#| echo: false
mariokart2 <-
  mariokart2 %>% 
  mutate(abw = 47.4 - total_pr)
```


Mit dem R-Paket `ggpubr` (Funktion `gghistogram`) lässt sich die Verteilung leicht visualisieren, s. @fig-mariokart2, links. 

```{r}
#| label: fig-mariokart2
#| fig-cap: Verteilung von `mariokart2`
#| layout-ncol: 2
#| echo: false
#| fig-subcap:
#|   - Wie nah drängen sich die Verkaufspreise um ihren Mittelwert?
#|   - Abweichungen vom Mittelwert


gghistogram(mariokart2, x = "total_pr", 
            add = "mean",  # Mittelwert wird hinzugefügt
            add.params = list(color = okabeito_colors()[1], size = 3))  +# Schnickschnack zur Verschönerung
  annotate("label", x=47, y = 0, label = "Mittelwert")

gghistogram(mariokart2, x = "abw",
            add = "mean",  # Mittelwert wird hinzugefügt
            add.params = list(color =  okabeito_colors()[1], size = 3))  +# Schnickschnack zur Verschönerung
  annotate("label", x= 0, y = 0, label = "Mittelwert")
```



Tja, das ist doch etwas Streuung um den Mittelwert herum.

:::callout-important
Je weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell für die Daten, bzw. desto höher die Modellgüte.$\square$
:::

Ja, es ist *etwas* Streuung, aber wie viel? Kann man das genau angeben?
Sie überlegen ... und überlegen. Da! Eine Idee!

Man könnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist.
Je größer diese Abweichung, desto schlechter die Modellgüte!
Also rechnen Sie diese Abweichung aus.

```{r}
mariokart2 <-
  mariokart2 %>% 
  mutate(abw = 47.4 - total_pr)
```

Anders gesagt: Wir haben die Verkaufspreise *zentriert.*

:::{#def-zentrieren}
### Zentrieren 
Zentrieren bedeutet, von jedem Wert einer Verteilung $X$ den Mittelwert abzuziehen.
Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. $\square$
:::


```{r fig-norm-verschieb-pfeil}
#| echo: false
#| label: fig-norm-dev
#| fig-cap: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt
#| fig-asp: 0.5

mw <- 47.4
streuung <- 9.11

d <- 
  tibble(groesse = rnorm(1e5, mw, streuung),
         groesse_zentriert = groesse - mean(groesse))

d_sum <-
  d %>% 
  pivot_longer(everything()) %>%
  group_by(name) %>% 
  summarise(MW = mean(value))
  

d %>% 
  ggplot() +
  geom_density(aes(x = groesse), color = "#E69F00FF", size = 2) +
  geom_density(aes(x = groesse_zentriert), color = "#56B4E9FF", size = 2) +
  theme_minimal() +
  geom_vline(data = d_sum,
             aes(xintercept = MW),
             color = "grey") +
  geom_label(data = d_sum,
             aes(label = paste0("MW: ", round(MW, 0)), x = MW),
             y = 0) +
  labs(x = "(zentrierte) Variable", 
       y = "") +
  annotate("segment", x = mw, xend = 0, y = 0.01, yend = 0.01,
           arrow = arrow(type = "closed", length = unit(0.02, "npc")))



# d %>% 
#   pivot_longer(everything()) %>% 
#   ggplot() +
#   aes(x = value) +
#   geom_density() +
#   facet_wrap(~ name) +
#   theme_minimal() +
#   geom_vline(data = d_sum,
#              aes(xintercept = MW), color = "red") +
#   geom_label(data = d_sum,
#              aes(label = paste0("MW: ", round(MW, 0)), x = MW),
#              y = 0) +
#   labs(x = "(zentrierte) Körpergröße", 
#        y = "")
```



Aber irgendwie sind Sie noch nicht am Ziel Ihrer Überlegungen:
Woher weiß man, ob 10 Euro oder 20 Euro "viel" Abweichung vom Verkaufspreis ist?
Man müsste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen.
Wieder! Ein Geistesblitz!
Man könnte doch die jeweilige Abweichung  in Bezug setzen zur *mittleren (absoluten) Abweichung* (MAA)!
Ein alternativer, ähnlicher Kennwert zur mittlerer absolute Abweichung ist die SD.
Sie haben gehört, dass die SD gebräuchlicher ist als die MAA. 
Um sich als Checker zu präsentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja ähnlich.

Also: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte,
dann hätten wir eine "standardisierte"^[abgekürzt manchmal mit `std`] Abweichung von 1, weil 10/10=1.

Begeistert über Ihre Schlauheit machen Sie sich ans Werk.

```{r}
mariokart2 <-
  mariokart2 %>% 
  mutate(abw_std = abw / sd(abw),  # std wie "standardisiert"
         abw_std2 = abw / mean(abs(abw)))  
```

Zufrieden betrachten Sie Ihr Werk, s. @fig-z-transf. 
In @fig-z-transf sieht man oben die Rohwerte und unten die transformierten Werte,
die wir hier als *standardisiert* bezeichnen, da wir sie in Bezug zur "typischen Abweichung", der SD, gesetzt haben.

```{r}
#| warning: false
#| echo: false
#| label: fig-z-transf
#| fig-cap: "Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert"

p1 <- gghistogram(mariokart2, x = "abw",
            add = "mean",  # Mittelwert wird hinzugefügt
            add.params = list(color = okabeito_colors()[1], size = 3)) +
  labs(title = "Rohwerte") +
  annotate("label", x = 0, y = 0, label = "MW", hjust = "bottom")

p2 <-  gghistogram(mariokart2, x = "abw_std",
            add = "mean",  # Mittelwert wird hinzugefügt
            add.params = list(color = okabeito_colors()[1], size = 3)) +
  labs(title = "Standardisierte Werte") +
  annotate("label", x = 0, y = 0, label = "MW", hjust = "bottom")

arrow_down <- png::readPNG("img/arrow-down.png", native = TRUE)
p_ad <- ggplot() + inset_element(arrow_down, 0, 0, 1, 1)

plots(p1, p_ad, p2, n_rows = 3)
```


Wir fassen die Schritte unserer Umrechnung ("Transformation") zusammen wie in einem Kochrezept:

1. Nimm die Verteilung der Verkaufspreise
2. Berechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)
4. Teile die Abweichungen (Schritt 2) durch die SD


Diese Art von Transformation bezeichnet man als *z-Transformation* und die resultierenden Werte als *z-Werte*.

:::{#def-z-werte}
### z-Werte
z-Werte sind das Resultat der z-Transformation.
Für die Variable $X$ berechnet sich der z-Wert der $i$-ten Beobachtung so: $z_i = \frac{x_i - \bar{x}}{sd_x}.\square$
:::

z-Werte sind nützlich, weil sie die "relative" Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.

Nach einer *Faustregel* spricht man von extremen Abweichungen (Extremwerten, Ausreißern), wenn $z_i > 2$ oder $z_i > 3$.


## Fazit

Der „gesunde Menschenverstand“ würde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. 
Das ist vernünftig, denn die MAA ist anschaulicher und damit nützlicher als die Varianz und die SD.

Warum sollte man überhaupt ein unanschauliches Maß wie die Varianz verwenden? 
Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt.
Gründe, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:^[Ich wollte noch hinzufügen, dass die Varianz eng verknüpft mit der linearen Algebra, aber ich war nicht sicher, ob das Argument allgemein überzeugen würde.]

- Die SD ist sehr nützlich zur Beschreibung der Normalverteilung
- Die Varianz wird häufig verwendet bzw. in Forschungsarbeiten berichtet, also müssen Sie die Varianz kennen.


Liegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenüber Mittelwert basierten Streuungsmaßen (MAA, Varianz, SD).


## Aufgaben



Die Webseite [datenwerk.netlify.app](https://datenwerk.netlify.app) stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:

<!-- :::{#exr-koerpergroesse} -->
<!-- Sagen wir, wir möchten die Körpergröße erwachsener (deutscher) Männer modellieren. -->
<!-- Einfach gesagt: Wir möchten wissen, wie groß typischerweise ein deutscher Mann ist. -->
<!-- Wir verwenden den Mittelwert, um diese Frage zu beantworten. -->
<!-- Aus der Literatur erfahren wir, dass die mittlere Körpergröße belgischer Männer bei 179 cm liegt und normalverteilt ist [@Garcia:2007aa].^[Das sind Daten für Belgien; Daten zur Standardabweichung für Deutschland habe ich nicht gefunden.] -->
<!-- ::: -->



Schauen Sie sich auch mal auf [Datenwerk](https://datenwerk.netlify.app/) die Aufgaben zu  dem Tag [variability](https://datenwerk.netlify.app/#category=variability) an.




:::{#exr-handy}
### Analysieren Sie den Datensatz zur Handynutzung
Laden Sie den [Datensatz zur Handynutzung](https://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing) von Google-Docs herunter.^[<https://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing>]. 
Berechnen Sie dann gängige deskriptive Statistiken und visualisieren Sie sie. $\square$
:::




## Literaturhinweise


Allen Downey [-@downey_probably_2023] stellt in seinem vergnüglich zu lesenden Buch eine kurzweilige Einführung in die Statistik vor;
auch Streuungsmaße haben dabei einen Auftritt.
Wer mehr "Lehrbuch-Feeling" sucht, wird bei @cetinkaya-rundel_introduction_2021-1 fündig (das Buch ist online frei verfügbar).
Es ist kein Geheimnis, dass Streuungsmaße keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne Streuungsmaße geht's nicht.
Jedenfalls werden Sie in jedem Statistik-Lehrbuch,
dass Sie in der Bib (oder sonstwo) aus dem Regal ziehen, fündig werden zu diesem Thema.
Die Bücher unterscheiden sich meist "nur" in ihrem Anspruch bzw. der didaktischen Aufmachung; für alle ist da was dabei.


## Literatur
