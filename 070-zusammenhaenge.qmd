# Punktmodelle 2 {#sec-zusammenhaenge}



## Lernsteuerung

### Standort im Lernpfad

@fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.




### Lernziele


- Sie k√∂nnen die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenh√§nge erl√§utern.
- Sie k√∂nnen die St√§rke einer Korrelation einsch√§tzen.

### Ben√∂tigte R-Pakete

In diesem Kapitel ben√∂tigen Sie folgende R-Pakete.

```{r}
library(tidyverse)
library(easystats)
```

```{r}
#| echo: false

source("_common.R")
```



```{r}
#| include: false
library(ggpubr)
library(TeachingDemos)
library(gt)
#library('MASS')
```


### Ben√∂tigte Daten



::: {.content-visible when-format="html"}

```{r import-mariokart-csv}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```
:::


::: {.content-visible when-format="pdf"}

@lst-mario-path definiert den Pfad zum Datensatz `mariokart` und importiert die zugeh√∂rige CSV-Datei in R, so dass wir einen Tibble mit Namen `mariokart` erhalten.


```{r import-mariokart-csv2}
mariokart_path <- paste0(
  "https://vincentarelbundock.github.io/Rdatasets/",
  "csv/openintro/mariokart.csv")

mariokart <- read.csv(mariokart_path)
```

:::



### Zum Einstieg

:::{#exm-zsgh-studis}

1. Suchen Sie sich eine vertrauenw√ºrdige Partnerin oder einen vertrauensw√ºrdigen Partner. Im Zweifel reicht die Person, die neben Ihnen sitzt. [üòÅ]{.conten-visible when-format="html"}
2. Nennen Sie zwei Variablen, die wie folgt zusammenh√§ngen:

- gleichsinnig (Viel von dem einen, viel von dem anderen)
- gegensinnig (viel von dem einen, wenig von dem anderen)
- Scheinzusammenhang (h√§ngt zusammen, ist aber nicht "echt" bzw. kausal)
:::



## Zusammenfassen zum Zusammenhang


In @sec-punktmodelle1 haben wir gelernt,
dass das Wesen eines Punktmodells als Zusammenfassung *einer* Spalte (eines Vektors) zu einer einzelnen Zahl^[auch Skalar genannt], zu einem "Punkt" sozusagen, zusammengefasst werden kann.

In diesem Kapitel fassen wir *zwei* Spalten zusammen, wieder zu *einer* Zahl, s. @eq-desk2.

$$\begin{array}{|c|} \hline \\ \hline \\\\\\ \hline \end{array} + \begin{array}{|c|} \hline \\ \hline \\\\\\ \hline \end{array} \qquad \rightarrow \qquad \begin{array}{|c|} \hline \\ \hline  \hline \end{array}$$ {#eq-desk2}


Wo wir in @sec-punktmodelle1 eine Variable mit Hilfe eines Lagema√ües beschrieben (bzw. dargestellt, zusammengefasst, modelliert) haben, tun wir hier das Gleiche f√ºr zwei Variablen.
Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben:
Wie die beiden Variablen von einander *abh√§ngen* bzw. miteinander (irgendwie) *zusammenh√§ngen.*
Wir begrenzen auf *metrische* Variablen.


:::{.exm-zsmn}
### Beispiele f√ºr Zusammenh√§nge

- Lernzeit und Klausurerfolg
- K√∂rpergr√∂√üe und Schuhgr√∂√üe
- Verbrauchtes Benzin und zur√ºckgelegte Strecke
- Produktionsmenge und Produktionskosten
- Bildschirmzeit und Schlafqualit√§t
- Umweltschutz und Biodiversifit√§t $\square$
:::

Die Verbildlichung^[Visualisierung] zweier metrischer Variablen haben wir bereits in @sec-zshg-metr kennengelernt.
Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal @fig-zshg.


```{r}
#| echo: false
#| label: fig-zshg
#| fig-cap: Visualisierung des Zusammenhangs von wheels und total_pr
#| fig-subcap: 
#|   - Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)
#|   - "'Verwackeltes' Streudiagramm, um die einzelnen Punkte besser zu erkennen"
#| layout-ncol: 2
data(mariokart, package = "openintro")

mariokart %>% 
  filter(total_pr < 100) %>% 
  ggscatter(x = "wheels", 
            y = "total_pr",
            add = "reg.line",
            add.params = list(color = "blue"),
            ellipse = TRUE)

mariokart %>% 
  filter(total_pr < 100) %>% 
  ggplot() +
  aes(x = wheels, y = total_pr) +
  geom_jitter()
```





## Abweichungsrechtecke {#sec-cov}

Die St√§rke des linearen Zusammenhangs zweier metrischer Variablen kann man gut mithilfe von Abweichungsrechtecken veranschaulichen.
Los geht's!


### Noten und Abweichungsrechtecke


```{r}
#| echo: false
d <- tibble::tribble(
  ~id, ~y, ~x,
   1L,   72,     70,
   2L,   44,     40,
   3L,   39,     35,
   4L,   50,     67
  ) %>% 
  mutate(x_avg = mean(x),
         y_avg = mean(y),
         x_delta = x - mean(x),
         y_delta = y - mean(y),
         x_pos = x > mean(x),
         y_pos = y > mean(y),
         cov_sign = sign(x_delta * y_delta),
         xy_area = x_delta * y_delta)

#write.csv(d, file = "noten.csv")

# cor(d$punkte, d$lernzeit)
#plot(d$lernzeit, d$punkte)
cov_xy <- cov(d$y, d$x)
```


:::{#exm-noten2}
### Wieder Statistiknoten

Anton, Bert, Carl und Daniel haben ihre Statistikklausur zur√ºckbekommen.
Die Lernzeit $X$ scheint mit der erreichten Punktzahl $Y$ (0-100, je mehr desto besser) zusammenzuh√§ngen.^[>   [üßë‚Äçüéì]{.content-visible when-format="html"}  Typisches Lehrerbeispiel!!]
Gar nicht so schlecht ausgefallen, s. @tbl-noten2.$\square$
:::

```{r}
#| echo: false
#| label: tbl-noten2
#| tbl-cap: Statistiknoten und Lernzeit

d %>% 
  select(id, y, x) %>% 
  kable() 
```

Zeichnen wir uns die Daten als Streudiagramm, s. @fig-delta-rect.
Dabei zeichnen wir noch *Abweichungsrechtecke* ein.


:::{#def-abweichungsrechteck}
### Abweichungsrechteck
Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert $\bar{x}$ bis zum Messwert $x_i$ und genauso f√ºr $Y$.
Wir bezeichnen mit $dx_i$ die Distanz (Abweichung) vom Mittelwert $\bar{x}$ bis zum Messwert $x_i$ (und analog $dy_i$), also $dx_i = x_i - \bar{x}$.  Die Fl√§che des Abweichungsrechtecks ist dann das Produkt der Abweichungen: $dx_i \cdot dy_i$.$\square$
:::

```{r}
#| echo: false
#| label: fig-delta-rect
#| fig-cap: "Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider."
p_cov <- 
ggplot(d) +
  aes(x = x, y = y) +
  geom_vline(xintercept = mean(d$x), linetype = "dashed") +
  geom_hline(yintercept = mean(d$y), linetype = "dashed") +
  geom_rect(aes(xmin = x, xmax = x_avg, ymin = y, ymax = y_avg,
                fill = factor(cov_sign)),
            alpha = .5) +
  labs(x = "Lernzeit",
       y = "Punkte (0-100)",
       fill = "Vorzeichen") + 
  theme_minimal() +
  annotate("label", x = Inf, y = Inf, 
           label = "Q1: +", hjust = "right", vjust = "top") +
  annotate("label", x = Inf, y = -Inf, 
           label = "Q2: -", hjust = "right", vjust = "bottom") +
  annotate("label", x = -Inf, y = -Inf, 
           label = "Q3: +", hjust = "left", vjust = "bottom") +
  annotate("label", x = -Inf, y = Inf, 
           label = "Q4: -", hjust = "left", vjust = "top") +
    geom_point(size = 2, color = "black") +
  scale_fill_okabeito() +
  theme(
    legend.position = c(0.95, 0.05),  # Adjust these values to position the legend
    legend.justification = c(1, 0)    # 1 = right, 0 = bottom
  )

p_cov
```



Stellen Sie sich vor, wir legen alle Rechtecke zusammen aus @fig-delta-rect.
Nennen wir das resultierende Rechteck das "Summenrechteck".
Ja, ich wei√ü, ich strapaziere mal wieder Ihre Phantasie^[hoffentlich nicht Ihre Geduld].
Jetzt kommt's: Je gr√∂√üer die Fl√§che des Summenrechtecks, desto st√§rker der (lineare) Zusammenhang.

Beachten Sie, dass die Fl√§chen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die F√ºllfarben der Rechtecke verdeutlichen dies, s. @fig-delta-rect.

Das *Vorzeichen* der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist.

So zeigt @fig-kov links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) √ºberwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ √ºberwiegt).

```{r}
#| label: fig-kov
#| fig-cap: "Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die Fl√§chen der Abweichungsrechtecke addiert."
#| layout-ncol: 2
#| fig-subcap: 
#|   - Positive Vorzeichen (Quadranten 1 und 3) √ºberwiegen, was in einer positiven Kovarianz resultiert
#|    - Negative Vorzeichen (Quadranten 2 und 4) √ºberwiegen, was in einer negativen Kovarianz resultiert
#| echo: false

## Positive correlation
x <- rnorm(25)
y <- x + rnorm(25,3, .5)
#cor(x,y)
cor.rect.plot(x,y)
## negative correlation
x <- rnorm(25)
y <- rnorm(25,10,1.5) - x
#cor(x,y)
cor.rect.plot(x,y)
```



Wir k√∂nnen das Summenrechteck noch durch die Anzahl der Datenpunkte teilen,
das √§ndert nichts an der Aussage,
aber der Mittelwert hat gegen√ºber der Summe den Vorteil, dass er unabh√§ngig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte.
Das resultierende Rechteck nennen wir das *mittlere Abweichungsrechteck*.


Ein Ma√ü f√ºr den Zusammenhang von Lernzeit und Klausurpunkte ist also die *Fl√§che des mittleren Abweichungsrechtecks*, s. @fig-cov2.


![Die Kovarianz als mittleres Abweichungsrechteck. Die Fl√§che der Rechtecks entspricht dem Wert der Kovarianz.](img/p_cov2.png){#fig-cov2}

```{r}
#| echo: false
#| label: fig-cov2a
#| eval: false
#| fig-cap: "Die Kovarianz als mittleres Abweichungsrechteck. Die Fl√§che der Rechtecks entspricht dem Wert der Kovarianz."
p_cov2 <- 
p_cov +
  geom_rect(aes(xmin = -Inf, 
                xmax = Inf, 
                ymin = -Inf, 
                ymax = Inf), 
            fill = "gray", 
            alpha = 0.2, 
            inherit.aes = FALSE) +
  geom_rect(aes(xmin = mean(d$x) - sqrt(cov_xy)/2, 
                xmax = mean(d$x) + sqrt(cov_xy)/2,
                ymin = mean(d$y) - sqrt(cov_xy)/2, 
                ymax = mean(d$y) + sqrt(cov_xy)/2)) +
  geom_text(aes(x = mean(d$x), y = mean(d$y), 
                label = "Kovarianz:\nmittleres\nAbweichungsrechteck"),
            color = "white") +
  theme(
    legend.position = c(0.95, 0.05),  # Adjust these values to position the legend
    legend.justification = c(1, 0))

p_cov2
```





### Kovarianz {#sec-kov}

:::{#def-kov}
### Kovarianz
Die Kovarianz ist definiert als die Fl√§che des mittleren Abweichungsrechtecks.
Sie ist ein Ma√ü f√ºr die St√§rke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. @fig-cov2.$\square$
:::


>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"}
 Zu viele Bilder! Ich brauch Zahlen.

>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Kommen gleich!


@tbl-kov2 zeigt die Werte f√ºr die X- und Y-Abweichung und die resultierenden Fl√§chen der Abweichungsrechtecke.
Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei [noten.csv](https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv)^[<https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv>].



```{r}
#| echo: false
#| label: tbl-kov2
#| tbl-cap: "Werte der Abweichungsrechtecke. avg: average (Mittelwert), cov_sign: Vorzeichen der Kovarianz,_pos: positiver Wert auf der entsprechenden Achse (x/y)?, xy_area: Produkt von x_delta und y_delta"

d %>% 
  select(-x_pos, -y_pos) |> 
  kable()
```


Berechnen wir als n√§chstes das mittlere Abweichungsrechteck, die Kovarianz:

```{r}
d %>%
  summarise(kovarianz = mean(xy_area))
```

Die Formel der Kovarianz lautet, s. @eq-cov4: 

$$\text{cov(xy)} = s_{xy}:=\frac{1}{n}\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y}) = \frac{1}{n}\sum_{i=1}^n dx_i\cdot dy_i$${#eq-cov4}

@eq-cov4 in Worten ausgedr√ºckt:

1. Rechne f√ºr jedes $x_i$ die Abweichung vom Mittelwert, $\bar{x}$, aus, $dx_i$.
1. Rechne f√ºr jedes $y_i$ die Abweichung vom Mittelwert, $\bar{y}$, aus, $dy_i$.
3. Multipliziere f√ºr alle $i$ $dx_i$ mit $xy_i$, um die Abweichungsrechtecke $dx_i dy_i$ zu erhalten.
4. Addiere die Fl√§chen der Abweichungsrechtecke.
5. Teile durch die Anzahl der Beobachtungen $n$.


:::{#exm-pos-kov}
### Variablen mit positiver Kovarianz

- Gr√∂√üe und Gewicht
- Lernzeit und Klausurerfolg
- Distanz zum Ziel und Reisezeit
- Temperatur und Eisverkauf$\square$
:::



:::{#exm-neg-kov}
### Variablen mit negativer Kovarianz

- Lernzeit und Freizeit
- Alter und Restlebenszeit
- Temperatur und Schneemenge
- Lebenszufriedenheit und Depressivit√§t$\square$
:::


Drei Extrembeispiele f√ºr Kovarianz-Werte sind in @fig-demos-cov dargestellt.


```{r}
#| echo: false
#| label: fig-demos-cov
#| fig-cap: Verschiedene Werte der Kovarianz
#| fig-subcap: 
#|   - kein Zusammenhang
#|   - perfekter (positiver) Zusammenhang
#|   - negativer Zusammenhang
#| layout-ncol: 3

# zero correlation
points1 <- data.frame(
  x = c(1,1,2,2,4,4,5,5),
  y = c(1,5,2,4,2,4,5,1)
)

cor.rect.plot(y = points1$y, x = points1$x,
              xlab = "X", ylab = "Y")

# perfect correlation
points2 <- data.frame(
  x = c(1,2,3,4,5,6,7),
  y = c(1,2,3,4,5,6,7)
)

cor.rect.plot(y = points2$y, x = points2$x,
              xlab = "X", ylab = "Y")

# perfect negative correlation
points3 <- data.frame(
  x = c(1,2,3,4,5,6,7),
  y = c(2.1,6,5,4,3,2,1)
)


cor.rect.plot(y = points3$y, x = points3$x,
              xlab = "X", ylab = "Y")
```



Bei einer Kovarianz von (ungef√§hr) 0 ist die Gesamt-Fl√§che der Abweichungsrechtecke^[Bei der Varianz waren es Quadrate, bei der Kovarianz sind es Rechtecke.], wenn man sie pro *Quadrant* aufsummiert, ungef√§hr gleich gro√ü, s. @fig-covnull.
Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so betr√§gt die Summe in etwa (oder genau) Null.

Damit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null, s. @eq-cov-is-zero: Wenn die Summe der Aweichungsrechtecke Null ist, dann ist auch ihr Mittelwert (MW) Null. Damit ist die Kovarianz Null.



$$\begin{aligned}
\sum \left(dX \cdot dY \right) &= 0\\
\Leftrightarrow \text{MW} \left(dX \cdot dY \right) &= 0\\
\Leftrightarrow \text{cov}(X, Y) &= 0
\end{aligned}$${#eq-cov-is-zero}




```{r}
#| echo: false
#| label: fig-covnull
#| fig-cap: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus
#| layout-ncol: 2
#| fig-subcap: 
#|   - 4 Abweichungsrechtecke, deren Fl√§che sich zu 0 addiert
#|   - 200 Abweichungsrechtecke, deren Fl√§che sich zu 0 addiert



# zero correlation
points1 <- data.frame(
  x = c(1,1,2,2,4,4,5,5),
  y = c(1,5,2,4,2,4,5,1)
)

#cor(points1$x, points1$y)

cor.rect.plot(y = points1$y, x = points1$x,
              xlab = "X", ylab = "Y")


# simulated data, uncorrelated
samples = 200
r = 0


data = MASS::mvrnorm(n=samples, mu=c(0, 0), Sigma=matrix(c(1, r, r, 1), nrow=2), empirical=TRUE)

data.df <- data.frame(data)

# p1 <- ggplot(data.df, aes(x=X1, y=X2)) + geom_point() + 
#   theme(text = element_text(size = 18))
# p1

cor.rect.plot(y = data.df$X1, x = data.df$X2,
              xlab = "X", ylab = "Y")
```






### Die Kovarianz ist schwer zu interpretieren

Die Kovarianz hat den Nachteil, dass sie abh√§ngig ist von der Skalierung.
So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst.
Das ist nicht w√ºnschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabh√§ngig davon, 
ob man Einkommen in Euro, Cent oder Dollar misst.
Au√üerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt.
Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.



## Korrelation

### Korrelation als mittleres z-Produkt

Der Korrelationskoeffizient $r$ nach Karl Pearson l√∂st das Problem, dass die Kovarianz schwer interpretierbar ist.
Der Wertebereich von $r$ reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation).
Eine Korrelation von $r = 0$ bedeutet *kein linearer* Zusammenhang.


Die Korrelation berechnet sich wie folgt:

1. Teile alle $x_i$ durch ihre Standardabweichung, $s_x$
2. Teile alle $y_i$ durch ihre Standardabweichung, $s_y$
3. Berechne mit diesen Werten die Kovarianz


Teilt man n√§mlich alle $x_i$ bzw. $y_i$ durch ihre Standardabweichung,
so f√ºhrt man mit $X$ bzw. $Y$ eine z-Transformation durch.
Daher kann man den Korrelationskoeffizienten $r$ so definieren:


:::{#def-r}
### Korrelationskoeffizient r

Der Korrelationskoeffizient $r$ (nach Pearson) ist definiert als das mittlere Produkt der z-Wert-Paare, s. @eq-r-def, vgl. @cohen_applied_2003. Er ist ein Ma√ü des linearen Zusammenhangs zweier metrischer Variablen. Der Wertebereich ist $[-1;1]$, wobei 0 keinen Zusammenhang anzeigt und $|r|=1$ perfekten Zusammenhang. $\quad \square$
:::

$$r_{xy}=\frac{1}{n}\sum_{i=1}^n z_{x_i} z_{y_i}$${#eq-r-def}

Man beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur f√ºr metrische Variablen definiert ist.


:::{.callout-note}
Aus dem Korrelationskoeffizienten k√∂nnen Sie zwei Informationen ableiten:

1. *Vorzeichen*: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).
2. *Absolutwert* der Korrelation: Der Absolutwert^[Betrag] des Korrelationskoeffizienten gibt die St√§rke des linearen Zusammenhangs an. Je n√§her der Wert bei 1 liegt desto st√§rker der Zusammenhang. 
  - $r = 0$: kein linearer Zusammenhang
  - $r = 1$: perfekter linearer Zusammenhang$\square$
:::



Eine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt @fig-corr-wiki.

![Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0](img/Correlation_examples2.svg){#fig-corr-wiki}

Die untere Zeile von @fig-corr-wiki zeigt Beispiele f√ºr nicht-lineare Zusammenh√§nge.
Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor ($r=0$), obwohl ein starker *nicht*-linearer Zusammhang besteht.

:::{#exr-corrgame}
### Korrelationsspiel
Spielen Sie das [Korrelationsspiel](https://gallery.shinyapps.io/correlation_game/): Sie Sehen ein Streudiagramm und m√ºssen den richtigen Korrelationskoeffizienten eingeben.$\square$
:::




:::{#exr-corrvis}
### Interaktive Visualisierung der Korrelation

Auf der Seite von [RPsychologist](https://rpsychologist.com/correlation/) findet sich eine ansprechende dynamische Visualisierung der Korrelation.
Nutzen Sie sie, um Ihr Gef√ºhl f√ºr die St√§rke des Korrelationskoeffizienten zu entwickeln.$\square$
:::


### Korrelation mit R berechnen

Ob der Verkaufspreis (`total_pr`) wohl mit der Dauer der Auktion (`duration`) oder mit der Anzahl der Gebote (`n_bids)` (linear) zusammenh√§ngt? 
Schauen wir nach! Die Funktion `correlation()` (aus dem Paket `{easystats}`) erledigt das Rechnen f√ºr uns, s. @tbl-mario-corr1.



```{r}
#| eval: false
mariokart |> 
  select(total_pr, duration, n_bids) |> 
  correlation()  |>  # aus `easystats`
  summary()
```



```{r mario-corr1}
#| echo: false
#| tbl-cap: "Korrelation berechnen mittels der Funktion `correlation` aus `easystats`"
mariokart |> 
  select(total_pr, duration, n_bids) |> 
  correlation() |> 
  summary() |> 
  print_md()
```




Sie k√∂nnen auch auf die letzte Zeile, also dem Befehl `summary()` verzichten. Dann ist die Ausgabe ausf√ºhrlicher.


### Korrelation ‚â† Kausation

Eine Studie fand eine starke Korrelation, 
 zwischen der (H√∂he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes [@messerli_chocolate_2012], s. @fig-schoki.
 
 ![Schoki futtern macht schlau?](img/correlation_550.png){#fig-schoki width=75%}

:::{.callout-caution}
Korrelation (bzw. Zusammenhang) ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. 
Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation. 
:::






### Korrelation misst nur linearen Zusammenhang





:::{#exm-scheinkorr}
### Scheinkorrelation


*St√∂rche und Babies*: Eine Urban Myth besagt: Die Anzahl der St√∂rche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis.

Eine Erkl√§rung f√ºr dieses (nur scheinbare) Paradoxon ist, dass die "Naturbelassenheit" des Landkreises die gemeinsame Ursache f√ºr St√∂rche ist (St√∂rche lieben Natur) und f√ºr Babies ist (die dortige Kultur beg√ºnstigt, mehr Kinder pro Frau). 


*Corona und Glatze*:

Macht die Glatze krank? M√§nner mit Glatze bekommen h√§ufiger Corona [@goren_preliminary_2020].

>   Bald men at higher risk of severe case of Covid-19, research finds^[<https://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/>, Abruf 2023-03-24]

Eine Erkl√§rung lautet, dass Alter einen Effekt hat auf Glatze (je √§lter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatz hat) und auf die Schwere des Corona-Verlaufs (√§ltere Menschen haben deutlich schwerere Corona-Verl√§ufe). $\square$

:::



## Wie man mit Statistik l√ºgt

### Range-Restriktion

Durch (nicht-randomisierte) Einschr√§nkung (Restriktion) des Ranges einer (oder beider) Variablen sinkt die St√§rke (der Absolutwert) einer Korrelation, vgl. @cohen_applied_2003 und @fig-corr-range.


Erstellen wir uns dazu zwei Datens√§tze mit je zwei Variablen, $X$ und $Y$ der Gr√∂√üe $n=100$.
Ein Datensatz ist ohne Einschr√§nkung des Ranges und einer mit.
$X$ und $Y$ seien normalverteilt mit $\mu=0$ (Mittelwert) und  $\sigma=1$ (Streuung); s. Datensatz `d` in @lst-corr-range.
Wir schr√§nken dann den Range von $X$ ein auf, sagen wir, den Bereich von $[-0.5, .5]$ (Datensatz `d_filtered`).


::: {#lst-corr-range}

```{r}
#| echo: true

set.seed(42)
n <- 1e2
d <-
  tibble(x = rnorm(n = n, mean = 0, sd = 1),
         e = rnorm(n = n, mean = 0, sd = .5),
         y = x + e)

x_min <- -0.5
x_max <- 0.5

d_filtered <-
d |> 
  filter(between(x, x_min, x_max))
```

:::

```{r}
#| echo: false
#| label: fig-corr-range
#| fig-cap: Schr√§nkt man den Range einer (oder beider) Variablen ein, so sinkt die St√§rke der Korrelation
#| layout-ncol: 2
#| fig-subcap: 
#|   - "Ohne Einschr√§nkung des Range: Starke Korrelation"
#|   - "Mit Einschr√§nkung des Range: Schw√§chere Korrelation"

d |> 
ggplot(aes(x = x, y = y)) +
  geom_point() +
  labs(title = paste0("r: ", round(cor(d$x, d$y), 2))) +
  theme_modern() +
  theme(plot.title = element_text(size = 16))

d_filtered |>   
ggplot(aes(x = x, y = y)) +
  annotate("rect", xmin = x_min, xmax = x_max, ymin = -Inf, ymax = Inf, fill = okabeito_colors()[1], alpha = .5) +
  geom_point(data = d, color = "grey80") +
  geom_point() +
  labs(title = paste0("r: ", round(cor(d_filtered$x, d_filtered$y), 2))) +
  theme_modern()
  
```


:::{#exr-corr-range}
### Berechnen Sie die Korrelation
Glauben Sie nicht, pr√ºfen Sie nach! Berechnen Sie die Korrelation von $X$ und $Y$ im Datensatz `d` und `d_filtered`! $\square$
:::






## Fallbeispiel


In Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenh√§ngen.


Falls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, k√∂nnen Sie die Daten so (in mittlerweile gewohnter Manier) importieren:

```{r}
#| eval: false
mariokart <- read.csv("mariokart.csv")
```


Falls der Datensatz im Unterordner mit Namen "Mein_Unterordner" liegt, so w√ºrden Sie folgenden Pfad eingeben:

```{r}
#| eval: false
mariokart <- read.csv("Mein_Unterordner/mariokart.csv")
```

Man beachte, dass solche sog. relativen Pfade (relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio) *nicht* mit einem Schr√§gstrich (Slash) beginnen.

Falls Sie die Daten nicht auf Ihrem Computer haben,
k√∂nnen Sie sie komfortable von z.B. der Webseite von [Vincent Arel-Bundock](https://vincentarelbundock.github.io/Rdatasets) herunterladen:

::: {.content-visible when-format="html"}

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```

:::

::: {.content-visible when-format="pdf"}

Den Pfad hatten wir in @lst-mario-path definiert.

```{r}
mariokart <- read.csv(mariokart_path)
```
:::

Sie w√§hlen die Variablen von `mariokart`, die Sie in diesem Fall interessieren -- nat√ºrlich nur die metrischen -- und lassen sich mit `cor` die Korrelation aller Variablen untereinander ausgeben: 

::: {.content-visible when-format="html"}

```{r}
mariokart %>%  
  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %>% 
  cor() %>% 
  round(2) # Runden auf zwei Dezimalen
```

:::

::: {.content-visible when-format="pdf"}
```{r}
mariokart %>%  
  dplyr::select(start_pr, ship_pr, total_pr) %>% 
  cor() %>% 
  round(2) # Runden auf zwei Dezimalen
```
:::


:::{.callout-caution}
### Namensverwechslung (name clash)
Es kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen `select` gibt.
R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben.
Das kann dann das falsche `select` sein, wie es mir oben in der Syntax passiert ist.
In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngem√§√ü sagt: "Hey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt." Auf Errisch: `Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels)`.
Eine einfache Abhilfe ist es, R zu sagen: "Hey R, nimm gef√§lligst `select` aus dem Paket `dplyr`, dort "wohnt" n√§mlich `select`. Auf Errisch spricht sich das so: `dplyr::select(...)`.$\square$
:::


::: {.content-visible when-format="html"}

Etwas sch√∂ner sieht die Ausgabe mit dem Befehl `correlation` aus `{easystats}` aus, s. @tbl-mario-corr.

```{r}
#| label: tbl-mario-corr
#| tbl-cap: Korrelationstabelle (tidy) im Datensatz mariokart
mariokart %>% 
  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %>% 
  correlation() 
```

:::

::: {.content-visible when-format="pdf"}
Etwas sch√∂ner sieht die Ausgabe mit dem Befehl `correlation` aus `{easystats}` aus, s. @tbl-mario-corr-pdf.

```{r}
#| label: tbl-mario-corr-pdf
#| tbl-cap: Korrelationstabelle (tidy) im Datensatz mariokart
mariokart %>% 
  dplyr::select(start_pr, ship_pr, total_pr) %>% 
  correlation() 
```

:::



Neben einigen Statistiken, die wir einfach geflissentlich ausblenden (`t` und `p`) beinhaltet die Tabelle eine interessante Information: den Sch√§tzbereich f√ºr die Korrelation, gekennzeichnet als `95% CI`.
*Grob* gesagt k√∂nnen wir diese Information so interpretieren: "Mit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich."^[Bayesianische Interpretation]


M√∂chte man nur einzelne Korrelationskoeffizienten ausrechnen, k√∂nnen wir die Idee des Zusammenfassens, s. @eq-desk2, nutzen:

```{r}
mariokart %>% 
  summarise(cor_super_wichtig = cor(total_pr, wheels))
```

:::{.callout-caution}
Im Falle von fehlenden Werte m√ºssen Sie den Befehl `cor()` aus seiner sch√ºchternen Vorsicht befreien und ermutigen, 
trotz fehlender Werte einen Korrelationskoeffizienten auszugeben.
Das geht mit dem Argument `use = "complete.obs"` in `cor`.
:::

```{r}
mariokart %>% 
  summarise(cor_super_wichtig = cor(total_pr, wheels, use = "complete.obs"))
```



>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Immer so viele Zahlen! Ich brauch Bilder.

::: {.content-visible when-format="html"}

Mit dem Befehl `plot_correlation` aus dem R-Paket `{dataExplorer}` bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. @fig-mario-corr.

```{r}
#| label: fig-mario-corr
#| fig-cap: Heatmap zu den Korrelationen im Datensatz mariokart.
library(DataExplorer)

mariokart %>% 
  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %>% 
  plot_correlation()
```

:::


::: {.content-visible when-format="pdf"}

Mit dem Befehl `plot_correlation` aus dem R-Paket `{dataExplorer}` bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. @fig-mario-corr-pdf.

```{r}
#| label: fig-mario-corr-pdf
#| fig-cap: Heatmap zu den Korrelationen im Datensatz mariokart.
library(DataExplorer)

mariokart %>% 
  dplyr::select(start_pr, ship_pr, total_pr) %>% 
  plot_correlation()
```

:::



## Vertiefung



Dieser [TED-Vortrag](https://www.youtube.com/watch?v=8B271L3NtAw) informiert zum Thema Scheinkorrelation.
[Hier](https://scheinkorrelation.jimdofree.com/) finden Sie weitere Beispiele f√ºr Scheinkorrelationen.



## Aufgaben

Schauen Sie sich auch mal auf der Webseite *Datenwerk*^[<https://datenwerk.netlify.app/>] die Aufgaben zu  dem Tag [association](https://datenwerk.netlify.app/#category=association) an.

1. [nasa02](https://datenwerk.netlify.app/posts/nasa02/nasa02.html)
2. [mariokart-korr1](https://datenwerk.netlify.app/posts/mariokart-korr1/mariokart-korr1.html)
2. [mariokart-korr2](https://datenwerk.netlify.app/posts/mariokart-korr2/mariokart-korr2.html)
3. [mariokart-korr3](https://datenwerk.netlify.app/posts/mariokart-korr3/mariokart-korr3.html)
2. [mariokart-korr4](https://datenwerk.netlify.app/posts/mariokart-korr4/mariokart-korr4.html)
5. [korr01](https://datenwerk.netlify.app/posts/korr01/korr01.html)
5. [korr02](https://datenwerk.netlify.app/posts/korr02/korr02.html)

## Halbzeitquiz

Testen Sie Ihr Wissen mit [diesem Quiz](https://forms.gle/w7eTW3ftKy8Hv3nw8) zur deskriptiven Statistik (Ma√üe der zentralen Tendenz, Variabilit√§t, Verteilungsformen, Normalverteilung, Korrelation).^[<https://forms.gle/w7eTW3ftKy8Hv3nw8>]

## Fallstudien

1. [YACSDA: EDA zu Flugversp√§tungen](https://datenwerk.netlify.app/posts/flights-yacsda-eda/)

:::{.callout-note}
Einige der Fallstudien oder √úbungsaufgaben k√∂nnen theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen.
In dem Fall: Einfach ignorieren. 
Oder Sie suchen nach einer L√∂sung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.$\square$
:::





2. [YACSDA: Topgear](https://data-se.netlify.app/2021/02/11/yacda-topgear/)
4. [Datensatz flights: Finde den Tag mit den meisten Abfl√ºgen](https://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/)
5. [Tidyverse Case Study: Exploring the Billboard Charts](https://www.njtierney.com/post/2017/11/07/tidyverse-billboard/)


:::{.callout-note}
Bitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl.
Es ist nicht n√∂tig, dass Sie alle Fallstudien bearbeiten.
Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und √úbung, dort, wo Sie es n√∂tig haben.$\square$
:::


## Literaturhinweise

Auch die Korrelation ist ein Allzeit-Favorit in der Statistik;
entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erl√§utern. 
Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat.
Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei @kaplan_statistical_2009 freuen.
Ein sch√∂nes, modernes Statistikbuch bietet der Psychologie-Prof Russel Poldrack von der Princeton University [-@poldrack_statistical_2023]; auch dieses Buch ist frei online verf√ºgbar. Tipp: Nutzen Sie die √úbersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen.
Ein Klassiker, wenn auch nicht mehr ganz frisch, ist  @cohen_applied_2003; immer noch sehr empfehlenswert, aber etwas h√∂heren Anspruchs.

## Literatur


