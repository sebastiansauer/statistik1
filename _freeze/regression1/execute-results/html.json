{
  "hash": "b8063b5707885e8e013dc43fff3e4f47",
  "result": {
    "markdown": "# Geradenmodelle 1 {#sec-gerade1}\n\n\n\n## Lernsteuerung\n\n\n\n\n### Standort im Lernpfad\n\nAbb. @fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n\n\n\n\n\n\n### Lernziele\n\n\n- Sie k√∂nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\n- Sie k√∂nnen die Bestandteile eines Geradenmodells aufz√§hlen und erl√§utern.\n- Sie k√∂nnen die G√ºte eines Geradenmodells anhand von Kennzahlen bestimmen.\n- Sie k√∂nnen Geradenmodelle sowie ihre Modellg√ºte in R berechnen.\n\n\n### Ben√∂tigte R-Pakete\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-1_febb832dc55bf40daca33cfc6bca7b74'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n### Ben√∂tigte Daten\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-2_70c844dc44ef94097816cc4cf0aecf77'}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n## Vorhersagen\n\n\nVorhersagen sind eine n√ºtzlich Sache, unter (mindestens) folgenden Voraussetzungen:\n\n1. Sie sind pr√§zise\n2. Wir kennen die Pr√§zision\n3. Jemand interessiert sich f√ºr die Vorhersage\n\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch *lineare Regression*.\n\n\n### Vorhersagen ohne Pr√§diktor\n\n:::{#exm-noten-prognose}\nNach intensiver Besch√§ftigung mit Statistik sind Sie allgemein als Checker bekannt.\nViele j√ºngere Studentis fragen Sie um Rat.\neines Tages kommt ei Studenti, Toni, und fragt: \"Welche Statistiknote kann ich in der Klausur erwarten?\"\nSie entgegnen: \"Wie viel hast du denn gelernt?\".\nDie Antwort: \"Sag ich nicht.\"\n\nNach kurzem √úberlegen geben sie den Notenschnitt der letzten Klausur als Prognose f√ºr dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).\n\nZuerst importieren Sie die Daten der letzten Klausur^[Diese Syntax wird bei Ihnen nur funktionieren, wenn auf *Ihrem Computer* dieser Ordner mit dieser Datei existiert. Andernfalls m√ºssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.]:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-3_7395e61aab19633dd3ef0a99be646697'}\n\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-4_5dfa9ff647fd3ab54f4b7294c02a6d89'}\n\n```{.r .cell-code}\nnoten2 <- read.csv(\"daten/noten2.csv\")\n```\n:::\n\n\nDann rechnen Sie den Mittelwert aus:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-5_b6a97dc451d6d600dd88762142a5e569'}\n\n```{.r .cell-code}\nnoten2 %>% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mw\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"71.07968\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIhre Antwort lautet also: \"Im Schnitt haben die Studis bei der letzten Klausur gut 50% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorherage machen, sorry!\"$\\square$\n:::\n\n:::{.callout-note}\nOhne Kenntnis eines Pr√§diktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert f√ºr jede Beobachtung, s. @fig-noten3.\nWir nutzen den Mittelwert als Punktmodell f√ºr den Klausurerfolg.$\\square$\n:::\n\n\n::: {.cell hash='regression1_cache/html/fig-noten3_0b2d6b0781a2a2683facb8bdb3988b98'}\n::: {.cell-output-display}\n![Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell](regression1_files/figure-html/fig-noten3-1.png){#fig-noten3 width=672}\n:::\n:::\n\n\n:::{def-nullmodell}\n### Nullmodell\nModelle ohne Pr√§diktor, Punktmodelle also, kann man so bezeichnen: `y ~ 1`. \nDa es null Pr√§diktoren hat, nennt man es auch manchmal \"Nullmodell\".\n:::\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-7_6e6257dcd4b27a1b0eba006055a2b02c'}\n\n```{.r .cell-code}\nlm0 <- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##       71.08\n```\n:::\n\n\n`lm` steht f√ºr \"lineares Modell\", die `0` sagt, dass es keine Pr√§diktoren gibt.\nIn dem Fall wird der Mittelwert als Gerade verwendet.\nDer zur√ºckgemeldete Koeffizient `(Intercept)` ist hier der Modell des Punktmodells.\nDa es ein Punktmodell ist, sagt es f√ºr alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\n\n\n\n### Vorhersagen mit Pr√§diktor\n\n\n\n\n:::{#exm-noten3}\n### Toni verr√§t die Lernzeit\n\nDis Studenti, Toni, entschlie√üt sich dann doch noch, die Lernzeit zu verraten:\n\"Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.\"\nJetzt m√ºssen Sie erstmal nachdenken: \"Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 gelernt hat?\"\n\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. @fig-noten4, links.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-8_cdea3e77f16126b1181651be298d736c'}\n\n```{.r .cell-code}\nnoten2 <- read.csv(noten2, \"daten/noten2.csv\")\n\nlibrary(DataExplorer)\nnoten2 %>% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-9_5b833fc670733992d823407a8ac4263e'}\n\n:::\n\n\n\nAuf dieser Basis antworten Sie Toni: \"Bei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. K√∂nnte mit dem Bestehen eng werden.\"\nToni ist nicht begeistert von Ihrer Prognose und zieht von dannen.$\\square$\n:::\n\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeiten und Klausurpunkte ist deutlich zu erkennen.\nMit einem Lineal k√∂nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. @fig-noten4.\n\n\n\n::: {#fig-noten4 .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-noten4_af58971602d77d2ebebd770e66f124b4'}\n::: {.cell-output-display}\n![Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)](regression1_files/figure-html/fig-noten4-1.png){#fig-noten4-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Eine 'Trendgerade' (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet.](regression1_files/figure-html/fig-noten4-2.png){#fig-noten4-2 width=672}\n:::\n\nNoten und Lernzeit: Rohdaten und Modell\n:::\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.\n\n\n\n## Geradenmodelle\n\n\n### Achsenabschnitt und Steigung definieren eine Gerade\n\nWir verwenden eine Gerade als Modell f√ºr die Daten, s. @fig-noten4, rechts.\nAnders gesagt: Wir modellieren die X-Y-Daten (bzw. ihren Zusammenhang) mit einem Geradenmodell.\n\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells:\nEin Punktmodell sagt f√ºr alle Beobachtungen den gleichen Wert vorher.\n@fig-noten3 und @fig-noten4 stellen ein Punktmodell einem Geradenmodell gegen√ºber.\n\nIn einem Geradenmodell wird nicht mehr (notwendig) f√ºr jede Beobachtung die gleiche Vorhersage $\\hat{y}$ gemacht (wie das bei einem Punktmodell der Fall ist).\n\n\n:::{#def-gerade}\nEine Gerade ist definiert durch zwei *Koeffizienten*: Achsenabschnitt (engl. intercept), und Steigung (engl. slope).\nH√§ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit $t$ und die Steigung mit $m$ bezeichnet: $f(x)=y=\\color{blue}[m]x + \\color{red}[t]$.\nIn der Statistik wird folgende Nomenklatur bevorzugt: $f(x)=\\hat{y} = \\color{red}{b_0} + \\color{blue}{b_1}x$ oder $y = \\color{red}{\\beta_0} + \\color{blue}{\\beta_1}x$ .^[Die Nomenklatur mit $b_0, b_1$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage √ºber eine Population, nicht nur √ºber eine Stichprobe, machen m√∂chte.]\n\n\n@fig-regrtex skizziert die Elemente einer Regression.\n:::\n\n\n![Achsenabschnitt und Steigung einer Regressionsgeraden](img/regr.png){#fig-regrtex width=\"70%\"}\n\n\n[Basierend auf diesem Diagramm von Henri Menke](https://texample.net/tikz/examples/linear-regression/)\n\n\n\n\n:::{#exm-noten5}\n### Toni will es genau wissen\nDa Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert.\n\"Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zur√ºck!\"\n\nDas sind gute Fragen. Den Y-Wert (Klausurpunkte) bei $X=0$ gibt der Achsenabschnitt zur√ºck. Schnell skizzieren Sie dazu ein Diagramm, s. @fig-beta0.\nPuh, die Antwort wird Toni nicht gefallen ...\n:::\n\n\n::: {.cell hash='regression1_cache/html/fig-beta0_2e532a81a10013a6f6ba10fce9d4683d'}\n::: {.cell-output-display}\n![Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)](regression1_files/figure-html/fig-beta0-1.png){#fig-beta0 width=672}\n:::\n:::\n\n\n\n\nAnstelle auf @fig-beta0 zu schauen, k√∂nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n\n>    üßë‚Äçüéì Hey R, predicte mir mal auf Basis vom Modell \"lm1\" den Lernerfolg f√ºr Toni, wenn der x=0 Stunden lernt.\n\n>    ü§ñ Okay, ich predicte mit Modell \"lm1\" und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-12_4b1532cd46dfdcd12d6086c3e5b24e83'}\n\n```{.r .cell-code}\ntonis_lernzeit <- tibble(x = 0)\ntonis_lernzeit\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-13_a445df4204cbc1758d06a98963c3ae12'}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit)\n##        1 \n## 8.603032\n```\n:::\n\n\n\n### Spezifikation eines Geradenmodells\n\n\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. @eq-mod1:\n\n$$\\hat{y} \\sim x$$ {#eq-mod1}\n\n\nLies: \"Laut meinem Modell ist $\\hat{y}$ irgendeine Funktion von $y$\".\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\n\n\n@eq-mod1 k√∂nnen Sie so ins Errische √ºbersetzen:\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-14_44d1a0bb62b3124432d183f13e99b787'}\n\n```{.r .cell-code}\nlm(y ~ x, data = meine_daten)\n```\n:::\n\n\n`lm` steht f√ºr \"lineares Modell\", also eine Gerade als Modell.\nDie Gerade nennt man auch *Regressionsgerade*^[an anderer Stelle in diesem Buch unscharf als \"Trendgerade\" bezeichnet.].\n\n:::{#exm-noten5}\n### Zahlen f√ºr Toni\nToni ist nicht zufrieden mit Ihren Vorhersagen: \"Jetzt h√∂r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir pr√§zise Zahlen!\".\n:::\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-15_846fdd97182898b626bc4851c280e2bf'}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      8.6030       0.8794\n```\n:::\n\n\nR gibt Ihnen die beiden Koeffizienten f√ºr die Gerade aus. \nDen Namen des Objekts k√∂nnen Sie frei aussuchen, z.B. `mein_erstes_lm`.\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige Y-Werte ausrechnen gegeben bestimmte X-Werte.\n\n:::{#exm-noten6}\n### Vorhersage f√ºr Klausurerfolg, n√§chster Versuch\nSie versuchen, noch etwas Gutes f√ºr Toni zu tun.\nR hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-16_676afc7dc97bb257196d7fb6f791f967'}\n\n```{.r .cell-code}\ntonis_lernzeit2 <- tibble(x = 73)\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-17_fc9296b72d7a544c5eae2f94fecf25e8'}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit2)\n##       1 \n## 72.7999\n```\n:::\n\n:::\n\n\nDie Syntax von `predict` lautet:\n\n```\npredict(name_des_objekts, newdata = tabelle_mit_pr√§diktorwerten)\n```\n\n:::{.callout-note}\nMit `predict` bekommt man eine Vorhersage; im Standard eine \"Punkt-Vorhersage\", eine einzelne Zahl.$\\square$\n:::\n\n\n### Vorhersagefehler\n\nDie Differenz zwischen vorhergesagten Wert f√ºr eine (neue) Beobachtung, $\\hat{y_0}$ und ihrem tats√§chlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: $e_i = y_i - \\hat{y}_i$.\n\n\n\n\n::: {#fig-resid .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-resid_181731942064e79c33b2c58655c90806'}\n::: {.cell-output-display}\n![Residuen beim Geradenmodell (lm1)](regression1_files/figure-html/fig-resid-1.png){#fig-resid-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Residuen beim Punktmodell (lm0)](regression1_files/figure-html/fig-resid-2.png){#fig-resid-2 width=672}\n:::\n\nVorhersagefehler als Abweichungsbalken\n:::\n\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\n\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben^[aus dem Paket `easystats`]:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-19_9b2cb0e6eb7870a94e9ad4a4d1c0f851'}\n\n```{.r .cell-code}\nmae(lm0)\n## [1] 11.18385\nmae(lm1)\n## [1] 7.954085\n```\n:::\n\n\n\nVergleichen wir MAE im  Nullmodell mit MAE in `lm1`: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-20_3880e66421a30ce939045b71fada1af2'}\n\n```{.r .cell-code}\nverhaeltnis_fehler_gerade_zu_punkt_mae <- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mae\n## [1] 0.7112118\n```\n:::\n\n\n\n\nAh! Das Geradenmodell ist viel besser:\nVon `lm0` zu `lm1` haben die mittlere (Absolut-)L√§nge des Fehlerbalkens auf 71 Prozent verbessert.\nNicht schlecht!\n\n\n:::{#def-fehlerstreung}\n### Fehlerstreuung\nAls Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte ($y_i$) vom vorhergesagten Wert ($\\hat{y}_i$).$\\square$\n:::\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngr√∂√üen wie MAE oder MSE.\n\n\n:::{.callout-note}\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreung), solange X mit Y korreliert ist.$\\square$\n:::\n\n\nNat√ºrlich k√∂nnen wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen^[Wer mag, kann den MSE auch von Hand berechnen: `mean((noten2$y-mean(noten2$y))^2)`].\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-21_7436194d167aea77fa2b70351397a597'}\n\n```{.r .cell-code}\nmse(lm0)\n## [1] 192.7863\nmse(lm1)\n## [1] 106.4519\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-22_f3f73cc64a55ffe768fe2301535494bc'}\n\n```{.r .cell-code}\nverhaeltnis_fehler_gerade_zu_punkt_mse <- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.5521755\n```\n:::\n\n\n\n### Berechnung der Modellkoeffizienten\n\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\n\nDie Regressionskoeffizienten b0 und b1 w√§hlt man so, dass die Residuen minimal sind.\nEs gibt verschiedene Algorithmen, um dies zu berechnen^[aber nicht in diesem Buch zu finden].\nEine sch√∂ne Darstellung dazu findet sich bei @kaplan_statistical_2009.\n\n\"Von Hand\" k√∂nnen Sie die Optimierung von b0 und b1 in [dieser App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/KleinsteQuadrate/) ausprobieren.\n\n\n\n\n## R-Quadrat\n\n### R-Quadrat als Verringerung der Fehlerstreuung\n\nAnders gesagt, wir haben uns um $1 - 0.55$ verbessert:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-23_e7534ebec6bf90fdc65901c2dbdf6364'}\n\n```{.r .cell-code}\n1 - verhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.4478245\n```\n:::\n\n\n\n:::{#def-r2}\n### R-Quadrat\nDie Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen  von `lm0` zum gerade untersuchten Modell nennt man  *R-Quadrat* ($R^2$).$\\square$\n:::\n\nWir k√∂nnen es uns von R z.B. so ausgeben lassen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-24_4ca1c4ba778274d93ecdbbe269d129fe'}\n\n```{.r .cell-code}\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n```\n:::\n\n\n\n:::{#def-r2}\n### R-Quadrat\nR-Quadrat ($R^2$) eines Modells $m$ ist definiert als die Verringerung der Streuung, wenn man das Modell $m$ mit dem Nullmodell $m_0$ vergleicht: $R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}$. R-Quadrat ist ein Ma√ü der *Modellg√ºte*: Je gr√∂√üer $R^2$, desto besser die Vorhersage. \nDa es ein Anteilsma√ü^[Prozentzahl] ist, liegt der Wertebereich zwischen 0 uns 1.\nIm Nullmodell liegt R-Quadrat per Definition bei 0.\nIm Fall von Modellen des Typs $y\\sim x$ gilt: $R^2 = r_{xy}^2$.\n$\\square$\n:::\n\n\n\nBei einer perfekten Korrelation ist $r=1$, daher ist dann auch $R^2 = 1$^[Bei Modellen mit einem Pr√§diktor; gibt es mehrere Pr√§diktoren gilt die Beziehung nur wenn die Pr√§diktoren alle paarweise unabh√§ngig sind.], \ns. @fig-r2-extreme.\n\n\n\n::: {#fig-r2-extreme .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-r2-extreme_504305156e68603978d7c9a70f866dd8'}\n::: {.cell-output-display}\n![Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert](regression1_files/figure-html/fig-r2-extreme-1.png){#fig-r2-extreme-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert](regression1_files/figure-html/fig-r2-extreme-2.png){#fig-r2-extreme-2 width=672}\n:::\n\nExtremf√§lle von R-Quadrat: 0 und 1\n:::\n\n\nBei einer perfekten Korrelation $R^2=1$ liegen die Punkte auf der Geraden.\nIm gegenteiligen Extremfall von $R^2=0$ ist die Vorhersage genauso gut, wie wenn man f√ºr jedes $y$ den Mittelwert, $\\bar{y}$, vorhersagen w√ºrde. \n\n\n:::{.callout-note}\nJe gr√∂√üer R-Quadrat, desto besser erkl√§rt das Modell die Daten (desto besser der \"Fit\", sagt man).\n:::\n\n[Diese App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/Variationszerlegung/) erlaubt es Ihnen mit der Gr√∂√üe der Residuen eines linearen Modells zu spielen.\n\n\n\n\n### Addition der Varianzen\n\n\nNennen wir die Varianz des Verkaufspreis $s^2_y$, die Verbesserung der Fehlerstreuung durch das *M*odell $s^2_m$ und die restliche Fehlerstreuung, den MSE, $s^2_e$.\nDann gilt:\n\n$$s^2_y = s^2_m + s^2_e \\\\\ns^2_m = s^2_y - s^2_e$$\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-26_9bc4b2f521d088218a3ec17369321d30'}\n\n```{.r .cell-code}\ns2_y = var(noten2$y)\ns2_e = mse(lm1)\ns2_m = s2_y - s2_e\ns2_m\n## [1] 88.28178\n```\n:::\n\n\nDie Varianzanteile addieren sich. Mit anderen Kennzahlen der Streuung (SD, MAE) funktioniert das nicht.\n\n\n## Interpretation des Modells\n\n\n### Modellg√ºte\n\nDie Residuen bestimmen die Modellg√ºte. Verschiedenen Koeffizienten stehen hier zur Verf√ºgung: R-Quadrat, r^[als Korrelation von tats√§chlichem $y$ und vorhergesaten $\\hat{y}], MSE, RMSE, MAE, ...\n\n\n### Koeffizienten\n\nDie Modellkoeffizienten, also Achsenabschnitt ($b_0$) und Steigung ($b_1$) sind nur eingeschr√§nkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abh√§ngigkeiten nicht kennt.\nNur aufgrund eines Zusammenhangs darf man keine kausalen Abh√§ngigkeiten annehmen.\nOhne eine guten Grund f√ºr eine Kausalbehauptung kann man kann nur *deskriptiv* argumentieren.\nOder sich mit der Modellg√ºte und den Vorhersagen begn√ºgen. Was auch was wert ist.\n\n#### Achsenabschnitt (b0)\n\n\"Im Modell `lm1` liegt der Achsenabschnitt bei $y=8.6$. Beobachtungen mit $x=0$ k√∂nnen also diesen Y-Wert erwarten.\"\nLeider ist es h√§ufig so, dass Pr√§diktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig n√ºtzt.\n\n:::{#exm-groesse}\n### Regression Gr√∂√üe und Gewicht\nNutzt man K√∂rpergr√∂√üe umd das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von K√∂rpergr√∂√üe wenig n√ºtzlich, da es keine Menschen gibt der Gr√∂√üe 0.$\\square$\n:::\n\n\n#### Geradensteigung (b1)\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-27_5c2678faa03bf336e36a9b4590f1acf0'}\n\n:::\n\n\n\n\"Im Modell `lm1` betr√§gt der Regressionskoeffizient `b1` $0.88$. Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich *laut Modell* um den Wert von b1.\"\n\n:::{.callout-caution}\nH√§ufig liest man, der \"Effekt des Pr√§diktors\" auf die AV betrage z.B. $0.88$. \"Effekt\" ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort \"Effekt\" mit Vorsicht genie√üen. Manche sprechen daher auch von einem \"statistischen Effekt\".$\\square$.\n:::\n\n\n## Fallbeispiel Mariokart\n\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt.\nSie m√∂chten eine genaue Vorhersage von Verkaufspreisen erzielen.\nAls Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs.\nGenaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz.\nAuf geht's!\n\nDaten laden:^[Und die √ºblichen Pakete starten, nicht vergessen.]\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-28_84b385cfaeb7ae84867fbe32509b4e86'}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-29_98b337b88682db16c53e66457ee9a18b'}\n\n```{.r .cell-code}\nlm2 <- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n```\n:::\n\n\n\nOh nein! Unterirdisch schlecht. Anstelle von blo√üen Rumprobieren √ºberlegen Sie und schauen dann in @fig-mario-corr nach, welche Variable am st√§rksten korreliert mit `total_pr`,\nes resultiert `lm3`: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-30_84f15efee0005aa64e6ef953057dcd40'}\n\n```{.r .cell-code}\nlm3 <- lm(total_pr ~ ship_pr, data = mariokart)\n```\n:::\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro: Ein Spiel, das mit Null Euro Preis startet, kann laut `lm3` etwa 36 Euro finaler Verkaufspreis erwarten.\nPro Euro an Versandkosten (`ship_pr`) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.^[Die Spalte `95 CI` gibt einen Sch√§tzbereich f√ºr den jeweiligen Modellkoeffizienten an,\ndenn es handelt sich bei den Koeffizienten um Sch√§tzwerte;\nder wahre Wert in der Population ist unbekannt. \nWir kennen schlie√ülich nur eine Stichprobe der Gr√∂√üe $n=143$.].\n\nMan kann sich die erwarteten Werte (\"expectations\") des Verkaufspreises in Abh√§ngigkeit vom Wert der UV (`ship_pr`) auch sch√§tzen (\"to estimate\") lassen, und zwar so^[Die Funktion stammt aus easystats]: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-31_5364fc1dff631a600ebaf169a9ab17a1'}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% head()  # nur die ersten paar vorhergesagten Werte\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"ship_pr\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Predicted\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SE\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_low\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_high\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Residuals\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"4.00\",\"2\":\"53.59442\",\"3\":\"1.874613\",\"4\":\"49.88844\",\"5\":\"57.30041\",\"6\":\"-2.044424\",\"_rn_\":\"1\"},{\"1\":\"3.99\",\"2\":\"53.55105\",\"3\":\"1.873160\",\"4\":\"49.84794\",\"5\":\"57.25416\",\"6\":\"-16.511052\",\"_rn_\":\"2\"},{\"1\":\"3.50\",\"2\":\"51.42581\",\"3\":\"1.822149\",\"4\":\"47.82355\",\"5\":\"55.02808\",\"6\":\"-5.925814\",\"_rn_\":\"3\"},{\"1\":\"0.00\",\"2\":\"36.24554\",\"3\":\"2.537924\",\"4\":\"31.22824\",\"5\":\"41.26284\",\"6\":\"7.754457\",\"_rn_\":\"4\"},{\"1\":\"0.00\",\"2\":\"36.24554\",\"3\":\"2.537924\",\"4\":\"31.22824\",\"5\":\"41.26284\",\"6\":\"34.754457\",\"_rn_\":\"5\"},{\"1\":\"4.00\",\"2\":\"53.59442\",\"3\":\"1.874613\",\"4\":\"49.88844\",\"5\":\"57.30041\",\"6\":\"-8.594424\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\n\n>   ü§ñ Das sieht man in der Spalte `Predicted`, dort steht der vorhersagte Wert f√ºr `total_pr` f√ºr einen bestimmten Wert von `ship_pr`.\n\n\n>    üßë‚Äçüéì Kann ich auch `predict` benutzen? Ich w√ºrde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n>   ü§ñ Ja, klar!\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-32_3461bd4f99ca16adc6fef4b3861f2e59'}\n\n```{.r .cell-code}\nneue_daten <- tibble(\n  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen\n)\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-33_a402df193e76682ed578e6dac5d25f27'}\n\n```{.r .cell-code}\npredict(lm3, newdata = neue_daten)\n##        1        2 \n## 40.58276 53.59442\n```\n:::\n\n\n\n\n\nAber n√ºtzlich w√§re noch, das Modell (bzw. die Sch√§tzung der erwarteten Werte) als Diagramm zu bekommen.\nDas erreicht man z.B. so, s. @fig-lm3.\n\n\n::: {.cell hash='regression1_cache/html/fig-lm3_fdb7e07bca47ff211f7ec45d0fca15ec'}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% plot()\n```\n\n::: {.cell-output-display}\n![Verbildlichung der erwarteteten Werte laut lm3](regression1_files/figure-html/fig-lm3-1.png){#fig-lm3 width=672}\n:::\n:::\n\n\n`estimate_expectation` hei√üt sinngem√§√ü \"sch√§tze den zu erwartenden Wert\".\nKurz gesagt: Wir wollen eine Vorhersage von R.\n\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie \"gut\" das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-35_8fa46db65f9e684a2d893c8bfc552b9a'}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13.0632\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-36_b72f67350742a156aaa7d57ac8488aa2'}\n\n:::\n\n\nDas Modell erkl√§rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-37_ae44153020dd8efe293194480f5fd7d9'}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13.0632\n```\n:::\n\n\n\n\nIm n√§chsten Meeting erz√§hlen Sie Ihrem Chef \"Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!\".\nH√∂rt sich gut an.\nAllerdings h√§tte ihr Chef es gerne genauer. Kann man da noch was machen?\n\n\n## Fallstudie Immobilienpreise\n\n\n### Einf√ºhrung\n\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen.\nKurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei [Kaggle](https://www.kaggle.com/) ein.\n\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. \n\n\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition [Ames House Prices](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview).\n\n- [Beschreibung](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description)\n- [Ziel/Aufgabe](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation)\n- [Spielregeln](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules)\n\n\n### Daten\n\nWenn Sie sich bei Kaggle einloggen m√∂chten, k√∂nnen Sie die Daten von Kaggle herunterladen und zwar [hier](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).\n\nIm Einzelnen m√ºssen Sie folgende Dateien herunterladen:\n\n- *Data_description.txt*: Code book, d.h. Beschreibung der Variablen im Datensatz\n- *train.csv*: Daten von H√§usern, die Sie nutzen, um Modelle zu erstellen\n- *test.csv*:  Daten von H√§usern, von denen Sie den Kaufpreis vorhersagen sollen\n- *sample_submission.csv*: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\n\nSie k√∂nnen auch so auf die Daten zugreifen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-38_2ca9791ab622061de682782ce8024c18'}\n\n```{.r .cell-code}\nd_train_path_online <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\n```\n:::\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\n\nDas Code Book k√∂nnen Sie [hier einsehen und herunterladen](https://github.com/sebastiansauer/Lehre/blob/main/data/ames-kaggle/data_description.txt).\n\n\n### Prognosedatei\n\n\nDie Prognosedatei soll prinzipiell so aussehen:\n\n::: {.cell hash='regression1_cache/html/read-data-ames_0e13840f053ee549da7b4b19eb7eeaf6'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1461\",\"2\":\"169277.1\"},{\"1\":\"1462\",\"2\":\"187758.4\"},{\"1\":\"1463\",\"2\":\"183583.7\"},{\"1\":\"1464\",\"2\":\"179317.5\"},{\"1\":\"1465\",\"2\":\"150730.1\"},{\"1\":\"1466\",\"2\":\"177151.0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte `id` und der Spalte `Saleprice`.\nDie Spalte `id` gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - f√ºr welches Haus Sie also gerade einen Kaufpreis vorhersagen.\ndie Spalte `SalePrice` ist Ihre Vorhersage f√ºr den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht.\nInsgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\n\n\n\nAlles klar? \n\nLos geht's!\n\n\n### Daten importieren\n\nWir starten die √ºblichen R-Pakete und importieren die Daten (`d`):\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-39_498319a67e8b7523c0e2f5544337751a'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n::: {.cell hash='regression1_cache/html/read-data-local_cca9e5ce8a0a98a4c779d13d87e480ee'}\n\n```{.r .cell-code}\nd_train_path <- \"daten/ames-kaggle/train.csv\"\nd_test_path <- \"daten/ames-kaggle/test.csv\"\nd_train <- read_csv(d_train_path)\nd_test <- read_csv(d_test_path)\n```\n:::\n\n\n\n\n:::{.callout-note}\nIn diesem Beispiel gehen wir davon aus, dass die Dateien `train.csv` und `test.csv` in einem Unterordner namens `daten/ames-kaggle` liegen.\nSie m√ºssen sie dort abspeichern.\nDieser Ornder muss ein Unterordner Ihres aktuellen R-Projekts sein.$\\square$\n:::\n\n:::{.callout-caution}\nWenn das Importieren von der Festplatte nicht klappt ... \nEs ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann.\nAber f√ºrs Erste k√∂nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.$\\square$\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-40_f82e498e972a70b9e56eecde9c07777f'}\n\n```{.r .cell-code}\nd_train <- read_csv(d_train_path_online)\nd_test <- read_csv(d_test_path_online)\n```\n:::\n\n### Ein erster Blick in die Daten\n\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, \n@tbl-ames1.\n\n::: {#tbl-ames1 .cell tbl-cap='Verteilung der metrischen Variablen im ames-Datensatz' hash='regression1_cache/html/tbl-ames1_f5e9c1e5b4a67eef94ec3276efa73b9f'}\n\n```{.r .cell-code}\ndescribe_distribution(d_train)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Mean\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SD\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"IQR\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Min\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Max\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Skewness\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Kurtosis\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[9],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n_Missing\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Id\",\"2\":\"7.305000e+02\",\"3\":\"4.216100e+02\",\"4\":\"730.50\",\"5\":\"1\",\"6\":\"1460\",\"7\":\"0.00000000\",\"8\":\"-1.20000000\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MSSubClass\",\"2\":\"5.689726e+01\",\"3\":\"4.230057e+01\",\"4\":\"50.00\",\"5\":\"20\",\"6\":\"190\",\"7\":\"1.40765675\",\"8\":\"1.58018796\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"LotFrontage\",\"2\":\"7.004996e+01\",\"3\":\"2.428475e+01\",\"4\":\"21.00\",\"5\":\"21\",\"6\":\"313\",\"7\":\"2.16356914\",\"8\":\"17.45286726\",\"9\":\"1201\",\"10\":\"259\"},{\"1\":\"LotArea\",\"2\":\"1.051683e+04\",\"3\":\"9.981265e+03\",\"4\":\"4060.00\",\"5\":\"1300\",\"6\":\"215245\",\"7\":\"12.20768785\",\"8\":\"203.24327102\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OverallQual\",\"2\":\"6.099315e+00\",\"3\":\"1.382997e+00\",\"4\":\"2.00\",\"5\":\"1\",\"6\":\"10\",\"7\":\"0.21694393\",\"8\":\"0.09629278\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OverallCond\",\"2\":\"5.575342e+00\",\"3\":\"1.112799e+00\",\"4\":\"1.00\",\"5\":\"1\",\"6\":\"9\",\"7\":\"0.69306747\",\"8\":\"1.10641346\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YearBuilt\",\"2\":\"1.971268e+03\",\"3\":\"3.020290e+01\",\"4\":\"46.00\",\"5\":\"1872\",\"6\":\"2010\",\"7\":\"-0.61346117\",\"8\":\"-0.43955194\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YearRemodAdd\",\"2\":\"1.984866e+03\",\"3\":\"2.064541e+01\",\"4\":\"37.00\",\"5\":\"1950\",\"6\":\"2010\",\"7\":\"-0.50356200\",\"8\":\"-1.27224519\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MasVnrArea\",\"2\":\"1.036853e+02\",\"3\":\"1.810662e+02\",\"4\":\"166.00\",\"5\":\"0\",\"6\":\"1600\",\"7\":\"2.66908421\",\"8\":\"10.08241732\",\"9\":\"1452\",\"10\":\"8\"},{\"1\":\"BsmtFinSF1\",\"2\":\"4.436397e+02\",\"3\":\"4.560981e+02\",\"4\":\"712.75\",\"5\":\"0\",\"6\":\"5644\",\"7\":\"1.68550307\",\"8\":\"11.11823629\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtFinSF2\",\"2\":\"4.654932e+01\",\"3\":\"1.613193e+02\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"1474\",\"7\":\"4.25526111\",\"8\":\"20.11333755\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtUnfSF\",\"2\":\"5.672404e+02\",\"3\":\"4.418670e+02\",\"4\":\"585.00\",\"5\":\"0\",\"6\":\"2336\",\"7\":\"0.92026845\",\"8\":\"0.47499399\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"TotalBsmtSF\",\"2\":\"1.057429e+03\",\"3\":\"4.387053e+02\",\"4\":\"503.50\",\"5\":\"0\",\"6\":\"6110\",\"7\":\"1.52425455\",\"8\":\"13.25048328\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"1stFlrSF\",\"2\":\"1.162627e+03\",\"3\":\"3.865877e+02\",\"4\":\"509.75\",\"5\":\"334\",\"6\":\"4692\",\"7\":\"1.37675662\",\"8\":\"5.74584148\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"2ndFlrSF\",\"2\":\"3.469925e+02\",\"3\":\"4.365284e+02\",\"4\":\"728.00\",\"5\":\"0\",\"6\":\"2065\",\"7\":\"0.81302982\",\"8\":\"-0.55346356\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"LowQualFinSF\",\"2\":\"5.844521e+00\",\"3\":\"4.862308e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"572\",\"7\":\"9.01134129\",\"8\":\"83.23481667\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GrLivArea\",\"2\":\"1.515464e+03\",\"3\":\"5.254804e+02\",\"4\":\"649.75\",\"5\":\"334\",\"6\":\"5642\",\"7\":\"1.36656036\",\"8\":\"4.89512058\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtFullBath\",\"2\":\"4.253425e-01\",\"3\":\"5.189106e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.59606661\",\"8\":\"-0.83909827\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtHalfBath\",\"2\":\"5.753425e-02\",\"3\":\"2.387526e-01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"2\",\"7\":\"4.10340270\",\"8\":\"16.39664195\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"FullBath\",\"2\":\"1.565068e+00\",\"3\":\"5.509158e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.03656156\",\"8\":\"-0.85704282\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"HalfBath\",\"2\":\"3.828767e-01\",\"3\":\"5.028854e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"2\",\"7\":\"0.67589745\",\"8\":\"-1.07692728\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BedroomAbvGr\",\"2\":\"2.866438e+00\",\"3\":\"8.157780e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"8\",\"7\":\"0.21179010\",\"8\":\"2.23087458\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"KitchenAbvGr\",\"2\":\"1.046575e+00\",\"3\":\"2.203382e-01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"4.48839678\",\"8\":\"21.53240384\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"TotRmsAbvGrd\",\"2\":\"6.517808e+00\",\"3\":\"1.625393e+00\",\"4\":\"2.00\",\"5\":\"2\",\"6\":\"14\",\"7\":\"0.67634084\",\"8\":\"0.88076157\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"Fireplaces\",\"2\":\"6.130137e-01\",\"3\":\"6.446664e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.64956518\",\"8\":\"-0.21723721\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GarageYrBlt\",\"2\":\"1.978506e+03\",\"3\":\"2.468972e+01\",\"4\":\"41.00\",\"5\":\"1900\",\"6\":\"2010\",\"7\":\"-0.64941462\",\"8\":\"-0.41834100\",\"9\":\"1379\",\"10\":\"81\"},{\"1\":\"GarageCars\",\"2\":\"1.767123e+00\",\"3\":\"7.473150e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"4\",\"7\":\"-0.34254893\",\"8\":\"0.22099776\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GarageArea\",\"2\":\"4.729801e+02\",\"3\":\"2.138048e+02\",\"4\":\"244.50\",\"5\":\"0\",\"6\":\"1418\",\"7\":\"0.17998091\",\"8\":\"0.91706720\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"WoodDeckSF\",\"2\":\"9.424452e+01\",\"3\":\"1.253388e+02\",\"4\":\"168.00\",\"5\":\"0\",\"6\":\"857\",\"7\":\"1.54137576\",\"8\":\"2.99295092\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OpenPorchSF\",\"2\":\"4.666027e+01\",\"3\":\"6.625603e+01\",\"4\":\"68.00\",\"5\":\"0\",\"6\":\"547\",\"7\":\"2.36434174\",\"8\":\"8.49033581\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"EnclosedPorch\",\"2\":\"2.195411e+01\",\"3\":\"6.111915e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"552\",\"7\":\"3.08987190\",\"8\":\"10.43076594\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"3SsnPorch\",\"2\":\"3.409589e+00\",\"3\":\"2.931733e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"508\",\"7\":\"10.30434203\",\"8\":\"123.66237945\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"ScreenPorch\",\"2\":\"1.506096e+01\",\"3\":\"5.575742e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"480\",\"7\":\"4.12221374\",\"8\":\"18.43906784\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"PoolArea\",\"2\":\"2.758904e+00\",\"3\":\"4.017731e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"738\",\"7\":\"14.82837364\",\"8\":\"223.26849892\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MiscVal\",\"2\":\"4.348904e+01\",\"3\":\"4.961230e+02\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"15500\",\"7\":\"24.47679419\",\"8\":\"701.00334228\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MoSold\",\"2\":\"6.321918e+00\",\"3\":\"2.703626e+00\",\"4\":\"3.00\",\"5\":\"1\",\"6\":\"12\",\"7\":\"0.21205299\",\"8\":\"-0.40410934\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YrSold\",\"2\":\"2.007816e+03\",\"3\":\"1.328095e+00\",\"4\":\"2.00\",\"5\":\"2006\",\"6\":\"2010\",\"7\":\"0.09626851\",\"8\":\"-1.19060057\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"SalePrice\",\"2\":\"1.809212e+05\",\"3\":\"7.944250e+04\",\"4\":\"84075.00\",\"5\":\"34900\",\"6\":\"755000\",\"7\":\"1.88287576\",\"8\":\"6.53628186\",\"9\":\"1460\",\"10\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Ein erstes Vorhersagemodell\n\n\n#### Welche Variablen eignen sich zur Vorhersage?\n\n\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, \ndie Korrelation aller Pr√§diktoren mit der abh√§ngigen Variablen^[die vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt] zu berechnen.\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-42_68da6ec1cc2697dd45f25d6ce99e47d0'}\n\n```{.r .cell-code}\nd_train %>% \n  select(-Id) %>% \n  correlation() %>%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %>%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %>%   # sortiere absteigend nach der H√∂he des Korrelationskoeffizienten r\n  filter(abs(r) > .3)  # nur |r| > 3.\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Parameter1\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Parameter2\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"r\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_low\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_high\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"t\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"df_error\"],\"name\":[8],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"p\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Method\"],\"name\":[10],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n_Obs\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"OverallQual\",\"2\":\"SalePrice\",\"3\":\"0.7909816\",\"4\":\"0.95\",\"5\":\"0.7709644\",\"6\":\"0.8094376\",\"7\":\"49.36366\",\"8\":\"1458\",\"9\":\"1.446917e-310\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"GrLivArea\",\"2\":\"SalePrice\",\"3\":\"0.7086245\",\"4\":\"0.95\",\"5\":\"0.6821200\",\"6\":\"0.7332695\",\"7\":\"38.34821\",\"8\":\"1458\",\"9\":\"2.986420e-220\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"GarageCars\",\"2\":\"SalePrice\",\"3\":\"0.6404092\",\"4\":\"0.95\",\"5\":\"0.6091192\",\"6\":\"0.6697086\",\"7\":\"31.83874\",\"8\":\"1458\",\"9\":\"1.641609e-166\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"GarageArea\",\"2\":\"SalePrice\",\"3\":\"0.6234314\",\"4\":\"0.95\",\"5\":\"0.5910324\",\"6\":\"0.6538222\",\"7\":\"30.44587\",\"8\":\"1458\",\"9\":\"3.443335e-155\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"TotalBsmtSF\",\"2\":\"SalePrice\",\"3\":\"0.6135806\",\"4\":\"0.95\",\"5\":\"0.5805529\",\"6\":\"0.6445923\",\"7\":\"29.67055\",\"8\":\"1458\",\"9\":\"6.183718e-149\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"1stFlrSF\",\"2\":\"SalePrice\",\"3\":\"0.6058522\",\"4\":\"0.95\",\"5\":\"0.5723391\",\"6\":\"0.6373448\",\"7\":\"29.07790\",\"8\":\"1458\",\"9\":\"3.506562e-144\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"FullBath\",\"2\":\"SalePrice\",\"3\":\"0.5606638\",\"4\":\"0.95\",\"5\":\"0.5244463\",\"6\":\"0.5948560\",\"7\":\"25.85402\",\"8\":\"1458\",\"9\":\"7.938138e-119\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"TotRmsAbvGrd\",\"2\":\"SalePrice\",\"3\":\"0.5337232\",\"4\":\"0.95\",\"5\":\"0.4960020\",\"6\":\"0.5694337\",\"7\":\"24.09902\",\"8\":\"1458\",\"9\":\"1.757626e-105\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"YearBuilt\",\"2\":\"SalePrice\",\"3\":\"0.5228973\",\"4\":\"0.95\",\"5\":\"0.4845947\",\"6\":\"0.5591987\",\"7\":\"23.42362\",\"8\":\"1458\",\"9\":\"1.892815e-100\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"YearRemodAdd\",\"2\":\"SalePrice\",\"3\":\"0.5071010\",\"4\":\"0.95\",\"5\":\"0.4679732\",\"6\":\"0.5442445\",\"7\":\"22.46586\",\"8\":\"1458\",\"9\":\"1.993917e-93\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"GarageYrBlt\",\"2\":\"SalePrice\",\"3\":\"0.4863617\",\"4\":\"0.95\",\"5\":\"0.4449986\",\"6\":\"0.5256540\",\"7\":\"20.65548\",\"8\":\"1377\",\"9\":\"5.414590e-80\",\"10\":\"Pearson correlation\",\"11\":\"1379\"},{\"1\":\"MasVnrArea\",\"2\":\"SalePrice\",\"3\":\"0.4774930\",\"4\":\"0.95\",\"5\":\"0.4367786\",\"6\":\"0.5162553\",\"7\":\"20.69390\",\"8\":\"1450\",\"9\":\"9.101094e-81\",\"10\":\"Pearson correlation\",\"11\":\"1452\"},{\"1\":\"Fireplaces\",\"2\":\"SalePrice\",\"3\":\"0.4669288\",\"4\":\"0.95\",\"5\":\"0.4258270\",\"6\":\"0.5061076\",\"7\":\"20.16194\",\"8\":\"1458\",\"9\":\"3.783156e-77\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"BsmtFinSF1\",\"2\":\"SalePrice\",\"3\":\"0.3864198\",\"4\":\"0.95\",\"5\":\"0.3418953\",\"6\":\"0.4292133\",\"7\":\"15.99761\",\"8\":\"1458\",\"9\":\"2.012707e-50\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"LotFrontage\",\"2\":\"SalePrice\",\"3\":\"0.3517991\",\"4\":\"0.95\",\"5\":\"0.3012274\",\"6\":\"0.4003973\",\"7\":\"13.01348\",\"8\":\"1199\",\"9\":\"1.488597e-33\",\"10\":\"Pearson correlation\",\"11\":\"1201\"},{\"1\":\"WoodDeckSF\",\"2\":\"SalePrice\",\"3\":\"0.3244134\",\"4\":\"0.95\",\"5\":\"0.2777335\",\"6\":\"0.3695650\",\"7\":\"13.09560\",\"8\":\"1458\",\"9\":\"2.284025e-34\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"2ndFlrSF\",\"2\":\"SalePrice\",\"3\":\"0.3193338\",\"4\":\"0.95\",\"5\":\"0.2724957\",\"6\":\"0.3646620\",\"7\":\"12.86706\",\"8\":\"1458\",\"9\":\"3.291435e-33\",\"10\":\"Pearson correlation\",\"11\":\"1460\"},{\"1\":\"OpenPorchSF\",\"2\":\"SalePrice\",\"3\":\"0.3158562\",\"4\":\"0.95\",\"5\":\"0.2689114\",\"6\":\"0.3613039\",\"7\":\"12.71131\",\"8\":\"1458\",\"9\":\"1.987730e-32\",\"10\":\"Pearson correlation\",\"11\":\"1460\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAha! Ein Menge Information.^[Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren.]\n\nDiese Variablen sind einigerma√üen stark mit unserer Zielvariablen `SalePrice` korreliert.\nNutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n\n#### Model 1\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-43_c2bc0592e661dfcbaf7b96f6bace3edd'}\n\n```{.r .cell-code}\nm1 <- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\n```\n:::\n\n\nWie gut sind die Vorhersagen des Modells f√ºr die Daten von `d_train`?\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-44_eb748259b15ed9ac7e237de1025ce098'}\n\n```{.r .cell-code}\nrmse(m1)\n## [1] 40566.42\n```\n:::\n\n\nIm Schnitt liegen unsere Vorhersagen ca. 40 Tausend Dollar daneben. Ist das gut?\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-45_8fea8b77d7664566c28613918e8147c4'}\n\n```{.r .cell-code}\nr2(m1)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n```\n:::\n\nOb das R-Quadrat \"gut\" oder \"hoch\" ist, beantwortet man am besten *relativ*, \nalso im Vergleich zu anderen Modellen.\n\n\n#### Nullmodell\n\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Pr√§diktoren.\nMan nennt es das \"Nullmodell\".\nIn diesem Modell sagen wir f√ºr jedes Haus einfach den mittleren Preis aller H√§user vorher.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-46_3dc2a8f724f702f949c3c7c5894aa6c8'}\n\n```{.r .cell-code}\nm0 <- lm(SalePrice ~ 1, data = d_train)\n```\n:::\n\n\nWie gut ist die Vorhersage des Nullnomdells?\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-47_d4b7a23105742672f3735f43cbccc001'}\n\n```{.r .cell-code}\nrmse(m0)\n## [1] 79415.29\n```\n:::\n\n\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-48_f3e7e140511830b37d419cd39240ef71'}\n\n```{.r .cell-code}\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n```\n:::\n\n\n### Vorhersagen im Test-Datensatz\n\nWir haben jetzt unseren Champion, `m1`.\nAlle Hoffnung ruht auf diesem Modell.\nOb die Vorhersagen im Test-Sample pr√§zise sein werden?\nOder himmelweit daneben?\nBitte, entt√§usche uns nicht!\n\n\nHier sind die Vorhersagen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-49_5d3282f9fdd7760ee95b3da9c71715a1'}\n\n```{.r .cell-code}\nm1_pred <- predict(m1, newdata = d_test)\n\nhead(m1_pred)\n##        1        2        3        4        5        6 \n## 103394.7 152441.4 161837.8 187675.8 225467.0 190260.2\n```\n:::\n\n\nDie Vohersagen f√ºgen wir jetzt dem Test-Sample hinzu:\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-50_baedf33c9e8aa7a21ae5178615524158'}\n\n```{.r .cell-code}\nd_test <- \n  d_test %>% \n  mutate(SalePrice = m1_pred)\n```\n:::\n\n\n### Einreichen!\n\n\nSo, wir haben unsere Vorhersagen!\nJetzt reichen wir diese Vorhesagen ein.\n\nF√ºr die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten `id` und `SalePrice`:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-51_89cdd78c0e2b16cae0a4d66ddf3cc069'}\n\n```{.r .cell-code}\nm1_subm <-\n  d_test %>% \n  select(Id, SalePrice)\n```\n:::\n\n\nKaggle m√∂chte keine fehlenden Werten in den Vorhersagen, also pr√ºfen wir das mal:\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-52_82846994ba6e09178b39868f11380f1b'}\n\n```{.r .cell-code}\nm1_subm %>% \n  drop_na() %>% \n  nrow()\n## [1] 1458\n```\n:::\n\nOh, das ist *eine* Zeile weniger! Wir haben also einen fehlenden Wert!\n\nFiltern wir die Spalte `SalePrice` mal nach \"ist NA\":\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-53_9516592a1f6c7e9ad79a115c91ff9dec'}\n\n```{.r .cell-code}\nm1_subm %>% \n  filter(is.na(SalePrice))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2577\",\"2\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nAh, da ist er, der fehlende Wert, in Zeile 2577!\nHinfort!\n\nWir ersetzen die fehlenden Werte in `SalePrice` mit dem Mittelwert von `SalePrice`:\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-54_6be1da30088d552043c02fee6ee80284'}\n\n```{.r .cell-code}\nm1_subm_nona <-\n  m1_subm %>% \n  mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE)))\n```\n:::\n\n\nUnd? Gib es jetzt noch fehlende Werte?\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-55_51fd311b541a204f0c72245c5422f3a6'}\n\n```{.r .cell-code}\nm1_subm_nona %>% \n  filter(is.na(SalePrice))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nNein! \"No NA\" - Keine NAs, keine fehlenden Werte mehr.\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-56_4e1373caa016fa826be77f4fb7eef924'}\n\n```{.r .cell-code}\nwrite_csv(m1_subm_nona, \"daten/ames-kaggle/m1-subm.csv\")\n```\n:::\n\nUnd dann laden Sie diese Datei, `m1_subm.csv` bei Kaggle hoch und hoffen auf einen Hauptgewinn.\n\nDas Modell erzielte einen Score von *0.55521*.\n\n\n\n### Debrief\n\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt.\nSicherlich gibt es viele Ans√§tze, dieses Modell zu verbessern.\n\nHier sind einige Fragen, die Sie sich dazu stellen k√∂nnen:\n\n- Welche Pr√§diktoren sollte ich in das Modell aufnehmen?\n- Sollte ich Interaktionen ber√ºcksichtigen?\n- Wie gehe ich mit fehlenden Werten um?\n- Wenn ein Pr√§diktor schief ist, sollte ich ihn dann log-transformieren?\n- Vielleicht sollte man manche Pr√§diktoren quadrieren?\n\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- ## Fazit -->\n<!-- TODO  -->\n\n## Aufgaben\n\nSuchen Sie beim [Datenwerk](https://datenwerk.netlify.app/) nach diesen Aufgaben\n\n    - Aussagen-einfache-Regr\n    - interpret-koeff-lm\n    - korr-als-regr\n    - Linearitaet1a\n    - lm1\n    - mtcars-regr01\n    - nichtlineare-regr1\n    - penguins-regr02\n    - regression1\n    - regression1b\n    - Regression3\n    - Regression4\n    - Regression5\n    - Regression6\n    \n    \n\nSchauen Sie sich die Aufgaben beim [Datenwerk](https://datenwerk.netlify.app/) an, vor allem die Tags [regression](https://datenwerk.netlify.app/#category=regression) und [lm](https://datenwerk.netlify.app/#category=lm).\n\n*Nicht alle Aufgaben* aus dieser Sammlung passen zum Stoff; vielleicht k√∂nnen Sie einige Aufgaben nicht l√∂sen.\nIgnorieren Sie einfach diese Aufgaben.\n\nBeachten Sie die [Hinweise zu den Aufgaben](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n\n## Literatur\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}