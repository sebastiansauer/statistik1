
<!-- CHILD Document -->



Gegenstand dieser Prüfungsform ist eine *Projektarbeit* in Form eines *Prognosewettbewerbs.*



### tl;dr: Zusammenfassung

Vorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. 
Wenn Sie den DAX-Stand von morgen genau vorhersagen können, 
rufen Sie mich bitte sofort an. 
Genau das ist Ihre Aufgabe in dieser Prüfungsleistung: 
Sie sollen Werte vorhersagen. 

Etwas konkreter: Stellen Sie sich ein paar Studentis vor. 
Von allen wissen Sie, wie lange die Person für die Statistikklausur gelernt hat. 
Außerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. 
Und Sie wissen die Note jeder Person in der Statistikklausur.
Auf dieser Basis fragt sie ein Student (Alois),
der im kommenden Semester die Prüfung in Statistik schreiben ~~muss~~ will:
"Sag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?".
Mit Hilfe Ihrer Analyse können Sie diese Frage (und andere) beantworten. 
Natürlich könnten Sie es sich leicht machen und antworten: 
"Mei, der Notendurchschnitt war beim letzten Mal 2.7.
Also ist 2.7 kein ganz doofer Tipp für deine Note." 
Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, 
wenn man es geschickt anstellt. 
Da hilft Ihnen die Statistik (doch, wirklich). 

Kurz gesagt gehen Sie so vor: 
Importieren Sie die Daten in R, starten Sie die nötigen R-Pakete und 
schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. 
Dann nehmen Sie die vielversprechendsten Prädiktoren in ein Regressionsmodell und schauen sich an,
wie gut die Vorhersage ist. 
Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. 
Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. 
Je genauer Ihre Vorhersage, desto besser ist Ihr Prüfungsergebnis.








### Vorhersage 

Neben der erklärenden, rückwärtsgerichteten Modellierung spielt insbesondere in der Praxis die *vorhersageorientierte* Modellierung eine wichtige Rolle: 
Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen $y$ *vorherzusagen*, z.B. für neue Kunden auf Basis von soziodemographischen Daten den *Kundenwert* -- möglichst genau -- zu prognostizieren.
Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden,
d.h. inklusive des für diese Kunden bekannten Kundenwertes.

Ihnen werden *zwei Teildatenmengen* zur Verfügung gestellt: 
Zum einen gibt es die Trainingsdaten (auch *Lerndaten* genannt) und zum anderen gibt es Anwendungsdaten (auch *Testdaten* genannt), auf die man das Modell anwendet. 

1.  Bei den Trainingsdaten (Train-Sample) liegen sowohl die erklärenden Variablen ${\bf{x}} = (x_1, x_2, \ldots, x_n)$ als auch die Zielvariable $y$ vor. 
   Auf diesen Trainingsdaten wird das Modell $y=f({x})+\epsilon = f(x_1, x_2, \ldots, x_n)+\epsilon$ gebildet und durch $\hat{f}(\cdot)$ geschätzt. Es ist also die Variable $y$ vorherzusagen.

2.  Dieses geschätzte Modell ($\hat{f}(\cdot)$) wird auf die Anwendungsdaten $x_0$, für die (Ihnen) die Werte der Zielvariable $y$ unbekannt sind,
angewendet, d.h., es wird $\hat{y}_0 :=\hat{f}({x}_0)$ berechnet. 
  Der unbekannte Wert $y_0$ der Zielvariable $y$ wird durch $\hat{y}_0$ prognostiziert.

Liegt zu einem noch späteren Zeitpunkt der eingetroffene Wert $y_0$ der Zielvariable $y$ vor, 
so  kann die eigene Vorhersage $\hat{y}_0$ evaluiert werden, 
d.h. z.B. kann der Fehler $e=y_0-\hat{y}_0$ zwischen prognostiziertem Wert $\hat{y}_0$ und wahrem Wert $y_0$ analysiert werden.

In der praktischen Anwendung können zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben): 

1. die *Trainingsphase*, d.h., die Phase für die sowohl erklärende ($x$) als auch die erklärte Variable ($y$) bekannt sind. 
Hier wird das Modell geschätzt (gelernt): $\hat{f}(x)$. Dafür wird der Trainingsdatensatz genutzt.

2. In der folgenden *Anwendungsphase* sind nur die erklärenden Variablen ($x_0$) bekannt, nicht $y_0$. 
Auf Basis der Ergebnisses aus dem 1. Schritt wird $\hat{y}_0 :=\hat{f}({\bf{x}}_0)$ prognostiziert.

3. Evt. gibt es später noch die *Evaluierungsphase*, für die dann auch die Zielvariable ($y_0$) bekannt ist, so dass die Vorhersagegüte des Modells überprüft werden kann.


Im Computer kann man dieses Anwendungsszenario *simulieren*: 
man teilt die Datenmenge *zufällig* in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; $(x,y)$) und eine Teststichprobe (Anwendungsdaten,  $(x_0)$) auf: 
Die Modellierung erfolgt auf den Trainingsdaten.
Das Modell wird angewendet auf die Testdaten (Anwendungsdaten).
Da man hier aber auch die Zielvariable ($y_0$) kennt, kann damit das Modell evaluiert werden.


### Hauptziel: Genaue Prognose

Ihre Aufgabe ist: Spielen Sie den Data-Scientist! 
Konstruieren Sie ein Modell auf Basis der Trainingsdaten $(x,y$) 
und sagen Sie für die Testdaten ($x_0$) die Zielvariable möglichst genau voraus ($\hat{y}_0$). 

Ihr(e) Dozent\*in kennt den Wert der Zielvariable ($y_0$). Sie nicht.



Von zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser,
das weniger Vorhersagefehler aufweist (im Test-Datensatz), also genauer vorhersagt. 
Kurz gesagt: Genauer ist besser.

<!-- Zur Bewertung der Vorhersagegüte wird der mittlere absolute Fehler als Koeffizient $\text{MAE}$ (${\bf{m}}$ean ${\bf{a}}$bsolute ${\bf{e}}$rror) auf die Anwendungsdaten herangezogen: -->

<!-- $$\text{MAE}_{\text{Test}}=\frac{1}{n_{\text{Test}}}\sum_{i=1}^{n_{\text{Test}}} |y_i-\hat{y}_i|$$ -->

<!-- Dabei sind $y_i$ die wahren Werte, $\hat{y}_i$ die prognostizierten Werte des geschätzten Modells $\hat{f}(\cdot)$ und $n_{\text{Test}}$ die Anzahl der Beobachtungen des Testdatensatzes (Anwendungsdatensatz).
Für eine gute Prognose sollte daher $\text{MAE}_{\text{Test}}$ möglichst klein sein. -->




### Prüfungsmaterial


Es werden Ihnen im Rahmen der Prüfung drei (Text-)Dateien bereitgestellt:

1. Trainings-Datensatz 
2. Test-Datensatz 
3. Data Dictionary

Beachten Sie, dass der Zugriff zum Prüfungsmaterial eingeschränkt sein kann (z.B. nur während der Prüfungszeit, nur nach Bestätigung der Kenntnis der Prüfungsbedingungen, nur für angemeldete Studentis).

Welche Variable vorherzusagen ist (die AV), steht im Data Dictionary.

Die Materialien (oder Hinweise zum Bezugsort) finden Sie im entsprechenden Moodlekurs.



### Einzureichende Dateien


1. Folgende *Dateiarten* sind einzureichen:

    1. Prognose: Ihre *Prognose-Datei* (CSV-Datei)
    2. Analyse: Ihr *Analyseskript* (R-, qmd-, Rmd-Notebook oder Rmd-Datei)
  
2. Weitere Dateien sind nicht einzureichen.

3. Komprimieren Sie die Dateien *nicht* (z.B. via *zip*). 

4. Der Name jeder eingereichte Datei muss wie folgt lauten: `Nachname_Vorname_Matrikelnummer_Dateiart.Endung`. Beispiel: `Sauer_Sebastian_0123456_Prognose.csv` bzw. `Sauer_Sebastian_0123456_Analyse.qmd`.





### Zum Aufbau Ihrer Prognosedatei im CSV-Format

1. Die CSV-Datei muss aus genau *zwei* Spalten mit exakt folgenden *Spaltennamen* bestehen:

  a) `id`: Den ID-Wert jedes vorhergesagten Wertes
  b) `pred`: Der vorhergesagte Wert.
  
2. Sofern nicht anderweitig definiert, entspricht die *ID* einer Beobachtung ihrer *Zeilennummer* (in der Reihenfolge, wie sie in der vom Prüfer ausgegebenen Datei vorliegt). Die erste Beobachtung (im Test-Sample) bekommt die ID `1`, die zweite Beobachtung die ID `2`, etc. Die ID ist als Zahl (reell oder ganzzahlig) zu formatieren.




3. Die CSV-Datei muss als *Spaltentrennzeichen* ein *Komma* verwenden und als *Dezimaltrennzeichen* einen *Punkt* (d.h. also die *Standardformatierung* einer CSV-Datei; *nicht* die deutsche Formatierung).

4. Die eingereichte CSV-Datei muss genau die *Anzahl an Zeilen* aufweisen, die der Zeilenlänge im *Test-Datensatz* entspricht.

5. Prüfen Sie, dass Ihre CSV-Datei sich *problemlos* *lesen* lässt. 
   Falls keine (funktionstüchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Prüfung nicht bestanden. 
   Tipp: Öffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vernünftig aussieht.
   Achtung: Öffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, 
   der CSV-Dateien verfälschen kann auch ohne dass man die Datei speichert.






1. Folgende *Dateiarten* sind einzureichen:

    1. Prognose: Ihre *Prognose-Datei* (CSV-Datei)
    2. Analyse: Ihr *Analyseskript* (R-, Rmd-, qmd- oder Rmd-Notebook-Datei)
  
2. Reichen Sie *keine weiteren Dateien* ein.

3. Komprimieren Sie die Dateien *nicht* (z.B. via *zip*). 

4. Der Name jeder eingereichten Datei muss wie folgt lauten: `Nachname_Vorname_Matrikelnummer_Dateiart.Endung`. Beispiel: `Sauer_Sebastian_0123456_Prognose.csv` bzw. `Sauer_Sebastian_0123456_Analyse.Rmd`.

5. *Umlaute* in ihren Dateinamen sind durch ASCII-Zeichen zu *ersetzen* (also `Süß` wird `Suess` etc.).



### Gliederung Ihrer Analyse


Ihr Analysedokument stellt alle Ihre Schritte vor, die Sie im Rahmen der Bearbeitung der Prüfungsaufgabe unternommen haben,
zumindest was die Analyse der Daten betrifft.

Das Dokument mischt drei Textarten: R-Syntax, R-Ausgaben sowie Prosa (d.h. Ihre Erklärung zu Ihrer Analyse).
Alle drei Aspekte sind gleichermaßen wichtig für diese Analyse.

Wenn Sie das Dokument als R-Markdown-Datei (qmd- oder Rmd-Datei) anlegen,
müssen Sie R-Code in einem "R-Chunk" auszeichnen. Prosa wird in Rmd-Datei als Standard gesehen,
sie brauchen ihn nicht extra auszuzeichnen (für R-Notebook-Dateien gilt das Gleiche).
In R-Skript-Dateien ist es umgekehrt: Sie müssen R-Code nicht extra auszeichnen,
da in R-Skripten R als "Standard-Text" gesehen wird. Hingegen müssen Sie Prosa als Kommentar einfügen.
Es bleibt Ihnen überlassen, für welche Variante (R-, Rmd- oder R-Notebook) Sie sich entscheiden.
Keine Option wird als besser oder schlechter gewertet (vermutlich ist Rmd für Sie am einfachsten).


Sie können Ihr Analysedokument z.B. so gliedern:

1. Forschungsfrage und Hintergrund (Beschreiben Sie kurz, worum es geht)
2. Vorbereitung (Pakete laden, Daten importieren, etc.)
3. Explorative Datenanalyse (Untersuchen Sie den Datensatz nach Auffälligkeiten, die Sie dann beim Modellieren nutzen)
4. Modelle (z.B. via `lm(av ~ uv)`)
5. Vorhersagen (Vorhersage der Test-Daten anhand des besten Vorhersagemodells und Einreichen)

Die Gliederung ist kein Muss; andere Gliederung sind auch möglich.
Entscheidend ist die fachliche Angemessenheit.


#### Abschnitt Forschungsfrage und Hintergrund

In diesem Abschnitt passiert noch keine Statistik bzw. keine Analyse.
Stattdessen stellen Sie in "normaler Sprache", 
also ohne intensiven Gebrauch vom (statistischem) Fachvokabular dar,
was Ziel und was Hintergrund der Analyse ist.
Sie können als Ziel bzw. Hintergrund den formalen Aspekt der Prüfung anführen,
wichtiger sind aber inhaltliche bzw. fachliche Überlegungen: Worum geht es in der Analyse?
Warum ist die Frage wichtig? 
Was wird untersucht? Anhand welcher Methodik wird die Frage untersucht?

Eine viertel bis halbe Seite sollte für diesen Abschnitt reichen.





#### Vorbereitung

In diesem Abschnitt Ihres Analysedokuments führen Sie die technische Vorbereitung durch.
Das betrifft vor allem das Importieren der Daten und das Starten aller R-Pakete, 
die in der Analyse verwendet werden.

Zum Importieren der Daten gehen Sie bitte so vor: Legen Sie für diese Analyse ein *Projekt in Rstudio* an. 
Speichern Sie in diesem Ordner (auf der Wurzelebene, nicht in Unterverzeichnissen) die zu analyiserenden Daten. 
Ändern Sie nicht den Dateinamen der Daten. 
Importieren Sie die Daten z.B. auf folgende Weise: `d_train <- read_csv("d_train.csv)` bzw. `d_test <- read_csv("d_test.csv")`.
Auf diese Weise ist die Reproduzierbarkeit Ihrer Analyse sichergestellt.


#### Explorative Datenanalyse

Die explorative Datenanalyse (EDA) meint sowohl die deskriptive Statistik als auch die Datenvisualisierung.
Typische Schritte sind: das Bearbeiten (oder Entfernen) von Extremwerten und fehlenden Werten,
die Untersuchung von Verteilungsformen oder das Suchen nach Mustern (Korrelationen, Gruppenunterschieden).
Ein nützliches Ergebnis ist z.B. zu erkennen, welche Variablen sich als Prädiktoren eignen (für den nächsten Abschnitt der Modellierung).
Ziel ist, dass Sie den folgenden Schritt vorbereiten,
also Schritte unternehmen, damit Sie die AV möglichst gut vorhersagen können.


#### Modellierung

In diesem Schritt berechnen Sie Prognosemodelle. Das sind oft lineare Modelle, also etwa `lm(av ~ uv)`.
Es empfiehlt sich, mehrere Modelle zu berechnen und zu schauen,
welches dieser Kandidaten am besten ist. 
Die Güte eines Prognosemodells bemisst sich letztlich *nur* an der Präzision der Vorhersage *neuer* Daten,
also des Test-Datensatzes.
Wie gut Ihre Vorhersagen also wirklich sind, erfahren Sie erst mit der Notenbekanntgabe.
Allerdings können Sie die Trainingsdaten nutzen, um die Güte Ihrer Modelle abzuschätzen.


#### Vorhersagen

Schließlich entscheiden Sie sich für einen Modellkandidaten.
Diesen Modellkandidaten nehmen Sie her, um die (Ihnen unbekannten) Werte der AV (Zielvariablen) vorherzusagen.
Diese Vorhersagen - zusammen mit der ID für jede Vorhersagen - speichern Sie als (reguläre) CSV-Datei ab 
und reichen Sie als Ihre Prüfungsleistung ein, zusammen mit Ihrer Analysedatei.





### Tipps


#### Tipps für eine gute Prognose

- Schauen Sie in die Literatur.

- Evtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. $\log()$ oder die Elimination von Ausreißern) helfen.

- Überlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierfür gibt es Algorithmen und R-Funktionen.

- Vermeiden Sie Über-Anpassung (Overfitting).

- Vermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgefüllt.

- Arbeiten Sie die bereitgestellten Fallstudien durch. Wenn Sie mehr tun möchten, finden Sie im Internet eine Fülle von weiteren Fallstudien.



#### Tipps zur Datenverarbeitung

- Ein "deutsches" Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets können dies allerdings.


#### Tipps zum Aufbau des Analyseskripts

- Zu Beginn des Skripts sollten alle verwendeten R-Pakete mittels `library()` gestartet werden.

<!-- - Zu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (*nicht* von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Prüfer, nicht lauffähig ist). -->







### Bewertung


#### Kriterien

- Es gibt drei Bewertungskriterien:

  - *Formalia*: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Übersichtlichkeit der Analyse.
  
  - *Methode*: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.
  
  - *Inhalt*: **Vorhersagegüte**.

- Das zentrale Bewertungskriterium ist *Inhalt*; die übrigen beiden Kriterien fließen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein.


- Die Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.

- Es werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.

- Es werden keine Hinweise vergeben, stattdessen gibt es einen Überblick an typischen Fehlern.

- Es wird i.d.R. keine Musterlösung veröffentlicht, um  nachfolgende Kohorten nicht zu bevorteilen bzw. die aktuelle Kohorte nicht zu benachteiligen.



#### Kennzahl der Modellgüte

Die Güte der Vorhersage wird anhand des RMSE bemessen.


<!-- Die Güte der Vorhersage wird anhand des *mittleren Absolutfehlers* (mae) bemessen: -->

<!-- $$\text{mae} = \frac{1}{n} \sum_{i=1}^n|(y_i - \hat{y}_i)|$$ -->


#### Notenstufen

Zur Vorhersagegüte: Die Vorhersagegüte eines einfachen Minimalmodells entspricht einer $4,0$, die eines Referenzmodells des Dozenten einer $2,0$.

Ihre Bewertung erfolgt entsprechend Ihrer Vorhersagegüte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als $2,0$! 


#### Bewertungsprozess

Der Gutachter legt im Nachgang der Prüfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellgüte offen. 
Außerdem werden die vorherzusagenden Daten veröffentlicht 
sowie die Grenzwerte für jede Notenstufe.
Auf dieser Basis ist es allen Teilnehmis möglich,
die Korrektheit Ihrer Note selbständig zu überprüfen.


#### Einsichtnahme

In der Regel gibt es keine "Einsichtnahme".
Der Grund ist einfach: Sie bekommen mit der Note den Wert Ihrer Modellgüte mitgeteilt.
Darüber hinaus wird (zumeist) keine Bewertung durchgeführt.
In diesem Fall gibt es also neben der Modellgüte keine weiteren Korrekturhinweise und damit nichts, was eingesehen werden könnte.

Beachten Sie, dass Sie den vom Prüfer angegebenen Wert Ihrer Modellgüte selber nachrechnen können - das ist besser als eine Einsichtnahme.

Wenn Sie der Meinung sind, dass Ihre Arbeit doch eigentlich besser sein müsste,
als es Ihre Note widerspiegelt, kann ein Blick in die Liste der "Lieblingsfehler" nützen. 
Vielleicht finden Sie auf jener Liste auch einen (oder mehrere Fehler), 
die Sie auch in Ihrer eigenen Analyse finden.




### Freie Wahl in der Methodik 

Sie haben *freie Wahl bei der Modellierung und Vorverarbeitung*. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie können aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen. (Die freie Wahl gilt nicht für die Formalia und Randbedingungen; auch nicht für die zu verwendende Software und Programmiersprachen.)

Eine Einführung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): *Moderne Datenanalyse mit R*^[[https://link.springer.com/book/10.1007/978-3-658-21587-3](https://link.springer.com/book/10.1007/978-3-658-21587-3)] aber auch bei Max Kuhn und Julia Silge (2021): *Tidy Modeling with R*.^[[https://www.tmwr.org/](https://www.tmwr.org/)]. Die Bücher beinhalten jeweils Beispiele und Anwendung mit R.

Auch ist es Ihnen überlassen, welche Variablen Sie zur Modellierung heranziehen -- und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausreißer bereinigen o.Ä.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchführen, auch auf den Testdaten (Anwendungsdaten) durchzuführen.

Hinweise zur Modellwahl usw. gibt es auch in erwähnter Literatur, aber auch in vielen Büchern zum Thema Data-Science. 

Alles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent sein.

Im Übrigen lautet die Aufgabe: 
Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. $\hat{y}=42$ ist zwar eine schöne Antwort,
trifft die Wirklichkeit aber leider nicht immer.
Eine gute Modellierung auf den *Trainingsdaten* (z.B. hohes $R^2$) bedeutet nicht zwangsläufig eine gute Vorhersage (*Test-Set*).





### Formalia



1. Es sind nur Einzelarbeiten zulässig. 


12. In der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in *bereitgestellten Datensatz* genutzt werden.

3. Alle Analyseschritte bzw. alle Veränderungen an den Daten müssen im (eingereichten) *Analyseskript* nachvollziehbar aufgeführt sein. Das Analyseskript ist als R-Skript, qmd-Datei, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie können die bereitgestellte Vorlage als Analyseskript nutzen (`Template-Dokumentation-Vorhersagemodellierung.Rmd`).

4. Das *Analyseskript* muss grundsätzlich *funktionstüchtig* für den Prüfer sein: Alle Befehle müssen ohne Fehlermeldung durchlaufen. Ausnahmen: a) Installation fehlender Pakete, b) Daten sollen aus der Wurzelebene des Projektordners importiert werden.. 

14. Es dürfen *keine weiteren Informationen (Daten)* als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzulässig.


4. Nichtbeachtung der für dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug führen.


5. Der Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten. 

6. Es muss keine Literatur zitiert werden.

7. Ein ausgedrucktes Exemplar muss nicht abgegeben werden.

8. Während der Prüfungsphase werden *keine* *inhaltlichen* Fragen ("wie macht man nochmal eine Log-Transformation?") und keine *technischen* Fragen ("wie installiert man nochmal ein R-Paket?") beantwortet. 



### Ich brauche Hilfe!

#### Wo finde ich Beispiele und Vorlagen?

Im Rahmen des Unterrichts wurden mehrere Fallstudien erarbeitet bzw. bereitgestellt,
diese dienen Ihnen als ideale Vorlage.

Eine Beispiel-Modellierung finden Sie in der Datei `Beispielanalyse-Prognose-Wettbewerb.Rmd`. 
Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen können, ist mit der Datei `Template-Vorhersagemodellierung.Rmd` [hier](https://github.com/sebastiansauer/Lehre/blob/main/Hinweise/Prognosewettbewerb/Template-Vorhersagemodellierung.Rmd) bereitgestellt. 


Im Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen können.




#### Probeprüfung für den Prognosewettbewerb


Ja, [hier](https://github.com/sebastiansauer/Lehre/tree/main/data/prognosewettbwerb-demo). In diesem Ordner liegen die Dokumente, die Sie für die echte Prüfung auch bekommen:

1. Train-Datensatz
2. Test-Datensatz
3. Hinweise zur vorherzusagenden Variablen





#### Materialsammlung

In [diesem Ordner](https://github.com/sebastiansauer/Lehre/tree/main/Hinweise/Prognosewettbewerb) finden Sie eine Materialsammlung zum Prognosewettbewerb.



#### Videos

[Diese Playlist](https://youtube.com/playlist?list=PLRR4REmBgpIH6uG8LZWPTSMReX1OFxfUx) beinhaltet Videos,
die die Rahmenbedingungen der Prüfungsleistung vorstellt.





### Plagiatskontrolle

Die eingereichten Arbeiten können automatisiert auf Plagiate überprüft werden. Gibt es substanzielle Überschneidungen zwischen zwei (oder mehr) Arbeiten, werden *alle* betreffenden Arbeiten mit *ungenügend* bewertet oder es folgt eine Abwertung der Note.







