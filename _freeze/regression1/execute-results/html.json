{
  "hash": "baf399526e615b8f7abb8552d95085d5",
  "result": {
    "markdown": "# Geradenmodelle 1 {#sec-gerade1}\n\n\n\n## Lernsteuerung\n\n\n\n\n### Standort im Lernpfad\n\nAbb. @fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n\n\n\n\n\n\n### Lernziele\n\n\n- Sie k√∂nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\n- Sie k√∂nnen die Bestandteile eines Geradenmodells aufz√§hlen und erl√§utern.\n- Sie k√∂nnen die G√ºte eines Geradenmodells anhand von Kennzahlen bestimmen.\n- Sie k√∂nnen Geradenmodelle sowie ihre Modellg√ºte in R berechnen.\n\n\n### Ben√∂tigte R-Pakete\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-1_febb832dc55bf40daca33cfc6bca7b74'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n### Ben√∂tigte Daten\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-2_70c844dc44ef94097816cc4cf0aecf77'}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n## Vorhersagen\n\n\nVorhersagen sind eine n√ºtzlich Sache, unter (mindestens) folgenden Voraussetzungen:\n\n1. Sie sind pr√§zise\n2. Wir kennen die Pr√§zision\n3. Jemand interessiert sich f√ºr die Vorhersage\n\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch *lineare Regression*.\n\n\n### Vorhersagen ohne Pr√§diktor\n\n:::{#exm-noten-prognose}\nNach intensiver Besch√§ftigung mit Statistik sind Sie allgemein als Checker bekannt.\nViele j√ºngere Studentis fragen Sie um Rat.\neines Tages kommt ei Studenti, Toni, und fragt: \"Welche Statistiknote kann ich in der Klausur erwarten?\"\nSie entgegnen: \"Wie viel hast du denn gelernt?\".\nDie Antwort: \"Sag ich nicht.\"\n\nNach kurzem √úberlegen geben sie den Notenschnitt der letzten Klausur als Prognose f√ºr dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).\n\nZuerst importieren Sie die Daten der letzten Klausur^[Diese Syntax wird bei Ihnen nur funktionieren, wenn auf *Ihrem Computer* dieser Ordner mit dieser Datei existiert. Andernfalls m√ºssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.]:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-3_7395e61aab19633dd3ef0a99be646697'}\n\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-4_5dfa9ff647fd3ab54f4b7294c02a6d89'}\n\n```{.r .cell-code}\nnoten2 <- read.csv(\"daten/noten2.csv\")\n```\n:::\n\n\nDann rechnen Sie den Mittelwert aus:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-5_b6a97dc451d6d600dd88762142a5e569'}\n\n```{.r .cell-code}\nnoten2 %>% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mw\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"71.07968\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIhre Antwort lautet also: \"Im Schnitt haben die Studis bei der letzten Klausur gut 50% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorherage machen, sorry!\"$\\square$\n:::\n\n:::{.callout-note}\nOhne Kenntnis eines Pr√§diktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert f√ºr jede Beobachtung, s. @fig-noten3.\nWir nutzen den Mittelwert als Punktmodell f√ºr den Klausurerfolg.$\\square$\n:::\n\n\n::: {.cell hash='regression1_cache/html/fig-noten3_0b2d6b0781a2a2683facb8bdb3988b98'}\n::: {.cell-output-display}\n![Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell](regression1_files/figure-html/fig-noten3-1.png){#fig-noten3 width=672}\n:::\n:::\n\n\n:::{def-nullmodell}\n### Nullmodell\nModelle ohne Pr√§diktor, Punktmodelle also, kann man so bezeichnen: `y ~ 1`. \nDa es null Pr√§diktoren hat, nennt man es auch manchmal \"Nullmodell\".\n:::\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-7_6e6257dcd4b27a1b0eba006055a2b02c'}\n\n```{.r .cell-code}\nlm0 <- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##       71.08\n```\n:::\n\n\n`lm` steht f√ºr \"lineares Modell\", die `0` sagt, dass es keine Pr√§diktoren gibt.\nIn dem Fall wird der Mittelwert als Gerade verwendet.\nDer zur√ºckgemeldete Koeffizient `(Intercept)` ist hier der Modell des Punktmodells.\nDa es ein Punktmodell ist, sagt es f√ºr alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\n\nDie Regressionsgleichung lautet demnach: `y_pred = 71.08`.\nIn Worten: \"Wir sagen von jede Beobachtung einen Wert von ca. 71 vorher\".\n\n\n### Vorhersagen mit Pr√§diktor\n\n\n\n\n:::{#exm-noten3}\n### Toni verr√§t die Lernzeit\n\nDis Studenti, Toni, entschlie√üt sich dann doch noch, die Lernzeit zu verraten:\n\"Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.\"\nJetzt m√ºssen Sie erstmal nachdenken: \"Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 gelernt hat?\"\n\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. @fig-noten4, links.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-8_cdea3e77f16126b1181651be298d736c'}\n\n```{.r .cell-code}\nnoten2 <- read.csv(noten2, \"daten/noten2.csv\")\n\nlibrary(DataExplorer)\nnoten2 %>% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-9_5b833fc670733992d823407a8ac4263e'}\n\n:::\n\n\n\nAuf dieser Basis antworten Sie Toni: \"Bei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. K√∂nnte mit dem Bestehen eng werden.\"\nToni ist nicht begeistert von Ihrer Prognose und zieht von dannen.$\\square$\n:::\n\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeiten und Klausurpunkte ist deutlich zu erkennen.\nMit einem Lineal k√∂nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. @fig-noten4.\n\n\n\n::: {#fig-noten4 .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-noten4_af58971602d77d2ebebd770e66f124b4'}\n::: {.cell-output-display}\n![Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)](regression1_files/figure-html/fig-noten4-1.png){#fig-noten4-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Eine 'Trendgerade' (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet.](regression1_files/figure-html/fig-noten4-2.png){#fig-noten4-2 width=672}\n:::\n\nNoten und Lernzeit: Rohdaten und Modell\n:::\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.\n\n\n\n## Geradenmodelle\n\n\n### Achsenabschnitt und Steigung definieren eine Gerade\n\nWir verwenden eine Gerade als Modell f√ºr die Daten, s. @fig-noten4, rechts.\nAnders gesagt: Wir modellieren die X-Y-Daten (bzw. ihren Zusammenhang) mit einem Geradenmodell.\n\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells:\nEin Punktmodell sagt f√ºr alle Beobachtungen den gleichen Wert vorher.\n@fig-noten3 und @fig-noten4 stellen ein Punktmodell einem Geradenmodell gegen√ºber.\n\nIn einem Geradenmodell wird nicht mehr (notwendig) f√ºr jede Beobachtung die gleiche Vorhersage $\\hat{y}$ gemacht (wie das bei einem Punktmodell der Fall ist).\n\n\n:::{#def-gerade}\nEine Gerade ist definiert durch zwei *Koeffizienten*: Achsenabschnitt (engl. intercept), und Steigung (engl. slope).\nH√§ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit $t$ und die Steigung mit $m$ bezeichnet: $f(x)=y=\\color{blue}[m]x + \\color{red}[t]$.\nIn der Statistik wird folgende Nomenklatur bevorzugt: $f(x)=\\hat{y} = \\color{red}{b_0} + \\color{blue}{b_1}x$ oder $y = \\color{red}{\\beta_0} + \\color{blue}{\\beta_1}x$ .^[Die Nomenklatur mit $b_0, b_1$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage √ºber eine Population, nicht nur √ºber eine Stichprobe, machen m√∂chte.]\n\n\n@fig-regrtex skizziert die Elemente einer Regression.\n:::\n\n\n![Achsenabschnitt und Steigung einer Regressionsgeraden](img/regr.png){#fig-regrtex width=\"70%\"}\n\n\n[Basierend auf diesem Diagramm von Henri Menke](https://texample.net/tikz/examples/linear-regression/)\n\n\n\n\n:::{#exm-noten5}\n### Toni will es genau wissen\nDa Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert.\n\"Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zur√ºck!\"\n\nDas sind gute Fragen. Den Y-Wert (Klausurpunkte) bei $X=0$ gibt der Achsenabschnitt zur√ºck. Schnell skizzieren Sie dazu ein Diagramm, s. @fig-beta0.\nPuh, die Antwort wird Toni nicht gefallen ...\n:::\n\n\n::: {.cell hash='regression1_cache/html/fig-beta0_2e532a81a10013a6f6ba10fce9d4683d'}\n::: {.cell-output-display}\n![Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)](regression1_files/figure-html/fig-beta0-1.png){#fig-beta0 width=672}\n:::\n:::\n\n\n\n\nAnstelle auf @fig-beta0 zu schauen, k√∂nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n\n>    üßë‚Äçüéì Hey R, predicte mir mal auf Basis vom Modell \"lm1\" den Lernerfolg f√ºr Toni, wenn der x=0 Stunden lernt.\n\n>    ü§ñ Okay, ich predicte mit Modell \"lm1\" und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-12_4b1532cd46dfdcd12d6086c3e5b24e83'}\n\n```{.r .cell-code}\ntonis_lernzeit <- tibble(x = 0)\ntonis_lernzeit\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-13_a445df4204cbc1758d06a98963c3ae12'}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit)\n##        1 \n## 8.603032\n```\n:::\n\n\n\n### Spezifikation eines Geradenmodells\n\n\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. @eq-mod1:\n\n$$\\hat{y} \\sim x$$ {#eq-mod1}\n\n\nLies: \"Laut meinem Modell ist $\\hat{y}$ irgendeine Funktion von $y$\".\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\n\n\n@eq-mod1 k√∂nnen Sie so ins Errische √ºbersetzen:\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-14_44d1a0bb62b3124432d183f13e99b787'}\n\n```{.r .cell-code}\nlm(y ~ x, data = meine_daten)\n```\n:::\n\n\n`lm` steht f√ºr \"lineares Modell\", also eine Gerade als Modell.\nDie Gerade nennt man auch *Regressionsgerade*^[an anderer Stelle in diesem Buch unscharf als \"Trendgerade\" bezeichnet.].\n\n:::{#exm-noten5}\n### Zahlen f√ºr Toni\nToni ist nicht zufrieden mit Ihren Vorhersagen: \"Jetzt h√∂r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir pr√§zise Zahlen!\".\n:::\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-15_846fdd97182898b626bc4851c280e2bf'}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      8.6030       0.8794\n```\n:::\n\n\nR gibt Ihnen die beiden Koeffizienten f√ºr die Gerade aus. \nDen Namen des Objekts k√∂nnen Sie frei aussuchen, z.B. `mein_erstes_lm`.\n\nDie Regressionsgleichung lautet demnach:\n`y_pred = 8.6 + 0.88*x`\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige Y-Werte ausrechnen gegeben bestimmte X-Werte.\n\nHat jemand zum Beispiel 10 Stunden gelernt, w√ºrden wir folgendes Klausurergebnis vorhersagen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-16_28735223d3a61f6bbc55471831cecea5'}\n\n```{.r .cell-code}\nlernzeit <- 10\ny_pred <- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17.4\n```\n:::\n\n\n\n:::{#exm-noten6}\n### Vorhersage f√ºr Klausurerfolg, n√§chster Versuch\nSie versuchen, noch etwas Gutes f√ºr Toni zu tun.\nR hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt.\nSie d√ºrfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n:::\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-17_65499c4fd3328190b6f57b960f4af964'}\n\n```{.r .cell-code}\ntonis_lernzeit2 <- tibble(x = 73)\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-18_3b761abed6f9dbd0ceea1734d6f39f99'}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit2)\n##       1 \n## 72.7999\n```\n:::\n\n:::\n\n\nDie Syntax von `predict` lautet:\n\n```\npredict(name_des_objekts, newdata = tabelle_mit_pr√§diktorwerten)\n```\n\n:::{.callout-note}\nMit `predict` bekommt man eine Vorhersage; im Standard eine \"Punkt-Vorhersage\", eine einzelne Zahl.$\\square$\n:::\n\n\n### Vorhersagefehler\n\nDie Differenz zwischen vorhergesagten Wert f√ºr eine (neue) Beobachtung, $\\hat{y_0}$ und ihrem tats√§chlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: $e_i = y_i - \\hat{y}_i$.\n\n\n\n\n::: {#fig-resid .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-resid_181731942064e79c33b2c58655c90806'}\n::: {.cell-output-display}\n![Residuen beim Geradenmodell (lm1)](regression1_files/figure-html/fig-resid-1.png){#fig-resid-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Residuen beim Punktmodell (lm0)](regression1_files/figure-html/fig-resid-2.png){#fig-resid-2 width=672}\n:::\n\nVorhersagefehler als Abweichungsbalken\n:::\n\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\n\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben^[aus dem Paket `easystats`]:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-20_93da93f151a39b54092ad3e4f4bada44'}\n\n```{.r .cell-code}\nmae(lm0)\n## [1] 11.18385\nmae(lm1)\n## [1] 7.954085\n```\n:::\n\n\n\nVergleichen wir MAE im  Nullmodell mit MAE in `lm1`: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-21_b0daa082945c7d43a6cf185ef110ccd7'}\n\n```{.r .cell-code}\nverhaeltnis_fehler_gerade_zu_punkt_mae <- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mae\n## [1] 0.7112118\n```\n:::\n\n\n\n\nAh! Das Geradenmodell ist viel besser:\nVon `lm0` zu `lm1` haben die mittlere (Absolut-)L√§nge des Fehlerbalkens auf 71 Prozent verbessert.\nNicht schlecht!\n\n\n:::{#def-fehlerstreung}\n### Fehlerstreuung\nAls Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte ($y_i$) vom vorhergesagten Wert ($\\hat{y}_i$).$\\square$\n:::\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngr√∂√üen wie MAE oder MSE.\n\n\n:::{.callout-note}\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreung), solange X mit Y korreliert ist.$\\square$\n:::\n\n\nNat√ºrlich k√∂nnen wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen^[Wer mag, kann den MSE auch von Hand berechnen: `mean((noten2$y-mean(noten2$y))^2)`].\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-22_c9e8e72240af5c40da63c89b7dc1e592'}\n\n```{.r .cell-code}\nmse(lm0)\n## [1] 192.7863\nmse(lm1)\n## [1] 106.4519\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-23_b794f760b583c85ac58b1f81c5811f8c'}\n\n```{.r .cell-code}\nverhaeltnis_fehler_gerade_zu_punkt_mse <- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.5521755\n```\n:::\n\n\n\n### Berechnung der Modellkoeffizienten\n\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\n\nDie Regressionskoeffizienten^[hier synonym: Modellparameter] b0 und b1 w√§hlt man so, dass die Residuen minimal sind.\nEs gibt verschiedene Algorithmen, um dies zu berechnen^[aber nicht in diesem Buch zu finden].\nEine sch√∂ne Darstellung dazu findet sich bei @kaplan_statistical_2009.\n\n\"Von Hand\" k√∂nnen Sie die Optimierung von b0 und b1 in [dieser App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/KleinsteQuadrate/) ausprobieren.\n\n\n\n\n## R-Quadrat\n\n### R-Quadrat als Verringerung der Fehlerstreuung\n\nAnders gesagt, wir haben uns um $1 - 0.55$ verbessert:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-24_f79949b12699e2c93e8f2a3dbe963b2e'}\n\n```{.r .cell-code}\n1 - verhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.4478245\n```\n:::\n\n\n\n\n\n:::{#def-r2}\n### R-Quadrat\nDie Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen  von `lm0` zum gerade untersuchten Modell nennt man  *R-Quadrat* ($R^2$).\nR-Quadrat ($R^2$) eines Modells $m$ ist definiert als die Verringerung der Streuung, wenn man das Modell $m$ mit dem Nullmodell $m_0$ vergleicht: $R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}$. R-Quadrat ist ein Ma√ü der *Modellg√ºte*: Je gr√∂√üer $R^2$, desto besser die Vorhersage. \nDa es ein Anteilsma√ü^[Prozentzahl] ist, liegt der Wertebereich zwischen 0 uns 1.\nIm Nullmodell liegt R-Quadrat per Definition bei 0.\nIm Fall von Modellen des Typs $y\\sim x$ gilt: $R^2 = r_{xy}^2$.\n$\\square$\n:::\n\n\n\n\nWir k√∂nnen R-Quadrat ($R^2$) uns von R z.B. so ausgeben lassen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-25_069257de7db5e4464ef2326ffe20e027'}\n\n```{.r .cell-code}\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n```\n:::\n\n\nBei einer perfekten Korrelation ist $r=1$, daher ist dann auch $R^2 = 1$^[Bei Modellen mit einem Pr√§diktor; gibt es mehrere Pr√§diktoren gilt die Beziehung nur wenn die Pr√§diktoren alle paarweise unabh√§ngig sind.], \ns. @fig-r2-extreme.\n\n\n\n::: {#fig-r2-extreme .cell layout-ncol=\"2\" hash='regression1_cache/html/fig-r2-extreme_504305156e68603978d7c9a70f866dd8'}\n::: {.cell-output-display}\n![Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert](regression1_files/figure-html/fig-r2-extreme-1.png){#fig-r2-extreme-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert](regression1_files/figure-html/fig-r2-extreme-2.png){#fig-r2-extreme-2 width=672}\n:::\n\nExtremf√§lle von R-Quadrat: 0 und 1\n:::\n\n\nBei einer perfekten Korrelation $R^2=1$ liegen die Punkte auf der Geraden.\nIm gegenteiligen Extremfall von $R^2=0$ ist die Vorhersage genauso gut, wie wenn man f√ºr jedes $y$ den Mittelwert, $\\bar{y}$, vorhersagen w√ºrde. \n\n\n:::{.callout-note}\nJe gr√∂√üer R-Quadrat, desto besser erkl√§rt das Modell die Daten (desto besser der \"Fit\", sagt man).\n:::\n\n[Diese App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/Variationszerlegung/) erlaubt es Ihnen mit der Gr√∂√üe der Residuen eines linearen Modells zu spielen.\n\n\n\n\n<!-- ### Addition der Varianzen -->\n\n\n<!-- Nennen wir die Varianz des Verkaufspreis $s^2_y$, die Verbesserung der Fehlerstreuung durch das *M*odell $s^2_m$ und die restliche Fehlerstreuung, den MSE, $s^2_e$. -->\n<!-- Dann gilt: -->\n\n<!-- $$s^2_y = s^2_m + s^2_e \\\\ -->\n<!-- s^2_m = s^2_y - s^2_e$$ -->\n\n<!-- ```{r} -->\n<!-- s2_y = var(noten2$y) -->\n<!-- s2_e = mse(lm1) -->\n<!-- s2_m = s2_y - s2_e -->\n<!-- s2_m -->\n<!-- ``` -->\n\n<!-- Die Varianzanteile addieren sich. Mit anderen Kennzahlen der Streuung (SD, MAE) funktioniert das nicht. -->\n\n\n## Interpretation eines Regressionsmodells\n\n\n### Modellg√ºte\n\nDie Residuen (Vorhersagefehler) bestimmen die Modellg√ºte:\nSind die Residuen im Schnitt gro√ü, so ist die Modellg√ºte gering (schlecht), und umgekerht.\nVerschiedenen Koeffizienten stehen zur Verf√ºgung: R-Quadrat, r^[als Korrelation von tats√§chlichem $y$ und vorhergesaten $\\hat{y}], MSE, RMSE, MAE, ...\n\n\n### Koeffizienten\n\nDie Modellkoeffizienten, also Achsenabschnitt ($b_0$) und Steigung ($b_1$) sind nur eingeschr√§nkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abh√§ngigkeiten nicht kennt.\nNur aufgrund eines Zusammenhangs darf man keine kausalen Abh√§ngigkeiten annehmen.\nOhne eine guten Grund f√ºr eine Kausalbehauptung kann man kann nur *deskriptiv* argumentieren.\nOder sich mit der Modellg√ºte und den Vorhersagen begn√ºgen. Was auch was wert ist.\n\n#### Achsenabschnitt (b0)\n\n\"Im Modell `lm1` liegt der Achsenabschnitt bei $y=8.6$. Beobachtungen mit $x=0$ k√∂nnen also diesen Y-Wert erwarten.\"\nLeider ist es h√§ufig so, dass Pr√§diktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig n√ºtzt.\n\n:::{#exm-groesse}\n### Regression Gr√∂√üe und Gewicht\nNutzt man K√∂rpergr√∂√üe umd das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von K√∂rpergr√∂√üe wenig n√ºtzlich, da es keine Menschen gibt der Gr√∂√üe 0.$\\square$\n:::\n\n\n#### Geradensteigung (b1)\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-27_5c2678faa03bf336e36a9b4590f1acf0'}\n\n:::\n\n\n\n\"Im Modell `lm1` betr√§gt der Regressionskoeffizient `b1` $0.88$. Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich *laut Modell* um den Wert von b1.\"\n\n:::{.callout-caution}\nH√§ufig liest man, der \"Effekt des Pr√§diktors\" auf die AV betrage z.B. $0.88$. \"Effekt\" ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort \"Effekt\" mit Vorsicht genie√üen. Manche sprechen daher auch von einem \"statistischen Effekt\".$\\square$.\n:::\n\n\n## Fallbeispiel Mariokart\n\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt.\nSie m√∂chten eine genaue Vorhersage von Verkaufspreisen erzielen.\nAls Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs.\nGenaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz.\nAuf geht's!\n\nDaten laden:^[Und die √ºblichen Pakete starten, nicht vergessen.]\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-28_84b385cfaeb7ae84867fbe32509b4e86'}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-29_98b337b88682db16c53e66457ee9a18b'}\n\n```{.r .cell-code}\nlm2 <- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n```\n:::\n\n\n\nOh nein! Unterirdisch schlecht. Anstelle von blo√üen Rumprobieren √ºberlegen Sie und schauen dann in @fig-mario-corr nach, welche Variable am st√§rksten korreliert mit `total_pr`,\nes resultiert `lm3`: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-30_f4a9c660f342b035d556a8c62fe715ad'}\n\n```{.r .cell-code}\nlm3 <- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n```\n:::\n\n::: {#tbl-lm3 .cell tbl-cap='Modellparameter von lm3' hash='regression1_cache/html/tbl-lm3_6dd34e4a7add8f4e4f8ffe00ba596690'}\n::: {.cell-output-display}\n|Parameter   | Coefficient |   SE |         95% CI | t(141) |      p |\n|:-----------|:-----------:|:----:|:--------------:|:------:|:------:|\n|(Intercept) |       36.25 | 2.54 | (31.23, 41.26) |  14.28 | < .001 |\n|ship pr     |        4.34 | 0.57 |   (3.22, 5.46) |   7.67 | < .001 |\n:::\n:::\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in @tbl-lm3 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut `lm3` etwa 36 Euro finaler Verkaufspreis erwarten.\n*Pro Euro an Versandkosten* (`ship_pr`) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.^[Die Spalte `95 CI` gibt einen Sch√§tzbereich f√ºr den jeweiligen Modellkoeffizienten an,\ndenn es handelt sich bei den Koeffizienten um Sch√§tzwerte;\nder wahre Wert in der Population ist unbekannt. \nWir kennen schlie√ülich nur eine Stichprobe der Gr√∂√üe $n=143$.].\n\nDie Regressionsgleichung von `lm3` lautet demnach:\n\n`total_pr_pred = 36.25 + 4.34*ship_pr`.\n\nIn Worten: \n\n>    Der vorhergesagte Gesamptreis eines Spiels liegt bei 36.25‚Ç¨ \"Sockelbetrag\" plus 4.34 mal die Versandkosten.\n\n\nMan kann sich die erwarteten Werte (\"expectations\") des Verkaufspreises in Abh√§ngigkeit vom Wert der UV (`ship_pr`) auch sch√§tzen (\"to estimate\") lassen, und zwar so^[Die Funktion stammt aus easystats]: \n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-32_00a0b01bb66b488a771887302c1ca314'}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% head()  # nur die ersten paar vorhergesagten Werte\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"ship_pr\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Predicted\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SE\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_low\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"CI_high\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Residuals\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"4.00\",\"2\":\"53.59442\",\"3\":\"1.874613\",\"4\":\"49.88844\",\"5\":\"57.30041\",\"6\":\"-2.044424\",\"_rn_\":\"1\"},{\"1\":\"3.99\",\"2\":\"53.55105\",\"3\":\"1.873160\",\"4\":\"49.84794\",\"5\":\"57.25416\",\"6\":\"-16.511052\",\"_rn_\":\"2\"},{\"1\":\"3.50\",\"2\":\"51.42581\",\"3\":\"1.822149\",\"4\":\"47.82355\",\"5\":\"55.02808\",\"6\":\"-5.925814\",\"_rn_\":\"3\"},{\"1\":\"0.00\",\"2\":\"36.24554\",\"3\":\"2.537924\",\"4\":\"31.22824\",\"5\":\"41.26284\",\"6\":\"7.754457\",\"_rn_\":\"4\"},{\"1\":\"0.00\",\"2\":\"36.24554\",\"3\":\"2.537924\",\"4\":\"31.22824\",\"5\":\"41.26284\",\"6\":\"34.754457\",\"_rn_\":\"5\"},{\"1\":\"4.00\",\"2\":\"53.59442\",\"3\":\"1.874613\",\"4\":\"49.88844\",\"5\":\"57.30041\",\"6\":\"-8.594424\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\n\n>   ü§ñ Das sieht man in der Spalte `Predicted`, dort steht der vorhersagte Wert f√ºr `total_pr` f√ºr einen bestimmten Wert von `ship_pr`.\n\n\n>    üßë‚Äçüéì Kann ich auch `predict` benutzen? Ich w√ºrde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n>   ü§ñ Ja, klar!\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-33_903fc0f6d0dcb2fb243a63dcb934cabb'}\n\n```{.r .cell-code}\nneue_daten <- tibble(\n  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen\n)\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-34_2c60ec7581fd1c32b8ed70c9d713aa05'}\n\n```{.r .cell-code}\npredict(lm3, newdata = neue_daten)\n##        1        2 \n## 40.58276 53.59442\n```\n:::\n\n\n\n\n\nAber n√ºtzlich w√§re noch, das Modell (bzw. die Sch√§tzung der erwarteten Werte) als Diagramm zu bekommen.\nDas erreicht man z.B. so, s. @fig-lm3.\n\n\n::: {.cell hash='regression1_cache/html/fig-lm3_fdb7e07bca47ff211f7ec45d0fca15ec'}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% plot()\n```\n\n::: {.cell-output-display}\n![Verbildlichung der erwarteteten Werte laut lm3](regression1_files/figure-html/fig-lm3-1.png){#fig-lm3 width=672}\n:::\n:::\n\n\n`estimate_expectation` hei√üt sinngem√§√ü \"sch√§tze den zu erwartenden Wert\".\nKurz gesagt: Wir wollen eine Vorhersage von R.\n\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie \"gut\" das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-36_440fe32ffe2760a4b392579e83744545'}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13.0632\n```\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-37_d6069ce2354fd2f7ce94bcb3fcd1b16c'}\n\n:::\n\n\nDas Modell erkl√§rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-38_98d59512e761226302b9407003ffd481'}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13.0632\n```\n:::\n\n\n\n\nIm n√§chsten Meeting erz√§hlen Sie Ihrem Chef \"Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!\".\nH√∂rt sich gut an.\nAllerdings h√§tte ihr Chef es gerne genauer. Kann man da noch was machen?\n\n\n\n\n\n\n\n\n## Fallstudie Immobilienpreise\n\n\n:::{.callout-caution}\nDiese Fallstudie stellt die Pr√ºfungsleistung \"Prognosewettbewerb\" einf√ºhrend dar. \nEs empfiehlt sich f√ºr Sie, diese Fallstudie sorgsam zu bearbeiten.$\\square$\n:::\n\n\n### Hintergrund\n\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen.\nKurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei [Kaggle](https://www.kaggle.com/) ein.\n\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. \n\n\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition [Ames House Prices](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview).\n\n- [Beschreibung](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description)\n- [Ziel/Aufgabe](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation)\n- [Spielregeln](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules)\n\n\n### Ben√∂tigte R-Pakete\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-39_00d7048fc38c5f8d3e3eba26d7789d17'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n### Daten\n\nWenn Sie sich bei Kaggle einloggen m√∂chten, k√∂nnen Sie die Daten von Kaggle herunterladen und zwar [hier](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).\n\nIm Einzelnen m√ºssen Sie folgende Dateien herunterladen:\n\n- *Data_description.txt*: Code book, d.h. Beschreibung der Variablen im Datensatz\n- *train.csv*: Daten von H√§usern, die Sie nutzen, um Modelle zu erstellen\n- *test.csv*:  Daten von H√§usern, von denen Sie den Kaufpreis vorhersagen sollen\n- *sample_submission.csv*: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\n\nSie k√∂nnen auch so auf die Daten zugreifen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-40_1d00f4a1a902d1ce77b5d3ade627c29e'}\n\n```{.r .cell-code}\nd_train_path_online <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online <- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\n\nd_train <- read_csv(d_train_path_online)\nd_test <- read_csv(d_test_path_online)\n```\n:::\n\n\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\n\nDas Code Book k√∂nnen Sie [hier einsehen und herunterladen](https://github.com/sebastiansauer/Lehre/blob/main/data/ames-kaggle/data_description.txt).\n\n\n### Prognosedatei\n\n\nDie Prognosedatei soll prinzipiell so aussehen:\n\n::: {.cell hash='regression1_cache/html/read-data-ames_0e13840f053ee549da7b4b19eb7eeaf6'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1461\",\"2\":\"169277.1\"},{\"1\":\"1462\",\"2\":\"187758.4\"},{\"1\":\"1463\",\"2\":\"183583.7\"},{\"1\":\"1464\",\"2\":\"179317.5\"},{\"1\":\"1465\",\"2\":\"150730.1\"},{\"1\":\"1466\",\"2\":\"177151.0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte `id` und der Spalte `Saleprice`.\nDie Spalte `id` gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - f√ºr welches Haus Sie also gerade einen Kaufpreis vorhersagen.\ndie Spalte `SalePrice` ist Ihre Vorhersage f√ºr den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht.\nInsgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\n\n\n\nAlles klar? \n\nLos geht's!\n\n\n### Daten importieren\n\nWir starten die √ºblichen R-Pakete und importieren die Daten (`d`):\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-41_b416b0b3bf82855cfa658fc0bea31540'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n::: {.cell hash='regression1_cache/html/read-data-local_cca9e5ce8a0a98a4c779d13d87e480ee'}\n\n```{.r .cell-code}\nd_train_path <- \"daten/ames-kaggle/train.csv\"\nd_test_path <- \"daten/ames-kaggle/test.csv\"\nd_train <- read_csv(d_train_path)\nd_test <- read_csv(d_test_path)\n```\n:::\n\n\n\n\n:::{.callout-note}\nIn diesem Beispiel gehen wir davon aus, dass die Dateien `train.csv` und `test.csv` in einem Unterordner namens `daten/ames-kaggle` liegen.\nSie m√ºssen sie dort abspeichern.\nDieser Ornder muss ein Unterordner Ihres aktuellen R-Projekts sein.$\\square$\n:::\n\n:::{.callout-caution}\nWenn das Importieren von der Festplatte nicht klappt ... \nEs ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann.\nAber f√ºrs Erste k√∂nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.$\\square$\n:::\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-42_0067f79bb794e0155d950d94c9d3e709'}\n\n```{.r .cell-code}\nd_train <- read_csv(d_train_path_online)\nd_test <- read_csv(d_test_path_online)\n```\n:::\n\n### Ein erster Blick in die Daten\n\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, \n@tbl-ames1.\n\n::: {#tbl-ames1 .cell tbl-cap='Verteilung der metrischen Variablen im ames-Datensatz' hash='regression1_cache/html/tbl-ames1_f5e9c1e5b4a67eef94ec3276efa73b9f'}\n\n```{.r .cell-code}\ndescribe_distribution(d_train)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Mean\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SD\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"IQR\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Min\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Max\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Skewness\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Kurtosis\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[9],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n_Missing\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Id\",\"2\":\"7.305000e+02\",\"3\":\"4.216100e+02\",\"4\":\"730.50\",\"5\":\"1\",\"6\":\"1460\",\"7\":\"0.00000000\",\"8\":\"-1.20000000\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MSSubClass\",\"2\":\"5.689726e+01\",\"3\":\"4.230057e+01\",\"4\":\"50.00\",\"5\":\"20\",\"6\":\"190\",\"7\":\"1.40765675\",\"8\":\"1.58018796\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"LotFrontage\",\"2\":\"7.004996e+01\",\"3\":\"2.428475e+01\",\"4\":\"21.00\",\"5\":\"21\",\"6\":\"313\",\"7\":\"2.16356914\",\"8\":\"17.45286726\",\"9\":\"1201\",\"10\":\"259\"},{\"1\":\"LotArea\",\"2\":\"1.051683e+04\",\"3\":\"9.981265e+03\",\"4\":\"4060.00\",\"5\":\"1300\",\"6\":\"215245\",\"7\":\"12.20768785\",\"8\":\"203.24327102\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OverallQual\",\"2\":\"6.099315e+00\",\"3\":\"1.382997e+00\",\"4\":\"2.00\",\"5\":\"1\",\"6\":\"10\",\"7\":\"0.21694393\",\"8\":\"0.09629278\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OverallCond\",\"2\":\"5.575342e+00\",\"3\":\"1.112799e+00\",\"4\":\"1.00\",\"5\":\"1\",\"6\":\"9\",\"7\":\"0.69306747\",\"8\":\"1.10641346\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YearBuilt\",\"2\":\"1.971268e+03\",\"3\":\"3.020290e+01\",\"4\":\"46.00\",\"5\":\"1872\",\"6\":\"2010\",\"7\":\"-0.61346117\",\"8\":\"-0.43955194\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YearRemodAdd\",\"2\":\"1.984866e+03\",\"3\":\"2.064541e+01\",\"4\":\"37.00\",\"5\":\"1950\",\"6\":\"2010\",\"7\":\"-0.50356200\",\"8\":\"-1.27224519\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MasVnrArea\",\"2\":\"1.036853e+02\",\"3\":\"1.810662e+02\",\"4\":\"166.00\",\"5\":\"0\",\"6\":\"1600\",\"7\":\"2.66908421\",\"8\":\"10.08241732\",\"9\":\"1452\",\"10\":\"8\"},{\"1\":\"BsmtFinSF1\",\"2\":\"4.436397e+02\",\"3\":\"4.560981e+02\",\"4\":\"712.75\",\"5\":\"0\",\"6\":\"5644\",\"7\":\"1.68550307\",\"8\":\"11.11823629\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtFinSF2\",\"2\":\"4.654932e+01\",\"3\":\"1.613193e+02\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"1474\",\"7\":\"4.25526111\",\"8\":\"20.11333755\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtUnfSF\",\"2\":\"5.672404e+02\",\"3\":\"4.418670e+02\",\"4\":\"585.00\",\"5\":\"0\",\"6\":\"2336\",\"7\":\"0.92026845\",\"8\":\"0.47499399\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"TotalBsmtSF\",\"2\":\"1.057429e+03\",\"3\":\"4.387053e+02\",\"4\":\"503.50\",\"5\":\"0\",\"6\":\"6110\",\"7\":\"1.52425455\",\"8\":\"13.25048328\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"1stFlrSF\",\"2\":\"1.162627e+03\",\"3\":\"3.865877e+02\",\"4\":\"509.75\",\"5\":\"334\",\"6\":\"4692\",\"7\":\"1.37675662\",\"8\":\"5.74584148\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"2ndFlrSF\",\"2\":\"3.469925e+02\",\"3\":\"4.365284e+02\",\"4\":\"728.00\",\"5\":\"0\",\"6\":\"2065\",\"7\":\"0.81302982\",\"8\":\"-0.55346356\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"LowQualFinSF\",\"2\":\"5.844521e+00\",\"3\":\"4.862308e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"572\",\"7\":\"9.01134129\",\"8\":\"83.23481667\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GrLivArea\",\"2\":\"1.515464e+03\",\"3\":\"5.254804e+02\",\"4\":\"649.75\",\"5\":\"334\",\"6\":\"5642\",\"7\":\"1.36656036\",\"8\":\"4.89512058\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtFullBath\",\"2\":\"4.253425e-01\",\"3\":\"5.189106e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.59606661\",\"8\":\"-0.83909827\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BsmtHalfBath\",\"2\":\"5.753425e-02\",\"3\":\"2.387526e-01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"2\",\"7\":\"4.10340270\",\"8\":\"16.39664195\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"FullBath\",\"2\":\"1.565068e+00\",\"3\":\"5.509158e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.03656156\",\"8\":\"-0.85704282\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"HalfBath\",\"2\":\"3.828767e-01\",\"3\":\"5.028854e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"2\",\"7\":\"0.67589745\",\"8\":\"-1.07692728\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"BedroomAbvGr\",\"2\":\"2.866438e+00\",\"3\":\"8.157780e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"8\",\"7\":\"0.21179010\",\"8\":\"2.23087458\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"KitchenAbvGr\",\"2\":\"1.046575e+00\",\"3\":\"2.203382e-01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"4.48839678\",\"8\":\"21.53240384\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"TotRmsAbvGrd\",\"2\":\"6.517808e+00\",\"3\":\"1.625393e+00\",\"4\":\"2.00\",\"5\":\"2\",\"6\":\"14\",\"7\":\"0.67634084\",\"8\":\"0.88076157\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"Fireplaces\",\"2\":\"6.130137e-01\",\"3\":\"6.446664e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"3\",\"7\":\"0.64956518\",\"8\":\"-0.21723721\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GarageYrBlt\",\"2\":\"1.978506e+03\",\"3\":\"2.468972e+01\",\"4\":\"41.00\",\"5\":\"1900\",\"6\":\"2010\",\"7\":\"-0.64941462\",\"8\":\"-0.41834100\",\"9\":\"1379\",\"10\":\"81\"},{\"1\":\"GarageCars\",\"2\":\"1.767123e+00\",\"3\":\"7.473150e-01\",\"4\":\"1.00\",\"5\":\"0\",\"6\":\"4\",\"7\":\"-0.34254893\",\"8\":\"0.22099776\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"GarageArea\",\"2\":\"4.729801e+02\",\"3\":\"2.138048e+02\",\"4\":\"244.50\",\"5\":\"0\",\"6\":\"1418\",\"7\":\"0.17998091\",\"8\":\"0.91706720\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"WoodDeckSF\",\"2\":\"9.424452e+01\",\"3\":\"1.253388e+02\",\"4\":\"168.00\",\"5\":\"0\",\"6\":\"857\",\"7\":\"1.54137576\",\"8\":\"2.99295092\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"OpenPorchSF\",\"2\":\"4.666027e+01\",\"3\":\"6.625603e+01\",\"4\":\"68.00\",\"5\":\"0\",\"6\":\"547\",\"7\":\"2.36434174\",\"8\":\"8.49033581\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"EnclosedPorch\",\"2\":\"2.195411e+01\",\"3\":\"6.111915e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"552\",\"7\":\"3.08987190\",\"8\":\"10.43076594\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"3SsnPorch\",\"2\":\"3.409589e+00\",\"3\":\"2.931733e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"508\",\"7\":\"10.30434203\",\"8\":\"123.66237945\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"ScreenPorch\",\"2\":\"1.506096e+01\",\"3\":\"5.575742e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"480\",\"7\":\"4.12221374\",\"8\":\"18.43906784\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"PoolArea\",\"2\":\"2.758904e+00\",\"3\":\"4.017731e+01\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"738\",\"7\":\"14.82837364\",\"8\":\"223.26849892\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MiscVal\",\"2\":\"4.348904e+01\",\"3\":\"4.961230e+02\",\"4\":\"0.00\",\"5\":\"0\",\"6\":\"15500\",\"7\":\"24.47679419\",\"8\":\"701.00334228\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"MoSold\",\"2\":\"6.321918e+00\",\"3\":\"2.703626e+00\",\"4\":\"3.00\",\"5\":\"1\",\"6\":\"12\",\"7\":\"0.21205299\",\"8\":\"-0.40410934\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"YrSold\",\"2\":\"2.007816e+03\",\"3\":\"1.328095e+00\",\"4\":\"2.00\",\"5\":\"2006\",\"6\":\"2010\",\"7\":\"0.09626851\",\"8\":\"-1.19060057\",\"9\":\"1460\",\"10\":\"0\"},{\"1\":\"SalePrice\",\"2\":\"1.809212e+05\",\"3\":\"7.944250e+04\",\"4\":\"84075.00\",\"5\":\"34900\",\"6\":\"755000\",\"7\":\"1.88287576\",\"8\":\"6.53628186\",\"9\":\"1460\",\"10\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Ein erstes Vorhersagemodell\n\n\n#### Welche Variablen eignen sich zur Vorhersage?\n\n\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, \ndie Korrelation aller Pr√§diktoren mit der abh√§ngigen Variablen^[die vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt] zu berechnen, s. @tbl-d_train_corr.\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-44_16b6b8519bad0aa7f292e742dcc1d838'}\n\n```{.r .cell-code}\nd_train %>% \n  select(-Id) %>% \n  correlation() %>%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %>%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %>%   # sortiere absteigend nach der H√∂he des Korrelationskoeffizienten r\n  filter(abs(r) > .3)  # nur |r| > 3.\n```\n:::\n\n\n::: {#tbl-d_train_corr .cell tbl-cap='Korrelation der Pr√§diktoren (UV) mit der AV' hash='regression1_cache/html/tbl-d_train_corr_8a1426835baaacdcd237be3f0fc8b68e'}\n::: {.cell-output-display}\nTable: Correlation Matrix (pearson-method)\n\n|Parameter1   | Parameter2 |    r |       95% CI |     t |   df |         p |\n|:------------|:----------:|:----:|:------------:|:-----:|:----:|:---------:|\n|OverallQual  |  SalePrice | 0.79 | (0.77, 0.81) | 49.36 | 1458 | < .001*** |\n|GrLivArea    |  SalePrice | 0.71 | (0.68, 0.73) | 38.35 | 1458 | < .001*** |\n|GarageCars   |  SalePrice | 0.64 | (0.61, 0.67) | 31.84 | 1458 | < .001*** |\n|GarageArea   |  SalePrice | 0.62 | (0.59, 0.65) | 30.45 | 1458 | < .001*** |\n|TotalBsmtSF  |  SalePrice | 0.61 | (0.58, 0.64) | 29.67 | 1458 | < .001*** |\n|1stFlrSF     |  SalePrice | 0.61 | (0.57, 0.64) | 29.08 | 1458 | < .001*** |\n|FullBath     |  SalePrice | 0.56 | (0.52, 0.59) | 25.85 | 1458 | < .001*** |\n|TotRmsAbvGrd |  SalePrice | 0.53 | (0.50, 0.57) | 24.10 | 1458 | < .001*** |\n|YearBuilt    |  SalePrice | 0.52 | (0.48, 0.56) | 23.42 | 1458 | < .001*** |\n|YearRemodAdd |  SalePrice | 0.51 | (0.47, 0.54) | 22.47 | 1458 | < .001*** |\n|GarageYrBlt  |  SalePrice | 0.49 | (0.44, 0.53) | 20.66 | 1377 | < .001*** |\n|MasVnrArea   |  SalePrice | 0.48 | (0.44, 0.52) | 20.69 | 1450 | < .001*** |\n|Fireplaces   |  SalePrice | 0.47 | (0.43, 0.51) | 20.16 | 1458 | < .001*** |\n|BsmtFinSF1   |  SalePrice | 0.39 | (0.34, 0.43) | 16.00 | 1458 | < .001*** |\n|LotFrontage  |  SalePrice | 0.35 | (0.30, 0.40) | 13.01 | 1199 | < .001*** |\n|WoodDeckSF   |  SalePrice | 0.32 | (0.28, 0.37) | 13.10 | 1458 | < .001*** |\n|2ndFlrSF     |  SalePrice | 0.32 | (0.27, 0.36) | 12.87 | 1458 | < .001*** |\n|OpenPorchSF  |  SalePrice | 0.32 | (0.27, 0.36) | 12.71 | 1458 | < .001*** |\np-value adjustment method: Holm (1979)\nObservations: 1201-1460\n:::\n:::\n\nAha! Ein Menge Information.^[Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: F√ºhren Sie die Syntax schrittweise aus. Zuerst `d_train` ausf√ºhren und das Ergebnis betrachten. Dann `d_train %>% select(-Id)` ausf√ºhren, wieder die Ausgabe betrachten, usw.]\n\nDiese Variablen sind einigerma√üen stark mit unserer Zielvariablen `SalePrice` korreliert.\nNutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n\n#### Model 1\n\nBerechnen wir ein erstes Modell f√ºr diese Forschungsfrage, s. @tbl-m1-params.\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-46_882eca5e7e370de4b48bc6a3c55efc2d'}\n\n```{.r .cell-code}\nm1 <- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m1)\n```\n:::\n\n\n::: {#tbl-m1-params .cell tbl-cap='Modellparameter von m1' hash='regression1_cache/html/tbl-m1-params_8164d9efc48082a25657d30428a7e7b2'}\n::: {.cell-output-display}\n|Parameter   | Coefficient |      SE |                 95% CI | t(1456) |      p |\n|:-----------|:-----------:|:-------:|:----------------------:|:-------:|:------:|\n|(Intercept) |   -98832.49 | 4842.90 | (-1.08e+05, -89332.69) |  -20.41 | < .001 |\n|OverallQual |    27104.83 | 1072.18 |   (25001.64, 29208.01) |   25.28 | < .001 |\n|GrLivArea   |       50.67 |    2.55 |         (45.67, 55.68) |   19.86 | < .001 |\n|GarageCars  |    21298.96 | 1807.06 |   (17754.23, 24843.69) |   11.79 | < .001 |\n:::\n:::\n\n\nWie gut sind die Vorhersagen des Modells f√ºr die Daten von `d_train`?\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-48_d884ce6a5e052a54ec3340dc0206a884'}\n\n```{.r .cell-code}\nrmse(m1)\n## [1] 40566.42\n```\n:::\n\n\nIm Schnitt liegen unsere Vorhersagen ca. 40 Tausend Dollar daneben. Ist das gut?\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-49_facf462bc7a0fa29b12f2e9c3f2a52cd'}\n\n```{.r .cell-code}\nr2(m1)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n```\n:::\n\nOb das R-Quadrat \"gut\" oder \"hoch\" ist, beantwortet man am besten *relativ*, \nalso im Vergleich zu anderen Modellen.\n\n\n#### Nullmodell\n\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Pr√§diktoren.\nMan nennt es das \"Nullmodell\".\nIn diesem Modell sagen wir f√ºr jedes Haus einfach den mittleren Preis aller H√§user vorher.\n\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-50_d2ebbde190bd556adeb1f865a1ff9da2'}\n\n```{.r .cell-code}\nm0 <- lm(SalePrice ~ 1, data = d_train)\n```\n:::\n\n\nWie gut ist die Vorhersage des Nullnomdells?\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-51_db76af1d284409081efb26cade61c39b'}\n\n```{.r .cell-code}\nrmse(m0)\n## [1] 79415.29\n```\n:::\n\n\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-52_0c541ff3f32411d510b0b25a9db8cc2e'}\n\n```{.r .cell-code}\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n```\n:::\n\n\n### Vorhersagen im Test-Datensatz\n\nWir haben jetzt unseren Champion, `m1`.\nAlle Hoffnung ruht auf diesem Modell.\nOb die Vorhersagen im Test-Sample pr√§zise sein werden?\nOder himmelweit daneben?\nBitte, entt√§usche uns nicht!\n\n\nHier sind die Vorhersagen:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-53_a9587b220824b6893cfa4c461a49694a'}\n\n```{.r .cell-code}\nm1_pred <- predict(m1, newdata = d_test)  # <1> \nhead(m1_pred) # <2>\n##        1        2        3        4        5        6 \n## 103394.7 152441.4 161837.8 187675.8 225467.0 190260.2\n```\n:::\n1. predicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus `d_test`\n2. zeige den \"Kopf\" der Vorhersagen (`m1_pred`), d.h. die ersten paar Vorhersagen\n\n\n\nDie Vohersagen f√ºgen wir jetzt dem Test-Sample hinzu:\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-54_897c4586a7f2935474b1fcd37820dcf5'}\n\n```{.r .cell-code}\nd_test <- \n  d_test %>% \n  mutate(SalePrice = m1_pred)\n```\n:::\n\n\n### Einreichen!\n\n\nSo, wir haben unsere Vorhersagen!\nJetzt reichen wir diese Vorhesagen ein.\n\nF√ºr die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten `id` und `SalePrice`:\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-55_a718bfc2eaa7328231f104448ece00e0'}\n\n```{.r .cell-code}\nm1_subm <-\n  d_test %>% \n  select(Id, SalePrice)\n```\n:::\n\n\nKaggle m√∂chte keine fehlenden Werten in den Vorhersagen, also pr√ºfen wir das mal:\n\n::: {.cell code-annotations='hover' hash='regression1_cache/html/unnamed-chunk-56_c806ca97e998b21a56e3f8791cc3ff24'}\n\n```{.r .cell-code}\nm1_subm %>% \n  drop_na() %>%  # <1>\n  nrow()         # <2>\n## [1] 1458\n```\n:::\n1. Lass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n2. z√§hle die Anzahl der Zeilen\n\n\nOh, das ist *eine* Zeile weniger! Wir haben also einen fehlenden Wert!\n\nFiltern wir die Spalte `SalePrice` mal nach \"ist NA\":\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-57_5525e5f91e5ddf89320a665e9f607586'}\n\n```{.r .cell-code}\nm1_subm %>% # <1)\n  filter(is.na(SalePrice)) # <2>\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2577\",\"2\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n√úbersetzen wir die Syntax auf Detusch:\n\n1. Nimm zuerst die Tabelle `m1_smb`\n2. Filter dann so, dass du nur Zeilen hast, f√ºr die gilt, \"hier ist ein NA in der Spalte `SalePrice`\n\nAh, da ist er, der fehlende Wert, in Zeile 2577!\nHinfort!\n\nWir ersetzen die fehlenden Werte in `SalePrice` mit dem Mittelwert von `SalePrice`:\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-58_69d3e4e8c6d4b61bd1b688a04fbc613e'}\n\n```{.r .cell-code}\nm1_subm_nona <- # <1>\n  m1_subm %>%  # <2>\n  mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE))) # <3>\n```\n:::\n\nDie Syntax wieder auf Deutsch:\n\n1. Definiere `m1_subm_nona` wie folgt\n2. Nimm `m1_subm` und dann\n3. Ver√§ndere die Spalte `SalePrice` und zwar so, dass NAs ersetzt werden durch den Mittelwert von `SalePrice`\n\n\nUnd? Gib es jetzt noch fehlende Werte?\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-59_1eb8faae0313f1b57671567c2028cd76'}\n\n```{.r .cell-code}\nm1_subm_nona %>% \n  filter(is.na(SalePrice))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"SalePrice\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\nNein! Die Ergebnistabelle hat null Zeilen. \n\"No NA\" - Keine NAs, keine fehlenden Werte mehr.\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.^[Es bietet sich an `write_csv` zu verwenden, da `write.csv` automatisch (ungefragt) noch eine Id-Spalte  ohne Namen einf√ºgt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen `Id` und `SalePrice`].\n\n\n::: {.cell hash='regression1_cache/html/unnamed-chunk-60_aa8fe6b933389b4b769f260e719526eb'}\n\n```{.r .cell-code}\nwrite_csv(m1_subm_nona, \"daten/ames-kaggle/m1-subm.csv\")\n```\n:::\n\nUnd dann laden Sie diese Datei, `m1_subm.csv` bei Kaggle hoch und hoffen auf einen Hauptgewinn.\n\nDas Modell erzielte einen Score von *0.55521*.\n\n\n\n### Debrief\n\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt.\nSicherlich gibt es viele Ans√§tze, dieses Modell zu verbessern.\n\nHier sind einige Fragen, die Sie sich dazu stellen k√∂nnen:\n\n- Welche Pr√§diktoren sollte ich in das Modell aufnehmen?\n- Wie gehe ich mit fehlenden Werten um?\n- Wenn ein Pr√§diktor schief ist, sollte ich ihn dann log-transformieren?\n- Vielleicht sollte man manche Pr√§diktoren quadrieren?\n- Wie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n- ...\n\nViel Spielraum f√ºr Ihre Kreativit√§t!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- ## Fazit -->\n<!-- TODO  -->\n\n## Aufgaben\n\nEine Aufgabe, die eine Einf√ºhrung zum [Kaggle-Wettbewerb Ames House Prices]((https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview) bietet, finden Sie [hier im Datenwerk](https://datenwerk.netlify.app/posts/ames-kaggle1/ames-kaggle1.html).\n\nSuchen Sie beim [Datenwerk](https://datenwerk.netlify.app/) nach diesen Aufgaben\n\n    - Aussagen-einfache-Regr\n    - interpret-koeff-lm\n    - korr-als-regr\n    - Linearitaet1a\n    - lm1\n    - mtcars-regr01\n    - nichtlineare-regr1\n    - penguins-regr02\n    - regression1\n    - regression1b\n    - Regression3\n    - Regression4\n    - Regression5\n    - Regression6\n    \n    \n\nSchauen Sie sich die Aufgaben beim [Datenwerk](https://datenwerk.netlify.app/) an, vor allem die Tags [regression](https://datenwerk.netlify.app/#category=regression) und [lm](https://datenwerk.netlify.app/#category=lm).\n\n*Nicht alle Aufgaben* aus dieser Sammlung passen zum Stoff; vielleicht k√∂nnen Sie einige Aufgaben nicht l√∂sen.\nIgnorieren Sie einfach diese Aufgaben.\n\nBeachten Sie die [Hinweise zu den Aufgaben](https://datenwerk.netlify.app/hinweise).\n\n\n\n\n## Literatur\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}