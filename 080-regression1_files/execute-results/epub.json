{
  "hash": "2f017f6a9521ef083eae7b22eb8e05b3",
  "result": {
    "engine": "knitr",
    "markdown": "# Geradenmodelle 1 {#sec-gerade1}\n\n\n\n## Lernsteuerung\n\n\n\nAbb. @fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n\n\n\n\n\n\n### Lernziele\n\n\n- Sie k√∂nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\n- Sie k√∂nnen die Bestandteile eines Geradenmodells aufz√§hlen und erl√§utern.\n- Sie k√∂nnen die G√ºte eines Geradenmodells anhand von Kennzahlen bestimmen.\n- Sie k√∂nnen Geradenmodelle sowie ihre Modellg√ºte in R berechnen.\n\n\n### Ben√∂tigte R-Pakete\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.content-visible unless-format=\"epub\"}\n$$\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n$$\n:::\n\n\n\n\n\n\n\n### Ben√∂tigte Daten\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n::: {.content-visible when-format=\"pdf\"}\n\n@lst-mario-path definiert den Pfad zum Datensatz `mariokart` und importiert die zugeh√∂rige CSV-Datei in R, so dass wir einen Tibble mit Namen `mariokart` erhalten.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart_path <- paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets/\",\n  \"csv/openintro/mariokart.csv\")\n\nmariokart <- read.csv(mariokart_path)\n```\n:::\n\n\n\n\n\n\n\n\n:::\n\n\n\n## Vorhersagen\n\n\nVorhersagen sind eine n√ºtzliche Sache, \nunter (mindestens) folgenden Voraussetzungen:\n\n1. Sie sind pr√§zise\n2. Wir kennen die Pr√§zision\n3. Jemand interessiert sich f√ºr die Vorhersage\n\n\nDie Methode des Vorhersagens, die wir hier betrachten, \nnennt man auch *lineare Regression*.\n\n\n### Vorhersagen ohne Pr√§diktor\n\n:::::{#exm-noten-prognose}\nNach intensiver Besch√§ftigung mit Statistik sind Sie allgemein als Checker bekannt.\nViele j√ºngere Studis fragen Sie um Rat.\neines Tages kommt eine Studentin, Toni, und fragt: \"Welche Statistiknote kann ich in der Klausur erwarten?\"\nSie entgegnen: \"Wie viel hast du denn gelernt?\".\nDie Antwort: \"Sag ich nicht.\"\n\nNach kurzem √úberlegen geben sie den Notenschnitt der letzten Klausur als Prognose f√ºr diese Person. \n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in @lst-noten2-lokal wird bei Ihnen nur funktionieren, \nwenn auf *Ihrem Computer* dieser Ordner mit dieser Datei existiert. \nAndernfalls m√ºssen Sie die Daten erst herunterladen^[<https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/noten.csv>]:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-noten2-lokal .r .cell-code  lst-cap=\"Der Datensatz 'noten2' liegt im Unterordner 'Noten.'\"}\nnoten2 <- read.csv(\"data/noten2.csv\")\n```\n:::\n\n{{< downloadthis data/noten2.csv dname = \"noten2\" >}}\n\n\n\n\n\n\n\n\n\n\n\n\n\n::::\n\nDazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnoten2 %>% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n```\n\n::: {.cell-output-display}\n\n\n| mw|\n|--:|\n| 91|\n:::\n:::\n\n\n\n\n\n\n\n\nIhre Antwort lautet also: \n\"Im Schnitt haben die Studis bei der letzten Klausur ungef√§hr 91.08  der Punkte erzielt. \nDiesen Wert kannst du erwarten. \nSolange ich keine genaueren Infos habe, \nz.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!\" $\\square$\n:::::\n\n\nOhne Kenntnis eines Pr√§diktors (UV) (wie z.B. Lernzeit) \nist der Mittelwert ein geeigneter Vorhersagewert f√ºr jede Beobachtung, s. @fig-noten3.\nWir nutzen den Mittelwert als Punktmodell f√ºr den Klausurerfolg. $\\square$\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell](080-regression1_files/figure-epub/fig-noten3-1.png){#fig-noten3 fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n\n\n\n:::{def-nullmodell}\n### Nullmodell (Punktmodell)\nModelle ohne Pr√§diktor, Punktmodelle also, \nkann man so bezeichnen: `y ~ 1`. \nDa das Modell null Pr√§diktoren hat, \nnennt man es auch manchmal \"Nullmodell\".\n:::\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm0 <- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        91.1\n```\n:::\n\n\n\n\n\n\n\n\n`lm` steht f√ºr \"lineares Modell\", die `1` sagt, \ndass es keine Pr√§diktoren gibt.\nIn dem Fall wird der Mittelwert, 91.08, als Gerade verwendet.\nDer zur√ºckgemeldete Koeffizient `(Intercept)` \nist hier der Modell des Punktmodells.\nDa es ein Punktmodell ist, sagt es f√ºr alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nWir sagen f√ºr jede Beobachtung einen Wert von 91.08 vorher.\n\n\n### Vorhersagen mit Pr√§diktor\n\n\n\n\n:::{#exm-noten3}\n### Toni verr√§t die Lernzeit\n\nToni entschlie√üt sich dann doch noch, die Lernzeit zu verraten:\n\"Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.\"\nJetzt m√ºssen Sie erstmal nachdenken: \n\"Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?\"\n\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. @fig-noten4, a).\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(DataExplorer)\nnoten2 %>% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\n\nAuf dieser Basis antworten Sie Toni: \n\"Bei 42 Stunden Lernzeit solltest du so 83 Punkte bekommen. \nK√∂nnte mit dem Bestehen eng werden.\"\nToni ist nicht begeistert von Ihrer Prognose und zieht von dannen. $\\square$\n:::\n\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von *Lernzeit* und *Klausurpunkte* ist deutlich zu erkennen.\nMit einem Lineal k√∂nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. @fig-noten4, b).\n\n\n\n\n\n\n\n\n\n::: {#fig-noten4 .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Streudiagramm](080-regression1_files/figure-epub/fig-noten4-1.png){#fig-noten4-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Streudigramm mit 'Trendgerade' (blau)](080-regression1_files/figure-epub/fig-noten4-2.png){#fig-noten4-2 fig-align='center' width=70%}\n:::\n\nNoten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt gekennzeichnet.\n:::\n\n\n\n\n\n\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.\n\n\n\n## Geradenmodelle\n\n\n### Achsenabschnitt und Steigung definieren eine Gerade\n\nWir verwenden eine Gerade als Modell f√ºr die Daten, s. @fig-noten4, b.\nAnders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\n\nEin *Geradenmodell* ist eine Verallgemeinerung des Punktmodells:\nEin Punktmodell sagt f√ºr alle Beobachtungen den gleichen Wert vorher.\n@fig-noten3 und @fig-noten4 stellen ein Punktmodell \neinem Geradenmodell gegen√ºber.\n\nIn einem Geradenmodell wird nicht mehr (notwendig) \nf√ºr jede Beobachtung die gleiche Vorhersage $\\hat{y}$ gemacht (wie das bei einem Punktmodell der Fall ist).\n\n::::{#def-gerade}\n### Gerade\n\nEine Gerade ist das, was man bekommt, \nwenn man eine lineare Funktion in ein Koordinatensystem einzeichnet.\nMan kann sie durch durch zwei *Koeffizienten* festlegen: \nAchsenabschnitt (engl. *intercept*), und Steigung (engl. *slope*).\nH√§ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit $t$ und die Steigung mit $m$ bezeichnet:\n \n::: {.content-visible unless-format=\"epub\"}\n\n<!-- HTML, PDF: -->\n\n$f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}$.\n\nIn der Statistik wird folgende Nomenklatur bevorzugt:  $f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + {\\beta_1} \\color{xcol}{x}$ oder $f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + {b_1} \\color{xcol}{x}$ .\n\nDie Nomenklatur mit $\\color{beta0col}{b_0}, \\color{beta1col}{b_1}$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. \nGriechische Buchstaben werden meist verwendet, um zu zeigen, \ndass man an einer Aussage √ºber eine Population, \nnicht nur √ºber eine Stichprobe, machen m√∂chte.\n\nDas \"Dach\" √ºber y, $\\color{modelcol}{\\hat{y}}$, \ndr√ºckt aus, dass es sich den den gesch√§tzten, bzw. vom Modell vorhergesagten (\"modellierten\") \nWert f√ºr $\\color{ycol}{y}$ handelt, nicht das tats√§chliche (empirische, beobachtete) $\\color{ycol}{y}$. $\\square$\n@fig-regrtex skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n:::\n\n\n\n \n::: {.content-visible when-format=\"epub\"}\n\n<!-- NUR EPUB: -->\n\n\n$f(x)={y}=mx + t.$\n\nIn der Statistik wird folgende Nomenklatur bevorzugt:  $f(x)={\\hat{y}}={\\beta_0} + {\\beta_1}$ oder $f(x)=y= {b_0} + {b_1}.$ \n\nDie Nomenklatur mit $b_0, b_1$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. \nGriechische Buchstaben werden meist verwendet, um zu zeigen, \ndass man an einer Aussage √ºber eine Population, \nnicht nur √ºber eine Stichprobe, machen m√∂chte.\n\nDas \"Dach\" √ºber y, $\\hat{y}$, \ndr√ºckt aus, dass es sich den den gesch√§tzten, bzw. vom Modell vorhergesagten (\"modellierten\") \nWert f√ºr ${y}$ handelt, nicht das tats√§chliche (empirische, beobachtete) ${y}$. $\\square$\n@fig-regrtex skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n:::\n\n::::\n\n\n\n\n\n\n\n![Achsenabschnitt ($\\beta_0$) und Steigung ($\\beta_1$) einer Regressionsgeraden [@menk_linear_2014]](img/regr.png){#fig-regrtex width=\"70%\"}\n\n\n::::: {.content-visible unless-format=\"epub\"}\n\n<!-- HTML, PDF -->\n\n\n:::{#def-einfache-lineare-modell}\n\n### Das einfache lineare Modell\n\nDas einfache lineare Modell nimmt den Wert einer abh√§ngigen metrischen Variablen, \\color{ycol}{y},\nals lineare Funktion von unabh√§ngigen Variablen, \\color{xcol}{x}, an, plus einem Fehlerterm, \\color{errorcol}{e} bzw. \\color{errorcol}{$\\epsilon$}, s. @eq-linear-model. $\\square$\n:::\n\n\n\n\n$$\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}$${#eq-linear-model}\n\nMit:\n\n- $\\color{beta0col}{\\beta_0}$: gesch√§tzter y-Achsenabschnitt laut Modell (engl. *intercept*)\n- $\\color{beta1col}{\\beta_1}$: gesch√§tzte Steigung (Regressionsgewicht) laut Modell (engl. *slope*)\n- $\\color{errorcol}{\\epsilon}$: Fehler des Modells\n\n\n:::::\n\n\n\n\n\n::::: {.content-visible when-format=\"epub\"}\n\n<!-- epub -->\n\n\n\n\n$$\\begin{aligned}\n{y} &= f({x}) + {\\epsilon} \\\\\n{y_i} &= {\\beta_0} + {\\beta_1} \\cdot {x_i} + {\\epsilon_i} \\square\n\\end{aligned}$$\n\nMit:\n\n- ${\\beta_0}$: gesch√§tzter y-Achsenabschnitt laut Modell\n- ${\\beta_1}$: gesch√§tzte Steigung laut Modell\n- ${\\epsilon}$: Fehler des Modells\n\n\n:::::\n\n\n\n\n\n\nJe nach Datenlage k√∂nnen sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. @fig-regr-div.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {#fig-regr-div .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Datensatz 1](080-regression1_files/figure-epub/fig-regr-div-1.png){#fig-regr-div-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Datensatz 2](080-regression1_files/figure-epub/fig-regr-div-2.png){#fig-regr-div-2 fig-align='center' width=70%}\n:::\n\nRegressionsanalysen mit verschiedenen Koeffizienten, aber gleicher Modellg√ºte\n:::\n\n\n\n\n\n\n\n\n\n::::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n@fig-linfun [@yi_interactive_2021] zeigt ein interaktives Beispiel einer linearen Funktion. \nSie k√∂nnen Punkte per Klick/Touch hinzuf√ºgen.\n\n\n::::{#fig-linfun}\n\n::: {.figure-content}\n\n\n\n\n\n\n\n\n\n\n\n\n\n```{ojs}\n//| echo: false\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () => {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n```\n\n```{ojs}\n//| echo: false\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () => {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n```\n\n```{ojs}\n//| echo: false\nrSquaredPlot = RSquaredPlot({ width: width })\n```\n\n```{ojs}\n//| echo: false\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) => x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) => y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n```\n\n```{ojs}\n//| echo: false\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) => {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n```\n\n```{ojs}\n//| echo: false\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) => {\n    setTimeout(() => {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R¬≤\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =>\n        update.call((update) => {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) => xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =>\n        update.call((update) => {\n          // Check if bar is too short\n          const check = (d) => d < 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) => xScale(d))\n            .text((d) => labelFormat(d))\n            .attr(\"fill\", (d) => (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) => (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) => (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n```\n\n```{ojs}\n//| echo: false\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) => x, // accessor function for x-coordinate\n    y = ([, y]) => y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) => ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) => ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) => d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) => d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) => d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) => d.xCoord)\n    .y((d) => d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) => g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) => g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () => {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () => {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) => d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) => {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) => xScale(d[0][0]))\n          .attr(\"x2\", (d) => xScale(d[1][0]))\n          .attr(\"y1\", (d) => yScale(d[0][1]))\n          .attr(\"y2\", (d) => yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =>\n          update\n            .transition()\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord)),\n        (exit) =>\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) => xScale(d.xCoord))\n            .attr(\"y1\", (d) => yScale(d.yCoord))\n            .attr(\"x2\", (d) => xScale(d.xCoord))\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =>\n          update.call((update) => {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) => xScale(d.xCoord))\n              .attr(\"y1\", (d) => yScale(d.yCoord))\n              .attr(\"x2\", (d) => xScale(d.xCoord))\n              .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =>\n          exit\n            .transition()\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) < 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) => xScale(d.xCoord))\n            .attr(\"y\", (d) => yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) => {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =>\n          update.call((update) => {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) => xScale(d.xCoord))\n              .attr(\"y\", (d) => yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) => exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) => ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nd3 = require(\"d3-regression\", \"d3\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nInteraktives Beispiel f√ºr eines lineares Modell. F√ºgen Sie Punkte per Klick/Touch hinzu.\n::::\n:::::\n\n\n\n:::{#exm-noten5}\n### Toni will es genau wissen\nDa Toni Sie als Statistik-Profi abgespeichert hat, w\nerden Sie wieder konsultiert.\n\"Okay, ich hab noch zwei Fragen. \nErstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? \nZweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zur√ºck!\"\n\n[Das sind gute Fragen. Den $\\color{ycol}{Y}$-Wert (Klausurpunkte) bei $\\color{xcol}{X}=0$ gibt der Achsenabschnitt zur√ºck. ]{.content-visible unless-format=\"epub\"}\n\n[Das sind gute Fragen. Den ${Y}$-Wert (Klausurpunkte) bei ${X}=0$ gibt der Achsenabschnitt zur√ºck. ]{.content-visible when-format=\"epub\"}\n\n\nSchnell skizzieren Sie dazu ein Diagramm, s. @fig-beta0.\nPuh, die Antwort wird Toni nicht gefallen ... $\\square$\n:::\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)](080-regression1_files/figure-epub/fig-beta0-1.png){#fig-beta0 fig-align='center' width=75%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nAnstelle auf @fig-beta0 zu schauen, \nk√∂nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n\n>    [üßë‚Äçüè´]{.content-visible when-format=\"html\"}[\\emoji{teacher}]{.content-visible when-format=\"pdf\"}  Hey R, predicte mir mal auf Basis vom Modell \"lm1\" den Lernerfolg f√ºr Toni, wenn der x=0 Stunden lernt.\n\n>    [ü§ñ]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Okay, ich predicte mit Modell \"lm1\" und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit <- tibble(x = 0)  # `tibble` erstellt eine Tabelle\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit)\n##  1 \n## 46\n```\n:::\n\n\n\n\n\n\n\n\n\n### Spezifikation eines Geradenmodells\n\n\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. @eq-mod1:\n\n\n::: {.content-visible unless-format=\"epub\"}\n\n$$\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}}$$ {#eq-mod1}\n\nLies: \"Laut meinem Modell ist mein (gesch√§tztes) $\\color{ycol}{\\hat{y}}$ irgendeine Funktion von $\\color{xcol}{\\text{x}}$\".\n\nWir erinnern uns, dass $\\color{ycol}{Y}$ die $\\color{ycol}{AV}$ und $\\color{xcol}{X}$ die $\\color{xcol}{UV}$ ist:\n\n$$\\color{ycol}{AV} \\sim \\color{xcol}{UV}$$ {#eq-mod1}\n\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n$${\\hat{y}} \\sim {\\text{x}}$$ {#eq-mod1}\n\nLies: \"Laut meinem Modell ist mein (gesch√§tztes) ${\\hat{y}}$ irgendeine Funktion von ${\\text{x}}$\".\n\nWir erinnern uns, dass ${Y}$ die ${AV}$ und ${X}$ die ${UV}$ ist:\n\n$${AV} \\sim {UV}$$ {#eq-mod1}\n:::\n\n\nWir werden als Funktion (erstmal) nur Geraden verwenden.\nDie genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\n\n\n@eq-mod1 k√∂nnen Sie so ins Errische √ºbersetzen:\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(y ~ x, data = meine_daten)\n```\n:::\n\n\n\n\n\n\n\n\n`lm` steht f√ºr \"lineares Modell\", also eine Gerade als Modell.\nDie Gerade nennt man auch *Regressionsgerade* (an anderer Stelle in diesem Buch unscharf als \"Trendgerade\" bezeichnet).\n\n:::{#exm-noten5}\n### Zahlen f√ºr Toni\nToni ist nicht zufrieden mit Ihren Vorhersagen: \"Jetzt h√∂r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir pr√§zise Zahlen!\".\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      46.191        0.879\n```\n:::\n\n\n\n\n\n\n\n\nR gibt Ihnen die beiden Koeffizienten f√ºr die Gerade aus. \nDen Namen des Objekts k√∂nnen Sie frei aussuchen, z.B. `mein_erstes_lm`.\n\nDie Regressionsgleichung lautet demnach:\n`y_pred = 8.6 + 0.88*x`.\n\n\n::: {.content-visible unless-format=\"epub\"}\n`8.6` ist der Achsenabschnitt, d.h. der Wert von $\\color{ycol}{Y}$ wenn $\\color{xcol}{x}=0$.\n`0.88` ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: F√ºr jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um `0.88` Punkte.\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige $\\color{ycol}{Y}$-Werte ausrechnen gegeben bestimmte $\\color{xcol}{X}$-Werte.\nHat jemand zum Beispiel 10 Stunden gelernt, \nw√ºrden wir folgendes Klausurergebnis vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlernzeit <- 10\ny_pred <- 46 + 0.88*lernzeit\ny_pred\n## [1] 55\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n\n`8.6` ist der Achsenabschnitt, d.h. der Wert von ${Y}$ wenn ${x}=0$.\n`0.88` ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: F√ºr jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um `0.88` Punkte.\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige ${Y}$-Werte ausrechnen gegeben bestimmte ${X}$-Werte.\nHat jemand zum Beispiel 10 Stunden gelernt, \nw√ºrden wir folgendes Klausurergebnis vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlernzeit <- 10\ny_pred <- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n:::{#exm-noten6}\n### Vorhersage f√ºr Klausurerfolg, n√§chster Versuch\nSie versuchen, noch etwas Gutes f√ºr Toni zu tun.\nR hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt.\nSie d√ºrfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit2 <- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n```\n:::\n\n\n\n\n\n\n\n\n`tonis_lernzeit2` ist eine Tabelle mit einer Zeile und einer Spalte:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit2\n```\n\n::: {.cell-output-display}\n\n\n|  x|\n|--:|\n| 73|\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit2)\n##   1 \n## 110\n```\n:::\n\n\n\n\n\n\n\n\n\n\nDie Syntax von `predict` lautet:\n\n```\npredict(name_des_objekts, newdata = tabelle_mit_pr√§diktorwerten)\n```\n\nDie Funktion `predict` liefert eine Vorhersage f√ºr eine Vorhersage.\n:::\n\n\n### Vorhersagefehler\n\n\n::: {.content-visible unless-format=\"epub\"}\nDie Differenz zwischen vorhergesagten Wert f√ºr eine (neue) Beobachtung, $\\color{modelcol}{\\hat{y_0}}$ \nund ihrem tats√§chlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: \n$\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}$.\n:::\n\n\n\n::: {.content-visible when-format=\"epub\"}\nDie Differenz zwischen vorhergesagten Wert f√ºr eine (neue) Beobachtung, ${\\hat{y_0}}$ \nund ihrem tats√§chlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: \n${e_i} = {y_i} - {\\hat{y}_i}$.\n:::\n\n\n\n\n\n\n\n\n\n\n::: {#fig-resid .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Geradenmodell (lm1)](080-regression1_files/figure-epub/fig-resid-1.png){#fig-resid-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Punktmodell (lm0)](080-regression1_files/figure-epub/fig-resid-2.png){#fig-resid-2 fig-align='center' width=70%}\n:::\n\nVorhersagefehler als Abweichungsbalken: Beim Geradenmodell, links, sind die Vorhersagefehler (Abweichungsbalken) kleiner (k√ºrzer) als beim Punktmodell, rechts.\n:::\n\n\n\n\n\n\n\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) \nin Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket `easystats`):\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm0)\nmae(lm1)\n## [1] 11\n## [1] 8\n```\n:::\n\n\n\n\n\n\n\n\n\nVergleichen wir MAE im  Nullmodell mit MAE in `lm1`: \n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverhaeltnis_fehler_mae <- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n```\n:::\n\n\n\n\n\n\n\n\n\n\nAh! Das Geradenmodell ist viel besser:\nVon `lm0` zu `lm1` haben die mittlere Absolutl√§nge des Fehlerbalkens auf 71 Prozent verbessert.\nNicht schlecht!\n\n\n:::{#def-fehlerstreung}\n### Fehlerstreuung\nAls Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte ($y_i$) vom vorhergesagten Wert ($\\hat{y}_i$). $\\square$\n:::\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngr√∂√üen \nwie MAE oder MSE.\n\n\n:::{.callout-note}\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), \nsolange X mit Y korreliert ist. $\\square$\n:::\n\n\nNat√ºrlich k√∂nnen wir -- in Analogie zur Varianz -- \nauch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen.\nWer mag, \nkann den MSE auch von Hand berechnen: `mean((noten2$y - mean(noten2$y))^2)`.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmse(lm0)\nmse(lm1)\n## [1] 193\n## [1] 106\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverhaeltnis_fehler_mse <- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n### Berechnung der Modellkoeffizienten\n\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\n\nDie Regressionskoeffizienten (hier synonym: Modellparameter) b0 und b1 w√§hlt man so, dass die *Residuen* *minimal* sind.\nGenauer gesagt wird die Summe der quadrierten [Residuen]{.green} minimiert, s. @eq-min.\n\n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n @fig-opt veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n::::{#fig-opt}\n\n:::{.panel-tabset}\n\n### Minimierung der Residuen\n\n![Berechnung der Modellkoeffizienten durch Minimierung der Residuen](img/RegressionSpring.gif)\n\n### Minimierung der quadrierten Residuen\n\n![Minimierung der quadrierten Residuen](img/RegressionRSS.gif)\n\n:::\n\n\nBildquelle: [Karsten L√ºbke, FOM Hochschule](https://www.fom-blog.de/autorinnen-und-autoren/karsten-luebke)\n\n::::\n:::::\n\n\n\n\n::: {.content-visible unless-format=\"epub\"}\n$$\\text{min}\\sum_i \\color{errorcol}{e_i}^2$${#eq-min}\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n$$\\text{min}\\sum_i {e_i}^2$${#eq-min}\n:::\n\nEs gibt verschiedene M√∂glichkeiten, \num die Koeffizienten zu berechnen (die sind aber nicht in diesem Buch zu finden).\nEine sch√∂ne Darstellung dazu findet sich bei @kaplan_statistical_2009.\n\n\n::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\"Von Hand\" k√∂nnen Sie die Optimierung von b0 und b1 in \n dieser App der FOM-Hochschule^[<https://fomshinyapps.shinyapps.io/KleinsteQuadrate/>] ausprobieren.\n:::\n\n\n\n\n\n\n\n\n## R-Quadrat als Ma√ü der Modellg√ºte\n\nAnders gesagt, wir haben uns ( (bzw. das Modell hat sich) um $1 - 0.55$ verbessert.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::{#def-r2}\n### R-Quadrat\nDie Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen  von `lm0` \nzum gerade untersuchten Modell nennt man  *R-Quadrat* ($R^2$).\nR-Quadrat ($R^2$) e\nines Modells $m$ ist definiert als die Verringerung der Streuung, \nwenn man das Modell $m$ mit dem Nullmodell $m_0$ vergleicht: $R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}$. \nR-Quadrat ist ein Ma√ü der *Modellg√ºte*: \nJe gr√∂√üer $R^2$, desto besser die Vorhersage. \nDa es ein Anteilsma√ü ist, \nliegt der Wertebereich zwischen 0 uns 1.\nIm Nullmodell liegt R-Quadrat per Definition bei 0.\nIm Fall von Modellen des Typs $y\\sim x$ gilt: $R^2 = r_{xy}^2$.\n$\\square$\n:::\n\n\nEinfach gesagt: $R^2$ gibt an, wie gut (zu welchem Anteil) \nein Modell die Zielvariable erkl√§rt. \n\n\nWir k√∂nnen R-Quadrat ($R^2$) uns von R z.B. so ausgeben lassen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n```\n:::\n\n\n\n\n\n\n\n\nBei einer perfekten Korrelation ist $r=1$, \ndaher ist dann auch $R^2 = 1$.\nDas gilt bei Modellen mit einem Pr√§diktor; \ngibt es mehrere Pr√§diktoren \ngilt die Beziehung nur, wenn die Pr√§diktoren alle paarweise unabh√§ngig sind, \nvgl. @fig-r2-extreme.\n\n\n\n\n\n\n\n\n\n::: {#fig-r2-extreme .cell layout=\"[[45,-10,45],[100]]\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Keine Korrelation](080-regression1_files/figure-epub/fig-r2-extreme-1.png){#fig-r2-extreme-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Perfekte Korrelation](080-regression1_files/figure-epub/fig-r2-extreme-2.png){#fig-r2-extreme-2 fig-align='center' width=70%}\n:::\n\nExtremf√§lle von R-Quadrat: 0 und 1. (a) Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungef√§hr) parallel zur X-Achse. (b) Perfekte Korrelation, r = 1 und $R2$ = 1: Die Prognose ist gleich dem beobachtetem Wert.\n:::\n\n\n\n\n\n\n\n\nBei einer perfekten Korrelation $R^2=1$ liegen die Punkte auf der Geraden.\nIm gegenteiligen Extremfall von $R^2=0$ ist die Vorhersage genauso gut, \nwie wenn man f√ºr jedes $y$ den Mittelwert, [$\\color{ycol}{\\bar{y}}$]{.content-visible unless-format=\"epub\"}\n[${\\bar{y}}$]{.content-visible when-format=\"epub\"}, vorhersagen w√ºrde. \nJe gr√∂√üer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser \"erkl√§rt\" das Modell die Daten \n(desto besser der \"Fit\", sagt man).\n\n::: {.content-visible when-format=\"html\"}\n[Diese App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/Variationszerlegung/) erlaubt es Ihnen mit der Gr√∂√üe der Residuen eines linearen Modells zu spielen.\n:::\n\n\n\n<!-- ### Addition der Varianzen -->\n\n\n<!-- Nennen wir die Varianz des Verkaufspreis $s^2_y$, die Verbesserung der Fehlerstreuung durch das *M*odell $s^2_m$ und die restliche Fehlerstreuung, den MSE, $s^2_e$. -->\n<!-- Dann gilt: -->\n\n<!-- $$s^2_y = s^2_m + s^2_e \\\\ -->\n<!-- s^2_m = s^2_y - s^2_e$$ -->\n\n<!-- ```{r} -->\n<!-- s2_y = var(noten2$y) -->\n<!-- s2_e = mse(lm1) -->\n<!-- s2_m = s2_y - s2_e -->\n<!-- s2_m -->\n<!-- ``` -->\n\n<!-- Die Varianzanteile addieren sich. Mit anderen Kennzahlen der Streuung (SD, MAE) funktioniert das nicht. -->\n\n\n## Interpretation eines Regressionsmodells {#sec-interpret-reg-mod}\n\n\n### Modellg√ºte\n\nDie Residuen (Vorhersagefehler) bestimmen die Modellg√ºte:\nSind die Residuen im Schnitt gro√ü, so ist die Modellg√ºte gering (schlecht), und umgekehrt.\nVerschiedenen Koeffizienten stehen zur Verf√ºgung: R-Quadrat, $r$ (als Korrelation von tats√§chlichem $y$ und vorhergesagten $\\hat{y}$), MSE, RMSE, MAE, ...\n\n\n### Koeffizienten\n\nDie Modellkoeffizienten, also Achsenabschnitt ($\\beta_0$; lies: \"beta Null\") und Steigung ($\\beta_1$) sind nur eingeschr√§nkt zu interpretieren, \nwenn man die zugrundeliegenden kausalen Abh√§ngigkeiten nicht kennt.\nNur aufgrund eines statistischen Zusammenhangs darf man keine kausalen Abh√§ngigkeiten annehmen.\nOhne eine guten Grund f√ºr eine Kausalbehauptung kann man kann nur *deskriptiv* argumentieren.\nOder sich mit der Modellg√ºte und den Vorhersagen begn√ºgen. \nWas auch was wert ist.\n\n#### Achsenabschnitt\n\n[Im Modell `lm1` liegt der Achsenabschnitt bei $\\textcolor{ycol}{y}=46.19$. \nBeobachtungen mit $\\color{xcol}{x}=0$ \nk√∂nnen also diesen $\\textcolor{ycol}{Y}$-Wert erwarten.]{.content-visible unless-format=\"epub\"}\n\n\n[Im Modell `lm1` liegt der Achsenabschnitt bei ${y}=46.19$. \nBeobachtungen mit ${x}=0$ \nk√∂nnen also diesen ${Y}$-Wert erwarten.]{.content-visible when-format=\"epub\"}\nLeider ist es h√§ufig so, dass Pr√§diktorwerte von 0 in der Praxis nicht realistisch sind, \nso dass der Achsenabschnitt dann wenig n√ºtzt.\n\n:::{#exm-groesse}\n### Regression Gr√∂√üe und Gewicht\nNutzt man K√∂rpergr√∂√üe und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von K√∂rpergr√∂√üe wenig n√ºtzlich, da es keine Menschen gibt der Gr√∂√üe 0. $\\square$\n:::\n\n\n#### Geradensteigung\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\nSo interpretiert man die Geradensteigung, $\\beta_1$:\n\"Im Modell `lm1` betr√§gt der Regressionskoeffizient $\\beta1 = 0.88$. Zwei Studentinnen, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich *laut Modell* um den Wert von $\\beta_1$\"\n\n:::{.callout-caution}\nH√§ufig liest man, der \"Effekt des Pr√§diktors\" auf die AV betrage z.B. $0.88$. \"Effekt\" ist aber ein Wort, \ndas man kausal verstehen kann.\nOhne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. \nDaher sollte man das Wort \"Effekt\" mit Vorsicht genie√üen. \nManche sprechen daher auch von einem \"statistischen Effekt\". $\\square$\n:::\n\n\n## Wie man mit Statistik l√ºgt\n\n\nDer Unterschied in Modellg√ºte zwischen, \nsagen wir, $r=.1$ und $r=.2$ ist *viel kleiner* als zwischen $r=.7$ und $r=.8$.\n$R^2$ ist ein (lineares) Ma√ü der Modellg√ºte und da $r = \\sqrt{R^2}$, darf $r$ nicht wie $R^2$ \nals Ma√ü der Modellg√ºte interpretiert werden. @fig-r-r2 zeigt den Zusammenhang von $r$ und $R^2$.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Der Zusammenhang von r und R-Quadrat ist nicht linear.](080-regression1_files/figure-epub/fig-r-r2-1.png){#fig-r-r2 fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::{.callout-caution}\nUnterschiede zwischen Korrelationsdifferenzen d√ºrfen nicht linear interpretiert werden. $\\square$\n:::\n\n\n## Fallbeispiel Mariokart\n\n### Der Datenwahrsager legt los\n\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, \nin dem Sie arbeiten, \nhaben Sie sich neue Ziele gesetzt.\nSie m√∂chten eine genaue Vorhersage von Verkaufspreisen erzielen.\nAls Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin.\nGenaue Vorhersagen, \ndas ist etwas von hoher betriebswirtschaftlicher Relevanz.\nAuf geht's!\n\nDaten laden (und die √ºblichen Pakete starten, nicht vergessen):\n\n::: {.content-visible when-format=\"html\"}\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(mariokart_path)\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm2 <- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n```\n:::\n\n\n\n\n\n\n\n\n\nOh nein! Unterirdisch schlecht. Anstelle von blo√üem Rumprobieren √ºberlegen Sie und schauen dann nach, welche Variable am st√§rksten korreliert mit `total_pr`;\nes resultiert `lm3`: \n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm3 <- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n```\n:::\n\n::: {#tbl-lm3 .cell layout-align=\"center\" tbl-cap='Modellparameter von lm3'}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |   SE |         95% CI | t(141) |      p |\n|:-----------|:-----------:|:----:|:--------------:|:------:|:------:|\n|(Intercept) |       36.25 | 2.54 | (31.23, 41.26) |  14.28 | < .001 |\n|ship pr     |        4.34 | 0.57 |   (3.22, 5.46) |   7.67 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, \nwie man in @tbl-lm3 sieht: Ein Spiel, \ndas mit Null Euro Preis startet, kann laut `lm3` etwa 36 Euro finaler Verkaufspreis erwarten.\n*Pro Euro an Versandkosten* (`ship_pr`) steigt der zu erwartende finale Verkaufspreis \num ca. 4 Euro.\n(Die Spalte `95 CI` gibt einen Sch√§tzbereich f√ºr den jeweiligen Modellkoeffizienten an,\ndenn es handelt sich bei den Koeffizienten um Sch√§tzwerte;\nder wahre Wert in der Population ist unbekannt. \nWir kennen schlie√ülich nur eine Stichprobe der Gr√∂√üe $n=143$.)\n\nDie Regressionsgleichung von `lm3` lautet demnach:\n`total_pr_pred = 36.25 + 4.34*ship_pr`.\n\nIn Worten: \n\n>    Der vorhergesagte Gesamptreis eines Spiels liegt bei 36.25‚Ç¨ \"Sockelbetrag\" plus 4.34 mal die Versandkosten.\n\n\n### Vertiefung\n\nMan kann sich die erwarteten Werte (\"expectations\") des Verkaufspreises in Abh√§ngigkeit vom Wert der UV (`ship_pr`) auch sch√§tzen (\"to estimate\") lassen, und zwar so mit `estimate_expectation(lm3)`, s. @tbl-lm3-expect.\n\n\n\n\n\n\n\n\n\n\n\n\n::: {#tbl-lm3-expect .cell layout-align=\"center\" tbl-cap='Die vorhergesagten (predicted) Werte und die Abweichungen vom vorhergesagten Wert (Residuals)'}\n::: {.cell-output-display}\n\n\nTable: Model-based Expectation\n\n|ship_pr | Predicted|  SE |        95% CI | Residuals|\n|:-------|---------:|:----|:--------------|---------:|\n|4.00    |     53.59|1.87 |(49.89, 57.30) |     -2.04|\n|3.99    |     53.55|1.87 |(49.85, 57.25) |    -16.51|\n|3.50    |     51.43|1.82 |(47.82, 55.03) |     -5.93|\n|0.00    |     36.25|2.54 |(31.23, 41.26) |      7.75|\n|0.00    |     36.25|2.54 |(31.23, 41.26) |     34.75|\n|4.00    |     53.59|1.87 |(49.89, 57.30) |     -8.59|\n\nVariable predicted: total_pr\n\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, \nfassen Sie sich die Ausgabe zusammen.\n\n\n>    [ü§ñ]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Das sieht man in der Spalte `Predicted`, dort steht der vorhersagte Wert f√ºr `total_pr` f√ºr einen bestimmten Wert von `ship_pr`.\n\n\n>    [üßë‚Äçüéì]{.content-visible when-format=\"html\"}[\\emoji{student}]{.content-visible when-format=\"pdf\"} Kann ich auch `predict` benutzen? Ich w√ºrde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n>    [ü§ñ]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Ja, klar!\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nneue_daten <- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\nAber n√ºtzlich w√§re noch, das Modell \n(bzw. die Sch√§tzung der erwarteten Werte) als Diagramm zu bekommen.\nDas erreicht man z.B. so, s. @fig-lm3.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% plot()\n```\n\n::: {.cell-output-display}\n![Verbildlichung der erwarteteten Werte laut lm3](080-regression1_files/figure-epub/fig-lm3-1.png){#fig-lm3 fig-align='center' width=75%}\n:::\n:::\n\n\n\n\n\n\n\n\n`estimate_expectation` hei√üt sinngem√§√ü \"sch√§tze den zu erwartenden Wert\".\nKurz gesagt: Wir wollen eine Vorhersage von R.\n\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie \"gut\" das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\nDas Modell erkl√§rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13\n```\n:::\n\n\n\n\n\n\n\n\n\n\nIm n√§chsten Meeting erz√§hlen Sie Ihrem Chef \n\"Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 \nDollar genau vorhersagen!\".\nH√∂rt sich gut an.\nAllerdings h√§tte ihr Chef es gerne genauer. \nKann man da noch was machen?\n\n\n\n\n## Fallstudie Immobilienpreise\n\n\n\n\n<!-- ## Fallstudie Immobilienpreise -->\n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n:::{.callout-caution}\nDiese Fallstudie stellt die Pr√ºfungsleistung \"Prognosewettbewerb\" einf√ºhrend dar. \nEs empfiehlt sich f√ºr Sie, diese Fallstudie sorgsam zu bearbeiten. $\\square$\n:::\n\n::::\n\n\n### Hintergrund\n\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen.\nKurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei [kaggle.com](https://www.kaggle.com/) ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. \nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition [\"House Prices - Advanced Regression Techniques\"](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview), die Sie auf der Kaggle-Webseite finden.\nDort finden Sie auch eine n√§here Beschreibung, das Ziel und die Spielregeln des Wettbewerbs.\n\n::: {.content-visible when-format=\"html\"}\n\n- [Beschreibung](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description)\n- [Ziel/Aufgabe](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation)\n- [Spielregeln](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules)\n\n:::\n\n\n### Ben√∂tigte R-Pakete\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n\n\n\n### Daten\n\nSie k√∂nnen die Daten von [Kaggle herunterladen](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).\n\nIm Einzelnen m√ºssen Sie folgende Dateien herunterladen:\n\n- *Data_description.txt*: Codebook, d.h. Beschreibung der Variablen im Datensatz\n- *train.csv*: Daten von H√§usern, die Sie nutzen, um Modelle zu erstellen\n- *test.csv*:  Daten von H√§usern, von denen Sie den Kaufpreis vorhersagen sollen\n- *sample_submission.csv*: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\n\nSie k√∂nnen auch √ºber das Github-Repo `statistik1`, Ordner `data` auf die Daten zugreifen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_train_path_online <- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-train.csv\")\n\nd_test_path_online <- paste0(\n\"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-test.csv\")\n\nd_train <- read.csv(d_train_path_online)\nd_test <- read.csv(d_test_path_online)\n```\n:::\n\n\n\n\n\n\n\n\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden \nUnterverzeichnis (Ihres Projektordners in RStudio) ab.\n\n\n\nImportieren wir die Daten von der Festplatte, aus dem Unterordner `data` in R\n(davon ausgehend, dass der Unterordner `data` ein Unterordner Ihres aktuellen R-Projekts ist):\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_train_path <- \"data/kaggle-train.csv\"\nd_test_path <- \"data/kaggle-test.csv\"\nd_train <- read.csv(d_train_path)\nd_test <- read.csv(d_test_path)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWenn das Importieren von der Festplatte nicht klappt ... \nEs ist zwar hilfreich, wenn man Daten von der eigenen Festplatte importieren kann.\nAber f√ºrs Erste k√∂nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.\n\n\n\n\n\n\n### Prognosedatei\n\n\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enth√§lt.\nSie soll prinzipiell so aussehen wie in @tbl-subm dargestellt.\n\n\n\n\n\n\n\n::: {#tbl-subm .cell layout-align=\"center\" tbl-cap='Beispiel f√ºr den Aufbau der Prognose-Datei'}\n::: {.cell-output-display}\n\n\n|   id| SalePrice|\n|----:|---------:|\n| 1461|    169277|\n| 1462|    187758|\n| 1463|    183584|\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte `id` und der Spalte `Saleprice`.\nDie Spalte `id` gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist -- \nf√ºr welches Haus Sie also gerade einen Kaufpreis vorhersagen.\ndie Spalte `SalePrice` ist Ihre Vorhersage f√ºr den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht.\nInsgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, \nalso die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar? Los geht's!\n\n\n\n\n### Ein erster Blick in die Daten\n\nSchauen Sie sich zu Beginn einmal die Verteilung der metrischen Variablen,\nz.B. mit `describe_distribution(d_train)` an.\n\n\n::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n\n\n\n\n\n::: {#tbl-ames1 .cell layout-align=\"center\" tbl-cap='Verteilung der metrischen Variablen im ames-Datensatz'}\n::: {.cell-output-display}\n\n\n|Variable      |     Mean |       SD |      IQR |                Range | Skewness | Kurtosis |    n | n_Missing |\n|:-------------|:--------:|:--------:|:--------:|:--------------------:|:--------:|:--------:|:----:|:---------:|\n|Id            |   730.50 |   421.61 |   730.50 |      (1.00, 1460.00) |     0.00 |    -1.20 | 1460 |         0 |\n|MSSubClass    |    56.90 |    42.30 |    50.00 |      (20.00, 190.00) |     1.41 |     1.58 | 1460 |         0 |\n|LotFrontage   |    70.05 |    24.28 |    21.00 |      (21.00, 313.00) |     2.16 |    17.45 | 1201 |       259 |\n|LotArea       | 10516.83 |  9981.26 |  4060.00 |  (1300.00, 2.15e+05) |    12.21 |   203.24 | 1460 |         0 |\n|OverallQual   |     6.10 |     1.38 |     2.00 |        (1.00, 10.00) |     0.22 |     0.10 | 1460 |         0 |\n|OverallCond   |     5.58 |     1.11 |     1.00 |         (1.00, 9.00) |     0.69 |     1.11 | 1460 |         0 |\n|YearBuilt     |  1971.27 |    30.20 |    46.00 |   (1872.00, 2010.00) |    -0.61 |    -0.44 | 1460 |         0 |\n|YearRemodAdd  |  1984.87 |    20.65 |    37.00 |   (1950.00, 2010.00) |    -0.50 |    -1.27 | 1460 |         0 |\n|MasVnrArea    |   103.69 |   181.07 |   166.00 |      (0.00, 1600.00) |     2.67 |    10.08 | 1452 |         8 |\n|BsmtFinSF1    |   443.64 |   456.10 |   712.75 |      (0.00, 5644.00) |     1.69 |    11.12 | 1460 |         0 |\n|BsmtFinSF2    |    46.55 |   161.32 |     0.00 |      (0.00, 1474.00) |     4.26 |    20.11 | 1460 |         0 |\n|BsmtUnfSF     |   567.24 |   441.87 |   585.00 |      (0.00, 2336.00) |     0.92 |     0.47 | 1460 |         0 |\n|TotalBsmtSF   |  1057.43 |   438.71 |   503.50 |      (0.00, 6110.00) |     1.52 |    13.25 | 1460 |         0 |\n|X1stFlrSF     |  1162.63 |   386.59 |   509.75 |    (334.00, 4692.00) |     1.38 |     5.75 | 1460 |         0 |\n|X2ndFlrSF     |   346.99 |   436.53 |   728.00 |      (0.00, 2065.00) |     0.81 |    -0.55 | 1460 |         0 |\n|LowQualFinSF  |     5.84 |    48.62 |     0.00 |       (0.00, 572.00) |     9.01 |    83.23 | 1460 |         0 |\n|GrLivArea     |  1515.46 |   525.48 |   649.75 |    (334.00, 5642.00) |     1.37 |     4.90 | 1460 |         0 |\n|BsmtFullBath  |     0.43 |     0.52 |     1.00 |         (0.00, 3.00) |     0.60 |    -0.84 | 1460 |         0 |\n|BsmtHalfBath  |     0.06 |     0.24 |     0.00 |         (0.00, 2.00) |     4.10 |    16.40 | 1460 |         0 |\n|FullBath      |     1.57 |     0.55 |     1.00 |         (0.00, 3.00) |     0.04 |    -0.86 | 1460 |         0 |\n|HalfBath      |     0.38 |     0.50 |     1.00 |         (0.00, 2.00) |     0.68 |    -1.08 | 1460 |         0 |\n|BedroomAbvGr  |     2.87 |     0.82 |     1.00 |         (0.00, 8.00) |     0.21 |     2.23 | 1460 |         0 |\n|KitchenAbvGr  |     1.05 |     0.22 |     0.00 |         (0.00, 3.00) |     4.49 |    21.53 | 1460 |         0 |\n|TotRmsAbvGrd  |     6.52 |     1.63 |     2.00 |        (2.00, 14.00) |     0.68 |     0.88 | 1460 |         0 |\n|Fireplaces    |     0.61 |     0.64 |     1.00 |         (0.00, 3.00) |     0.65 |    -0.22 | 1460 |         0 |\n|GarageYrBlt   |  1978.51 |    24.69 |    41.00 |   (1900.00, 2010.00) |    -0.65 |    -0.42 | 1379 |        81 |\n|GarageCars    |     1.77 |     0.75 |     1.00 |         (0.00, 4.00) |    -0.34 |     0.22 | 1460 |         0 |\n|GarageArea    |   472.98 |   213.80 |   244.50 |      (0.00, 1418.00) |     0.18 |     0.92 | 1460 |         0 |\n|WoodDeckSF    |    94.24 |   125.34 |   168.00 |       (0.00, 857.00) |     1.54 |     2.99 | 1460 |         0 |\n|OpenPorchSF   |    46.66 |    66.26 |    68.00 |       (0.00, 547.00) |     2.36 |     8.49 | 1460 |         0 |\n|EnclosedPorch |    21.95 |    61.12 |     0.00 |       (0.00, 552.00) |     3.09 |    10.43 | 1460 |         0 |\n|X3SsnPorch    |     3.41 |    29.32 |     0.00 |       (0.00, 508.00) |    10.30 |   123.66 | 1460 |         0 |\n|ScreenPorch   |    15.06 |    55.76 |     0.00 |       (0.00, 480.00) |     4.12 |    18.44 | 1460 |         0 |\n|PoolArea      |     2.76 |    40.18 |     0.00 |       (0.00, 738.00) |    14.83 |   223.27 | 1460 |         0 |\n|MiscVal       |    43.49 |   496.12 |     0.00 |     (0.00, 15500.00) |    24.48 |   701.00 | 1460 |         0 |\n|MoSold        |     6.32 |     2.70 |     3.00 |        (1.00, 12.00) |     0.21 |    -0.40 | 1460 |         0 |\n|YrSold        |  2007.82 |     1.33 |     2.00 |   (2006.00, 2010.00) |     0.10 |    -1.19 | 1460 |         0 |\n|SalePrice     | 1.81e+05 | 79442.50 | 84075.00 | (34900.00, 7.55e+05) |     1.88 |     6.54 | 1460 |         0 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n:::\n\n### Ein erstes Vorhersagemodell\n\n\n#### Welche Variablen eignen sich zur Vorhersage?\n\n\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, \ndie Korrelation aller Pr√§diktoren mit der abh√§ngigen Variablen^[die vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt] zu berechnen, s. \n<!-- @tbl-d_train_corr und -->\n@lst-get-high-corrs.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-get-high-corrs .r .cell-code  lst-cap=\"Welche Variablen korrelieren st√§rker als .3?\"}\nd_train %>% \n  select(-Id) %>% \n  correlation() %>%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %>%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %>%   # sortiere absteigend nach der H√∂he des Korrelationskoeffizienten r\n  filter(abs(r) > .3)  # nur |r| > .3\n```\n:::\n\n::: {#tbl-d_train_corr .cell layout-align=\"center\" tbl-cap='Korrelation der Pr√§diktoren (UV) mit der AV'}\n\n:::\n\n\n\n\n\n\n\nAha! Ein Menge Information ... Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: \nIm Zweifel einfach ignorieren. \nWenn Sie die R-Syntax nicht verstehen: \nF√ºhren Sie die Syntax schrittweise aus. Zuerst `d_train` ausf√ºhren und das Ergebnis betrachten. \nDann `d_train %>% select(-Id)` ausf√ºhren, wieder die Ausgabe betrachten, usw.\n\nDie als Output von @lst-get-high-corrs aufgef√ºhrten Variablen sind\neinigerma√üen stark mit unserer Zielvariablen `SalePrice` korreliert.\nNutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n\n\n\n#### Modell 1\n\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im Gro√üen und Ganzen durch den Zustand der Immobilie (`OverallQual`) vorhergesagt werden kann.\nDiese Variable ist am st√§rksten mit der Zielvariable korreliert und ist daher ein guter Kandidat f√ºr die Vorhersage.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |      SE |                 95% CI | t(1458) |      p |\n|:-----------|:-----------:|:-------:|:----------------------:|:-------:|:------:|\n|(Intercept) |   -96206.08 | 5756.41 | (-1.07e+05, -84914.35) |  -16.71 | < .001 |\n|OverallQual |    45435.80 |  920.43 |   (43630.29, 47241.31) |   49.36 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWie gut ist das Modell?\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m1)  # aus easystats\n## [1] 48589\n```\n:::\n\n\n\n\n\n\n\nIm Schnitt liegen wir 4.54\\times 10^{4} Dollar daneben. \nOb das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\n\nR-Quadrat liefert einen anderen Blick auf die Modellg√ºte:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n```\n:::\n\n\n\n\n\n\n\n\n\n#### Model 2\n\n\n\nMann kann mehrere UV (Pr√§diktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in `lm()`:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmein_modell <- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n```\n:::\n\n\n\n\n\n\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur \"als UV nimm UV1 und UV2 und ...\". \n\n\nBerechnen wir als n√§chstes ein Modell mit mehreren UV, `m2`.\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2 <- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n```\n:::\n\n\n\n\n\n\n\n\n@tbl-m2-params zeigt die Koeffizienten von `m2`. \n\n\n\n\n\n\n\n::: {#tbl-m2-params .cell layout-align=\"center\" tbl-cap='Modellparameter von m1'}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |      SE |                 95% CI | t(1456) |      p |\n|:-----------|:-----------:|:-------:|:----------------------:|:-------:|:------:|\n|(Intercept) |   -98832.49 | 4842.90 | (-1.08e+05, -89332.69) |  -20.41 | < .001 |\n|OverallQual |    27104.83 | 1072.18 |   (25001.64, 29208.01) |   25.28 | < .001 |\n|GrLivArea   |       50.67 |    2.55 |         (45.67, 55.68) |   19.86 | < .001 |\n|GarageCars  |    21298.96 | 1807.06 |   (17754.23, 24843.69) |   11.79 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells `m2` f√ºr die Daten von `d_train`?\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m2)\n## [1] 40566\n```\n:::\n\n\n\n\n\n\n\n\nIm Schnitt liegen unsere Vorhersagen 2.71\\times 10^{4} Dollar daneben. Ist das gut?\n\nBetrachten wir noch $R^2$:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n```\n:::\n\n\n\n\n\n\n\nOb die Modellg√ºte (R-Quadrat, RMSE, etc.) \"gut\" bzw. \"hoch\" ist, beantwortet man am besten *relativ*, \nalso im Vergleich zu anderen Modellen. \n\n\n\n#### Nullmodell\n\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Pr√§diktoren.\nMan nennt es das \"Nullmodell\".\nIn diesem Modell sagen wir f√ºr jedes Haus einfach den mittleren Preis aller H√§user vorher.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm0 <- lm(SalePrice ~ 1, data = d_train)\n```\n:::\n\n\n\n\n\n\n\n\nWie gut ist die Vorhersage des Nullnomdells?\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m0)\n## [1] 79415\n```\n:::\n\n\n\n\n\n\n\n\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\n\n\n\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n```\n:::\n\n\n\n\n\n\n\n\n### Vorhersagen im Test-Datensatz mit `m2`\n\nWir haben jetzt unseren Champion, `m2`.\nAlle Hoffnung ruht auf diesem Modell.\nOb die Vorhersagen im Test-Sample pr√§zise sein werden?\nOder himmelweit daneben?\nEntt√§usche uns nicht!\n\n\nHier sind die Vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2_pred <- predict(m2, newdata = d_test)  # <1> \nhead(m2_pred) # <2>\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n```\n:::\n\n\n\n\n\n\n1. predicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus `d_test`\n2. zeige den \"Kopf\" der Vorhersagen (`m1_pred`), d.h. die ersten paar Vorhersagen\n\n\n\nDie Vohersagen f√ºgen wir jetzt dem Test-Sample hinzu:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_test <- \n  d_test %>% \n  mutate(SalePrice = m2_pred)\n```\n:::\n\n\n\n\n\n\n\n\n### Einreichen!\n\n\n#### Wir brauchen zwei Spalten: `Id` und `SalePrice`\n\n\nSo, wir haben unsere Vorhersagen!\nJetzt reichen wir diese Vorhersagen ein.\nF√ºr die Prognosedatei (submission file) brauchen wir nur die Spalten `id` und `SalePrice`:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2_subm <-\n  d_test %>% \n  select(Id, SalePrice)\n```\n:::\n\n\n\n\n\n\n\n\nKaggle m√∂chte keine fehlenden Werten in den Vorhersagen, also pr√ºfen wir das mal:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\" code-annotations='hover'}\n\n```{.r .cell-code}\nm2_subm %>% \n  drop_na() %>%  # <1>\n  nrow()         # <2>\n## [1] 1458\n```\n:::\n\n\n\n\n\n\n\n1. Lass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2. z√§hle die Anzahl der Zeilen (die noch verbleiben)\n\nDie Anzahl der Zeilen, die wir hier erhalten, ist gleich zu den Anzahl der Zeilen von `d_test`. Es gibt also keine fehlenden Werte.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnrow(d_test)\n## [1] 1459\n```\n:::\n\n\n\n\n\n\n\n\n<!-- #### Vertiefung: Fehlende Werte -->\n\n\n<!-- Angenommen wir h√§tten fehlende Werte bei `SalePrice`. -->\n\n<!-- Filtern wir die Spalte `SalePrice` mal nach \"ist NA\": -->\n\n<!-- ```{r} -->\n<!-- m1_subm %>% # <1) -->\n<!--   filter(is.na(SalePrice)) # <2> -->\n<!-- ``` -->\n\n<!-- √úbersetzen wir die Syntax auf Deutsch: -->\n\n\n<!-- 1. Nimm zuerst die Tabelle `m1_smb` -->\n\n<!-- 2. Filter dann so, dass du nur Zeilen hast, f√ºr die gilt, \"hier ist ein NA in der Spalte `SalePrice` -->\n\n<!-- Ah, da ist er, der fehlende Wert, in Zeile 2577! -->\n<!-- Hinfort! -->\n\n<!-- Wir ersetzen die fehlenden Werte in `SalePrice` mit dem Mittelwert von `SalePrice`: -->\n\n<!-- ```{r} -->\n<!-- m1_subm_nona <- # <1> -->\n<!--   m1_subm %>%  # <2> -->\n<!--   mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE))) # <3> -->\n<!-- ``` -->\n\n<!-- Die Syntax wieder auf Deutsch: -->\n\n<!-- 1. Definiere `m1_subm_nona` wie folgt -->\n<!-- 2. Nimm `m1_subm` und dann -->\n<!-- 3. Ver√§ndere die Spalte `SalePrice` und zwar so, dass NAs ersetzt werden durch den Mittelwert von `SalePrice` -->\n\n\n<!-- Und? Gib es jetzt noch fehlende Werte? -->\n\n<!-- ```{r} -->\n<!-- m1_subm_nona %>%  -->\n<!--   filter(is.na(SalePrice)) -->\n<!-- ``` -->\n\n<!-- Nein! Die Ergebnistabelle hat null Zeilen.  -->\n<!-- \"No NA\" - Keine NAs, keine fehlenden Werte mehr. -->\n\n#### Hochladen\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.\nEs bietet sich an `write_csv` zu verwenden, da `write.csv` automatisch (ungefragt) noch eine Id-Spalte  ohne Namen einf√ºgt (mit den Zeilennummern), das mag aber Kaggle nicht. \nKaggle erwartet exakt zwei Spalten und zwar mit den Namen `Id` und `SalePrice`.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwrite_csv(m2_subm, \"data/ames-kaggle/m1-subm.csv\")\n```\n:::\n\n\n\n\n\n\n\nUnd dann laden Sie diese Datei, `m1_subm.csv` bei Kaggle hoch und hoffen auf einen Hauptgewinn.\n\nDas Modell erzielte einen Score von *0.55521*.\n\n\n\n### Fazit\n\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt.\nSicherlich gibt es viele Ans√§tze, dieses Modell zu verbessern.\n\nHier sind einige Fragen, die Sie sich dazu stellen k√∂nnen:\n\n- Welche Pr√§diktoren sollte ich in das Modell aufnehmen?\n- Wie gehe ich mit fehlenden Werten um?\n- Wenn ein Pr√§diktor schief ist, sollte ich ihn dann log-transformieren?\n- Vielleicht sollte man manche Pr√§diktoren quadrieren?\n- Wie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n- ...\n\nViel Spielraum f√ºr Ihre Kreativit√§t!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- ## Fazit -->\n<!-- TODO  -->\n\n## Aufgaben\n\n\n\nDie Webseite [datenwerk.netlify.app](https://datenwerk.netlify.app) stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. \nSie k√∂nnen die Suchfunktion der Webseite nutzen, \num die Aufgaben mit den folgenden Namen zu suchen:\n\n\n- Aussagen-einfache-Regr\n- interpret-koeff-lm\n- korr-als-regr\n- Linearitaet1a\n- lm1\n- mtcars-regr01\n- nichtlineare-regr1\n- penguins-regr02\n- regression1\n- regression1b\n- Regression3\n- Regression4\n- Regression5\n- Regression6\n- ames-kaggle1    \n    \n\nSchauen Sie sich auch weitere Aufgaben des [Datenwerks](https://sebastiansauer.github.io/Datenwerk/) an, \nvor allem mit den Tags [regression](https://sebastiansauer.github.io/Datenwerk/#category=regression) und [lm](https://sebastiansauer.github.io/Datenwerk/#category=lm).\n\n*Nicht alle Aufgaben* aus dieser Sammlung passen zum Stoff dieses Kapitels; \nvielleicht k√∂nnen Sie einige Aufgaben nicht l√∂sen.\nIgnorieren Sie einfach diese Aufgaben.\n\n\n\n## Literaturhinweise\n\n@gelman_regression_2021 liefert eine deutlich umfassendere Einf√ºhrung \nin die Regressionsanalyse als dieses Kapitel es tut.\nEine moderne, R-orientierte Einf√ºhrung in Statistik inklusive der Regressionsanalyse findet sich bei @cetinkaya-rundel_introduction_2021.\nEin Klassiker mit viel Aha-Potenzial ist @cohen_applied_2003.\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}