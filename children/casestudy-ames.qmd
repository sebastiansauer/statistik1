<!-- ## Fallstudie Immobilienpreise -->

:::: {.content-visible when-format="html" unless-format="epub"}


:::{.callout-caution}
Diese Fallstudie stellt die Prüfungsleistung "Prognosewettbewerb" einführend dar. 
Es empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten. $\square$
:::

::::


### Hintergrund

In dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen.
Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei [kaggle.com](https://www.kaggle.com/) ein.
Kaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. 
In dieser Fallstudie nehmen Sie teil an der Kaggle-Competition ["House Prices - Advanced Regression Techniques"](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview), die Sie auf der Kaggle-Webseite finden.
Dort finden Sie auch eine nähere Beschreibung, das Ziel und die Spielregeln des Wettbewerbs.

::: {.content-visible when-format="html"}

- [Beschreibung](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description)
- [Ziel/Aufgabe](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation)
- [Spielregeln](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules)

:::




### Daten

Sie können die Daten von [www.kaggle.com herunterladen](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).
Im Einzelnen müssen Sie folgende Dateien herunterladen:

- *Data_description.txt*: Codebook, d.h. Beschreibung der Variablen im Datensatz
- *train.csv*: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen
- *test.csv*:  Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen
- *sample_submission.csv*: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen


Sie können auch über das Github-Repo `statistik1`, Ordner `data` auf die Daten zugreifen:


```{r import-ames-data}
d_train_path_online <- paste0(
    "https://raw.githubusercontent.com/sebastiansauer/statistik1/",
    "refs/heads/main/data/kaggle-train.csv")

d_test_path_online <- paste0(
"https://raw.githubusercontent.com/sebastiansauer/statistik1/",
    "refs/heads/main/data/kaggle-test.csv")

d_train <- read.csv(d_train_path_online)
d_test <- read.csv(d_test_path_online)
```



Laden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden 
Unterverzeichnis (Ihres Projektordners in RStudio) ab.



Importieren wir die Daten von der Festplatte, aus dem Unterordner `data` in R
(davon ausgehend, dass der Unterordner `data` ein Unterordner Ihres aktuellen R-Projekts ist):



```{r read-data-local}
#| message: false
#| eval: false
d_train_path <- "data/kaggle-train.csv"
d_test_path <- "data/kaggle-test.csv"
d_train <- read.csv(d_train_path)
d_test <- read.csv(d_test_path)
```








Wenn das Importieren von der Festplatte nicht klappt ... 
Es ist zwar hilfreich, wenn man Daten von der eigenen Festplatte importieren kann.
Aber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.






### Prognosedatei


Die Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthält.
Sie soll prinzipiell so aussehen wie in @tbl-subm dargestellt.

```{r}
#| tbl-cap: Beispiel für den Aufbau der Prognose-Datei
#| label: tbl-subm
#| echo: false
sample_subm_data <-
tribble( ~id, ~SalePrice,
        1461, 169277.1,
        1462, 187758.4,
        1463, 183583.7)

knitr::kable(sample_subm_data)
```


```{r read-data-ames}
#| echo: false
#sample_subm_path <- "data/ames-kaggle/sample_submission.csv"
#sample_subm <- readr::read_csv(sample_subm_path)
#head(sample_subm)
```

Die Prognosedatei besteht also aus zwei Spalten: der Spalte `id` und der Spalte `Saleprice`.
Die Spalte `id` gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist -- 
für welches Haus Sie also gerade einen Kaufpreis vorhersagen.
die Spalte `SalePrice` ist Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht.
Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, 
also die Tabelle, die die vorherzusagenden Werte angibt.
Alles klar? Los geht's!




### Ein erster Blick in die Daten

Schauen Sie sich zu Beginn einmal die Verteilung der metrischen Variablen,
z.B. mit `describe_distribution(d_train)` an.


::: {.content-visible when-format="html" unless-format="epub"}

```{r}
#| label: tbl-ames1
#| tbl-cap: Verteilung der metrischen Variablen im ames-Datensatz 
#| echo: false
describe_distribution(d_train) |> print_md()
```

:::

### Ein erstes Vorhersagemodell





Eine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, 
die Korrelation aller Prädiktoren mit der abhängigen Variablen^[die vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt] zu berechnen, s. 
<!-- @tbl-d_train_corr und -->
@lst-get-high-corrs.



```{r}
#| results: hide
#| lst-label: lst-get-high-corrs
#| lst-cap: "Welche Variablen korrelieren stärker als .3?"
d_train %>% 
  select(-Id) %>% 
  correlation() %>%  # berechne Korrelationen
  filter(Parameter2 == "SalePrice") %>%   # aber nur, wo die zweite Variable "SalesPrice" ist
  arrange(-abs(r)) %>%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r
  filter(abs(r) > .3)  # nur |r| > .3
```


```{r}
#| echo: false
#| results: hide
#| label: tbl-d_train_corr
#| tbl-cap: "Korrelation der Prädiktoren (UV) mit der AV"
d_train %>% 
  select(-Id) %>% 
  correlation() %>%  # berechne Korrelationen
  filter(Parameter2 == "SalePrice") %>%   # aber nur, wo die zweite Variable "SalesPrice" ist
  arrange(-abs(r)) %>%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r
  filter(abs(r) > .3)  %>%  # nur |r| > .3
  print_md()
```

Aha! Ein Menge Information ... Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: 
Im Zweifel einfach ignorieren. 
Wenn Sie die R-Syntax nicht verstehen: 
Führen Sie die Syntax schrittweise aus. Zuerst `d_train` ausführen und das Ergebnis betrachten. 
Dann `d_train %>% select(-Id)` ausführen, wieder die Ausgabe betrachten, usw.
Die als Output von @lst-get-high-corrs aufgeführten Variablen sind
einigermaßen stark mit unserer Zielvariablen `SalePrice` korreliert.
Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.






Im ersten Modell gehen wir davon aus, dass der Verkaufspreis im Großen und Ganzen durch den Zustand der Immobilie (`OverallQual`) vorhergesagt werden kann.
Diese Variable ist am stärksten mit der Zielvariable korreliert und ist daher ein guter Kandidat für die Vorhersage.


```{r}
#| eval: false
m1 <- lm(SalePrice ~ OverallQual, data = d_train)
parameters(m1)  # aus easystats
```





```{r lm1-ames}
#| echo: false
m1 <- lm(SalePrice ~ OverallQual, data = d_train)
parameters(m1)  |> print_md() # aus easystats
```




Wie gut ist das Modell?

```{r}
rmse(m1)  # aus easystats
```

Im Schnitt liegen wir `r round(coef(m1)[2], 0)` Dollar daneben. 
Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.

R-Quadrat liefert einen anderen Blick auf die Modellgüte:


```{r}
r2(m1)  # aus easystats
```





Mann kann mehrere UV (Prädiktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in `lm()`:

```{r}
#| eval: false
mein_modell <- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)
```

Dabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur "als UV nimm UV1 und UV2 und ...". 
Berechnen wir als nächstes ein Modell mit mehreren UV, `m2`.

```{r}
#| results: hide
m2 <- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)
parameters(m2)
```


@tbl-m2-params zeigt die Koeffizienten von `m2`. 

```{r}
#| echo: false
#| label: tbl-m2-params
#| tbl-cap: "Modellparameter von m1"
parameters(m2) %>% print_md()
```




Wie gut sind die Vorhersagen des Modells `m2` für die Daten von `d_train`?


```{r}
rmse(m2)
```


Im Schnitt liegen unsere Vorhersagen `r round(coef(m2)[2], 0)` Dollar daneben. Ist das gut?
Betrachten wir noch $R^2$:

```{r}
r2(m2)
```

Ob die Modellgüte (R-Quadrat, RMSE, etc.) "gut" bzw. "hoch" ist, beantwortet man am besten *relativ*, 
also im Vergleich zu anderen Modellen. 




Zum Vergleich berechnen wir das maximal einfache Modell: ohne Prädiktoren.
Man nennt es das "Nullmodell".
In diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.



```{r}
m0 <- lm(SalePrice ~ 1, data = d_train)
```


Wie gut ist die Vorhersage des Nullnomdells?

```{r}
rmse(m0)
```



Beim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.



Das R-Quadrat der Nullmodells ist per Definition Null:


```{r}
r2(m0)
```


### Vorhersagen im Test-Datensatz mit `m2`

Wir haben jetzt unseren Champion, `m2`.
Alle Hoffnung ruht auf diesem Modell.
Ob die Vorhersagen im Test-Sample präzise sein werden?
Oder himmelweit daneben?
Enttäusche uns nicht!


Hier sind die Vorhersagen:


```{r}
m2_pred <- predict(m2, newdata = d_test)  # <1> 
head(m2_pred) # <2>
```
1. Erstelle eine Vorhersage anhand der Regressionsgerade von `m1` und zwar anhand der Daten aus `d_test`.
2. Zeige den "Kopf" der Vorhersagen (`m1_pred`), d.h. die ersten paar Vorhersagen.



Die Vohersagen fügen wir jetzt dem Test-Sample hinzu:

```{r}
d_test <- 
  d_test %>% 
  mutate(SalePrice = m2_pred)
```


### Einreichen!





So, wir haben unsere Vorhersagen!
Jetzt reichen wir diese Vorhersagen ein.
Für die Prognosedatei (submission file) brauchen wir nur die Spalten `id` und `SalePrice`:


```{r}
m2_subm <-
  d_test %>% 
  select(Id, SalePrice)
```


Kaggle möchte keine fehlenden Werten in den Vorhersagen, also prüfen wir das mal:

```{r}
#| eval: true
#| code-annotations: hover
m2_subm %>% 
  drop_na() %>%  # <1>
  nrow()         # <2>
```

1. Lass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus

2. zähle die Anzahl der Zeilen (die noch verbleiben)

Die Anzahl der Zeilen, die wir hier erhalten, ist gleich zu den Anzahl der Zeilen von `d_test`. Es gibt also keine fehlenden Werte.


```{r}
nrow(d_test)
```


<!-- #### Vertiefung: Fehlende Werte -->


<!-- Angenommen wir hätten fehlende Werte bei `SalePrice`. -->

<!-- Filtern wir die Spalte `SalePrice` mal nach "ist NA": -->

<!-- ```{r} -->
<!-- m1_subm %>% # <1) -->
<!--   filter(is.na(SalePrice)) # <2> -->
<!-- ``` -->

<!-- Übersetzen wir die Syntax auf Deutsch: -->


<!-- 1. Nimm zuerst die Tabelle `m1_smb` -->

<!-- 2. Filter dann so, dass du nur Zeilen hast, für die gilt, "hier ist ein NA in der Spalte `SalePrice` -->

<!-- Ah, da ist er, der fehlende Wert, in Zeile 2577! -->
<!-- Hinfort! -->

<!-- Wir ersetzen die fehlenden Werte in `SalePrice` mit dem Mittelwert von `SalePrice`: -->

<!-- ```{r} -->
<!-- m1_subm_nona <- # <1> -->
<!--   m1_subm %>%  # <2> -->
<!--   mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE))) # <3> -->
<!-- ``` -->

<!-- Die Syntax wieder auf Deutsch: -->

<!-- 1. Definiere `m1_subm_nona` wie folgt -->
<!-- 2. Nimm `m1_subm` und dann -->
<!-- 3. Verändere die Spalte `SalePrice` und zwar so, dass NAs ersetzt werden durch den Mittelwert von `SalePrice` -->


<!-- Und? Gib es jetzt noch fehlende Werte? -->

<!-- ```{r} -->
<!-- m1_subm_nona %>%  -->
<!--   filter(is.na(SalePrice)) -->
<!-- ``` -->

<!-- Nein! Die Ergebnistabelle hat null Zeilen.  -->
<!-- "No NA" - Keine NAs, keine fehlenden Werte mehr. -->



Diesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.
Es bietet sich an `write_csv` zu verwenden, da `write.csv` automatisch (ungefragt) noch eine Id-Spalte  ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. 
Kaggle erwartet exakt zwei Spalten und zwar mit den Namen `Id` und `SalePrice`.


```{r}
#| eval: false
write_csv(m2_subm, "data/ames-kaggle/m1-subm.csv")
```

Und dann laden Sie diese Datei, `m1_subm.csv` bei Kaggle hoch und hoffen auf einen Hauptgewinn.
Das Modell erzielte einen Score von *0.55521*.



### Fazit

Diese Fallstudie hat ein einfaches Prognosemodell vorgestellt.
Sicherlich gibt es viele Ansätze, dieses Modell zu verbessern.
Hier sind einige Fragen, die Sie sich dazu stellen können:

- Welche Prädiktoren sollte ich in das Modell aufnehmen?
- Wie gehe ich mit fehlenden Werten um?
- Wenn ein Prädiktor schief ist, sollte ich ihn dann log-transformieren?
- Vielleicht sollte man manche Prädiktoren quadrieren?
- Wie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?
- ...

Viel Spielraum für Ihre Kreativität!









