# Modellg√ºte


## Lernsteuerung


### Standort im Lernpfad

@fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.




### Lernziele


- Sie kennen g√§ngige Ma√üe der Streuung einer Stichprobe und k√∂nnen diese definieren und mit Beispielen erl√§utern.
- Sie k√∂nnen g√§ngige Ma√üe der Streuung einer Stichprobe mit R berechnen.
- Sie k√∂nnen die Bedeutung von Streuung f√ºr die G√ºte eines Modells erl√§utern.

### Ben√∂tigte R-Pakete

In diesem Kapitel ben√∂tigen Sie folgende R-Pakete.

```{r}
library(tidyverse)
library(easystats)
library(DataExplorer)
```

```{r libs-hideen}
#| echo: false
library(patchwork)
library(ggpubr)
```


```{r}
#| echo: false
source("_common.R")
```




### Ben√∂tigte Daten

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```





```{r}
#| echo: false
ggplot2::theme_set(theme_minimal())
```



### Zum Einstieg

:::{#exr-streuung-erkennen}
### Freiwillige vor! 
F√ºr diese kleine Live-Demonstration brauchen wir einige Freiwillige. 
Die Lehrkraft teilt die Freiwilligen in zwei Gruppen, Gruppe *Gleich-Gro√ü* und Gruppe *Verschieden-Gro√ü*. 
Erkennen Sie, dass die *Unterschiedlichkeit* der Gr√∂√üe in Gruppe *Gleich-Gro√ü* gering ist, aber in Gruppe *Verschieden-Gro√ü* hoch? $\square$
:::


## Warum Sie die Streuung Ihrer Daten kennen sollten




### Die Schlankheitspille von Prof. Weiss-Ois  {#sec-weiss-ois}

Prof. Weiss-Ois hat eine Erfindung gemacht, eine Schlankheitspille üíä  ...

:::: {.columns}
::: {.column width="45%"}

#### Was er sagt

!["Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!"](img/teacher.png){width="25%"}

:::


::: {.column width="10%"}
<!-- empty column to create gap -->
:::


::: {.column width="45%"}
#### Was er NICHT sagt
!["Allerdings streuten die Werte der Gewichtsver√§nderung um 10kg um den Mittelwert herum."](img/teacher.png){width="25%"}

:::

::::


[Icon unter Flaticon licence, Autor: iconixar](https://www.flaticon.com/free-icons/professor)


:::{exr-weisoiss2}
W√ºrden Sie die Pille von Prof. I. Ch. Weiss-Ois nehmen?^[Ich auf keinen Fall.]

a) ja
b) nein
c) Nur wenn ich 100 Euro bekomme
d) Okay, f√ºr 1000 Euro$\square$
:::


:::{.callout-important}
Wie sehr die Werte eines Modells streuen, ist eine wichtige Information.$\square$
:::


### Wie man seine Kuh √ºber den Fluss bringt

Treffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack.
Fritz will mit seiner Kuh einen Fluss √ºberqueren, nur kann die Kuh nicht schwimmen^[ob es Fritz kann, ist nicht √ºberliefert.]. 


>    üßë‚Äçüåæ (Fritz): Sag mal, Karla, ist der Fluss tief?

>    üë©‚Äçüåæ (Karla): N√∂, im Schnitt nur einen Meter.


Also f√ºhrt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, im Flo√ü ersoffen, s. @fig-fluss-tief.

![Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.](img/fluss-tief.png){#fig-fluss-tief}


>    üë©‚Äçüåæ (Karla): √úbrigens, Lagema√üe sagen nicht alles, Fritz.

>    üßë‚Äçüåæ (Fritz): L√§uft die Kuh durch den Fluss, kann sie schwimmen oder 's ist Schluss.


:::{.callout-important}
Die Streuung ihrer Daten zu kennen ist eine wesentliche Information. $\square$
:::




## Woran erkennt man ein gutes Modell?








@fig-streuung zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts).
Links ist die Streuung der Schlankheitspille *Dicktableitin* und rechts von der Schlankheitspille *Pfundafliptan* abgetragen.

```{r viel-wenig-streuung}
#| echo: false
#| label: fig-streuung
#| fig-cap: "Ein Modell mit wenig Streuung (links) vs. ein Modell mit viel Streuung (rechts). Die vertikalen grauen Balken kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale orange Linie). Je l√§nger die 'Abstandsbalken', desto gr√∂√üer die Streuung."
set.seed(42)
d <-
  tibble(
    id = 1:100,
    x1 = rnorm(100, 0, 1),
    x2 = rnorm(100, 0, 7)
  ) %>% 
  pivot_longer(-id) %>% 
  group_by(name) %>% 
  mutate(avg = mean(value),
         e = value - avg) %>% 
  ungroup()

d_sum <-
  d %>% 
  group_by(name) %>% 
  summarise(avg = mean(value))

group_names <-
  c(x1 = "wenig Streuung:\nDiktableibtin",
    x2 = "viel Streuung:\nPfundafliptan")

d %>% 
  ggplot(aes(x = id, y = value)) +
  geom_point() +
  facet_wrap(~ name, labeller = as_labeller(group_names)) +
  geom_hline(color = okabeito_colors()[1], yintercept = 0) +
  geom_segment(aes(x = id, xend = id, y = value, yend = avg), 
               alpha = .5, color = "grey") +
  theme_minimal() +
  geom_label(x = 0, y = 0, label = "MW", color = okabeito_colors()[1]) +
  scale_x_continuous(limits = c(-10,100))
```


Bei einem Modell mit *wenig* Streuung liegen die tats√§chlichen, beobachtete Werte ($y$) nah an den Modellwerten (vorhergesagten Werten, $\hat{y}$); 
die Abweichungen $e = y - \hat{y}$ sind also gering (der Modellfehler ist klein).
Bei einem Modell mit *viel* Streuung ist der Modellfehler $e$ (im Vergleich dazu) gro√ü.




<!-- >   üßë‚Äçüéì  Immer diese Trivialit√§ten! -->

<!-- >   üë©‚Äçüè´ Wird gleich interessanter. -->

:::{#exm-weiss-ois}
### Daten zur Schlankheitskur von Prof. Weiss-Ois
In @fig-streuung sind die Daten zu der Gewichtsver√§nderung nach Einnahme von "Schlankheitspillen" zweier verschiedener Pr√§parate. 
Wie man sieht unterscheidet sich die typische (vorhergesagte) Gewichtsver√§nderung zwischen den beiden Pr√§paraten kaum. Die Streuung allerdings schon.
Links sieht man die Gewichtsver√§nderungen nach Einnahme des Pr√§parats "Dickableibtin extra mild" (c) und rechts das Pr√§parat von Prof. Weiss-Ois "Pfundafliptan Forte".
Welches Pr√§parat w√ºrden Sie lieber einnehmen?$\square$
:::




:::{.callout-important}
Wir wollen ein pr√§zises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erkl√§ren, also wenig vom tats√§chlichen Wert abweichen.
Jedes Modell sollte Informationen √ºber die Pr√§zision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellg√ºte, d.h. der Pr√§zision der Sch√§tzung des Modellwerts, ist wenig n√ºtze.$\square$
:::






>   üë©‚Äçüéì Ich frage mich, ob man so ein Modell nicht verbessern kann?

>   üë©‚Äçüè´ Die Frage ist, was wir mit "verbessern" meinen?

>    üë©‚Äçüéì Naja, k√ºrzere Fehlerbalken, ist doch klar!

Da die Anzahl der Lenkr√§der mit dem Verkaufsgebot zusammenh√§ngt, k√∂nnte es vielleicht sein, dass wir die Lenkr√§der-Anzahl da irgendwie nutzen k√∂nnten.
Das sollten wir ausprobieren.


@fig-fehler-red zeigt, dass die Fehlerbalken *k√ºrzer* werden, wenn wir ein (sinnvolles) komplexeres Modell finden.
Innerhalb jeder der beiden Gruppen (mit 2 Lenkr√§dern vs. mit 0 Lenkr√§dern) 
sind die Fehlerbalken jeweils im Durchschnitt k√ºrzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm).^[Aus Gr√ºnden der √úbersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros ber√ºcksichtigt und nur Spiele mit 0 oder mit 2 Lenkr√§dern.]




```{r fehlerbalken}
#| echo: false
#| label: fig-fehler-red
#| fig-cap: Fehlerbalken in einem einfachen und komplexeren Modell
#| layout-ncol: 2
#| fig-subcap:
#|   - "Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt"
#|   - "Fehlerbalken im komplexen Modell: Zwei Mittelwerte; weniger Streuung in jeder Gruppe. Das erkennt man daran, dass die vertikalen, grauen Abstandsbalken im Schnitt k√ºrzer sind als im einfachen Modell (links)"
data(mariokart, package = "openintro")
m <-
  mariokart %>%
  filter(total_pr < 100) %>% 
  filter(wheels %in% c(0, 2)) %>% 
  mutate(ID = 1:nrow(.),
         total_pr_resid = total_pr - mean(total_pr),
         total_pr_resid_quad = total_pr_resid^2) %>% 
  group_by(wheels) %>% 
  mutate(total_pr_mean_group = mean(total_pr)) %>% 
  ungroup()


m_sum <- 
  m %>% 
  group_by(wheels) %>% 
  summarise(total_pr = mean(total_pr)) %>% 
  ungroup()


m %>% 
  ggplot() +
  geom_hline(aes(yintercept = mean(total_pr))) +
  geom_segment(aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
                   ), color = "grey") +
  geom_point(aes(x = ID, y = total_pr)) +
  annotate("label", x = 0, y = 47, label = "MW", hjust = "left", size = 6)



m %>% 
  ggplot() +
  geom_segment(data = filter(m, wheels == 0),
               aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
               ), color = "grey") +
   geom_hline(data = m_sum,
     aes(yintercept = total_pr,
                 color = factor(wheels))) +
   geom_segment(data = filter(m, wheels == 2),
               aes(x = ID,
                   xend = ID,
                   y = total_pr,
                   yend = mean(total_pr)
               ), color = "grey") +
  geom_point(
    aes(x = ID, y = total_pr, color = factor(wheels))) +
  labs(color = "wheels") +
  theme(legend.position = "none") +
  geom_label(data = m_sum,
    aes(label = paste0("MW bei ", wheels, " R√§der"), y = total_pr, color = factor(wheels)), x = 3, size = 6) +
  scale_color_okabeito() +
  scale_x_continuous(limits = c(-10, 90))
```


:::{.callout-important}
Durch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.$\square$
:::


## Streuungsma√üe {#sec-streuung}

:::{#def-streuungsma√üe}
### Streuungsma√üe
Ein Streuungsma√ü quantifiziert die Variabilit√§t eines Merkmals. $\square$
:::

Ein einfaches Streuungsma√ü ist der *Range*, definiert als Abstand von gr√∂√ütem und kleinsten Wert eines Merkmals.
Dieses Mermals ist aber nicht robust (gegen√ºber Extremwerten) und sollte daher nur mit Einschr√§nkung verwendet werden.


### Der mittlere Abweichungsbalken

>   üßë‚Äçüéì Wir m√ºssen jetzt mal pr√§ziser werden! Wie k√∂nnen wir die Streuung berechnen?

>   üë®‚Äçüè´ Gute Frage! Am einfachsten ist es, wenn wir die mittlere L√§nge eines Abweichungsbalkens ausrechnen. 



Legen wir (gedanklich) alle Abweichungsbalken $e$ aneinander und teilen durch die Anzahl $n$ der Balken,
so erhalten wir wir den "mittleren Abweichungsbalken",
den wir mit $\varnothing e$ bezeichnen k√∂nnten.
Diesen Kennwert bezeichnet man als *Mean Absolute Error* (MAE) 
bzw. als *Mittlere Absolutabweichung* (MAA).
Er ist so definiert, s. @eq-mae.


$${\displaystyle \mathrm {MAE} ={\frac {\sum _{i=1}^{n}\left|y_{i}-\bar{y}\right|}{n}}={\frac {\sum _{i=1}^{n}\left|e_{i}\right|}{n}}.}$$ {#eq-mae}

:::{#def-mae}
### Mittlere Absolutabweichung
Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte.^[Wenn man solche S√§tze liest, f√ºhlt sich die Formel fast einfacher an.]$\square$
:::

:::{#exm-mae}
@fig-mae visualisiert ein einfaches Beispiel zum MAE.
Rechnen wir den MAE f√ºr das Beispiel von @fig-mae aus:

$MAE = \frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5$
:::

```{r mae-balken}
#| echo: false
#| label: fig-mae
#| fig-cap: "Abweichungsbalken und der MAE"
#| fig-asp: .5
d <-
  tibble(id = 1:4,
         y = c(1, -3, 1, 1))


ggplot(d) +
  aes(x = id, y = y) +
  geom_point(size = 5, alpha = .7, color = "red") +
  geom_segment(aes(x = id, xend = id, y = y, yend = mean(y))) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  annotate("label", x = 0.5, y = 0, label = "Mittelwert") +
  theme_minimal() +
  scale_x_continuous(limits = c(0, 4))
```

Nat√ºrlich k√∂nnen wir R auch die Rechenarbeit √ºberlassen.


>   ü§ñ Loving it!!


Schauen Sie: Den Mittelwert (s. @fig-mae) kann man doch mit Fug und Recht als ein *lineares Modell*, eine Gerade, betrachten, oder nicht?
Schlie√ülich erkl√§ren wir $y$ anhand einer Gerade (die parallel zur X-Achse ist).

In R gibt es einen Befehl f√ºr ein *l*ineares *M*odell, 
er hei√üt `lm`.

Die Syntax von `lm()` lautet:

`lm(y ~ 1, data = meine_daten)`.

In Worten: 

>   Hey R, berechne mit ein lineares Modell zur Erkl√§rung von Y. Aber verwende keine andere Variable zur Erkl√§rung von Y, sondern nimm den Mittelwert von Y.

```{r}
lm1 <- lm(y ~ 1, data = d)
```


Den MAE k√∂nnen wir uns jetzt so ausgeben lassen:

```{r}
mae(lm1)
```




### Der Interquartilsabstand


Der Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein Streuungsma√ü, das nicht auf dem Mittelwert aufbaut.
Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.

:::{#def-iqr}
### Interquartilsabstand
Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil.$\square$
:::


:::{#exm-iqr}
### IQR im H√∂rsaal
In einem Statistikkurs betragen die Quartile der K√∂rpergr√∂√üe: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR betr√§gt dann: $IQR = Q3-Q1 = 1.75m - 1.65m = 0.10m$, d.h. 10 cm.$\square$
:::


@fig-iqr-mario stellt den IQR (und einige Quantile) f√ºr den Verkaufspreise von Mariokart-Spielen dar.

::: {#fig-iqr-mario}

:::{.panel-tabset}

### Histogramm

```{r}
#| echo: false
#| label: fig-mario-qs-iqr1
#| fig-cap: IQR, Q1, Q2 und Q3 f√ºr das Schlussgebot (nur Spiele f√ºr weniger als 100 Euro)
mario_quantile2 <- 
mariokart %>% 
  filter(total_pr < 100) %>% 
  summarise(q25 = quantile(total_pr, .25),
            q50 = quantile(total_pr, .50),
            q75 = quantile(total_pr, .75))

mario_quantile <- 
  mariokart %>% 
  filter(total_pr < 100) %>% 
  reframe(qs = quantile(total_pr, c(.25, .5, .75)))

mariokart %>% 
  filter(total_pr < 100) %>%  
  ggplot(aes(x = total_pr)) +
  geom_histogram() +
  geom_vline(xintercept = mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = 0, label =  mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = Inf, label =  c("Q1", "Median", "Q3"), vjust = 2) +
  labs(y = "Anzahl") +
  geom_segment( 
           aes(x = q25, xend = q75), 
           y = 5, yend = 5, color = "#56B4E9",
           data = mario_quantile2, size = 3) +
  annotate("label", x = mario_quantile2$q50, y = 5,
           label = "IQR", color = "#56B4E9")
```


### Dichtediagramm

```{r}
#| echo: false
#| label: fig-mario-iqr2
#| fig-cap: IQR, Q1, Q2 und Q3 f√ºr das Schlussgebot (nur Spiele f√ºr weniger als 100 Euro)

mariokart %>% 
  filter(total_pr < 100) %>%  
  ggplot(aes(x = total_pr)) +
  geom_density() +
  geom_vline(xintercept = mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = 0, label =  mario_quantile$qs) +
  annotate("label", x =  mario_quantile$qs, y = Inf, label =  c("Q1", "Median", "Q3"), vjust = 2) +
  labs(y = "Anzahl") +
  geom_segment( 
           aes(x = q25, xend = q75), 
           y = 0.01, yend = 0.01, color = "#56B4E9",
           data = mario_quantile2, size = 3) +
  annotate("label", x = mario_quantile2$q50, y = .01,
           label = "IQR", color = "#56B4E9")
```

:::

Der IQR f√ºr den Verkaufspreis von Mariokart-Spielen.

:::



### Streuungsma√üe f√ºr Normalverteilungen

Normalverteilungen sind recht h√§ufig anzutreffen in der Praxis der Datenanalyse.
Daher lohnt es sich, zu √ºberlegen,
wie man diese Verteilungen gut zusammenfasst.
Man kann zeigen, dass eine Normalverteilung sich komplett √ºber ihren *Mittelwert* sowie ihre *Standardabweichung* beschreiben l√§sst.
Au√üerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt.
Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), "verschiebt man den Berg" ja nur zur Seite, ohne seine Form zu ver√§ndern, s. @fig-norm-dev.


:::callout-note
Hat man normalverteilte Variablen/Abweichungen/Residuen, so ist die *Standardabweichung* (engl. standard deviation, SD, $\sigma$, $s$) eine komfortable Ma√üeinheit der Streuung,
denn damit l√§sst sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.$\square$
:::


>   üßë‚Äçüéì Aber wie berechnet man jetzt diese Standardabweichung?

>    üë®‚Äçüè´ Moment, noch ein kurzer Exkurs zur Varianz ...

>    üßë‚Äçüéì (seufzt)


### Varianz


#### Intuition

:::{.callout-note}
Die Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.$\square$
:::



:::: {.columns}

::: {.column}

@fig-var illustriert die Varianz:

1. Man gehe von der H√§ufigkeitsverteilung der Daten aus.
2. Betrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.
3. Man bilde Quadrate f√ºr jeden Datenpunkt mit der Kantenl√§nge, die dem Abstand des Punktes zum Mittelwert entspricht.
4. Die Quadrate quetscht man jetzt wo n√∂tig in rechteckige Formen (ohne dass sich die Fl√§che √§ndern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit Seitenl√§nge $n$ und $\sigma^2$ anordnen.

:::

:::: {.column}


![Illustration zur Varianz als "mittlerer Quadratfehler"](img/Variance_visualisation.svg.png){#fig-var}

[By Cmglee - Own work, CC BY-SA 3.0](https://commons.wikimedia.org/w/index.php?curid=39472834)

:::

::::






@fig-mse visualisiert die Varianz f√ºr @exm-mae.^[Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine...]

Links sind die *Abweichungsquadrate* dargestellt, rechts die Varianz als "*typisches Abweichungsquadrat*".

:::{.callout-note}
Die Varianz ist also ein Ma√ü, das die typische Abweichung der Beobachtungen  vom Mittelwert in eine Zahl fasst.$\square$
:::


```{r delta-plot, echo = FALSE}
#| echo: false
#| label: fig-mse
#| fig-cap: "Sinnbild zur Varianz als typischer Fehlerbalken"
#| fig-subcap: 
#|   - Quadrierte Fehlerbalken
#|   - "Varianz als 'typischer' Fehlerbalken"
#| warning: false
#| layout-ncol: 2

library(viridis)

d <-
  tibble(id = 1:4,
         y = c(0.1, -.3, .1, .1)) %>% 
  mutate(y_avg = mean(y),
         delta = y - y_avg,
         delta_abs = abs(delta),
         pos = ifelse(delta > 0, "positiv", "negativ"),
         delta_sq = delta^2)

var_smpl <- mean(d$delta_sq)

p_deltas <- 
d %>%   
  ggplot(aes(x = id, y = y)) +
  geom_hline(yintercept = mean(d$y), linetype = "dashed", show.legend = FALSE) +
  geom_segment(aes(y = mean(d$y),
                   yend = y,
                   x = id,
                   xend = id,
                   linetype = pos), show.legend = FALSE) +
  annotate(geom = "label",
           x = 0,
           hjust = 0,
           y = mean(d$y), 
           label = paste0("MW = ", round(mean(d$y), 2)), show.legend = FALSE) +
  geom_rect(aes(ymin = y_avg,
                ymax = y,
                xmin = id,
                xmax = id+delta_abs),
            fill = "#E69F00FF" ,
            alpha = .5, show.legend = FALSE) +
  geom_text(aes(label=round(delta_sq,3)),
            hjust = "left", 
            nudge_x = 0.05,
            vjust = ifelse(d$pos == "positiv", "top", "bottom"),
            nudge_y = ifelse(d$pos == "positiv", -0.05, 0.05),
            color = "#E69F00FF",
            size = 6, show.legend = FALSE) +
  geom_point(size = 5, show.legend = FALSE) +
  labs(linetype = "",
       x = "",
       y = "")  +
  scale_y_continuous(limits = c(-.3, .1)) +
  scale_x_continuous(limits = c(0, 5)) +
  theme_minimal()

p_var <- 
  d %>%   
    ggplot(aes(x = id, y = y)) + 
    geom_hline(yintercept = mean(d$y), linetype = "dashed") +
     annotate(geom = "label",
             x = 0,
             hjust = 0,
             y = mean(d$y), 
             label = paste0("MW = ", round(mean(d$y), 2))) +
    annotate("rect", 
             xmin =  5, ymin = 0, xmax = 5.2, ymax = var_smpl, 
             fill = "#56B4E9FF") +
    scale_y_continuous(limits = c(-.3, .1)) +
    scale_x_continuous(limits = c(0, 6)) +
    annotate(geom = "label",
                  x = 5,
                  hjust = 0.5,
                  y = -0.01,
                  label = "Varianz") +
  theme_minimal() +
  annotate("label", x = 1, y = -0.1,
           hjust = 0,
           label = paste0(var_smpl, " = (0.01 + 0.01 + 0.01 + 0.09)/4"))

p_deltas
p_var
```





Bildquelle: FOM-ifes


:::{#exm-var}
Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen.
Nat√ºrlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.

Zun√§chst betrachten Sie die Streuung in den Verkaufspreisen:

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")

m <-
  mariokart %>%
  filter(total_pr < 100)  # ohne Extremwerte

m_summ <- 
  m %>% 
  summarise(
    pr_mw = mean(total_pr),
    pr_iqr = IQR(total_pr),
    pr_maa = mean(abs(total_pr - mean(total_pr))),
    pr_var = var(total_pr),
    pr_sd = sd(total_pr))
```


```{r}
#| echo: false
m_summ %>% print_md()
```



Statistiken sind ja sch√∂n ... aber Bilder sind auch gut, s. @fig-var. $\square$


```{r}
#| eval: false
mariokart %>% 
  mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  plot_density()
```



```{r}
#| echo: false
#| fig-cap: Die Verteilung des Verkaufspreises von Mariokart-Spielen 
#| label: fig-var
#| layout-ncol: 2
#| fig-subcap: 
#|   - Dichtediagramm mit MW¬±SD in roter Farbe
#|   - Violindiagramm mit MW¬±SD in roter Farbe
mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  ggplot() +
  geom_density(aes(x = total_pr)) +
  geom_rect(data = m_summ, 
               aes(
                 xmin = pr_mw - 0.5*(pr_sd),
                 xmax = pr_mw + 0.5*(pr_sd),
                 ymin = 0,
                 ymax = Inf
               ),
            alpha = .5,
            fill = "red")

mariokart %>% 
  select(total_pr) %>% 
  filter(total_pr < 100) %>%  # ohne Extremwerte
  ggplot() +
  geom_violin(aes(
    x = 1,
    y = total_pr)) +
  geom_jitter(aes(
    x = 1,
    y = total_pr),
    width = 0.1) +
  scale_x_continuous(limits = c(0, 2)) +
  geom_rect(data = m_summ, 
               aes(
                 ymin = pr_mw - 0.5*(pr_sd),
                 ymax = pr_mw + 0.5*(pr_sd),
                 xmin = -Inf,
                 xmax = Inf
               ),
            alpha = .5,
            fill = "red")
```


:::


Wer sich die Berechnung von Hand f√ºr `pr_maa` sparen m√∂chte, kann die [Funktion `MeanAD` aus dem Paket `DescTools`](https://rdrr.io/cran/DescTools/man/MeanAD.html) nutzen.


#### Kochrezept f√ºr die Varianz


Um die Standardabweichung zu berechnen, berechnet man zun√§chst die *Varianz*, $s^2$ abgek√ºrzt. Hier ist ein "Kochrezept"^[Algorithmus] zur Berechnung der Varianz:

1. F√ºr alle Datenpunkte $x_i$: Berechne die Abweichungen vom Mittelwert, $\bar{x}$
2. Quadriere diese Werte
3. Summiere dann auf
4. Teile durch die Anzahl $N$ der Werte


Als Formel ausgedr√ºckt, lautet die Definition der Varianz^[sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugeh√∂rigen Population zu sch√§tzen, teilt man nicht durch $N$, sondern durch $N-1$] einer Stichprobe wie folgt, s. @eq-var.


$${\displaystyle s^{2}={\frac {1}{N}}\sum _{i=1}^{n}\left(y_{i}-{\bar {y}}\right)^{2}={\frac {1}{N}}\sum _{i=1}^{n}dy_i^{2}.}$$ {#eq-var}


:::{#def-var}
### Varianz
Die Varianz ($s^2, \sigma^2$) ist definiert als der Mittelwert der quadrierten Abweichungen, $dy_i^2$, (vom Mittelwert).$\square$
:::


Die Varianz steht im engen Verh√§ltnis zur Kovarianz, s. @sec-cov.
Die Varianz kann auch verstehen als den *mittleren Quadratfehler* (Mean Squared Error, MSE) eines Modells, s. @eq-mse.



$${\displaystyle MSE={\frac {1}{N}}\sum _{i=1}^{N}\left(x_{i}-{\hat {y}}\right)^{2}.}$$ {#eq-mse}

Im Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.



### Die Standardabweichung

Kennt man die Varianz, so l√§sst sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.


:::{#def-sd}
### Standardabweichung
Die Standardabweichung (SD, s, $\sigma$) ist definiert als die Quadratwurzel der Varianz, s. @eq-sd.


$$s := \sqrt{s^2}$$ {#eq-sd}

$\square$
:::


Durch das Wurzelziehen besitzt die Standardabweichung wieder *in etwa* die gleiche Gr√∂√üenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr gro√ü werden kann).


Aus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE.
Dann nennt man sie *Root Mean Squared Error* (RMSE): $rmse := \sqrt{mse}$.


:::{.callout-note}
Die SD ist i.d.R. *un*gleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.$\square$
:::


:::{#exm-sd-mario}

Sie arbeiten weiter an Ihrem Mariokart-Projekt.
Da Sie heute keine Lust auf viel Tippen haben,
nutzen Sie das R-Paket `easystats` mit der Funktion `describe_distribution`.

```{r}
library(easystats)

mariokart %>% 
  select(total_pr) %>% 
  describe_distribution()
```

Ah! Das war einfach. Wird auch langsam Zeit f√ºr Feierabend.$\square$
:::



:::{#exm-gruppen-mw}

Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. 
Bevor Sie nach Hause gehen, m√∂chten Sie noch eine Sache anschauen.
In einer fr√ºheren Analyse (s. @fig-fehler-red) fanden Sie heraus,
dass die Fehlerbalken k√ºrzer werden, wenn man ein geschickteres und komplexeres Modell findet. 
Das wollen Sie nat√ºrlich pr√ºfen.
Sie √ºberlegen: "Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll."

Das spezifizieren Sie so:

```{r}
lm1 <- lm(total_pr ~ 1, data = mariokart)
mae(lm1)
```


Im n√§chsten Schritt spezifizieren Sie ein Modell,
in dem der Verkaufpreis eine Funktion der Anzahl der Lenkr√§der ist (√§hnlich wie in @fig-fehler-red):

```{r}
lm2 <- lm(total_pr ~ wheels, data = mariokart)
mae(lm2)
```

Ah! Sehr sch√∂n, Sie haben mit `lm2` ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach hause!$\square$
:::


## Streuung als Modellfehler

Wenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellg√ºte auffassen.

Definieren wir zun√§chst als Punktmodell auf Errisch:

```{r}
lm_mario1 <- lm(total_pr ~ 1, data = mariokart)
```

Zur Erinnerung: Wir modellieren `total_pr` ohne Pr√§diktoren, sondern als Punktmodell,
und zwar sch√§tzen wir den Mittelwert mit den Daten `mariokoart`.

Das (Meta-)Paket `easystats` bietet komfortable Befehle, um die Modellg√ºte zu berechnen:

```{r}
mae(lm_mario1)  # Mean absolute error
mse(lm_mario1)  # Mean squared error
rmse(lm_mario1)  # Root mean squared error
```



## z-Transformation

Sie arbeiten immer noch als Datenknecht, Moment, *Datenhecht* bei dem Online-Auktionshaus.
Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzeigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen.
Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen.
Schon ist das Leben leichter, s. `mariokart2`.

```{r}
mariokart2 <- 
  mariokart %>% 
  filter(total_pr < 100)
```


```{r}
#| echo: false
mariokart2 <-
  mariokart2 %>% 
  mutate(abw = 47.4 - total_pr)
```


Mit dem R-Paket `ggpubr` (Funktion `gghistogram`) l√§sst sich die Verteilung leicht visualisieren, s. @fig-mariokart2, links. 

```{r}
#| label: fig-mariokart2
#| fig-cap: Verteilung von `mariokart2`
#| layout-ncol: 2
#| echo: false
#| fig-subcap:
#|   - Wie nah dr√§ngen sich die Verkaufspreise um ihren Mittelwert?
#|   - Abweichungen vom Mittelwert


gghistogram(mariokart2, x = "total_pr", 
            add = "mean",  # Mittelwert wird hinzugef√ºgt
            add.params = list(color = okabeito_colors()[1], size = 3))  +# Schnickschnack zur Versch√∂nerung
  annotate("label", x=47, y = 0, label = "Mittelwert")

gghistogram(mariokart2, x = "abw",
            add = "mean",  # Mittelwert wird hinzugef√ºgt
            add.params = list(color =  okabeito_colors()[1], size = 3))  +# Schnickschnack zur Versch√∂nerung
  annotate("label", x= 0, y = 0, label = "Mittelwert")
```



Tja, das ist doch etwas Streuung um den Mittelwert herum.

:::callout-important
Je weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell f√ºr die Daten, bzw. desto h√∂her die Modellg√ºte.$\square$
:::

Ja, es ist *etwas* Streuung, aber wie viel? Kann man das genau angeben?
Sie √ºberlegen ... und √ºberlegen. Da! Eine Idee!

Man k√∂nnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist.
Je gr√∂√üer diese Abweichung, desto schlechter die Modellg√ºte!
Also rechnen Sie diese Abweichung aus.

```{r}
mariokart2 <-
  mariokart2 %>% 
  mutate(abw = 47.4 - total_pr)
```

Anders gesagt: Wir haben die Verkaufspreise *zentriert.*

:::{#def-zentrieren}
### Zentrieren 
Zentrieren bedeutet, von jedem Wert einer Verteilung $X$ den Mittelwert abzuziehen.
Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. $\square$
:::


```{r fig-norm-verschieb-pfeil}
#| echo: false
#| label: fig-norm-dev
#| fig-cap: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt
#| fig-asp: 0.5

mw <- 47.4
streuung <- 9.11

d <- 
  tibble(groesse = rnorm(1e5, mw, streuung),
         groesse_zentriert = groesse - mean(groesse))

d_sum <-
  d %>% 
  pivot_longer(everything()) %>%
  group_by(name) %>% 
  summarise(MW = mean(value))
  

d %>% 
  ggplot() +
  geom_density(aes(x = groesse), color = "#E69F00FF", size = 2) +
  geom_density(aes(x = groesse_zentriert), color = "#56B4E9FF", size = 2) +
  theme_minimal() +
  geom_vline(data = d_sum,
             aes(xintercept = MW),
             color = "grey") +
  geom_label(data = d_sum,
             aes(label = paste0("MW: ", round(MW, 0)), x = MW),
             y = 0) +
  labs(x = "(zentrierte) Variable", 
       y = "") +
  annotate("segment", x = mw, xend = 0, y = 0.01, yend = 0.01,
           arrow = arrow(type = "closed", length = unit(0.02, "npc")))



# d %>% 
#   pivot_longer(everything()) %>% 
#   ggplot() +
#   aes(x = value) +
#   geom_density() +
#   facet_wrap(~ name) +
#   theme_minimal() +
#   geom_vline(data = d_sum,
#              aes(xintercept = MW), color = "red") +
#   geom_label(data = d_sum,
#              aes(label = paste0("MW: ", round(MW, 0)), x = MW),
#              y = 0) +
#   labs(x = "(zentrierte) K√∂rpergr√∂√üe", 
#        y = "")
```



Aber irgendwie sind Sie noch nicht am Ziel Ihrer √úberlegungen:
Woher wei√ü man, ob 10 Euro oder 20 Euro "viel" Abweichung vom Verkaufspreis ist?
Man m√ºsste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen.
Wieder! Ein Geistesblitz!
Man k√∂nnte doch die jeweilige Abweichung  in Bezug setzen zur *mittleren (absoluten) Abweichung* (MAA)!
Ein alternativer, √§hnlicher Kennwert zur mittlerer absolute Abweichung ist die SD.
Sie haben geh√∂rt, dass die SD gebr√§uchlicher ist als die MAA. 
Um sich als Checker zu pr√§sentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja √§hnlich.

Also: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte,
dann h√§tten wir eine "standardisierte"^[abgek√ºrzt manchmal mit `std`] Abweichung von 1, weil 10/10=1.

Begeistert √ºber Ihre Schlauheit machen Sie sich ans Werk.

```{r}
mariokart2 <-
  mariokart2 %>% 
  mutate(abw_std = abw / sd(abw),  # std wie "standardisiert"
         abw_std2 = abw / mean(abs(abw)))  
```

Zufrieden betrachten Sie Ihr Werk, s. @fig-z-transf. 
In @fig-z-transf sieht man oben die Rohwerte und unten die transformierten Werte,
die wir hier als *standardisiert* bezeichnen, da wir sie in Bezug zur "typischen Abweichung", der SD, gesetzt haben.

```{r}
#| warning: false
#| echo: false
#| label: fig-z-transf
#| fig-cap: "Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert"

p1 <- gghistogram(mariokart2, x = "abw",
            add = "mean",  # Mittelwert wird hinzugef√ºgt
            add.params = list(color = okabeito_colors()[1], size = 3)) +
  labs(title = "Rohwerte") +
  annotate("label", x = 0, y = 0, label = "MW", hjust = "bottom")

p2 <-  gghistogram(mariokart2, x = "abw_std",
            add = "mean",  # Mittelwert wird hinzugef√ºgt
            add.params = list(color = okabeito_colors()[1], size = 3)) +
  labs(title = "Standardisierte Werte") +
  annotate("label", x = 0, y = 0, label = "MW", hjust = "bottom")

arrow_down <- png::readPNG("img/arrow-down.png", native = TRUE)
p_ad <- ggplot() + inset_element(arrow_down, 0, 0, 1, 1)

plots(p1, p_ad, p2, n_rows = 3)
```


Wir fassen die Schritte unserer Umrechnung ("Transformation") zusammen wie in einem Kochrezept:

1. Nimm die Verteilung der Verkaufspreise
2. Berechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)
4. Teile die Abweichungen (Schritt 2) durch die SD


Diese Art von Transformation bezeichnet man als *z-Transformation* und die resultierenden Werte als *z-Werte*.

:::{#def-z-werte}
### z-Werte
z-Werte sind das Resultat der z-Transformation.
F√ºr die Variable $X$ berechnet sich der z-Wert der $i$-ten Beobachtung so: $z_i = \frac{x_i - \bar{x}}{sd_x}.\square$
:::

z-Werte sind n√ºtzlich, weil sie die "relative" Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.

Nach einer *Faustregel* spricht man von extremen Abweichungen (Extremwerten, Ausrei√üern), wenn $z_i > 2$ oder $z_i > 3$.


## Fazit

Der ‚Äûgesunde Menschenverstand‚Äú w√ºrde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. 
Das ist vern√ºnftig, denn die MAA ist anschaulicher und damit n√ºtzlicher als die Varianz und die SD.

Warum sollte man √ºberhaupt ein unanschauliches Ma√ü wie die Varianz verwenden? 
Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt.
Gr√ºnde, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:^[Ich wollte noch hinzuf√ºgen, dass die Varianz eng verkn√ºpft mit der linearen Algebra, aber ich war nicht sicher, ob das Argument allgemein √ºberzeugen w√ºrde.]

- Die SD ist sehr n√ºtzlich zur Beschreibung der Normalverteilung
- Die Varianz wird h√§ufig verwendet bzw. in Forschungsarbeiten berichtet, also m√ºssen Sie die Varianz kennen.


Liegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegen√ºber Mittelwert basierten Streuungsma√üen (MAA, Varianz, SD).


## Aufgaben



Die Webseite [datenwerk.netlify.app](https://datenwerk.netlify.app) stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:

<!-- :::{#exr-koerpergroesse} -->
<!-- Sagen wir, wir m√∂chten die K√∂rpergr√∂√üe erwachsener (deutscher) M√§nner modellieren. -->
<!-- Einfach gesagt: Wir m√∂chten wissen, wie gro√ü typischerweise ein deutscher Mann ist. -->
<!-- Wir verwenden den Mittelwert, um diese Frage zu beantworten. -->
<!-- Aus der Literatur erfahren wir, dass die mittlere K√∂rpergr√∂√üe belgischer M√§nner bei 179 cm liegt und normalverteilt ist [@Garcia:2007aa].^[Das sind Daten f√ºr Belgien; Daten zur Standardabweichung f√ºr Deutschland habe ich nicht gefunden.] -->
<!-- ::: -->



Schauen Sie sich auch mal auf [Datenwerk](https://datenwerk.netlify.app/) die Aufgaben zu  dem Tag [variability](https://datenwerk.netlify.app/#category=variability) an.




:::{#exr-handy}
### Analysieren Sie den Datensatz zur Handynutzung
Laden Sie den [Datensatz zur Handynutzung](https://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing) von Google-Docs herunter.^[<https://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing>]. 
Berechnen Sie dann g√§ngige deskriptive Statistiken und visualisieren Sie sie. $\square$
:::




## Literaturhinweise


Allen Downey [-@downey_probably_2023] stellt in seinem vergn√ºglich zu lesenden Buch eine kurzweilige Einf√ºhrung in die Statistik vor;
auch Streuungsma√üe haben dabei einen Auftritt.
Wer mehr "Lehrbuch-Feeling" sucht, wird bei @cetinkaya-rundel_introduction_2021-1 f√ºndig (das Buch ist online frei verf√ºgbar).
Es ist kein Geheimnis, dass Streuungsma√üe keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne Streuungsma√üe geht's nicht.
Jedenfalls werden Sie in jedem Statistik-Lehrbuch,
dass Sie in der Bib (oder sonstwo) aus dem Regal ziehen, f√ºndig werden zu diesem Thema.
Die B√ºcher unterscheiden sich meist "nur" in ihrem Anspruch bzw. der didaktischen Aufmachung; f√ºr alle ist da was dabei.


## Literatur
