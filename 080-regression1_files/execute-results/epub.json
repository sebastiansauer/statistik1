{
  "hash": "2f017f6a9521ef083eae7b22eb8e05b3",
  "result": {
    "engine": "knitr",
    "markdown": "# Geradenmodelle 1 {#sec-gerade1}\n\n\n\n## Lernsteuerung\n\n\n\nAbb. @fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n\n\n\n\n\n\n### Lernziele\n\n\n- Sie können ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\n- Sie können die Bestandteile eines Geradenmodells aufzählen und erläutern.\n- Sie können die Güte eines Geradenmodells anhand von Kennzahlen bestimmen.\n- Sie können Geradenmodelle sowie ihre Modellgüte in R berechnen.\n\n\n### Benötigte R-Pakete\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.content-visible unless-format=\"epub\"}\n$$\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n$$\n:::\n\n\n\n\n\n\n\n### Benötigte Daten\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n::: {.content-visible when-format=\"pdf\"}\n\n@lst-mario-path definiert den Pfad zum Datensatz `mariokart` und importiert die zugehörige CSV-Datei in R, so dass wir einen Tibble mit Namen `mariokart` erhalten.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart_path <- paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets/\",\n  \"csv/openintro/mariokart.csv\")\n\nmariokart <- read.csv(mariokart_path)\n```\n:::\n\n\n\n\n\n\n\n\n:::\n\n\n\n## Vorhersagen\n\n\nVorhersagen sind eine nützliche Sache, \nunter (mindestens) folgenden Voraussetzungen:\n\n1. Sie sind präzise\n2. Wir kennen die Präzision\n3. Jemand interessiert sich für die Vorhersage\n\n\nDie Methode des Vorhersagens, die wir hier betrachten, \nnennt man auch *lineare Regression*.\n\n\n### Vorhersagen ohne Prädiktor\n\n:::::{#exm-noten-prognose}\nNach intensiver Beschäftigung mit Statistik sind Sie allgemein als Checker bekannt.\nViele jüngere Studis fragen Sie um Rat.\neines Tages kommt eine Studentin, Toni, und fragt: \"Welche Statistiknote kann ich in der Klausur erwarten?\"\nSie entgegnen: \"Wie viel hast du denn gelernt?\".\nDie Antwort: \"Sag ich nicht.\"\n\nNach kurzem Überlegen geben sie den Notenschnitt der letzten Klausur als Prognose für diese Person. \n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in @lst-noten2-lokal wird bei Ihnen nur funktionieren, \nwenn auf *Ihrem Computer* dieser Ordner mit dieser Datei existiert. \nAndernfalls müssen Sie die Daten erst herunterladen^[<https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/noten.csv>]:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-noten2-lokal .r .cell-code  lst-cap=\"Der Datensatz 'noten2' liegt im Unterordner 'Noten.'\"}\nnoten2 <- read.csv(\"data/noten2.csv\")\n```\n:::\n\n{{< downloadthis data/noten2.csv dname = \"noten2\" >}}\n\n\n\n\n\n\n\n\n\n\n\n\n\n::::\n\nDazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnoten2 %>% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n```\n\n::: {.cell-output-display}\n\n\n| mw|\n|--:|\n| 91|\n:::\n:::\n\n\n\n\n\n\n\n\nIhre Antwort lautet also: \n\"Im Schnitt haben die Studis bei der letzten Klausur ungefähr 91.08  der Punkte erzielt. \nDiesen Wert kannst du erwarten. \nSolange ich keine genaueren Infos habe, \nz.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!\" $\\square$\n:::::\n\n\nOhne Kenntnis eines Prädiktors (UV) (wie z.B. Lernzeit) \nist der Mittelwert ein geeigneter Vorhersagewert für jede Beobachtung, s. @fig-noten3.\nWir nutzen den Mittelwert als Punktmodell für den Klausurerfolg. $\\square$\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell](080-regression1_files/figure-epub/fig-noten3-1.png){#fig-noten3 fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n\n\n\n\n:::{def-nullmodell}\n### Nullmodell (Punktmodell)\nModelle ohne Prädiktor, Punktmodelle also, \nkann man so bezeichnen: `y ~ 1`. \nDa das Modell null Prädiktoren hat, \nnennt man es auch manchmal \"Nullmodell\".\n:::\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm0 <- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        91.1\n```\n:::\n\n\n\n\n\n\n\n\n`lm` steht für \"lineares Modell\", die `1` sagt, \ndass es keine Prädiktoren gibt.\nIn dem Fall wird der Mittelwert, 91.08, als Gerade verwendet.\nDer zurückgemeldete Koeffizient `(Intercept)` \nist hier der Modell des Punktmodells.\nDa es ein Punktmodell ist, sagt es für alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nWir sagen für jede Beobachtung einen Wert von 91.08 vorher.\n\n\n### Vorhersagen mit Prädiktor\n\n\n\n\n:::{#exm-noten3}\n### Toni verrät die Lernzeit\n\nToni entschließt sich dann doch noch, die Lernzeit zu verraten:\n\"Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.\"\nJetzt müssen Sie erstmal nachdenken: \n\"Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?\"\n\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. @fig-noten4, a).\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(DataExplorer)\nnoten2 %>% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\n\nAuf dieser Basis antworten Sie Toni: \n\"Bei 42 Stunden Lernzeit solltest du so 83 Punkte bekommen. \nKönnte mit dem Bestehen eng werden.\"\nToni ist nicht begeistert von Ihrer Prognose und zieht von dannen. $\\square$\n:::\n\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von *Lernzeit* und *Klausurpunkte* ist deutlich zu erkennen.\nMit einem Lineal könnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. @fig-noten4, b).\n\n\n\n\n\n\n\n\n\n::: {#fig-noten4 .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Streudiagramm](080-regression1_files/figure-epub/fig-noten4-1.png){#fig-noten4-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Streudigramm mit 'Trendgerade' (blau)](080-regression1_files/figure-epub/fig-noten4-2.png){#fig-noten4-2 fig-align='center' width=70%}\n:::\n\nNoten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt gekennzeichnet.\n:::\n\n\n\n\n\n\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.\n\n\n\n## Geradenmodelle\n\n\n### Achsenabschnitt und Steigung definieren eine Gerade\n\nWir verwenden eine Gerade als Modell für die Daten, s. @fig-noten4, b.\nAnders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\n\nEin *Geradenmodell* ist eine Verallgemeinerung des Punktmodells:\nEin Punktmodell sagt für alle Beobachtungen den gleichen Wert vorher.\n@fig-noten3 und @fig-noten4 stellen ein Punktmodell \neinem Geradenmodell gegenüber.\n\nIn einem Geradenmodell wird nicht mehr (notwendig) \nfür jede Beobachtung die gleiche Vorhersage $\\hat{y}$ gemacht (wie das bei einem Punktmodell der Fall ist).\n\n::::{#def-gerade}\n### Gerade\n\nEine Gerade ist das, was man bekommt, \nwenn man eine lineare Funktion in ein Koordinatensystem einzeichnet.\nMan kann sie durch durch zwei *Koeffizienten* festlegen: \nAchsenabschnitt (engl. *intercept*), und Steigung (engl. *slope*).\nHäufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit $t$ und die Steigung mit $m$ bezeichnet:\n \n::: {.content-visible unless-format=\"epub\"}\n\n<!-- HTML, PDF: -->\n\n$f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}$.\n\nIn der Statistik wird folgende Nomenklatur bevorzugt:  $f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + {\\beta_1} \\color{xcol}{x}$ oder $f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + {b_1} \\color{xcol}{x}$ .\n\nDie Nomenklatur mit $\\color{beta0col}{b_0}, \\color{beta1col}{b_1}$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. \nGriechische Buchstaben werden meist verwendet, um zu zeigen, \ndass man an einer Aussage über eine Population, \nnicht nur über eine Stichprobe, machen möchte.\n\nDas \"Dach\" über y, $\\color{modelcol}{\\hat{y}}$, \ndrückt aus, dass es sich den den geschätzten, bzw. vom Modell vorhergesagten (\"modellierten\") \nWert für $\\color{ycol}{y}$ handelt, nicht das tatsächliche (empirische, beobachtete) $\\color{ycol}{y}$. $\\square$\n@fig-regrtex skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n:::\n\n\n\n \n::: {.content-visible when-format=\"epub\"}\n\n<!-- NUR EPUB: -->\n\n\n$f(x)={y}=mx + t.$\n\nIn der Statistik wird folgende Nomenklatur bevorzugt:  $f(x)={\\hat{y}}={\\beta_0} + {\\beta_1}$ oder $f(x)=y= {b_0} + {b_1}.$ \n\nDie Nomenklatur mit $b_0, b_1$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\\beta$. \nGriechische Buchstaben werden meist verwendet, um zu zeigen, \ndass man an einer Aussage über eine Population, \nnicht nur über eine Stichprobe, machen möchte.\n\nDas \"Dach\" über y, $\\hat{y}$, \ndrückt aus, dass es sich den den geschätzten, bzw. vom Modell vorhergesagten (\"modellierten\") \nWert für ${y}$ handelt, nicht das tatsächliche (empirische, beobachtete) ${y}$. $\\square$\n@fig-regrtex skizziert die Elemente einer Regression. (Bildquelle: Basierend auf TikZ-Quellcode von Henri Menke.)\n:::\n\n::::\n\n\n\n\n\n\n\n![Achsenabschnitt ($\\beta_0$) und Steigung ($\\beta_1$) einer Regressionsgeraden [@menk_linear_2014]](img/regr.png){#fig-regrtex width=\"70%\"}\n\n\n::::: {.content-visible unless-format=\"epub\"}\n\n<!-- HTML, PDF -->\n\n\n:::{#def-einfache-lineare-modell}\n\n### Das einfache lineare Modell\n\nDas einfache lineare Modell nimmt den Wert einer abhängigen metrischen Variablen, \\color{ycol}{y},\nals lineare Funktion von unabhängigen Variablen, \\color{xcol}{x}, an, plus einem Fehlerterm, \\color{errorcol}{e} bzw. \\color{errorcol}{$\\epsilon$}, s. @eq-linear-model. $\\square$\n:::\n\n\n\n\n$$\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}$${#eq-linear-model}\n\nMit:\n\n- $\\color{beta0col}{\\beta_0}$: geschätzter y-Achsenabschnitt laut Modell (engl. *intercept*)\n- $\\color{beta1col}{\\beta_1}$: geschätzte Steigung (Regressionsgewicht) laut Modell (engl. *slope*)\n- $\\color{errorcol}{\\epsilon}$: Fehler des Modells\n\n\n:::::\n\n\n\n\n\n::::: {.content-visible when-format=\"epub\"}\n\n<!-- epub -->\n\n\n\n\n$$\\begin{aligned}\n{y} &= f({x}) + {\\epsilon} \\\\\n{y_i} &= {\\beta_0} + {\\beta_1} \\cdot {x_i} + {\\epsilon_i} \\square\n\\end{aligned}$$\n\nMit:\n\n- ${\\beta_0}$: geschätzter y-Achsenabschnitt laut Modell\n- ${\\beta_1}$: geschätzte Steigung laut Modell\n- ${\\epsilon}$: Fehler des Modells\n\n\n:::::\n\n\n\n\n\n\nJe nach Datenlage können sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. @fig-regr-div.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {#fig-regr-div .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Datensatz 1](080-regression1_files/figure-epub/fig-regr-div-1.png){#fig-regr-div-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Datensatz 2](080-regression1_files/figure-epub/fig-regr-div-2.png){#fig-regr-div-2 fig-align='center' width=70%}\n:::\n\nRegressionsanalysen mit verschiedenen Koeffizienten, aber gleicher Modellgüte\n:::\n\n\n\n\n\n\n\n\n\n::::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n@fig-linfun [@yi_interactive_2021] zeigt ein interaktives Beispiel einer linearen Funktion. \nSie können Punkte per Klick/Touch hinzufügen.\n\n\n::::{#fig-linfun}\n\n::: {.figure-content}\n\n\n\n\n\n\n\n\n\n\n\n\n\n```{ojs}\n//| echo: false\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () => {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n```\n\n```{ojs}\n//| echo: false\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () => {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n```\n\n```{ojs}\n//| echo: false\nrSquaredPlot = RSquaredPlot({ width: width })\n```\n\n```{ojs}\n//| echo: false\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) => x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) => y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n```\n\n```{ojs}\n//| echo: false\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) => {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n```\n\n```{ojs}\n//| echo: false\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) => {\n    setTimeout(() => {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =>\n        update.call((update) => {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) => xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =>\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =>\n        update.call((update) => {\n          // Check if bar is too short\n          const check = (d) => d < 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) => xScale(d))\n            .text((d) => labelFormat(d))\n            .attr(\"fill\", (d) => (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) => (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) => (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n```\n\n```{ojs}\n//| echo: false\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) => x, // accessor function for x-coordinate\n    y = ([, y]) => y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) => ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) => ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) => d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) => d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) => d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) => d.xCoord)\n    .y((d) => d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) => g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) => g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) => {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () => {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () => {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) => d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) => {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) => xScale(d[0][0]))\n          .attr(\"x2\", (d) => xScale(d[1][0]))\n          .attr(\"y1\", (d) => yScale(d[0][1]))\n          .attr(\"y2\", (d) => yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =>\n          update\n            .transition()\n            .attr(\"cx\", (d) => xScale(d.xCoord))\n            .attr(\"cy\", (d) => yScale(d.yCoord)),\n        (exit) =>\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) => xScale(d.xCoord))\n            .attr(\"y1\", (d) => yScale(d.yCoord))\n            .attr(\"x2\", (d) => xScale(d.xCoord))\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            // Add transition\n            .call((enter) =>\n              enter\n                .transition()\n                .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =>\n          update.call((update) => {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) => xScale(d.xCoord))\n              .attr(\"y1\", (d) => yScale(d.yCoord))\n              .attr(\"x2\", (d) => xScale(d.xCoord))\n              .attr(\"y2\", (d) => yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =>\n          exit\n            .transition()\n            .attr(\"y2\", (d) => yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) => {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) < 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) => d.id)\n      .join(\n        (enter) =>\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) => xScale(d.xCoord))\n            .attr(\"y\", (d) => yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) => {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =>\n          update.call((update) => {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) => xScale(d.xCoord))\n              .attr(\"y\", (d) => yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) => exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) => ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n```\n\n```{ojs}\n//| echo: false\nd3 = require(\"d3-regression\", \"d3\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nInteraktives Beispiel für eines lineares Modell. Fügen Sie Punkte per Klick/Touch hinzu.\n::::\n:::::\n\n\n\n:::{#exm-noten5}\n### Toni will es genau wissen\nDa Toni Sie als Statistik-Profi abgespeichert hat, w\nerden Sie wieder konsultiert.\n\"Okay, ich hab noch zwei Fragen. \nErstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? \nZweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurück!\"\n\n[Das sind gute Fragen. Den $\\color{ycol}{Y}$-Wert (Klausurpunkte) bei $\\color{xcol}{X}=0$ gibt der Achsenabschnitt zurück. ]{.content-visible unless-format=\"epub\"}\n\n[Das sind gute Fragen. Den ${Y}$-Wert (Klausurpunkte) bei ${X}=0$ gibt der Achsenabschnitt zurück. ]{.content-visible when-format=\"epub\"}\n\n\nSchnell skizzieren Sie dazu ein Diagramm, s. @fig-beta0.\nPuh, die Antwort wird Toni nicht gefallen ... $\\square$\n:::\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)](080-regression1_files/figure-epub/fig-beta0-1.png){#fig-beta0 fig-align='center' width=75%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nAnstelle auf @fig-beta0 zu schauen, \nkönnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n\n>    [🧑‍🏫]{.content-visible when-format=\"html\"}[\\emoji{teacher}]{.content-visible when-format=\"pdf\"}  Hey R, predicte mir mal auf Basis vom Modell \"lm1\" den Lernerfolg für Toni, wenn der x=0 Stunden lernt.\n\n>    [🤖]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Okay, ich predicte mit Modell \"lm1\" und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit <- tibble(x = 0)  # `tibble` erstellt eine Tabelle\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit)\n##  1 \n## 46\n```\n:::\n\n\n\n\n\n\n\n\n\n### Spezifikation eines Geradenmodells\n\n\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. @eq-mod1:\n\n\n::: {.content-visible unless-format=\"epub\"}\n\n$$\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}}$$ {#eq-mod1}\n\nLies: \"Laut meinem Modell ist mein (geschätztes) $\\color{ycol}{\\hat{y}}$ irgendeine Funktion von $\\color{xcol}{\\text{x}}$\".\n\nWir erinnern uns, dass $\\color{ycol}{Y}$ die $\\color{ycol}{AV}$ und $\\color{xcol}{X}$ die $\\color{xcol}{UV}$ ist:\n\n$$\\color{ycol}{AV} \\sim \\color{xcol}{UV}$$ {#eq-mod1}\n\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n$${\\hat{y}} \\sim {\\text{x}}$$ {#eq-mod1}\n\nLies: \"Laut meinem Modell ist mein (geschätztes) ${\\hat{y}}$ irgendeine Funktion von ${\\text{x}}$\".\n\nWir erinnern uns, dass ${Y}$ die ${AV}$ und ${X}$ die ${UV}$ ist:\n\n$${AV} \\sim {UV}$$ {#eq-mod1}\n:::\n\n\nWir werden als Funktion (erstmal) nur Geraden verwenden.\nDie genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\n\n\n@eq-mod1 können Sie so ins Errische übersetzen:\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(y ~ x, data = meine_daten)\n```\n:::\n\n\n\n\n\n\n\n\n`lm` steht für \"lineares Modell\", also eine Gerade als Modell.\nDie Gerade nennt man auch *Regressionsgerade* (an anderer Stelle in diesem Buch unscharf als \"Trendgerade\" bezeichnet).\n\n:::{#exm-noten5}\n### Zahlen für Toni\nToni ist nicht zufrieden mit Ihren Vorhersagen: \"Jetzt hör mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir präzise Zahlen!\".\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      46.191        0.879\n```\n:::\n\n\n\n\n\n\n\n\nR gibt Ihnen die beiden Koeffizienten für die Gerade aus. \nDen Namen des Objekts können Sie frei aussuchen, z.B. `mein_erstes_lm`.\n\nDie Regressionsgleichung lautet demnach:\n`y_pred = 8.6 + 0.88*x`.\n\n\n::: {.content-visible unless-format=\"epub\"}\n`8.6` ist der Achsenabschnitt, d.h. der Wert von $\\color{ycol}{Y}$ wenn $\\color{xcol}{x}=0$.\n`0.88` ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: Für jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um `0.88` Punkte.\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige $\\color{ycol}{Y}$-Werte ausrechnen gegeben bestimmte $\\color{xcol}{X}$-Werte.\nHat jemand zum Beispiel 10 Stunden gelernt, \nwürden wir folgendes Klausurergebnis vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlernzeit <- 10\ny_pred <- 46 + 0.88*lernzeit\ny_pred\n## [1] 55\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n\n`8.6` ist der Achsenabschnitt, d.h. der Wert von ${Y}$ wenn ${x}=0$.\n`0.88` ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: Für jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um `0.88` Punkte.\n\nMit Kenntnis der beiden Koeffizienten kann man beliebige ${Y}$-Werte ausrechnen gegeben bestimmte ${X}$-Werte.\nHat jemand zum Beispiel 10 Stunden gelernt, \nwürden wir folgendes Klausurergebnis vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlernzeit <- 10\ny_pred <- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n:::{#exm-noten6}\n### Vorhersage für Klausurerfolg, nächster Versuch\nSie versuchen, noch etwas Gutes für Toni zu tun.\nR hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt.\nSie dürfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit2 <- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n```\n:::\n\n\n\n\n\n\n\n\n`tonis_lernzeit2` ist eine Tabelle mit einer Zeile und einer Spalte:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntonis_lernzeit2\n```\n\n::: {.cell-output-display}\n\n\n|  x|\n|--:|\n| 73|\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm1, newdata = tonis_lernzeit2)\n##   1 \n## 110\n```\n:::\n\n\n\n\n\n\n\n\n\n\nDie Syntax von `predict` lautet:\n\n```\npredict(name_des_objekts, newdata = tabelle_mit_prädiktorwerten)\n```\n\nDie Funktion `predict` liefert eine Vorhersage für eine Vorhersage.\n:::\n\n\n### Vorhersagefehler\n\n\n::: {.content-visible unless-format=\"epub\"}\nDie Differenz zwischen vorhergesagten Wert für eine (neue) Beobachtung, $\\color{modelcol}{\\hat{y_0}}$ \nund ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: \n$\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}$.\n:::\n\n\n\n::: {.content-visible when-format=\"epub\"}\nDie Differenz zwischen vorhergesagten Wert für eine (neue) Beobachtung, ${\\hat{y_0}}$ \nund ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: \n${e_i} = {y_i} - {\\hat{y}_i}$.\n:::\n\n\n\n\n\n\n\n\n\n\n::: {#fig-resid .cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Geradenmodell (lm1)](080-regression1_files/figure-epub/fig-resid-1.png){#fig-resid-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Punktmodell (lm0)](080-regression1_files/figure-epub/fig-resid-2.png){#fig-resid-2 fig-align='center' width=70%}\n:::\n\nVorhersagefehler als Abweichungsbalken: Beim Geradenmodell, links, sind die Vorhersagefehler (Abweichungsbalken) kleiner (kürzer) als beim Punktmodell, rechts.\n:::\n\n\n\n\n\n\n\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) \nin Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket `easystats`):\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm0)\nmae(lm1)\n## [1] 11\n## [1] 8\n```\n:::\n\n\n\n\n\n\n\n\n\nVergleichen wir MAE im  Nullmodell mit MAE in `lm1`: \n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverhaeltnis_fehler_mae <- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n```\n:::\n\n\n\n\n\n\n\n\n\n\nAh! Das Geradenmodell ist viel besser:\nVon `lm0` zu `lm1` haben die mittlere Absolutlänge des Fehlerbalkens auf 71 Prozent verbessert.\nNicht schlecht!\n\n\n:::{#def-fehlerstreung}\n### Fehlerstreuung\nAls Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte ($y_i$) vom vorhergesagten Wert ($\\hat{y}_i$). $\\square$\n:::\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngrößen \nwie MAE oder MSE.\n\n\n:::{.callout-note}\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), \nsolange X mit Y korreliert ist. $\\square$\n:::\n\n\nNatürlich können wir -- in Analogie zur Varianz -- \nauch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen.\nWer mag, \nkann den MSE auch von Hand berechnen: `mean((noten2$y - mean(noten2$y))^2)`.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmse(lm0)\nmse(lm1)\n## [1] 193\n## [1] 106\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nverhaeltnis_fehler_mse <- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n### Berechnung der Modellkoeffizienten\n\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\n\nDie Regressionskoeffizienten (hier synonym: Modellparameter) b0 und b1 wählt man so, dass die *Residuen* *minimal* sind.\nGenauer gesagt wird die Summe der quadrierten [Residuen]{.green} minimiert, s. @eq-min.\n\n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n @fig-opt veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n::::{#fig-opt}\n\n:::{.panel-tabset}\n\n### Minimierung der Residuen\n\n![Berechnung der Modellkoeffizienten durch Minimierung der Residuen](img/RegressionSpring.gif)\n\n### Minimierung der quadrierten Residuen\n\n![Minimierung der quadrierten Residuen](img/RegressionRSS.gif)\n\n:::\n\n\nBildquelle: [Karsten Lübke, FOM Hochschule](https://www.fom-blog.de/autorinnen-und-autoren/karsten-luebke)\n\n::::\n:::::\n\n\n\n\n::: {.content-visible unless-format=\"epub\"}\n$$\\text{min}\\sum_i \\color{errorcol}{e_i}^2$${#eq-min}\n:::\n\n\n::: {.content-visible when-format=\"epub\"}\n$$\\text{min}\\sum_i {e_i}^2$${#eq-min}\n:::\n\nEs gibt verschiedene Möglichkeiten, \num die Koeffizienten zu berechnen (die sind aber nicht in diesem Buch zu finden).\nEine schöne Darstellung dazu findet sich bei @kaplan_statistical_2009.\n\n\n::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\"Von Hand\" können Sie die Optimierung von b0 und b1 in \n dieser App der FOM-Hochschule^[<https://fomshinyapps.shinyapps.io/KleinsteQuadrate/>] ausprobieren.\n:::\n\n\n\n\n\n\n\n\n## R-Quadrat als Maß der Modellgüte\n\nAnders gesagt, wir haben uns ( (bzw. das Modell hat sich) um $1 - 0.55$ verbessert.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::{#def-r2}\n### R-Quadrat\nDie Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen  von `lm0` \nzum gerade untersuchten Modell nennt man  *R-Quadrat* ($R^2$).\nR-Quadrat ($R^2$) e\nines Modells $m$ ist definiert als die Verringerung der Streuung, \nwenn man das Modell $m$ mit dem Nullmodell $m_0$ vergleicht: $R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}$. \nR-Quadrat ist ein Maß der *Modellgüte*: \nJe größer $R^2$, desto besser die Vorhersage. \nDa es ein Anteilsmaß ist, \nliegt der Wertebereich zwischen 0 uns 1.\nIm Nullmodell liegt R-Quadrat per Definition bei 0.\nIm Fall von Modellen des Typs $y\\sim x$ gilt: $R^2 = r_{xy}^2$.\n$\\square$\n:::\n\n\nEinfach gesagt: $R^2$ gibt an, wie gut (zu welchem Anteil) \nein Modell die Zielvariable erklärt. \n\n\nWir können R-Quadrat ($R^2$) uns von R z.B. so ausgeben lassen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n```\n:::\n\n\n\n\n\n\n\n\nBei einer perfekten Korrelation ist $r=1$, \ndaher ist dann auch $R^2 = 1$.\nDas gilt bei Modellen mit einem Prädiktor; \ngibt es mehrere Prädiktoren \ngilt die Beziehung nur, wenn die Prädiktoren alle paarweise unabhängig sind, \nvgl. @fig-r2-extreme.\n\n\n\n\n\n\n\n\n\n::: {#fig-r2-extreme .cell layout=\"[[45,-10,45],[100]]\" layout-align=\"center\"}\n::: {.cell-output-display}\n![Keine Korrelation](080-regression1_files/figure-epub/fig-r2-extreme-1.png){#fig-r2-extreme-1 fig-align='center' width=70%}\n:::\n\n::: {.cell-output-display}\n![Perfekte Korrelation](080-regression1_files/figure-epub/fig-r2-extreme-2.png){#fig-r2-extreme-2 fig-align='center' width=70%}\n:::\n\nExtremfälle von R-Quadrat: 0 und 1. (a) Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefähr) parallel zur X-Achse. (b) Perfekte Korrelation, r = 1 und $R2$ = 1: Die Prognose ist gleich dem beobachtetem Wert.\n:::\n\n\n\n\n\n\n\n\nBei einer perfekten Korrelation $R^2=1$ liegen die Punkte auf der Geraden.\nIm gegenteiligen Extremfall von $R^2=0$ ist die Vorhersage genauso gut, \nwie wenn man für jedes $y$ den Mittelwert, [$\\color{ycol}{\\bar{y}}$]{.content-visible unless-format=\"epub\"}\n[${\\bar{y}}$]{.content-visible when-format=\"epub\"}, vorhersagen würde. \nJe größer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser \"erklärt\" das Modell die Daten \n(desto besser der \"Fit\", sagt man).\n\n::: {.content-visible when-format=\"html\"}\n[Diese App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/Variationszerlegung/) erlaubt es Ihnen mit der Größe der Residuen eines linearen Modells zu spielen.\n:::\n\n\n\n<!-- ### Addition der Varianzen -->\n\n\n<!-- Nennen wir die Varianz des Verkaufspreis $s^2_y$, die Verbesserung der Fehlerstreuung durch das *M*odell $s^2_m$ und die restliche Fehlerstreuung, den MSE, $s^2_e$. -->\n<!-- Dann gilt: -->\n\n<!-- $$s^2_y = s^2_m + s^2_e \\\\ -->\n<!-- s^2_m = s^2_y - s^2_e$$ -->\n\n<!-- ```{r} -->\n<!-- s2_y = var(noten2$y) -->\n<!-- s2_e = mse(lm1) -->\n<!-- s2_m = s2_y - s2_e -->\n<!-- s2_m -->\n<!-- ``` -->\n\n<!-- Die Varianzanteile addieren sich. Mit anderen Kennzahlen der Streuung (SD, MAE) funktioniert das nicht. -->\n\n\n## Interpretation eines Regressionsmodells {#sec-interpret-reg-mod}\n\n\n### Modellgüte\n\nDie Residuen (Vorhersagefehler) bestimmen die Modellgüte:\nSind die Residuen im Schnitt groß, so ist die Modellgüte gering (schlecht), und umgekehrt.\nVerschiedenen Koeffizienten stehen zur Verfügung: R-Quadrat, $r$ (als Korrelation von tatsächlichem $y$ und vorhergesagten $\\hat{y}$), MSE, RMSE, MAE, ...\n\n\n### Koeffizienten\n\nDie Modellkoeffizienten, also Achsenabschnitt ($\\beta_0$; lies: \"beta Null\") und Steigung ($\\beta_1$) sind nur eingeschränkt zu interpretieren, \nwenn man die zugrundeliegenden kausalen Abhängigkeiten nicht kennt.\nNur aufgrund eines statistischen Zusammenhangs darf man keine kausalen Abhängigkeiten annehmen.\nOhne eine guten Grund für eine Kausalbehauptung kann man kann nur *deskriptiv* argumentieren.\nOder sich mit der Modellgüte und den Vorhersagen begnügen. \nWas auch was wert ist.\n\n#### Achsenabschnitt\n\n[Im Modell `lm1` liegt der Achsenabschnitt bei $\\textcolor{ycol}{y}=46.19$. \nBeobachtungen mit $\\color{xcol}{x}=0$ \nkönnen also diesen $\\textcolor{ycol}{Y}$-Wert erwarten.]{.content-visible unless-format=\"epub\"}\n\n\n[Im Modell `lm1` liegt der Achsenabschnitt bei ${y}=46.19$. \nBeobachtungen mit ${x}=0$ \nkönnen also diesen ${Y}$-Wert erwarten.]{.content-visible when-format=\"epub\"}\nLeider ist es häufig so, dass Prädiktorwerte von 0 in der Praxis nicht realistisch sind, \nso dass der Achsenabschnitt dann wenig nützt.\n\n:::{#exm-groesse}\n### Regression Größe und Gewicht\nNutzt man Körpergröße und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von Körpergröße wenig nützlich, da es keine Menschen gibt der Größe 0. $\\square$\n:::\n\n\n#### Geradensteigung\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\nSo interpretiert man die Geradensteigung, $\\beta_1$:\n\"Im Modell `lm1` beträgt der Regressionskoeffizient $\\beta1 = 0.88$. Zwei Studentinnen, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich *laut Modell* um den Wert von $\\beta_1$\"\n\n:::{.callout-caution}\nHäufig liest man, der \"Effekt des Prädiktors\" auf die AV betrage z.B. $0.88$. \"Effekt\" ist aber ein Wort, \ndas man kausal verstehen kann.\nOhne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. \nDaher sollte man das Wort \"Effekt\" mit Vorsicht genießen. \nManche sprechen daher auch von einem \"statistischen Effekt\". $\\square$\n:::\n\n\n## Wie man mit Statistik lügt\n\n\nDer Unterschied in Modellgüte zwischen, \nsagen wir, $r=.1$ und $r=.2$ ist *viel kleiner* als zwischen $r=.7$ und $r=.8$.\n$R^2$ ist ein (lineares) Maß der Modellgüte und da $r = \\sqrt{R^2}$, darf $r$ nicht wie $R^2$ \nals Maß der Modellgüte interpretiert werden. @fig-r-r2 zeigt den Zusammenhang von $r$ und $R^2$.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Der Zusammenhang von r und R-Quadrat ist nicht linear.](080-regression1_files/figure-epub/fig-r-r2-1.png){#fig-r-r2 fig-align='center' width=50%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::{.callout-caution}\nUnterschiede zwischen Korrelationsdifferenzen dürfen nicht linear interpretiert werden. $\\square$\n:::\n\n\n## Fallbeispiel Mariokart\n\n### Der Datenwahrsager legt los\n\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, \nin dem Sie arbeiten, \nhaben Sie sich neue Ziele gesetzt.\nSie möchten eine genaue Vorhersage von Verkaufspreisen erzielen.\nAls Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin.\nGenaue Vorhersagen, \ndas ist etwas von hoher betriebswirtschaftlicher Relevanz.\nAuf geht's!\n\nDaten laden (und die üblichen Pakete starten, nicht vergessen):\n\n::: {.content-visible when-format=\"html\"}\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n```\n:::\n\n\n\n\n\n\n\n:::\n\n::: {.content-visible when-format=\"pdf\"}\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmariokart <- read.csv(mariokart_path)\n```\n:::\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm2 <- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n```\n:::\n\n\n\n\n\n\n\n\n\nOh nein! Unterirdisch schlecht. Anstelle von bloßem Rumprobieren überlegen Sie und schauen dann nach, welche Variable am stärksten korreliert mit `total_pr`;\nes resultiert `lm3`: \n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm3 <- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n```\n:::\n\n::: {#tbl-lm3 .cell layout-align=\"center\" tbl-cap='Modellparameter von lm3'}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |   SE |         95% CI | t(141) |      p |\n|:-----------|:-----------:|:----:|:--------------:|:------:|:------:|\n|(Intercept) |       36.25 | 2.54 | (31.23, 41.26) |  14.28 | < .001 |\n|ship pr     |        4.34 | 0.57 |   (3.22, 5.46) |   7.67 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, \nwie man in @tbl-lm3 sieht: Ein Spiel, \ndas mit Null Euro Preis startet, kann laut `lm3` etwa 36 Euro finaler Verkaufspreis erwarten.\n*Pro Euro an Versandkosten* (`ship_pr`) steigt der zu erwartende finale Verkaufspreis \num ca. 4 Euro.\n(Die Spalte `95 CI` gibt einen Schätzbereich für den jeweiligen Modellkoeffizienten an,\ndenn es handelt sich bei den Koeffizienten um Schätzwerte;\nder wahre Wert in der Population ist unbekannt. \nWir kennen schließlich nur eine Stichprobe der Größe $n=143$.)\n\nDie Regressionsgleichung von `lm3` lautet demnach:\n`total_pr_pred = 36.25 + 4.34*ship_pr`.\n\nIn Worten: \n\n>    Der vorhergesagte Gesamptreis eines Spiels liegt bei 36.25€ \"Sockelbetrag\" plus 4.34 mal die Versandkosten.\n\n\n### Vertiefung\n\nMan kann sich die erwarteten Werte (\"expectations\") des Verkaufspreises in Abhängigkeit vom Wert der UV (`ship_pr`) auch schätzen (\"to estimate\") lassen, und zwar so mit `estimate_expectation(lm3)`, s. @tbl-lm3-expect.\n\n\n\n\n\n\n\n\n\n\n\n\n::: {#tbl-lm3-expect .cell layout-align=\"center\" tbl-cap='Die vorhergesagten (predicted) Werte und die Abweichungen vom vorhergesagten Wert (Residuals)'}\n::: {.cell-output-display}\n\n\nTable: Model-based Expectation\n\n|ship_pr | Predicted|  SE |        95% CI | Residuals|\n|:-------|---------:|:----|:--------------|---------:|\n|4.00    |     53.59|1.87 |(49.89, 57.30) |     -2.04|\n|3.99    |     53.55|1.87 |(49.85, 57.25) |    -16.51|\n|3.50    |     51.43|1.82 |(47.82, 55.03) |     -5.93|\n|0.00    |     36.25|2.54 |(31.23, 41.26) |      7.75|\n|0.00    |     36.25|2.54 |(31.23, 41.26) |     34.75|\n|4.00    |     53.59|1.87 |(49.89, 57.30) |     -8.59|\n\nVariable predicted: total_pr\n\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, \nfassen Sie sich die Ausgabe zusammen.\n\n\n>    [🤖]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Das sieht man in der Spalte `Predicted`, dort steht der vorhersagte Wert für `total_pr` für einen bestimmten Wert von `ship_pr`.\n\n\n>    [🧑‍🎓]{.content-visible when-format=\"html\"}[\\emoji{student}]{.content-visible when-format=\"pdf\"} Kann ich auch `predict` benutzen? Ich würde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n>    [🤖]{.content-visible when-format=\"html\"}[\\emoji{robot}]{.content-visible when-format=\"pdf\"} Ja, klar!\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nneue_daten <- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\nAber nützlich wäre noch, das Modell \n(bzw. die Schätzung der erwarteten Werte) als Diagramm zu bekommen.\nDas erreicht man z.B. so, s. @fig-lm3.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nestimate_expectation(lm3) %>% plot()\n```\n\n::: {.cell-output-display}\n![Verbildlichung der erwarteteten Werte laut lm3](080-regression1_files/figure-epub/fig-lm3-1.png){#fig-lm3 fig-align='center' width=75%}\n:::\n:::\n\n\n\n\n\n\n\n\n`estimate_expectation` heißt sinngemäß \"schätze den zu erwartenden Wert\".\nKurz gesagt: Wir wollen eine Vorhersage von R.\n\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie \"gut\" das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\n\nDas Modell erklärt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmae(lm3)\n## [1] 13\n```\n:::\n\n\n\n\n\n\n\n\n\n\nIm nächsten Meeting erzählen Sie Ihrem Chef \n\"Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 \nDollar genau vorhersagen!\".\nHört sich gut an.\nAllerdings hätte ihr Chef es gerne genauer. \nKann man da noch was machen?\n\n\n\n\n## Fallstudie Immobilienpreise\n\n\n\n\n<!-- ## Fallstudie Immobilienpreise -->\n\n:::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n:::{.callout-caution}\nDiese Fallstudie stellt die Prüfungsleistung \"Prognosewettbewerb\" einführend dar. \nEs empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten. $\\square$\n:::\n\n::::\n\n\n### Hintergrund\n\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen.\nKurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei [kaggle.com](https://www.kaggle.com/) ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. \nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition [\"House Prices - Advanced Regression Techniques\"](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview), die Sie auf der Kaggle-Webseite finden.\nDort finden Sie auch eine nähere Beschreibung, das Ziel und die Spielregeln des Wettbewerbs.\n\n::: {.content-visible when-format=\"html\"}\n\n- [Beschreibung](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/description)\n- [Ziel/Aufgabe](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview/evaluation)\n- [Spielregeln](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/rules)\n\n:::\n\n\n### Benötigte R-Pakete\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\n```\n:::\n\n\n\n\n\n\n\n\n\n### Daten\n\nSie können die Daten von [Kaggle herunterladen](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data).\n\nIm Einzelnen müssen Sie folgende Dateien herunterladen:\n\n- *Data_description.txt*: Codebook, d.h. Beschreibung der Variablen im Datensatz\n- *train.csv*: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen\n- *test.csv*:  Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen\n- *sample_submission.csv*: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\n\nSie können auch über das Github-Repo `statistik1`, Ordner `data` auf die Daten zugreifen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_train_path_online <- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-train.csv\")\n\nd_test_path_online <- paste0(\n\"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-test.csv\")\n\nd_train <- read.csv(d_train_path_online)\nd_test <- read.csv(d_test_path_online)\n```\n:::\n\n\n\n\n\n\n\n\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden \nUnterverzeichnis (Ihres Projektordners in RStudio) ab.\n\n\n\nImportieren wir die Daten von der Festplatte, aus dem Unterordner `data` in R\n(davon ausgehend, dass der Unterordner `data` ein Unterordner Ihres aktuellen R-Projekts ist):\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_train_path <- \"data/kaggle-train.csv\"\nd_test_path <- \"data/kaggle-test.csv\"\nd_train <- read.csv(d_train_path)\nd_test <- read.csv(d_test_path)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWenn das Importieren von der Festplatte nicht klappt ... \nEs ist zwar hilfreich, wenn man Daten von der eigenen Festplatte importieren kann.\nAber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.\n\n\n\n\n\n\n### Prognosedatei\n\n\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthält.\nSie soll prinzipiell so aussehen wie in @tbl-subm dargestellt.\n\n\n\n\n\n\n\n::: {#tbl-subm .cell layout-align=\"center\" tbl-cap='Beispiel für den Aufbau der Prognose-Datei'}\n::: {.cell-output-display}\n\n\n|   id| SalePrice|\n|----:|---------:|\n| 1461|    169277|\n| 1462|    187758|\n| 1463|    183584|\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte `id` und der Spalte `Saleprice`.\nDie Spalte `id` gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist -- \nfür welches Haus Sie also gerade einen Kaufpreis vorhersagen.\ndie Spalte `SalePrice` ist Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht.\nInsgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, \nalso die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar? Los geht's!\n\n\n\n\n### Ein erster Blick in die Daten\n\nSchauen Sie sich zu Beginn einmal die Verteilung der metrischen Variablen,\nz.B. mit `describe_distribution(d_train)` an.\n\n\n::: {.content-visible when-format=\"html\" unless-format=\"epub\"}\n\n\n\n\n\n\n\n::: {#tbl-ames1 .cell layout-align=\"center\" tbl-cap='Verteilung der metrischen Variablen im ames-Datensatz'}\n::: {.cell-output-display}\n\n\n|Variable      |     Mean |       SD |      IQR |                Range | Skewness | Kurtosis |    n | n_Missing |\n|:-------------|:--------:|:--------:|:--------:|:--------------------:|:--------:|:--------:|:----:|:---------:|\n|Id            |   730.50 |   421.61 |   730.50 |      (1.00, 1460.00) |     0.00 |    -1.20 | 1460 |         0 |\n|MSSubClass    |    56.90 |    42.30 |    50.00 |      (20.00, 190.00) |     1.41 |     1.58 | 1460 |         0 |\n|LotFrontage   |    70.05 |    24.28 |    21.00 |      (21.00, 313.00) |     2.16 |    17.45 | 1201 |       259 |\n|LotArea       | 10516.83 |  9981.26 |  4060.00 |  (1300.00, 2.15e+05) |    12.21 |   203.24 | 1460 |         0 |\n|OverallQual   |     6.10 |     1.38 |     2.00 |        (1.00, 10.00) |     0.22 |     0.10 | 1460 |         0 |\n|OverallCond   |     5.58 |     1.11 |     1.00 |         (1.00, 9.00) |     0.69 |     1.11 | 1460 |         0 |\n|YearBuilt     |  1971.27 |    30.20 |    46.00 |   (1872.00, 2010.00) |    -0.61 |    -0.44 | 1460 |         0 |\n|YearRemodAdd  |  1984.87 |    20.65 |    37.00 |   (1950.00, 2010.00) |    -0.50 |    -1.27 | 1460 |         0 |\n|MasVnrArea    |   103.69 |   181.07 |   166.00 |      (0.00, 1600.00) |     2.67 |    10.08 | 1452 |         8 |\n|BsmtFinSF1    |   443.64 |   456.10 |   712.75 |      (0.00, 5644.00) |     1.69 |    11.12 | 1460 |         0 |\n|BsmtFinSF2    |    46.55 |   161.32 |     0.00 |      (0.00, 1474.00) |     4.26 |    20.11 | 1460 |         0 |\n|BsmtUnfSF     |   567.24 |   441.87 |   585.00 |      (0.00, 2336.00) |     0.92 |     0.47 | 1460 |         0 |\n|TotalBsmtSF   |  1057.43 |   438.71 |   503.50 |      (0.00, 6110.00) |     1.52 |    13.25 | 1460 |         0 |\n|X1stFlrSF     |  1162.63 |   386.59 |   509.75 |    (334.00, 4692.00) |     1.38 |     5.75 | 1460 |         0 |\n|X2ndFlrSF     |   346.99 |   436.53 |   728.00 |      (0.00, 2065.00) |     0.81 |    -0.55 | 1460 |         0 |\n|LowQualFinSF  |     5.84 |    48.62 |     0.00 |       (0.00, 572.00) |     9.01 |    83.23 | 1460 |         0 |\n|GrLivArea     |  1515.46 |   525.48 |   649.75 |    (334.00, 5642.00) |     1.37 |     4.90 | 1460 |         0 |\n|BsmtFullBath  |     0.43 |     0.52 |     1.00 |         (0.00, 3.00) |     0.60 |    -0.84 | 1460 |         0 |\n|BsmtHalfBath  |     0.06 |     0.24 |     0.00 |         (0.00, 2.00) |     4.10 |    16.40 | 1460 |         0 |\n|FullBath      |     1.57 |     0.55 |     1.00 |         (0.00, 3.00) |     0.04 |    -0.86 | 1460 |         0 |\n|HalfBath      |     0.38 |     0.50 |     1.00 |         (0.00, 2.00) |     0.68 |    -1.08 | 1460 |         0 |\n|BedroomAbvGr  |     2.87 |     0.82 |     1.00 |         (0.00, 8.00) |     0.21 |     2.23 | 1460 |         0 |\n|KitchenAbvGr  |     1.05 |     0.22 |     0.00 |         (0.00, 3.00) |     4.49 |    21.53 | 1460 |         0 |\n|TotRmsAbvGrd  |     6.52 |     1.63 |     2.00 |        (2.00, 14.00) |     0.68 |     0.88 | 1460 |         0 |\n|Fireplaces    |     0.61 |     0.64 |     1.00 |         (0.00, 3.00) |     0.65 |    -0.22 | 1460 |         0 |\n|GarageYrBlt   |  1978.51 |    24.69 |    41.00 |   (1900.00, 2010.00) |    -0.65 |    -0.42 | 1379 |        81 |\n|GarageCars    |     1.77 |     0.75 |     1.00 |         (0.00, 4.00) |    -0.34 |     0.22 | 1460 |         0 |\n|GarageArea    |   472.98 |   213.80 |   244.50 |      (0.00, 1418.00) |     0.18 |     0.92 | 1460 |         0 |\n|WoodDeckSF    |    94.24 |   125.34 |   168.00 |       (0.00, 857.00) |     1.54 |     2.99 | 1460 |         0 |\n|OpenPorchSF   |    46.66 |    66.26 |    68.00 |       (0.00, 547.00) |     2.36 |     8.49 | 1460 |         0 |\n|EnclosedPorch |    21.95 |    61.12 |     0.00 |       (0.00, 552.00) |     3.09 |    10.43 | 1460 |         0 |\n|X3SsnPorch    |     3.41 |    29.32 |     0.00 |       (0.00, 508.00) |    10.30 |   123.66 | 1460 |         0 |\n|ScreenPorch   |    15.06 |    55.76 |     0.00 |       (0.00, 480.00) |     4.12 |    18.44 | 1460 |         0 |\n|PoolArea      |     2.76 |    40.18 |     0.00 |       (0.00, 738.00) |    14.83 |   223.27 | 1460 |         0 |\n|MiscVal       |    43.49 |   496.12 |     0.00 |     (0.00, 15500.00) |    24.48 |   701.00 | 1460 |         0 |\n|MoSold        |     6.32 |     2.70 |     3.00 |        (1.00, 12.00) |     0.21 |    -0.40 | 1460 |         0 |\n|YrSold        |  2007.82 |     1.33 |     2.00 |   (2006.00, 2010.00) |     0.10 |    -1.19 | 1460 |         0 |\n|SalePrice     | 1.81e+05 | 79442.50 | 84075.00 | (34900.00, 7.55e+05) |     1.88 |     6.54 | 1460 |         0 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n:::\n\n### Ein erstes Vorhersagemodell\n\n\n#### Welche Variablen eignen sich zur Vorhersage?\n\n\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, \ndie Korrelation aller Prädiktoren mit der abhängigen Variablen^[die vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt] zu berechnen, s. \n<!-- @tbl-d_train_corr und -->\n@lst-get-high-corrs.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{#lst-get-high-corrs .r .cell-code  lst-cap=\"Welche Variablen korrelieren stärker als .3?\"}\nd_train %>% \n  select(-Id) %>% \n  correlation() %>%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %>%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %>%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r\n  filter(abs(r) > .3)  # nur |r| > .3\n```\n:::\n\n::: {#tbl-d_train_corr .cell layout-align=\"center\" tbl-cap='Korrelation der Prädiktoren (UV) mit der AV'}\n\n:::\n\n\n\n\n\n\n\nAha! Ein Menge Information ... Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: \nIm Zweifel einfach ignorieren. \nWenn Sie die R-Syntax nicht verstehen: \nFühren Sie die Syntax schrittweise aus. Zuerst `d_train` ausführen und das Ergebnis betrachten. \nDann `d_train %>% select(-Id)` ausführen, wieder die Ausgabe betrachten, usw.\n\nDie als Output von @lst-get-high-corrs aufgeführten Variablen sind\neinigermaßen stark mit unserer Zielvariablen `SalePrice` korreliert.\nNutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n\n\n\n#### Modell 1\n\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im Großen und Ganzen durch den Zustand der Immobilie (`OverallQual`) vorhergesagt werden kann.\nDiese Variable ist am stärksten mit der Zielvariable korreliert und ist daher ein guter Kandidat für die Vorhersage.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |      SE |                 95% CI | t(1458) |      p |\n|:-----------|:-----------:|:-------:|:----------------------:|:-------:|:------:|\n|(Intercept) |   -96206.08 | 5756.41 | (-1.07e+05, -84914.35) |  -16.71 | < .001 |\n|OverallQual |    45435.80 |  920.43 |   (43630.29, 47241.31) |   49.36 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWie gut ist das Modell?\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m1)  # aus easystats\n## [1] 48589\n```\n:::\n\n\n\n\n\n\n\nIm Schnitt liegen wir 4.54\\times 10^{4} Dollar daneben. \nOb das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\n\nR-Quadrat liefert einen anderen Blick auf die Modellgüte:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n```\n:::\n\n\n\n\n\n\n\n\n\n#### Model 2\n\n\n\nMann kann mehrere UV (Prädiktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in `lm()`:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmein_modell <- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n```\n:::\n\n\n\n\n\n\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur \"als UV nimm UV1 und UV2 und ...\". \n\n\nBerechnen wir als nächstes ein Modell mit mehreren UV, `m2`.\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2 <- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n```\n:::\n\n\n\n\n\n\n\n\n@tbl-m2-params zeigt die Koeffizienten von `m2`. \n\n\n\n\n\n\n\n::: {#tbl-m2-params .cell layout-align=\"center\" tbl-cap='Modellparameter von m1'}\n::: {.cell-output-display}\n\n\n|Parameter   | Coefficient |      SE |                 95% CI | t(1456) |      p |\n|:-----------|:-----------:|:-------:|:----------------------:|:-------:|:------:|\n|(Intercept) |   -98832.49 | 4842.90 | (-1.08e+05, -89332.69) |  -20.41 | < .001 |\n|OverallQual |    27104.83 | 1072.18 |   (25001.64, 29208.01) |   25.28 | < .001 |\n|GrLivArea   |       50.67 |    2.55 |         (45.67, 55.68) |   19.86 | < .001 |\n|GarageCars  |    21298.96 | 1807.06 |   (17754.23, 24843.69) |   11.79 | < .001 |\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells `m2` für die Daten von `d_train`?\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m2)\n## [1] 40566\n```\n:::\n\n\n\n\n\n\n\n\nIm Schnitt liegen unsere Vorhersagen 2.71\\times 10^{4} Dollar daneben. Ist das gut?\n\nBetrachten wir noch $R^2$:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n```\n:::\n\n\n\n\n\n\n\nOb die Modellgüte (R-Quadrat, RMSE, etc.) \"gut\" bzw. \"hoch\" ist, beantwortet man am besten *relativ*, \nalso im Vergleich zu anderen Modellen. \n\n\n\n#### Nullmodell\n\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Prädiktoren.\nMan nennt es das \"Nullmodell\".\nIn diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm0 <- lm(SalePrice ~ 1, data = d_train)\n```\n:::\n\n\n\n\n\n\n\n\nWie gut ist die Vorhersage des Nullnomdells?\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrmse(m0)\n## [1] 79415\n```\n:::\n\n\n\n\n\n\n\n\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\n\n\n\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n```\n:::\n\n\n\n\n\n\n\n\n### Vorhersagen im Test-Datensatz mit `m2`\n\nWir haben jetzt unseren Champion, `m2`.\nAlle Hoffnung ruht auf diesem Modell.\nOb die Vorhersagen im Test-Sample präzise sein werden?\nOder himmelweit daneben?\nEnttäusche uns nicht!\n\n\nHier sind die Vorhersagen:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2_pred <- predict(m2, newdata = d_test)  # <1> \nhead(m2_pred) # <2>\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n```\n:::\n\n\n\n\n\n\n1. predicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus `d_test`\n2. zeige den \"Kopf\" der Vorhersagen (`m1_pred`), d.h. die ersten paar Vorhersagen\n\n\n\nDie Vohersagen fügen wir jetzt dem Test-Sample hinzu:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nd_test <- \n  d_test %>% \n  mutate(SalePrice = m2_pred)\n```\n:::\n\n\n\n\n\n\n\n\n### Einreichen!\n\n\n#### Wir brauchen zwei Spalten: `Id` und `SalePrice`\n\n\nSo, wir haben unsere Vorhersagen!\nJetzt reichen wir diese Vorhersagen ein.\nFür die Prognosedatei (submission file) brauchen wir nur die Spalten `id` und `SalePrice`:\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm2_subm <-\n  d_test %>% \n  select(Id, SalePrice)\n```\n:::\n\n\n\n\n\n\n\n\nKaggle möchte keine fehlenden Werten in den Vorhersagen, also prüfen wir das mal:\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\" code-annotations='hover'}\n\n```{.r .cell-code}\nm2_subm %>% \n  drop_na() %>%  # <1>\n  nrow()         # <2>\n## [1] 1458\n```\n:::\n\n\n\n\n\n\n\n1. Lass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2. zähle die Anzahl der Zeilen (die noch verbleiben)\n\nDie Anzahl der Zeilen, die wir hier erhalten, ist gleich zu den Anzahl der Zeilen von `d_test`. Es gibt also keine fehlenden Werte.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnrow(d_test)\n## [1] 1459\n```\n:::\n\n\n\n\n\n\n\n\n<!-- #### Vertiefung: Fehlende Werte -->\n\n\n<!-- Angenommen wir hätten fehlende Werte bei `SalePrice`. -->\n\n<!-- Filtern wir die Spalte `SalePrice` mal nach \"ist NA\": -->\n\n<!-- ```{r} -->\n<!-- m1_subm %>% # <1) -->\n<!--   filter(is.na(SalePrice)) # <2> -->\n<!-- ``` -->\n\n<!-- Übersetzen wir die Syntax auf Deutsch: -->\n\n\n<!-- 1. Nimm zuerst die Tabelle `m1_smb` -->\n\n<!-- 2. Filter dann so, dass du nur Zeilen hast, für die gilt, \"hier ist ein NA in der Spalte `SalePrice` -->\n\n<!-- Ah, da ist er, der fehlende Wert, in Zeile 2577! -->\n<!-- Hinfort! -->\n\n<!-- Wir ersetzen die fehlenden Werte in `SalePrice` mit dem Mittelwert von `SalePrice`: -->\n\n<!-- ```{r} -->\n<!-- m1_subm_nona <- # <1> -->\n<!--   m1_subm %>%  # <2> -->\n<!--   mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE))) # <3> -->\n<!-- ``` -->\n\n<!-- Die Syntax wieder auf Deutsch: -->\n\n<!-- 1. Definiere `m1_subm_nona` wie folgt -->\n<!-- 2. Nimm `m1_subm` und dann -->\n<!-- 3. Verändere die Spalte `SalePrice` und zwar so, dass NAs ersetzt werden durch den Mittelwert von `SalePrice` -->\n\n\n<!-- Und? Gib es jetzt noch fehlende Werte? -->\n\n<!-- ```{r} -->\n<!-- m1_subm_nona %>%  -->\n<!--   filter(is.na(SalePrice)) -->\n<!-- ``` -->\n\n<!-- Nein! Die Ergebnistabelle hat null Zeilen.  -->\n<!-- \"No NA\" - Keine NAs, keine fehlenden Werte mehr. -->\n\n#### Hochladen\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.\nEs bietet sich an `write_csv` zu verwenden, da `write.csv` automatisch (ungefragt) noch eine Id-Spalte  ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. \nKaggle erwartet exakt zwei Spalten und zwar mit den Namen `Id` und `SalePrice`.\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwrite_csv(m2_subm, \"data/ames-kaggle/m1-subm.csv\")\n```\n:::\n\n\n\n\n\n\n\nUnd dann laden Sie diese Datei, `m1_subm.csv` bei Kaggle hoch und hoffen auf einen Hauptgewinn.\n\nDas Modell erzielte einen Score von *0.55521*.\n\n\n\n### Fazit\n\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt.\nSicherlich gibt es viele Ansätze, dieses Modell zu verbessern.\n\nHier sind einige Fragen, die Sie sich dazu stellen können:\n\n- Welche Prädiktoren sollte ich in das Modell aufnehmen?\n- Wie gehe ich mit fehlenden Werten um?\n- Wenn ein Prädiktor schief ist, sollte ich ihn dann log-transformieren?\n- Vielleicht sollte man manche Prädiktoren quadrieren?\n- Wie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n- ...\n\nViel Spielraum für Ihre Kreativität!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- ## Fazit -->\n<!-- TODO  -->\n\n## Aufgaben\n\n\n\nDie Webseite [datenwerk.netlify.app](https://datenwerk.netlify.app) stellt eine Reihe von einschlägigen Übungsaufgaben bereit. \nSie können die Suchfunktion der Webseite nutzen, \num die Aufgaben mit den folgenden Namen zu suchen:\n\n\n- Aussagen-einfache-Regr\n- interpret-koeff-lm\n- korr-als-regr\n- Linearitaet1a\n- lm1\n- mtcars-regr01\n- nichtlineare-regr1\n- penguins-regr02\n- regression1\n- regression1b\n- Regression3\n- Regression4\n- Regression5\n- Regression6\n- ames-kaggle1    \n    \n\nSchauen Sie sich auch weitere Aufgaben des [Datenwerks](https://sebastiansauer.github.io/Datenwerk/) an, \nvor allem mit den Tags [regression](https://sebastiansauer.github.io/Datenwerk/#category=regression) und [lm](https://sebastiansauer.github.io/Datenwerk/#category=lm).\n\n*Nicht alle Aufgaben* aus dieser Sammlung passen zum Stoff dieses Kapitels; \nvielleicht können Sie einige Aufgaben nicht lösen.\nIgnorieren Sie einfach diese Aufgaben.\n\n\n\n## Literaturhinweise\n\n@gelman_regression_2021 liefert eine deutlich umfassendere Einführung \nin die Regressionsanalyse als dieses Kapitel es tut.\nEine moderne, R-orientierte Einführung in Statistik inklusive der Regressionsanalyse findet sich bei @cetinkaya-rundel_introduction_2021.\nEin Klassiker mit viel Aha-Potenzial ist @cohen_applied_2003.\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}