[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik1",
    "section": "",
    "text": "1 Willkommen!\nStatistik und Du: Guter Fit!",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#es-geht-um-ihren-lernerfolg",
    "href": "index.html#es-geht-um-ihren-lernerfolg",
    "title": "Statistik1",
    "section": "1.1 Es geht um Ihren Lernerfolg",
    "text": "1.1 Es geht um Ihren Lernerfolg\nMeister Yoda rÃ¤t: Lesen Sie die Hinweise (AbbildungÂ 1.1).\n\n\n\n\n\n\nAbbildungÂ 1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\n\n\nQuelle: Imgflip Memengenerator\n\n1.1.1 Lernziele\n\nDie Studentis sind mit wesentlichen Methoden der explorativen Datenanalyse vertraut und kÃ¶nnen diese selbstÃ¤ndig anwenden.\nDie Studentis kÃ¶nnen gÃ¤ngige Forschungsfragen in lineare Modelle Ã¼bersetzen, diese auf echte DatensÃ¤tze anwenden und die Ergebnisse interpretieren.\n\nKurz gesagt: Das ist ein Grundkurs in Daten zÃ¤hmen.\n\n\n\nDaten zÃ¤hmen\n\n\nBildquelle: Allison Horst, CC-BY\n\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nWas lerne ich hier?\nSie lernen das Handwerk der Datenanalyse mit einem Schwerpunkt auf Vorhersage. Anders gesagt: Sie lernen, Daten aufzubereiten und aus Daten Vorhersagen abzuleiten. Zum Beispiel: Kommt ein Student zu Ihnen und sagt â€œIch habe 42 Stunden fÃ¼r die Klausur gelernt, welche Note kann ich in der Klausur erwarten?â€. Darauf Ihre Antwort: â€œAuf Basis meiner Daten und meines Modells mÃ¼sstest du eine 2.7 schreiben!â€.1. AuÃŸerdem lernen Sie, wie man die GÃ¼te einer Vorhersage auf Stichhaltigkeit prÃ¼ft. Denn Vorhersagen kann man ja in jeder Eckkneipe oder beim Wahrsager bekommen. Wir wollen aber belastbare Vorhersagen und zumindest wissen, wie gut die Vorhersagen (von jemanden) bisher waren.\nWarum ist das wichtig?\nWir wollen nicht auf Leuten vertrauen, die behaupten, sie wÃ¼ssten, was fÃ¼r uns richtig und gut ist. Wir wollen selber die Fakten prÃ¼fen kÃ¶nnen.\nWozu brauche ich das im Job?\nDatenanalyse spielt bereits heute in vielen Berufen eine Rolle. Tendenz stark zunehmend.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse hinsichtlich quantitativ zu analysieren.\nIst Statistik nicht sehr abstrakt?\nDer Schwerpunkt dieses Kurses liegt auf Anwenden und Tun; Ã¤hnlich dem Erlernen eines Handwerks. Theorien und Abstraktionen stehen nur am Rand.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n\n\n1.1.3 Motivieren Sie mich!\nAnsprache zur Motivation\n\n\n1.1.4 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie Folgendes mitbringen:\n\nBereitschaft, Neues zu lernen\nBereitschaft, nicht gleich aufzugeben\nKenntnis grundlegender Methoden wissenschaftlichen Arbeitens\n\nWas Sie nicht brauchen, sind besondere Mathe-Vorkenntnisse.\n\n\n1.1.5 Ãœberblick\nAbb. AbbildungÂ 1.2 gibt einen Ãœberblick Ã¼ber den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Modellieren]\n      direction TB\n      M1[Verbildlichen] --&gt; Vis[Punktmodelle]\n      Vis --&gt; U[Modellguete]\n      U --&gt; G[Geradenmodelle]\n    end\n    subgraph N[Nachbereiten]\n      direction TB\n      D[Diskutieren]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\n\nAbbildungÂ 1.2: Ãœberblick Ã¼ber den Inhalt und Verlauf des Buches\n\n\n\n\n\nDas Diagramm zeigt den Ablauf einer typischen Datenanalyse. NatÃ¼rlich kann man sich auch andere sinnvolle Darstellungen dieses Ablaufs vorstellen.\n\n\n\n\n1.1.6 PDF-Version\nSie kÃ¶nnen die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Statistik1",
    "section": "1.2 Software",
    "text": "1.2 Software\nSie benÃ¶tigen R, RStudio und einige R-Pakete fÃ¼r diesen Kurs.\n\n1.2.1 Installation\nHier finden Sie Installationshinweise.\n\n\n1.2.2 Viel R (?)\nDieses Buch enthÃ¤lt â€œmittelâ€ viel R. Auf fortgeschrittene R-Techniken wurde aber komplett verzichtet. Dem einen oder der anderen AnfÃ¤nger:in mag es dennoch â€œviel Codeâ€ erscheinen. Es wÃ¤re ja auch mÃ¶glich gewesen, auf R zu verzichten und stattdessen eine â€œKlick-Softwareâ€ zu verwenden. JASP oder Jamovi sind Beispiele fÃ¼r tolle Software aus dieser Kategorie. Ich glaube aber, der Verzicht auf eine Skriptsprache (R) wÃ¤re ein schlechter Dienst an den Studentis. Mit Blick auf eine â€œHigh-Tech-Zukunftâ€ sollte man zumindest mit etwas Computer-Code vertraut sein. Auf Computercode zu verzichten erschiene mir daher fahrlÃ¤ssig fÃ¼r die â€œZukunftsfestigkeitâ€ der Ausbildung.\n\n\n\nDas sind Sie nach der LektÃ¼re dieses Buchs",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Statistik1",
    "section": "1.3 Hinweise",
    "text": "1.3 Hinweise\n\nğŸ“º YouTube-Playlists zu Statistik\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine PrÃ¼fung in diesem Modul ist jedes Semester mÃ¶glich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#prÃ¼fung",
    "href": "index.html#prÃ¼fung",
    "title": "Statistik1",
    "section": "1.4 PrÃ¼fung",
    "text": "1.4 PrÃ¼fung\nHier finden Sie Hinweise zur PrÃ¼fung.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Statistik1",
    "section": "1.5 Zum Autor",
    "text": "1.5 Zum Autor\nNÃ¤here Hinweise zum Autor dieses Buch, Sebastian Sauer, finden Sie hier. Dort gibt es auch einen Ãœberblick Ã¼ber weitere BÃ¼cher des Autors zum Themenkreis Datenanalyse.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#nomenklatur",
    "href": "index.html#nomenklatur",
    "title": "Statistik1",
    "section": "1.6 Nomenklatur",
    "text": "1.6 Nomenklatur\n\n1.6.1 Farben\nIn Gleichungen werden zum Teil Farben verwendet, diese haben folgende Bedeutung:\n\nY bzw. AbhÃ¤ngige Variable\nX bzw. UnabhÃ¤ngige Variable\ne bzw. Fehlerterm\nb0 bzw. Achsenabschnitt\nb1 bzw. Steigung (Regressionsgewicht)\nm bzw. y-Dach bzw. Modellwert\n\nIn Diagrammen werden auch Farben verwendet, die haben allerdings keine feste Bedeutung, sondern dienen der Ãœbersichtlichkeit.\n\n\n1.6.2 Griechische Buchstaben\nIn diesem Buch werden ein paar (wenige) griechische Buchstaben verwendet, die in der Statistik Ã¼blich sind.\nHÃ¤ufig werden griechische Buchstaben verwendet, um eine Grundgesamtheit (Population) zu beschreiben (die meistens unbekannt ist). Lateinische (â€œnormaleâ€) Buchstaben werden demgegenÃ¼ber verwendet, um eine Stichprobe (Datensatz, vorliegende Daten) zu beschreiben.\nTabelleÂ 1.1 stellt diese Buchstaben zusammen mit ihrer Aussprache und Bedeutung vor.\n\n\n\nTabelleÂ 1.1: Griechische Buchstaben, die in diesem Buch verwendet werden.\n\n\n\n\n\nZeichen\nAussprache\nBuchstabe\nBedeutung in der Statistik\n\n\n\n\n\\(\\beta\\)\nbeta\nb\nRegressionskoeffizent\n\n\n\\(\\mu\\)\nmÃ¼\nm\nMittelwert\n\n\n\\(\\sigma\\)\nsigma\ns\nStreuung\n\n\n\\(\\Sigma\\)\nSigma\nS\nSummenzeichen\n\n\n\\(\\rho\\)\nrho\nr\nKorrelation (nach Pearson)\n\n\n\n\n\n\nMehr griechische Buchstaben finden sich hier.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Statistik1",
    "section": "1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2024). Statistik1. https://statistik1.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren kÃ¶nnen:\n@book{sauer_statistik1,\n    title = {Statistik1},\n    rights = {CC-BY-NC},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2024},\n}\nHier ist die DOI:\n\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "Statistik1",
    "section": "1.8 Reproduzierbarkeit",
    "text": "1.8 Reproduzierbarkeit\nDie verwendeten R-Pakete sind renv dokumentiert.\nDer Quellcode ist in diesem Github-Repo dokumentiert.\nDieses Dokument wurde erzeugt am/um 2024-03-19 22:51:47.\n\n## â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2024-03-19\n##  pandoc   3.1.12.2 @ /usr/local/bin/ (via rmarkdown)\n## \n## â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  ! package     * version date (UTC) lib source\n##  P cli           3.6.2   2023-12-11 [?] CRAN (R 4.2.0)\n##  P digest        0.6.33  2023-07-07 [?] CRAN (R 4.2.0)\n##  P evaluate      0.23    2023-11-01 [?] CRAN (R 4.2.0)\n##  P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.2.0)\n##  P htmltools     0.5.7   2023-11-03 [?] CRAN (R 4.2.0)\n##  P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.2.0)\n##  P jsonlite      1.8.8   2023-12-04 [?] CRAN (R 4.2.0)\n##  P knitr       * 1.45    2023-10-30 [?] CRAN (R 4.2.1)\n##    renv          1.0.2   2023-08-15 [1] CRAN (R 4.2.0)\n##  P rlang         1.1.3   2024-01-10 [?] CRAN (R 4.2.1)\n##  P rmarkdown     2.26    2024-03-05 [?] CRAN (R 4.2.1)\n##  P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.2.0)\n##  P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n##  P xfun          0.41    2023-11-01 [?] CRAN (R 4.2.0)\n##  P yaml          2.3.8   2023-12-11 [?] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/github-repos/statistik1/renv/library/R-4.2/x86_64-apple-darwin17.0\n##  [2] /Users/sebastiansaueruser/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/fb4b0a46\n## \n##  P â”€â”€ Loaded and on-disk path mismatch.\n## \n## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#literatur",
    "href": "index.html#literatur",
    "title": "Statistik1",
    "section": "1.9 Literatur",
    "text": "1.9 Literatur\n\n\n\n\nForum, W. E. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Statistik1",
    "section": "",
    "text": "Darauf dis Studenti: â€œHpmf.â€â†©ï¸",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html",
    "href": "010-rahmen.html",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "2.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#lernsteuerung",
    "href": "010-rahmen.html#lernsteuerung",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "2.1.1 Standort im Lernpfad\nAbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\nAbbildungÂ 2.1 zeigt, dass unser Vorgehen in diesem Buch einem FlieÃŸband gleicht: Schritt fÃ¼r Schritt, in der richtigen Reihenfolge, vom Anfang bis Ende, erarbeiten wir unser â€œDatenproduktâ€.\n\n\n\n\n\nAbbildungÂ 2.1: Datenanalyse als eine Abfolge am FlieÃŸband\n\n\n\nQuelle\n\n\n2.1.2 Lernziele\n\nSie kÃ¶nnen eine Definition von Statistik wiedergeben.\nSie kÃ¶nnen eine Definition von Daten wiedergeben.\nSie kÃ¶nnen den Begriff Tidy-Daten erlÃ¤utern.\nSie kÃ¶nnen Beispiele fÃ¼r verschiedene Skalenniveaus nennen.\n\n2.1.3 Einstieg\n\nÃœbungsaufgabe 2.1 (Hallo, Statistik) Gehen Sie in eine kleine Gruppe zusammen (3-4 Personen). Stellen Sie sich anhand der Schlagworte einander vor:\n\nName\n(wissenschaftliche) Interessen\nErwartung an diesen Kurs \\(\\square\\)\n\n\n\n\n2.1.4 Erfolsgrezept\nIhren Lernerfolg kann man als von drei Faktoren abhÃ¤ngig betrachten: 1) Ihrer Lehrkraft, 2) Ihrer Mitarbeit im Unterricht und 3) Ihrem Eigenstudium zuhause (Vor- bzw. Nachbereitung des Unterrichts), s. AbbildungÂ 2.2.\n\n\n\n\n\nflowchart TD\n  subgraph Lehrkraft\n    F[\"ğŸ”¥\"]\n  end\n  subgraph A[Konzentraion im Unterricht]\n    C[\"ğŸªµ\"]\n  end\n  subgraph E[Eigenstudium]\n    D[\"ğŸŒ³\"] \n  end  \n\n\n\n\n\nAbbildungÂ 2.2: Ihr Lernerfolg besteht aus drei Komponenten: Der Lehrkraft, Ihrer Konzentration im Unterricht und Ihrer Vor- bzw. Nachbereitung zuhause.\n\n\n\n\nEine gute Lehrkraft ist wie der Funke, der eine (Lern-)Flamme entzÃ¼ndet. Aber es braucht Brennmaterial, einen Holzscheit, das ist Ihre Konzentration im Unterricht. Ein Holzscheit alleine ist aber nicht nachhaltig, es braucht viel mehr Brennmaterial, um das Feuer am Leben zu halten: Ihr Eigenstudium, das stetige, selbstÃ¤ndige BeschÃ¤ftigen mit der Materie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "href": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.2 Was ist Statistik und wozu ist sie gut?",
    "text": "2.2 Was ist Statistik und wozu ist sie gut?\n\n2.2.1 Eine Definition von Statistik\nEs gibt mehrere Definition von Statistik; hier ist eine.\n\nDefinition 2.1 (Statistik) Statistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen und beschreibt die Ungewissheit unserer SchlÃ¼sse Poldrack (2023).\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Buch werden die Begriffe Statistik, Datenanalyse und Data Science synonym verwendet.\\(\\square\\)\n\n\nHm. Vielleicht fragen wir mal ChatGPT, was es unter Statistik versteht:\n\nğŸ‘¨ Was ist Statistik? Bitte definiere verstÃ¤ndlich.\n\n\nğŸ¤– Statistik ist eine Wissenschaft, die sich mit der Sammlung, Analyse, Interpretation, PrÃ¤sentation und Ãœbertragung von Daten beschÃ¤ftigt. Ziel ist es, Muster und Trends in den Daten zu erkennen und verlÃ¤ssliche Schlussfolgerungen Ã¼ber eine grÃ¶ÃŸere Gruppe (z.B. BevÃ¶lkerung) auf der Basis einer Stichprobe (Teilmenge) zu treffen. Die Statistik hilft uns bei der Beantwortung von Fragen, indem sie uns dabei hilft, die Unsicherheit in den Daten zu messen und zu verstehen1.\n\n\nÃœbungsaufgabe 2.2 (Nutzen von Statistik) ğŸ‹ï¸â€â™€ï¸ Fragen Sie ChatGPT, was der Nutzen von Statistik ist. Diskutieren Sie die Antwort.\n\n\n\n\n\n\n\n\n\n2.2.2 Unterschiedlichkeit messen\nEine allgegenwÃ¤rtige Tatsache ist, dass die Dinge der Welt sich unterscheiden, etwa, dass Exemplare einer Gattung sich unterscheiden. So sind nicht alle Menschen gleich groÃŸ, nicht alle BÃ¼cher gleich lang oder nicht alle Tage gleich warm.\nEin zentrales Vorgehen bei statistischen Analysen ist es, die Unterschiedlichkeit der Dinge zu beschreiben, prÃ¤ziser gesagt: die Variation zu quantifizieren. Betrachten wir dazu das Beispiel in s. AbbildungÂ 2.3.\n\n\n\n\n\n\n\nAbbildungÂ 2.3: Wenig Variation in der KÃ¶rpergrÃ¶ÃŸe bei den Basketballern. Alles lange Kerle. Viel Variation bei den Schachspielern: Manche sind klein, ander groÃŸ.\n\n\n\n\nBei den Basketballern gibt es geringe Variation in der KÃ¶rpergrÃ¶ÃŸe - alle sind groÃŸ, Ã¤hnlich groÃŸ. Bei den Schachspielern gibt es (im VerhÃ¤ltnis) hohe Variation: Einige Personen sind groÃŸ, andere klein.\nDie Variation (auch â€œVariabilitÃ¤tâ€ genannt) kann man auch gut so darstellen wie in s. AbbildungÂ 2.4 gezeigt.\n\n\n\n\n\n\n\nAbbildungÂ 2.4: Die Abweichungen der einzelnen Personen von der mittleren KÃ¶rpergrÃ¶ÃŸe ihres Teams\n\n\n\n\nEine Abweichung (auch Residuum) genannt, zeigt hier die Differenz von Mittelwert und dem Wert der KÃ¶rpergrÃ¶ÃŸe bei der jeweiligen Person. Wenn wir allgemein von einer Person \\(i\\) sprechen, Das Merkmal KÃ¶rpergrÃ¶ÃŸe mit \\(X\\) bezeichnen und den Mittelwert der KÃ¶rpergrÃ¶ÃŸe als \\(\\bar{x}\\) (â€œx querâ€), dann kÃ¶nnen wir knapp und prÃ¤zise das Residuum der \\(i\\)-ten Person mit \\(r_i\\) bezeichnen und entsprechend definieren.\n\nDefinition 2.2 (Residuum) Das Residuum des Merkmals \\(X\\) der \\(i\\)-ten Beobachtung ist definiert als die Differenz vom Wert \\(x_i\\) und einem Referenzwert, etwa dem Mittelwert, \\(\\bar{x}\\):\n\\(r_i = x_i - \\bar{x}\\). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "href": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.3 Was ist das Ziel Ihrer Analyse?",
    "text": "2.3 Was ist das Ziel Ihrer Analyse?\n\n2.3.1 Arten von Zielen\n\n\n\n\n\ngraph TD\n  subgraph Ziele\n    A[beschreiben]\n    B[vorhersagen]\n    C[erklÃ¤ren]\n  end\n\n\n\n\nAbbildungÂ 2.5: Zielarten einer Datenanalyse\n\n\n\n\nBeispiele fÃ¼r die einzelnen Zielarten der Datenanalyse:\n\n\nBeschreiben: â€œWie groÃŸ ist der Gender-Paygap in der Branche X im Zeitraum Y?â€\n\nVorhersagen: Wenn ich 100 Stunden auf die Statistikklausur lernen, welche Note kann ich dann erwarten?\n\nErklÃ¤ren: Wie viel bringt mir das Lernen auf die Statistikklausur?\n\n2.3.2 Forschungsfrage\nEine Forschungsfrage ist die Leitfrage Ihrer Analyse. Sie definiert, was Sie herausfinden wollen. HÃ¤ufig sind Forschungsfragen so aufgebaut:\n\nHat X einen Einfluss auf Y?\n\nEine Forschungsfrage weist hÃ¤ufig folgende Struktur auf, s. AbbildungÂ 2.6.\n\n\n\n\n\ngraph LR\n    Input --&gt; X[hier passiert irgendwas]\n    subgraph \"Schwarze Kiste\"\n      X\n    end\n    X --&gt; Output\n\n\n\n\nAbbildungÂ 2.6: Struktur eine Forschungsfrage\n\n\n\n\n\nBeispiel 2.1 (Forschungsfrage 1) Â \n\nHat Lernen einen Einfluss auf den PrÃ¼fungserfolg? Verringert Joggen die Menge des HÃ¼ftgolds? Um welchen Betrag erhÃ¶ht sich der Umsatz, wenn wir 1000â‚¬ mehr Werbung ausgeben?\\(\\square\\)\n\n\n\nBeispiel 2.2 (Forschungsfrage 2) Nach dem Studium haben Sie bei einem groÃŸen Online-Auktionshaus angeheuert. Da Sie angaben, sich im Studium intensiv etwas mit Statistik beschÃ¤ftigt zu haben, hat man Sie in die F&E-Abteilung2 gesteckt. Heute ist es Ihre Aufgabe, Auktionen zur Spielekonsole Wii zu untersuchen, genauer gesagt, geht es um das Spiel Mariokart. Ihre Forschungsfrage lautet:\n\nWelche Produktmerkmale stehen mit einem hohen VerkaufserlÃ¶s in Zusammenhang?\\(\\square\\)\n\n\n\n2.3.3 Der Prozess der Datenanalyse\nDatenanalyse ist eine Art des ProblemlÃ¶sens. Anders gesagt, man macht es nicht zum SpaÃŸ3, sondern um ein Ziel zu erreichen, d.h. ein Problem zu lÃ¶sen. Daher analysiert man nicht gleich zu Anfang wild drauf los. ZunÃ¤chst 1) klÃ¤rt man das Problem und das Ziel. Dann 2) plant man das Vorgehen, z.B. welche Daten man erheben mÃ¶chte. Als nÃ¤chstes 3) erhebt man die Daten und bereitet sie auf. SchlieÃŸlich kann man sie 4) endlich analysieren. Aber Daten sprechen nicht fÃ¼r sich, man muss sie 5) interpretieren und SchlÃ¼sse daraus ziehen. Dazu gehÃ¶rt auch, dass man die SchwÃ¤chen der eigenen Analyse kritisch beleuchtet, vgl. AbbildungÂ 2.7. Diesen Ablauf nennt man auch das PPDAC-Modell (MacKay & Oldford, 2000):\n\nP: Problem (Problem und Ziel und Sachgegenstand verstehen)\nP: Plan (Vorgehen planen)\nD: Data (Daten erheben und aufbereiten)\nA: Analysis (Daten analysieren)\nC: Conclusions (Schlussfolgerungen ziehen; Daten interpretieren )\n\n\n\n\n\n\ngraph LR\n    Problem --&gt; Plan --&gt; Data --&gt; Analysis --&gt; Conclusions --&gt; Problem\n\n\n\n\nAbbildungÂ 2.7: Datenanalyse als Prozess: Das PPDAC-Modell\n\n\n\n\n\nBeispiel 2.3 (Aus der Forschung: Smartphone-Brain-Drain ğŸ“±ğŸ§ ğŸš«) Ward et al. (2017) untersuchten die Forschungsfrage, ob die bloÃŸe Gegenwart eines Handies (z.B. wenn es vor Ihnen auf dem Tisch liegt) dazu fÃ¼hrt, dass man abgelenkt wird und daher schlechtere kognitive Leistungen zeigt.\nLeider schreiben die Autoren Ihre Hypothese nicht glasklar, aber implizit ist obige Hypothese herauszulesen:\n\nFirst, smartphones may redirect the orientation of conscious attention away from the focal task and toward thoughts or behaviors associated with oneâ€™s phone. Prior research provides ample evidence that â€¦ this digital distraction adversely affects both performance â€¦ and enjoyment.\n\nSpÃ¤ter formulieren Sie Ihre Hypothese noch genauer:\n\nIn two experiments, we test the hypothesis that the mere presence of oneâ€™s own smartphone reduces available cognitive capacity.\n\nDie Ergebnisse unterstÃ¼tzen Ihre Hypothese, s. AbbildungÂ 2.8. Im Diagramm ist ersichtlich, dass die kognitive Leistung (Y-Achse) sowohl in der KapazitÃ¤t des ArbeitsgedÃ¤chtnisses (links) als auch in der fluiden Intelligenz (rechts) am geringsten ist, wenn das Handy auf dem Schreibtisch (Desk) liegt. Am besten ist die kognitive Leistung, wenn das Handy nicht im Raum ist.\\(\\square\\)\n\n\n\n\n\nAbbildungÂ 2.8: Handy in Sichtweite verringert die kognitiven Ressourcen\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEs ist ein hÃ¤ufiger Fehler, in der Forschungsfrage zu formulieren â€œX fÃ¼hrt zu Yâ€, aber in der Analyse keine Methode zu verwenden, die geeignet ist, kausale ZusammenhÃ¤nge aufzudecken. Es reicht nicht, dass man z.B. einen (negativen) Zusammenhang zwischen der HÃ¤ufigkeit von Smartphone-Nutzung und KonzentrationsfÃ¤higkeit findet (Schwaiger & Tahir, 2022), um zu sagen: â€œDaddeln macht dumm!â€. Es kÃ¶nnte ja z.B. auch umgekehrt sein. Platt gesagt: â€œDummheit fÃ¼hrt zu Daddelnâ€. Weitere ErklÃ¤rungen sind mÃ¶glich. Vorsicht also mit (vor)schnellen Aussagen zu kausalen AbhÃ¤ngigkeiten.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-sind-daten",
    "href": "010-rahmen.html#was-sind-daten",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.4 Was sind Daten?",
    "text": "2.4 Was sind Daten?\n\nDefinition 2.3 (Hallo, Daten) Daten kann man als eine geordnete Folge von Zeichen definieren.\\(\\square\\)\n\nDaten kommen hÃ¤ufig in Tabellenform vor; so sind sie (oft) am besten zu untersuchen, s. TabelleÂ 2.1.\n\n\n\nTabelleÂ 2.1: So sehen Daten aus.\n\n\n\n\n\n\nid\nname\nnote\n\n\n\n1\nAnna\n1.3\n\n\n2\nBerta\n2.3\n\n\n3\nCarla\n3.0\n\n\n\n\n\n\n\n\n\nDie erste Spalte id ist nur eine laufende Nummer. Sie dient dazu, die einzelnen Beobachtungen (hier Studentis) identifizieren zu kÃ¶nnen und birgt ansonsten keine Information. Beispiele fÃ¼r ID-Variablen sind z.B. Matrikulationsnummer, Personalausweisnummern oder Bestellnummern.\n\nBeispiel 2.4 (Daten zur Forschungsfrage 2) Hier ist ein Auszug der Daten zur Tabelle mariokart, s. TabelleÂ 2.2.\n\n\n\nTabelleÂ 2.2: Auszug aus der Tabelle mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n3\n20\nnew\n0.99\n4.00\n51.55\nstandard\n1580\nyes\n1\n\n\n7\n13\nused\n0.99\n3.99\n37.04\nfirstClass\n365\nyes\n1\n\n\n3\n16\nnew\n0.99\n3.50\n45.50\nfirstClass\n998\nno\n1\n\n\n3\n18\nnew\n0.99\n0.00\n44.00\nstandard\n7\nyes\n1\n\n\n1\n20\nnew\n0.01\n0.00\n71.00\nmedia\n820\nyes\n2\n\n\n3\n19\nnew\n0.99\n4.00\n45.00\nstandard\n270144\nyes\n0\n\n\n\n\n\n\n\n\nEine ErklÃ¤rung aller Variablen des Datensatzes mariokart findet sich hier. \\(\\square\\)\n\n\nDefinition 2.4 (Data Dictionary) Eine ErklÃ¤rung, was die Namen einer Datentabelle bedeuten, nennt man Code Book or Data Dictionary.\\(\\square\\)\n\n\n2.4.1 Was ist eine Variable?\n\nDefinition 2.5 (Variable) Eine Variable ist ein Platzhalter, der fÃ¼r ein Merkmal steht, das verschiedene Werte annehmen kann.\\(\\square\\)\n\nMan kann sich eine Variable wie einen BehÃ¤lter vorstellen, auf dem mit einem Stift geschrieben steht, was fÃ¼r eine Art Inhalt darin ist, s. AbbildungÂ 2.9.\n\n\n\n\n\nAbbildungÂ 2.9: Wir definieren eine Variable â€œtempâ€ mit dem Inhalt â€œ9â€\n\n\n\n2.4.2 Beobachtungseinheit\n\nDefinition 2.6 (Beobachtungseinheit) Beobachtungseinheiten sind die Dinge, die wir untersuchen (beobachten). Beobachtungseinheiten sind die TrÃ¤ger von Variablen.\\(\\square\\)\n\nIn TabelleÂ 2.1 gibt es drei Variablen: id, Name und Note. Es gibt auch drei Beobachtungseinheiten: Anna, Berta und Carla.\n\n2.4.3 Wert\n\nDefinition 2.7 (Wert) Ein Wert ist der Inhalt einer Variablen.\\(\\square\\)\n\nIn AbbildungÂ 2.9 ist der Wert von temp 9. In TabelleÂ 2.1 hat die Variable name drei Elemente: Anna, Berta, Carla. Der Wert des 2. Elements ist Berta.\n\nDefinition 2.8 Als AusprÃ¤gungen bezeichnet man die verschiedenen Werte einer Variablen. \\(\\square\\)\n\n\nBeispiel 2.5 In einer Studie wurden zehn Probanden untersucht. Die Variable geschlecht dokumentiert die Geschlechter der Personen:\n\ngeschlecht &lt;- c(\"Mann\", \"Frau\", \"Frau\", \"Frau\", \"Mann\",\n                \"Frau\", \"Mann\", \"Mann\", \"divers\", \"Frau\")\ngeschlecht\n##  [1] \"Mann\"   \"Frau\"   \"Frau\"   \"Frau\"   \"Mann\"   \"Frau\"   \"Mann\"   \"Mann\"  \n##  [9] \"divers\" \"Frau\"\n\nIn dieser Variable (die aus 10 Werten besteht) finden sich drei AusprÃ¤gungen: divers, Frau, Mann.\\(\\square\\)\n\n\n\n\n\n\n\nTipp\n\n\n\nGerade haben Sie etwas Computer-Syntax gesehen, genauer gesagt, Befehle aus der Programmiersprache R. Bisher haben wir diese Befehle nicht kennengelernt. Sie verstehen Sie vermutlich (nicht ganz). Ignorieren Sie diese Befehle einfach erstmal.\n\n\n\n2.4.4 Tidy-Data\n\nDefinition 2.9 Unter Tidy-Data (tidy data, â€œNormalformâ€) versteht man eine Tabelle, in der jede Zeile eine Beobachtungseinheit darstellt, jede Spalte eine Variable und jede Zelle der Tabelle einen Wert, s. AbbildungÂ 2.10 (a). (ZusÃ¤tzlich ist noch eine â€œKopfzeileâ€ erlaubt, in der die Namen der Variablen stehen.)\\(\\square\\)\n\nTabelleÂ 2.1 ist ein Beispiel fÃ¼r Tidy-Data. AbbildungÂ 2.10 (a) zeigt ein Sinnbild fÃ¼r Tidy-Data (Wickham & Grolemund, 2018). Und AbbildungÂ 2.10 (b) erlÃ¤utert das Tidy-Prinzip genauer.\n\n\n\n\n\n\n\n\n\n(a) Tidy-Data-Sinnbild. Image Credit: Hadley Wickham\n\n\n\n\n\n\n\n\n\n(b) Was ist Tidy-Data?. Image Credit: Allision Horst\n\n\n\n\n\n\nAbbildungÂ 2.10: Stay Tidy!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nFÃ¼r eine statistische Analyse ist es oft sinnvoll, dass die Daten im Tidy-Format vorliegen.\n\n\nDer Vorteil des Tidy-Formats ist es, dass man weiÃŸ, wie die Daten aufgebaut sind. AuÃŸerdem kÃ¶nnen Statistikprogramme oft mit dieser Form am besten umgehen, s. AbbildungÂ 2.11.\n\n\n\n\n\nAbbildungÂ 2.11: Immer schÃ¶n Ordnung haltenâ€¦ Image credit: Allision Horst\n\n\n\nQuelle\n\nDas Tidy-Format wird auch als â€œlangesâ€ Format bezeichnet.\nAbbildungÂ 2.12 zeigt einen Datensatz in der â€œlangenâ€ Form, also tidy, und den gleichen Datensatz, umformatiert in der â€œbreitenâ€ Form, nicht-tidy.\n\n\n\n\n\nAbbildungÂ 2.12: Links: Eine Tabelle mit Format â€œwideâ€ - nicht â€œtidyâ€. Rechts: Das â€œLangformatâ€ (â€œlongâ€) ist â€œtidyâ€.\n\n\nQuelle: Garrick Aden-Buie, 2018, CC0-1.0 license, https://www.garrickadenbuie.com/project/tidyexplain/\n\n\n\n\n\n\nTipp\n\n\n\nIn vielen Organisationen werden Exceltabellen fÃ¼r bestimmte Zwecke der Datenverarbeitung verwendet. Excel4 hat bestimmte StÃ¤rken und Vorteile, aber auch gewisse Nachteile und SchwÃ¤che; das liegt z.T. daran, dass Excel fÃ¼r bestimmte Aufgaben besser und fÃ¼r andere weniger gut geeignet ist. Wenn man mit Excel arbeitet, wiederholen sich erfahrungsgemÃ¤ÃŸ immer wieder die gleichen Fehler bzw. suboptimalen Vorgehensweise zum Aufbau einer Exceltabelle.\nDieser Artikel von Broman & Woo (2018) zeigt anhand einiger praktischer Tipps, wie man Exceltabellen so aufbaut, dass Fehler minimiert werden.\n\n\n\nÃœbungsaufgabe 2.3 (Sind wir sÃ¼chtig nach dem Handy?) Sind Sie sÃ¼chtig nach Ihrem Handy? Lassen Sie uns eine kleine Studie dazu live im HÃ¶rsaal durchfÃ¼hren. FÃ¼llen Sie diese Umfrage zum Thema Smartphonse-Sucht aus (anonym und kein Muss). Wir werden die Daten spÃ¤ter zusammen aus. \\(\\square\\)\n\n\n2.4.5 Je mehr, desto besser (?)\nWas Daten betrifft, kÃ¶nnte man behaupten: â€œViel hilft vielâ€ oder â€œJe mehr, desto besserâ€. NatÃ¼rlich unter sonst gleichen UmstÃ¤nden5. Viel DatenmÃ¼ll ist natÃ¼rlich nicht besser als ein paar knappe, wasserdichte Fakten!\n\nBeispiel 2.6 Um Ihre eigene LehraktivitÃ¤t zu organisieren, wollen Sie sich ein Bild machen, wie viel Ihre Nebensitzer im HÃ¶rsaal so lernen. Sie blicken nach links und fragen â€œwie viel lernst du so?â€. Sie blicken nach recht und wiederholen die Frage gerichtet an den rechtsnebensitzenden Kommilitonen. Dann addieren Sie die zwei Zahlen (unter der Annahme, dass Sie zwei Zahlen bekommen haben), und teilen durch zwei, um den Mittelwert zu erhalten.\nEin kritischer Geist kÃ¶nnte anmerken, dass Sie besser die Untersuchung nicht gemacht hÃ¤tten (auch wenn Sie, vielleicht ohne zu wollen, eine statistische Untersuchung angestellt haben). Denn bei so wenig befragten Personen ist die Ungenauigkeit Ihrer SchÃ¤tzung der typischen Lernzeit bei Studentis einfach zu hoch.\\(\\square\\)\n\nAbbildungÂ 2.13 veranschaulicht, dass man einen Mittelwert genauer schÃ¤tzen kann, wenn man auf eine grÃ¶ÃŸere Stichprobe zurÃ¼ckgreift. Das Teilbild links zeigt den Mittelwert einer Stichprobe mit \\(n=20\\) Beobachtungen. Das Teilbild rechts zeigt den Mittelwert einer Stichprobe mit \\(n=200\\) Beobachtungen (jeweils aus der gleichen Grundgesamtheit). Wie man sieht, ist im linken Teilbild die Streuung (Variation) hÃ¶her als im rechten Teilbild:\n\n\n\n\n\nAbbildungÂ 2.13: SchÃ¤tzgenauigkeit als Funktion der StichprobengrÃ¶ÃŸe: Die vertikale Linie zeigt den wahren Mittelwert. Kleinere Stichproben-Mittelwerte schanken (variieren) mehr um den Mittelwert herum als grÃ¶ÃŸere Stichproben.\n\n\nBildquelle: Karsten LÃ¼bke\n\n\n\n\n\n\nWichtig\n\n\n\nMehr Daten = genauere Ergebnisse (unter sonst gleichen UmstÃ¤nden) \\(\\square\\)\n\n\n\nÃœbungsaufgabe 2.4 (Live-Experiment zum Effekt der StichprobengrÃ¶ÃŸe) In diesem Live-Experiment untersuchen wir den Effekt der StichprobengrÃ¶ÃŸe auf die Streuung des Mittelwerts in der Stichprobe. Streuen die Ergebnisse mehr in kleinen Stichproben als in groÃŸen? Probieren wir es aus!\nIn diesem Experiment werfen Sie (in kleinen Gruppen) eine MÃ¼nze (auf faire Art und Weise) und notieren das Ergebnis (Kopf oder Zahl). Uns interessiert dabei die Frage, ob die Ergebnisse bei kleinen Stichproben (n=5 MÃ¼nzwÃ¼rfe) anders streuen als in groÃŸen Stichproben (n=20 MÃ¼nzwÃ¼rfe).\nSie brauchen nur experimentierfreudige Partner (Kleingruppen mit 2-4 Personen), eine faire MÃ¼nze und dann kannâ€™s los gehen! Klicken Sie hier, um mit dem Experiment zu starten\nDie Daten aller Versuche kÃ¶nnen Sie hier einsehen. \\(\\square\\)\n\n\nBeispiel 2.7 (Dorfschulen machen die schlauesten SchÃ¼ler!) In einer Pressemitteilung sei zu lesen, dass die besten SchÃ¼ler in den Dorfschulen zu finden seien6. Mit etwas Recherche finden Sie heraus, dass diese Aussage fÃ¼r belastbaren Daten beruht: TatsÃ¤chlich sind die Notendurchschnitte auf den kleinen Dorfschulen deutlich besser als in den groÃŸen Schulen in der Stadt. Also stimmt die Behauptung der Pressemitteilung? Die gute Landluft lÃ¤sst das Hirn wachsen? Sie recherchieren noch etwas weiter in den Daten. Dann fÃ¤llt Ihnen auf: Die schlechtesten SchÃ¼ler kommen auch aus den Dorfschulen! Eine statistische ErklÃ¤rung bietet sich an: In den Dorfschulen gibt es nur wenig Kinder und kleine Klassen â€“ die Stichproben sind also klein. Bei kleinen Stichproben gibt es viel Variation um den Mittelwert herum, s. AbbildungÂ 2.13, und zwar nach oben (guter Notenschnitt) und nach unten (schlechter Notenschnitt). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#sec-arten-variablen",
    "href": "010-rahmen.html#sec-arten-variablen",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.5 Arten von Variablen",
    "text": "2.5 Arten von Variablen\n\n2.5.1 Nach Position in der Forschungsfrage\nAngenommen, Ihre Forschungsfrage lautet:\n\nHat Lernen einen Einfluss auf den PrÃ¼fungserfolg?\n\nIn dem Fall gilt:\n\n\nLernen ist die Inputvariable/X-Variable/Ursache/unabhÃ¤ngig Variable (UV)\n\nPrÃ¼fungserfolg ist die Outputvariable/Y-Variable/Wirkung/abhÃ¤ngige Variable (AV)\n\nAbbildungÂ 2.14 stellt diese beiden â€œPositionenâ€ einer Variable dar. Die erste Position ist vor dem Pfeil. Die zweite Position ist nach dem Pfeil.\n\n\n\n\n\ngraph LR\n    Input --&gt; Output\n    X --&gt; Y\n    P[PrÃ¤diktor] --&gt; K[Kriterium]\n    Ursache --&gt; Wirkung\n    UV[unabhÃ¤ngige Variable] --&gt; AV[abhÃ¤ngige Variable]\n\n\n\n\nAbbildungÂ 2.14: Synonyme Bezeichnungen fÃ¼r Input- und Output-Variablen einer Forschungsfrage\n\n\n\n\n\nÃœbungsaufgabe 2.5 Ãœberlegen Sie sich eine Forschungsfrage, die eine UV und eine AV enthÃ¤lt. Sagen Sie einer/em Kommilitonen diese Forschungsfrage und fragen Sie, was die UV und die AV ist. Bei richtiger Antwort belohnen Sie groÃŸzÃ¼gig. \\(\\square\\)\n\n\n2.5.2 Nach dem Skalenniveau\n\nDefinition 2.10 Der Begriff Skalenniveau wird verwendet, um die Art und Menge der Information, die in Variablen enthalten ist, zu benennen. Diese Klassifikation basiert auf den Eigenschaften der Daten und den mathematischen Operationen, die sinnvoll auf diese Daten angewendet werden kÃ¶nnen. \\(\\square\\)\n\nAbbildungÂ 2.15 gibt einen Ãœberblick Ã¼ber typisch verwendete Skalenniveaus.\n\n\n\n\n\ngraph TD\n    Variablen --&gt; qualitativ\n    Variablen --&gt; quantitativ\n    qualitativ --&gt; nominal\n    qualitativ --&gt; ordinal\n    quantitativ --&gt; Intervallniveau\n    quantitativ --&gt; VerhÃ¤ltnisniveau\n\n\n\n\nAbbildungÂ 2.15: Skalenniveaus\n\n\n\n\n\n2.5.3 Beispiele fÃ¼r Skalenniveaus\nBeispiele zu den Skalenniveaus sind in TabelleÂ 2.3 aufgefÃ¼hrt. \\(\\square\\)\n\n\n\nTabelleÂ 2.3: Beispiele fÃ¼r Skalenniveaus\n\n\n\n\nVariable\nSkalenniveau\n\n\n\nHaarfarbe\nNominalskala\n\n\nAugenfarbe\nNominalskala\n\n\nGeschlecht\nNominalskala\n\n\nAutomarke\nNominalskala\n\n\nPartei\nNominalskala\n\n\nLieblingsessen\nOrdinalskala\n\n\nMedaillen beim 100-Meter-Lauf\nOrdinalskala\n\n\nUniranking\nOrdinalskala\n\n\nIQ\nIntervallskala\n\n\nExtraversion\nIntervallskala\n\n\nTemperatur in Celcius\nIntervallskala\n\n\nTemperatur in Fahrenheit\nIntervallskala\n\n\nTemperatur in Kelvin\nVerhÃ¤ltnisskala\n\n\nKÃ¶rpergrÃ¶ÃŸe\nVerhÃ¤ltnisskala\n\n\nGeschwindigkeit\nVerhÃ¤ltnisskala\n\n\nLÃ¤nge\nVerhÃ¤ltnisskala\n\n\n\n\n\n\n\n\nJe nach dem, Ã¼ber welches Skalenniveau eine Variable verfÃ¼gt, sind verschiedenen Rechenoperationen erlaubt, s. tbl-skalenniveaus .\n\n\n\nTabelleÂ 2.4: Erlaubte Rechenoperationen nach Skalenniveau\n\n\n\n\nSkalenniveau\nQuantitativ\nâ‰ \nâ‰¼\n+\nÃ—\n\n\n\nNominalniveau\nnein\nâœ…\nâŒ\nâŒ\nâŒ\n\n\nOrdinalniveau\nnein\nâœ…\nâœ…\nâŒ\nâŒ\n\n\nIntervallniveau\nja\nâœ…\nâœ…\nâœ…\nâŒ\n\n\nVerhÃ¤ltnisniveau\nja\nâœ…\nâœ…\nâœ…\nâœ…\n\n\n\n\n\n\n\n\nWas soll das bedeuten, â€œRechenoperationenâ€?\nSchauen wir uns fÃ¼r jedes Skalenniveau ein â€œRechenbeispielâ€ an.\nNominalskala: Die Variable Geschlecht ist nominalskaliert. Das bedeutet, dass ihre AusprÃ¤gungen Frau und Mann z.B. nicht (sinnvoll) addiert oder sonstwie â€œverrechnetâ€ werden kÃ¶nnen. Man kÃ¶nnte, z.B. um das Eintippen zu erleichtern, Frauen mit 1 kodieren und MÃ¤nner mit 2. Damit darf man aber nicht rechnen! Nicht addieren, multiplizieren â€¦ Es macht keinen Sinn zu sagen: â€œIch habe eine Frau und einen Mann in meiner Tabelle, das ist im Schnitt ein diverses Geschlecht, weil der Mittelwert von 1 und 2 ist 1,5!â€\nDie einzige â€œRechenoperationâ€, die man auf der Nominalskala machen darf, ist die PrÃ¼fung auf Gleichheit: Mann kann feststellen, ob ein Objekt gleich zu einem anderen ist oder unterschiedlich. Also ob zwei Personen das gleiche Geschlecht haben oder von unterschiedlichem Geschlecht sind. Anders ausgedrÃ¼ckt:\n\nğŸ‘© \\(\\ne\\) ğŸ‘¨\nğŸ‘© \\(=\\) ğŸ‘©\nğŸ‘¨ \\(=\\) ğŸ‘¨\n\nOrdinalskala: Diese Skala entspricht einer Rangordnung. Eine Rangordnung ist etwa die geordnete Abfolge Ihres Leibgerichte7. Etwas â€œformalerâ€ ausgedrÃ¼ckt:\n\nğŸ• \\(\\succ\\) ğŸ \\(\\succ\\) ğŸ¥©\n\nDas komische Zeichen \\(\\succ\\) soll heiÃŸen: â€œIst auf meiner Liste von Leibgerichten weiter oben, mag ich lieberâ€. Man kann aber nicht sagen, â€œIch mag aber Pizza um 42% mehr als die Spagetthi und die wieder um 73% mehr als ein Schnitzel!â€. Zumindest kann man das nicht ohne weitere Informationen und Annahmen. Es gibt also Dinge auf der Welt, die man leicht in eine Rangordnung bringen kann, aber die man nur schwer in der GrÃ¶ÃŸe der Unterschiede bemessen kann. Das ist die Ordinalskala.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Ordinalskale erlaubt, Objekte zu ordnen (hinsichtlich eines Merkmals). Die AbstÃ¤nde zwischen den Objekten kÃ¶nnen nicht quantifiziert werden. \\(\\square\\)\n\n\nIntervallskala: Das ist vielleicht eine Ãœberraschung fÃ¼r Sie: Wenn es heute 10Â°C hat und morgen 5Â°C â€“ dann ist es heute nicht doppelt so warm wie morgen. Ja, 10 ist das Doppelte von 5. Aber 10Â° Celcius ist nicht doppelt so warm wie 20Â° Celcius. Wenn Sie das verwundert: Das ist normal, so geht es vielen Leuten, wenn sie das zum ersten Mal hÃ¶ren. Der Grund, dass es nicht erlaubt ist, VerhÃ¤ltnisse (wie doppelt/halb so viel etc.) auf der Celcius-Skala zu bilden, ist, dass der Nullpunkt der Skala, 0Â° C, kein echter, physikalischer Nullpunkt ist. Bei 0Â° C liegt eben nicht Null WÃ¤rmeenergie vor. Stattdessen wurde eine WÃ¤rmenergiemenge gewÃ¤hlt, die fÃ¼r uns Menschen ganz praktisch, da augenfÃ¤llig ist: der Gefrierpunkt von Wasser. Was bei der Intervallskala erlaubt ist, ist das Addieren (und Subtrahieren): heute 10Â°C, morgen 5Â°C, das ist ein Unterschied von 5Â°C. Oder: Im Schnitt waren es 7,5Â°C, das ist genau in der Mitte von 5 und 10Â°C. AbbildungÂ 2.16 versinnbildlicht die Intervallskala.\n\n\n\n\n\n\n\nAbbildungÂ 2.16: Ein MetermaÃŸ steckt im Wasser. Auf dem MetermaÃŸ kÃ¶nnen wir die aufgedruckten Zahlen ablesen. Aber wir wissen nicht, ob der MetermaÃŸ auf dem Boden steht. Wir wissen demnach nicht, ob der vom MetermaÃŸ angegebene Nullpunkt der wahre Nullpunkt (Meeresboden) ist.\n\n\n\n\nVerhÃ¤ltnisskala: Eine VerhÃ¤ltnisskala ist das, was man sich gemeinhin unter einer metrische Variable vorstellt: Man kann â€œnormalâ€ rechnen, alle Rechenoperationen sind erlaubt. ZuzÃ¼glich zu denen, die auch in anderen, â€œniedrigerenâ€ Skalenniveaus erlaubt sind, ist das das Bilden von VerhÃ¤ltnissen - Multiplizieren, s. AbbildungÂ 2.17.\n\n\n\n\n\n\n\nAbbildungÂ 2.17: Puh! Der rote Flitzer ist 10 Mal so teuer wie die blaue MÃ¶hre. Kohlen zusammenkratzen.\n\n\n\n\nIn diesem Video gibt es noch ausfÃ¼hrlichere ErklÃ¤rung zum Thema Skalenniveaus.\n\nAuÃŸerdem kÃ¶nnen quantitative Variablen untergliedert werden in:\n\n\nstetige Variablen, das sind Variablen, bei denen man zwischen zwei AusprÃ¤gungen immer noch eine weitere quetschen kann. So gibt es eine Wert fÃ¼r die KÃ¶pergrÃ¶ÃŸe zwischen 1.60â€¯m und 1.61â€¯m. Und einen Wert zwischen 1.601â€¯m und 1.602â€¯m, etc.\ndiskrete Variablen, das sind metrische Variablen, die nur bestimmte AusprÃ¤gungen haben, hÃ¤ufig sind das die natÃ¼rlichen Zahlen: \\(1,2,...\\). Ein Beispiel wÃ¤re die Anzahl der Kinder in einer Familie.\n\n\n\n\n\n\n\nTipp\n\n\n\nFragen nach Skalenniveaus gehÃ¶ren zu den LieblingsprÃ¼fungsfragen in diesem Themenbereich. Sie sind gut beraten, sich gerade mit dieser Frage intensiver zu beschÃ¤ftigen. Auch in thematisch angrenzenden FÃ¤chern wird immer wieder die Frage nach dem Skalennvieau aufgeworfen. Das zeigt natÃ¼rlich auch die hohe Relevanz des Themas.\n\n\n\nÃœbungsaufgabe 2.6 Ãœberlegen Sie sich fÃ¼r einige Variablen die Skalenniveaus und befragen Sie dann eine:n Kommilitonen dazu. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#modelle",
    "href": "010-rahmen.html#modelle",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.6 Modelle",
    "text": "2.6 Modelle\nWoran denken Sie beim Wort â€œModellâ€? Vielleicht an Spielzeugautos, s. AbbildungÂ 2.18.\n\n\n\n\n\nAbbildungÂ 2.18: Matchbox-Autos sind Modelle fÃ¼r Autos\n\n\n\nDefinition 2.11 (Modelle) Modelle sind ein vereinfachtes Abbild der RealitÃ¤t eine ReprÃ¤sentation (Kaplan, 2009).\\(\\square\\)\n\n\nBeispiel 2.8 (Beispiele fÃ¼r Modelle) Puppen sind Modelle fÃ¼r Babies, Landkarten fÃ¼r Landstriche und das Atommodell von Nils Bohr ist ein Modell fÃ¼r Atome.\\(\\square\\)\n\nAuch in der Statistik nutzen wir Modelle. Helfen Sie Prof.Â Weiss-Ois: Er blickt nicht durch. Gerne wÃ¼rde er wissen, wie viele Stunden seine Studentis auf die PrÃ¼fung lernen. Aber mit so vielen Zahlen kann er nicht umgehen â€¦ Geben Sie ihm ein Modell: Sagen Sie ihm, wie lang die Studis typischerweise lernen (sagen Sie ihm ein einfach den Mittelwert der Lernzeiten).\n\n\n\n2.6.1 Vorher\n12, 8, 10, 11, 10, 9, 13, 9, 14, 9, 12, 14, 7, 9, 9, 11, 9, 4, 5, 12, 9, 6, 9, 12, 13, 9, 9, 6, 10, 8\n\n\nOh jeh, so viele Zahlen! Ich check nix! Wie viel lernen denn jetzt meine Studis?!\n\n\n\n\n\n\n2.6.2 Nachher\n\n9.6\n\n \n\n\nYeah, jetzt weiÃŸ ich, wie viel die Studis so typischerweise lernen. Viel zu wenig natÃ¼rlich!\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\nDer Nutzen von Modellen ist, dass sie komplexe Sachverhalte vereinfachen und damit oft Ã¼berhaupt erst dem VerstÃ¤ndnis oder einer Untersuchung zugÃ¤nglich machen: Modelle ermÃ¶glichen VerstÃ¤ndnis. In der Datenanalyse bzw. Statistik8 fassen Sie oft viele Daten prÃ¤gnant zusammen, z.B. zu einer einzelnen Kennzahl. Das VerrÃ¼ckte an Modellen ist, dass man Informationen wegwirft, um eine (andere, hoffentlich nÃ¼tzlichere) Information zu bekommen (Stigler, 2016). Weniger ist mehr?!",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#praxisbezug",
    "href": "010-rahmen.html#praxisbezug",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.7 Praxisbezug",
    "text": "2.7 Praxisbezug\nWir leben im Datenzeitalter; Daten durchdringen alle Bereiche des beruflichen, gesellschaftlichen und privaten Lebens. Die Datenanalyse hat sich in den letzten Jahren massiv verÃ¤ndert, s. AbbildungÂ 2.19.\n\n\n\n\n\nAbbildungÂ 2.19: Forschung frÃ¼her und heute\n\n\nDiese Entwicklung ist durchaus auch kritisch zu betrachten. Mit der wachsenden Bedeutung von Daten wÃ¤chst in gleichem MaÃŸe die Bedeutung von Datenanalyse. Denn Daten ohne Sinn sind nutzlos. Aus diesem Grund kann man sagen, dass Datenanalyse (und damit auch Statistik als eine spezielle Art von Datenanalyse) zu stark nachgefragten Jobs gehÃ¶ren.\nLaut dem Entgeltatlas der Bundesagentur fÃ¼r Arbeit liegt ein typisches Gehalt von Data Scientisten bei knapp 6000 â‚¬ pro Monat (in der Altersgruppe von 25 bis 54)9. Laut dem Gehaltsreporter liegt das Einstiegsgehalt dieser Berufsgruppe bei knapp 50.000â‚¬ pro Jahr.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "010-rahmen.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.8 Wie man mit Statistik lÃ¼gt",
    "text": "2.8 Wie man mit Statistik lÃ¼gt\nDas File-Drawer-Problem: Sie haben ein tolles Experiment durchgefÃ¼hrt, viel Arbeit, viel Stress, endlich geschafft, puh. Von den 20 Variablen (als AV, s. Kapitel 2.5), die Sie untersucht haben, zeigt nur 1 einen interessanten Effekt, leider. 1 von 20, das hÃ¶rt sich nicht so toll an. WÃ¤re es da nicht â€œelegantâ€, die 19 Variablen ohne schÃ¶nen Effekt einfach in der Schublade liegen zu lassen bis zum Sankt-Nimmerleins-Tag? Dann kÃ¶nnten Sie stattdessen als Ergebnis nur die eine Variable mit schÃ¶nen Ergebnis prÃ¤sentieren, ganz ohne widersprechende Befunde.\nDieser Versuchung nicht zu erliegen, kann schwer sein. Es ist aber gefÃ¤hrlich, missliebige Ergebnisse zu verschweigen: Die anderen Menschen bekommen dann ein falsches Bild der Ergebnislage; man spricht von Publikationsbias. Wer Ergebnisse verschweig, verzerrt die insgesamte Befundlage (Rothstein, 2014).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#fazit",
    "href": "010-rahmen.html#fazit",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.9 Fazit",
    "text": "2.9 Fazit\nDie Aufgabe von Statistik ist es, durch Zusammenfassen von Daten Modelle zu bilden, die es uns einfacher machen, schwierige Sachverhalte zu verstehen. Zentral ist dabei, die Analyse von VariabilitÃ¤t der Daten. Daten kommen in verschiedenen Varianten vor, typischerweise in Tabellenform, mÃ¶glichst im Tidy-Format.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#aufgaben",
    "href": "010-rahmen.html#aufgaben",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nvariation01\nDef-Statistik01\ntidy1\nSkalenniveau1a\nZiele-Statistik\nvariation02\nSkalenniveau1b\ntidydata1",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#vertiefung",
    "href": "010-rahmen.html#vertiefung",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.11 Vertiefung",
    "text": "2.11 Vertiefung\nFassen Sie den Artikel von Broman & Woo (2018) zusammen.\nInspiration von einer Praktikerin der Datenanalyse: Caitlin Hudon verrÃ¤t in diesem Video, welche Fehler Sie sie in in den acht Jahren ihrer Berufserfahrung gemacht hat und was sie daraus gelernt hat.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literaturhinweise",
    "href": "010-rahmen.html#literaturhinweise",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.12 Literaturhinweise",
    "text": "2.12 Literaturhinweise\nEinen Einblick in die Fundamente statistischer Analyse bietet Stigler (2016). Ã‡etinkaya-Rundel & Hardin (2021), stellen grundlegende Konzepte der Analyse von Daten im Kapitel 1, â€œHello dataâ€, vor. Downey (2023) illustriert statistische Ãœberraschungsmoment auf unterhaltsame, und vor allem: sofataugliche Art.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literatur",
    "href": "010-rahmen.html#literatur",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.13 Literatur",
    "text": "2.13 Literatur\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization in Spreadsheets. The American Statistician, 72(1), 2â€“10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nÃ‡etinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific Method, Statistical Method and the Speed of Light. Statistical Science, 15(3), 254â€“278. https://doi.org/10.1214/ss/1009212817\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley StatsRef: Statistics Reference Online. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSchwaiger, E., & Tahir, R. (2022). The Impact of Nomophobia and Smartphone Presence on Fluid Intelligence and Attention. Cyberpsychology: Journal of Psychosocial Research on Cyberspace, 16(1). https://doi.org/10.5817/CP2022-1-5\n\n\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press.\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain Drain: The Mere Presence of Oneâ€™s Own Smartphone Reduces Available Cognitive Capacity. Journal of the Association for Consumer Research, 2(2), 140â€“154. https://doi.org/10.1086/691462\n\n\nWickham, H., & Grolemund, G. (2018). R FÃ¼r Data Science: Daten Importieren, Bereinigen, Umformen, Modellieren Und Visualisieren (F. Langenau, Ãœbers.; 1. Auflage). Oâ€™Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#footnotes",
    "href": "010-rahmen.html#footnotes",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "Release 2023-Janâ†©ï¸\nForschung und Entwicklungâ†©ï¸\njedenfalls nicht alle von unsâ†©ï¸\nund Ã¤hnliche Programmeâ†©ï¸\nCeteris paribus, auf Latein, hÃ¶rt sich gleich viel schlauer anâ†©ï¸\nDas ist eine fiktive Geschichteâ†©ï¸\n1. Pizza, 2. Spagetthi, 3. Schnitzelâ†©ï¸\ndie beiden Begriffe werden hier weitgehend synonym gebrauchtâ†©ï¸\nAbrufdatum: 1.2.23â†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "020-R.html",
    "href": "020-R.html",
    "title": "\n3Â  Daten einlesen\n",
    "section": "",
    "text": "3.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#lernsteuerung",
    "href": "020-R.html#lernsteuerung",
    "title": "\n3Â  Daten einlesen\n",
    "section": "",
    "text": "3.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n3.1.2 Lernziele\n\nSie kÃ¶nnen R und RStudio starten.\nSie kÃ¶nnen R-Pakete installieren und starten.\nSie kÃ¶nnen Variablen in R zuweisen und auslesen.\nSie kÃ¶nnen Daten in R importieren.\nSie kÃ¶nnen den Begriff Reproduzierbarkeit definieren.\n\n3.1.3 Ãœberblick\nAbbildungÂ 1.2 zeigt Ihnen, wo auf unserer Reise durch die Datenanalyse sich dieses Kapitels verorten lÃ¤sst.\nAbbildungÂ 3.1 zeigt den typischen Lernverlauf in Zusammenhang mit Datenanalyse (und R) an: Es gibt HÃ¶hen und Tiefen. Die wechseln sich ab. Das ist ganz normal!\n\n\n\n\n\nAbbildungÂ 3.1: Life is a roller-coaster. You just have to ride it. Image credit: Allison Horst\n\n\n\nQuelle\n\n\n3.1.4 Ab diesem Kapitel benÃ¶tigen Sie R\nBitte stellen Sie sicher, dass Sie R rechtzeitig einsatzbereit haben. Weiter unten in diesem Kapitel finden Sie Installationshinweise. Falls Sie dieses Kapitel zum ersten Mal bzw. sich noch nicht mir R auskennen, werden Sie vielleicht einigen Inhalten begegnen, die Sie noch nicht gleich verstehen. Keine Sorge, das ist normal. Mit etwas Ãœbung wird Ihnen bald alles schnell von der Hand ghen.\n\n3.1.5 BenÃ¶tigte R-Pakete\n\nlibrary(openintro)  # Datensatz `mariokart`\n\n\n3.1.6 BenÃ¶tigte Daten\nSie benÃ¶tigen den Datensatz mariokart, der entweder Ã¼ber diese Internetadresse oder Ã¼ber R-Paket openintro importiert werden kann:\n\n3.1.6.1 Import via Download\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n3.1.6.2 Import via R-Paket\n\ndata(mariokart, package = \"openintro\")  # Das Paket muss installiert sein\n\n\n3.1.7 Begleitvideos\nSchauen Sie sich mal in dieser Playlist um, dort finden Sie einige Videos zum Thema R.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errrstkontakt",
    "href": "020-R.html#errrstkontakt",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.2 Errrstkontakt",
    "text": "3.2 Errrstkontakt\n\n3.2.1 Warum R?\nGrÃ¼nde, die fÃ¼r den Einsatz von R sprechen:\n\nğŸ†“ R ist kostenlos, andere Softwarepakete fÃ¼r Datenanalyse sind teuer. ğŸ’¸\nğŸ“– R und R-Befehle sind quelloffen, d.h. man kann sich die zugrundeliegenden Computerbefehle anschauen. Jede/r kann prÃ¼fen, ob R vernÃ¼nftig arbeitet. Jede/r kann beitragen.\nğŸ†• R hat die neuesten Methoden.\nğŸ«‚ R hat eine groÃŸe Community.\nğŸª¡ R ist maÃŸgeschneidert fÃ¼r Datenanalyse.\n\nAllerdings gibt es auch abweichende Meinungen, s. AbbildungÂ 3.2.\n\n\n\n\n\nAbbildungÂ 3.2: Manche finden Excel cooler als R, nicht wahr, Bill Gates?\n\n\n\n3.2.2 R und Reproduziebarkeit\n\nDefinition 3.1 (Reproduzierbarkeit) Ein (wissenschaftlicher) Befunde ist reproduzierbar, wenn andere Analystis mit dem gleichen experimentellen Setup zum gleichen Ergebnis (wie in der ursprÃ¼nglichen Analyse) kommen (Plesser, 2018). \\(\\square\\)\n\n\nDefinitionÂ 3.1 ist, etwas Ã¼berspitzt, in AbbildungÂ 3.3 wiedergegeben.\n\n\n\nğŸ”¢ + ğŸ¤– + ğŸ”¬ = ğŸ¤©\n\n\n\nAbbildungÂ 3.3: Daten + Syntax + genaue Beschreibung der Messungen = reproduzierbar\n\n\n\nBeispiel 3.1 (Aus der Forschung: Reproduzierbarkeit in der Psychologie) Â \n\nğŸ§‘â€ğŸ“ Wie ist es um unsere Wissenschaft, Psychologie, bestellt? Haben die Befunde Hand und FuÃŸ?\n\nObels et al. (2020) haben die Reproduzierbarkeit in psychologischen Studien untersucht. Sie berichten folgendes Ergebnis\n\nWe examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#architektur-von-r",
    "href": "020-R.html#architektur-von-r",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.3 Architektur von R",
    "text": "3.3 Architektur von R\n\n3.3.1 R & RStudio\n\n\n\n\n\nğŸ’–\n\n\n\n\n\nIsmay & Kim (2020) zeigen eine schÃ¶ne Analogie, was der Unterschied von R und RStudio ist, s. AbbildungÂ 3.4.1\n\n\n\n\n\n\n\nAbbildungÂ 3.4: R vs.Â RStudio: R macht die Arbeit, RStudio ist fÃ¼r Komfort und Ãœbersicht\n\n\n\n\nWir verwenden beide Programme. Aber wir Ã¶ffnen nur RStudio. RStudio findet selbstÃ¤ndig R und Ã¶ffnet diese â€œheimlichâ€. Ã–ffnen Sie nicht noch extra R (sonst wÃ¤re R zweifach geÃ¶ffnet).\nHier sehen Sie einen Screenshot von der OberflÃ¤che von RStudio, s. AbbildungÂ 3.5.\n\n\n\n\n\nAbbildungÂ 3.5: So sieht RStudio aus\n\n\n\n3.3.2 Posit Cloud\nPosit Cloud2 ist ein Webdienst von Posit/RStudio (zum Teil kostenlos). Man kann damit online mit R arbeiten. Die OberflÃ¤che ist praktisch identisch zur Desktop-Version, s. AbbildungÂ 3.6. Ein Vorteil ist, dass man als Nutzer nichts installieren muss und dass es auch auf Tablets lÃ¤uft (im Gegensatz zur Desktop-Version von R). Ein Nachteil ist, dass es etwas langsamer ist und nur fÃ¼r ein gewisses Zeitvolumen kostenlos.\n\n\n\n\n\nAbbildungÂ 3.6: So sieht RStudio Cloud aus. Genau wie RStudio Desktop\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Ihr Dozent Ihnen einen Projektordner bzw. einen Link dazu bereitstellt, ist das komfortabel, da der Dozent dann schon Pakete installieren, Daten bereitstellen und andere Nettigkeit vorbereiten kann fÃ¼r Sie. Allerdings mÃ¼ssen Sie den Projektordner in Ihrem Konto abspeichern, wenn Sie etwas speichern mÃ¶chten, da Sie vermutlich keine Schreibrechte im Projektordner Ihres Dozenten haben. Klicken Sie dazu auf â€œSave a permanent copyâ€, s. AbbildungÂ 3.7.\\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 3.7: Einen Projektordner im eigenen Konto abspeichern, um Schreibrechte zu haben\n\n\nSie kÃ¶nnen auch von der Cloud exportieren, also Ihre Syntaxdatei herunterladen. Klicken Sie dazu im Reiter â€œFilesâ€ auf More &gt; Export ....\n\n3.3.3 Installation\nLesen Sie hier die Installation von R und seiner Freunde nach.\nKurz gesagt: Laden Sie R von der R-Homepage, genannt â€œCRANâ€3 herunter. R wird fÃ¼r alle gÃ¤ngigen Betriebssystem angeboten.\n\n3.3.4 R-Pakete\nTypisch fÃ¼r R ist sein modularer Aufbau: Man kann eine groÃŸe Zahl an Erweiterungen (â€œPaketeâ€, engl. packages) installieren, alle kostenlos. In R Paketen â€œwohnenâ€ R-Befehle, also Dinge, die R kann, â€œSkillsâ€ sozusagen. AuÃŸerdem kÃ¶nnen in R-Paketen auch Daten bereitgestellt werden. Damit man die Inhalte eines R-Pakets nutzen kann, muss man es zuerst installieren und dann starten.\nMan kann sich daher ein R-Paket vorstellen wie ein Buch: Wenn R es gelesen hat, dann kennt es die Inhalte. Diese Inhalte kÃ¶nnten irgendwelche Formeln, also Berechnungen sein. Es kÃ¶nnte aber die â€œBauanleitungâ€ fÃ¼r ein schÃ¶nes Diagramm sein.\nIst ein spezielles R-Paket auf Ihrem Computer installiert, so kÃ¶nnen Sie diese FunktionalitÃ¤t nutzen.\nDie Zahl an diesen â€œPaketenâ€ ist groÃŸ; zur Verdeutlichung s. AbbildungÂ 3.8.\n\n\n\n\nViele Pakete\nEs kommen viele dazu\n\n\n\n\n\n\n\n\n(a) Containershiff mit vielen Paketen, Corey Seeman, CC-BY-NC 20, Flickr.com\n\n\n\n\n\n\n\n\n\n(b) Die Anzahl der R-Pakete ist exponenziell gewachsen\n\n\nEs gibt viele R-Pakete.\n\n\n\n\n\nAbbildungÂ 3.8\n\n\nErweiterungen kennt man von vielen Programmen, sie werden auch Add-Ons, Plug-Ins oder sonstwie genannt. Man siehe zur Verdeutlichung Erweiterungen beim Broswer Chrome, AbbildungÂ 3.9.\n\n\n\n\n\nAbbildungÂ 3.9: Erweiterungen beim Browser Chrome\n\n\nDie Anzahl der R-Pakete ist groÃŸ; allein auf dem â€œoffiziellen Web-Storeâ€ (nennt sich â€œCRANâ€) von R gibt es ca. 20,000 Pakete (vgl. AbbildungÂ 3.8 (b)); Stand: 2022; Quelle). Und es kommen immer mehr dazu.\n\n3.3.4.1 Pakete installieren\nWie jede Software muss man Pakete (Erweiterungen fÃ¼r R) erst einmal installieren, bevor man sie verwenden kann. Ja, einmal installieren reicht.\nDas geht komfortabel, wenn man beim Reiter Packages auf Install klickt (s. AbbildungÂ 3.10) und dann den Namen des zu installierenden Pakets eingibt.\n\n\n\n\n\n\n\n\n\n(a) Klicken Sie auf â€œInstallâ€ im Reiter â€œPackagesâ€, um R-Pakete zu installieren\n\n\n\n\n\n\n\n\n\n(b) So kann man R-Pakete installieren in RStudio\n\n\n\n\n\n\nAbbildungÂ 3.10: So installiert man Pakete in R.\n\n\nDann Ã¶ffnet sich ein MenÃ¼, wo man die Namen der gewÃ¼nschten R-Pakete eingeben kann (s. Abbildung AbbildungÂ 3.11).\n\n\n\n\n\nAbbildungÂ 3.11: Hier den oder die Namen der gewÃ¼nschten R-Pakete eingeben\n\n\n\nğŸ§‘â€ğŸ“Welche R-Pakete sind denn schon installiert?\n\nIm Reiter Packages kÃ¶nnen Sie nachschauen, welche Pakete auf Ihrem Computer schon installiert sind. Diese Pakete brauchen Sie logischerweise dann nicht noch mal installieren, s. AbbildungÂ 3.12.\n\n\n\n\n\nAbbildungÂ 3.12: So sehen Sie, ob ein R-Paket auf Ihrem System installiert ist\n\n\n\nğŸ§‘â€ğŸ“Ja, aber welche R-Pakete â€œsollâ€ ich denn installieren, welche brauch ich denn?\n\nIm Moment sollten Sie die folgenden Pakete installiert haben:\n\ntidyverse\neasystats\n\nWenn Sie die noch nicht installiert haben sollten, dann kÃ¶nnen Sie das jetzt ja nachholen.4\n\n\n\n\n\n\nHinweis\n\n\n\nIhre R-Pakete sollten aktuell sein. Klicken Sie beim Reiter Packages auf â€œUpdateâ€, um Ihre R-Pakete zu aktualisieren. Arnold Schwarzenegger rÃ¤t, Ihre R-Pakete aktuell zu halten, s. AbbildungÂ 3.13.\n\n\n\n\n\n\n\nAbbildungÂ 3.13: R-Pakete sollten stets aktuell sein, so Arnold Schwarzenegger\n\n\n\nmade at https://imgflip.com/memegenerator\n\n\n\n\n\n\n\nVorsicht\n\n\n\nBevor Sie ein R-Paket (oder Ã¼berhaupt irgendwelche Software) installieren/updaten, sollten Sie das R-Paket schlieÃŸen/beenden. Sonst schrauben Sie an einem elektrischen GerÃ¤t herum, das noch unter Strom steht (nicht gut). Die einfachste Art, alle Pakete zu beenden ist, Session &gt; Restart R zu klicken (in RStudio).\\(\\square\\)\n\n\n\n3.3.4.2 Pakete updaten\nKlicken Sie im Reiter Packages (in RStudio) und dort auf den Button Update.5\nDenken Sie daran, dass Sie das Paket, das Sie updaten/installieren, nicht laufen darf.\n\n3.3.4.3 Pakete starten\nWenn Sie ein Softwareprogramm - nichts anderes sind R-Pakete - installiert haben, mÃ¼ssen Sie es noch starten.\nMerke: Ein bestimmtes Paket muss man nur einmalig installieren. Aber man muss es jedes Mal neu starten, wenn man R (bzw. RStudio) startet.\nSie erkennen leicht, ob ein Paket gestartet ist, wenn Sie ein HÃ¤kchen vor dem Namen des Pakets in der Paketliste (Reiter Packages) sehen, s. Abbildung AbbildungÂ 3.10 (a).\nDieses Video verdeutlicht den Unterschied zwischen Installation und Starten eines R-Pakets.\n\n3.3.5 Projekte in R\nEin Projekt in RStudio (s. AbbildungÂ 3.14) ist letztlich ein Ordner, der als â€œBasisâ€ fÃ¼r eine Reihe von Dateien verwendet wird. Sagen wir, das Projekt heiÃŸt cool_stuff. RStudio legt uns diesen Ordner an einem von uns gewÃ¤hlten Platz auf unserem Computer an. Das ist ganz praktisch, weil man dann sagen kann â€œHey R, nimmt die Datei â€˜daten.csvâ€™â€, ohne einen Pfad anzugeben. Vorausgesetzt, die Datei liegt auch im Projektordner (cool_stuff).\nProjekte kann anlegen mit Klick auf das Icon, das einen Quader mit dem Buchstaben R darin anzeigt (s. AbbildungÂ 3.14 (a)). RStudio-Projekte machen Ihr Leben leichter (s. AbbildungÂ 3.14).\n\n\n\n\n\n\n\n\n\n(a) RStudio-Projekte, Beispiele\n\n\n\n\n\n\n\n\n\n(b) RStudio-Projekte sind viel sicherer als das Arbeitsverzeichnis von Hand zu wÃ¤hlen oder mit Pfaden herumzubasteln. Image credit: Allision Horst\n\n\n\n\n\n\nAbbildungÂ 3.14: Nutzen Sie RStudio-Projekte, das macht Ihr Leben leichter.\n\n\n\n3.3.6 Skriptdateien\nDie R-Befehle (â€œSyntaxâ€) schreiben Sie am besten in eine speziell dafÃ¼r vorgesehene Textdatei in RStudio. Eine Sammlung von (R-)Computer-Befehlen nennt man auch ein Skript, daher spricht man auch von einer Skriptdatei.\n\n3.3.6.1 So Ã¶ffnen Sie eine neue Skriptdatei\nUm eine neue R-Skriptdatei zu Ã¶ffnen, klicken Sie auf das Icon, das ein weiÃŸes Blatt mit einem grÃ¼nen Pluszeichen zeigt, s. AbbildungÂ 3.15.\n\n\n\n\n\n\n\n\n\n(a) So erstellen Sie eine neue Skriptdatei\n\n\n\n\n\n\n\n\n\n(b) Klicken Sie auf das Icon mit dem leeren Blatt und dem grÃ¼nen Plus\n\n\n\n\n\n\nAbbildungÂ 3.15: Es gibt verschiedene Wege, um eine neue R-Skript-Datei in RStudio zu Ã¶ffnen.\n\n\n\n3.3.6.2 So speichern Sie Ihre Skripdatei\nVergessen Sie nicht zu speichern, wenn Sie ein tolles Skript geschrieben haben. DafÃ¼r gibt es mehrere MÃ¶glichkeiten:\n\nStrg+S\nMenÃ¼: File &gt; Save\nKlick auf das Icon mit der Diskette, s. AbbildungÂ 3.15.\n\n3.3.6.3 So Ã¶ffnen Sie eine Skriptdatei\nEine Skriptdatei kÃ¶nnen Sie in typischer Manier Ã¶ffnen:\n\nStrg+O\nKlick auf das Icon mit der Akte und dem grÃ¼nen Pfeil (vgl. AbbildungÂ 3.15)\nMenÃ¼: File &gt; Open File...\n\n\n3.3.7 Quarto-Dokumente\nQuarto ist ein Programm zum Erstellen von Texten, in das man R-Syntax einfÃ¼gen kann. Die Ausgaben der R-Befehle werden dann direkt im Dokument eingebunden. AbbildungÂ 3.16 zeit ein Beispiel fÃ¼r ein Quarto-Dokument.\n\n\n\n\n\n\nHinweis\n\n\n\nQuarto ist eine komfortable und leistungsfÃ¤hige Methode, um Dokumente mit R-Syntax zu schreiben. Sie sind aber nicht verpflichtet, Quarto zu nutzen. Stattdessen kÃ¶nnen Sie Ihre Syntax auch in Skriptdateien schreiben. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 3.16: Dokumente schreiben mit Quarto\n\n\nWenn Sie Quarto nutzen mÃ¶chten, mÃ¼ssen Sie es zunÃ¤chst installieren, d.h. herunterladen. Dann kÃ¶nnen Sie in RStudio Quarto-Dateien erstellen.\nEin neues Quarto-Dokument kÃ¶nnen Sie erstellen mit Klick auf File &gt; New File &gt; Quarto Document â€¦.\nDieses Video gibt Ihnen Einstieg in Quarto.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errisch-fÃ¼r-einsteiger",
    "href": "020-R.html#errisch-fÃ¼r-einsteiger",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.4 Errisch fÃ¼r Einsteiger",
    "text": "3.4 Errisch fÃ¼r Einsteiger\n\n\n\n\n\n\nHinweis\n\n\n\nR ist penibel: So sind name und Name zwei verschiedene Variablen fÃ¼r R. GroÃŸ- und Kleinschreibung wird von R genau beachtet! Hingegen ist es R egal, ob Sie zur besseren Ãœbersichtlichkeit Leerzeichen in Ihre Syntax tippen. Ausnahme sind spezielle Operatoren wie &lt;- oder &lt;=.\nEine gute Nachricht: Wenn R etwas von WARNING (bzw. Warnung) sagt, kÃ¶nnen Sie das zumeist ignorieren. Eine Warnung ist kein Fehler (ERROR) und meistens nicht gravierend oder nicht dringend. Im Zweifel ist Googeln eine gute Idee. Nur wenn R von Error spricht, ist es auch ein Fehler.\\(\\square\\)\n\n\n\n3.4.1 Variablen\nIn jeder Programmiersprache kann man Variablen definieren, so auch in R:\n\nrichtige_antwort = 42\nfalsche_antwort = 43\ntyp = \"Antwort\"\nist_korrekt = TRUE\n\nAlternativ zum Gleichheitszeichen = kÃ¶nnen Sie auch (synonym) den Zuweisungspfeil &lt;- verwenden. Beides fÃ¼hrt zum gleichen Ergebnis. Allerdings ist der Zuweisungspfeil prÃ¤ziser, und sollte daher bevorzugt werden.\nDer Zuweisungspfeil &lt;- bzw. das Gleichheitszeichen = definiert eine neue Variable (oder Ã¼berschreibt den Inhalt, wenn die Variable schon existiert).\n\nrichtige_antwort &lt;- 42\nfalsche_antwort &lt;- 43\ntyp &lt;- \"Antwort\"\nist_korrekt &lt;- TRUE\n\nDieses Video und dieses Video geben eine EinfÃ¼hrung in das Definieren von Variablen in R.\nSie kÃ¶nnen sich eine Variable wie einen Becher oder BehÃ¤lter vorstellen, der bestimmte Werte enthÃ¤lt. Auf dem Becher steht (mit Edding geschrieben) der Name des Bechers. NatÃ¼rlich kÃ¶nnen Sie die Werte aus dem Becher entfernen und sie durch neue ersetzen (vgl. AbbildungÂ 3.17).\n\n\n\n\n\nAbbildungÂ 3.17: Variablen zuweisen\n\n\nR kann Ã¼brigens auch rechnen. Probieren Sie es doch gleich mal hier aus!\n\ndie_summe &lt;- falsche_antwort + richtige_antwort\n\nAber was ist jetzt der Wert, der â€œInhaltâ€ der Variable die_summe?\nUm den Wert, d.h. den Inhalt einer Variablen in R auszulesen, geben wir einfach den Namen des Objekts ein:\n\ndie_summe\n## [1] 85\n\nWas passiert wohl, wenn wir die_summe jetzt wie folgt definieren?\n\ndie_summe &lt;- falsche_antwort + richtige_antwort + 1\n\nWer hÃ¤ttâ€™s geahnt:\n\ndie_summe\n## [1] 86\n\nVariablen kÃ¶nnen auch â€œleerâ€ sein:\n\nalter &lt;- NA\nalter\n## [1] NA\n\nNA steht fÃ¼r not available, nicht verfÃ¼gbar und macht deutlich, dass hier ein Wert fehlt.\n\nğŸ§‘â€ğŸ“ Wozu brauche ich bitte fehlende Werte?!\n\nFehlende Werte sind ein hÃ¤ufiges Problem in der Praxis. Vielleicht hat sich die befragte Person geweigert, ihr Alter anzugeben6. Oder als Sie die Daten in Ihren Computer eingeben wollten, ist Ihre Katze Ã¼ber die Tastatur gelaufen und alles war futschâ€¦\n\n3.4.2 Funktionen (â€œBefehleâ€)\nDas, was R kann, ist in â€œFunktionenâ€ hinterlegt. Genauer gesagt ist â€œBefehlâ€ eine Funktion.\n\nDefinition 3.2 (Funktion) Eine Funktion ist eine Regel, die jedem Eingabewert (auch Argument genannt) einen Ausgabewert zuordnet. Man kann sich Funktionen als Maschinen vorstellen, die Eingabedaten in Ausgabedaten umwandeln, vgl. AbbildungÂ 3.18. \\(\\square\\)\n\n\n3.4.2.1 Eine erste Funktion: Vektoren erstellen\nEin Beispiel fÃ¼r eine solche Funktion kÃ¶nnte sein: â€œBerechne den Mittelwert dieser Datenreiheâ€ (schauen wir uns gleich an).\nDas geht so:\n\nAntworten &lt;- c(42, 43)\n\nDer Befehl c (c wie combine) fÃ¼gt mehrere Werte zusammen zu einer â€œListeâ€ (einem Vektor).7\n\nDefinition 3.3 Als Vektor bezeichnen wir eine geordnete Folge von Werten. In R kann man sie mit der Funktion c() erstellen. Die Werte eines Vektors bezeichnet man als Elemente. \\(\\square\\)\n\nMit dem Zuweisungspfeil geben wir diesem Vektor einen Namen, hier Antworten. Dieser Vektor besteht aus zwei Werten, zuerst 42, dann kommt 43.\n\nBeispiel 3.2 (Beispiele fÃ¼r Vektoren) Vektoren kÃ¶nnen (praktisch) beliebig lang sein, z.B. drei Elemente.\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 3)  # x und y sind ungleich (Reihenfolge der Werte)\nz &lt;- c(3.14, 2.71)  \nnamen &lt;- c(\"Anni\", \"Bert\", \"Charli\") # Text-Vektor\n\n\nZwei wichtige Typen von Vektoren sind numerische Vektoren (reelle Zahlen; in R auch als numeric oder double bezeichnet) und Textvektoren, in R auch als String oder character bezeichnet.\n\nBeispiel 3.3 Weitere Beispiel fÃ¼r Funktionen sind:\n\nâ€œErstelle eine Liste (Vektor) von Wertenâ€.\nâ€œLade dieses R-Paket.â€\nâ€œGib den grÃ¶ÃŸten Wert dieser Datenreihe aus.â€ \\(\\square\\)\n\n\n\n\n3.4.3 Unsere erste statistische Funktion\nJetzt wirdâ€™s ernst. Jetzt kommt die Statistik. ğŸ§Ÿ Berechnen wir also unsere erste statistische Funktion: Den Mittelwert. Puh.\n\nmean(Antworten)\n## [1] 42.5\n\nSie hÃ¤tten Antworten auch durch c(42, 43) ersetzen kÃ¶nnen, so haben Sie ja schlieÃŸlich die Variable gerade definiert.\nR arbeitet so einen â€œverschachteltenâ€ Befehl von innen nach auÃŸen ab:\nStart: mean(Antworten)\n  â¬‡ï¸ \nSchritt 1: mean(c(42, 43))\n  â¬‡ï¸ \nSchritt 2: 42.5\n\n3.4.3.1 Schema einer Funktion\nAbbildungÂ 3.18 stellt eine Funktion schematisch dar.\n\n\n\n\n\nAbbildungÂ 3.18: Schema einer Funktion\n\n\n\n3.4.3.2 Argumente einer Funktion\nEine Funktion hat einen oder mehrere Inputs, das sind Daten oder Verarbeitungshinweise, die man in die Funktion fun eingibt, bevor sie loslegt. Eine Funktion hat immer (genau) eine Ausgabe (Output), in der das Ergebnis einer Funktion ausgegeben wird.\n\nDefinition 3.4 (Argumente einer Funktion) Die â€œTrichterâ€ einer (R-)Funktion, in denen man die Eingaben â€œeinfÃ¼lltâ€, nennt man auch Argumente.\\(\\square\\)\n\nSo hat die Funktion mean() z.B. folgende Argumente, s. ListingÂ 3.1.\n\n\nListingÂ 3.1: Die Argumente der R-Funktion mean\n\n\nmean(x, trim = 0, na.rm = FALSE, ...)\n\n\n\n\n\n\nx: das ist der Vektor, fÃ¼r den der Mittelwert berechnet werden soll\n\ntrim = 0: Sollen die extremsten Werte von x lieber â€œabgeschnittenâ€ werden, also nicht in die Berechnung des Mittelwerts einflieÃŸen?\n\nna.rm = FALSE: Wie soll mit fehlenden Werten NA umgegangen werden? Im Standard liefert mean8 NA zurÃ¼ck. R schwenkt sozusagen die rote Fahne, um zu signalisieren, Achtung, Mensch, hier ist irgendwas nicht in Ordnung. Setzt man aber na.rm = TRUE, dann entfernt (remove, rm) R die fehlenden Werte und berechnet den Mittelwert.\n\n... heiÃŸt â€œsonstiges Zeugs, das manchmal eine Rolle spielen kÃ¶nnteâ€; darum kÃ¼mmern wir uns jetzt nicht.\n\nEinige Argumente haben einen Standardwert bzw. eine Voreinstellung (engl. default). So wird bei der Funktion mean im Standard nicht getrimmt (trim = 0) und fehlende Werte werden nicht entfernt (na.rm = FALSE).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn ein R-Befehl ein Argument mit Voreinstellung hat, brauchen Sie dieses Argument nicht zu befÃ¼llen. In dem Fall wird auf den Wert der Voreinstellung zurÃ¼ckgegriffen. Argumente ohne Voreinstellung - wie x bei mean() - mÃ¼ssen Sie aber auf jeden Fall mit einem Wert befÃ¼llen. Man wÃ¼rde also mean zumeist so aufrufen: mean(x). \\(\\square\\)\n\n\nBei jedem R-Befehl haben die Argumente eine bestimmte Reihenfolge, etwa bei mean(): mean(x, trim = 0, na.rm = FALSE, ...).\n(Nur) wenn man die Argumente in ihrer vorgegebenen Reihenfolge anspricht, muss man nicht den Namen des Arguments anfÃ¼hren:\nâœ… mean(Antworten, 0, FALSE)\nHÃ¤lt man sic aber nicht an die vorgebene Reihenfolge, so weiÃŸ R nicht, was zu tun ist und flÃ¼chtet sich in eine Fehlermeldung:\n\nmean(Antworten, FALSE, 0)  # FALSCH, DON'T DO IT ğŸ™…â€â™€ï¸\n## Error in mean.default(Antworten, FALSE, 0): 'trim' must be numeric of length one\n\nWenn man die Namen der Argumente anspricht, ist die Reihenfolge egal:\n\nmean(na.rm = FALSE, x = Antworten)  # ok\nmean(trim = 0, x = Antworten, na.rm = TRUE)  # ok\n\nÃœbrigens: Leerzeichen sind R fast immer egal. Aus GrÃ¼nden der Ãœbersichtlichkeit sollte man aber Leerzeichen verwenden. In diesen FÃ¤llen sind Leerzeichen nicht erlaubt:\n\n&lt;-\n\n&lt;= etc.\nVariablennamen\n\n3.4.3.3 Achtung bei fehlenden Werten\nSagen wir, wir haben einen fehlenden Wert in unseren Daten:\n\nAntworten &lt;- c(42, 43, NA)\nAntworten\n## [1] 42 43 NA\n\nWenn wir jetzt den Mittelwert berechnen wollen, quittiert R das mit einem schnÃ¶den NA. NA steht fÃ¼r not available, ist also ein Hinweis, dass Werte fehlen.\n\nmean(Antworten)\n## [1] NA\n\nR meint es gut mit Ihnen9. Stellen Sie sich vor, dass R Sie auf dieses Problem aufmerksam machen mÃ¶chte:\n\nğŸ¤– Achtung, lieber Herr und Gebieter, du hast nicht mehr alle Latten am Zaun, will sagen, alle Daten im Vektor!\n\n(Danke, R.)\nMÃ¶chten Sie aber lieber R dieses Verhalten austreiben, so befÃ¼llen Sie das Argument na.rm mit dem Wert TRUE.10\n\nmean(Antworten, na.rm = TRUE)\n## [1] 42.5\n\n\nÃœbungsaufgabe 3.1 (Geben Sie lustige Bedeutungen an, was â€œNAâ€ noch bedeuten kÃ¶nnte!) Â \n\nğŸ¤– Wie wÃ¤re es mit â€œnebulÃ¶se Anomalieâ€ oder â€œnix-checkender Angeberâ€ oder â€œnÃ¶lender Automatâ€.\n\n\nğŸ§‘â€ğŸ“ Hmâ€¦\n\n\\(\\square\\)\n\n\n3.4.4 Vektorielles Rechnen\n\nDefinition 3.5 Das Rechnen mit Vektoren in R bezeichnen wir als vektorielles Rechnen. \\(\\square\\)\n\nVektorielles Rechnen ist ein praktische Angelegenheit, man kann z.B. folgende Dinge einfach in R ausrechnen.\nGegeben sei x als Vektor (1, 2, 3). Dann kÃ¶nnen wir die Differenz (Abweichung) jedes Elements von x zum Mittelwert von x komfortabel so ausrechnen:\n\nx - mean(x)\n## [1] -1  0  1\n\nEtwas fancier ausgedrÃ¼ckt: Wir haben die Funktion mit Namen â€œDifferenzâ€ (â€œMinus-Rechnenâ€) auf jedes Element von x angewandt. Im Einzelnen haben wir also folgenden drei Differenzen ausgerechnet:\n\n1 - 2\n2 - 2\n3 - 2\n\n\n\n\n\n\n\n\nAbbildungÂ 3.19: Schema des vektoriellen Rechnens: Eine Funktion wird auf jedes Elemnt eines Vektors angewandt\n\n\n\n\n\n3.4.5 R-Quiz\n\nÃœbungsaufgabe 3.2 Ihre R-Muskeln sind gestÃ¤hlt? ğŸ’ª Noch nicht so ganz ausdefiniert? ğŸ˜¤ Macht nichts! Trainieren Sie sich mit diesem Quiz!\n\n\n3.4.6 HÃ¤ufige R-Fragen\n\n\nWo finde ich Hilfe zu einer bestimmten Funktion, z.B. fun()? Geben Sie dazu folgenden R-Befehl ein: help(fun).\n\nWenn ich ein R-Paket installiere, fragt mich R manchmal, ob ich auch Pakete installieren, will, die â€œkompiliertâ€ werden mÃ¼ssen. Soll ich das machen?. Nein, das ist nicht nÃ¶tig; geben Sie â€œnoâ€ ein.\n\nIn welchem Paket wohnt meine R-Funktion? Suchen Sie nach der Funktion auf dieser Seite.\n\nIch weiÃŸ nicht, wie der R-Befehl funktioniert! Vermutlich haben andere Ihr Problem auch, und meistens hat irgendwer das Problem schon gelÃ¶st. Am besten suchen Sie mal auf Stackoverflow.\n\nIch muss mal grundlegend verstehen, wozu ein bestimmten R-Paket gut ist. Was tun? Lesen Sie die Dokumenation (â€œVignetteâ€) eines R-Pakets durch. FÃ¼r das Paket dplyr bekommen Sie so einen Ãœberblick Ã¼ber die verfÃ¼gbaren Vignetten diese Pakets: vignette(package = \"dplyr\"). Dann suchen Sie sich aus der angezeigten Liste eine Vignette raus; mit vignette(\"rowwise\") kÃ¶nnen Sie sich dann die gewÃ¼nschte Vignette (z.B. rowwise) anzeigen lassen.\n\nOh nein, ich seh rot, das heiÃŸt, R zeigt mir irgendwas in roter Schrift an. Ist jetzt was kaputt? Keine Sorge, R ist in seiner Ausgabe nicht sparsam mit roter Frabe. Solange es nicht als Fehlermeldung (ERROR) erscheint, ist es meist kein Problem.\n\nR hat sich aufgehÃ¤ngt oder bringt einen Fehler an einer Stelle, wo sonst alles funktioniert hat. Probieren Sie auf jeden Fall mal das AEG-Prinzip (Aus-Ein-Gut): sprich R neu starten.\n\nIch suche schon seit einer Stunde einen Fehler und find ihn nicht. Ich habe schon verschiedene GegenstÃ¤nde vor Wut an die Wand geworfen. Was soll ich tun? Machen Sie eine Pause. Doch, das ist ernst gemeint. Meine Erfahrung: Mit etwas Abstand wird der Kopf klarer und man findet das Problem viel einfacher.11\n\n\n3.4.7 Hilfe?! Erbie!\nR will nicht, so wie Sie wollen? Sie haben das GefÃ¼hl, R verweigert stÃ¶rrisch den Dienst, vermutlich rein aus Boshaftigkeit, rein um Sie zu Ã¤rgern? AusfÃ¼hrliches Googeln und ChatGPT befragen hat keine LÃ¶sung gebracht? Kurz, Sie brauchen die Hilfe eines kundigen Menschens?12\nHier finden Sie eine Anleitung, wie man seinen Hilfeschrei so formuliert (ruft), dass er nicht nur gehÃ¶rt, sondern auch verstanden wird und einen anderen Menschen veranlasst und ermÃ¶glicht Ihnen zu helfen.\nAlso: Sie mÃ¼ssen Ihr Problem nachvollziehbar aber prÃ¤gnant formulieren. Das nennt man auch ein ERBie, ein einfaches, reproduzierbare Beispiel Ihres Problems mit (R-)Syntax:\n\neinfach: die einfachste Syntax, die Ihr Problem bzw. die Fehlermeldung produziert. Es bietet sich an, einen einfachen, allgemein bekannten Datensatz zu verwenden, etwa mtcars\n\nreproduzierbar: Code (z.B. als Textdatei oder in einem Post), der die Fehlermeldung entstehen lÃ¤sst\n\n\nBeispiel 3.4 (Beispiel fÃ¼r ein Erbie) Problem: Ich verstehe nicht, warum eine Fehlermeldung kommt\nZiel: Ich mÃ¶chte die Automatikautos filtern (am = 0)\nWas ich schon versucht habe: Ich habe folgende Posts gelesen â€¦, aber ohne Erfolg\nErbie:\n\ndata(mtcars)\nlibrary(dplyr)  # nicht \"tidyverse\", denn \"dplyr\" reicht\n\nmtcars %&gt;% \n  filter(am = 0)  # den kÃ¼rzesten Code, der Ihren Fehler entstehen lÃ¤sst!\n## Error in `filter()`:\n## ! We detected a named input.\n## â„¹ This usually means that you've used `=` instead of `==`.\n## â„¹ Did you mean `am == 0`?\n\nsessionInfo()  # gibt Infos zur R-Version etc. aus\n## R version 4.2.1 (2022-06-23)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur ... 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] see_0.8.0          report_0.5.7       parameters_0.21.3  performance_0.10.8\n##  [5] modelbased_0.8.6   insight_0.19.6     effectsize_0.8.6   datawizard_0.9.0  \n##  [9] correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0    lubridate_1.9.3   \n## [13] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3        purrr_1.0.2       \n## [17] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.4     \n## [21] tidyverse_2.0.0    knitr_1.45        \n## \n## loaded via a namespace (and not attached):\n##  [1] mvtnorm_1.2-2      lattice_0.21-8     png_0.1-8          zoo_1.8-12        \n##  [5] digest_0.6.33      utf8_1.2.3         R6_2.5.1           evaluate_0.21     \n##  [9] coda_0.19-4        pillar_1.9.0       rlang_1.1.1        multcomp_1.4-25   \n## [13] rstudioapi_0.15.0  Matrix_1.5-4.1     rmarkdown_2.25     labeling_0.4.3    \n## [17] textshaping_0.3.6  splines_4.2.1      htmlwidgets_1.6.2  munsell_0.5.0     \n## [21] compiler_4.2.1     xfun_0.40          systemfonts_1.0.4  pkgconfig_2.0.3   \n## [25] htmltools_0.5.6.1  tidyselect_1.2.0   codetools_0.2-19   fansi_1.0.5       \n## [29] tzdb_0.4.0         withr_2.5.2        MASS_7.3-60        grid_4.2.1        \n## [33] jsonlite_1.8.7     xtable_1.8-4       gtable_0.3.4       lifecycle_1.0.3   \n## [37] magrittr_2.0.3     scales_1.2.1       estimability_1.4.1 cli_3.6.1         \n## [41] stringi_1.7.12     farver_2.1.1       ragg_1.2.5         generics_0.1.3    \n## [45] vctrs_0.6.4        sandwich_3.0-2     TH.data_1.1-2      tools_4.2.1       \n## [49] glue_1.6.2         hms_1.1.3          emmeans_1.8.9      fastmap_1.1.1     \n## [53] survival_3.5-5     yaml_2.3.7         timechange_0.2.0   colorspace_2.1-0\n\nMit dem Paket reprex kann man sich R-Syntax schÃ¶n formuliert ausgeben lassen. Das ist perfekt, um den Code dann in einem Forum (oder Mail) einzustellen. DafÃ¼r mÃ¼ssen Sie nur den Code auswÃ¤hlen, Strg-C drÃ¼cken und dann reprex::reprex ausfÃ¼hren. Mit Strg-V kÃ¶nnen Sie die schÃ¶n formatierte Syntax (sowie die Ausgabe, auch schÃ¶n formatiert) dann irgendwohin pasten.\n\n\n\n\n\nvia GIFER\n\n\n\n\n\n\n\n\nTipp\n\n\n\nPosten Sie Ihr Erbie bei https://gist.github.com/ als â€œpublic gistâ€. Hier ist ein Beispiel.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#daten-importieren",
    "href": "020-R.html#daten-importieren",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.5 Daten importieren",
    "text": "3.5 Daten importieren\n\n3.5.1 Wo sind meine Daten?\nDamit Sie eine Datendatei importieren kÃ¶nnen, mÃ¼ssen Sie wissen, wo die Datei ist. Schauen wir uns zwei MÃ¶glichkeiten an, wo Ihre Datei liegen kÃ¶nnte.\n\nIrgendwo im Internet, z.B. hier\n\nIrgendwo auf Ihrem Computer, z.B. in Ihrem Projektordner\n\nIn beiden FÃ¤llen wird der â€œAufenthaltsortâ€ der Datei durch den Pfad13 und den Namen der Datei definiert.\n\n\n\n\n\n\nHinweis\n\n\n\nWir werden in diesem Kurs hÃ¤ufiger mit dem Daten mariokart arbeiten; Sie finden ihn hier.14\n\n\n\n3.5.2 GebrÃ¤uchliche Datenformate\nDaten werden in verschiedenen Formaten im Computer abgespeichert; Tabellen hÃ¤ufig als\n\nExcel-Datei\nCSV-Datei\n\nIn der Datenanalyse ist das gebrÃ¤uchlichste Format fÃ¼r Daten in Tabellenform die CSV-Datei. Das hat den Grund, weil dieses Format technisch schÃ¶n einfach ist. FÃ¼r uns Endverbraucher tut das nichts groÃŸ zur Sache, die CSV-Datei beherbergt einfach eine brave Tabelle in einer Textdatei, sonst nichts.\n\nÃœbungsaufgabe 3.3 (CSV-Datei von innen) ğŸ‹ï¸â€â™€ï¸ Ã–ffnen Sie mal eine CSV-Datei mit einem Texteditor (nicht mit Word und auch nicht mit Excel). Schauen Sie sich gut an, was Sie dort sehen und erklÃ¤ren Sie die Datenstruktur. \\(\\square\\)\n\nIn diesem Buch werden wir mit einem Datensatz namens mariokart arbeiten; hallo Mario (s. AbbildungÂ 3.20)!\n\n\n\n\n\nAbbildungÂ 3.20: Hallo, Mario\n\n\n Download \n\n3.5.3 Einlesen aus einem R-Paket\nIhr Datensatz schon in einem R-Paket gespeichert, kÃ¶nnen Sie ihn aus diesem R-Paket starten. Das ist die bequemste Option. Zum Beispiel â€œwohntâ€ der Datensatz mariokart im R-Paket openintro.\n\n\n\n\n\n\nTipp\n\n\n\nEin hÃ¤ufiger Fehler ist, dass man vergisst, dass man zuerst ein R-Paket installieren muss, bevor man es nutzen kann. Auf der anderen Seite muss man ein R-Paket (wie andere Software auch) nur ein Mal installieren - das Paket muss man ein Paket nach jedem Neustart von RStudio mit library() starten.\n\n\n\ndata(\"mariokart\", package = \"openintro\")\n\n\n3.5.4 Einlesen von einer Webseite\nHier ist eine MÃ¶glichkeit, Daten (in Form einer Tabelle) von einer Webseite (URL) in R zu importieren:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nEs ist egal, welchen Namen Sie der Tabelle geben. Ich nehme oft d, d die Daten. AuÃŸerdem ist d kurz, muss man nicht so viel tippen.\nWerfen wir einen Blick in die Tabelle (engl. to glimpse):\n\nglimpse(d)\n## Rows: 143\n## Columns: 12\n## $ id          &lt;dbl&gt; 150377422259, 260483376854, 320432342985, 280405224677, 17â€¦\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7â€¦\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, â€¦\n## $ cond        &lt;fct&gt; new, used, new, new, new, new, used, new, used, used, new,â€¦\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9â€¦\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00â€¦\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47â€¦\n## $ ship_sp     &lt;fct&gt; standard, firstClass, firstClass, standard, media, standarâ€¦\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,â€¦\n## $ stock_photo &lt;fct&gt; yes, yes, no, yes, yes, yes, yes, yes, yes, no, yes, yes, â€¦\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2â€¦\n## $ title       &lt;fct&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW â€¦\n\nHier findet sich eine ErklÃ¤rung des Datensatzes.\n\n\nDownload einer Datendatei (CSV-Format) von einer Webseite\n\n\n3.5.5 Importieren von Ihrem Computer\nStellen Sie zuerst sicher, dass sich die Datendatei in Ihrem RStudio-Projektordner befindet. Dann kÃ¶nnen Sie die Datei einfach so importieren:\n\nd &lt;- read.csv(\"mariokart.csv\")\n\nDieses Video erklÃ¤rt die Schritte des Importierens einer Datendatei von Ihrem Computer.\n\n\n\n\n\n\nHinweis\n\n\n\nEs gibt verschiedene Formate, in denen (Tabellen-)Dateien in einem Computer abgespeichert werden. Die gebrÃ¤uchlichsten sind CSV und Excel. Es gibt auch mehrere R-Befehle, um Daten in R zu importieren, z.B. read.csv() oder data_read(). Praktischerweise kann der R-Befehl data_read() viele verschiedene Formate automatisch einlesen, so dass wir uns nicht weiter um das Format kÃ¼mmern brauchen. Der Vorteil von read.csv ist, dass Sie kein Extra-Paket installiert bzw. gestartet haben mÃ¼ssen.\n\n\n\n3.5.6 Dataframes\nEine in R importierte Tabelle (mit bestimmten Eigenschaften) heiÃŸt Dataframe. Dataframes sind in der Datenanalyse von groÃŸer Bedeutung.\n\nDefinition 3.6 (Dataframe) Ein Dataframe (data frame; auch â€œTibbleâ€ genannt15) ist ein Datenobjekt in R zur Darstellung von Tabellen. Dataframes bestehen aus einer oder mehreren Spalten. Spalten haben einen Namen, sozusagen einen â€œSpaltenkopfâ€. Alle Spalten mÃ¼ssen die gleiche LÃ¤nge haben; anschaulich gesprochen ist eine Tabelle (in R) rechteckig. Jede Spalte einzeln betrachtet kann als Vektor aufgefasst werden. \\(\\square\\)\n\nTabelleÂ 2.2 ist die Tabelle mit den Mariokart-Daten; etwas prÃ¤ziser gesprochen ein Dataframe mit Namen mariokart. Ãœbrigens ist TabelleÂ 2.2 in Normalform (Tidy-Format), vgl. DefinitionÂ 2.9.\n\n\n\n\n\n\nHinweis\n\n\n\nGeben Sie den Namen eines Dataframes ein, um sich den Inhalt anzeigen zu lassen. Beachten Sie, dass Sie die Daten auf diese Weise nur anschauen, nicht Ã¤ndern kÃ¶nnen. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n3.5.7 Tabellen in R betrachten\nWenn Sie in R z.B. die Tabelle mariokart in einer Excel-typischen Ansicht betrachten wollen, klicken Sie am besten auf das Tabellen-Icon im Reiter Environment, gleich neben dem Namen mariokart, s. AbbildungÂ 3.21.\n\n\n\n\n\nAbbildungÂ 3.21: Per Klick auf das Tabellen-Icon kÃ¶nnen Sie eine Tabellenansicht der Tabelle mariokart Ã¶ffnen\n\n\nAlternativ Ã¶ffnet der Befehl View(mariokart) die gleiche Ansicht.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-logic",
    "href": "020-R.html#sec-logic",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.6 LogikprÃ¼fung",
    "text": "3.6 LogikprÃ¼fung\n\nğŸ§‘â€ğŸ“ Wer will schon wieder wen prÃ¼fen?!\n\nIn diesem Abschnitt schauen wir uns LogikprÃ¼fungen an: Wir lassen R prÃ¼fen, ob eine Variable einen bestimmten Wert hat oder grÃ¶ÃŸer/kleiner als ein Referenzwert ist.\nDefinieren wir zuerst eine Variable, x.\n\nx &lt;- 42\n\nDann fragen wir R, ob diese Variable den Wert 42 hat.\n\nx == 42\n## [1] TRUE\n\n\nğŸ¤– Hallo, Mensch. Ja, diese Variable hat den Wert 42.\n\n(Danke, R.)\nMÃ¶chte man mit R prÃ¼fen, ob eine Variable x einen bestimmten Wert (â€œInhaltâ€) hat, so schreibt man:\nx == Wert.\n\n\n\n\n\n\nWichtig\n\n\n\nMan beachte das doppelte Gleichheitszeichen. Zur PrÃ¼fung auf Gleichheit muss man das doppelte Gleichheitszeichen verwenden.\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEin beliebter Fehler ist es, bei der PrÃ¼fung auf Gleichheit, nur ein Gleichheitszeichen zu verwenden, z.B. so: x = 73. Mit einem Gleichheitszeichen prÃ¼ft man aber nicht auf Gleichheit, sondern man definiert die Variable oder bestimmt ein Funktionsargument, s. Kapitel 3.4.1. \\(\\square\\)\n\n\nTabelleÂ 3.1 gibt einen Ãœberblick Ã¼ber wichtige LogikprÃ¼fungen in R.\n\n\n\nTabelleÂ 3.1: Logische PrÃ¼fungen in R\n\n\n\n\n\n\nPrÃ¼fung.auf\nR-Syntax\n\n\n\nGleichheit\nx == Wert\n\n\nUngleichheit\nx != Wert\n\n\nGrÃ¶ÃŸer als Wert\nx &gt; Wert\n\n\nGrÃ¶ÃŸer oder gleich Wert\nx &gt;= Wert\n\n\nKleiner als Wert\nx &lt; Wert\n\n\nKleiner oder gleich Wert\nx &lt;= Wert\n\n\nLogisches UND\n(x &lt; Wert1) & (x &gt; Wert2)\n\n\nLogisches ODER\n(x &lt; Wert1) | (x &gt; Wert2)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#praxisbezug",
    "href": "020-R.html#praxisbezug",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.7 Praxisbezug",
    "text": "3.7 Praxisbezug\n\nğŸ§‘â€ğŸ“Wird R in der Praxis wirklich genutzt? Oder ist R nur der Traum von (vielleicht verwirrten) Profs im Elfenbeinturm?\n\nSchauen wir uns dazu die Suchanfragen bei stackoverflow.com an, dem grÃ¶ÃŸten FAQ-Forum fÃ¼r Software-Entwicklung. Wir vergleichen Suchanfragen mit dem Tag [r] zu Suchanfragen mit dem Tag [spss]16. Die Ergebnisse sind in Abbildung AbbildungÂ 3.22 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 3.22: Suchanfragen nach R bzw SPSS, Stand 2022-02-24\n\n\n\n\nDas ist grob gerechnet ein Faktor von 200 (der Unterschied von R zu SPSS). Dieses Ergebnis lÃ¤sst darauf schlieÃŸen, dass R in der Praxis viel mehr als Excel gebraucht wird.\n\nğŸ§‘â€ğŸ“ Aber ist R wirklich ein Werkzeug, das mir im Job hilft?\n\nViele Firmen weltweit nutzen R zur Datenanalyse, wie diese Liste zeigt.\n\nğŸ‘¨â€ğŸ« R ist der Place-to-be fÃ¼r die Datenanalyse.\n\n\nğŸ§‘â€ğŸ“ Aber ist Datenanalyse wirklich etwas, womit ich in Zukunft einen guten Job bekomme?\n\nBerufe mit Bezug zu Daten, Datenanalyse oder, allgemeiner, KÃ¼nstlicher Intelligenz (artificial intelligence) gehÃ¶ren zu den am meisten wachsenden Berufen:\n\nArtificial intelligence (AI) continues to make a strong showing on our Emerging Jobs lists, which is no surprise. Many jobs that have risen up as a result of AI in ï¬elds like cybersecurity and data science and because itâ€™s is so pervasive many roles may demand more knowledge of AI than you may think. For example, real estate and business development roles. Quelle: LinkedIn",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#aufgaben",
    "href": "020-R.html#aufgaben",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.8 Aufgaben",
    "text": "3.8 Aufgaben\n\nÃœbungsaufgabe 3.4 (Statistik-Meme) Suchen Sie ein schÃ¶nes Meme zum Thema Statistik, Datenanalyse und Data Science. Hier ist ein Startpunkt. \\(\\square\\)\n\n\nTyp-Fehler-R-01\nTyp-Fehler-R-02\nTyp-Fehler-R-03\nTyp-Fehler-R-04\nTyp-Fehler-R-06a\nTyp-Fehler-R-07\nTyp-Fehler-R-08-name-clash\nLogikpruefung1\nLogikpruefung2\nthere-is-no-package\nWertberechnen2\nWertzuweisen_mc\nargumente\nimport-mtcars\nWertzuweisen\nWertpruefen\nwrangle1\nrepro1-sessioninfo",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#vertiefung",
    "href": "020-R.html#vertiefung",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.9 Vertiefung",
    "text": "3.9 Vertiefung\n\n3.9.1 Varianten zu read.csv\n\nHier ist eine weitere MÃ¶glichkeit, um Daten von einem Ordner (egal ob dieser sich im Internet oder auf Ihrem Computer befinde) einzulesen, stellt die Funktion data_read bereit:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nd &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nDer Unterschied ist, dass data_read viele Formate von Daten (Excel, CSV, SPSS, â€¦) verkraftet, wohingegen read.csv nur Standard-CSV einlesen kann.\nSchauen wir uns die letzte R-Syntax en Detail an:\nHey R,\nhol das \"Buch\" easystats aus der BÃ¼cherei und lies es\ndefiniere als \"d\" die Tabelle,\ndie du unter der angegebenen URL findest.\nIn R gibt es oft viele MÃ¶glichkeiten, ein Ziel zu erreichen. Zum Beispiel haben wir hier den Befehl data_read() verwendet, um Daten zu importieren. Andere, gebrÃ¤uchliche Befehle, die CSV-Dateien importieren, heiÃŸen read.csv() (aus dem Standard-R, kein Extra-Paket nÃ¶tig) und read_csv() (aus dem Meta-Paket tidyverse).\n\n3.9.2 Der Dollar-Operator\nIn BeispielÂ 3.2 hatten wir Vektoren definiert. Solche Vektoren fliegen sozusagen frei in Ihrem Environment herum (Schauen Sie mal dort nach!) Die Spalten einer Tabelle sind aber auch Vektoren, nur eben nicht frei im Environment, sondern in eine Tabelle eingebunden.\nMÃ¶chte man diese Vektoren direkt ansprechen, so kann man das mit dem sog. Dollar-Operator $ tun.\nAngenommen, Sie mÃ¶chten sich die Verkaufspreise (total_pr) aus der Tabelle mariokart herausziehen, dann kÃ¶nnen Sie das mit dem Dollar-Operator tun:\n\nmariokart$total_pr\n##   [1]  51.55  37.04  45.50  44.00  71.00  45.00  37.02  53.99  47.00  50.00\n##  [11]  54.99  56.01  48.00  56.00  43.33  46.00  46.71  46.00  55.99 326.51\n##  [21]  31.00  53.98  64.95  50.50  46.50  55.00  34.50  36.00  40.00  47.00\n##  [31]  43.00  31.00  41.99  49.49  41.00  44.78  47.00  44.00  63.99  53.76\n##  [41]  46.03  42.25  46.00  51.99  55.99  41.99  53.99  39.00  38.06  46.00\n##  [51]  59.88  28.98  36.00  51.99  43.95  32.00  40.06  48.00  36.00  31.00\n##  [61]  53.99  30.00  58.00  38.10 118.50  61.76  53.99  40.00  64.50  49.01\n##  [71]  47.00  40.10  41.50  56.00  64.95  49.00  48.00  38.00  45.00  41.95\n##  [81]  43.36  54.99  45.21  65.02  45.75  64.00  36.00  54.70  49.91  47.00\n##  [91]  43.00  35.99  54.49  46.00  31.06  55.60  40.10  52.59  44.00  38.26\n## [101]  51.00  48.99  66.44  63.50  42.00  47.00  55.00  33.01  53.76  46.00\n## [111]  43.00  42.55  52.50  57.50  75.00  48.92  45.99  40.05  45.00  50.00\n## [121]  49.75  47.00  56.00  41.00  46.00  34.99  49.00  61.00  62.89  46.00\n## [131]  64.95  36.99  44.00  41.35  37.00  58.98  39.00  40.70  39.51  52.00\n## [141]  47.70  38.76  54.51\n\nDer Dollar-Operator trennt den Namen der Tabelle vom Namen der Spalte.\nNatÃ¼rlich kÃ¶nnen Sie mit dem resultierenden Vektor beliebig weiterarbeiten, etwa ihn in einem anderen Vektor speichern oder eine Funktion anwenden:\n\nverkaufspreise &lt;- mariokart$total_pr\nmean(verkaufspreise)\n## [1] 49.88049\nmean(mariokart$total_pr)  # synonym zur obigen Zeile\n## [1] 49.88049\n\n\n3.9.3 R-Zertifikat bei LinkedIn\nSie kÃ¶nnen bei LinkedIn ein Zertifikat bekommen, das Ihre R-Kenntnisse dokumentiert. Praktischerweise wird das Zertifikat gleich Ihrem Profil zugeordnet.\n\n3.9.4 R-Funktionen verschachteln\nDas Kombinieren von Funktionen kann kompliziert werden:\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x)-x)) \n## [1] 2\n\nDie Funktion abs(x) gibt den (Absolut-)Betrag von x zurÃ¼ck (entfernt das Vorzeichen, mit anderen Worten).\nHier haben wir die mittlere Absolutabweichung der Elemente von x zum Mittelwert ausgerechnet.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literaturhinweise",
    "href": "020-R.html#literaturhinweise",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.10 Literaturhinweise",
    "text": "3.10 Literaturhinweise\nâ€œWarum R? Warum, R?â€ heiÃŸt ein Kapitel in Sauer (2019), das einiges zum Pro und Contra von R ausfÃ¼hrt. In Kapitel 3 in der gleichen Quelle finden sich viele Hinweise, wie man R startet; In Kapitel 4 werden Grundlagen von â€œErrischâ€ erlÃ¤utert; Kapitel 5 fÃ¼hrt in Datenstrukturen von R ein (schon etwas anspruchsvoller). Alternativ bietet Kapitel 1 von Ismay & Kim (2020) einen guten und sehr anwenderfreundlichen Ãœberblick. Das Buch hat auch den Vorteil, dass es komplett frei online verfÃ¼gbar ist. Vergleichbar dazu ist Ã‡etinkaya-Rundel & Hardin (2021), vielleicht einen Tick formaler; auf jeden Fall genau das richtige Niveau fÃ¼r Bachelor-Statistik in angewandten nicht-technischen StudiengÃ¤ngen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literatur",
    "href": "020-R.html#literatur",
    "title": "\n3Â  Daten einlesen\n",
    "section": "\n3.11 Literatur",
    "text": "3.11 Literatur\n\n\n\n\nÃ‡etinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229â€“237. https://doi.org/10.1177/2515245920918872\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability: A Brief History of a Confused Terminology. Frontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nSauer, S. (2019). Moderne Datenanalyse Mit R: Daten Einlesen, Aufbereiten, Visualisieren Und Modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#footnotes",
    "href": "020-R.html#footnotes",
    "title": "\n3Â  Daten einlesen\n",
    "section": "",
    "text": "Streng genommen ist RStudio fÃ¼r die Datenanalyse irrelevant, aber RStudio ist praktisch, Sie werden es nicht missen wollen.â†©ï¸\nfrÃ¼her hieÃŸ der Dienst â€œRStudio Cloudâ€â†©ï¸\nCRAN: Comprehensive R Archive Networkâ†©ï¸\nÃœbrigens sind tidyverse und easystats Pakete, die nur dafÃ¼r da sind, mehrere Pakete zu installieren. So gehÃ¶ren z.B. zu tidyverse die Pakete ggplot (Daten verbildlichen) und dplyr (Datenjudo). Damit wir nicht alle Pakete einzeln installieren und starten mÃ¼ssen, bietet uns das Paket tidyverse den Komfort, alle die Pakete dieser â€œSammlungâ€ auf einmal zu starten. Praktisch.â†©ï¸\nWenn die Anzahl der zu aktualisierenden Pakete groÃŸ ist, dann besser nicht alle auswÃ¤hlen, sondern nur ein paar. Dann die nÃ¤chsten paar Pakete usw.â†©ï¸\nDatenschutz!â†©ï¸\nStreng genommen sollte man nicht von einer Liste sprechen, da es in R noch einen anderen Objekttyp gibt, der list heiÃŸt, und eine verallgemeinerte Form eines Vektors ist.â†©ï¸\nund viele andere arithmetische Funktionen in Râ†©ï¸\n&gt; ğŸ¤– Naja, manchmal.â†©ï¸\nna.rm steht fÃ¼r remove die NA, also fehlenden Werteâ†©ï¸\nUnd manchmal ist einem das Problem danach schlichtweg egal.â†©ï¸\nhttps://www.youtube.com/watch?v=2Q_ZzBGPdqEâ†©ï¸\nDer Pfad einer Datei sagt, in welchem Ordner und Unterorder und Unter-Unterordner die gesuchte Datei liegt. Ein Pfad kÃ¶nnte z.B. so aussehen: â€œ/Users/sebastiansaueruser/github-repos/statistik1/020-R.qmdâ€.â†©ï¸\nAuf dieser Webseite finden Sie eine groÃŸe Zahl an DatensÃ¤tzen. Nur fÃ¼r den Fall, dass Ihnen langweilig ist.â†©ï¸\nvon â€œtblâ€ wie Tableâ†©ï¸\nDurchgefÃ¼hrt am 2022-02-24, 17:21 CETâ†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html",
    "href": "030-aufbereiten.html",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "4.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#lernsteuerung",
    "href": "030-aufbereiten.html#lernsteuerung",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "4.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n4.1.2 Lernziele\n\nSie kÃ¶nnen folgende Verben des Datenjudo anwenden: arrange, filter, select, summarise, group_by, mutate.\nSie kÃ¶nnen R-Befehle mit der â€œPfeifeâ€ verketten.\n\n4.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n4.1.4 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nÃœbungsaufgabe 4.1 Importieren Sie den Datensatz mariokart. Probieren Sie alle vorgestellten Verben des Datenjudos aus, zunÃ¤chst in dem Sie einfach den R-Code kopieren und selber ausfÃ¼hren.\\(\\square\\)\n\n\n4.1.5 Frag den Bot\n\nğŸ‘¨â€ğŸ« ErklÃ¤re einem FÃ¼nfjÃ¤hrigen, warum Statistik nÃ¼tzlich ist.\n\n\nğŸ¤– Okay, hÃ¶r zu. Stell dir vor, du hast viele Spielzeugautos und du willst herausfinden, welches Auto am meisten bespielt wird. Du kannst jeden Tag zÃ¤hlen, wie oft du jedes Auto benutzt hast. Aber das wÃ¤re sehr mÃ¼hsam und kÃ¶nnte schnell durcheinander gebracht werden. Stattdessen kannst du mit Statistik eine einfachere Methode finden. Du kannst zum Beispiel eine Liste machen und jedes Auto mit einer bestimmten Farbe markieren. Dann kannst du jeden Tag einfach zÃ¤hlen, wie oft du jede Farbe verwendet hast. Am Ende kannst du herausfinden, welches Auto am meisten bespielt wurde, indem du siehst, welche Farbe am meisten verwendet wurde. Das ist ein Beispiel dafÃ¼r, wie Statistik uns dabei helfen kann, Muster in groÃŸen DatensÃ¤tzen zu finden und Entscheidungen zu treffen, ohne alles einzeln zu zÃ¤hlen.\n\nQuelle: ChatGTP 3.5, 2023-02-09",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#datenjudo",
    "href": "030-aufbereiten.html#datenjudo",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.2 Datenjudo",
    "text": "4.2 Datenjudo\n\nDefinition 4.1 (Datenjudo) Mit Datenjudo meint man den Prozess der Aufbereitens, Umformens oder Zusammenfassen von Daten, sowohl fÃ¼r einzelne Beobachtungen (Zeilen einer Datentabelle) oder Variablen (Spalten einer Datentabelle) oder einer ganzen Datentabelle. \\(\\square\\)\n\n\n4.2.1 Die Wahrheit Ã¼ber Data Science\nDenkt man an Data Science, stellt man sich coole Leute vor (in San Francisco oder Berlin), die an abgefahrenen Berechnungen mit hoch komplexen statistischen Modellen fÃ¼r gigantische Datenmengen basteln. TatsÃ¤chlich besteht ein groÃŸer Teil der Arbeit aus dem Aufbereiten von Daten.\n\n4.2.2 Praxisbezug: Aus dem Alltag des Data Scientisten\nLaut dem Harvard Business Review allerdings, verbringen diese Leute â€œ80%â€ ihrer Zeit mit dem Aufbereiten von Daten (Bowne-Anderson, 2018). Ja: mit uncoolen TÃ¤tigkeiten wie Tippfehler aus DatensÃ¤tzen entfernen oder die Daten Ã¼berhaupt nutzbar und verstÃ¤ndlich zu machen.\nDas zeigt zumindest, dass das Aufbereiten von Daten a) wichtig ist und b) dass man allein damit schon weit kommen kann. Eine gute Nachricht ist (vielleicht), dass das Aufbereiten von Daten keine aufwÃ¤ndige Mathematik verlangt, stattdessen muss man ein paar Handgriffe und Kniffe kennen. Daher passt der Begriff Datenjudo vielleicht ganz gut. KÃ¼mmern wir uns also um das Aufbereiten bzw. Umformen von Daten, um das Datenjudo. ğŸ”¢ğŸ¤¹ \\(\\square\\)\n\nBeispiel 4.1 Beispiele fÃ¼r typische TÃ¤tigkeiten des Datenjudos sind:\n\nZeilen filtern (z. B. nur Studentis des Studiengangs X)\nZeilen sortieren (z. B. Studenten mit guten Noten in den oberen Zeilen)\nSpalten wÃ¤hlen (z. B. 100 weitere Produkte ausblenden)\nSpalten in eine Zahl zusammenfassen (z. B. Notenschnitt der 1. Klausur)\nTabelle gruppieren (z. B. Analyse getrennt nach Standorten)\nWerte aus einer Spalte verÃ¤ndern oder neue Spalte bilden (z. B. Punkte in Prozent-Richtige umrechnen).\nâ€¦ \\(\\square\\)\n\n\n\n\n4.2.3 Machâ€™s einfach\nEs gibt einen (einfachen) Trick, wie man umfangreiche Datenaufbereitung elegant geregelt kriegt, klingt fast zu schÃ¶n, um wahr zu sein (s. AbbildungÂ 4.1).\n\n\n\n\n\nAbbildungÂ 4.1: Machâ€™s einfach. Made at imgflip.com, Meme Generator\n\n\nDer Trick besteht darin, komplexe Operationen in mehrere einfache Teilschritte zu zergliedern1. Man kÃ¶nnte vom â€œLego-Prinzipâ€ sprechen, s. AbbildungÂ 4.2. Im linken Teil von AbbildungÂ 4.2 sieht man ein (recht) komplexes Gebilde. Zerlegt man es aber in seine Einzelteile, so sind es deutlich einfachere geometrische Objekte wie Dreiecke oder Quadrate (rechter Teil des Diagramms).\n\n\n\n\n\nAbbildungÂ 4.2: Das Lego-Prinzip\n\n\nDamit Sie es selber einfach machen kÃ¶nnen, mÃ¼ssen Sie selber Hand anlegen. Importieren Sie daher den Datensatz mariokart, z.B. so:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nglimpse(mariokart)\n## Rows: 143\n## Columns: 13\n## $ rownames    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,â€¦\n## $ id          &lt;dbl&gt; 150377422259, 260483376854, 320432342985, 280405224677, 17â€¦\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7â€¦\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, â€¦\n## $ cond        &lt;chr&gt; \"new\", \"used\", \"new\", \"new\", \"new\", \"new\", \"used\", \"new\", â€¦\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9â€¦\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00â€¦\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47â€¦\n## $ ship_sp     &lt;chr&gt; \"standard\", \"firstClass\", \"firstClass\", \"standard\", \"mediaâ€¦\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,â€¦\n## $ stock_photo &lt;chr&gt; \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"yeâ€¦\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2â€¦\n## $ title       &lt;chr&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW â€¦\n\n\nBeispiel 4.2 Sie arbeiten immer noch bei dem groÃŸen Online-Auktionshaus. Mittlerweile haben Sie sich den Ruf des â€œDatenguruâ€ erworben. Vielleicht weil Sie behauptet haben, Data Science sei zu 80% Datenjudo, das hat irgendwie Eindruck geschindetâ€¦ Naja, jedenfalls mÃ¼ssen Sie jetzt mal zeigen, dass Sie nicht nur schlaue SprÃ¼che draufhaben, sondern auch die Daten ordentlich abbÃ¼rsten kÃ¶nnen. Sie analysieren dafÃ¼r im Folgenden den Datensatz mariokart. Na, dann los.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#die-verben-des-datenjudos",
    "href": "030-aufbereiten.html#die-verben-des-datenjudos",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.3 Die Verben des Datenjudos",
    "text": "4.3 Die Verben des Datenjudos\nIm R-Paket dplyr, das wiederum Teil des R-Pakets tidyverse ist, gibt es eine Reihe von R-Befehlen, die das Datenjudo in eine Handvoll einfacher Verben runterbrechen.2 Die wichtigsten Verben des Datenjudos schauen wir uns im Folgenden an.\nWir betrachten dazu im Folgenden einen einfachen (Spielzeug-)Datensatz, an dem wir zunÃ¤chst die Verben des Datenjudos vorstellen, s. TabelleÂ 4.1.\n\n\n\nTabelleÂ 4.1: Ein einfacher Datensatz von schlichtem GemÃ¼t\n\n\n\n\n\n\nid\nname\ngruppe\nnote\n\n\n\n1\nAnni\nA\n2.7\n\n\n2\nBerti\nA\n2.7\n\n\n3\nCharli\nB\n1.7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Verben des Datenjudos wohnen im Paket {dyplr}, welches gestartet wird, wenn Sie library(tidyverse) eingeben. Falls Sie vergessen , das Paket tidyverse zu starten, dann funktionieren diese Befehle nicht.\\(\\square\\)\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: In RStudio kÃ¶nnen Sie per Klick auf das kleine Tabellen-Icon im Bereich Environment die Tabellenansicht einer Tabelle Ã¶ffnen, s. Kapitel 3.5.7. \\(\\square\\)\n\n\n\n4.3.1 Tabelle sortieren: arrange\n\nSortieren der Zeilen ist eine einfache, aber hÃ¤ufige TÃ¤tigkeit des Datenjudos, s. AbbildungÂ 4.3.\n\n\n\n\n\n\n\nAbbildungÂ 4.3: Sinnbild fÃ¼r das Sortieren einer Tabelle mit arrange()\n\n\n\n\n\nBeispiel 4.3 (Was sind die hÃ¶chsten Preise?) Sie wollen mal locker anfangen. Daher stellen Sie sich folgende Frage: Was sind denn eigentlich die hÃ¶chsten Preise, fÃ¼r die das Spiel Mariokart Ã¼ber den Online-Ladentisch geht? Die Spalte des Verkaufspreis heiÃŸt offenbar total_pr (s. Tabelle mariokart). In Excel kann die Spalte, nach der man die Tabelle sortieren mÃ¶chte, einfach anklicken. Ob das in R auch so einfach geht?\n\nmariokart_neu &lt;- arrange(mariokart, total_pr)\nmariokart_neu\n\n\n  \n\n\n\nÃœbersetzen wir die R-Syntax ins Deutsche:\nHey R,\narrangiere (sortiere) `mariokart` nach der Spalte `total_pr`\nGar nicht so schwer.\\(\\square\\)\n\nÃœbrigens wird in arrange() per Voreinstellung aufsteigend sortiert. Setzt man ein Minus vor der zu sortierenden Spalte, wird umgekehrt, also absteigend sortiert:\n\nmario_sortiert &lt;- arrange(mariokart, -total_pr)\n\n\nÃœbungsaufgabe 4.2 Sortierne Sie die Mariokart-Daten absteigend nach der Anzahl der beigelegten LenkrÃ¤der.\\(\\square\\)\n\n\n4.3.2 Zeilen filtern: filter\n\nZeilen filtern bedeutet, dass man nur bestimmte Zeilen (Beobachtungen) behalten mÃ¶chte, die restlichen Zeilen brauchen wir nicht, weg mit ihnen. Wir haben also ein Filterkriterium im Kopf, anhand dessen wir die Tabelle filern, s. AbbildungÂ 4.4.\n\n\n\n\n\n\n\nAbbildungÂ 4.4: Sinnbild fÃ¼r das Filtern einer Tabelle mit filter()\n\n\n\n\n\nBeispiel 4.4 (Ob ein Foto fÃ¼r den Verkaufspreis nÃ¼tzlich ist?) Als nÃ¤chstes kommt Ihnen die Idee, mal zu schauen, ob Auktionen mit Photo der Ware einen hÃ¶heren Verkaufspreis erzielen als Auktionen ohne Photo.\n\nmariokart_neu &lt;- filter(mariokart, stock_photo == \"yes\")\nmariokart_neu\n\n\n  \n\n\n\nSie filtern also die Tabelle so, dass nur diese Auktionen im Datensatz verbleiben, welche ein Photo haben, mit anderen Worten, Auktionen (Beobachtungen) bei denen gilt: stock_photo == TRUE.\\(\\square\\)\n\n\n4.3.3 Komplexeres Filtern\nAngestachelt von Ihren Erfolgen mÃ¶chten Sie jetzt komplexere Hypothesen prÃ¼fen: Ob wohl Auktionen von neuen Spielen und zwar mit Photo einen hÃ¶heren Preis erzielen als die Ã¼brigen Auktionen?\nAnders gesagt haben Sie zwei Filterkriterien im Blick: Neuheit cond und Photo stock_photo. Nur diejenigen Auktionen, die sowohl Neuheit als auch Photo erfÃ¼llen, mÃ¶chten Sie nÃ¤her untersuchen.\n\nmario_filter1 &lt;- filter(mariokart, stock_photo == \"yes\" & cond == \"new\")\nmario_filter1\n\n\n  \n\n\n\nHm. Was ist mit den Auktionen, die entweder Ã¼ber ein Photo verfÃ¼gen oder neu sind (oder beides)?\n\nmario_filter2 &lt;- filter(mariokart, stock_photo == \"yes\" | cond == \"new\")\nmario_filter2\n\n\n  \n\n\n\nHier kÃ¶nnte man noch viele interessante Hypothesen prÃ¼fen, denken Sie sich und tun das auch â€¦\n\nÃœbungsaufgabe 4.3 Filtern Sie die Spiele mit nur einem Lenkrad und ohne Versandkosten.\\(\\square\\)\n\n\nÃœbungsaufgabe 4.4 Filtern Sie die Spiele mit nur einem Lenkrad mit Ã¼berdurchschnittlichen Verkaufspreis. Tipp: Nutzen Sie die Funtion describe_distribution(name_der_tabelle), um den Mittelwert einer Variable des Datensatzes zu erfahren (diese Funktion wohnt im R-Paket easystats. \\(\\square\\)\n\n\n4.3.4 Spalten auswÃ¤hlen mit select\n\nEine Tabelle mit vielen Spalten kann schnell unÃ¼bersichtlich werden. Da lohnt es sich, eine alte goldene Regel zu beachten: Mache die Dinge so einfach wie mÃ¶glich, aber nicht einfacher. WÃ¤hlen wir also nur die Spalten aus, die uns interessieren und entfernen wir die restlichen, s. AbbildungÂ 4.5.\n\n\n\n\n\n\n\nAbbildungÂ 4.5: Sinnbild fÃ¼r das AuswÃ¤hlen von Spalten mit select()\n\n\n\n\n\nBeispiel 4.5 (Fokus auf nur zwei Spalten) Ob wohl gebrauchte Spiele deutlich geringere Preise erzielen im Vergleich zu neuwertigen Spielen? Sie entschlieÃŸen sich, mal ein StÃ¼ndchen auf die relevanten Daten zu starren.\n\nmario_select1 &lt;- select(mariokart, cond, total_pr)\nmario_select1\n\nAha (?)\\(\\square\\)\n\nDer Befehl select erwartet als Input eine Tabelle und gibt (als Output) eine Tabelle zurÃ¼ck - genau wie die meisten anderen Befehle des Datenjudos. Auch wenn Sie nur eine Spalte auswÃ¤hlen, bleibt es eine Tabelle, eben eine Tabelle mit nur einer Spalte.\nselect erlaubt Komfort; Sie kÃ¶nnen Spalten auf mehrere Arten auswÃ¤hlen, z.B.\n\nselect(mariokart, 1, 2)  # Spalte 1 und 2\nselect(mariokart, 2:5)  #  Spalten 2 *bis* 5 \nselect(mariokart, -1)  # Alle Spalte *aber nicht* Spalte 1\n\nVertiefte Informationen zum AuswÃ¤hlen von Spalten mit select findet sich hier.\n\n4.3.5 Spalten zu einer Zahl zusammenfassen mit summarise\n\nSo eine lange Spalte mit Zahlen â€“ mal ehrlich: wer blickt da schon durch? Viel besser wÃ¤re es doch, die Spalte total_pr zu einer Zahl zusammenzufassen, das ist doch viel handlicher. Kurz entschlossen fassen Sie die Spalte total_pr, den Verkaufspreis, zum Mittelwert zusammen, s. AbbildungÂ 4.6.\n\n\n\n\n\n\n\nAbbildungÂ 4.6: Spalten zu einer einzelnen Zahl zusammenfassen mit summaris()\n\n\n\n\n\nBeispiel 4.6 (Was ist der mittlere Verkaufspreis?) Mit summarise, s. ?lst-summarise, kÃ¶nnen wir den mittleren Verkaufspreis der Mariokart-Spiele berechnen.\n\nmariokart_neu &lt;- summarise(mariokart, preis_mw = mean(total_pr))\nmariokart_neu\n\n\n  \n\n\n\nAha! Etwa 50â‚¬ erzielt so eine Auktion im Schnitt.\\(\\square\\)\n\nÃœbersetzen wir ?lst-summarise vom Errischen ins Deutsche:\n\nğŸ§‘â€ğŸ“ Hey R, fasse die Zeilen von total_pr aus mariokart zu einer Zahl zusammen, und zwar mit Hilfe des Mittelwerts. Die resultierende Tabelle nennen wir mariokart_neu, sehr kreativ. Und die resultierende Spalte, die einzige inmariokart_neu, nennen wirpreis_mw`.\n\nEin bisschen abstrakter gesprochen, fasst summarise also eine Spalte zu einer (einzelnen) Zahl zusammen, s. GleichungÂ 4.1.3\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\  \\\\  \\\\ \\\\ \\hline \\end{array} \\qquad \\rightarrow  \\qquad \\begin{array}{|c|} \\hline \\\\  \\hline \\end{array} \\tag{4.1}\\]\n\n4.3.6 Tabelle gruppieren\nEs ist ja gut und schÃ¶n, zu wissen, was so ein Spiel im Schnitt kostet. Aber viel interessanter wÃ¤re es doch, denken Sie sich, zu wissen, ob die neuen Spiele im Schnitt mehr kosten als die alten? Ob R Ihnen so etwas ausrechnen kann?\n\nğŸ¤– Ich tue fast alles fÃ¼r dich. ğŸ§¡\n\nAlso gut, R, dann gruppiere die Tabelle, s. AbbildungÂ 4.7.\n\n\n\n\n\n\n\nAbbildungÂ 4.7: Gruppieren von DatensÃ¤tzen mit group_by()\n\n\n\n\nDurch das Gruppieren wird die Tabelle in â€œTeiltabellenâ€ - entsprechend der Gruppen - aufgeteilt. Das sieht man der R-Tabelle aber nicht wirklich an. Aber alle nachfolgenden Berechnungen werden fÃ¼r jede Teiltabelle einzeln ausgefÃ¼hrt.\n\nBeispiel 4.7 (Mittlerer Preis pro Gruppe) Gruppieren alleine liefert Ihnen zwei (oder mehrere) Teiltabellen, etwa neue Spiele (Gruppe 1, new) vs.Â gebrauchte Spiele (Gruppe 2, used). Mit anderen Worten: Wir gruppieren anhand der Variable cond.\n\nmariokart_gruppiert &lt;- group_by(mariokart, cond)\n\nWenn Sie die neue Tabelle betrachte, sehen Sie wenig Aufregendes, nur einen Hinweis, dass die Tabelle gruppiert ist. Jetzt kÃ¶nnen Sie an jeder Teiltabelle Ihre weiteren Berechnungen vornehmen, etwa die Berechnung des mittleren Verkaufspreises.\n\nsummarise(mariokart_gruppiert, preis_mw = mean(total_pr))\n\n\n  \n\n\n\nLangsam fÃ¼hlen Sie sich als Datenchecker â€¦ ğŸ¥· ğŸ¦¹â€â™€ $\n\n\n4.3.7 Spalten verÃ¤ndern mit mutate\n\nImmer mal wieder mÃ¶chte man Spalten verÃ¤ndern, bzw. deren Werte umrechnen, s. AbbildungÂ 4.8.\n\n\n\n\n\n\n\nAbbildungÂ 4.8: Spalten verÃ¤ndern/neu berechnen mit mutate()\n\n\n\n\n\nBeispiel 4.8 Der Hersteller des Computerspiels Mariokart kommt aus Japan; daher erscheint es Ihnen opportun fÃ¼r ein anstehendes Meeting mit dem Hersteller die Verkaufspreise von Dollar in japanische Yen umzurechnen. Nach etwas Googeln finden Sie einen Umrechnungskurs von 1:133.\n\nmariokart2 &lt;- mutate(mariokart, total_pr_yen = total_pr * 133)\nmariokart2 &lt;- select(mariokart2, total_pr_yen, total_pr)\nmariokart2\n\n\n  \n\n\n\nSicherlich werden Sie Ihre GesprÃ¤chspartner schwer beeindrucken.\\(\\square\\)\n\nMit mutate berechnen Sie eine Spalte x (in einer Tabelle) neu. Die Funktion, die Sie in mutate benennen wird fÃ¼r jede Zeile der Spalte x angewendet.\n\nBeispiel 4.9 (Beispiele fÃ¼r Funktionen fÃ¼r mutate) mutate eignet sich, z.B. um Spalten zu addieren, zu multiplizieren oder sonstwie zu transformieren (z.B. den Logarithmus anwenden oder den Mittelwert der Spalte von jeder Zeile abziehen). \\(\\square\\)\n\n\nğŸ§Ÿâ€â™€ï¸ Statistik, wann braucht man schon sowas!?\n\n\nğŸ‘¨â€ğŸ« Eigentlich nur dann, wenn man die Fakten gut verstehen will, sonst nicht.\n\n\n4.3.8 Zeilen zÃ¤hlen mit count\n\nArbeitet man mit nominalskalierten Daten, ist (fast) alles, was man tun kann, das Zeilen zÃ¤hlen.4\nMan kÃ¶nnte z.B. fragen, wie viele neue und wie viele alte Spiele in der Tabelle (Dataframe) mariokart vorhanden sind.\n\nBeispiel 4.10 Nach der letzten PrÃ¤sentation Ihrer Analyse hat Ihre Chefin gestÃ¶hnt: â€œOh nein, alles so kompliziert. Statistik! Himmel hilf! Kann man das nicht einfacher machen?â€ Anstelle von irgendwelchen komplizierten Berechnungen (Mittelwert?) mÃ¶chten Sie ihr beim nÃ¤chsten Treffen nur zeigen, wie viele Computerspiele neu und wie viele gebraucht sind (in Ihrem Datensatz). Schlichte HÃ¤ufigkeiten also. Hoffentlich ist Ihre Chefin nicht wieder Ã¼berfordertâ€¦\n\nmariocart_counted &lt;- count(mariokart, cond)\nmariocart_counted\n\n\n  \n\n\n\nAha! Es gibt mehr gebrauchte als neue Spiele.\\(\\square\\)\n\nJetzt kÃ¶nnte man noch den Anteil (engl. proportion) ergÃ¤nzen: Welcher Anteil (der 143 Spiele in mariokart) ist neu, welcher gebraucht?\n\nmariocart_counted %&gt;% \n  mutate(Anteil = n / sum(n))\n\n\n  \n\n\n\n\n4.3.9 Fazit: Verben am FlieÃŸband\ndie Befehle (â€œVerbenâ€) des Tidyverse sind jeweils fÃ¼r einzelne, typische Aufgaben des Datenaufbereitens (â€œDatenjudoâ€) zustÃ¤ndig.\nTypischerweise erwarten diese Befehle eine Tabelle (â–¥) als Input und liefern eine Tabelle aus Output zurÃ¼ck, s. AbbildungÂ 4.9.\n\n\n\n\n\nflowchart LR\n  A[\"â–¥\"] --&gt; B[tidyverse-Befehl] --&gt; C[\"â–¥\"] \n\n\n\n\nAbbildungÂ 4.9: Tidyverse-Befehle erwarten normalerweise eine Tabelle (tibble) als Input und geben auch eine Tabelle zurÃ¼ck als Output",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#sec-pipe",
    "href": "030-aufbereiten.html#sec-pipe",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.4 Die Pfeife",
    "text": "4.4 Die Pfeife\nğŸš¬ ğŸ‘ˆ Das ist keine Pfeife, wie RenÃ© Magritte 1929 in seinem berÃ¼hmten Bild schrieb, s. AbbildungÂ 4.10.\n\n\n\n\n\n\n\n\n\n(a) Das ist keine Pfeife. Sondern ein Bild einer Pfeife.\n\n\n\n\n\n\n%&gt;%\n\n\n\n|&gt;\n\n\n\n\n\nAbbildungÂ 4.10: So sieht die Pfeife in R aus5. Links: Ein Bild einer Pfeife. Mitte und Rechts: Die zwei R-Symbole fÃ¼r eine â€œPfeifeâ€ (pipe).\n\n\n\n4.4.1 Russische Puppen\nComputerbefehle, und im Speziellen R-Befehle kann man â€œaufeinanderâ€ â€“ oder vielmehr: ineinander â€“ stapeln, so Ã¤hnlich wie eine russische Puppe (vgl. Kapitel 3.4.3). Schauen wir uns das in einem Beispiel an. Dazu definieren wir zuerst einen Vektor x aus drei Zahlen:\n\nx &lt;- c(1, 2, 3)\n\nUnd dann kommt unser verschachtelter Befehl:\n\nsum(x - mean(x))\n## [1] 0\n\nWie schon erwÃ¤hnt, arbeitet R so einen â€œverschachteltenâ€ Befehl von innen nach auÃŸen ab:\nStart: sum(x - mean(x))\n  â¬‡ï¸ \nSchritt 1: sum(x - 2)\n  â¬‡ï¸ \nSchritt 2: sum(-1, 0, 1)\n  â¬‡ï¸ \nSchritt 3: 0. Fertig. Puh. Kompliziert.\nSoweit kann man noch einigermaÃŸen folgen. Aber das Verschachteln kann man noch extremer machen, dann wirdâ€™s wild. Schauen Sie sich mal folgende (Pseudo-)Syntax an:6\n\n\nListingÂ 4.1: Eine wild verschachtelte Sequenz von R-Befehlen\n\nfasse_zusammen(gruppiere(wÃ¤hle_spalten(filter_zeilen(meine_daten))))\n\n\n\nğŸ¤¯\n\n4.4.2 Die Pfeife zur Rettung\nListingÂ 4.1 ist schon harter Tobak, was fÃ¼r echte Fans. WÃ¤re es nicht einfacher, man kÃ¶nnte ListingÂ 4.1 wie folgt schreiben:\nNimm \"meine_daten\" *und dann*\n  filter gewÃ¼nschte Zeilen *und dann*\n  wÃ¤hle gewÃ¼nschte Spalten *und dann*\n  teile in Subgruppen *und dann*\n  fasse sie zusammen.\n\nDefinition 4.2 (Pfeife) â€œUnd dannâ€ heiÃŸt auf Errisch %&gt;% oder |&gt;. Man nennt diesen Befehl â€œPfeifeâ€ (engl. pipe). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Befehl %&gt;% verknÃ¼pft Befehle. Der Shortcut fÃ¼r diesen Befehl ist Strg-Shift-M. Die Pfeife %&gt;% â€œwohntâ€ im Paket tidyverse.7\n\n\nMittlerweile8 ist auch im Standard-R eine Pfeife eingebaut. die sieht so aus: |&gt;. Die eingebaute Pfeife funktioniert praktisch gleich zur anderen Pfeife %&gt;%, hat aber den Vorteil, dass Sie nicht tidyverse starten mÃ¼ssen. Da wir tidyverse aber sowieso praktisch immer starten werden, bringt es uns keinen Vorteil, die neuere Pfeife des Standard-R |&gt; zu verwenden.9\n\n\n\n\n\n\n\nflowchart TD\n  A[\"meine Daten ğŸ—³\"] --filter_zeilen--&gt;B[\"â–¥\"] \n  B --wÃ¤hle_spalten--&gt; C[\"â–¥\"]\n  C --gruppiere--&gt; D[\"â–¥\"]\n  D --fasse_zusammen--&gt; E[\"â–¥ Fertig. ğŸ¤©\"]\n\n\n\n\n\nAbbildungÂ 4.11: Illustration fÃ¼r eine Pfeifensequenz, es geht vorwÃ¤rts wie am FlieÃŸband.\n\n\n\n\n\nUnd jetzt kommtâ€™s: So eine Art von Befehls-Verkettung gibt es in R. Schauen Sie sich mal ListingÂ 4.2 an:\n\n\nListingÂ 4.2: Eine Pfeifen-Befehlssequenz (Pseudo-Syntax)\n\nmeine_daten %&gt;%\n  filter_gewÃ¼nschte_zeilen() %&gt;%\n  wÃ¤hle_gewÃ¼nschte_spalten() %&gt;%\n  gruppiere() %&gt;%\n  fasse_zusammen() \n\n\n\nSo eine Pfeifen-Befehlsequenz ist ein wie ein FlieÃŸband, an dem es mehrere Arbeitsstationen gibt, s. AbbildungÂ 4.11. Unser Datensatz wird am FlieÃŸband von Station zu Station weitergereicht und an jeder Stelle weiterverarbeitet.\n\n\n\n\n\n\n\nSo kÃ¶nnte Ihre â€œPfeifen-Sequenzâ€ aussehen:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")  # Daten einlesen nicht vergessen\n\nlibrary(tidyverse)  # Die Pfeife wohnt auch im Paket \"tidyverse\"\n\n# Hey R:\nmariokart %&gt;%   # nimm die Tabelle \"mariokart\" und dann...\n  filter(total_pr &lt; 100) %&gt;%  # filter nur die gÃ¼nstigen Spiele und dann...\n  select(cond, total_pr) %&gt;%  # wÃ¤hle die zwei Spalten und dann ...\n  group_by(cond) %&gt;%  # gruppiere die Tabelle nach Zustand des Spiels und dann ...\n  summarise(total_pr_mean = mean(total_pr))  # fasse beide Gruppen nach dem mittleren Preis zusammen\n\n\n  \n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDie Syntax filter(mariokart, total_pr &lt; 100) und die Syntax mariokart |&gt; filter(total_pr &lt; 100) sind identisch.\nAllgemeiner: d |&gt; f(x) = f(d, x).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallbeispiel",
    "href": "030-aufbereiten.html#fallbeispiel",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.5 Fallbeispiel",
    "text": "4.5 Fallbeispiel\n\nÃœbungsaufgabe 4.5 Bevor Sie die LÃ¶sungen der folgenden Fallbeispiele lesen, versuchen Sie die Aufgaben selber zu lÃ¶sen. Ja, ich weiÃŸ, es ist hart, nicht gleich auf die LÃ¶sungen zu schauen! Protipp: Am besten scrollen Sie so, dass Sie die LÃ¶sungen nicht gleich sehen.\\(\\square\\)\n\nSie arbeiten als Diener strategischer Assistent der GeschÃ¤ftsfÃ¼hrerin und sind fÃ¼r Faktenchecks und andere Daten-Aufgaben zustÃ¤ndig. Heute sollen Sie zeigen, was Sie kÃ¶nnen (Schluck).\n\n4.5.1 Forschungsfrage 1\n\nï¸ğŸ‘© Ich wÃ¼rde von Ihnen gerne wissen, was das teuerste Spiel ist, aber jeweils fÃ¼r neue und gebrauchte Spiele. Aber nur fÃ¼r Spiele, die mit Foto verkauft wurden!\n\n\nmariokart %&gt;% \n  filter(stock_photo == \"yes\") %&gt;% \n  group_by(cond) %&gt;% \n  summarise(total_pr_max = max(total_pr))\n\n\n  \n\n\n\nDie Funktion max liefert den grÃ¶ÃŸten Wert eines Vektors zurÃ¼ck:\n\nx &lt;- c(1, 2, 10)\nmax(x)\n## [1] 10\n\n\n4.5.2 Forschungsfrage 2\n\nï¸ğŸ‘©ï¸ Ich wÃ¼rde gerne die mittlere Versandpauschale wissen, aber getrennt nach Anzahl der LenkrÃ¤der, die dem Spiel beigelegt sind. Und ich will nur Gruppen berÃ¼cksichtigen, die aus mindestens 10 Spielen bestehen!\n\nWenn wir die Anzahl der Spiele zÃ¤hlen in AbhÃ¤ngigkeit der beigelegten LenkrÃ¤der (wheels), bekommen wir eine Tabelle mit zwei Spalten: wheels und n. n zÃ¤hlt, wie viele Spiele (Zeilen) in der jeweiligen Gruppe (â€œTeiltabelleâ€) von wheels sind.\n\nmariokart %&gt;%\n  count(wheels)\n\n\n  \n\n\n\nAus dieser Tabellet sehen wir, dass es 3 oder 4 LenkrÃ¤der nur selten (2 bzw. 1 Mal) beigelegt wurden und wir solche Spiele herausfiltern sollten bevor wir den Mittelwert der Versankosten ausrechnen:\n\nmariokart %&gt;%\n  filter(wheels &lt; 3) %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(mittlere_versandkosten = mean(ship_pr),\n            anzahl_spiele = n())\n\n\n  \n\n\n\nDie Funktion n() gibt die Anzahl der Zeilen pro Teiltabelle zurÃ¼ck.\n\n4.5.3 Forschungsfrage 3\n\nï¸ğŸ‘©ï¸ Ich wÃ¼rde gerne den Verkaufspreis in Yen wissen, nicht in Euro. Dann rechne mal den mittleren Verkaufspreis aus und ziehe 10% ab, die wir als Provision unseren VerkÃ¤ufern zahlen mÃ¼ssen.\n\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  mutate(total_pr_yen = total_pr * 133) %&gt;% \n  summarise(preis_yen_mw = mean(total_pr_yen),\n            preis_yen_mw_minus_10proz = preis_yen_mw - 0.1*preis_yen_mw)\n\n\n  \n\n\n\nWie man sieht kann man in summarise auch mehr als eine Berechnung einstellen. In diesem Fall haben wir zwei Berechnungen angestellt: Einmal den Mittelwert und einmal den Mittelwert minus 10% (des Mittelwerts).\n\nÃœbungsaufgabe 4.6 (DYI) Denken Sie sich selber Ã¤hnliche Forschungsfragen aus. Stellen Sie diese einer vertrauenswÃ¼rdigen Kommilitonen bzw. einem vertrauenswÃ¼rdigen Kommilitonen. Schauen Sie, ob Ihre Aufgabe richtig gelÃ¶st wird. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#praxisbezug",
    "href": "030-aufbereiten.html#praxisbezug",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.6 Praxisbezug",
    "text": "4.6 Praxisbezug\nDie Covid19-Epidemie hatte weltweit massive Auswirkungen; auch psychologischer Art wie Vereinsamung, Angst oder Depression. Eine Studie, die die psychologischen Auswirkungen von Mulukom et al. (2020), die unter diesem Projekt bei der Open Science Foundation (OSF) angemeldet ist. Die Daten wurden mit R ausgewertet. Beispielhaft ist hier die R-Syntax zu sehen, die die Autoren zur Datenaufbereitung verwendet haben. Einen guten Teil dieser Syntax kennen Sie aus diesem Kapitel. Diese Studie ist, neben einigen vergleichbaren, ein schÃ¶nes Beispiel, wie Forschung und Praxis ineinander greifen kÃ¶nnen: Angewandte Forschung als Beitrag zur LÃ¶sung eines akuten Problems, der Corona-Pandemie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "030-aufbereiten.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.7 Wie man mit Statistik lÃ¼gt",
    "text": "4.7 Wie man mit Statistik lÃ¼gt\nEin (leider) immer mal wieder zu beobachtender â€œTrickâ€, um Daten zu frisieren ist, nur die Daten zu berichten, die einem in den Kram passen.\n\nBeispiel 4.11 Ei Analysti ğŸ§‘â€ğŸ¦° mÃ¶chte zeigen, dass der Verkaufspreis von Mariokart-Spielen â€œviel zu niedrigâ€ ist. Es muss ein hÃ¶herer Wert rauskommen, findet dis Analysti. Der mittlere Verkaufspreis (im Datensatz mariokart) liegt bei 50 Euro.\n\nâ€ğŸ¦° Kann man den Wert nicht â€¦ â€œkreativ verbessernâ€? Ein paar Statistik-Tricks anwenden?\n\nUm dieses Ziel zu erreichen, teilt dis Analysti den Datensatz in Gruppen nach Anzahl der dem Spiel beigelegten LenkrÃ¤der (wheels). Dann berechnet er den Mittelwert pro Gruppe.\n\nmariokart_wheels &lt;- \nmariokart %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_mean = mean(total_pr),\n            count_n = n())  # n() gibt die Anzahl der Zeilen pro Gruppe an\n\nmariokart_wheels\n\n\n  \n\n\n\nSchlieÃŸlich berechnet unser Analysti den ungewichteten Mittelwert Ã¼ber diese 5 Gruppen:\n\nmariokart_wheels %&gt;% \n  summarise(mean(pr_mean))\n\n\n  \n\n\n\nUnd das Ergebnis lautet: 56 Euro! Das ist doch schon etwas â€œbesserâ€ als 50 Euro.\nNatÃ¼rlich ist es falsch und irrefÃ¼hrend, hier einen ungewichteten Mittelwert zu berechnen. Der gewichtete Mittelwert wÃ¼rde wiederum zum korrekten Ergebnis, 50 Euro, fÃ¼hren.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallstudie",
    "href": "030-aufbereiten.html#fallstudie",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.8 Fallstudie",
    "text": "4.8 Fallstudie\n\n\n\n\n\nAbbildungÂ 4.12: Possierlich: Die Pinguine\n\n\n\nÃœbungsaufgabe 4.7 Machen Sie sich zunÃ¤chst mit dem Pinguin-Datensatz vertraut. Fokussieren Sie sich auf die Zielvariable Gewicht. Die folgende Datenapp ermÃ¶glicht Ihnen, die Verteilung des KÃ¶rpergewichts zu betrachten, wobei sie die Pinguin-Spezies filtern kÃ¶nnen sowie eine MindestlÃ¤nge des Schnabels verlangen kÃ¶nnen. \\(\\square\\)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\nData\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"daten/penguins.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\nBearbeiten Sie die Fallstudie zu Pinguinen von Allison Horst. Sie kÃ¶nnen die Teile auslassen, die Themen beinhalten, die nicht in diesem Kapitel vorgestellt wurden.\nDie Verben des Datenjudos werden hier anschaulich illustriert.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#aufgaben",
    "href": "030-aufbereiten.html#aufgaben",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.9 Aufgaben",
    "text": "4.9 Aufgaben\n\n\n\n\n\n\nChatGPT\n\n\n\nNutzen Sie einen Chat-Bot wie ChatGPT, um sich Hilfe fÃ¼r die R-Syntax geben zu lassen. \\(\\square\\)\n\n\n\nwrangle3\nwrangle4\nwrangle5\nwrangle7\nwrangle9\nwrangle10\ntidydata1\naffairs-dplyr\ndplyr-uebersetzen\nhaeufigkeit01\nmariokart-mean1\nmariokart-mean2\nmariokart-mean3\nmariokart-mean4\nmariokart-max1\nmariokart-max2\nfilter01\naffairs-dplyr\nsummarise01\nsummarise02\nmutate01",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#vertiefung",
    "href": "030-aufbereiten.html#vertiefung",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.10 Vertiefung",
    "text": "4.10 Vertiefung\n\n\n\n\n\n\nHinweis\n\n\n\nIn weiterfÃ¼hrendem Material werden Sie immer wieder auf Inhalte treffen, die Sie noch nicht kennen, die etwa noch nicht im Unterricht behandelt wurden. Seien Sie unbesorgt: In der Regel kÃ¶nnen Sie diese Inhalte einfach auslassen, ohne den Anschluss zu verlieren. Einfach ignorieren. ğŸ˜„\n\n\nHÃ¤ufig ist es nÃ¼tzlich, die Werte einer Variablen umzukodieren, z.B. â€œweiblichâ€ in â€œwâ€ oder in 0. Eine gute MÃ¶glichkeit, dies in R umzusetzen, bietet der Befehl case_when(); der Befehl wohnt im Tidyverse. Hier - und an vielen weiteren Stellen im Internet - finden Sie ein Tutorium.\nWer sich tiefer in das Datenjudo mit dem Tidyverse einarbeiten mÃ¶chte, dem sei z.B. dieser Kurs empfohlen.\nEin gutes und frei verfÃ¼gbares Buch ist das von Wickham & Grolemund (2018); Kap. 5 behandelt (etwas ausfÃ¼hrlicher) die Themen dieses Kapitels.\nDiese Fallstudie hat die Analyse von FlugverspÃ¤tungen zum Thema.\n\n\nhttps://osf.io/z39us/\n\n\nThe COVIDiSTRESS global survey is an international collaborative undertaking for data gathering on human experiences, behavior and attitudes during the COVID-19 pandemic. In particular, the survey focuses on psychological stress, compliance with behavioral guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures, but multiple further items and scales are included for descriptive statistics, further analysis and comparative mapping between participating countries. Round one data collection was concluded May 30. 2020. To gather comparable data swiftly from across the globe, when the Coronavirus started making a critical impact on societies and individuals, the collaboration and survey was constructed as an urgent collaborative process. Individual contributors and groups in the COVIDiSTRESS network (see below) conducted translations to each language and shared online links by their own best means in each country.\n\nDie Daten stehen zur freien VerfÃ¼gung. Sie kÃ¶nnen diese echten Daten eigenstÃ¤ndig analysieren. Diese Datei beinhaltet die finalen, aufbereiteten Daten. Achtung: Die Datei ist recht groÃŸ, ca. 90 MB.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#exkurs",
    "href": "030-aufbereiten.html#exkurs",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.11 Exkurs",
    "text": "4.11 Exkurs\nDall-E 2 ist eine KI, die â€œrealistische Bilder und Kunst aus einer Beschreibung in natÃ¼rlicher Spracheâ€ erstellt.\n\nğŸ‘¨â€ğŸ« Iâ€™d like a mixture between robot und professor, in oil painting\n\n\nğŸ¤– â€¦ s. AbbildungÂ 4.13\n\n\n\n\n\n\nAbbildungÂ 4.13: Bild erzeugt von kÃ¼nstlicher Intelligenz, Quelle: DALL-E 2, 2023-02-09\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Nutzen kÃ¼nstlicher Intelligenz fÃ¼r die Datenanalyse ist natÃ¼rlich breiter: Wenn Sie sich z.B. Ã¼ber die Syntax eines bestimmten Befehls (oder allgemeiner: Vorhabens) nicht sicher sind, fragen Sie sich doch mal einen Bot wie ChatGPT.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literaturhinweise",
    "href": "030-aufbereiten.html#literaturhinweise",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.12 Literaturhinweise",
    "text": "4.12 Literaturhinweise\nSauer (2019), Kap. 7, gibt eine EinfÃ¼hrung in die Datenaufbereitung (mit Hilfe von R), Ã¤hnlich zu den Inhalten dieses Kapitels. Mehr in die Tiefe des â€œDatenjudoâ€ fÃ¼hren Wickham & Grolemund (2018); der Autor Hadley Wickham ist die Leitfigur in der R-Community schlechthin. Er ist einer der Hauptautoren von den beliebten R-Paketen dplyr und ggplot2.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literatur",
    "href": "030-aufbereiten.html#literatur",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.13 Literatur",
    "text": "4.13 Literatur\n\n\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do, According to 35 Data Scientists. Harvard Business Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, & Farias, M. (2020). Psychological Impact of COVID-19 Pandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nSauer, S. (2019). Moderne Datenanalyse Mit R: Daten Einlesen, Aufbereiten, Visualisieren Und Modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., & Grolemund, G. (2018). R FÃ¼r Data Science: Daten Importieren, Bereinigen, Umformen, Modellieren Und Visualisieren (F. Langenau, Ãœbers.; 1. Auflage). Oâ€™Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#footnotes",
    "href": "030-aufbereiten.html#footnotes",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "Genau darin besteht das Wesen einer Analyse: die Zerlegung eines Objekts in seine Bestandteile.â†©ï¸\nFalls Sie das R-Paket tidyverse noch nicht installiert haben sollten, wÃ¤re jetzt ein guter Zeitpunkt dafÃ¼r.â†©ï¸\nEine Alternative, um eine Spalte zu einer Zahl zusammenzufassen, bietet der â€œDollar-Operatorâ€ ($): mean(mariokart$total_pr). Der Dollar-Operator trennt hier die Tabelle von der Spalte: tibble$spalte. Im Gegensatz zu den Verben des Tidyverse (die immer einer Tabelle zurÃ¼ckliefern), liefert der Dollar-Operator einen Vektor (Spalte) zurÃ¼ck. (Diese wird von mean dann zu einer einzelnen Zahl zusammengefasst.)â†©ï¸\nJa, das ist traurig.â†©ï¸\nJaja, das ist keine Pfeife, sondern ein Symbol einer Pfeifeâ€¦â†©ï¸\nEin beliebter Fehler ist es Ã¼brigens, nicht die richtige Zahl an schlieÃŸenden Klammern hinzuschreiben, z.B. fasse_zusammen(gruppiere(wÃ¤hle_spalten(filter_zeilen(meine_daten)))) FALSCHE ZAHL AN KLAMMERN.â†©ï¸\nGenauer gesagt im Paket magrittr, welches aber under the hood von tidyverse geladen wird. Also nichts, um dass Sie sich kÃ¼mmern mÃ¼ssten.â†©ï¸\nSeit R 4.1â†©ï¸\nAber auch keinen Nachteil. Unter Tools &gt; Global Optionsâ€¦ kÃ¶nnen Sie einstellen, dass der Shortcut Strg-Shift-M die eingebaute Pfeife verwendet.â†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#lernsteuerung",
    "href": "040-verbildlichen.html#lernsteuerung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n5.1.2 Lernziele\n\nSie kÃ¶nnen erlÃ¤utern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arte von Datendiagrammen.\nSie kÃ¶nnen typische Datendiagramme mit R visualisieren.\nSie kÃ¶nnen zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\n\n\n5.1.4 Wozu das alles?\n\n\n\n\nQuelle: GIPHY\n\n\n\nğŸ¥· Wir mÃ¼ssen die Galaxis retten, Kermit.\n\n\nğŸ¸ Schlock",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heiÃŸt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte, s. AbbildungÂ 5.1.\n\n\n\n\n\nAbbildungÂ 5.1: Dinosaurier und Kreis: Gleiche statistischen Kennwerte\n\n\n\nQuelle\n\nIn AbbildungÂ 5.1 sieht man zwei verschiedene â€œBilderâ€, also DatensÃ¤tze: einmal einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschiedene sind, sind die zentralen statistischen Kennwerte (praktisch) identisch.\nIn die gleiche Bresche schlÃ¤gt â€œAnscombes Quartettâ€, s. AbbildungÂ 5.2: Es zeigt 4 DatensÃ¤tze, in denen die zentralen Statistiken fast identisch sind, also Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthÃ¼llt, was der Statistik (als Kennzahl) verhÃ¼llt bleibt.\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Diagramme kÃ¶nnen Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier DatensÃ¤tzen\n\n\n\nQuelle\n\nUnter visueller Cortex ist sehr leistungsfÃ¤hig. Wir kÃ¶nnen ohne MÃ¼he eine groÃŸe Anzahl an Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen.\n\n\n\n\n\n\nTipp\n\n\n\nNutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mÃ¤chtig.\n\n\n\n5.2.1 Datendiagramm\nEin Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwÃ¤ndiges (und ansprechendes) Datendiagramm) Hier finden Sie ein Beispiel fÃ¼r ein Datendiagramm, das mit R erzeugt wurde (Scherer et al., 2019).\n\n\n5.2.2 Ein Bild hat nicht so viele Dimensionen\nAbbildungÂ 5.3 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer â€œDimensionâ€ entsprechen. Wie man (nicht) sieht, wird es langsam unÃ¼bersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die â€œDimensionalitÃ¤tâ€ eines Diagramms hat ihre Grenzen, vielleicht bei 4-6 Variablen.\n\n\n\n\n\n\n\nAbbildungÂ 5.3: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\nMÃ¶chten wir den Zusammenhang von vielen Variablen, z.B. mehr als 5, verstehen, kommen wir mit Bildern nicht weiter. Dann brauchen wir andere Werkzeuge: statistics to the rescue.\n\n\n\n\n\n\nHinweis\n\n\n\nBei klaren ZusammenhÃ¤ngen und wenig Variablen braucht man keine (aufwÃ¤ndige) Statistik. Ein Bild (Datendiagramm) ist dann (oft) ausreichend. Man kÃ¶nnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. 4-6 Variablen nicht gleichzeitig umgehen kann.\n\n\n\nÃœbungsaufgabe 5.1 Wie viele Variablen sind in AbbildungÂ 5.3 dargestellt?1\n\nEine weitere MÃ¶glichkeit, mehr Variablen in einem Diagramm unterzubringen, ist, die â€œFlatlandsâ€ zu verlassen, also von 2D auf 3D zu wechseln, s. hier, s. AbbildungÂ 5.4.\n\n\n\n\n\n\n\nAbbildungÂ 5.4: Eine 3D-Karte der Erde\n\n\n\nQuelle: Plotly",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelleÂ 5.1 zeigt eine - sehr kurze Nomenklatur - an Datendigrammen.2\n\n\n\nTabelleÂ 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefÃ¼lltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefÃ¼lltes Balkendiagramm\nBoxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir arbeiten hier mit dem Datensatz mariokart. Hilfe bzw. ein Data-Dictionary (Codebook) finden Sie hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung: nominale Variable\n\nDefinition 5.1 (Verteilung) Eine (HÃ¤ufigkeits-)Verteilung einer Variablen \\(X\\) schlÃ¼sselt auf, wie hÃ¤ufig jede AusprÃ¤gung von \\(X\\) ist.\\(\\square\\)\n\n\nBeispiel 5.2 TabelleÂ 5.2 zeigt die HÃ¤ufigkeitsverteilung von cond aus dem Datensatz mariokart. Die Variable hat 5 AusprÃ¤gungen; z.b. kommt die AusprÃ¤gung new 59 mal vor.\\(\\square\\)\n\n\n\n\nTabelleÂ 5.2: HÃ¤ufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. AbbildungÂ 5.5. Wie man sieht, besteht so ein Diagramm als Balken, daher heiÃŸt es Balkendiagramm3. Man kann so ein Diagramm um 90Â° drehen; keine Ausrichtung ist unbedingt besser als die andere.\n\nDefinition 5.2 (Balkendiagramm) Ein Balkendiagramm eignet sich, um HÃ¤ufigkeiten darzustellen\n\n\n\n\n\n\n\n\nAbbildungÂ 5.5: HÃ¤ufigkeitsverteilung der Variable cond\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.6: Balkendiagramm mit dem R-Paket DataExplorer\n\n\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. AbbildungÂ 5.6.\nZuerst importieren wir die Daten, s. ListingÂ 5.1.\n\n\nListingÂ 5.1: Mariokart-Daten importieren von einer Webseite\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n\nAuÃŸerdem nicht vergessen, das Paket DataExplorer zu starten, s. ListingÂ 5.2.4 In diesem Paket â€œwohnenâ€ die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden.\n\n\nListingÂ 5.2: Wir starten das R-Paket DataExplorer\n\nlibrary(DataExplorer)\n\n\n\n\n\nListingÂ 5.3: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\nListingÂ 5.4: Syntax zur Erstellung eines Balkendiagramms\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\nDie Syntax ist in ListingÂ 5.4 abgedruckt5 . Ãœbersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz mariokart *und dann*\n  wÃ¤hle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm.\n\nÃœbungsaufgabe 5.2 (Spalten wÃ¤hlen fÃ¼r das Balkendiagramm) HÃ¤tten wir andere Spalten ausgewÃ¤hlt, so wÃ¼rde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie kÃ¶nnen auch mehrere Variablen auf einmal auswÃ¤hlen. Probieren Sie das doch mal aus!\n\n\n\n5.4.2 Verteilung: quantitative Variable\n\n5.4.2.1 Histogramm\nBei einer quantitativen Variablen mit vielen AusprÃ¤gungen wÃ¤re ein Balkendiagramm nicht so aussagekrÃ¤ftig, s. AbbildungÂ 5.7. Es gibt einfach zu viele AusprÃ¤gungen.\n\n\n\n\n\n\n\nAbbildungÂ 5.7: Balkendiagramm fÃ¼r total_pr\n\n\n\n\nDie LÃ¶sung: Wir reduzieren die Anzahl der AusprÃ¤gungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger AusprÃ¤gungen zu bekommen, kÃ¶nnen wir einfach Gruppen definieren, z.B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 2: 11-15 Dollar â€¦\n\nIn AbbildungÂ 5.8 sind z.B. die AusprÃ¤gungen des Verkaufspreis (total_pr) in in Gruppen der Breite von 5 Dollar aufgeteilt worden. ZusÃ¤tzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\nAbbildungÂ 5.8: Balkendiagramm fÃ¼r total_pr\n\n\n\n\n\nDefinition 5.3 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der HÃ¤ufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt sind. Die HÃ¶he der Balken zeigt die HÃ¤ufigkeit der Daten in dieser Gruppe/in diesem Balken6.\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten nicht sehr viele und nicht sehr wenig sein, s. AbbildungÂ 5.9 links bzw. AbbildungÂ 5.9, rechts.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildungÂ 5.9: Nicht zu wenig und nicht zu viele Balken im Balkendiagramm\n\n\nZur Erstellung eines Histogramms kÃ¶nnen Sie die Syntax ListingÂ 5.5 nÃ¼tzen, vgl. AbbildungÂ 5.10, links.\n\n\nListingÂ 5.5: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 5.10: Eine stetige Verteilung verbildlichen\n\n\n\n5.4.2.2 Dichtediagramm\nAbbildungÂ 5.11 fÃ¼gt zu AbbildungÂ 5.8 ein Dichtediagramm hinzu (rote Linie). Ein Dichtediagramm Ã¤hnelt einem â€œglattgeschmirgeltemâ€ Histogramm.\n\nDefinition 5.4 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglÃ¤ttet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden.7\n\n\n\n\n\n\n\n\nAbbildungÂ 5.11: Balkendiagramm fÃ¼r total_pr\n\n\n\n\n\nÃœbungsaufgabe 5.3 Erstellen Sie das Diagramm AbbildungÂ 5.10, rechtes Teildiagramm!8\\(\\square\\)\n\n\n5.4.2.3 Eigenschaften von Verteilungen\nVerteilungen unterscheiden sich z.B. einerseits in ihrem â€œtypischenâ€ oder â€œmittlerenâ€ Wert9 und anderseits in ihrer Streuung10\n(Diagramme von) Verteilungen kÃ¶nnen symmetrisch oder schief (nicht symmetrisch) sein, s. AbbildungÂ 5.12.\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildungÂ 5.12: Symmetrische vs.Â schiefe Verteilung, verbildlicht\n\n\nAbbildungÂ 5.13 zeigt verschiedene Formen von Verteilungen. â€œBimodalâ€ meint â€œzweigipfligâ€ und â€œmultimodalâ€ entsprechend â€œmehrgipfligâ€.\n\n\n\n\n\n\n\nAbbildungÂ 5.13: Verschiedene Verteilungsformen\n\n\n\n\nQuelle: ifes/FOM Hochschule\n\n5.4.3 Normalverteilung\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer quantitativen Variablen. Aber sie ist besonders wichtig, und ist daher hier herausgestellt.\nEine Normalverteilung sehen Sie in AbbildungÂ 5.12, links. Sie hat u.a. folgende Eigenschaften:\n\nsymmetrisch\nglockenfÃ¶rmig\nstetig\neingipflig (unimodal)\nMittelwert, Median und Modus sind identisch\n\n\nBeispiel 5.3 Beispiele fÃ¼r normalverteilte Variablen sind KÃ¶rpergrÃ¶ÃŸe von MÃ¤nnern oder Frauen, IQ-Werte, PrÃ¼fungsergebnisse, Messfehler, Lebensdauer von GlÃ¼hbirnen, Gewichte von Brotlaiben, Milchproduktion von KÃ¼hen, Brustumfang schottischer Soldaten (Lyon, 2014).\\(\\square\\)\n\nDie Normalverteilung ist von hoher Bedeutung, da sich diese Verteilung unter (recht hÃ¤ufigen) Bedingungen zwangslÃ¤ufig ergeben muss.\n\nDefinition 5.5 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhÃ¤ngiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\nDieses PhÃ¤nomen kann man gut anhand des Galton-Bretts veranschaulichen.\n\n\n\n\n\n\n\nParameter der Normalverteilung\n\n\n\nEine Normalverteilung lÃ¤sst sich exakt beschreiben anhand zweier Parameter: ihres zentralen Werts (Mittelwerts), \\(\\mu\\) und ihrer Streuung (Standardabweichung), \\(\\sigma\\). \\(\\square\\)\n\n\nAbbildungÂ 5.14 zeigt interaktive Beispiele fÃ¼r Normalverteilung. WÃ¤hlen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler. Quelle\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\n\n\n\n\n\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\n\n\n\n\n\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\n\n\n\n\n\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\n\n\n\n\n\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\n\n\n\n\n\n\nshow_curve = true\n\n\n\n\n\n\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\n\n\n\n\n\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.14: Interaktives Beispiel fÃ¼r Normalverteilungen.\n\n\nKennt man diese beiden Parameter, so kann man einfach angeben, welcher Anteil der FlÃ¤che sich in einem bestimmten Bereich befindet, s. AbbildungÂ 5.15.\nDavon leitet sich die â€œ68-95-99-Prozentregelâ€ ab:\n\n\n\\(68\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{,}7\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.15: Die FlÃ¤cheninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in AbhÃ¤ngigkeit der SD-Einheiten\n\n\nBy Ainali - Own work, CC BY-SA 3.0",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.5 ZusammenhÃ¤nge verbildlichen",
    "text": "5.5 ZusammenhÃ¤nge verbildlichen\n\n5.5.1 Zusammenhang: nominale Variablen\n\nBeispiel 5.4 (Beispiele fÃ¼r ZusammenhÃ¤nge bei nominalen Variablen) Â \n\nHÃ¤ngt Berufserfolg (FÃ¼hrungskraft ja/nein) mit dem Geschlecht zusammen?\nHÃ¤ngt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen Automarke und politische PrÃ¤ferenz einer Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primÃ¤r bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. AbbildungÂ 5.16.\n\n\n\n\n\n\n\n\n\n(a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten\n\n\n\n\n\n\n\n\n\n(b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\n\n\n\nAbbildungÂ 5.16: Zusammenhang zwischen nominalskalierten Variablen verbildlichen\n\n\nTatsÃ¤chlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (AbbildungÂ 5.16, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der HÃ¤lfte der FÃ¤lle.\nAnders sieht es aus fÃ¼r die Frage, ob ein (oder mehrere) LenkrÃ¤der dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach â€œFoto des Produkts dabeiâ€ betraf (AbbildungÂ 5.16, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten).\nAnders gesagt: Unterscheiden sich die â€œFÃ¼llhÃ¶heâ€ in den Diagrammen, so gibt es einen Unterschied hinsichtlich â€œFoto ist dabeiâ€ zwischen den beiden Gruppen (linker vs.Â rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs.Â gebrauchte Spiele), so spielt z.B. die Variable â€œFoto dabeiâ€ offenbar eine Rolle. Dann hÃ¤ngen Neuwertigkeit und â€œFoto dabeiâ€ also zusammen!\nSo kÃ¶nnen Sie sich in R ein gefÃ¼lltes Balkendiagramm ausgeben lassen, s. AbbildungÂ 5.17.\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\nAbbildungÂ 5.17: Ein gefÃ¼lltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nGefÃ¼llte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei AusprÃ¤gungen aufweisen, sonst sind die ZusammenhÃ¤nge nicht mehr so gut zu erkennen.\\(\\square\\)\n\n\n\n5.5.2 Zusammenhang: metrisch\nDen (etwaigen) Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). AbbildungÂ 5.18 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine â€œTrendgeradeâ€ (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schlieÃŸen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je hÃ¶her der Startpreis, desto hÃ¶her der Abschlusspreis, zumindest tendenziell. Diese Gerade liegt â€œmittigâ€ in den Daten (wir definieren dies spÃ¤ter genauer). Diese Trendgerade gibt Aufschluss Ã¼ber â€œtypischeâ€ Werte: Welcher Y-Wert ist â€œtypischâ€ fÃ¼r einen bestimmten X-Wert?\nAbbildungÂ 5.18 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis. Das erkennt man an der sinkenden Trendgeraden.\nDie Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. AbbildungÂ 5.20.\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) negativer, eher schwacher Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 5.18: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\nDefinition 5.6 (Linearer Zusammenhang) LÃ¤sst sich die Beziehung zwischen zwei Variablen mit einer Gerade visualisieren, so spricht man von einem linearen Zusammenhang. Ã„ndert man eine der beiden Variablen um einen bestimmten Wert (z.B. 1), so Ã¤ndert sich die andere um einen proportionalen Weg (z.B. 0.5). \\(\\square\\)\n\nNatÃ¼rlich kÃ¶nnte man auch nicht-lineare ZusammenhÃ¤nge untersuchen, aber der Einfachheit halber konzentrieren wir uns mit linearen; Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge sind in AbbildungÂ 5.19 zu sehen.\n\n\n\n\n\n\n\nAbbildungÂ 5.19: Beispiele nichtlinearer ZusammenhÃ¤nge\n\n\n\n\n\nDefinition 5.7 (Richtig und StÃ¤rke eines Zusammenhang) Gleichsinnige (positive) ZusammenhÃ¤nge erkennt man an aufsteigenden Trendgeraden; gegensinnigen (negative) ZusammenhÃ¤nge an absteigenden Trendgeraden:\n\nâ• : â¬†ï¸\nâ– : â¬‡ï¸\n\nStarke ZusammenhÃ¤nge erkennt man an schmalen Ellipsen (â€œBaguetteâ€); schwache ZusammenhÃ¤nge an breiten Ellipsen (â€œTorteâ€):\n\nschwach: ğŸ¥®\nstark: ğŸ¥–\n\n\\(\\square\\)\n\nAbbildungÂ 5.20 bietet einen Ãœberblick Ã¼ber verschiedene Beispiele von Richtung und StÃ¤rke von ZusammenhÃ¤ngen.\n\n\n\n\n\n\n\nAbbildungÂ 5.20: Lineare ZusammenhÃ¤nge verschiedener StÃ¤rke und Richtung\n\n\n\n\n\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgraf\n\nIn AbbildungÂ 5.20 ist fÃ¼r jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und StÃ¤rke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht fÃ¼r einen positiven Zusammenhang, ein negatives Vorzeichen fÃ¼r einen negativen Zusammenhang. Der (Absolut-)Wert gibt die StÃ¤rke des linearen Zusammenhangs an (Cohen, 1992):\n\nÂ±0: Kein Zusammenhang\nÂ±0.1: schwacher Zusammenhang\nÂ±0.3: mittlerer Zusammenhang\nÂ±0.5: starker Zusammenhang\nÂ±1: perfekter Zusammenhang\n\nAbbildungÂ 5.21 hat die gleiche Aussage, ist aber plakativer, indem StÃ¤rke (schwach, stark) und Richtung (positiv, negativ) gegenÃ¼bergestellt sind.\n\n\n\n\n\n\n\nAbbildungÂ 5.21: Ãœberblick Ã¼ber starke vs.Â schwache bzw. positive vs.Â negative ZusammenhÃ¤nge\n\n\n\n\nMan sieht in AbbildungÂ 5.20 und AbbildungÂ 5.21, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade 11 (blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke ZusammenhÃ¤nge mit einer schmaler Ellipse einhergehen und schwache ZusammenhÃ¤nge mit einer breiten Ellipse einhergehen.\nAbbildungÂ 5.22 zeigt interaktive Beispiele fÃ¼r (lineare) ZusammenhÃ¤nge. Quelle\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.22: Interaktives Beispiel fÃ¼r Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und machmal gehÃ¶rt Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhÃ¤ngen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. Starten Sie dieses Paket, s. ListingÂ 5.2. AuÃŸerdem mÃ¼ssen wir noch die Daten importieren, falls noch nicht getan, s. ListingÂ 5.1.\nSo, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf metrische Variablen konzentrieren wollen, wÃ¤hlen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewÃ¤hlten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primÃ¤r interessiert. Das Ergebnis sieht man in AbbildungÂ 5.23.\n\nmariokart %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildungÂ 5.23: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nAhaâ€¦ Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafÃ¼r sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur VerkÃ¤ufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100). Das Ergebnis ist in AbbildungÂ 5.24 zu sehen.\n\nmariokart2 &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nmariokart2 %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildungÂ 5.24: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nOhne Extremwerte schÃ¤lt sich ein deutlicheres Bild (AbbildungÂ 5.24) hervor: Startpreis (start_pr) und Anzahl der RÃ¤der (wheels) scheinen am stÃ¤rksten mit dem Abschlusspreis zusammenzuhÃ¤ngen.\nDas Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle Ã¼brigen Variablen kommen jeweils einmal als X-Variable vor.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.6 Unterschiede verbildlichen",
    "text": "5.6 Unterschiede verbildlichen\n\n5.6.1 Unterschied: nominale Variablen\nGute Nachrichten: FÃ¼r nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von ZusammenhÃ¤ngen als auch von Unterschieden an. Genau genommen zeigt ja AbbildungÂ 5.16 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Photos beiliegen. Und wie man in AbbildungÂ 5.16 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen hÃ¶her als bei gebrauchten Spielen.12\n\n5.6.2 Unterschied: quantitative Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich unterscheiden. Genauer gesagt untersucht man z.B. oft, ob sich die Mittelwerte der beiden Gruppen zwischen der Zielvariablen deutlich unterscheiden. Das hÃ¶rt sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. AbbildungÂ 5.25.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildungÂ 5.25: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von AbbildungÂ 5.25 zeigt das Histogramm von total_pr, getrennt fÃ¼r neue und gebrauchte Spiele, vgl. AbbildungÂ 5.10. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsfrom, den Boxplot.13\n\n\n\n\n\n\n\n\n\n(a) Y: Abschlusspreis, X: Zustand\n\n\n\n\n\n\n\n\n\n(b) Y: Abschlusspreis, X: Photo dabei?\n\n\n\n\n\n\nAbbildungÂ 5.26: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von AbbildungÂ 5.26 zeigt den Unterschied in den Verteilungen von total_pr, einmal fÃ¼r die neuen Computerspiele (cond == new) und einmal fÃ¼r gebrauchte Spiele (cond == used).\nWas ein â€œdeutlicherâ€14 Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\nDefinition 5.8 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms.15 Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar.\\(\\square\\)\n\nIn AbbildungÂ 5.27 sieht man die â€œÃœbersetzungâ€ von Histogramm (oben) zu einem Boxplot (unten).\n\n\n\n\n\n\n\nAbbildungÂ 5.27: Ãœbersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die â€œAnatomieâ€ des Boxplots nÃ¤her an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto grÃ¶ÃŸer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie â€œAntennenâ€ des Boxplots zeigen die Streuung in den kleinsten 25% der Werte (linke Antenne) bzw. die Streuung der grÃ¶ÃŸten 25% der Werte (rechte Antennen). Je lÃ¤nger die Antenne, desto grÃ¶ÃŸer die Streuung.\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, auÃŸerhalb der Antennen gezeigt werden. Daher ist die AntennenlÃ¤nge auf die 1,5-fache LÃ¤nge der Box beschrÃ¤nkt. Werte die auÃŸerhalb dieses Bereichs liegen (also mehr als das 1,5-fache der BoxlÃ¤nge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.h. sie ist schief). Gleiches gilt fÃ¼r die AntennenlÃ¤ngen: Sind die Antennen gleich lang, so ist der Ã¤uÃŸere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der LenkrÃ¤der untersucht. Jetzt mÃ¶chten Sie eine sehr Ã¤hnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten LenkrÃ¤der? Flink erstellen Sie dazu folgendes Diagramm, AbbildungÂ 5.28, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl LenkrÃ¤der (by = \"wheels).\nAber ganz glÃ¼cklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wÃ¤re eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen wÃ¼rde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von AbbildungÂ 5.28) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert.16 Aber wir mÃ¶chten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir mÃ¶chten wheels als nominale Variable definieren. Das kann man mit dem Befehle factor(wheels) erreichen (verpackt in mutate), s. AbbildungÂ 5.28, rechts.\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  mutate(wheels = factor(wheels)) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildungÂ 5.28: Abschlusspreis nach Anzahl von beigelegten LenkrÃ¤dern\n\n\nSie schliÃŸen aus dem Bild, dass LenkrÃ¤der und Preis (positiv) zusammenhÃ¤ngen. Allerdings scheint es wenig Daten fÃ¼r wheels == 4 zu geben. Das prÃ¼fen Sie nach:\n\nmariokart2 %&gt;% \n  count(wheels)\n\n\n  \n\n\n\nTatsÃ¤chlich gibt es (in mariokart2) auch fÃ¼r 3 LenkrÃ¤der schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten.\\(\\square\\)\n\nÃœbrigens bezeichnet Sie Ihre Chefin nur noch als â€œDatengottâ€.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.7 So lÃ¼gt man mit Statistik",
    "text": "5.7 So lÃ¼gt man mit Statistik\nDiagramme werden hÃ¤ufig eingesetzt, um die Wahrheit â€œaufzuhÃ¼bschenâ€.\n\n5.7.1 Achsen manipulieren\nAchsen zu stauchen ist ein einfacher Trick, s. AbbildungÂ 5.29.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.29: Stauchen der Y-Achse, um mit Statistik zu lÃ¼gen\n\n\nNatÃ¼rlich kann man auch durch â€œAbschneidenâ€ der Y-Achse einen eindrucksvollen Effekt erzielen, s. AbbildungÂ 5.30.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.30: Abschneiden der Y-Achse, um mit Statistik zu lÃ¼gen\n\n\n\n5.7.2 Scheinkorrelation\nMesserli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: LÃ¤nder), s. AbbildungÂ 5.31. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?)\n\n\n\n\n\nAbbildungÂ 5.31: Schokolodenkonsum und Nobelpreise\n\n\nLeider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhÃ¤ngen, heiÃŸt das nicht, dass die Variable die Ursache und die andere die Wirkung sein muss. So kÃ¶nnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In hÃ¶her entwickelten LÃ¤ndern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu LÃ¤ndern mit geringerem Entwicklungsstand.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.8 Praxisbezug",
    "text": "5.8 Praxisbezug\nEin, wie ich finde schlagendes Beispiel zur StÃ¤rke von Datendiagrammen ist AbbildungÂ 5.32. Das Diagramm zeigt die HÃ¤ufigkeit von Masern, vor und nach der EinfÃ¼hrung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurÃ¼ck. Das Diagramm und weitere finden sich in Ã¤hnlicher Form im Wall Street Journal.\n\n\n\n\n\nAbbildungÂ 5.32: HÃ¤ufigkeit von Masern und Impfung in den USA, Lizenz: MIT\n\n\nQuellcode Datenquelle\nIn der â€œfreien Wildbahnâ€ findet man hÃ¤ufig sog. â€œTortendiagrammeâ€. Zwar sind sie beliebt, doch ist von ihrer Verwendung zumeist abzuraten; vgl. auch hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\nEinen Ãœberblick Ã¼ber verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur findet sich bei data-to-vis.\n\n5.9.1 Animation\nEine weitere nÃ¼tzliche Art von Visualisierung sind Karten und Animationen. So zeigt z.B. AbbildungÂ 5.33 die VerÃ¤nderung der Lebenserwartung (in Jahren) Ã¼ber die letzten Dekaden.\n\n\n\n\n\nAbbildungÂ 5.33: Animation zur VerÃ¤nderung der Lebenserwartung\n\n\nDer Quellcode der Animation ist hier zu finden.\nIn einigen Situation kÃ¶nnen Animationen zweckdienlich sein. AuÃŸerdem sind sie mitunter nett anzuschauen, s. AbbildungÂ 5.34.\n\n\n\n\n\nAbbildungÂ 5.34: VerÃ¤nderung des Zusammenhangs von Lebenswertung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\nNatÃ¼rlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animationen ziemlich atemberaubend.\n\n5.9.2 Schicke Diagramme\nEin Teil der Diagramm dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen, so lautet die etwa die Syntax von AbbildungÂ 5.26 wie folgt.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMÃ¶chte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median heraustellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.B.) mit ggpubr, s. AbbildungÂ 5.35.\n\nggviolin(mariokart2, x = \"cond\", y = \"total_pr\",\n         add = \"mean_sd\") \n\n\n\n\n\n\nAbbildungÂ 5.35: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nEin â€œViolinenplotâ€ hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die â€œViolineâ€, desto mehr Beobachtungen gibt es an dieser Stelle. Weitere Varianten zum Violinenplot mit ggpubr finden sich hier.\nÃœbrigens sind Modelle - und Diagramme sind Modelle - immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen. Dieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.\nEin weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heiÃŸt ggstatsplot.\nAbbildungÂ 5.36 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart2,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrÃ¼ckt statistische Kennzahlen\n)\n\n\n\n\n\n\nAbbildungÂ 5.36: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. MÃ¶chte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE.17.\n\nğŸ§‘â€ğŸ“ Ich wÃ¼rde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\nğŸ‘¨â€ğŸ« Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.\n\n\n5.9.3 Farbwahl\nEinige Ãœberlegungen zur Farbwahl findet sich in diesem Post; ausfÃ¼hrlichere ErlÃ¤uterung bietet Wilke (2019), s. Kap. 4.\nSo ist die Farbpalette von Okabe und Ito (vgl. Ichihara et al., 2008) empfehlenswert, da sie auch bei Schwarz-WeiÃŸ-Druck und bei SehschwÃ¤chen die Farben noch recht gut unterscheiden lÃ¤sst, s. AbbildungÂ 5.37\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\") +\n  scale_fill_okabeito()\n\n\n\n\n\n\nAbbildungÂ 5.37: Die Farbskala von Okabe und Ito: Geeignet bei Farbseh-SchwÃ¤chen und fÃ¼r Schwarz-WeiÃŸ-Druck. AuÃŸerdem nett anzuschauen.\n\n\n\n\n\n5.9.4 Literaturhinweise\nSowohl ggpubr als auch DataExplorer (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2009). Eine neue, gute EinfÃ¼hrung in Datenvisualisierung findet sich bei Wilke (2019). Beide BÃ¼cher sind kostenfrei online lesbar.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise-1",
    "href": "040-verbildlichen.html#literaturhinweise-1",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.11 Literaturhinweise",
    "text": "5.11 Literaturhinweise\nWilke (2019) gibt einen hervorragenden Ãœberblick Ã¼ber praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In Ã¤hnlicher Richtung geht Fisher & Meyer (2018). Hier ist eine Liste von BÃ¼chern zum Thema; dort kÃ¶nnen Sie bei Interesse tiefer suchen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literatur",
    "href": "040-verbildlichen.html#literatur",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.12 Literatur",
    "text": "5.12 Literatur\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155â€“159.\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight (First edition). Oâ€™Reilly.\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206â€“213. https://doi.org/10.1117/12.765420\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nScherer, C., Radchuk, V., Staubach, C., MÃ¼ller, S., Blaum, N., Thulke, H., & Kramerâ€Schadt, S. (2019). Seasonal Host Lifeâ€history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812â€“1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152â€“2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2009). Ggplot2: Elegant Graphics for Data Analysis. Springer. https://doi.org/10.1007/978-0-387-98141-3\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures (First edition). Oâ€™Reilly Media. https://clauswilke.com/dataviz/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5â†©ï¸\nWeitere Nomenklaturen sind mÃ¶glich, aber wir halten hier die Sache einfach.â†©ï¸\nsynonym: SÃ¤ulendiagrammâ†©ï¸\nNatÃ¼rlich mÃ¼ssen Sie das Paket einmalig installiert haben, bevor Sie es starten kÃ¶nnen.â†©ï¸\nZur Erinnerung: %&gt;% nennt man die â€œPfeife und lÃ¤sst sich alsâ€und dannâ€ Ã¼bersetzen, vgl. Kapitel 4.4.â†©ï¸\nbei konstanter Balkenbreiteâ†©ï¸\nMit Dichte ist die Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.â†©ï¸\nGrob gesagt: mariokart %&gt;% plot_density().â†©ï¸\nvgl. Kapitel 6.5â†©ï¸\nvgl. Kapitel 7.4.â†©ï¸\nsynonym: Regressionsgeradeâ†©ï¸\nAber Freunde lassen Freunde keine Tortendiagramme verwenden.â†©ï¸\nÃœbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen.â†©ï¸\nâ€œsubstanziellerâ€, â€œbedeutsamerâ€, â€œrelevanterâ€ oder â€œ(inhaltlich) signifikanterâ€â†©ï¸\nOb der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack Ã¼berlassen.â†©ï¸\nVielleicht so, dass in jeder Gruppe gleich viele Wert sind?â†©ï¸\nWeitere Hinweise finden sich auf der Hilfeseite der Funktionâ†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#lernsteuerung",
    "href": "050-zusammenfassen.html#lernsteuerung",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Standort im Lernpfad\nAbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n6.1.2 Lernziele\n\nSie kÃ¶nnen gÃ¤ngige Arten von LagemaÃŸe definieren.\nSie kÃ¶nnen erlÃ¤utern, inwiefern man ein LagemaÃŸ als ein Modell hernehmen kann.\nSie kÃ¶nnen LagemaÃŸe mit R berechnen.\n\n6.1.3 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n6.1.4 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer klassische Mittelwert (arithmetisches Mittel) ist ein prototypisches Beispiel fÃ¼r ein Modell in der Statistik.\n\nÃœbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hÃ¶ren, dass der â€œtypische deutsche Mannâ€ 1,80m groÃŸ ist (Roser et al., 2013)?1\n\nDie HÃ¤lfte der MÃ¤nner ist grÃ¶ÃŸer als 1,80m, die andere HÃ¤lfte kleiner.\nDas arithmetische Mittel der MÃ¤nner betrÃ¤gt 1,80m.\nDie meisten MÃ¤nner sind 1,80m groÃŸ.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 6.2 Laut dieser Quelle betrÃ¤gt der Wert der mittleren GrÃ¶ÃŸe deutscher Frauen etwa 1,66m, also 14â€‰cm weniger als bei MÃ¤nnern. \\(\\square\\)\n\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiÃŸ nicht \\(\\square\\)\n\n\n\n\nAuf dieser Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So kÃ¶nnte man z.B. sagen, â€œmehr als 5â€‰cm sind vielâ€. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\)) betrÃ¤gt: 2. \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Zu easy!\n\n\nğŸ‘¨â€ğŸ« Schon gut! Chill mal. Wird gleich interessanter.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig. ğŸ˜„\n\nEtwas abstrakter kann man BeispielÂ 6.1 in folgendem Schaubild darstellen, s. GleichungÂ 6.1.\n\\[\n\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} = 3 \\cdot \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}\n\\tag{6.1}\\]\nDer Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) fÃ¼r die â€œtypische Noteâ€ im Statistikkurs, s. GleichungÂ 6.2.\n\\[\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} \\qquad \\leftrightarrow  \\qquad \\underbrace{\\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}}_{\\text{\"typischer Vertreter\"}} \\tag{6.2}\\]\n\n\n\n\n\n\nWichtig\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er eine Datenreihe zu einen â€œtypischen Vertreterâ€ zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller MerkmalstrÃ¤ger in gleichem MaÃŸe einflieÃŸen. Er gibt uns eine (mÃ¶gliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen.\n\n\nEine nÃ¼tzliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. AbbildungÂ 6.1.\n\n\n\n\n\nAbbildungÂ 6.1: Mittelwert als ausbalancierte Wippe mit Mittelwert 3\n\n\n\nQuelle: Von Maphry - Eigenes Werk, CC BY-SA 4.0\n\nIn â€œMathe-Sprechâ€ bezeichnet man den Mittelwert hÃ¤ufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. GleichungÂ 6.3.\n\\[\\bar {x} =\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.3}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert von \\(X\\), prÃ¤ziser: das arithmetische Mittel, ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n. \\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. AbbildungÂ 6.2 sehen wir die Noten von (dieses Mal) vier Studentis. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert. Bezeichnen wir die Abweichung - auch als â€œFehlerâ€, â€œRestâ€ oder â€œResiduumâ€ bezeichnet - der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, â€œFehler) und die \\(i\\)-te Note mit \\(x_i\\), so kÃ¶nnen wir festhalten:\n\\[\\color{ycol}{\\text{y}_i} = \\color{modelcol}{\\bar{x}} + \\color{errorcol}{\\text{e}_i}\\]\nAnders ausgedrÃ¼ckt:\n\\[\\color{ycol}{\\text{Daten}} =     \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe.\nUm Modelle darzustellen, wird in der Datenanalyse hÃ¤ufig folgende Art von Modellgleichung verwendet, s. GleichungÂ 6.4.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{6.4}\\]\nLies: â€œDer Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)â€. Der Kringel â€œ~â€2 soll also hier heiÃŸen â€œâ€¦ ist eine Funktion von â€¦â€.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklÃ¤rende Variable3 gemeint. Das â€œDachâ€ Ã¼ber dem \\(\\color{ycol}{\\text{y}}\\) bedeutet â€œvorhergesagter Y-Wertâ€ oder â€œY-Wert laut dem Modellâ€. Der tatsÃ¤chliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\).\n\\[\\color{ycol}{\\text{y}}  = \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (â€œy-Dachâ€). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir schreiben kÃ¶nnen:\n\\[\\color{ycol}{y}  = \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklÃ¤rt, auÃŸer gehen wir von einem Fehler \\(e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In spÃ¤teren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklÃ¤ren. WÃ¼rden wir z.B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklÃ¤ren, so wÃ¼rden wir schreiben:\n\\[\\color{modelcol}{\\bar{y}} \\sim \\color{xcol}{\\text{x}} \\] Da wir im Moment aber keine andere Variablen bemÃ¼hen, um \\(\\color{ycol}{\\text{y}}\\) zu erklÃ¤ren, schreibt man auch:\n\\[\\color{modelcol}{\\bar{y}} \\sim 1\\]\nDiese Schreibweise sieht verwirrend aus. Die \\(1\\) soll aber einfach zeigen, dass wir keine andere Variable zur ErklÃ¤rung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\).\n\nBeispiel 6.2 (Noten, Mittelwert und Abweichung) Vier Studentis â€“ Anna, Berta, Carl, Dani â€“ haben ihre Statistik-Klausur zurÃ¼ckbekommen (Schluck). Die Noten sehen Sie in AbbildungÂ 6.2, gar nicht so schlecht ausgefallen. AuÃŸerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen der einzelnen Noten vom Mittelwert eingezeichnet.\\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken4 in AbbildungÂ 6.2 einmal genauer an.\n\n\n\n\n\n\n\nAbbildungÂ 6.2: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\nJetzt stellen Sie sich vor, Sie wÃ¼rden die vom Mittelwert nach oben ragenden BalkenlÃ¤ngen aneinanderlegen (das sind die gestrichelten. Sehen Sie das vor Ihrem geistigen Auge? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht) jetzt, dass die GesamtlÃ¤nge der â€œBalken nach obenâ€ identisch ist zur GesamtlÃ¤nge der nach â€œunten ragenden Balkenâ€, vgl. AbbildungÂ 6.1.\nPrÃ¤ziser ausgedrÃ¼ckt und ohne Ihre Phantasie zu strapazieren (GleichungÂ 6.5):\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.5}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDie Summe der Abweichungen vom Mittelwert ist Null.\n\n\n\nÃœbungsaufgabe 6.3 Was schÃ¤tzen Sie, wie hoch das â€œmittlereâ€ VermÃ¶gen des Haushalte in Deutschland in etwa ist?5)\n\n\n\nAuswahl\nAntwort\n\n\n\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\n\n\n\n\n\n50.000 Euro, ca. 60.000 Euro (laut der o.g. Quelle)\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\n\n\n\n\n\nBeispiel 6.3 (Der reichste Mensch der Welt in Ihrem HÃ¶rsaal) Kommt der wertvollste FuÃŸballspieler der Welt in Ihren HÃ¶rsaal, sagen wir, es ist Kylian MbappÃ©6. Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro7.\n\nğŸ¦¹â€â™‚ï¸ Hey Leute, wie gehtâ€™s denn so! Wie viel Kohle verdient ihr eigentlich so?\n\n\nğŸ§‘â€ğŸ“ Ã„h, wir studieren und verdienen fast nix!\n\nDie 100 Studis im HÃ¶rsaal schauen verdattert aus der WÃ¤sche: Was ist das fÃ¼r eine komische Frage!? Aber zumindest verteilt der FuÃŸballspieler Autogramme.\n\n\nÃœbungsaufgabe 6.4 (Mittleres Einkommen im HÃ¶rsaal, mit Kylian MbappÃ©) SchÃ¤tzen Sie â€“ im Kopf â€“ das mittlere VermÃ¶gen im HÃ¶rsaal, gehen Sie davon aus, dass alle der 100 Studentis jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (prÃ¤ziser: das arithmetische Mittel des Einkommens) wie folgt berechnen.8\n\n\nListingÂ 6.1: Wir simulieren Einkommen von 100 Studis plus MbappÃ©.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100 Mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 MbappÃ© mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nuller hinter der fÃ¼hrenden Eins. 1 Million ist 1000 mal 1000. Anders gesagt: 1 Million = \\(10^6 = 10^3 * 10^3\\). In Taschenrechner oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als â€œ1 Mal 10 hoch 6, also mit 6 im Exponentenâ€.\n\n\nDer Mittelwert im HÃ¶rsaal betrÃ¤gt also 1,189,109 Euro. Ist das ein gutes Modell fÃ¼r das â€œtypischeâ€ VermÃ¶gen im HÃ¶rsaal?\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. AbbildungÂ 6.3, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell verwendet eine Gerade als Modell der Daten. Es erklÃ¤rt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildungÂ 6.3: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\nAbbildungÂ 6.3 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit Extremwerte (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (engl. outlier) ist eine Beobachtung, dessen Wert deutlich vom GroÃŸteil der anderen Beobachtungen im Datensatz abweicht, z.B. viel grÃ¶ÃŸer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R (vgl. ListingÂ 6.1):\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear modell\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl gibt als Koeffizient einen Wert zurÃ¼ck und zwar den Mittelwert von einkommen, ListingÂ 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet, das wird verstÃ¤ndlich, wenn man z.B. in AbbildungÂ 6.3 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet.\nDie Syntax des Befehls lm() sieht etwas merkwÃ¼rdig aus. Ignorieren Sie das fÃ¼rs Erste, wir besprechen das spÃ¤ter (Kapitel 9) ausfÃ¼hrlich. lm steht Ã¼brigens fÃ¼r â€œlineares Modellâ€.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.3 Median als Modell",
    "text": "6.3 Median als Modell\n\nğŸ§‘â€ğŸ“ Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert fÃ¼r die Menschen im HÃ¶rsaal. Weder fÃ¼r den MbappÃ©, noch fÃ¼r uns Studis!\n\n\nğŸ‘¨â€ğŸ« Ja, da habt ihr Recht.\n\n\nâš½ Die Welt ist schon ungerecht!\n\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. AbbildungÂ 6.4) ist der Mittelwert (sehr) wenig aussagekrÃ¤ftig, da er nicht mehr â€œtypischeâ€ Werte fÃ¼r die MerkmalstrÃ¤ger beschreibt.\n\n\nAbbildungÂ 6.4 stellt die Verteilung einer mit normal skalierter Achse und einmal mit logarithmischer X-Achse. Die logarithmische X-Achse stellt den Unterschied von Mittelwert (MW) und Median deutlicher heraus als die â€œnormaleâ€ (additive) Achse.\n\n\n\n\n\n\n\n\n\n(a) X-Achse in additiver Form\n\n\n\n\n\n\n\n\n\n\n\n(b) X-Achse in multiplikativer Form (logarithmische Darstellung)\n\n\n\n\n\n\nAbbildungÂ 6.4: Die Einkommensverteilung im HÃ¶rsaal\n\n\nDer Mittelwert ist HÃ¶rsaal ist nicht typisch fÃ¼r die Menschen im HÃ¶rsaal: Weder fÃ¼r MbappÃ©, noch fÃ¼r die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Mittelwert ist empfÃ¤nglich fÃ¼r Extremwerte: Gibt es einen extremen Wert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wieder und weniger die Mehrheit der gemÃ¤ÃŸigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenÃ¼ber Extremwerten).\n\n\n\nBeispiel 6.4 (Das Median-Einkommen einiger Studentinnen) FÃ¼nf Studentinnen tauschen sich Ã¼ber ihr Einkommen aus, s. AbbildungÂ 6.5, links. Es handelt sich um eine schiefe Verteilung.\n\n\n\n\n\n\n\n\n\n(a) ID auf der X-Achse, Einkommen auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n\n(b) Einkommen auf der X-Achse, HÃ¤ufigkeit auf der Y-Achse\n\n\n\n\n\n\nAbbildungÂ 6.5: Das Median-Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\nWir kÃ¶nnten jetzt behaupten, dass Carla das typische Einkommen (fÃ¼r diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\nDefinition 6.4 (Median) MerkmalsausprÃ¤gung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt. \\(\\square\\)\n\nDer Median ist robust (gegenÃ¼ber) Extremwerten: FÃ¼gt man Extremwerte zu einer Verteilung hinzu, Ã¤ndert sich der Median zumeist (deutlich) weniger als der Mittelwert.\nAbbildungÂ 6.6 stellt den Median schematisch dar.\n\n\n\n\n\n\n1,60m\n\n\n\n\n\n1,72m\n\n\n\n\n\n1,79m: Median!\n\n\n\n\n\n1,94\n\n\n\n\n\n2,12m\n\n\n\n\n\nAbbildungÂ 6.6: Der Median als der Wert des â€œmittlerenâ€ Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert als der Median wie Objekte mit grÃ¶ÃŸerem Wert als der Median.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.5 Bei der Messreihe 1, 2, 3, 4, 5, 6, 8, 9 betrÃ¤gt der Median 4.5.\\(\\square\\)\n\n\nÃœbungsaufgabe 6.5 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhÃ¶ht sich um das Hundertfache. Wie verÃ¤ndert sich der Median?9 \\(\\square\\)\n\n\nÃœbungsaufgabe 6.6 (Wer ist mehr â€œmittelâ€? Median oder Mittelwert?) Â \n\nğŸ§‘â€ğŸ“ Das arithmetische Mittel sollte Mittelwert heiÃŸen, weil es die Mitte von zwei Messwerten widerspiegelt, also z.B. von 1 und 10 ist die Mitte 5,5 - also genau beim Mittelwert!\n\n\nğŸ‘©â€ğŸ“ Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der GrÃ¶ÃŸe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion!\\(\\square\\)\n\n\nBeispiel 6.6 (Ein â€œmittlererâ€ Preis fÃ¼r Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median fÃ¼r das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist hÃ¶her als der Median.\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n  \n\n\n\nWie man sieht, ist der Mittelwert grÃ¶ÃŸer als der Median, s. AbbildungÂ 6.7\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Das Start-Gebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert grÃ¶ÃŸer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell fÃ¼r den â€œtypischen Wertâ€ vorzuziehen.\n\n\n\nÃœbungsaufgabe 6.7 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die fÃ¼r einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis mÃ¶glicherweise Ã¼ber die GebÃ¼hr. \\(\\square\\)\n\n\n\nAufgabe\nLÃ¶sung\n\n\n\nEntfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\n\n\n\nmariokart2 &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# ohne Extremwerte:\nmariokart2 |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n\n\n\n\nÃœbungsaufgabe 6.8 Was schÃ¤tzen Sie, wie hoch das mediane VermÃ¶gen des Haushalte in Deutschland in etwa ist (Stand 2016)?10)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 6.9 Was schÃ¤tzen Sie, wie groÃŸ der Unterschied zwischen medianem und mittlerem (arithm. Mittel) des Jahreseinkommen deutscher Haushalte ungefÃ¤hr ist?11)\n\n1.000 Euro\n2.000 Euro\n3.000 Euro\n4.000 Euro\n5.000 Euro\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere HÃ¤lfte. Er markiert sozusagen eine â€œ50-Prozent-Markeâ€ (der aufsteigend sortierten Beobachtungen). Betrachten wir einmal nur alle Spiele, die fÃ¼r weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. AbbildungÂ 6.8 (a). 50% aller Spiele wurden fÃ¼r weniger als ca. 46 Euro verkauft; 50% aller Spiele fÃ¼r mehr als 46 Euro. Der Median betrÃ¤gt als 46 Euro.\nJetzt kÃ¶nnten wir nur die gÃ¼nstigere HÃ¤lfte betrachten und wieder nach dem Median fragen (d.h. total_pr &lt; 46). Dieser â€œMedian der gÃ¼nstigeren HÃ¤lfteâ€ grenzt damit das insgesamt gÃ¼nstigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25%). Den Median nennt man das zweite Quartil (Q2, 50%). Entsprechend heiÃŸt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75%).\\(\\square\\)\n\n\nBeispiel 6.7 (Quartile des Verkaufsgebot) AbbildungÂ 6.8 (a) zeigt die Quartile fÃ¼r das Verkaufsgebot.\\(\\square\\)\n\nJetzt kÃ¶nnte man sagen, hey, warum nur in 25%-StÃ¼cke die Verteilung aufteilen? Warum nicht in 10%-Schritten?\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleiche Teile unterteilen, nennt man Dezile. \\(\\square\\)\n\nOder vielleicht in 1%-Schritten oder in sonstigen Schnitten? Wo die Quartile in 25%-Schritten aufteilen, teilt in Quantil in \\(p\\)-Prozent-Schritten auf, s. fig-quantile-anim.\n\nDefinition 6.7 (Quantile) Ein p-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht Ã¼berschritten wird.\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Quantil ist ein Oberbegriff fÃ¼r Quartile, Dezile, etc. \\(\\square\\)\n\n\nAbbildungÂ 6.8 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil fÃ¼r den Datensatz mariokart2.\n\n\n\n\n\n\n\n\n\n(a) Q1, Q2 und Q3 fÃ¼r das Schlussgebot (nur Spiele fÃ¼r weniger als 100 Euro)\n\n\n\n\n\n\nAbbildungÂ 6.8: Verschiedene Arten von Quantilen.\n\n\nQuantile kann man in R mit dem Befehl quantile() berechnen:\n\nmario_quantile &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(q25 = quantile(total_pr, .25),\n            q50 = quantile(total_pr, .50),\n            q75 = quantile(total_pr, .75))\n\nAbbildungÂ 6.9 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildungÂ 6.9: Verschiedenen Quantile animiert\n\n\nAbbildungÂ 6.10 visualisiert ebenfalls verschiedene Quantile. Man beachte, dass alle Regionen gleiche FlÃ¤chen (d.h. Wahrscheinlichkeitsmassen) aufweisen.\n\n\n\n\nQuartile\nDezile\nPerzentile\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.10: Verschiedene Quantile visualisiert. In jedem Diagramm sind die Regionen gleich groÃŸ, beinhalten also (ungefÃ¤hr) die gleiche Anzahl von Beobachtungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.5 LagemaÃŸe",
    "text": "6.5 LagemaÃŸe\n\nğŸ§‘â€ğŸ“ Was ist der Oberbegriff fÃ¼r Median, Mittelwert und so weiter?\n\n\nğŸ‘©â€ğŸ« Gute Frage! Wie wÃ¼rden Sie ihn nennen?\n\n\nDefinition 6.8 (LagemaÃŸ) Ein LagemaÃŸ (synonym: MaÃŸ der zentralen Tendenz) fÃ¼r eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, zu erwarten, reprÃ¤sentativ oder â€œmittelâ€ ansehen sollten.\\(\\square\\)\n\n\nBeispiel 6.8 Typische LagemaÃŸe sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuartile\nQuantile\nMinimum (kleinster Wert)\nMaximum (grÃ¶ÃŸter Wert)\nModus (hÃ¤ufigster Wert) \\(\\square\\)\n\n\n\nBerechnen wir LagemaÃŸe fÃ¼r den Mariokart-Datensatz, s. ListingÂ 6.2.12\n\n\nListingÂ 6.2: Syntax zur Berechnung von LagemaÃŸen\n\n\nmariokart_lagemaÃŸe_total_pr &lt;-\n  mariokart %&gt;% \n  summarise(mw = mean(total_pr),\n            md = median(total_pr),\n            q1 = quantile(total_pr, .25),\n            q2 = quantile(total_pr, .5),\n            q3 = quantile(total_pr, .75),\n            min = min(total_pr),\n            max = max(total_pr))\nmariokart_lagemaÃŸe_total_pr\n\n\n  \n\n\n\n\n\n\n\n6.5.1 Gruppierte LagemaÃŸe\nHÃ¤ufig mÃ¶chte man Statistiken wie LagemaÃŸe fÃ¼r mehrere Teilgruppen â€“ z.B. Mittlere KÃ¶rpergrÃ¶ÃŸe von Frauen vs.Â Mittlere KÃ¶rpergrÃ¶ÃŸe von MÃ¤nner â€“ berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage kÃ¶nnte lauten:\n\nUnterscheidet sich die mittlere KÃ¶rpergrÃ¶ÃŸe von Frauen und MÃ¤nnern?\n\nOder vielleicht:\n\nHat das Geschlecht einen Einfluss auf die KÃ¶rpergrÃ¶ÃŸe?\n\nAnders ausgedrÃ¼ckt:\n\nKÃ¶rpergrÃ¶ÃŸe \\(\\color{ycol}{\\text{y}}\\) ist eine Funktion des Geschlechts \\(\\color{xcol}{G}\\).\n\nDie Modellformel kÃ¶nnte also lauten:\n\\[\\color{ycol}{y} \\sim \\color{xcol}{G}\\]\nGruppierte LagemaÃŸe lassen sich in R z.B. so berechnen, s. ListingÂ 6.3, also Ã¤hnlich wie in @#lst-mario-lage.\n\n\nListingÂ 6.3: Gruppierte LagemaÃŸe\n\n\nmariokart_lagemaÃŸe_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\nmariokart_lagemaÃŸe_gruppiert\n\n\n  \n\n\n\n\n\n\nAbbildungÂ 6.11 zeigt ein Beispiel fÃ¼r ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. AbbildungÂ 6.3. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, â€œglobalenâ€ Mittelwert): Innerhalb der Gruppe ohne LenkrÃ¤der und innerhalb der Gruppe mit 2 LenkrÃ¤dern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering â€“ im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\n\n\n\n\n\n\n\n\n(a) Mittelwert fÃ¼r Verkaufspreis (ungruppiert)\n\n\n\n\n\n\n\n\n\n(b) Mittelwert fÃ¼r Verkaufspreis gruppiert nach Anzahl der LenkrÃ¤der\n\n\n\n\n\n\nAbbildungÂ 6.11: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches fÃ¼r alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heiÃŸt ein Punktmodell. Anders gesagt fasst ein Punktmodell eine Wertereihe (hÃ¤ufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem â€œPunktâ€ in diesem Sinne, s. GleichungÂ 6.6.\\(\\square\\)\n\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{6.6}\\]\nMittelwert, Median und Quartile sind Beispiele fÃ¼r Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein â€œBildâ€ der Daten, machen Sie uns verstÃ¤ndlich - sie sind uns ein Modell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lÃ¼gt",
    "text": "6.6 Wie man mit Statistik lÃ¼gt\nMit Statistik kann man vortrefflich lÃ¼gen, heiÃŸt es. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lÃ¤sst: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzufÃ¼hren. Viele Wege fÃ¼hren nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und UnschÃ¤rfen ohne bÃ¶se Abwehr aufzudecken, gibt es ein probates Gegenmittel: Transparenz.\n\nStellen Sie hohe Anforderung an die Transparenz einer statistischen Analyse. Nur durch NachprÃ¼fbarkeit kÃ¶nnen Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation Ã¼berzeugen.\n\nHier ist eine (nicht abschlieÃŸende!) Checkliste, was Sie nachprÃ¼fen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\n\n\n\n\n\nNr\nCheck\n\n\n\n1\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\n\n\n2\nWurden ausreichend Daten gesammelt (z.B. mind. 20 Beobachtungen pro Gruppe)?\n\n\n3\nWurden alle untersuchten Variablen berichtet?\n\n\n4\nWurden alle durchgefÃ¼hrten Interventionen berichtet?\n\n\n5\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) BegrÃ¼ndung?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.9 (Survival-Tipp) Eine Studentin aus dem dem Bachelorstudiengang â€œAngewandte Medien- und Wirtschaftspsychologieâ€ mit Schwerpunkt Data Science berichtet ihre â€œSurvival-Tippsâ€ fÃ¼r Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich wÃ¤hrend des Semesters neue Begriffe und ihre ErklÃ¤rung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in hÃ¶heren Semestern nach Tipps fragen.\\(\\square\\)\n\n\n\n\nğŸ‘©â€ğŸ“ Irgendwie kann ich mir R-Code so schlecht merken.\n\n\nğŸ‘©â€ğŸ« Frag doch mal ChatGPT, oder einen anderen Chatbot, da bekommt man auch R-Code ausgegegeben.\n\n\nÃœbungsaufgabe 6.10 (Ãœbungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Ãœbungsaufgaben.\nSie kÃ¶nnen sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\nğŸ§‘â€ğŸ“ Ich bin ein Student in einem Bachelor-Studiengang fÃ¼r Psychologie. Gerade bereite ich mich auf die Klausur im Fach â€œGrundlagen der Statistikâ€ vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die PrÃ¼fung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: MaÃŸe der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.B. Nominalskala vs.Â Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben.\n\n\\(\\square\\)\n\n\n6.7.1 DatensÃ¤tze zum Ãœben\nMittlerweile verfÃ¼gen Sie die wesentlichen Werkzeuge des Datenjudo. Hier finden Sie einen Ãœberblick an DatensÃ¤tze, die Sie nach Herzenslust analysieren kÃ¶nnen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber spÃ¤ter kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekannte Stoff.\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nnasa02\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu z.B. dem Tag EDA an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele LehrbÃ¼cher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehÃ¶ren zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel fÃ¼r LehrbÃ¼cher sind Mittag & SchÃ¼ller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Ein Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurÃ¼ckschreckt, ist mit Cetinkaya-Rundel & Hardin (2021) oder Poldrack (2022) gut beraten. Beide BÃ¼cher sind online verfÃ¼gbar. Tipp: Mit dem Browser einfach auf Deutsch Ã¼bersetzen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literatur",
    "href": "050-zusammenfassen.html#literatur",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.10 Literatur",
    "text": "6.10 Literatur\n\n\n\n\nBortz, J., & Schuster, C. (2010). Statistik FÃ¼r Human- Und Sozialwissenschaftler. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und SpaÃŸ im Horrorfach nichttechnischer StudiengÃ¤nge. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height. Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359â€“1366. https://doi.org/10.1177/0956797611417632\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., van Aert, R. C. M., & van Assen, M. A. L. M. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7, 1832. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "Ihr Vorstellung updatet sich in in DefinitionÂ 6.1.â†©ï¸\nDas â€œKringelâ€ oder die â€œWelleâ€ â€œ~â€ nennt man auch â€œTildeâ€â†©ï¸\nAV, Output-Variable, Zielvariableâ†©ï¸\nResiduen, Fehler; hÃ¤ufig mit \\(e\\) wie error bezeichnetâ†©ï¸\nQuelle: WSI \\(\\square\\), Abruf 2023-04-19â†©ï¸\nQuelle: https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop, 2023-03-19â†©ï¸\nQuelle: https://www.einkommenmagazin.de/kylian-mbappe-einkommen/, 2023-03-19â†©ï¸\nDie Details der Syntax, z.B. der Befehl rep(), sind von geringer Bedeutung.â†©ï¸\nEr bleibt gleich, verÃ¤ndert sich also nicht: Der Median ist robust, er verÃ¤ndert sich nicht oder kaum, wenn Extremwerte vorliegen.â†©ï¸\nQuelle: WSI, https://www.wsi.de/en/how-is-wealth-distributed-in-germany-14401.htm, Abruf 2023-04-19. Die Antwort lautet: ca. 60 Tsd Euro laut der angegebenen Quelleâ†©ï¸\nQuelle: Wikipedia, Abruf 2023-04-19, der Unterschied betrÃ¤gt knapp 3000 Euro laut der Quelleâ†©ï¸\nEs ist Ã¼brigens egal, wie sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname â€“ alles okay!â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#lernsteuerung",
    "href": "060-modellguete.html#lernsteuerung",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1.1 Standort im Lernpfad\nAbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n7.1.2 Lernziele\n\nSie kennen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe und kÃ¶nnen diese definieren und mit Beispielen erlÃ¤utern.\nSie kÃ¶nnen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe mit R berechnen.\nSie kÃ¶nnen die Bedeutung von Streuung fÃ¼r die GÃ¼te eines Modells erlÃ¤utern.\n\n7.1.3 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)\n\n\n7.1.4 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "href": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.2 Warum Sie die Streuung Ihrer Daten kennen sollten",
    "text": "7.2 Warum Sie die Streuung Ihrer Daten kennen sollten\n\n7.2.1 Prof.Â Weiss-Ois hat eine Idee\n\n\n\n7.2.1.1 Was er sagt\n\n\nâ€œIch habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!â€\n\n\n\n\n\n\n7.2.1.2 Was er NICHT sagt\n\n\nâ€œAllerdings streuten die Werte der GewichtsverÃ¤nderung um 10kg um den Mittelwert herum.â€\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\n\nWÃ¼rden Sie die Pille von Prof.Â I. Ch. Weiss-Ois nehmen?1\n\nja\nnein\nNur wenn ich 100 Euro bekomme\nOkay, fÃ¼r 1000 Euro\\(\\square\\)\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information.\\(\\square\\)\n\n\n\n7.2.2 Wie man seine Kuh Ã¼ber den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss Ã¼berqueren, nur kann die Kuh nicht schwimmen2.\n\nğŸ§‘â€ğŸŒ¾ (Fritz): Sag mal, Karl, ist der Fluss tief?\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): NÃ¶, im Schnitt nur einen Meter.\n\nAlso fÃ¼hrt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, s. AbbildungÂ 7.1.\n\n\n\n\n\nAbbildungÂ 7.1: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): Ãœbrigens, LagemaÃŸe sagen nicht alles, Fritz.\n\n\nğŸ§‘â€ğŸŒ¾ (Fritz): LÃ¤uft die Kuh durch den Fluss, kann sie schwimmen oder â€™s ist Schluss.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.3 Woran erkennt man ein gutes Modell?",
    "text": "7.3 Woran erkennt man ein gutes Modell?\nAbbildungÂ 7.2 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs.Â ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen.\n\n\n\n\n\n\n\nAbbildungÂ 7.2: Ein Modell mit wenig Streuung vs.Â ein Modell mit viel Streuung\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsÃ¤chlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groÃŸ.\n\n\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof.Â Weiss-Ois) In AbbildungÂ 7.2 sind die Daten zu der GewichtsverÃ¤nderung nach Einnahme von â€œSchlankheitspillenâ€ zweier verschiedener PrÃ¤parate. Wie man sieht unterscheidet sich die typische (vorhergesagte) GewichtsverÃ¤nderung zwischen den beiden PrÃ¤paraten kaum. Die Streuung allerdings schon. Links sieht man die GewichtsverÃ¤nderungen nach Einnahme des PrÃ¤parats â€œDickableibtin extra mildâ€ (c) und rechts das PrÃ¤parat von Prof.Â Weiss-Ois â€œPfundafliptan Forteâ€. Welches PrÃ¤parat wÃ¼rden Sie lieber einnehmen?\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nWir wollen ein prÃ¤zises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklÃ¤ren, also wenig vom tatsÃ¤chlichen Wert abweichen. Jedes Modell sollte Informationen Ã¼ber die PrÃ¤zision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der ModellgÃ¼te, d.h. der PrÃ¤zision der SchÃ¤tzung des Modellwerts, ist wenig nÃ¼tze.\\(\\square\\)\n\n\n\nğŸ‘©â€ğŸ“ Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\nğŸ‘©â€ğŸ« Die Frage ist, was wir mit â€œverbessernâ€ meinen?\n\n\nğŸ‘©â€ğŸ“ Naja, kÃ¼rzere Fehlerbalken, ist doch klar!\n\nDa die Anzahl der LenkrÃ¤der mit dem Verkaufsgebot zusammenhÃ¤ngt, kÃ¶nnte es vielleicht sein, dass wir die LenkrÃ¤der-Anzahl da irgendwie nutzen kÃ¶nnten. Das sollten wir ausprobieren.\nAbbildungÂ 7.3 zeigt, dass die Fehlerbalken kÃ¼rzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 LenkrÃ¤dern vs.Â mit 0 LenkrÃ¤dern) sind die Fehlerbalken jeweils im Durchschnitt kÃ¼rzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm).3\n\n\n\n\n\n\n\n\n\n(a) Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt\n\n\n\n\n\n\n\n\n\n(b) Fehlerbalken im komplexen Modell: Zwei Mittelwerte; wenig Streuung in jeder Gruppe\n\n\n\n\n\n\nAbbildungÂ 7.3: Fehlerbalken in einem einfachen und komplexeren Modell\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.4 StreuungsmaÃŸe",
    "text": "7.4 StreuungsmaÃŸe\n\nDefinition 7.1 (StreuungsmaÃŸe) Ein StreuungsmaÃŸ quantifiziert die VariabilitÃ¤t eines Merkmals. \\(\\square\\)\n\nEin einfaches StreuungsmaÃŸ ist der Range, definiert als Abstand von grÃ¶ÃŸtem und kleinsten Wert eines Merkmals. Dieses Mermals ist aber nicht robust (gegenÃ¼ber Extremwerten) und sollte daher nur mit EinschrÃ¤nkung verwendet werden.\n\n7.4.1 Der mittlere Abweichungsbalken\n\nğŸ§‘â€ğŸ“ Wir mÃ¼ssen jetzt mal prÃ¤ziser werden! Wie kÃ¶nnen wir die Streuung berechnen?\n\n\nğŸ‘¨â€ğŸ« Gute Frage! Am einfachsten ist es, wenn wir die mittlere LÃ¤nge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir wir den â€œmittleren Abweichungsbalkenâ€, den wir mit \\(\\varnothing e\\) bezeichnen kÃ¶nnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als Mittlere Absolutabweichung (MAA). Er ist so definiert, s. GleichungÂ 7.1.\n\\[{\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}.} \\tag{7.1}\\]\n\nDefinition 7.2 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte.4\\(\\square\\)\n\n\nBeispiel 7.2 AbbildungÂ 7.4 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE fÃ¼r das Beispiel von AbbildungÂ 7.4 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.4: Abweichungsbalken und der MAE\n\n\n\n\nNatÃ¼rlich kÃ¶nnen wir R auch die Rechenarbeit Ã¼berlassen.\n\nğŸ¤– Loving it!!\n\nSchauen Sie: Den Mittelwert (s. AbbildungÂ 7.4) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? SchlieÃŸlich erklÃ¤ren wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse ist).\nIn R gibt es einen Befehl fÃ¼r ein lineares Modell, er heiÃŸt lm.\nDie Syntax von lm() lautet:\nlm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur ErklÃ¤rung von Y. Aber verwende keine andere Variable zur ErklÃ¤rung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm1 &lt;- lm(y ~ 1, data = d)\n\nDen MAE kÃ¶nnen wir uns jetzt so ausgeben lassen:\n\nmae(lm1)\n## [1] 1.5\n\n\n7.4.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein StreuungsmaÃŸ, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.\n\nDefinition 7.3 (Interquartilsabstand) Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil.\\(\\square\\)\n\n\nBeispiel 7.3 (IQR im HÃ¶rsaal) In einem Statistikkurs betragen die Quartile der KÃ¶rpergrÃ¶ÃŸe: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR betrÃ¤gt dann: \\(IQR = Q3-Q1 = 1.75m - 1.65m = 0.10m\\), d.h. 10 cm.\\(\\square\\)\n\n\n7.4.3 StreuungsmaÃŸe fÃ¼r Normalverteilungen\nNormalverteilungen sind recht hÃ¤ufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu Ã¼berlegen, wie man diese Verteilungen gut zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett Ã¼ber ihren Mittelwert sowie ihre Standardabweichung beschreiben lÃ¤sst. AuÃŸerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), â€œverschiebt man den Bergâ€ ja nur zur Seite, ohne seine Form zu verÃ¤ndern, s. AbbildungÂ 7.9.\n\n\n\n\n\n\nHinweis\n\n\n\nHat man normalverteilte Variablen/Abweichungen/Residuen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma\\), \\(s\\)) eine komfortable MaÃŸeinheit der Streuung, denn damit lÃ¤sst sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\\(\\square\\)\n\n\n\nğŸ§‘â€ğŸ“ Aber wie berechnet man jetzt diese Standardabweichung?\n\n\nğŸ‘¨â€ğŸ« Moment, noch ein kurzer Exkurs zur Varianz â€¦\n\n\nğŸ§‘â€ğŸ“ (seufzt)\n\n\n7.4.4 Varianz\n\n7.4.4.1 Intuition\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.\\(\\square\\)\n\n\n\n\nAbbildungÂ 7.7 illustriert die Varianz:\n\nMan gehe von der HÃ¤ufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan bilde Quadrate fÃ¼r jeden Datenpunkt mit der KantenlÃ¤nge, die dem Abstand des Punktes zum Mittelwert entspricht.\nDie Quadrate quetscht man jetzt wo nÃ¶tig in rechteckige Formen (ohne dass sich die FlÃ¤che Ã¤ndern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit SeitenlÃ¤nge \\(n\\) und \\(\\sigma^2\\) anordnen.\n\n\n\n\n\n\n\nAbbildungÂ 7.5: Illustration zur Varianz als â€œmittlerer Quadratfehlerâ€\n\n\nBy Cmglee - Own work, CC BY-SA 3.0\n\n\nAbbildungÂ 7.6 visualisiert die Varianz fÃ¼r BeispielÂ 7.2.5\nLinks sind die Abweichungsquadrate dargestellt, rechts die Varianz als â€œtypisches Abweichungsquadratâ€.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz ist also ein MaÃŸ, das die typische Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als â€˜typischerâ€™ Fehlerbalken\n\n\n\n\n\n\nAbbildungÂ 7.6: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\nBildquelle: FOM-ifes\n\nBeispiel 7.4 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. NatÃ¼rlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.\nZunÃ¤chst betrachten Sie die Streuung in den Verkaufspreisen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nm &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  m %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47.43\n12.99\n7.20\n83.06\n9.11\n\n\n\n\nStatistiken sind ja schÃ¶n â€¦ aber Bilder sind auch gut, s. AbbildungÂ 7.7. \\(\\square\\)\n\nmariokart %&gt;% \n  mariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_density()\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm mit MWÂ±SD in roter Farbe\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm mit MWÂ±SD in roter Farbe\n\n\n\n\n\n\nAbbildungÂ 7.7: Die Verteilung des Verkaufspreises von Mariokart-Spielen\n\n\n\nWer sich die Berechnung von Hand fÃ¼r pr_maa sparen mÃ¶chte, kann die Funktion MeanAD aus dem Paket DescTools nutzen.\n\n7.4.4.2 Kochrezept fÃ¼r die Varianz\nUm die Standardabweichung zu berechnen, berechnet man zunÃ¤chst die Varianz, \\(s^2\\) abgekÃ¼rzt. Hier ist ein â€œKochrezeptâ€6 zur Berechnung der Varianz:\n\nFÃ¼r alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\)\n\nQuadriere diese Werte\nSummiere dann auf\nTeile durch die Anzahl \\(N\\) der Werte\n\nAls Formel ausgedrÃ¼ckt, lautet die Definition der Varianz7 einer Stichprobe wie folgt, s. GleichungÂ 7.2.\n\\[{\\displaystyle s^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}dy_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.4 (Varianz) Die Varianz (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen, \\(dy_i^2\\), (vom Mittelwert).\\(\\square\\)\n\nDie Varianz steht im engen VerhÃ¤ltnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. GleichungÂ 7.3.\n\\[{\\displaystyle MSE={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(x_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.\n\n7.4.5 Die Standardabweichung\nKennt man die Varianz, so lÃ¤sst sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.\n\nDefinition 7.5 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. GleichungÂ 7.4.\n\\[s := \\sqrt{s^2} \\tag{7.4}\\]\n\\(\\square\\)\n\nDurch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche GrÃ¶ÃŸenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groÃŸ werden kann).\nAus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(rmse := \\sqrt{mse}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.\\(\\square\\)\n\n\n\nBeispiel 7.5 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n  \n\n\n\nAh! Das war einfach. Wird auch langsam Zeit fÃ¼r Feierabend.\\(\\square\\)\n\n\nBeispiel 7.6 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. Bevor Sie nach Hause gehen, mÃ¶chten Sie noch eine Sache anschauen. In einer frÃ¼heren Analyse (s. AbbildungÂ 7.3) fanden Sie heraus, dass die Fehlerbalken kÃ¼rzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natÃ¼rlich prÃ¼fen. Sie Ã¼berlegen: â€œOkay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.â€\nDas spezifizieren Sie so:\n\nlm1 &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm1)\n## [1] 10.01811\n\nIm nÃ¤chsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufpreis eine Funktion der Anzahl der LenkrÃ¤der ist (Ã¤hnlich wie in AbbildungÂ 7.3):\n\nlm2 &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm2)\n## [1] 7.375873\n\nAh! Sehr schÃ¶n, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach hause!\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.5 Streuung als Modellfehler",
    "text": "7.5 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der ModellgÃ¼te auffassen.\nDefinieren wir zunÃ¤chst als Punktmodell auf Errisch:\n\nlm_mario1 &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne PrÃ¤diktoren, sondern als Punktmodell, und zwar schÃ¤tzen wir den Mittelwert mit den Daten mariokoart.\nDas (Meta-)Paket easystats bietet komfortable Befehle, um die ModellgÃ¼te zu berechnen:\n\nmae(lm_mario1)  # Mean absolute error\n## [1] 10.01811\nmse(lm_mario1)  # Mean squared error\n## [1] 655.2874\nrmse(lm_mario1)  # Root mean squared error\n## [1] 25.59858",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#z-transformation",
    "href": "060-modellguete.html#z-transformation",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.6 z-Transformation",
    "text": "7.6 z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzeigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. mariokart2.\n\nmariokart2 &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nMit dem R-Paket ggpubr (Funktion gghistogram) lÃ¤sst sich die Verteilung leicht visualisieren, s. AbbildungÂ 7.8, links.\n\n\n\n\n\n\n\n\n\n(a) Wie nah drÃ¤ngen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert\n\n\n\n\n\n\nAbbildungÂ 7.8: Verteilung von mariokart2\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell fÃ¼r die Daten, bzw. desto hÃ¶her die ModellgÃ¼te.\\(\\square\\)\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie Ã¼berlegen â€¦ und Ã¼berlegen. Da! Eine Idee!\nMan kÃ¶nnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je grÃ¶ÃŸer diese Abweichung, desto schlechter die ModellgÃ¼te! Also rechnen Sie diese Abweichung aus.\n\nmariokart2 &lt;-\n  mariokart2 %&gt;% \n  mutate(abw = 47.4 - total_pr)\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.6 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert abzuziehen. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.9: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt\n\n\n\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Ãœberlegungen: Woher weiÃŸ man, ob 10 Euro oder 20 Euro â€œvielâ€ Abweichung vom Verkaufspreis ist? Man mÃ¼sste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man kÃ¶nnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, Ã¤hnlicher Kennwert zur mittlerer absolute Abweichung ist die SD. Sie haben gehÃ¶rt, dass die SD gebrÃ¤uchlicher ist als die MAA. Um sich als Checker zu prÃ¤sentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja Ã¤hnlich.\nAlso: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte, dann hÃ¤tten wir eine â€œstandardisierteâ€8 Abweichung von 1, weil 10/10=1.\nBegeistert Ã¼ber Ihre Schlauheit machen Sie sich ans Werk.\n\nmariokart2 &lt;-\n  mariokart2 %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. AbbildungÂ 7.10. In AbbildungÂ 7.10 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als standardisiert bezeichnen, da wir sie in Bezug zur â€œtypischen Abweichungâ€, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildungÂ 7.10: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (â€œTransformationâ€) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.7 (z-Werte) z-Werte sind das Resultat der z-Transformation. FÃ¼r die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i = \\frac{x_i - \\bar{x}}{sd_x}.\\square\\)\n\nz-Werte sind nÃ¼tzlich, weil sie die â€œrelativeâ€ Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.\nNach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, AusreiÃŸern), wenn \\(z_i &gt; 2\\) oder \\(z_i &gt; 3\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#fazit",
    "href": "060-modellguete.html#fazit",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.7 Fazit",
    "text": "7.7 Fazit\nDer â€gesunde Menschenverstandâ€œ wÃ¼rde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Das ist vernÃ¼nftig, denn die MAA ist anschaulicher und damit nÃ¼tzlicher als die Varianz und die SD.\nWarum sollte man Ã¼berhaupt ein unanschauliches MaÃŸ wie die Varianz verwenden? Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. GrÃ¼nde, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:9\n\nDie SD ist sehr nÃ¼tzlich zur Beschreibung der Normalverteilung\nDie Varianz wird hÃ¤ufig verwendet bzw. in Forschungsarbeiten berichtet, also mÃ¼ssen Sie die Varianz kennen.\n\nLiegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenÃ¼ber Mittelwert basierten StreuungsmaÃŸen (MAA, Varianz, SD).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\n\n\n\n\n\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag variability an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.9 Literaturhinweise",
    "text": "7.9 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnÃ¼glich zu lesenden Buch eine kurzweilige EinfÃ¼hrung in die Statistik vor; auch StreuungsmaÃŸe haben dabei einen Auftritt. Wer mehr â€œLehrbuch-Feelingâ€ sucht, wird bei Ã‡etinkaya-Rundel & Hardin (2021) fÃ¼ndig (das Buch ist online frei verfÃ¼gbar). Es ist kein Geheimnis, dass StreuungsmaÃŸe keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne StreuungsmaÃŸe gehtâ€™s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonstwo) aus dem Regal ziehen, fÃ¼ndig werden zu diesem Thema. Die BÃ¼cher unterscheiden sich meist â€œnurâ€ in ihrem Anspruch bzw. der didaktischen Aufmachung; fÃ¼r alle ist da was dabei.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literatur",
    "href": "060-modellguete.html#literatur",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.10 Literatur",
    "text": "7.10 Literatur\n\n\n\n\nÃ‡etinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "Ich auf keinen Fall.â†©ï¸\nob es Fritz kann, ist nicht Ã¼berliefert.â†©ï¸\nAus GrÃ¼nden der Ãœbersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berÃ¼cksichtigt und nur Spiele mit 0 oder mit 2 LenkrÃ¤dern.â†©ï¸\nWenn man solche SÃ¤tze liest, fÃ¼hlt sich die Formel fast einfacher an.â†©ï¸\nDie Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meineâ€¦â†©ï¸\nAlgorithmusâ†©ï¸\nsog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehÃ¶rigen Population zu schÃ¤tzen, teilt man nicht durch \\(N\\), sondern durch \\(N-1\\)â†©ï¸\nabgekÃ¼rzt manchmal mit stdâ†©ï¸\nIch wollte noch hinzufÃ¼gen, dass die Varianz eng verknÃ¼pft mit der linearen Algebra, aber ich war nicht sicher, ob das Argument allgemein Ã¼berzeugen wÃ¼rde.â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#lernsteuerung",
    "href": "070-zusammenhaenge.html#lernsteuerung",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Standort im Lernpfad\nAbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n8.1.2 Lernziele\n\nSie kÃ¶nnen die Begriffe Kovarianz und Korrelation definieren und ihren ZusammenhÃ¤nge erlÃ¤utern.\nSie kÃ¶nnen die StÃ¤rke einer Korrelation einschÃ¤tzen.\n\n8.1.3 BenÃ¶tigte R-Pakete\nIn diesem Kapitel benÃ¶tigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n8.1.4 BenÃ¶tigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl1, zu einem â€œPunktâ€ sozusagen, zusammengefasst werden kann.\nIn diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. GleichungÂ 8.1.\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{8.1}\\]\nWo wir in Kapitel 6 eine Variable mit Hilfe eines LagemaÃŸes beschrieben/dargestellt/zusammengefasst/modelliert haben, tun wir hier das Gleiche fÃ¼r zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen von einander abhÃ¤ngen bzw. miteinander (irgendwie) zusammenhÃ¤ngen. Wir begrenzen auf metrische Variablen.\nDie Verbildlichung2 zweier metrischer Variablen haben wir bereits in Kapitel 5.5.2 kennengelernt. Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal AbbildungÂ 8.1.\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)\n\n\n\n\n\n\n\n\n\n(b) â€˜Verwackeltesâ€™ Streudiagramm, um die einzelnen Punkte besser zu erkennen\n\n\n\n\n\n\nAbbildungÂ 8.1: Visualisierung des Zusammenhangs von wheels und total_pr",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.1 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurÃ¼ckbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhÃ¤ngen.3 Gar nicht so schlecht ausgefallen, s. TabelleÂ 8.1.\\(\\square\\)\n\n\n\n\nTabelleÂ 8.1: Statistiknoten und Lernzeit\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. AbbildungÂ 8.2. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso fÃ¼r \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\). Die FlÃ¤che des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\).\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 8.2: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus AbbildungÂ 8.2. Nennen wir das resultierende Rechteck das â€œSummenrechteckâ€. Ja, ich weiÃŸ, ich strapaziere mal wieder Ihre Phantasie4. Jetzt kommtâ€™s: Je grÃ¶ÃŸer die FlÃ¤che des Summenrechtecks, desto stÃ¤rker der (lineare) Zusammenhang.\nBeachten Sie, dass die FlÃ¤chen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die FÃ¼llfarben der Rechtecke verdeutlichen dies, s. AbbildungÂ 8.2. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist. So zeigt AbbildungÂ 8.3 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) Ã¼berwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ Ã¼berwiegt).\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten 1 und 3) Ã¼berwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) Ã¼berwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\n\n\n\n(b) Positive Vorzeichen (Quadranten 1 und 3) Ã¼berwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) Ã¼berwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildungÂ 8.3: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die FlÃ¤chen der Abweichungsrechtecke addiert.\n\n\nWir kÃ¶nnen das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das Ã¤ndert nichts an der Aussage, aber der Mittelwert hat gegenÃ¼ber der Summe den Vorteil, dass er unabhÃ¤ngig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck.\nEin MaÃŸ fÃ¼r den Zusammenhang von Lernzeit und Klausurpunkte ist also die FlÃ¤che des mittleren Abweichungsrechtecks, s. AbbildungÂ 8.4.\n\n\n\n\n\nAbbildungÂ 8.4: Die Kovarianz als mittleres Abweichungsrechteck. Die FlÃ¤che der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die FlÃ¤che des mittleren Abweichungsrechtecks. Sie ist ein MaÃŸ fÃ¼r die StÃ¤rke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. AbbildungÂ 8.4.\\(\\square\\)\n\n\nğŸ‘©â€ğŸ“ Zu viele Bilder! Ich brauch Zahlen.\n\n\nğŸ‘©â€ğŸ« Kommen schon!\n\nTabelleÂ 8.2 zeigt die Werte fÃ¼r die X- und Y-Abweichung und die resultierenden FlÃ¤chen der Abweichungsrechtecke. Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv.\n\n\n\nTabelleÂ 8.2: Werte der Abweichungsrechtecke\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\nx_pos\ny_pos\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51.25\n17\n20.75\nTRUE\nTRUE\n1\n352.75\n\n\n2\n44\n40\n53\n51.25\n-13\n-7.25\nFALSE\nFALSE\n1\n94.25\n\n\n3\n39\n35\n53\n51.25\n-18\n-12.25\nFALSE\nFALSE\n1\n220.50\n\n\n4\n50\n67\n53\n51.25\n14\n-1.25\nTRUE\nFALSE\n-1\n-17.50\n\n\n\n\n\n\n\n\nBerechnen wir als nÃ¤chstes das mittlere Abweichungsrechteck, die Kovarianz:\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. GleichungÂ 8.2:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.2}\\]\nGleichungÂ 8.2 in Worten ausgedrÃ¼ckt:\n\nRechne fÃ¼r jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne fÃ¼r jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere fÃ¼r alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die FlÃ¤chen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.2 (Variablen mit positiver Kovarianz) Â \n\nGrÃ¶ÃŸe und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf\\(\\square\\)\n\n\n\n\nBeispiel 8.3 (Variablen mit negativer Kovarianz) Â \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und DepressivitÃ¤t\\(\\square\\)\n\n\n\nDrei Extrembeispiele fÃ¼r Kovarianz-Werte sind in AbbildungÂ 8.5 dargestellt.\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\n\n\n\n(c) negativer Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 8.5: Verschiedene Werte der Kovarianz\n\n\nBei einer Kovarianz von (ungefÃ¤hr) 0 ist die Gesamt-FlÃ¤che der Abweichungsrechtecke5, wenn man sie pro Quadrant aufsummiert, ungefÃ¤hr gleich groÃŸ, s. AbbildungÂ 8.6. Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so betrÃ¤gt die Summe in etwa (oder genau) Null.\nDamit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null:\n\\[\\begin{align}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\varnothing \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov} &= 0\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke, deren FlÃ¤che sich zu 0 addiert\n\n\n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke, deren FlÃ¤che sich zu 0 addiert\n\n\n\n\n\n\nAbbildungÂ 8.6: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhÃ¤ngig ist von der Skalierung. So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wÃ¼nschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabhÃ¤ngig davon, ob man Einkommen in Euro, Cent oder Dollar misst. AuÃŸerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson lÃ¶st das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nÃ¤mlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so fÃ¼hrt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) so definieren:\n\nDefinition 8.3 (Korrelationskoeffizient r) Der Korrelationskoeffizient \\(r\\) ist definiert als das mittlere Produkt der z-Wert-Paare: \\(r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i}\\), vgl Cohen et al. (2003). \\(\\square\\)\n\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur fÃ¼r metrische Variablen definiert ist.\n\n\n\n\n\n\nHinweis\n\n\n\nAus dem Korrelationskoeffizienten kÃ¶nnen Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert6 des Korrelationskoeffizienten gibt die StÃ¤rke des linearen Zusammenhangs an. Je nÃ¤her der Wert bei 1 liegt desto stÃ¤rker der Zusammenhang.\n\n\n\n\\(r = 0\\): kein linearer Zusammenhang\n\n\\(r = 1\\): perfekter linearer Zusammenhang\\(\\square\\)\n\n\n\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt AbbildungÂ 8.7.\n\n\n\n\n\nAbbildungÂ 8.7: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0\n\n\nDie untere Zeile von AbbildungÂ 8.7 zeigt Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammhang besteht.\n\nÃœbungsaufgabe 8.1 (Korrelationsspiel) Spielen Sie das Korrelationsspiel: Sie Sehen ein Streudiagramm und mÃ¼ssen den richtigen Korrelationskoeffizienten eingeben.\\(\\square\\)\n\n\nÃœbungsaufgabe 8.2 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr GefÃ¼hl fÃ¼r die StÃ¤rke des Korrelationskoeffizienten zu entwickeln.\\(\\square\\)\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhÃ¤ngt? Schauen wir nach! Die Funktion correlation() (aus dem Paket easystats) erledigt das Rechnen fÃ¼r uns.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  # aus `easystats`\n\n\n  \n\n\n\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\nSie kÃ¶nnen auch auf die letzte Zeile, also dem Befehl summary() verzichten. Dann ist die Ausgabe ausfÃ¼hrlicher.\n\n8.4.3 Korrelation â‰  Kausation\nEine Studie fand eine starke Korrelation, zwischen der (HÃ¶he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. AbbildungÂ 8.8.\n\n\n\n\n\nAbbildungÂ 8.8: Schoki futtern macht schlau?\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nKorrelation (bzw. Zusammenhang) ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.4 (Scheinkorrelation) StÃ¶rche und Babies: Eine Urban Myth besagt: Die Anzahl der StÃ¶rche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis.\nEine ErklÃ¤rung fÃ¼r dieses (nur scheinbare) Paradoxon ist, dass die â€œNaturbelassenheitâ€ des Landkreises die gemeinsame Ursache fÃ¼r StÃ¶rche ist (StÃ¶rche lieben Natur) und fÃ¼r Babies ist (die dortige Kultur begÃ¼nstigt, mehr Kinder pro Frau).\nCorona und Glatze:\nMacht die Glatze krank? MÃ¤nner mit Glatze bekommen hÃ¤ufiger Corona (Goren et al., 2020).\n\nBald men at higher risk of severe case of Covid-19, research finds7\n\nEine ErklÃ¤rung lautet, dass Alter einen Effekt hat auf Glatze (je Ã¤lter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatz hat) und auf die Schwere des Corona-Verlaufs (Ã¤ltere Menschen haben deutlich schwerere Corona-VerlÃ¤ufe). \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lÃ¼gt",
    "text": "8.5 Wie man mit Statistik lÃ¼gt\n\n8.5.1 Range-Restriktion\nDurch (nicht-randomisierte) EinschrÃ¤nkung (Restriktion) des Ranges einer (oder beider) Variablen sinkt die StÃ¤rke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003) und AbbildungÂ 8.9.\nErstellen wir uns dazu zwei DatensÃ¤tze mit je zwei Variablen, \\(X\\) und \\(Y\\) der GrÃ¶ÃŸe \\(n=100\\). Ein Datensatz ist ohne EinschrÃ¤nkung des Ranges und einer mit. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in ListingÂ 8.1. Wir schrÃ¤nken dann den Range von \\(X\\) ein auf, sagen wir, den Bereich von \\([-0.5, .5]\\) (Datensatz d_filtered).\n\n\nListingÂ 8.1\n\n\nset.seed(42)\nn &lt;- 1e2\nd &lt;-\n  tibble(x = rnorm(n = n, mean = 0, sd = 1),\n         e = rnorm(n = n, mean = 0, sd = .5),\n         y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-\nd |&gt; \n  filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne EinschrÃ¤nkung des Range: Starke Korrelation\n\n\n\n\n\n\n\n\n\n(b) Mit EinschrÃ¤nkung des Range: SchwÃ¤chere Korrelation\n\n\n\n\n\n\nAbbildungÂ 8.9: SchrÃ¤nkt man den Range einer (oder beider) Variablen ein, so sinkt die StÃ¤rke der Korrelation\n\n\n\nÃœbungsaufgabe 8.3 (Berechnen Sie die Korrelation) Glauben Sie nicht, prÃ¼fen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhÃ¤ngen.\nFalls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, kÃ¶nnen Sie die Daten so (in mittlerweile gewohnter Manier) importieren:\n\nmariokart &lt;- read.csv(\"mariokart.csv\")\n\nFalls der Datensatz im Unterordner mit Namen â€œMein_Unterordnerâ€ liegt, so wÃ¼rden Sie folgenden Pfad eingeben:\n\nmariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\")\n\nMan beachte, dass solche sog. relativen Pfade (relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio) nicht mit einem SchrÃ¤gstrich (Slash) beginnen.\nFalls Sie die Daten nicht auf Ihrem Computer haben, kÃ¶nnen Sie sie komfortable von z.B. der Webseite von Vincent Arel-Bundock herunterladen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wÃ¤hlen die Variablen von mariokart, die Sie in diesem Fall interessieren â€“ natÃ¼rlich nur die metrischen â€“ und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\n\n\n\n\n\n\nNamensverwechslung (name clash)\n\n\n\nEs kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein, wie es mir oben in der Syntax passiert ist. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemÃ¤ÃŸ sagt: â€œHey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.â€ Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: â€œHey R, nimm gefÃ¤lligst select aus dem Paket dplyr, dortâ€wohntâ€ nÃ¤mlich select. Auf Errisch spricht sich das so: dplyr::select(...).\\(\\square\\)\n\n\nEtwas schÃ¶ner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. TabelleÂ 8.3.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  correlation() \n\n\nTabelleÂ 8.3: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n  \n\n\n\n\n\n\nNeben einigen Statistiken, die wir einfach geflissentlich ausblenden (t und p) beinhaltet die Tabelle eine interessante Information: den SchÃ¤tzbereich fÃ¼r die Korrelation, gekennzeichnet als 95% CI. Grob gesagt kÃ¶nnen wir diese Information so interpretieren: â€œMit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich.â€8\nMÃ¶chte man nur einzelne Korrelationskoeffizienten ausrechnen, kÃ¶nnen wir die Idee des Zusammenfassens, s. GleichungÂ 8.1, nutzen:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels))\n\n\n  \n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nIm Falle von fehlenden Werte mÃ¼ssen Sie R aus seiner schÃ¼chternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n  \n\n\n\n\n\n\nğŸ§‘â€ğŸ“ Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket {dataExplorer} bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. AbbildungÂ 8.10.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildungÂ 8.10: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#vertiefung",
    "href": "070-zusammenhaenge.html#vertiefung",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.7 Vertiefung",
    "text": "8.7 Vertiefung\nDieser TED-Vortrag informiert zum Thema Scheinkorrelation. Hier finden Sie weitere Beispiele fÃ¼r Scheinkorrelationen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.8 Aufgaben",
    "text": "8.8 Aufgaben\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag association an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#halbzeitquiz",
    "href": "070-zusammenhaenge.html#halbzeitquiz",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.9 Halbzeitquiz",
    "text": "8.9 Halbzeitquiz\nHier gehtâ€™s zu einem Quiz zur deskriptiven Statistik (MaÃŸe der zentralen Tendenz, VariabilitÃ¤t, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.10 Fallstudien",
    "text": "8.10 Fallstudien\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Ãœbungsaufgaben kÃ¶nnen theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer LÃ¶sung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.\\(\\square\\)\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl. Es ist nicht nÃ¶tig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Ãœbung, dort, wo Sie es nÃ¶tig haben.\\(\\square\\)\n\n\n\nEDA zu FlugverspÃ¤tungen\nYACSDA: Topgear\nExplorative Datenanalyse zum Datensatz â€œOECD Wellbeingâ€\nDatensatz flights: Finde den Tag mit den meisten AbflÃ¼gen\nTidyverse Case Study: Exploring the Billboard Charts",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.11 Literaturhinweise",
    "text": "8.11 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erlÃ¤utern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schÃ¶nes, modernes Statistikbuch bietet der Psychologie-Prof Russel Poldrack von der Princeton University (2023); auch dieses Buch ist frei online verfÃ¼gbar. Tipp: Nutzen Sie die Ãœbersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas hÃ¶heren Anspruchs.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literatur",
    "href": "070-zusammenhaenge.html#literatur",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.12 Literatur",
    "text": "8.12 Literatur\n\n\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGoren, A., VaÃ±o-GalvÃ¡n, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain â€“ A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545â€“1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "auch Skalar genanntâ†©ï¸\nVisualisierungâ†©ï¸\n&gt; ğŸ§‘â€ğŸ“ Typisches Lehrerbeispiel!!â†©ï¸\nhoffentlich nicht Ihre Geduldâ†©ï¸\nBei der Varianz waren es Quadrate, bei der Kovarianz sind es Rechtecke.â†©ï¸\nBetragâ†©ï¸\nhttps://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/, Abruf 2023-03-24â†©ï¸\nBayesianische Interpretationâ†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#lernsteuerung",
    "href": "080-regression1.html#lernsteuerung",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n9.1.2 Lernziele\n\nSie kÃ¶nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie kÃ¶nnen die Bestandteile eines Geradenmodells aufzÃ¤hlen und erlÃ¤utern.\nSie kÃ¶nnen die GÃ¼te eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie kÃ¶nnen Geradenmodelle sowie ihre ModellgÃ¼te in R berechnen.\n\n9.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.4 BenÃ¶tigte Daten\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nÃ¼tzlich Sache, unter (mindestens) folgenden Voraussetzungen:\n\nSie sind prÃ¤zise\nWir kennen die PrÃ¤zision\nJemand interessiert sich fÃ¼r die Vorhersage\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne PrÃ¤diktor\n\nBeispiel 9.1 Nach intensiver BeschÃ¤ftigung mit Statistik sind Sie allgemein als Checker bekannt. Viele jÃ¼ngere Studentis fragen Sie um Rat. eines Tages kommt ei Studenti, Toni, und fragt: â€œWelche Statistiknote kann ich in der Klausur erwarten?â€ Sie entgegnen: â€œWie viel hast du denn gelernt?â€. Die Antwort: â€œSag ich nicht.â€\nNach kurzem Ãœberlegen geben sie den Notenschnitt der letzten Klausur als Prognose fÃ¼r dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).\nZuerst importieren Sie die Daten der letzten Klausur1:\n\nnoten2 &lt;- read.csv(\"daten/noten2.csv\")\n\n Download \nDann rechnen Sie den Mittelwert aus:\n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n  \n\n\n\nIhre Antwort lautet also: â€œIm Schnitt haben die Studis bei der letzten Klausur gut 70% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!â€\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Kenntnis eines PrÃ¤diktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert fÃ¼r jede Beobachtung, s. AbbildungÂ 9.1. Wir nutzen den Mittelwert als Punktmodell fÃ¼r den Klausurerfolg.\\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\n9.2.2 Nullmodell (Punktmodell)\nModelle ohne PrÃ¤diktor, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null PrÃ¤diktoren hat, nennt man es auch manchmal â€œNullmodellâ€.\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##       71.08\n\nlm steht fÃ¼r â€œlineares Modellâ€, die 1 sagt, dass es keine PrÃ¤diktoren gibt. In dem Fall wird der Mittelwert als Gerade verwendet. Der zurÃ¼ckgemeldete Koeffizient (Intercept) ist hier der Modell des Punktmodells. Da es ein Punktmodell ist, sagt es fÃ¼r alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nDie Regressionsgleichung lautet demnach: y_pred = 71.08. In Worten: â€œWir sagen fÃ¼r jede Beobachtung einen Wert von ca. 71 vorherâ€.\n\n9.2.3 Vorhersagen mit PrÃ¤diktor\n\nBeispiel 9.2 (Toni verrÃ¤t die Lernzeit) Dis Studenti, Toni, entschlieÃŸt sich dann doch noch, die Lernzeit zu verraten: â€œOkay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.â€ Jetzt mÃ¼ssen Sie erstmal nachdenken: â€œWie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?â€\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. AbbildungÂ 9.2, a).2\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: â€œBei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. KÃ¶nnte mit dem Bestehen eng werden.â€ Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.\\(\\square\\)\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen. Mit einem Lineal kÃ¶nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. AbbildungÂ 9.2, b).\n\n\n\n\n\n\n\n\n\n(a) Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)\n\n\n\n\n\n\n\n\n\n(b) Eine â€˜Trendgeradeâ€™ (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet.\n\n\n\n\n\n\nAbbildungÂ 9.2: Noten und Lernzeit: Rohdaten und Modell\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell fÃ¼r die Daten, s. AbbildungÂ 9.2, rechts. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt fÃ¼r alle Beobachtungen den gleichen Wert vorher. AbbildungÂ 9.1 und AbbildungÂ 9.2 stellen ein Punktmodell einem Geradenmodell gegenÃ¼ber.\nIn einem Geradenmodell wird nicht mehr (notwendig) fÃ¼r jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.1 Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). HÃ¤ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet: \\(f(\\color{xcol}{x})=\\color{ycol}{y}=\\color{beta1col}{m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + \\color{beta1col}{b_1} \\color{xcol}{x}\\) .3\nDas â€œDachâ€ Ã¼ber y, \\(\\color{modelcol}{\\hat{y}}\\), drÃ¼ckt aus, dass es sich den den geschÃ¤tzten, bzw. vom Modell vorhergesagten (â€œmodelliertenâ€) Wert fÃ¼r \\(\\color{ycol}{y}\\) handelt, nicht das tatsÃ¤chliche (empirische, beobachtete) \\(\\color{ycol}{y}\\). \\(\\square\\)\n\nAbbildungÂ 9.3 skizziert die Elemente einer Regression.\n\n\n\n\n\nAbbildungÂ 9.3: Achsenabschnitt und Steigung einer Regressionsgeraden\n\n\nBildquelle: Basierend auf diesem Diagramm von Henri Menke\n\n\n\n\n\n\nDas einfache lineare Modell\n\n\n\nDas einfache lineare Modell nimmt den Wert einer abhÃ¤ngigen metrischen Variablen, y als lineare Funktion von unabhÃ¤ngigen Variablen, x an, plus einem Fehlerterm, e. \\(\\square\\)\n\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}\\]\nMit:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschÃ¤tzter y-Achsenabschnitt laut Modell\n\n\\(\\color{beta1col}{\\beta_1}\\): geschÃ¤tzte Steigung laut Modell\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nJe nach Datenlage kÃ¶nnen sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. AbbildungÂ 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildungÂ 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher ModellgÃ¼te\n\n\nAbbildungÂ 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie kÃ¶nnen Punkte per Klick/Touch hinzufÃ¼gen.\n\n\n\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"RÂ²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\nQuelle\n\n\n\nAbbildungÂ 9.5: Interaktives Beispiel fÃ¼r eines lineares Modell. FÃ¼gen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert. â€œOkay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurÃ¼ck!â€\nDas sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{X}=0\\) gibt der Achsenabschnitt zurÃ¼ck. Schnell skizzieren Sie dazu ein Diagramm, s. AbbildungÂ 9.6. Puh, die Antwort wird Toni nicht gefallen â€¦\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 9.6: Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf AbbildungÂ 9.6 zu schauen, kÃ¶nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\nğŸ§‘â€ğŸ“ Hey R, predicte mir mal auf Basis vom Modell â€œlm1â€ den Lernerfolg fÃ¼r Toni, wenn der x=0 Stunden lernt.\n\n\nğŸ¤– Okay, ich predicte mit Modell â€œlm1â€ und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)\ntonis_lernzeit\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit)\n##        1 \n## 8.603032\n\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. GleichungÂ 9.2 :\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.1}\\]\nLies: â€œLaut meinem Modell ist mein (geschÃ¤tztes) \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)â€.\nWir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist:\n\\[\\color{ycol}{AV} \\sim \\color{xcol}{UV} \\tag{9.2}\\]\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\nGleichungÂ 9.2 kÃ¶nnen Sie so ins Errische Ã¼bersetzen:\n\nlm(y ~ x, data = meine_daten)\n\nlm steht fÃ¼r â€œlineares Modellâ€, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade4.\n\nBeispiel 9.4 (Zahlen fÃ¼r Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: â€œJetzt hÃ¶r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir prÃ¤zise Zahlen!â€.\n\n\nlm1 &lt;- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      8.6030       0.8794\n\nR gibt Ihnen die beiden Koeffizienten fÃ¼r die Gerade aus. Den Namen des Objekts kÃ¶nnen Sie frei aussuchen, z.B. mein_erstes_lm.\nDie Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x\n8.6 ist der Achsenabschnitt, d.h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: FÃ¼r jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 10 Stunden gelernt, wÃ¼rden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 10\ny_pred &lt;- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17.4\n\n\nBeispiel 9.5 (Vorhersage fÃ¼r Klausurerfolg, nÃ¤chster Versuch) Sie versuchen, noch etwas Gutes fÃ¼r Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dÃ¼rfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit2)\n##       1 \n## 72.7999\n\nDie Syntax von predict lautet:\npredict(name_des_objekts, newdata = tabelle_mit_prÃ¤diktorwerten)\n\n\n\n\n\n\nHinweis\n\n\n\nMit predict bekommt man eine Vorhersage; im Standard eine â€œPunkt-Vorhersageâ€, eine einzelne Zahl.\\(\\square\\)\n\n\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagten Wert fÃ¼r eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsÃ¤chlichen Wert nennt man Vorhersagefehler (error, \\(e_i\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Residuen beim Geradenmodell (lm1)\n\n\n\n\n\n\n\n\n\n(b) Residuen beim Punktmodell (lm0)\n\n\n\n\n\n\nAbbildungÂ 9.7: Vorhersagefehler als Abweichungsbalken\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben5:\n\nmae(lm0)\n## [1] 11.18385\nmae(lm1)\n## [1] 7.954085\n\nVergleichen wir MAE im Nullmodell mit MAE in lm1:\n\nverhaeltnis_fehler_mae &lt;- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.7112118\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm1 haben die mittlere (Absolut-)LÃ¤nge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.2 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)).\\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere KenngrÃ¶ÃŸen wie MAE oder MSE.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist.\\(\\square\\)\n\n\nNatÃ¼rlich kÃ¶nnen wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen6.\n\nmse(lm0)\n## [1] 192.7863\nmse(lm1)\n## [1] 106.4519\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.5521755\n\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\nDie Regressionskoeffizienten7 b0 und b1 wÃ¤hlt man so, dass die Residuen minimal sind, s. AbbildungÂ 9.8.\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildungÂ 9.8: Bildquelle: Karsten LÃ¼bke, FOM Hochschule\n\n\nGenauer gesagt wird die Summe der quadrierten Residuen minimiert, s. GleichungÂ 9.3.\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene MÃ¶glichkeiten, um die Koeffizienten zu berechnen8. Eine schÃ¶ne Darstellung dazu findet sich bei Kaplan (2009).\nâ€œVon Handâ€ kÃ¶nnen Sie die Optimierung von b0 und b1 in dieser App der FOM-Hochschule ausprobieren.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r-quadrat-als-maÃŸ-der-modellgÃ¼te",
    "href": "080-regression1.html#r-quadrat-als-maÃŸ-der-modellgÃ¼te",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.4 R-Quadrat als MaÃŸ der ModellgÃ¼te",
    "text": "9.4 R-Quadrat als MaÃŸ der ModellgÃ¼te\nAnders gesagt, wir haben uns um \\(1 - 0.55\\) verbessert:\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.4478245\n\n\nDefinition 9.3 (R-Quadrat) Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen von lm0 zum gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). R-Quadrat (\\(R^2\\)) eines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein MaÃŸ der ModellgÃ¼te: Je grÃ¶ÃŸer \\(R^2\\), desto besser die Vorhersage. Da es ein AnteilsmaÃŸ9 ist, liegt der Wertebereich zwischen 0 uns 1. Im Nullmodell liegt R-Quadrat per Definition bei 0. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable erklÃ¤rt.\nWir kÃ¶nnen R-Quadrat (\\(R^2\\)) uns von R z.B. so ausgeben lassen:\n\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\)10, s. AbbildungÂ 9.9.\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation, r â‰… 0 und R2 â‰… 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefÃ¤hr) parallel zur X-Achse\n\n\n\n\n\n\n\n\n\n(b) Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert\n\n\n\n\n\n\nAbbildungÂ 9.9: ExtremfÃ¤lle von R-Quadrat: 0 und 1\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man fÃ¼r jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\), vorhersagen wÃ¼rde.\n\n\n\n\n\n\nHinweis\n\n\n\nJe grÃ¶ÃŸer R-Quadrat, desto besser erklÃ¤rt das Modell die Daten (desto besser der â€œFitâ€, sagt man).\n\n\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der GrÃ¶ÃŸe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 ModellgÃ¼te\nDie Residuen (Vorhersagefehler) bestimmen die ModellgÃ¼te: Sind die Residuen im Schnitt groÃŸ, so ist die ModellgÃ¼te gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur VerfÃ¼gung: R-Quadrat, r11, MSE, RMSE, MAE, â€¦\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\)12) und Steigung (\\(beta_1\\)) sind nur eingeschrÃ¤nkt zu interpretieren, wenn man die zugrundeliegenden kausalen AbhÃ¤ngigkeiten nicht kennt. Nur aufgrund eines statistischen Zusammenhangs darf man keine kausalen AbhÃ¤ngigkeiten annehmen. Ohne eine guten Grund fÃ¼r eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der ModellgÃ¼te und den Vorhersagen begnÃ¼gen. Was auch was wert ist.\n\n9.5.2.1 Achsenabschnitt (b0)\nâ€œIm Modell lm1 liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=8.6\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) kÃ¶nnen also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten.â€ Leider ist es hÃ¤ufig so, dass PrÃ¤diktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nÃ¼tzt.\n\nBeispiel 9.6 (Regression GrÃ¶ÃŸe und Gewicht) Nutzt man KÃ¶rpergrÃ¶ÃŸe und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von KÃ¶rpergrÃ¶ÃŸe wenig nÃ¼tzlich, da es keine Menschen gibt der GrÃ¶ÃŸe 0.\\(\\square\\)\n\n\n9.5.2.2 Geradensteigung (b1)\nâ€œIm Modell lm1 betrÃ¤gt der Regressionskoeffizient b1 \\(0.88\\). Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von b1.â€\n\n\n\n\n\n\nVorsicht\n\n\n\nHÃ¤ufig liest man, der â€œEffekt des PrÃ¤diktorsâ€ auf die AV betrage z.B. \\(0.88\\). â€œEffektâ€ ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort â€œEffektâ€ mit Vorsicht genieÃŸen. Manche sprechen daher auch von einem â€œstatistischen Effektâ€.\\(\\square\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lÃ¼gt",
    "text": "9.6 Wie man mit Statistik lÃ¼gt\nDer Unterschied in ModellgÃ¼te zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) MaÃŸ der ModellgÃ¼te und da \\(r = \\sqrt{R^2}\\), darf \\(r\\) nicht wie \\(R^2\\) als MaÃŸ der ModellgÃ¼te interpretiert werden. AbbildungÂ 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildungÂ 9.10: Zusammenhang von r und R-Quadrat\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dÃ¼rfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie mÃ¶chten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs. Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz. Auf gehtâ€™s!\nDaten laden:13\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloÃŸem Rumprobieren Ã¼berlegen Sie und schauen dann in AbbildungÂ 8.10 nach, welche Variable am stÃ¤rksten korreliert mit total_pr; es resultiert lm3:\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n\n\n\n\nTabelleÂ 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in TabelleÂ 9.1 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut lm3 etwa 36 Euro finaler Verkaufspreis erwarten. Pro Euro an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.14.\nDie Regressionsgleichung von lm3 lautet demnach:\ntotal_pr_pred = 36.25 + 4.34*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36.25â‚¬ â€œSockelbetragâ€ plus 4.34 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (â€œexpectationsâ€) des Verkaufspreises in AbhÃ¤ngigkeit vom Wert der UV (ship_pr) auch schÃ¤tzen (â€œto estimateâ€) lassen, und zwar so15:\n\nestimate_expectation(lm3) %&gt;% head()  # nur die ersten paar vorhergesagten Werte\n\n\n  \n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\nğŸ¤– Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert fÃ¼r total_pr fÃ¼r einen bestimmten Wert von ship_pr.\n\n\nğŸ§‘â€ğŸ“ Kann ich auch predict benutzen? Ich wÃ¼rde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n\nğŸ¤– Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen\n)\n\n\npredict(lm3, newdata = neue_daten)\n##        1        2 \n## 40.58276 53.59442\n\nAber nÃ¼tzlich wÃ¤re noch, das Modell (bzw. die SchÃ¤tzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.B. so, s. AbbildungÂ 10.10.\n\nestimate_expectation(lm3) %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heiÃŸt sinngemÃ¤ÃŸ â€œschÃ¤tze den zu erwartenden Wertâ€. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie â€œgutâ€ das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13.0632\n\nDas Modell erklÃ¤rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nmae(lm3)\n## [1] 13.0632\n\nIm nÃ¤chsten Meeting erzÃ¤hlen Sie Ihrem Chef â€œIch kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!â€. HÃ¶rt sich gut an. Allerdings hÃ¤tte ihr Chef es gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie stellt die PrÃ¼fungsleistung â€œPrognosewettbewerbâ€ einfÃ¼hrend dar. Es empfiehlt sich fÃ¼r Sie, diese Fallstudie sorgsam zu bearbeiten.\\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei Kaggle ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet.\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition Ames House Prices.\n\nBeschreibung\nZiel/Aufgabe\nSpielregeln\n\n9.8.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.8.3 Daten\nWenn Sie sich nicht bei Kaggle einloggen mÃ¶chten, kÃ¶nnen Sie die Daten von Kaggle herunterladen und zwar hier.\nIm Einzelnen mÃ¼ssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Code book, d.h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von HÃ¤usern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von HÃ¤usern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\nSie kÃ¶nnen auch so auf die Daten zugreifen:\n\nd_train_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\nDas Code Book kÃ¶nnen Sie hier einsehen und herunterladen.\n\n9.8.4 Prognosedatei\nDie Prognosedatei soll prinzipiell so aussehen:\n\n\n\n  \n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - fÃ¼r welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice ist Ihre Vorhersage fÃ¼r den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar?\nLos gehtâ€™s!\n\n9.8.5 Daten importieren\nWir starten die Ã¼blichen R-Pakete und importieren die Daten (d):\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\nd_train_path &lt;- \"daten/ames-kaggle/train.csv\"\nd_test_path &lt;- \"daten/ames-kaggle/test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Beispiel gehen wir davon aus, dass die Dateien train.csv und test.csv in einem Unterordner namens daten/ames-kaggle liegen. Sie mÃ¼ssen sie dort abspeichern. Dieser Ornder muss ein Unterordner Ihres aktuellen R-Projekts sein.\\(\\square\\)\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn das Importieren von der Festplatte nicht klappt â€¦ Es ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fÃ¼rs Erste kÃ¶nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.\\(\\square\\)\n\n\n\nd_train &lt;- read_csv(d_train_path_online)\nd_test &lt;- read_csv(d_test_path_online)\n\n\n9.8.6 Ein erster Blick in die Daten\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, TabelleÂ 9.2.\n\ndescribe_distribution(d_train)\n\n\nTabelleÂ 9.2: Verteilung der metrischen Variablen im ames-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n9.8.7 Ein erstes Vorhersagemodell\n\n9.8.7.1 Welche Variablen eignen sich zur Vorhersage?\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller PrÃ¤diktoren mit der abhÃ¤ngigen Variablen16 zu berechnen, s. TabelleÂ 9.3.\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der HÃ¶he des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\nTabelleÂ 9.3: Korrelation der PrÃ¤diktoren (UV) mit der AV\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt\ndf\np\n\n\n\nOverallQual\nSalePrice\n0.79\n(0.77, 0.81)\n49.36\n1458\n&lt; .001***\n\n\nGrLivArea\nSalePrice\n0.71\n(0.68, 0.73)\n38.35\n1458\n&lt; .001***\n\n\nGarageCars\nSalePrice\n0.64\n(0.61, 0.67)\n31.84\n1458\n&lt; .001***\n\n\nGarageArea\nSalePrice\n0.62\n(0.59, 0.65)\n30.45\n1458\n&lt; .001***\n\n\nTotalBsmtSF\nSalePrice\n0.61\n(0.58, 0.64)\n29.67\n1458\n&lt; .001***\n\n\n1stFlrSF\nSalePrice\n0.61\n(0.57, 0.64)\n29.08\n1458\n&lt; .001***\n\n\nFullBath\nSalePrice\n0.56\n(0.52, 0.59)\n25.85\n1458\n&lt; .001***\n\n\nTotRmsAbvGrd\nSalePrice\n0.53\n(0.50, 0.57)\n24.10\n1458\n&lt; .001***\n\n\nYearBuilt\nSalePrice\n0.52\n(0.48, 0.56)\n23.42\n1458\n&lt; .001***\n\n\nYearRemodAdd\nSalePrice\n0.51\n(0.47, 0.54)\n22.47\n1458\n&lt; .001***\n\n\nGarageYrBlt\nSalePrice\n0.49\n(0.44, 0.53)\n20.66\n1377\n&lt; .001***\n\n\nMasVnrArea\nSalePrice\n0.48\n(0.44, 0.52)\n20.69\n1450\n&lt; .001***\n\n\nFireplaces\nSalePrice\n0.47\n(0.43, 0.51)\n20.16\n1458\n&lt; .001***\n\n\nBsmtFinSF1\nSalePrice\n0.39\n(0.34, 0.43)\n16.00\n1458\n&lt; .001***\n\n\nLotFrontage\nSalePrice\n0.35\n(0.30, 0.40)\n13.01\n1199\n&lt; .001***\n\n\nWoodDeckSF\nSalePrice\n0.32\n(0.28, 0.37)\n13.10\n1458\n&lt; .001***\n\n\n2ndFlrSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.87\n1458\n&lt; .001***\n\n\nOpenPorchSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.71\n1458\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 1201-1460\n\n\n\n\n\nAha! Ein Menge Information.17\nDiese Variablen sind einigermaÃŸen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n9.8.7.2 Modell 1\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im GroÃŸen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stÃ¤rksten mit der Zielvariable korreliert und ist daher ein guter Kandidat fÃ¼r die Vorhersage.\n\nm1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n\n\n  \n\n\n\nWie gut ist das Modell?\n\nrmse(m1)  # aus easystats\n## [1] 48589.45\n\nIm Schnitt liegen wir ca. 56 Tausend Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die ModellgÃ¼te:\n\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\n\n9.8.7.3 Model 2\nBerechnen wir als nÃ¤chstes ein Modell mit mehreren UV, m2.\n\n\n\n\n\n\nHinweis\n\n\n\nMann kann mehrere UV (PrÃ¤diktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur â€œals UV nimm UV1 und UV2 und â€¦â€. \\(\\square\\)\n\n\n\nm2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n\nTabelleÂ 9.4 zeigt die Koeffizienten von m2.\n\n\n\nTabelleÂ 9.4: Modellparameter von m1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1456)\np\n\n\n\n(Intercept)\n-98832.49\n4842.90\n(-1.08e+05, -89332.69)\n-20.41\n&lt; .001\n\n\nOverallQual\n27104.83\n1072.18\n(25001.64, 29208.01)\n25.28\n&lt; .001\n\n\nGrLivArea\n50.67\n2.55\n(45.67, 55.68)\n19.86\n&lt; .001\n\n\nGarageCars\n21298.96\n1807.06\n(17754.23, 24843.69)\n11.79\n&lt; .001\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells m2 fÃ¼r die Daten von d_train?\n\nrmse(m2)\n## [1] 40566.42\n\nIm Schnitt liegen unsere Vorhersagen ca. 40 Tausend Dollar daneben. Ist das gut?\n\nr2(m1)\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\nOb die ModellgÃ¼te (R-Quadrat, RMSE, etc.) â€œgutâ€ oder â€œhochâ€ ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen.\n\n9.8.7.4 Nullmodell\nZum Vergleich berechnen wir das maximal einfache Modell: ohne PrÃ¤diktoren. Man nennt es das â€œNullmodellâ€. In diesem Modell sagen wir fÃ¼r jedes Haus einfach den mittleren Preis aller HÃ¤user vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnomdells?\n\nrmse(m0)\n## [1] 79415.29\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.8 Vorhersagen im Test-Datensatz\nWir haben jetzt unseren Champion, m1. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample prÃ¤zise sein werden? Oder himmelweit daneben? EnttÃ¤usche uns nicht!\nHier sind die Vorhersagen:\n\nm1_pred &lt;- predict(m1, newdata = d_test)\nhead(m1_pred)\n##        1        2        3        4        5        6 \n## 130972.9 176408.7 130972.9 176408.7 267280.3 176408.7\n\n\n1\n\npredicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus d_test\n\n2\n\nzeige den â€œKopfâ€ der Vorhersagen (m1_pred), d.h. die ersten paar Vorhersagen\n\n\n\n\nDie Vohersagen fÃ¼gen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = m1_pred)\n\n\n9.8.9 Einreichen!\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhesagen ein.\nFÃ¼r die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten id und SalePrice:\n\nm1_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\nKaggle mÃ¶chte keine fehlenden Werten in den Vorhersagen, also prÃ¼fen wir das mal:\n\nm1_subm %&gt;% \n  drop_na() %&gt;%\n  nrow()\n## [1] 1459\n\n\n1\n\nLass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2\n\nzÃ¤hle die Anzahl der Zeilen\n\n\n\n\nOh, das ist eine Zeile weniger! Wir haben also einen fehlenden Wert!\nFiltern wir die Spalte SalePrice mal nach â€œist NAâ€:\n\nm1_subm %&gt;% # &lt;1)\n  filter(is.na(SalePrice))\n\n\n  \n\n\n\nÃœbersetzen wir die Syntax auf Deutsch:\n\nNimm zuerst die Tabelle m1_smb\nFilter dann so, dass du nur Zeilen hast, fÃ¼r die gilt, â€œhier ist ein NA in der Spalte SalePrice\n\nAh, da ist er, der fehlende Wert, in Zeile 2577! Hinfort!\nWir ersetzen die fehlenden Werte in SalePrice mit dem Mittelwert von SalePrice:\n\nm1_subm_nona &lt;-\n  m1_subm %&gt;%\n  mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE)))\n\nDie Syntax wieder auf Deutsch:\n\nDefiniere m1_subm_nona wie folgt\nNimm m1_subm und dann\nVerÃ¤ndere die Spalte SalePrice und zwar so, dass NAs ersetzt werden durch den Mittelwert von SalePrice\n\n\nUnd? Gib es jetzt noch fehlende Werte?\n\nm1_subm_nona %&gt;% \n  filter(is.na(SalePrice))\n\n\n  \n\n\n\nNein! Die Ergebnistabelle hat null Zeilen. â€œNo NAâ€ - Keine NAs, keine fehlenden Werte mehr.\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.18\n\nwrite_csv(m1_subm_nona, \"daten/ames-kaggle/m1-subm.csv\")\n\nUnd dann laden Sie diese Datei, m1_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn.\nDas Modell erzielte einen Score von 0.55521.\n\n9.8.10 Debrief\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele AnsÃ¤tze, dieses Modell zu verbessern.\nHier sind einige Fragen, die Sie sich dazu stellen kÃ¶nnen:\n\nWelche PrÃ¤diktoren sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn ein PrÃ¤diktor schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche PrÃ¤diktoren quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\nâ€¦\n\nViel Spielraum fÃ¼r Ihre KreativitÃ¤t!",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nEine Aufgabe, die eine EinfÃ¼hrung zum Kaggle-Wettbewerb Ames House Prices bietet, finden Sie hier im Datenwerk.\nSuchen Sie beim Datenwerk auch nach diesen Aufgaben:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\n\nSchauen Sie sich die Aufgaben beim Datenwerk an, vor allem die Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff; vielleicht kÃ¶nnen Sie einige Aufgaben nicht lÃ¶sen. Ignorieren Sie einfach diese Aufgaben.\nBeachten Sie die Hinweise zu den Aufgaben.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere EinfÃ¼hrung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte EinfÃ¼hrung in Statistik inklusive der Regressionsanalyse findet sich bei Cetinkaya-Rundel & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literatur",
    "href": "080-regression1.html#literatur",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.11 Literatur",
    "text": "9.11 Literatur\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "Diese Syntax wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls mÃ¼ssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.â†©ï¸\nDie Daten stehen hier zum Download bereit.â†©ï¸\nDie Nomenklatur mit \\(b_0, b_1\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, ...\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage Ã¼ber eine Population, nicht nur Ã¼ber eine Stichprobe, machen mÃ¶chte.â†©ï¸\nan anderer Stelle in diesem Buch unscharf als â€œTrendgeradeâ€ bezeichnet.â†©ï¸\naus dem Paket easystatsâ†©ï¸\nWer mag, kann den MSE auch von Hand berechnen: mean((noten2$y-mean(noten2$y))^2)â†©ï¸\nhier synonym: Modellparameterâ†©ï¸\ndie sind aber nicht in diesem Buch zu findenâ†©ï¸\nProzentzahlâ†©ï¸\nBei Modellen mit einem PrÃ¤diktor; gibt es mehrere PrÃ¤diktoren gilt die Beziehung nur wenn die PrÃ¤diktoren alle paarweise unabhÃ¤ngig sind.â†©ï¸\nals Korrelation von tatsÃ¤chlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)â†©ï¸\nlies: â€œbeta Nullâ€â†©ï¸\nUnd die Ã¼blichen Pakete starten, nicht vergessen.â†©ï¸\nDie Spalte 95 CI gibt einen SchÃ¤tzbereich fÃ¼r den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um SchÃ¤tzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schlieÃŸlich nur eine Stichprobe der GrÃ¶ÃŸe \\(n=143\\).â†©ï¸\nDie Funktion stammt aus easystatsâ†©ï¸\ndie vorherzusagende Variable, auch Ziel- oder Outcome-Variable genanntâ†©ï¸\nWenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: FÃ¼hren Sie die Syntax schrittweise aus. Zuerst d_train ausfÃ¼hren und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausfÃ¼hren, wieder die Ausgabe betrachten, usw.â†©ï¸\nEs bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfÃ¼gt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#lernsteuerung",
    "href": "090-regression2.html#lernsteuerung",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n10.1.2 Lernziele\n\nSie kÃ¶nnen Regressionsmodelle fÃ¼r Forschungsfragen mit binÃ¤rer, nominaler und metrischer UV erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen Interaktionseffekte in Regressionsmodellen erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen Modelle nutzen, um Vorhersagen anhand neuer Daten zu erstellen.\n\n10.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(yardstick)  # fÃ¼r ModellgÃ¼te im Test-Sample\nlibrary(easystats)\n\n\n10.1.4 BenÃ¶tigte Daten\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD.1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "href": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: GlÃ¤serne Kunden",
    "text": "10.2 Forschungsbezug: GlÃ¤serne Kunden\nLineare Modelle2 sind ein altes, aber mÃ¤chtiges Werkzeug. Sie gehÃ¶ren immernoch zum Standard-Repertoire moderner Analystis.\n\nBeispiel 10.1 (Wie gut kann man Ihre PersÃ¶nlchkeit auf Basis des Facebook-Profils vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Kosinski et al. (2013), wie gut PersÃ¶nlichkeitszÃ¼ge durch Facebook-Daten (Likes etc.) vorhergesagt werden kÃ¶nnen. Die Autoren resÃ¼mieren:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten Ã¼ber hohe ModellgÃ¼te (\\(r\\)) zwischen den tatsÃ¤chlichen persÃ¶nlichen Attributen und den vorhergesagten Werten Ihres Modells, s. AbbildungÂ 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also Ã¤hnlich zu dem in diesem Kapitel vorgestellten Methoden.\nNeben der analytischen StÃ¤rke der Regressionsanalyse zeigt das Beispiel auch, wie glÃ¤sern Konsument:innen im Internet sind.\\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach ewtas Abwechslung. Viel Geld verdienen und Ruhm und Anerkennung sind ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehÃ¶ren, und daher den schnÃ¶den Mammon nicht so hoch schÃ¤tzen sollten. Sie entschlieÃŸen sich, Ihre hochgeschÃ¤tzten Analyse-Skills fÃ¼r etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels.\nBeim Deutschen Wetterdienst, DWD haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen resultiert ein schÃ¶ner Datensatz, den Sie jetzt analysieren wollen3:\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\nEin Data-Dictionary fÃ¼r den Datensatz kÃ¶nnen Sie hier herunterladen.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Data-Dictionary (Codebook) erklÃ¤rt einen Datensatz. Oft bedeutet das, das fÃ¼r jede Spalte der Datentabelle erklÃ¤rt wird, was die Spalte bedeutet.\\(\\square\\)\n\n\nIn TabelleÂ 10.1 und AbbildungÂ 10.2 kann man sich die Daten en Detail anschauen (Temperatur und Niederschlag im Zeitverlauf).\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celcius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlage (mm) im Verlauf der Jahre\n\n\n\n\n\nVerÃ¤nderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildungÂ 10.2: VerÃ¤nderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\n\n\n\nTabelleÂ 10.1: Wetterdaten fÃ¼r Deutschland\n\n\n\n  \n\n\n\n\n\n\nHervorragend!\nAn die Arbeit! ğŸ’ª\n\n\n10.3.1 metrische UV\n\n10.3.1.1 Modell Wetter1\nSie stellen sich nun folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ“ Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in TabelleÂ 10.2 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelleÂ 10.2: Modellparameter von lm_wetter1\n\n\n\n  \n\n\n\n\n\n\nLaut Ihrem Modell wurde es pro Jahr um 0.01 Grad wÃ¤rmer, pro Jahrzehnt also 0.1 und pro Jahrhundert 1 Grad.\n\nğŸ§‘â€ğŸ“ Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\nğŸ‘¨â€ğŸ« Mit der Ruhe, das schauen Sie sich spÃ¤ter an.\n\n\n10.3.1.2 Punkt- vs.Â BereichsschÃ¤tzung\nIn tbl-lm-wetter1 finden sich zwei Arten von Information fÃ¼r den Wert des Achsenabschnitts (b0) und des Regressionsgewichts von year(b1):\n\nPunktschÃ¤tzungen In der Spalte Coefficient sehen Sie den â€œBest-Guessâ€ fÃ¼r den entsprechenden Koeffizienten in der Population. Das is sozusagen der Wert fÃ¼r den sich das Modell festlegen wÃ¼rde, wenn es sonst nichts sagen dÃ¼rfte.\nBereichschÃ¤tzungen Cleverer als PunktschÃ¤tzungen sind BereichsschÃ¤tzungen (IntervallschÃ¤tzungen): Hier wird ein Bereich plausibler Werte fÃ¼r den entsprechenden Wert angegeben. Der â€œBereich plausibler Werteâ€ wird auch als Konfidenzintervall (engl. confidence intervall, CI) bezeichnet. Entsprechend gibt CI_low die Untergrenze des Bereichs plausibler Werte und CI_high die Obergrenze aus. So kÃ¶nnen wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschÃ¤tzt wird.\n\nğŸ’¡ Merke: Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschÃ¤tzt.\n\n10.3.1.3 Modell Wetter1a\nDas Modell lm_wetter1, bzw. die SchÃ¤tzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. AbbildungÂ 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. AbbildungÂ 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. fÃ¼r Niederschlag\n\nAuf dieser Basis erstellen wir ein neues lineares Modell, s. TabelleÂ 10.3.\n\nlm_wetter1a &lt;- lm(temp ~ year, data = wetter_summ)\nparameters(lm_wetter1a)\n\n\n\n\nTabelleÂ 10.3: Modellparameter von lm_wetter1a\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(140)\np\n\n\n\n(Intercept)\n-14.14\n2.70\n(-19.48, -8.79)\n-5.23\n&lt; .001\n\n\nyear\n0.01\n1.38e-03\n(8.86e-03, 0.01)\n8.38\n&lt; .001\n\n\n\n\n\n\n\n\nplot(estimate_relation(lm_wetter1)) \nplot(estimate_relation(lm_wetter1a))\n\n\n\n\n\n\n\n\n\n(a) Jeder Punkt ist ein Tag (viel Overplotting, wenig nÃ¼tzlich)\n\n\n\n\n\n\n\n\n\n(b) Jeder Punkt ist ein Jahr (wetter_summ)\n\n\n\n\n\n\nAbbildungÂ 10.3: Die VerÃ¤nderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD)\n\n\n\nğŸ§‘â€ğŸ“ Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der Y-Wert an der Stelle X=0, s. Kapitel 9.5.\nIn den Wetterdaten wÃ¤re Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extraplieren, ganz ohne dass wir dafÃ¼r Daten haben, s. AbbildungÂ 10.4.\n\n\n\n\n\nAbbildungÂ 10.4: Du sollst nicht ein Modell weit auÃŸerhalb seines Datenbereichs extrapolieren\n\n\nSinnvoller ist es da, z.B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezÃ¶ge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn fÃ¼r dieses Jahr haben wir Daten.\nHat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es Ã¼blich, z.B. den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten.\nSo zentriert man eine Verteilung:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist Ã¼brigens 1951:\n\nwetter %&gt;% \n  summarise(mean(year))\n\n\n  \n\n\n\nDie Steigung (d.h. der Regressionskoeffizient fÃ¼r year_c) bleibt unverÃ¤ndert, nur der Achsenabschnitt Ã¤ndert sich, s. TabelleÂ 10.4.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert)\n\n\n\n\nTabelleÂ 10.4: Modellparameter von lm_wetter1_zentriert\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n8.49\n0.04\n(8.42, 8.57)\n219.43\n&lt; .001\n\n\nyear c\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celcius. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\n\n\n\n\n\n\nReferenzwert entspricht Null\n\n\n\nDer Referenzwert bzw. der Wert der Referenzgruppe entspricht dem Y-Wert bei x=0 im Regressionsmodell.\\(\\square\\)\n\n\nWie gut erklÃ¤rt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklÃ¤rt das Modell mit year_c4 aber nicht. Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.B. die Jahreszeit eine groÃŸe Rolle fÃ¼r die Temperatur. Das haben wir nicht berÃ¼cksichtigt.\n\nğŸ§‘â€ğŸ“ Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##       1 \n## 9.65775\n\n\nğŸ§‘â€ğŸ“ Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5Â° Celcius.5\n\n\nğŸ‘¨â€ğŸ« Wir brauchen ein besseres Modell! Zum GlÃ¼ck haben wir ambitionierte Nachwuchs-Wissenschaftler:innen.\n\nDie VerÃ¤nderung der auf fÃ¼nf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in AbbildungÂ 10.5 dargestellt. Links ist eine grobe Temperatur-rasterung zu sehenR (Daten ab 1753)6; rechts eine feinere (Daten ab 1881)7.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020\n\n\n\nAbbildungÂ 10.5: \n\nBildquelle; Lizenz: GeoNutzV\n\n10.3.3 BinÃ¤re UV\n\nDefinition 10.1 (BinÃ¤re Variable) Eine binÃ¤re UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei AusprÃ¤gungen: 0 und 1.\\(\\square\\)\n\n\nBeispiel 10.3 (BinÃ¤re Variablen) Das sind zum Beispiel weiblich mit den AusprÃ¤gungen 0 (nein) und 1 (ja) oder before_1950 mit 1 fÃ¼r Jahre frÃ¼her als 1950 und 0 ansonsten.\\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ“ Ob es in der zweiten HÃ¤lfte des 20. Jahrhunderts wohl wÃ¤rmer warm, im Durchschnitt, als vorher?\\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite HÃ¤lfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Ãœberlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.4.4) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prÃ¼fe ob as Jahr grÃ¶ÃŸer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht grÃ¶ÃŸer als 1950, das dritte schon.\nJa, so kÃ¶nnte das klappen! Diese Syntax Ã¼bertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten fÃ¼r Gesamt-Deutschland\n\nScheint zu klappen!\nJetzt ein lineares Modell dazu berechnen:\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\nDie Parameter des Modells lassen darauf schlieÃŸen, dass es tatsÃ¤chlich wÃ¤rmer war nach 1950, und zwar im Schnitt offenbar ein gutes halbes Grad, s. AbbildungÂ 10.6.\n\n\n\n\n\n\nDer SchÃ¤tzbereich fÃ¼r den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied\n\n\n\n\n\nWie man sieht, Ã¼berlappen die Temperaturen dennoch betrÃ¤chtlich; aufgrund des starken Overplotting ist dieses Diagramm alles andere als ideal\n\n\n\n\n\nAbbildungÂ 10.6: Modell temp ~ after_1950\n\n\nLeider zeigt ein Blick zum r2, dass die VorhersagegÃ¼te des Modells zu wÃ¼nschen Ã¼brig lÃ¤sst8. \\(\\square\\)\n\n\n\n\n\n\nLineare Modelle verkraften nur metrische Variablen\n\n\n\nUm die Koeffizienten eines linearen Modells auszurechnen, benÃ¶tigt man eine metrische X- und eine metrische Y-Variable. Hier haben wir aber keine richtige metrische X-Variable9, sondern eine logische Variable mit den Werten TRUE und FALSE.\\(\\square\\)\n\n\nUm die X-Variable in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R fÃ¼r uns ohne viel AnkÃ¼ndigung durchfÃ¼hrt.\n\n\n\n\n\n\nHinweis\n\n\n\nHat ein nominaler PrÃ¤diktor zwei Stufen, so Ã¼berfÃ¼hrt10 lm() diese Variable in eine binÃ¤re Variable. Da eine binÃ¤re Variable metrisch ist, kann die Regression in gewohnter Weise durchgefÃ¼hrt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binÃ¤re Variable. Man beachte, dass der ursprÃ¼ngliche Datensatz nicht geÃ¤ndert wird, nur wÃ¤hrend der Analyse von lm wird die Umwandlung der Variable 11 druchgefÃ¼hrt.\\(\\square\\)\n\n\n\nğŸ¤– Eine 1 kannst du als â€œJa! Richtig!â€ verstehen und eine0 als â€œNein! Falsch!â€\n\n\nafter_1950 wird in eine Indikatorvariable umgewandelt:\n\n\n\n\n\nid\nafter_1950\n\n\n\n1\nTRUE\n\n\n2\nFALSE\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\nafter_1950TRUE\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\nBeispiel 10.5 (Beispiel: â€˜Geschlechtâ€™ in eine binÃ¤re Variable umwandeln.) Angeonmen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umgewandeln. Da â€œFrauâ€ alphabetisch vor â€œMannâ€ kommt, nimmt R â€œFrauâ€ als erste Stufe bzw. als Referenzgruppe. â€œMannâ€ ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann).\\(\\square\\)\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\nEin lineares Modell mit binÃ¤rer UV ist nichts anderes die Differenz der Gruppenmittelwerte zu berechnen:\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n  \n\n\n\nDie Interpretation eines linearen Modells mit binÃ¤rer UV veranschaulicht AbbildungÂ 10.7: Der Achsenabschnitt (b0) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (AbbildungÂ 10.7 zeigt nur die Daten fÃ¼r den Monat Juli im Bundesland Bayern, der Einfachheit und Ãœbersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildungÂ 10.7: Sinnbild zur Interpretation eines linearen Modells mit binÃ¤rer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten fÃ¼r das Modell mit binÃ¤rer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (b0)\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (b0) + Steigung der Regressionsgeraden (b1)\n\n\nFÃ¼r die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nBei nominalen (und auch bei binÃ¤ren) Variablen ist \\(\\color{beta1col}{\\beta_1}\\) ein Schalter; bei metrischen Variablen ein Dimmer.12 \\(\\square\\)\n\n\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineare Modell13 mit einer mehrstufigen14 (nominalskalierten) UV.15\n\nBeispiel 10.6 Ob es wohl substanzielle16 Temperaturunterschiede zwischen den BundeslÃ¤ndern gibt?\n\nBefragen wir dazu ein lineares Modell, s. TabelleÂ 10.5.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\nparameters(lm_wetter_region)\n\n\n\n\nTabelleÂ 10.5: Modellparameter fÃ¼r lm_wetter_region\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27152)\np\n\n\n\n(Intercept)\n8.25\n0.16\n(7.93, 8.56)\n51.62\n&lt; .001\n\n\nregion (Bayern)\n-0.63\n0.23\n(-1.07, -0.19)\n-2.79\n0.005\n\n\nregion (Brandenburg)\n0.57\n0.23\n(0.13, 1.02)\n2.53\n0.011\n\n\nregion (Brandenburg/Berlin)\n0.58\n0.23\n(0.14, 1.03)\n2.59\n0.010\n\n\nregion (Hessen)\n0.11\n0.23\n(-0.33, 0.56)\n0.51\n0.612\n\n\nregion (Mecklenburg-Vorpommern)\n0.08\n0.23\n(-0.37, 0.52)\n0.34\n0.732\n\n\nregion (Niedersachsen)\n0.52\n0.23\n(0.07, 0.96)\n2.29\n0.022\n\n\nregion (Niedersachsen/Hamburg/Bremen)\n0.52\n0.23\n(0.08, 0.96)\n2.31\n0.021\n\n\nregion (Nordrhein-Westfalen)\n0.80\n0.23\n(0.35, 1.24)\n3.53\n&lt; .001\n\n\nregion (Rheinland-Pfalz)\n0.46\n0.23\n(0.02, 0.90)\n2.03\n0.042\n\n\nregion (Saarland)\n0.71\n0.23\n(0.27, 1.16)\n3.16\n0.002\n\n\nregion (Sachsen)\n-0.04\n0.23\n(-0.48, 0.40)\n-0.18\n0.853\n\n\nregion (Sachsen-Anhalt)\n0.55\n0.23\n(0.11, 1.00)\n2.45\n0.014\n\n\nregion (Schleswig-Holstein)\n0.17\n0.23\n(-0.27, 0.62)\n0.76\n0.446\n\n\nregion (Thueringen)\n-0.48\n0.23\n(-0.92, -0.03)\n-2.11\n0.035\n\n\nregion (Thueringen/Sachsen-Anhalt)\n0.10\n0.23\n(-0.34, 0.54)\n0.43\n0.664\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariablen um. Genauer gesagt ist es immer eine Indikatorvariablen weniger als es Stufen in der nominalskalierten Variablen gibt.\n\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland (aus GrÃ¼nden der Einfachheit hier nur mit 3 BundeslÃ¤ndern). Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt:\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWÃ¼\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\nAuch im Fall mehrerer AusprÃ¤gungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binÃ¤ren Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 1. Regressionsgeraden (b1)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 2. Regressionsgeraden (b2)\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts ausgewÃ¤hlt wurde) nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.\n\n\n\n\n\n\nHinweis\n\n\n\nBei einer Variable vom Typ character wÃ¤hlt R den alphabetisch ersten Wert als Referenzgruppe fÃ¼r ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. \\(\\square\\)\n\n\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-WÃ¼rttemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewÃ¤hlt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird.\\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. AbbildungÂ 10.8.\n\n\n\n\n\n\n\nAbbildungÂ 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). Die Achsen wurden um 90Â° gedreht, damit man die Namen der BundeslÃ¤nder besser lessen kann.\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht auÃŸer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechnen!\n\nğŸ¤– Endlich gehtâ€™s weiter! Ergebnisse in TabelleÂ 10.6! \\(\\square\\)\n\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelleÂ 10.6: Modellparameter fÃ¼r lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschied im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. AbbildungÂ 10.9, links.17 Oh nein: R betrachtet month als numerische Variable! Aber â€œMonatâ€ bzw. â€œJahreszeitâ€ sollte nominal sein.\n\nğŸ¤– Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\nğŸ‘© Okay, R, wir mÃ¼ssen month in eine nominale Zahl transformieren. Wie geht das?\n\n\nğŸ¤– Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heiÃŸt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau.\\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. TabelleÂ 10.7.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor)\n\n\n\n\nTabelleÂ 10.7: Modellparameter von lm_wetter_month_factor\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27156)\np\n\n\n\n(Intercept)\n56.95\n0.64\n(55.68, 58.21)\n88.56\n&lt; .001\n\n\nmonth factor (2)\n-9.95\n0.91\n(-11.73, -8.17)\n-10.94\n&lt; .001\n\n\nmonth factor (3)\n-7.78\n0.91\n(-9.56, -6.00)\n-8.56\n&lt; .001\n\n\nmonth factor (4)\n-8.49\n0.91\n(-10.27, -6.71)\n-9.34\n&lt; .001\n\n\nmonth factor (5)\n4.74\n0.91\n(2.96, 6.53)\n5.22\n&lt; .001\n\n\nmonth factor (6)\n14.34\n0.91\n(12.56, 16.12)\n15.77\n&lt; .001\n\n\nmonth factor (7)\n24.36\n0.91\n(22.57, 26.14)\n26.74\n&lt; .001\n\n\nmonth factor (8)\n17.52\n0.91\n(15.74, 19.31)\n19.24\n&lt; .001\n\n\nmonth factor (9)\n1.93\n0.91\n(0.15, 3.72)\n2.12\n0.034\n\n\nmonth factor (10)\n2.29\n0.91\n(0.51, 4.08)\n2.52\n0.012\n\n\nmonth factor (11)\n0.89\n0.91\n(-0.89, 2.68)\n0.98\n0.327\n\n\nmonth factor (12)\n5.20\n0.91\n(3.42, 6.99)\n5.71\n&lt; .001\n\n\n\n\n\n\n\n\nSehr schÃ¶n! Jetzt haben wir eine Referenzgruppe (Monat 1, d.h. Januar) und 11 Unterschiede zum Januar, s. AbbildungÂ 10.9, rechts.\n\n\n\n\n\n\nlm_wetter_month, Monat fÃ¤lschlich als metrische Variable\n\n\n\n\n\nlm_wetter_month_text, Monat korrekt als nominale Variable (aber mit viel Overplotting, das mÃ¼sste man besser machen)\n\n\n\n\n\nAbbildungÂ 10.9: Niederschlagsunterschiede pro Monat (ein Punkt ist ein Jahr); aufgrund der vielen Datenpunkte ist das Diagramm wenig Ã¼bersichtlich (Overplotting).\n\n\nMÃ¶chte man die Referenzgruppe eines Faktors Ã¤ndern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geÃ¤nderte Reihenfolge aus:18:\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 BinÃ¤re plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binÃ¤ren) UV plus einer metrischen UV.19\n\nBeispiel 10.12 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\nğŸ‘¨â€ğŸ« Ich muss mal kurz auf eine Sache hinweisenâ€¦\n\n\n\n\n\n\n\nFaktorvariable\n\n\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich fÃ¼r nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten AusprÃ¤gungen (â€œFaktorstufenâ€) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht.\nDas kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche AusprÃ¤gungen in Ihrer Variable mÃ¶glich sind.\\(\\square\\)\n\n\n\nBeispiel 10.10 (Beispiel fÃ¼r eine Faktorvariable) Â \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\n\nBeispiel 10.11 (Filtern verÃ¤ndert die Faktorstufen nicht) Wenn Sie von der Faktorvariablen20 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.B. nur die ersten beiden Elemente Ã¼brig bleiben mit allein der AusprÃ¤gung \"f\", merkt sich R trotzdem, dass es zwei Faktorstufen gibt (\"f\" und \"m\").\nGenaus so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. MÃ¶chten Sie die herausgefilterten Faktorstufen â€œlÃ¶schenâ€, so kÃ¶nnen Sie einfach die Faktorvariable neu berechnen (mit factor).\\(\\square\\)\n\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  mutate(month_factor = factor(month))  # Faktor (und damit die Faktorstufen) neu berechnen\n\nOkay. Wie spezifiziert man jetzt das lineare Modell?\\(\\square\\)\n\nHat man mehrere (â€œmultipleâ€) X-Variablen21, so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.B. temp ~ year_c + month.\n\n\n\n\n\n\nMultiple Regression\n\n\n\nEine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y ~ x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\n\nDie VerÃ¤nderung der monatlichen Temperatur (10-Jahres-Mittel) ist in AbbildungÂ 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schÃ¶ner aus).\n\n\n\n\n\n\nModellgleichung\n\n\n\nDas Pluszeichen hat in der Modellgleichung22 keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur â€œund noch folgende UVâ€¦â€.\\(\\square\\)\n\n\nDie obige Modellgleichung liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, data = wetter_month_1_7)\n\nDie Modellparameter sind in TabelleÂ 10.8 zu sehen.\n\n\n\nTabelleÂ 10.8: Modellparameter von lm_year_month\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4525)\np\n\n\n\n(Intercept)\n56.94\n0.68\n(55.60, 58.27)\n83.57\n&lt; .001\n\n\nyear c\n0.03\n0.01\n(5.59e-03, 0.05)\n2.43\n0.015\n\n\nmonth factor (7)\n24.37\n0.97\n(22.48, 26.27)\n25.25\n&lt; .001\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (b0, (Intercept)): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57 mm pro Quadratmeter.\nRegressionskoeffizient fÃ¼r Jahr (b1, year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.02 mm an (im Referenzmonat).\nRegressionskoeffizient fÃ¼r Monat (b2, month [7]) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25 mm Ã¼ber dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7.\nIm Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0.\n\nğŸ§‘â€ğŸ“ Puh, kompliziert!\n\n\nğŸ‘¨â€ğŸ« Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. BeispielÂ 10.13.\n\n\nBeispiel 10.13 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag fÃ¼r Januar im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"1\"))\npredict(lm_year_month, newdata = neue_daten)\n##        1 \n## 58.92171\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nAlle Regressionskoeffizienten beziehen sich auf den Y-Wert unter der Annahme, dass alle Ã¼brigen PrÃ¤diktoren den Wert Null (bzw. Referenzwert) aufweisen.\\(\\square\\)\n\n\nVisualisieren wir uns die geschÃ¤tzten Erwartungswert pro PrÃ¤diktorwert, s. AbbildungÂ 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildungÂ 10.10: Temperaturverlauf Ã¼ber die Jahre fÃ¼r zwei Monate. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von (Okabe & Ito, 2023) ersetzt (s. Hinweise hier). Das ist nicht unbedingt nÃ¶tig, aber robuster bei Schwarz-WeiÃŸ-Druck und bei SehschwÃ¤chen, vgl. Kapitel 5.9.3.\nDie erklÃ¤rte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht wÃ¼rden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dÃ¼rfen?\nNicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. AbbildungÂ 10.11.\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\nplot(estimate_expectation(lm_year_month_interaktion)) +\n  scale_color_okabeito()  # schÃ¶nes Farbschema\n\n\n\n\n\n\nAbbildungÂ 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die VerÃ¤nderung im Verlauf der Jahre ist unterschiedlich fÃ¼r die Monate (Janur vs.Â Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator : fÃ¼gt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\n\n\n\n\n\nWichtig\n\n\n\nEinen Interaktionseffekt von x1 und x2 kennzeichnet man mit dem Doppelpunkt-Operator:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\n\nIn Worten:\n\nâ€œy wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.â€\n\nWie man in AbbildungÂ 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel.\n\n\n\n\n\n\nHinweis\n\n\n\nSind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor.\\(\\square\\)\n\n\n\nBeispiel 10.14 (Interaktionseffekt von Niederschlag und Monat) Wie ist die VerÃ¤nderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich fÃ¼r die Monate: Im Juli nahm der Niederschlag ab, im Januar zu.\\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von â€œdemâ€ (statistischen) Effekt eines PrÃ¤diktors (afu die Y-Variable) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.B. Monat) unterscheidet der Effekt.23\nBetrachten wir die Parameterwerte des Interaktionsmodells (parameters(lm_year_month_interaktion)), s. TabelleÂ 10.9.\n\n\n\nTabelleÂ 10.9: Modellparameter von lm_year_month_interaktion\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4524)\np\n\n\n\n(Intercept)\n56.91\n0.68\n(55.59, 58.24)\n84.21\n&lt; .001\n\n\nyear c\n0.13\n0.02\n(0.10, 0.16)\n7.80\n&lt; .001\n\n\nmonth factor (7)\n24.37\n0.96\n(22.50, 26.25)\n25.45\n&lt; .001\n\n\nyear c Ã— month factor (7)\n-0.20\n0.02\n(-0.25, -0.16)\n-8.62\n&lt; .001\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die Zeile year c Ã— month factor [7]. Sie gibt die StÃ¤rke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre Ã¤ndert: Im Monat \"7\" ist der Effekt von year_c um 0.20 mm geringer: Die Regressionsgerade neigt sich mehr nach â€œuntenâ€ im Monat Juli, da der Koeffizient kleiner als Null ist.\nDie Regressionsgleichung lautet: precip_pred = 56.91 + 0.13*year_c + 24.37*month_factor_7 - 0.20*year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert fÃ¼r Y an unter der Annahme, dass alle PrÃ¤diktoren den Wert Null aufweisen. In diesem Fall gibt der Achsenabschnitt also den Niederschlag fÃ¼r den Janur des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in Y an, wenn der jeweilige PrÃ¤diktorwert um 1 steigt, die Ã¼brigen PrÃ¤diktoren aber den Wert 0 aufweisen.\\(\\square\\)\n\n\nDas R-Quadrat von lm_year_month_interaktion betrÃ¤gt Ã¼brigens:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. AbbildungÂ 10.12. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n3D-Animation\nInteraktives 3D-Diagramm\n2D-Diagramm fÃ¼r 3D-Modell\n\n\n\n\n\nAnimation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklÃ¤rt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.12\n\n\nGrundsÃ¤tzlich kann man viele PrÃ¤diktoren in ein (lineares) Modell aufnehmen.\nBetrachten wir z.â€‰B. folgendes lineares Modell mit zwei metrischen UV.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.13: Lineares Modell mit 2 metrischen UV (und 1 metrische AV)\n\n\n\nJedes der beiden Regressionsgewichte in lm_mario_2uv entspricht der Steigung in der beiden Achsen in AbbildungÂ 10.13, d.h. die Steigung fÃ¼r start_pr bzw. die Steigung fÃ¼r ship_pr.\n\n10.4.2 Viele UV ins Modell?\nWir kÃ¶nnten im Prinzip alle Variablen unserer Datentabelle als PrÃ¤diktoren in das Regressionsmodell aufnehmen. Die Frage ist nur: macht es Sinn?\nHier sind einige Richtlinien, die helfen, welche PrÃ¤diktoren (und wie viele) man in ein Modell aufnehmen sollte (Gelman et al., 2021a, S. 199f):\n\nMan sollte alle PrÃ¤diktoren aufnehmen, von denen anzunehmen ist, dass Sie Ursachen fÃ¼r die Zielvariablen sind\nBei PrÃ¤diktoren mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen\nPrÃ¤diktoren mit kleinem SchÃ¤tzbereich (95 CI) sollten tendenziell im Modell belassen werden, da sie die ModellgÃ¼te verbessern",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.15 (Prognose des Verkaufspreis) Ganz kÃ¶nnen Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen mÃ¶glichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld.\\(\\square\\)\n\n\n10.5.1 Modell â€œall-inâ€\nUm die GÃ¼te Ihrer Vorhersagen zu prÃ¼fen, teilt Ihr Chef den Datensatz in zwei zufÃ¤llige Teile.\n\nğŸ§”â€â™‚ï¸ Ich teile den Datensatz mariokart zufÃ¤llig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (â€œtrainierenâ€) und ihre GÃ¼te zu prÃ¼fen. Den Teil nenne ich â€œTrainingssampleâ€, hÃ¶rt sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die GÃ¼te deiner Vorhersagen in dem verbleibenden Teil, die Ã¼brigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten auf Ihrer Festplatte liegen, z.B. im Unterordner daten, dann kÃ¶nne Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"daten/mariokart_train.csv\")\n\nAlternativ kÃ¶nnen Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die â€œAll-in-Strategieâ€: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.979\n\nDer Punkt in total_pr ~ . heiÃŸt â€œalle Variablen in der Tabelle (auÃŸer total_pr)â€.\n\nğŸ§”â€â™‚ï¸ Hey! Das ist ja fast perfekte ModellgÃ¼te!\n\n\nğŸ¦¹â€â™€ï¸ Vorsicht: Wenn ein Angebot aussieht wie â€œtoo good to be trueâ€, dann ist es meist auch too good to be true.\n\n\n\n\n\n\n\nOverfitting\n\n\n\nDer Grund fÃ¼r den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. WeiÃŸ man, welcher Titel zu welcher Auktion gehÃ¶rt, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nÃ¼tzen die Titel der Auktionen im Train-Sample nichts fÃ¼r andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stÃ¼tzen. Merke: HÃ¶chst idiografische Informationen wie Namen, Titel etc. sind nicht nÃ¼tzlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\\(\\square\\)\n\n\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in eval(predvars, data, env): object 'V1' not found\n\nOh nein! Was ist los!? Eine Fehlermeldung!\n\n\n\n\n\n\nVorsicht\n\n\n\nNominalskalierte PrÃ¤diktorvariablen mit vielen AusprÃ¤gungen, wie title sind problematisch. Kommt eine AusprÃ¤gung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. HÃ¤ufig ist es sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting fÃ¼hren.\\(\\square\\)\n\n\n\n10.5.2 Modell â€œall-inâ€, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. NÃ¤chster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, V1, id))\n\nWir entfernen auch die Spalte V1 und id, da sie ebenfalls keine Informatione bergen.\n\nlm_allin_no_title &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist ja durchaus ordentlich. Schauen wir uns noch den rmse (die SD der Vorhersagefehler) an24:\n\nğŸ¤– Gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title)\n## [1] 20.22998\n\n\n\n\n\n\n\nName Clash\n\n\n\nIm Paket yardstick gibt es eine Funktion namens rmse und im Paket performance, Teil des Meta-Pakets easystats ebenfalls. Da sind Probleme vorprogrammiert. Das ist so als wÃ¼rde die Lehrerin rufen: â€œSchorsch, komm her!â€. Dabei gibt es zwei Schorsche in der Klasse: Den MÃ¼llers Schorsch und den Meiers Schorsch. Sonst kommen beide, was die Lehrerin nicht will. Die Lehrerin mÃ¼sste also rufen: â€œMÃ¼ller Schorsch, komm her!â€. Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den â€œNachnamenâ€ des Befehls: paketname::funktion ist wie MÃ¼ller::Schorsch. In unserem Fall also: performance::rmse Endlich weiÃŸ R wieder, was zu tun ist!\\(\\square\\)\n\n\nSie rennen zu Ihrem Chef, der jetzt die GÃ¼te Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\nğŸ§”â€â™‚ï¸ Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das â€œTest-Sampleâ€.\n\nIhr Chef schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n  \n\n\n\n\nğŸ§”â€â™‚ï¸ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nHier sind Ihre Vorhersagen25:\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title, newdata = mariokart_test)\n\nHier sind Ihre ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##        1        2        3        4        5        6 \n## 28.62826 53.85885 53.28035 54.03619 41.75512 46.57713\n\nDies Vorhersagen fÃ¼gen wir noch der Ordnung halber in die Tabelle mit den Test-Daten:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title, newdata = mariokart_test))\n\nOkay, was ist jetzt der mittlere Vorhersagefehler?\nUm die VorhersagegÃ¼te im Test-Sample auszurechnen26, nutzen wir die Funktionen des R-Paketes yardstick27:\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\n\nIhr mittlerer Vorhersagefehler (MAE) liegt bei ca. 13 Euro.28\n\nğŸ§”â€â™‚ï¸ Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\n\n\nğŸ§”â€â™‚ï¸ 17%, nicht berauschend, aber immerhin!\n\n\n\n\n\n\n\nModellgÃ¼te im Test-Sample meist geringer als im Train-Sample\n\n\n\nWie das Beispiel zeigt, ist die ModellgÃ¼te im Test-Sample (leider) oft geringer als im Train-Sample. Die ModellgÃ¼te im Train-Sample ist mitunter Ã¼bermÃ¤ÃŸig optimistisch. Dieses PhÃ¤nomen bezeichnet man als Overfitting.\\(\\square\\)\n\n\n\n\n\n\n\n\nTipp\n\n\n\nBevor man Vorhersagen eines Modells einreicht, bietet es sich, die ModellgÃ¼te in einem neuen Datensatz, als einem Test-Sample, zu Ã¼berprÃ¼fen.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste SchÃ¤tzung der GÃ¼te Ihres Modells erfahren mÃ¶chten, bietet sich folgendes Vorgehen an (vgl. AbbildungÂ 10.14):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrÃ¼fen Sie die ModellgÃ¼te im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie kÃ¶nnen sie z.B. so bewerkstelligen:\n\nlibrary(rsample)\nmariokart &lt;- read_csv(\"daten/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"daten\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split bestimmt fÃ¼r jede Zeile (Beobachtung) zufÃ¤llig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt29; das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafÃ¼r, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wÃ¤re nÃ¤mlich blÃ¶d fÃ¼r Ihr Modell, wenn im Train-Sample z.B. nur die teuren, und im Test-Sample nur die gÃ¼nstigen Spiele landen wÃ¼rde.30 In so einem Fall wÃ¼rde sich Ihr Modell unnÃ¶tig schwer tun.\nIm nÃ¤chsten Schritt kÃ¶nnen Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsÃ¤chlich aufteilen.31\n\nmariokart_train &lt;- training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- testing(meine_aufteilung)  # Assessment-Sample\n\nIch persÃ¶nliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kÃ¼rzer zu tippen und einheitlich. Sie kÃ¶nnen aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, auÃŸerdem KÃ¼rze und aussagekrÃ¤ftige Namen.\n\n10.6.2 Train- vs.Â Test-Sample\n\nDefinition 10.2 (Train-Sample) Den Datensatz, fÃ¼r die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\nDas Train-Sample stellt die bekannten Daten dar; aus denen kÃ¶nnen wir lernen, d.h. unser Modell berechnen.\n\nDefinition 10.3 (Test-Sample) Den Datensatz, fÃ¼r den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\nDas Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiÃŸ, was der Wert der AV ist.\nDer Zusammenhang dieser verschiedenen, aber zusammengehÃ¶rigen Arten von Stichproben ist in AbbildungÂ 10.14 dargestellt.\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildungÂ 10.14: Verschiedene Arten von zusammengehÃ¶rigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden â€œabwanderungsgefÃ¤hrdetâ€ sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (â€œcustomer churnâ€). Es gibt eine ganze Reihe von Untersuchungen dazu, z.B. die von Lalwani et al. (2022). Die Forschis versuchen anhand von Daten und u.a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von Ã¼ber 80% in Ihrem (besten) Vorhersagemodell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lÃ¼gt",
    "text": "10.8 Wie man mit Statistik lÃ¼gt\n\n10.8.1 Pinguine drehen durch\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von SchnabellÃ¤nge (bill length) und Schnabeltiefe (bill depth) interessiert, s. AbbildungÂ 10.15.\n\n\n\n\n\nAbbildungÂ 10.15: SchnabellÃ¤nge und Schnabeltiefe\n\n\nDas Team hat in schweiÃŸtreibender eiszapfentreibender Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und Ã¼berlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von SchnabellÃ¤nge und Schnabeltiefe. Das kÃ¶nnte einen Nobelpreis wert sein. Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")\n\n\n\n\n\n\n\nHier sind die statistischen Details, s. TabelleÂ 10.10.\n\nlm1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelleÂ 10.10: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(340)\np\n\n\n\n(Intercept)\n20.89\n0.84\n(19.23, 22.55)\n24.75\n&lt; .001\n\n\nbill length mm\n-0.09\n0.02\n(-0.12, -0.05)\n-4.46\n&lt; .001\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf verÃ¶ffentlicht eine verfeindete Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von SchnabelllÃ¤nge und Schnabeltiefe.\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\", color = \"species\")\n\n\n\n\n\n\n\nOh nein! Was ist hier nur los? Daten lÃ¼gen nicht, oder doch?\nHier sind die statistischen Details der zweiten Analyse, s. TabelleÂ 10.11. Im zweiten Modell kam species als zweiter PrÃ¤diktor neu ins Modell (zusÃ¤tlich zur SchnabellÃ¤nge).\n\nlm2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelleÂ 10.11: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(338)\np\n\n\n\n(Intercept)\n10.59\n0.68\n(9.25, 11.94)\n15.51\n&lt; .001\n\n\nbill length mm\n0.20\n0.02\n(0.17, 0.23)\n11.43\n&lt; .001\n\n\nspecies (Chinstrap)\n-1.93\n0.22\n(-2.37, -1.49)\n-8.62\n&lt; .001\n\n\nspecies (Gentoo)\n-5.11\n0.19\n(-5.48, -4.73)\n-26.67\n&lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaten alleine reichen nicht\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse - Gesamtdaten oder Subgruppen - die richtige ist. Nicht-exprimentelle Studien kÃ¶nnen zu grundverschiedenen Ergebnissen fÃ¼hren, jenachdem ob PrÃ¤diktoren dem Modell hinzugefÃ¼gt oder weggenommen werden. \\(\\square\\)\n\n\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere nie Modellkoeffizienten ohne ein Kausalmodell.\\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lÃ¤sst man besser die Finger von der Interpretation der Modellkoeffizienten und begnÃ¼gt sich mit der Beschreibung der ModellgÃ¼te und mit Vorhersage32. Wer das nicht glaubt, der betrachte AbbildungÂ 10.16, links.33 Ei Forschi stellt das Modell m1: y ~ x auf und interpretiert dann b1: â€œIst ja klar, X hat einen starken positiven Effekt auf Y!â€.\nIn der nÃ¤chsten Studie nimmt dis Forschi dann eine zweite Variable, group (z.B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. AbbildungÂ 10.16, rechts!\nDieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt â€œechtâ€, also kausal, ist. Handelt es sich aber um â€œnicht echteâ€, also nicht-kausale ZusammenhÃ¤nge, um ScheinzusammenhÃ¤nge also, so kÃ¶nnen sich die Modellkoeffizienten dramatisch verÃ¤ndern (sogar das Vorzeichen kann wechseln34), wenn man das Modell verÃ¤ndert, also Variablen hinzufÃ¼gt oder wegnimmt.\nWenn man die kausalen AbhÃ¤ngigkeiten nicht kennt, weiÃŸ man also nicht, ob die ZusammenhÃ¤nge kausal oder nicht-kausal sind. Man weiÃŸ also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker Zusammenhang; b1 ist stark positiv\n\n\n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, in jeder der beiden Gruppen ist der Zusammenhang praktisch Null, b1 = 0\n\n\n\n\n\n\nAbbildungÂ 10.16: FÃ¼gt man in ein Modell eine Variable hinzu, kÃ¶nnen sich die Koeffizienten massiv Ã¤ndern. In beiden Diagrammen wurden die gleichen Daten verwendet.\n\n\nMan kÃ¶nnte hÃ¶chstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.B. â€œDort wo es viele StÃ¶rche gibt, gibt es auch viele Babiesâ€.35 Leider ist unser Gehirn auf kausale ZusammenhÃ¤nge geprÃ¤gt: Es fÃ¤llt uns schwer, ZusammenhÃ¤nge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulÃ¤ssig kausal interpretiert - von Laien und Wissenschaftlern auch.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fazit",
    "href": "090-regression2.html#fazit",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.9 Fazit",
    "text": "10.9 Fazit\nIn diesem Kapitel haben Sie lineare Modelle gelernt, die Ã¼ber einfache Modelle der Art y ~ x hinausgehen. Dazu gehÃ¶ren multiple Modelle, das sind Modelle mit mehr als einer UV (PrÃ¤diktor) und auch Interaktionsmodelle. AuÃŸerdem haben Sie sich mit einem Datensatz von gesamtgesellschaftlichen Nutzen beschÃ¤ftigt - sehr schÃ¶n. Das Fallbeispiel zum Schluss war vielleicht erhellend insofern, als dass ein gutes Modell im Train-Sample nicht (notwendig) zu guten Vorhersagen im Test-Sample fÃ¼hrt.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. AbbildungÂ 10.17. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) So ging es Ihnen gestern\n\n\n\n\n\n\n\n\n\n(b) So wird es Ihnen morgen ergehen, wenn Sie dran bleiben\n\n\n\n\n\n\nAbbildungÂ 10.17: Statistik, Sie und Party: Gestern und (vielleicht) morgen.\n\n\nQuelle: imgflip",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausfÃ¼hrlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker FlugverspÃ¤tungen\n\nSource\nVorhersage von FlugverspÃ¤tungen\n\n10.10.2 FilmerlÃ¶se\nVorhersagen von FilmerlÃ¶sen",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklÃ¤rt die lineare Regression mit Hilfe von Drachen. ğŸ‰ Sehenswert.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nWenn es ein Standardwerk fÃ¼r Regressionsanalyse geben kÃ¶nnte, dann vielleicht das neueste Buch von Andrew Gelman, einer der bekanntesten Statistiker (Gelman et al., 2021b). Sein Buch ist fÃ¼r Sozialwissenschaftler geschrieben, also nicht fÃ¼r typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literatur",
    "href": "090-regression2.html#literatur",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.14 Literatur",
    "text": "10.14 Literatur\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021a). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021b). Regression and Other Stories. Cambridge University Press.\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private Traits and Attributes Are Predictable from Digital Records of Human Behavior. Proceedings of the National Academy of Sciences, 110(15), 5802â€“5805. https://doi.org/10.1073/pnas.1218772110\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing. Archives for Scientific Computing, 104(2), 271â€“294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "Lizenzhinweis: Datenbasis: Deutscher Wetterdienst, eigene Elemente ergÃ¤nzt.â†©ï¸\nsynonym: Regressionsanalysenâ†©ï¸\nTemperatur: Grad Celcius, Niederschlag (precip) mm Niederschlag pro Quadratmeterâ†©ï¸\nyear und year_c sind gleich stark mit temp korreliert, daher wird sich die ModellgÃ¼te nicht unterscheiden.â†©ï¸\nQuelle: Umweltbundesamtâ†©ï¸\nQuelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3â†©ï¸\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/â†©ï¸\nr2(lm_wetter_bin_uv)â†©ï¸\nUVâ†©ï¸\nsynonym: transformiertâ†©ï¸\nTransformationâ†©ï¸\nIch danke Karsten LÃ¼bke fÃ¼r diese Idee.â†©ï¸\nfÃ¼r uns synonym: Regressionsmodellâ†©ï¸\ndrei oder mehr Stufen bzw. AusprÃ¤gungenâ†©ï¸\nSo ein Modell ist von den Ergebnissen her praktisch identisch zu einer einfachen Varianzanalyse.â†©ï¸\nwie kÃ¶nnte man dieses Wort eigentlich definieren?â†©ï¸\nplot(estimate_expectation(lm_wetter_month)â†©ï¸\nZum Dollar-Operator s. Kapitel 3.9.2â†©ï¸\nSo ein Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ancova) bezeichnet werden.â†©ï¸\nsynonym: nominalskalierte Variableâ†©ï¸\nPrÃ¤diktoren, unabhÃ¤ngige Variablen, X-Variablenâ†©ï¸\nsynonym: Regressionsformelâ†©ï¸\nEffekt ist hier immer statistisch, nie kausal gemeint.â†©ï¸\nder Befehl wohnt im Paket performance, Teil des Metapakets easystatsâ†©ï¸\nengl. predictions; to predict: vorhersagenâ†©ï¸\nwir verwenden dazu die Funktionen mae und rsqâ†©ï¸\nwelches Sie vielleicht noch installieren mÃ¼ssen.â†©ï¸\nWir haben hier yardstick::mae geschrieben und nicht nur mae, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens mae gibt. Name-Clash-Alarm! R kÃ¶nnte daher den anderen mae meinen als Sie, was garantiert zu Verwirrung fÃ¼hrt. Entweder bei R oder bei Ihnen.â†©ï¸\nvgl. help(initial_split)â†©ï¸\nAnderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B.â†©ï¸\ninitial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgefÃ¼hrt.â†©ï¸\nsynonym: Prognoseâ†©ï¸\nQuelleâ†©ï¸\ndas nennt man dann Simpsons Paradoxâ†©ï¸\nDas StÃ¶rche-Babies-Beispiel passt auch zu AbbildungÂ 10.16.â†©ï¸",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html",
    "href": "100-abschluss.html",
    "title": "\n11Â  Abschluss\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#lernsteuerung",
    "href": "100-abschluss.html#lernsteuerung",
    "title": "\n11Â  Abschluss\n",
    "section": "",
    "text": "11.1.1 Standort im Lernpfad\nAbb. AbbildungÂ 1.2 den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel.\n\n11.1.2 Lernziele\nkein neuer Stoff\nZiel dieses Kapitels ist es, den Stoff des Moduls zu wiederholen und zu konsolidieren.\n\n11.1.3 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n11.1.4 BenÃ¶tigte Daten\n\n\ndata(mtcars)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#herzlichen-glÃ¼ckwÃ¼nsch",
    "href": "100-abschluss.html#herzlichen-glÃ¼ckwÃ¼nsch",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.2 Herzlichen GlÃ¼ckwÃ¼nsch!",
    "text": "11.2 Herzlichen GlÃ¼ckwÃ¼nsch!\n\nHerzlichen GlÃ¼ckwunsch - Sie haben diesen Kurs abgeschlossen! Es sei denn, Sie haben nur ein bisschen durchgeschaut. Dann war es hoffentlich zumindest interessant. ğŸ˜„",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#wie-gehts-weiter",
    "href": "100-abschluss.html#wie-gehts-weiter",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.3 Wie gehtâ€™s weiter?",
    "text": "11.3 Wie gehtâ€™s weiter?\nEs gibt viele weiterfÃ¼hrende BÃ¼cher und Kurse. Ein logischer nÃ¤chster Schritt ist es, sich mit Inferenzstatistik zu beschÃ¤ftigen. Dazu bietet sich z.B. der Kurs Start:Bayes! an, zufÃ¤lligerweise aus der Feder des gleichen Autorsâ€¦\nWenn Sie sich breiter (nicht tiefer) mit Data Literacy beschÃ¤ftigen wollen, bietet sich der Online-Kurs des KI-Campus an. Es gibt viele Online-Kurse, die sich anbieten, wenn Sie im Thema moderne Datenanalyse fit werden wollen. Schauen Sie doch mal z.B. bei Coursera oder Ã¤hnlichen Anbietern vorbei.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#aufgabensammlungen",
    "href": "100-abschluss.html#aufgabensammlungen",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.4 Aufgabensammlungen",
    "text": "11.4 Aufgabensammlungen\nAuf dem Datenwerk finden Sie reichlich Aufgaben zur PrÃ¼fungsvorbereitung.\nU.a. folgende Tags sind fÃ¼r diesen Kurs relevant:\n\nR\nassociation\ndatawrangling\ndplyr\nlagemaÃŸe\nstreuungsmaÃŸ\nvariablelevles\nyacsda",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#quizze",
    "href": "100-abschluss.html#quizze",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.5 Quizze",
    "text": "11.5 Quizze\nHier gehtâ€™s zu einem Quiz zur deskriptiven Statistik (MaÃŸe der zentralen Tendenz, VariabilitÃ¤t, Verteilungsformen, Normalverteilung, Korrelation).\nHier gehtâ€™s zu einem Quiz zum Thema Verteilungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#fallstudien",
    "href": "100-abschluss.html#fallstudien",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.6 Fallstudien",
    "text": "11.6 Fallstudien\n\n11.6.1 Datenvisualisierung\nFallstudien â€“ NUR Datenvisualisierung\n\nvis-gapminder\nvis-penguins\nvis-mtcars\nAufgabe zur Datenvisualisierung des Diamantenpreises\n\n11.6.2 Explorative Datenanalyse\nFALLSTUDIEN - NUR EXPLORATIVE DATENANALYSE\n\nLouise E. Sinks: TidyTuesday Week 18: Portal Project\nLouise E. Sinks: TidyTuesday Week 17: London Marathon\nLouise E. Sinks: TidyTuesday Week 16: Neolithic Founder Crops\nDatenjudo mit Pinguinen\nData-Wrangling-Aufgaben zur Lebenserwartung\nCase study: data vizualization on flight delays using tidyverse tools\nFallstudie FlugverspÃ¤tungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten FlugverspÃ¤tungen, Datensatz â€˜nycflights13â€™\nCleaning and visualizing genomic data: a case study in tidy analysis\nTidyverse Case Study: Exploring the Billboard Charts\nAnalyse einiger RKI-Coronadaten: Eine reproduzierbare Fallstudie\nOpenCaseStudies - Health Expenditure\nOpen Case Studies: School Shootings in the United States - includes dashboards\nOpen Case Studies: Disparities in Youth Disconnection\nYACSDA SeitensprÃ¼nge\nThe Open Case Study Search provides a nice collection of helpful case studies.\nifes@FOM Fallstudienseite\n\n11.6.3 Lineare Modelle\nFALLSTUDIEN - NUR LINEARE MODELLE\n\nBeispiel fÃ¼r Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel fÃ¼r Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel fÃ¼r Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von FlugverspÃ¤tungen\nModelling movie successes: linear regression\nMovies\nFallstudie Einfache lineare Regression in Base-R, AnfÃ¤ngerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\nFallstudie zum Beitrag verschiedener Werbeformate zum Umsatz; eine Fallstudie in Python, aber mit etwas Erfahrung wird man den Code einfach in R umsetzen kÃ¶nnen (wenn man nicht in Python schreiben will)\nPractical Linear Regression with R: A case study on diamond prices\nCase Study: Italian restaurants in NYC\nVorhersage-Modellierung des Preises von Diamanten\nModellierung Diamantenpreis 2",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#faq",
    "href": "100-abschluss.html#faq",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.7 FAQ",
    "text": "11.7 FAQ\nWerfen Sie auch einen Blick in typische R-Fragen.\n\n11.7.1 SD berechnen\nFRAGE: Macht es einen Unterschied, ob man dafÃ¼r den Befehlt summary() oder den Befehl sd() verwendet? Bei mir kommen da nÃ¤mlich unterschiedliche Zahlen raus.\nANTWORT: summary() gibt nicht SD aus, sondern nur den IQR (IQR = Q3-Q3).\n\ndata(mtcars)\nsd(mtcars$mpg)\n## [1] 6.026948\nsummary(mtcars$mpg)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   10.40   15.43   19.20   20.09   22.80   33.90\n\n\n11.7.2 count vs.Â filter\nFRAGE: Wann benutzt man count() und wann filter()?\nANTWORT: Mit filter plus dem ZÃ¤hlen der Ã¼brig gebliebenen Zeilen erreicht man etwas Ã„hnliches wie mit count:\n\nmtcars |&gt; \n  filter(am == 0) |&gt; \n  nrow()\n## [1] 19\n\n\nmtcars |&gt; \n  count(am)\n\n\n  \n\n\n\n\n11.7.3 1000\nFRAGE: gibt es einen Unterschied zwischen 10^3 und 1e3? Es kommen nÃ¤mlich unterschiedliche Ergebnisse raus.\nANTWORT: Nein, beide Schreibweisen meinen das Gleiche, nÃ¤mlich die Zahl 1000.\n\n10^3 == 1000 \n## [1] TRUE\n1e3 == 1000\n## [1] TRUE",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#literaturhinweise",
    "href": "100-abschluss.html#literaturhinweise",
    "title": "\n11Â  Abschluss\n",
    "section": "\n11.8 Literaturhinweise",
    "text": "11.8 Literaturhinweise\nDiese Literaturliste empfiehlt Ihnen LehrbÃ¼cher zu grundlegenden Themen der Datenanalyse (mit R).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Abschluss</span>"
    ]
  }
]