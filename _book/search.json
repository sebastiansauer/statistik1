[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik1",
    "section": "",
    "text": "1 Willkommen!\nStatistik und Du: Guter Fit!",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#es-geht-um-ihren-lernerfolg",
    "href": "index.html#es-geht-um-ihren-lernerfolg",
    "title": "Statistik1",
    "section": "1.1 Es geht um Ihren Lernerfolg",
    "text": "1.1 Es geht um Ihren Lernerfolg\nMeister Yoda rät: Lesen Sie die Hinweise (Abbildung 1.1).\n\n\n\n\n\n\nAbbildung 1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\n\n\nQuelle: Imgflip Memengenerator\n\n1.1.1 Lernziele\n\nDie Studentis sind mit wesentlichen Methoden der explorativen Datenanalyse vertraut und können diese selbständig anwenden.\nDie Studentis können gängige Forschungsfragen in lineare Modelle übersetzen, diese auf echte Datensätze anwenden und die Ergebnisse interpretieren.\n\nKurz gesagt: Das ist ein Grundkurs in Daten zähmen.\n\n\n\nDaten zähmen\n\n\nBildquelle: Allison Horst, CC-BY\n\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nWas lerne ich hier?\nSie lernen das Handwerk der Datenanalyse mit einem Schwerpunkt auf Vorhersage. Anders gesagt: Sie lernen, Daten aufzubereiten und aus Daten Vorhersagen abzuleiten. Zum Beispiel: Kommt ein Student zu Ihnen und sagt “Ich habe 42 Stunden für die Klausur gelernt, welche Note kann ich in der Klausur erwarten?”. Darauf Ihre Antwort: “Auf Basis meiner Daten und meines Modells müsstest du eine 2.7 schreiben!”.1. Außerdem lernen Sie, wie man die Güte einer Vorhersage auf Stichhaltigkeit prüft. Denn Vorhersagen kann man ja in jeder Eckkneipe oder beim Wahrsager bekommen. Wir wollen aber belastbare Vorhersagen und zumindest wissen, wie gut die Vorhersagen (von jemanden) bisher waren.\nWarum ist das wichtig?\nWir wollen nicht auf Leuten vertrauen, die behaupten, sie wüssten, was für uns richtig und gut ist. Wir wollen selber die Fakten prüfen können.\nWozu brauche ich das im Job?\nDatenanalyse spielt bereits heute in vielen Berufen eine Rolle. Tendenz stark zunehmend.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es üblich, statistische Ergebnisse hinsichtlich quantitativ zu analysieren.\nIst Statistik nicht sehr abstrakt?\nDer Schwerpunkt dieses Kurses liegt auf Anwenden und Tun; ähnlich dem Erlernen eines Handwerks. Theorien und Abstraktionen stehen nur am Rand.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den “Top 20 job roles in increasing and decreasing demand across industries” (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n\n\n1.1.3 Motivieren Sie mich!\nAnsprache zur Motivation\n\n\n1.1.4 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie Folgendes mitbringen:\n\nBereitschaft, Neues zu lernen\nBereitschaft, nicht gleich aufzugeben\nKenntnis grundlegender Methoden wissenschaftlichen Arbeitens\n\nWas Sie nicht brauchen, sind besondere Mathe-Vorkenntnisse.\n\n\n1.1.5 Überblick\nAbb. Abbildung 1.2 gibt einen Überblick über den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Modellieren]\n      direction TB\n      M1[Verbildlichen] --&gt; Vis[Punktmodelle]\n      Vis --&gt; U[Modellguete]\n      U --&gt; G[Geradenmodelle]\n    end\n    subgraph N[Nachbereiten]\n      direction TB\n      D[Diskutieren]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\n\nAbbildung 1.2: Überblick über den Inhalt und Verlauf des Buches\n\n\n\n\n\nDas Diagramm zeigt den Ablauf einer typischen Datenanalyse. Natürlich kann man sich auch andere sinnvolle Darstellungen dieses Ablaufs vorstellen.\n\n\n\n\n1.1.6 PDF-Version\nSie können die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Statistik1",
    "section": "1.2 Software",
    "text": "1.2 Software\nSie benötigen R, RStudio und einige R-Pakete für diesen Kurs.\n\n1.2.1 Installation\nHier finden Sie Installationshinweise.\n\n\n1.2.2 Viel R (?)\nDieses Buch enthält “mittel” viel R. Auf fortgeschrittene R-Techniken wurde aber komplett verzichtet. Dem einen oder der anderen Anfänger:in mag es dennoch “viel Code” erscheinen. Es wäre ja auch möglich gewesen, auf R zu verzichten und stattdessen eine “Klick-Software” zu verwenden. JASP oder Jamovi sind Beispiele für tolle Software aus dieser Kategorie. Ich glaube aber, der Verzicht auf eine Skriptsprache (R) wäre ein schlechter Dienst an den Studentis. Mit Blick auf eine “High-Tech-Zukunft” sollte man zumindest mit etwas Computer-Code vertraut sein. Auf Computercode zu verzichten erschiene mir daher fahrlässig für die “Zukunftsfestigkeit” der Ausbildung.\n\n\n\nDas sind Sie nach der Lektüre dieses Buchs",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#hinweise",
    "href": "index.html#hinweise",
    "title": "Statistik1",
    "section": "1.3 Hinweise",
    "text": "1.3 Hinweise\n\n📺 YouTube-Playlists zu Statistik\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine Prüfung in diesem Modul ist jedes Semester möglich.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#prüfung",
    "href": "index.html#prüfung",
    "title": "Statistik1",
    "section": "1.4 Prüfung",
    "text": "1.4 Prüfung\nHier finden Sie Hinweise zur Prüfung.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#zum-autor",
    "href": "index.html#zum-autor",
    "title": "Statistik1",
    "section": "1.5 Zum Autor",
    "text": "1.5 Zum Autor\nNähere Hinweise zum Autor dieses Buch, Sebastian Sauer, finden Sie hier. Dort gibt es auch einen Überblick über weitere Bücher des Autors zum Themenkreis Datenanalyse.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#nomenklatur",
    "href": "index.html#nomenklatur",
    "title": "Statistik1",
    "section": "1.6 Nomenklatur",
    "text": "1.6 Nomenklatur\n\n1.6.1 Farben\nIn Gleichungen werden zum Teil Farben verwendet, diese haben folgende Bedeutung:\n\nY bzw. Abhängige Variable\nX bzw. Unabhängige Variable\ne bzw. Fehlerterm\nb0 bzw. Achsenabschnitt\nb1 bzw. Steigung (Regressionsgewicht)\nm bzw. y-Dach bzw. Modellwert\n\nIn Diagrammen werden auch Farben verwendet, die haben allerdings keine feste Bedeutung, sondern dienen der Übersichtlichkeit.\n\n\n1.6.2 Griechische Buchstaben\nIn diesem Buch werden ein paar (wenige) griechische Buchstaben verwendet, die in der Statistik üblich sind.\nHäufig werden griechische Buchstaben verwendet, um eine Grundgesamtheit (Population) zu beschreiben (die meistens unbekannt ist). Lateinische (“normale”) Buchstaben werden demgegenüber verwendet, um eine Stichprobe (Datensatz, vorliegende Daten) zu beschreiben.\nTabelle 1.1 stellt diese Buchstaben zusammen mit ihrer Aussprache und Bedeutung vor.\n\n\n\nTabelle 1.1: Griechische Buchstaben, die in diesem Buch verwendet werden.\n\n\n\n\n\nZeichen\nAussprache\nBuchstabe\nBedeutung in der Statistik\n\n\n\n\n\\(\\beta\\)\nbeta\nb\nRegressionskoeffizent\n\n\n\\(\\mu\\)\nmü\nm\nMittelwert\n\n\n\\(\\sigma\\)\nsigma\ns\nStreuung\n\n\n\\(\\Sigma\\)\nSigma\nS\nSummenzeichen\n\n\n\\(\\rho\\)\nrho\nr\nKorrelation (nach Pearson)\n\n\n\n\n\n\nMehr griechische Buchstaben finden sich hier.",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Statistik1",
    "section": "1.7 Zitation",
    "text": "1.7 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2024). Statistik1. https://statistik1.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren können:\n@book{sauer_statistik1,\n    title = {Statistik1},\n    rights = {CC-BY-NC},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2024},\n}\nHier ist die DOI:\n\n\n\nDOI",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#reproduzierbarkeit",
    "href": "index.html#reproduzierbarkeit",
    "title": "Statistik1",
    "section": "1.8 Reproduzierbarkeit",
    "text": "1.8 Reproduzierbarkeit\nDie verwendeten R-Pakete sind renv dokumentiert.\nDer Quellcode ist in diesem Github-Repo dokumentiert.\nDieses Dokument wurde erzeugt am/um 2024-03-19 22:51:47.\n\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2024-03-19\n##  pandoc   3.1.12.2 @ /usr/local/bin/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  ! package     * version date (UTC) lib source\n##  P cli           3.6.2   2023-12-11 [?] CRAN (R 4.2.0)\n##  P digest        0.6.33  2023-07-07 [?] CRAN (R 4.2.0)\n##  P evaluate      0.23    2023-11-01 [?] CRAN (R 4.2.0)\n##  P fastmap       1.1.1   2023-02-24 [?] CRAN (R 4.2.0)\n##  P htmltools     0.5.7   2023-11-03 [?] CRAN (R 4.2.0)\n##  P htmlwidgets   1.6.4   2023-12-06 [?] CRAN (R 4.2.0)\n##  P jsonlite      1.8.8   2023-12-04 [?] CRAN (R 4.2.0)\n##  P knitr       * 1.45    2023-10-30 [?] CRAN (R 4.2.1)\n##    renv          1.0.2   2023-08-15 [1] CRAN (R 4.2.0)\n##  P rlang         1.1.3   2024-01-10 [?] CRAN (R 4.2.1)\n##  P rmarkdown     2.26    2024-03-05 [?] CRAN (R 4.2.1)\n##  P rstudioapi    0.15.0  2023-07-07 [?] CRAN (R 4.2.0)\n##  P sessioninfo   1.2.2   2021-12-06 [?] CRAN (R 4.2.0)\n##  P xfun          0.41    2023-11-01 [?] CRAN (R 4.2.0)\n##  P yaml          2.3.8   2023-12-11 [?] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/github-repos/statistik1/renv/library/R-4.2/x86_64-apple-darwin17.0\n##  [2] /Users/sebastiansaueruser/Library/Caches/org.R-project.R/R/renv/sandbox/R-4.2/x86_64-apple-darwin17.0/fb4b0a46\n## \n##  P ── Loaded and on-disk path mismatch.\n## \n## ──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#literatur",
    "href": "index.html#literatur",
    "title": "Statistik1",
    "section": "1.9 Literatur",
    "text": "1.9 Literatur\n\n\n\n\nForum, W. E. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Statistik1",
    "section": "",
    "text": "Darauf dis Studenti: “Hpmf.”↩︎",
    "crumbs": [
      "Organisatorisches",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Willkommen!</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html",
    "href": "010-rahmen.html",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "2.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#lernsteuerung",
    "href": "010-rahmen.html#lernsteuerung",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "2.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\nAbbildung 2.1 zeigt, dass unser Vorgehen in diesem Buch einem Fließband gleicht: Schritt für Schritt, in der richtigen Reihenfolge, vom Anfang bis Ende, erarbeiten wir unser “Datenprodukt”.\n\n\n\n\n\nAbbildung 2.1: Datenanalyse als eine Abfolge am Fließband\n\n\n\nQuelle\n\n\n2.1.2 Lernziele\n\nSie können eine Definition von Statistik wiedergeben.\nSie können eine Definition von Daten wiedergeben.\nSie können den Begriff Tidy-Daten erläutern.\nSie können Beispiele für verschiedene Skalenniveaus nennen.\n\n2.1.3 Einstieg\n\nÜbungsaufgabe 2.1 (Hallo, Statistik) Gehen Sie in eine kleine Gruppe zusammen (3-4 Personen). Stellen Sie sich anhand der Schlagworte einander vor:\n\nName\n(wissenschaftliche) Interessen\nErwartung an diesen Kurs \\(\\square\\)\n\n\n\n\n2.1.4 Erfolsgrezept\nIhren Lernerfolg kann man als von drei Faktoren abhängig betrachten: 1) Ihrer Lehrkraft, 2) Ihrer Mitarbeit im Unterricht und 3) Ihrem Eigenstudium zuhause (Vor- bzw. Nachbereitung des Unterrichts), s. Abbildung 2.2.\n\n\n\n\n\nflowchart TD\n  subgraph Lehrkraft\n    F[\"🔥\"]\n  end\n  subgraph A[Konzentraion im Unterricht]\n    C[\"🪵\"]\n  end\n  subgraph E[Eigenstudium]\n    D[\"🌳\"] \n  end  \n\n\n\n\n\nAbbildung 2.2: Ihr Lernerfolg besteht aus drei Komponenten: Der Lehrkraft, Ihrer Konzentration im Unterricht und Ihrer Vor- bzw. Nachbereitung zuhause.\n\n\n\n\nEine gute Lehrkraft ist wie der Funke, der eine (Lern-)Flamme entzündet. Aber es braucht Brennmaterial, einen Holzscheit, das ist Ihre Konzentration im Unterricht. Ein Holzscheit alleine ist aber nicht nachhaltig, es braucht viel mehr Brennmaterial, um das Feuer am Leben zu halten: Ihr Eigenstudium, das stetige, selbständige Beschäftigen mit der Materie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "href": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "title": "\n2  Rahmen\n",
    "section": "\n2.2 Was ist Statistik und wozu ist sie gut?",
    "text": "2.2 Was ist Statistik und wozu ist sie gut?\n\n2.2.1 Eine Definition von Statistik\nEs gibt mehrere Definition von Statistik; hier ist eine.\n\nDefinition 2.1 (Statistik) Statistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen und beschreibt die Ungewissheit unserer Schlüsse Poldrack (2023).\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Buch werden die Begriffe Statistik, Datenanalyse und Data Science synonym verwendet.\\(\\square\\)\n\n\nHm. Vielleicht fragen wir mal ChatGPT, was es unter Statistik versteht:\n\n👨 Was ist Statistik? Bitte definiere verständlich.\n\n\n🤖 Statistik ist eine Wissenschaft, die sich mit der Sammlung, Analyse, Interpretation, Präsentation und Übertragung von Daten beschäftigt. Ziel ist es, Muster und Trends in den Daten zu erkennen und verlässliche Schlussfolgerungen über eine größere Gruppe (z.B. Bevölkerung) auf der Basis einer Stichprobe (Teilmenge) zu treffen. Die Statistik hilft uns bei der Beantwortung von Fragen, indem sie uns dabei hilft, die Unsicherheit in den Daten zu messen und zu verstehen1.\n\n\nÜbungsaufgabe 2.2 (Nutzen von Statistik) 🏋️‍♀️ Fragen Sie ChatGPT, was der Nutzen von Statistik ist. Diskutieren Sie die Antwort.\n\n\n\n\n\n\n\n\n\n2.2.2 Unterschiedlichkeit messen\nEine allgegenwärtige Tatsache ist, dass die Dinge der Welt sich unterscheiden, etwa, dass Exemplare einer Gattung sich unterscheiden. So sind nicht alle Menschen gleich groß, nicht alle Bücher gleich lang oder nicht alle Tage gleich warm.\nEin zentrales Vorgehen bei statistischen Analysen ist es, die Unterschiedlichkeit der Dinge zu beschreiben, präziser gesagt: die Variation zu quantifizieren. Betrachten wir dazu das Beispiel in s. Abbildung 2.3.\n\n\n\n\n\n\n\nAbbildung 2.3: Wenig Variation in der Körpergröße bei den Basketballern. Alles lange Kerle. Viel Variation bei den Schachspielern: Manche sind klein, ander groß.\n\n\n\n\nBei den Basketballern gibt es geringe Variation in der Körpergröße - alle sind groß, ähnlich groß. Bei den Schachspielern gibt es (im Verhältnis) hohe Variation: Einige Personen sind groß, andere klein.\nDie Variation (auch “Variabilität” genannt) kann man auch gut so darstellen wie in s. Abbildung 2.4 gezeigt.\n\n\n\n\n\n\n\nAbbildung 2.4: Die Abweichungen der einzelnen Personen von der mittleren Körpergröße ihres Teams\n\n\n\n\nEine Abweichung (auch Residuum) genannt, zeigt hier die Differenz von Mittelwert und dem Wert der Körpergröße bei der jeweiligen Person. Wenn wir allgemein von einer Person \\(i\\) sprechen, Das Merkmal Körpergröße mit \\(X\\) bezeichnen und den Mittelwert der Körpergröße als \\(\\bar{x}\\) (“x quer”), dann können wir knapp und präzise das Residuum der \\(i\\)-ten Person mit \\(r_i\\) bezeichnen und entsprechend definieren.\n\nDefinition 2.2 (Residuum) Das Residuum des Merkmals \\(X\\) der \\(i\\)-ten Beobachtung ist definiert als die Differenz vom Wert \\(x_i\\) und einem Referenzwert, etwa dem Mittelwert, \\(\\bar{x}\\):\n\\(r_i = x_i - \\bar{x}\\). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "href": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "title": "\n2  Rahmen\n",
    "section": "\n2.3 Was ist das Ziel Ihrer Analyse?",
    "text": "2.3 Was ist das Ziel Ihrer Analyse?\n\n2.3.1 Arten von Zielen\n\n\n\n\n\ngraph TD\n  subgraph Ziele\n    A[beschreiben]\n    B[vorhersagen]\n    C[erklären]\n  end\n\n\n\n\nAbbildung 2.5: Zielarten einer Datenanalyse\n\n\n\n\nBeispiele für die einzelnen Zielarten der Datenanalyse:\n\n\nBeschreiben: “Wie groß ist der Gender-Paygap in der Branche X im Zeitraum Y?”\n\nVorhersagen: Wenn ich 100 Stunden auf die Statistikklausur lernen, welche Note kann ich dann erwarten?\n\nErklären: Wie viel bringt mir das Lernen auf die Statistikklausur?\n\n2.3.2 Forschungsfrage\nEine Forschungsfrage ist die Leitfrage Ihrer Analyse. Sie definiert, was Sie herausfinden wollen. Häufig sind Forschungsfragen so aufgebaut:\n\nHat X einen Einfluss auf Y?\n\nEine Forschungsfrage weist häufig folgende Struktur auf, s. Abbildung 2.6.\n\n\n\n\n\ngraph LR\n    Input --&gt; X[hier passiert irgendwas]\n    subgraph \"Schwarze Kiste\"\n      X\n    end\n    X --&gt; Output\n\n\n\n\nAbbildung 2.6: Struktur eine Forschungsfrage\n\n\n\n\n\nBeispiel 2.1 (Forschungsfrage 1)  \n\nHat Lernen einen Einfluss auf den Prüfungserfolg? Verringert Joggen die Menge des Hüftgolds? Um welchen Betrag erhöht sich der Umsatz, wenn wir 1000€ mehr Werbung ausgeben?\\(\\square\\)\n\n\n\nBeispiel 2.2 (Forschungsfrage 2) Nach dem Studium haben Sie bei einem großen Online-Auktionshaus angeheuert. Da Sie angaben, sich im Studium intensiv etwas mit Statistik beschäftigt zu haben, hat man Sie in die F&E-Abteilung2 gesteckt. Heute ist es Ihre Aufgabe, Auktionen zur Spielekonsole Wii zu untersuchen, genauer gesagt, geht es um das Spiel Mariokart. Ihre Forschungsfrage lautet:\n\nWelche Produktmerkmale stehen mit einem hohen Verkaufserlös in Zusammenhang?\\(\\square\\)\n\n\n\n2.3.3 Der Prozess der Datenanalyse\nDatenanalyse ist eine Art des Problemlösens. Anders gesagt, man macht es nicht zum Spaß3, sondern um ein Ziel zu erreichen, d.h. ein Problem zu lösen. Daher analysiert man nicht gleich zu Anfang wild drauf los. Zunächst 1) klärt man das Problem und das Ziel. Dann 2) plant man das Vorgehen, z.B. welche Daten man erheben möchte. Als nächstes 3) erhebt man die Daten und bereitet sie auf. Schließlich kann man sie 4) endlich analysieren. Aber Daten sprechen nicht für sich, man muss sie 5) interpretieren und Schlüsse daraus ziehen. Dazu gehört auch, dass man die Schwächen der eigenen Analyse kritisch beleuchtet, vgl. Abbildung 2.7. Diesen Ablauf nennt man auch das PPDAC-Modell (MacKay & Oldford, 2000):\n\nP: Problem (Problem und Ziel und Sachgegenstand verstehen)\nP: Plan (Vorgehen planen)\nD: Data (Daten erheben und aufbereiten)\nA: Analysis (Daten analysieren)\nC: Conclusions (Schlussfolgerungen ziehen; Daten interpretieren )\n\n\n\n\n\n\ngraph LR\n    Problem --&gt; Plan --&gt; Data --&gt; Analysis --&gt; Conclusions --&gt; Problem\n\n\n\n\nAbbildung 2.7: Datenanalyse als Prozess: Das PPDAC-Modell\n\n\n\n\n\nBeispiel 2.3 (Aus der Forschung: Smartphone-Brain-Drain 📱🧠🚫) Ward et al. (2017) untersuchten die Forschungsfrage, ob die bloße Gegenwart eines Handies (z.B. wenn es vor Ihnen auf dem Tisch liegt) dazu führt, dass man abgelenkt wird und daher schlechtere kognitive Leistungen zeigt.\nLeider schreiben die Autoren Ihre Hypothese nicht glasklar, aber implizit ist obige Hypothese herauszulesen:\n\nFirst, smartphones may redirect the orientation of conscious attention away from the focal task and toward thoughts or behaviors associated with one’s phone. Prior research provides ample evidence that … this digital distraction adversely affects both performance … and enjoyment.\n\nSpäter formulieren Sie Ihre Hypothese noch genauer:\n\nIn two experiments, we test the hypothesis that the mere presence of one’s own smartphone reduces available cognitive capacity.\n\nDie Ergebnisse unterstützen Ihre Hypothese, s. Abbildung 2.8. Im Diagramm ist ersichtlich, dass die kognitive Leistung (Y-Achse) sowohl in der Kapazität des Arbeitsgedächtnisses (links) als auch in der fluiden Intelligenz (rechts) am geringsten ist, wenn das Handy auf dem Schreibtisch (Desk) liegt. Am besten ist die kognitive Leistung, wenn das Handy nicht im Raum ist.\\(\\square\\)\n\n\n\n\n\nAbbildung 2.8: Handy in Sichtweite verringert die kognitiven Ressourcen\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEs ist ein häufiger Fehler, in der Forschungsfrage zu formulieren “X führt zu Y”, aber in der Analyse keine Methode zu verwenden, die geeignet ist, kausale Zusammenhänge aufzudecken. Es reicht nicht, dass man z.B. einen (negativen) Zusammenhang zwischen der Häufigkeit von Smartphone-Nutzung und Konzentrationsfähigkeit findet (Schwaiger & Tahir, 2022), um zu sagen: “Daddeln macht dumm!”. Es könnte ja z.B. auch umgekehrt sein. Platt gesagt: “Dummheit führt zu Daddeln”. Weitere Erklärungen sind möglich. Vorsicht also mit (vor)schnellen Aussagen zu kausalen Abhängigkeiten.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-sind-daten",
    "href": "010-rahmen.html#was-sind-daten",
    "title": "\n2  Rahmen\n",
    "section": "\n2.4 Was sind Daten?",
    "text": "2.4 Was sind Daten?\n\nDefinition 2.3 (Hallo, Daten) Daten kann man als eine geordnete Folge von Zeichen definieren.\\(\\square\\)\n\nDaten kommen häufig in Tabellenform vor; so sind sie (oft) am besten zu untersuchen, s. Tabelle 2.1.\n\n\n\nTabelle 2.1: So sehen Daten aus.\n\n\n\n\n\n\nid\nname\nnote\n\n\n\n1\nAnna\n1.3\n\n\n2\nBerta\n2.3\n\n\n3\nCarla\n3.0\n\n\n\n\n\n\n\n\n\nDie erste Spalte id ist nur eine laufende Nummer. Sie dient dazu, die einzelnen Beobachtungen (hier Studentis) identifizieren zu können und birgt ansonsten keine Information. Beispiele für ID-Variablen sind z.B. Matrikulationsnummer, Personalausweisnummern oder Bestellnummern.\n\nBeispiel 2.4 (Daten zur Forschungsfrage 2) Hier ist ein Auszug der Daten zur Tabelle mariokart, s. Tabelle 2.2.\n\n\n\nTabelle 2.2: Auszug aus der Tabelle mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n3\n20\nnew\n0.99\n4.00\n51.55\nstandard\n1580\nyes\n1\n\n\n7\n13\nused\n0.99\n3.99\n37.04\nfirstClass\n365\nyes\n1\n\n\n3\n16\nnew\n0.99\n3.50\n45.50\nfirstClass\n998\nno\n1\n\n\n3\n18\nnew\n0.99\n0.00\n44.00\nstandard\n7\nyes\n1\n\n\n1\n20\nnew\n0.01\n0.00\n71.00\nmedia\n820\nyes\n2\n\n\n3\n19\nnew\n0.99\n4.00\n45.00\nstandard\n270144\nyes\n0\n\n\n\n\n\n\n\n\nEine Erklärung aller Variablen des Datensatzes mariokart findet sich hier. \\(\\square\\)\n\n\nDefinition 2.4 (Data Dictionary) Eine Erklärung, was die Namen einer Datentabelle bedeuten, nennt man Code Book or Data Dictionary.\\(\\square\\)\n\n\n2.4.1 Was ist eine Variable?\n\nDefinition 2.5 (Variable) Eine Variable ist ein Platzhalter, der für ein Merkmal steht, das verschiedene Werte annehmen kann.\\(\\square\\)\n\nMan kann sich eine Variable wie einen Behälter vorstellen, auf dem mit einem Stift geschrieben steht, was für eine Art Inhalt darin ist, s. Abbildung 2.9.\n\n\n\n\n\nAbbildung 2.9: Wir definieren eine Variable “temp” mit dem Inhalt “9”\n\n\n\n2.4.2 Beobachtungseinheit\n\nDefinition 2.6 (Beobachtungseinheit) Beobachtungseinheiten sind die Dinge, die wir untersuchen (beobachten). Beobachtungseinheiten sind die Träger von Variablen.\\(\\square\\)\n\nIn Tabelle 2.1 gibt es drei Variablen: id, Name und Note. Es gibt auch drei Beobachtungseinheiten: Anna, Berta und Carla.\n\n2.4.3 Wert\n\nDefinition 2.7 (Wert) Ein Wert ist der Inhalt einer Variablen.\\(\\square\\)\n\nIn Abbildung 2.9 ist der Wert von temp 9. In Tabelle 2.1 hat die Variable name drei Elemente: Anna, Berta, Carla. Der Wert des 2. Elements ist Berta.\n\nDefinition 2.8 Als Ausprägungen bezeichnet man die verschiedenen Werte einer Variablen. \\(\\square\\)\n\n\nBeispiel 2.5 In einer Studie wurden zehn Probanden untersucht. Die Variable geschlecht dokumentiert die Geschlechter der Personen:\n\ngeschlecht &lt;- c(\"Mann\", \"Frau\", \"Frau\", \"Frau\", \"Mann\",\n                \"Frau\", \"Mann\", \"Mann\", \"divers\", \"Frau\")\ngeschlecht\n##  [1] \"Mann\"   \"Frau\"   \"Frau\"   \"Frau\"   \"Mann\"   \"Frau\"   \"Mann\"   \"Mann\"  \n##  [9] \"divers\" \"Frau\"\n\nIn dieser Variable (die aus 10 Werten besteht) finden sich drei Ausprägungen: divers, Frau, Mann.\\(\\square\\)\n\n\n\n\n\n\n\nTipp\n\n\n\nGerade haben Sie etwas Computer-Syntax gesehen, genauer gesagt, Befehle aus der Programmiersprache R. Bisher haben wir diese Befehle nicht kennengelernt. Sie verstehen Sie vermutlich (nicht ganz). Ignorieren Sie diese Befehle einfach erstmal.\n\n\n\n2.4.4 Tidy-Data\n\nDefinition 2.9 Unter Tidy-Data (tidy data, “Normalform”) versteht man eine Tabelle, in der jede Zeile eine Beobachtungseinheit darstellt, jede Spalte eine Variable und jede Zelle der Tabelle einen Wert, s. Abbildung 2.10 (a). (Zusätzlich ist noch eine “Kopfzeile” erlaubt, in der die Namen der Variablen stehen.)\\(\\square\\)\n\nTabelle 2.1 ist ein Beispiel für Tidy-Data. Abbildung 2.10 (a) zeigt ein Sinnbild für Tidy-Data (Wickham & Grolemund, 2018). Und Abbildung 2.10 (b) erläutert das Tidy-Prinzip genauer.\n\n\n\n\n\n\n\n\n\n(a) Tidy-Data-Sinnbild. Image Credit: Hadley Wickham\n\n\n\n\n\n\n\n\n\n(b) Was ist Tidy-Data?. Image Credit: Allision Horst\n\n\n\n\n\n\nAbbildung 2.10: Stay Tidy!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nFür eine statistische Analyse ist es oft sinnvoll, dass die Daten im Tidy-Format vorliegen.\n\n\nDer Vorteil des Tidy-Formats ist es, dass man weiß, wie die Daten aufgebaut sind. Außerdem können Statistikprogramme oft mit dieser Form am besten umgehen, s. Abbildung 2.11.\n\n\n\n\n\nAbbildung 2.11: Immer schön Ordnung halten… Image credit: Allision Horst\n\n\n\nQuelle\n\nDas Tidy-Format wird auch als “langes” Format bezeichnet.\nAbbildung 2.12 zeigt einen Datensatz in der “langen” Form, also tidy, und den gleichen Datensatz, umformatiert in der “breiten” Form, nicht-tidy.\n\n\n\n\n\nAbbildung 2.12: Links: Eine Tabelle mit Format “wide” - nicht “tidy”. Rechts: Das “Langformat” (“long”) ist “tidy”.\n\n\nQuelle: Garrick Aden-Buie, 2018, CC0-1.0 license, https://www.garrickadenbuie.com/project/tidyexplain/\n\n\n\n\n\n\nTipp\n\n\n\nIn vielen Organisationen werden Exceltabellen für bestimmte Zwecke der Datenverarbeitung verwendet. Excel4 hat bestimmte Stärken und Vorteile, aber auch gewisse Nachteile und Schwäche; das liegt z.T. daran, dass Excel für bestimmte Aufgaben besser und für andere weniger gut geeignet ist. Wenn man mit Excel arbeitet, wiederholen sich erfahrungsgemäß immer wieder die gleichen Fehler bzw. suboptimalen Vorgehensweise zum Aufbau einer Exceltabelle.\nDieser Artikel von Broman & Woo (2018) zeigt anhand einiger praktischer Tipps, wie man Exceltabellen so aufbaut, dass Fehler minimiert werden.\n\n\n\nÜbungsaufgabe 2.3 (Sind wir süchtig nach dem Handy?) Sind Sie süchtig nach Ihrem Handy? Lassen Sie uns eine kleine Studie dazu live im Hörsaal durchführen. Füllen Sie diese Umfrage zum Thema Smartphonse-Sucht aus (anonym und kein Muss). Wir werden die Daten später zusammen aus. \\(\\square\\)\n\n\n2.4.5 Je mehr, desto besser (?)\nWas Daten betrifft, könnte man behaupten: “Viel hilft viel” oder “Je mehr, desto besser”. Natürlich unter sonst gleichen Umständen5. Viel Datenmüll ist natürlich nicht besser als ein paar knappe, wasserdichte Fakten!\n\nBeispiel 2.6 Um Ihre eigene Lehraktivität zu organisieren, wollen Sie sich ein Bild machen, wie viel Ihre Nebensitzer im Hörsaal so lernen. Sie blicken nach links und fragen “wie viel lernst du so?”. Sie blicken nach recht und wiederholen die Frage gerichtet an den rechtsnebensitzenden Kommilitonen. Dann addieren Sie die zwei Zahlen (unter der Annahme, dass Sie zwei Zahlen bekommen haben), und teilen durch zwei, um den Mittelwert zu erhalten.\nEin kritischer Geist könnte anmerken, dass Sie besser die Untersuchung nicht gemacht hätten (auch wenn Sie, vielleicht ohne zu wollen, eine statistische Untersuchung angestellt haben). Denn bei so wenig befragten Personen ist die Ungenauigkeit Ihrer Schätzung der typischen Lernzeit bei Studentis einfach zu hoch.\\(\\square\\)\n\nAbbildung 2.13 veranschaulicht, dass man einen Mittelwert genauer schätzen kann, wenn man auf eine größere Stichprobe zurückgreift. Das Teilbild links zeigt den Mittelwert einer Stichprobe mit \\(n=20\\) Beobachtungen. Das Teilbild rechts zeigt den Mittelwert einer Stichprobe mit \\(n=200\\) Beobachtungen (jeweils aus der gleichen Grundgesamtheit). Wie man sieht, ist im linken Teilbild die Streuung (Variation) höher als im rechten Teilbild:\n\n\n\n\n\nAbbildung 2.13: Schätzgenauigkeit als Funktion der Stichprobengröße: Die vertikale Linie zeigt den wahren Mittelwert. Kleinere Stichproben-Mittelwerte schanken (variieren) mehr um den Mittelwert herum als größere Stichproben.\n\n\nBildquelle: Karsten Lübke\n\n\n\n\n\n\nWichtig\n\n\n\nMehr Daten = genauere Ergebnisse (unter sonst gleichen Umständen) \\(\\square\\)\n\n\n\nÜbungsaufgabe 2.4 (Live-Experiment zum Effekt der Stichprobengröße) In diesem Live-Experiment untersuchen wir den Effekt der Stichprobengröße auf die Streuung des Mittelwerts in der Stichprobe. Streuen die Ergebnisse mehr in kleinen Stichproben als in großen? Probieren wir es aus!\nIn diesem Experiment werfen Sie (in kleinen Gruppen) eine Münze (auf faire Art und Weise) und notieren das Ergebnis (Kopf oder Zahl). Uns interessiert dabei die Frage, ob die Ergebnisse bei kleinen Stichproben (n=5 Münzwürfe) anders streuen als in großen Stichproben (n=20 Münzwürfe).\nSie brauchen nur experimentierfreudige Partner (Kleingruppen mit 2-4 Personen), eine faire Münze und dann kann’s los gehen! Klicken Sie hier, um mit dem Experiment zu starten\nDie Daten aller Versuche können Sie hier einsehen. \\(\\square\\)\n\n\nBeispiel 2.7 (Dorfschulen machen die schlauesten Schüler!) In einer Pressemitteilung sei zu lesen, dass die besten Schüler in den Dorfschulen zu finden seien6. Mit etwas Recherche finden Sie heraus, dass diese Aussage für belastbaren Daten beruht: Tatsächlich sind die Notendurchschnitte auf den kleinen Dorfschulen deutlich besser als in den großen Schulen in der Stadt. Also stimmt die Behauptung der Pressemitteilung? Die gute Landluft lässt das Hirn wachsen? Sie recherchieren noch etwas weiter in den Daten. Dann fällt Ihnen auf: Die schlechtesten Schüler kommen auch aus den Dorfschulen! Eine statistische Erklärung bietet sich an: In den Dorfschulen gibt es nur wenig Kinder und kleine Klassen – die Stichproben sind also klein. Bei kleinen Stichproben gibt es viel Variation um den Mittelwert herum, s. Abbildung 2.13, und zwar nach oben (guter Notenschnitt) und nach unten (schlechter Notenschnitt). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#sec-arten-variablen",
    "href": "010-rahmen.html#sec-arten-variablen",
    "title": "\n2  Rahmen\n",
    "section": "\n2.5 Arten von Variablen",
    "text": "2.5 Arten von Variablen\n\n2.5.1 Nach Position in der Forschungsfrage\nAngenommen, Ihre Forschungsfrage lautet:\n\nHat Lernen einen Einfluss auf den Prüfungserfolg?\n\nIn dem Fall gilt:\n\n\nLernen ist die Inputvariable/X-Variable/Ursache/unabhängig Variable (UV)\n\nPrüfungserfolg ist die Outputvariable/Y-Variable/Wirkung/abhängige Variable (AV)\n\nAbbildung 2.14 stellt diese beiden “Positionen” einer Variable dar. Die erste Position ist vor dem Pfeil. Die zweite Position ist nach dem Pfeil.\n\n\n\n\n\ngraph LR\n    Input --&gt; Output\n    X --&gt; Y\n    P[Prädiktor] --&gt; K[Kriterium]\n    Ursache --&gt; Wirkung\n    UV[unabhängige Variable] --&gt; AV[abhängige Variable]\n\n\n\n\nAbbildung 2.14: Synonyme Bezeichnungen für Input- und Output-Variablen einer Forschungsfrage\n\n\n\n\n\nÜbungsaufgabe 2.5 Überlegen Sie sich eine Forschungsfrage, die eine UV und eine AV enthält. Sagen Sie einer/em Kommilitonen diese Forschungsfrage und fragen Sie, was die UV und die AV ist. Bei richtiger Antwort belohnen Sie großzügig. \\(\\square\\)\n\n\n2.5.2 Nach dem Skalenniveau\n\nDefinition 2.10 Der Begriff Skalenniveau wird verwendet, um die Art und Menge der Information, die in Variablen enthalten ist, zu benennen. Diese Klassifikation basiert auf den Eigenschaften der Daten und den mathematischen Operationen, die sinnvoll auf diese Daten angewendet werden können. \\(\\square\\)\n\nAbbildung 2.15 gibt einen Überblick über typisch verwendete Skalenniveaus.\n\n\n\n\n\ngraph TD\n    Variablen --&gt; qualitativ\n    Variablen --&gt; quantitativ\n    qualitativ --&gt; nominal\n    qualitativ --&gt; ordinal\n    quantitativ --&gt; Intervallniveau\n    quantitativ --&gt; Verhältnisniveau\n\n\n\n\nAbbildung 2.15: Skalenniveaus\n\n\n\n\n\n2.5.3 Beispiele für Skalenniveaus\nBeispiele zu den Skalenniveaus sind in Tabelle 2.3 aufgeführt. \\(\\square\\)\n\n\n\nTabelle 2.3: Beispiele für Skalenniveaus\n\n\n\n\nVariable\nSkalenniveau\n\n\n\nHaarfarbe\nNominalskala\n\n\nAugenfarbe\nNominalskala\n\n\nGeschlecht\nNominalskala\n\n\nAutomarke\nNominalskala\n\n\nPartei\nNominalskala\n\n\nLieblingsessen\nOrdinalskala\n\n\nMedaillen beim 100-Meter-Lauf\nOrdinalskala\n\n\nUniranking\nOrdinalskala\n\n\nIQ\nIntervallskala\n\n\nExtraversion\nIntervallskala\n\n\nTemperatur in Celcius\nIntervallskala\n\n\nTemperatur in Fahrenheit\nIntervallskala\n\n\nTemperatur in Kelvin\nVerhältnisskala\n\n\nKörpergröße\nVerhältnisskala\n\n\nGeschwindigkeit\nVerhältnisskala\n\n\nLänge\nVerhältnisskala\n\n\n\n\n\n\n\n\nJe nach dem, über welches Skalenniveau eine Variable verfügt, sind verschiedenen Rechenoperationen erlaubt, s. tbl-skalenniveaus .\n\n\n\nTabelle 2.4: Erlaubte Rechenoperationen nach Skalenniveau\n\n\n\n\nSkalenniveau\nQuantitativ\n≠\n≼\n+\n×\n\n\n\nNominalniveau\nnein\n✅\n❌\n❌\n❌\n\n\nOrdinalniveau\nnein\n✅\n✅\n❌\n❌\n\n\nIntervallniveau\nja\n✅\n✅\n✅\n❌\n\n\nVerhältnisniveau\nja\n✅\n✅\n✅\n✅\n\n\n\n\n\n\n\n\nWas soll das bedeuten, “Rechenoperationen”?\nSchauen wir uns für jedes Skalenniveau ein “Rechenbeispiel” an.\nNominalskala: Die Variable Geschlecht ist nominalskaliert. Das bedeutet, dass ihre Ausprägungen Frau und Mann z.B. nicht (sinnvoll) addiert oder sonstwie “verrechnet” werden können. Man könnte, z.B. um das Eintippen zu erleichtern, Frauen mit 1 kodieren und Männer mit 2. Damit darf man aber nicht rechnen! Nicht addieren, multiplizieren … Es macht keinen Sinn zu sagen: “Ich habe eine Frau und einen Mann in meiner Tabelle, das ist im Schnitt ein diverses Geschlecht, weil der Mittelwert von 1 und 2 ist 1,5!”\nDie einzige “Rechenoperation”, die man auf der Nominalskala machen darf, ist die Prüfung auf Gleichheit: Mann kann feststellen, ob ein Objekt gleich zu einem anderen ist oder unterschiedlich. Also ob zwei Personen das gleiche Geschlecht haben oder von unterschiedlichem Geschlecht sind. Anders ausgedrückt:\n\n👩 \\(\\ne\\) 👨\n👩 \\(=\\) 👩\n👨 \\(=\\) 👨\n\nOrdinalskala: Diese Skala entspricht einer Rangordnung. Eine Rangordnung ist etwa die geordnete Abfolge Ihres Leibgerichte7. Etwas “formaler” ausgedrückt:\n\n🍕 \\(\\succ\\) 🍝 \\(\\succ\\) 🥩\n\nDas komische Zeichen \\(\\succ\\) soll heißen: “Ist auf meiner Liste von Leibgerichten weiter oben, mag ich lieber”. Man kann aber nicht sagen, “Ich mag aber Pizza um 42% mehr als die Spagetthi und die wieder um 73% mehr als ein Schnitzel!”. Zumindest kann man das nicht ohne weitere Informationen und Annahmen. Es gibt also Dinge auf der Welt, die man leicht in eine Rangordnung bringen kann, aber die man nur schwer in der Größe der Unterschiede bemessen kann. Das ist die Ordinalskala.\n\n\n\n\n\n\nWichtig\n\n\n\nDie Ordinalskale erlaubt, Objekte zu ordnen (hinsichtlich eines Merkmals). Die Abstände zwischen den Objekten können nicht quantifiziert werden. \\(\\square\\)\n\n\nIntervallskala: Das ist vielleicht eine Überraschung für Sie: Wenn es heute 10°C hat und morgen 5°C – dann ist es heute nicht doppelt so warm wie morgen. Ja, 10 ist das Doppelte von 5. Aber 10° Celcius ist nicht doppelt so warm wie 20° Celcius. Wenn Sie das verwundert: Das ist normal, so geht es vielen Leuten, wenn sie das zum ersten Mal hören. Der Grund, dass es nicht erlaubt ist, Verhältnisse (wie doppelt/halb so viel etc.) auf der Celcius-Skala zu bilden, ist, dass der Nullpunkt der Skala, 0° C, kein echter, physikalischer Nullpunkt ist. Bei 0° C liegt eben nicht Null Wärmeenergie vor. Stattdessen wurde eine Wärmenergiemenge gewählt, die für uns Menschen ganz praktisch, da augenfällig ist: der Gefrierpunkt von Wasser. Was bei der Intervallskala erlaubt ist, ist das Addieren (und Subtrahieren): heute 10°C, morgen 5°C, das ist ein Unterschied von 5°C. Oder: Im Schnitt waren es 7,5°C, das ist genau in der Mitte von 5 und 10°C. Abbildung 2.16 versinnbildlicht die Intervallskala.\n\n\n\n\n\n\n\nAbbildung 2.16: Ein Metermaß steckt im Wasser. Auf dem Metermaß können wir die aufgedruckten Zahlen ablesen. Aber wir wissen nicht, ob der Metermaß auf dem Boden steht. Wir wissen demnach nicht, ob der vom Metermaß angegebene Nullpunkt der wahre Nullpunkt (Meeresboden) ist.\n\n\n\n\nVerhältnisskala: Eine Verhältnisskala ist das, was man sich gemeinhin unter einer metrische Variable vorstellt: Man kann “normal” rechnen, alle Rechenoperationen sind erlaubt. Zuzüglich zu denen, die auch in anderen, “niedrigeren” Skalenniveaus erlaubt sind, ist das das Bilden von Verhältnissen - Multiplizieren, s. Abbildung 2.17.\n\n\n\n\n\n\n\nAbbildung 2.17: Puh! Der rote Flitzer ist 10 Mal so teuer wie die blaue Möhre. Kohlen zusammenkratzen.\n\n\n\n\nIn diesem Video gibt es noch ausführlichere Erklärung zum Thema Skalenniveaus.\n\nAußerdem können quantitative Variablen untergliedert werden in:\n\n\nstetige Variablen, das sind Variablen, bei denen man zwischen zwei Ausprägungen immer noch eine weitere quetschen kann. So gibt es eine Wert für die Köpergröße zwischen 1.60 m und 1.61 m. Und einen Wert zwischen 1.601 m und 1.602 m, etc.\ndiskrete Variablen, das sind metrische Variablen, die nur bestimmte Ausprägungen haben, häufig sind das die natürlichen Zahlen: \\(1,2,...\\). Ein Beispiel wäre die Anzahl der Kinder in einer Familie.\n\n\n\n\n\n\n\nTipp\n\n\n\nFragen nach Skalenniveaus gehören zu den Lieblingsprüfungsfragen in diesem Themenbereich. Sie sind gut beraten, sich gerade mit dieser Frage intensiver zu beschäftigen. Auch in thematisch angrenzenden Fächern wird immer wieder die Frage nach dem Skalennvieau aufgeworfen. Das zeigt natürlich auch die hohe Relevanz des Themas.\n\n\n\nÜbungsaufgabe 2.6 Überlegen Sie sich für einige Variablen die Skalenniveaus und befragen Sie dann eine:n Kommilitonen dazu. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#modelle",
    "href": "010-rahmen.html#modelle",
    "title": "\n2  Rahmen\n",
    "section": "\n2.6 Modelle",
    "text": "2.6 Modelle\nWoran denken Sie beim Wort “Modell”? Vielleicht an Spielzeugautos, s. Abbildung 2.18.\n\n\n\n\n\nAbbildung 2.18: Matchbox-Autos sind Modelle für Autos\n\n\n\nDefinition 2.11 (Modelle) Modelle sind ein vereinfachtes Abbild der Realität eine Repräsentation (Kaplan, 2009).\\(\\square\\)\n\n\nBeispiel 2.8 (Beispiele für Modelle) Puppen sind Modelle für Babies, Landkarten für Landstriche und das Atommodell von Nils Bohr ist ein Modell für Atome.\\(\\square\\)\n\nAuch in der Statistik nutzen wir Modelle. Helfen Sie Prof. Weiss-Ois: Er blickt nicht durch. Gerne würde er wissen, wie viele Stunden seine Studentis auf die Prüfung lernen. Aber mit so vielen Zahlen kann er nicht umgehen … Geben Sie ihm ein Modell: Sagen Sie ihm, wie lang die Studis typischerweise lernen (sagen Sie ihm ein einfach den Mittelwert der Lernzeiten).\n\n\n\n2.6.1 Vorher\n12, 8, 10, 11, 10, 9, 13, 9, 14, 9, 12, 14, 7, 9, 9, 11, 9, 4, 5, 12, 9, 6, 9, 12, 13, 9, 9, 6, 10, 8\n\n\nOh jeh, so viele Zahlen! Ich check nix! Wie viel lernen denn jetzt meine Studis?!\n\n\n\n\n\n\n2.6.2 Nachher\n\n9.6\n\n \n\n\nYeah, jetzt weiß ich, wie viel die Studis so typischerweise lernen. Viel zu wenig natürlich!\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\nDer Nutzen von Modellen ist, dass sie komplexe Sachverhalte vereinfachen und damit oft überhaupt erst dem Verständnis oder einer Untersuchung zugänglich machen: Modelle ermöglichen Verständnis. In der Datenanalyse bzw. Statistik8 fassen Sie oft viele Daten prägnant zusammen, z.B. zu einer einzelnen Kennzahl. Das Verrückte an Modellen ist, dass man Informationen wegwirft, um eine (andere, hoffentlich nützlichere) Information zu bekommen (Stigler, 2016). Weniger ist mehr?!",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#praxisbezug",
    "href": "010-rahmen.html#praxisbezug",
    "title": "\n2  Rahmen\n",
    "section": "\n2.7 Praxisbezug",
    "text": "2.7 Praxisbezug\nWir leben im Datenzeitalter; Daten durchdringen alle Bereiche des beruflichen, gesellschaftlichen und privaten Lebens. Die Datenanalyse hat sich in den letzten Jahren massiv verändert, s. Abbildung 2.19.\n\n\n\n\n\nAbbildung 2.19: Forschung früher und heute\n\n\nDiese Entwicklung ist durchaus auch kritisch zu betrachten. Mit der wachsenden Bedeutung von Daten wächst in gleichem Maße die Bedeutung von Datenanalyse. Denn Daten ohne Sinn sind nutzlos. Aus diesem Grund kann man sagen, dass Datenanalyse (und damit auch Statistik als eine spezielle Art von Datenanalyse) zu stark nachgefragten Jobs gehören.\nLaut dem Entgeltatlas der Bundesagentur für Arbeit liegt ein typisches Gehalt von Data Scientisten bei knapp 6000 € pro Monat (in der Altersgruppe von 25 bis 54)9. Laut dem Gehaltsreporter liegt das Einstiegsgehalt dieser Berufsgruppe bei knapp 50.000€ pro Jahr.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#wie-man-mit-statistik-lügt",
    "href": "010-rahmen.html#wie-man-mit-statistik-lügt",
    "title": "\n2  Rahmen\n",
    "section": "\n2.8 Wie man mit Statistik lügt",
    "text": "2.8 Wie man mit Statistik lügt\nDas File-Drawer-Problem: Sie haben ein tolles Experiment durchgeführt, viel Arbeit, viel Stress, endlich geschafft, puh. Von den 20 Variablen (als AV, s. Kapitel 2.5), die Sie untersucht haben, zeigt nur 1 einen interessanten Effekt, leider. 1 von 20, das hört sich nicht so toll an. Wäre es da nicht “elegant”, die 19 Variablen ohne schönen Effekt einfach in der Schublade liegen zu lassen bis zum Sankt-Nimmerleins-Tag? Dann könnten Sie stattdessen als Ergebnis nur die eine Variable mit schönen Ergebnis präsentieren, ganz ohne widersprechende Befunde.\nDieser Versuchung nicht zu erliegen, kann schwer sein. Es ist aber gefährlich, missliebige Ergebnisse zu verschweigen: Die anderen Menschen bekommen dann ein falsches Bild der Ergebnislage; man spricht von Publikationsbias. Wer Ergebnisse verschweig, verzerrt die insgesamte Befundlage (Rothstein, 2014).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#fazit",
    "href": "010-rahmen.html#fazit",
    "title": "\n2  Rahmen\n",
    "section": "\n2.9 Fazit",
    "text": "2.9 Fazit\nDie Aufgabe von Statistik ist es, durch Zusammenfassen von Daten Modelle zu bilden, die es uns einfacher machen, schwierige Sachverhalte zu verstehen. Zentral ist dabei, die Analyse von Variabilität der Daten. Daten kommen in verschiedenen Varianten vor, typischerweise in Tabellenform, möglichst im Tidy-Format.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#aufgaben",
    "href": "010-rahmen.html#aufgaben",
    "title": "\n2  Rahmen\n",
    "section": "\n2.10 Aufgaben",
    "text": "2.10 Aufgaben\n\nvariation01\nDef-Statistik01\ntidy1\nSkalenniveau1a\nZiele-Statistik\nvariation02\nSkalenniveau1b\ntidydata1",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#vertiefung",
    "href": "010-rahmen.html#vertiefung",
    "title": "\n2  Rahmen\n",
    "section": "\n2.11 Vertiefung",
    "text": "2.11 Vertiefung\nFassen Sie den Artikel von Broman & Woo (2018) zusammen.\nInspiration von einer Praktikerin der Datenanalyse: Caitlin Hudon verrät in diesem Video, welche Fehler Sie sie in in den acht Jahren ihrer Berufserfahrung gemacht hat und was sie daraus gelernt hat.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literaturhinweise",
    "href": "010-rahmen.html#literaturhinweise",
    "title": "\n2  Rahmen\n",
    "section": "\n2.12 Literaturhinweise",
    "text": "2.12 Literaturhinweise\nEinen Einblick in die Fundamente statistischer Analyse bietet Stigler (2016). Çetinkaya-Rundel & Hardin (2021), stellen grundlegende Konzepte der Analyse von Daten im Kapitel 1, “Hello data”, vor. Downey (2023) illustriert statistische Überraschungsmoment auf unterhaltsame, und vor allem: sofataugliche Art.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literatur",
    "href": "010-rahmen.html#literatur",
    "title": "\n2  Rahmen\n",
    "section": "\n2.13 Literatur",
    "text": "2.13 Literatur\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization in Spreadsheets. The American Statistician, 72(1), 2–10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nÇetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific Method, Statistical Method and the Speed of Light. Statistical Science, 15(3), 254–278. https://doi.org/10.1214/ss/1009212817\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley StatsRef: Statistics Reference Online. John Wiley & Sons, Ltd. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSchwaiger, E., & Tahir, R. (2022). The Impact of Nomophobia and Smartphone Presence on Fluid Intelligence and Attention. Cyberpsychology: Journal of Psychosocial Research on Cyberspace, 16(1). https://doi.org/10.5817/CP2022-1-5\n\n\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press.\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain Drain: The Mere Presence of One’s Own Smartphone Reduces Available Cognitive Capacity. Journal of the Association for Consumer Research, 2(2), 140–154. https://doi.org/10.1086/691462\n\n\nWickham, H., & Grolemund, G. (2018). R Für Data Science: Daten Importieren, Bereinigen, Umformen, Modellieren Und Visualisieren (F. Langenau, Übers.; 1. Auflage). O’Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#footnotes",
    "href": "010-rahmen.html#footnotes",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "Release 2023-Jan↩︎\nForschung und Entwicklung↩︎\njedenfalls nicht alle von uns↩︎\nund ähnliche Programme↩︎\nCeteris paribus, auf Latein, hört sich gleich viel schlauer an↩︎\nDas ist eine fiktive Geschichte↩︎\n1. Pizza, 2. Spagetthi, 3. Schnitzel↩︎\ndie beiden Begriffe werden hier weitgehend synonym gebraucht↩︎\nAbrufdatum: 1.2.23↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "020-R.html",
    "href": "020-R.html",
    "title": "\n3  Daten einlesen\n",
    "section": "",
    "text": "3.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#lernsteuerung",
    "href": "020-R.html#lernsteuerung",
    "title": "\n3  Daten einlesen\n",
    "section": "",
    "text": "3.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n3.1.2 Lernziele\n\nSie können R und RStudio starten.\nSie können R-Pakete installieren und starten.\nSie können Variablen in R zuweisen und auslesen.\nSie können Daten in R importieren.\nSie können den Begriff Reproduzierbarkeit definieren.\n\n3.1.3 Überblick\nAbbildung 1.2 zeigt Ihnen, wo auf unserer Reise durch die Datenanalyse sich dieses Kapitels verorten lässt.\nAbbildung 3.1 zeigt den typischen Lernverlauf in Zusammenhang mit Datenanalyse (und R) an: Es gibt Höhen und Tiefen. Die wechseln sich ab. Das ist ganz normal!\n\n\n\n\n\nAbbildung 3.1: Life is a roller-coaster. You just have to ride it. Image credit: Allison Horst\n\n\n\nQuelle\n\n\n3.1.4 Ab diesem Kapitel benötigen Sie R\nBitte stellen Sie sicher, dass Sie R rechtzeitig einsatzbereit haben. Weiter unten in diesem Kapitel finden Sie Installationshinweise. Falls Sie dieses Kapitel zum ersten Mal bzw. sich noch nicht mir R auskennen, werden Sie vielleicht einigen Inhalten begegnen, die Sie noch nicht gleich verstehen. Keine Sorge, das ist normal. Mit etwas Übung wird Ihnen bald alles schnell von der Hand ghen.\n\n3.1.5 Benötigte R-Pakete\n\nlibrary(openintro)  # Datensatz `mariokart`\n\n\n3.1.6 Benötigte Daten\nSie benötigen den Datensatz mariokart, der entweder über diese Internetadresse oder über R-Paket openintro importiert werden kann:\n\n3.1.6.1 Import via Download\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n3.1.6.2 Import via R-Paket\n\ndata(mariokart, package = \"openintro\")  # Das Paket muss installiert sein\n\n\n3.1.7 Begleitvideos\nSchauen Sie sich mal in dieser Playlist um, dort finden Sie einige Videos zum Thema R.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errrstkontakt",
    "href": "020-R.html#errrstkontakt",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.2 Errrstkontakt",
    "text": "3.2 Errrstkontakt\n\n3.2.1 Warum R?\nGründe, die für den Einsatz von R sprechen:\n\n🆓 R ist kostenlos, andere Softwarepakete für Datenanalyse sind teuer. 💸\n📖 R und R-Befehle sind quelloffen, d.h. man kann sich die zugrundeliegenden Computerbefehle anschauen. Jede/r kann prüfen, ob R vernünftig arbeitet. Jede/r kann beitragen.\n🆕 R hat die neuesten Methoden.\n🫂 R hat eine große Community.\n🪡 R ist maßgeschneidert für Datenanalyse.\n\nAllerdings gibt es auch abweichende Meinungen, s. Abbildung 3.2.\n\n\n\n\n\nAbbildung 3.2: Manche finden Excel cooler als R, nicht wahr, Bill Gates?\n\n\n\n3.2.2 R und Reproduziebarkeit\n\nDefinition 3.1 (Reproduzierbarkeit) Ein (wissenschaftlicher) Befunde ist reproduzierbar, wenn andere Analystis mit dem gleichen experimentellen Setup zum gleichen Ergebnis (wie in der ursprünglichen Analyse) kommen (Plesser, 2018). \\(\\square\\)\n\n\nDefinition 3.1 ist, etwas überspitzt, in Abbildung 3.3 wiedergegeben.\n\n\n\n🔢 + 🤖 + 🔬 = 🤩\n\n\n\nAbbildung 3.3: Daten + Syntax + genaue Beschreibung der Messungen = reproduzierbar\n\n\n\nBeispiel 3.1 (Aus der Forschung: Reproduzierbarkeit in der Psychologie)  \n\n🧑‍🎓 Wie ist es um unsere Wissenschaft, Psychologie, bestellt? Haben die Befunde Hand und Fuß?\n\nObels et al. (2020) haben die Reproduzierbarkeit in psychologischen Studien untersucht. Sie berichten folgendes Ergebnis\n\nWe examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#architektur-von-r",
    "href": "020-R.html#architektur-von-r",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.3 Architektur von R",
    "text": "3.3 Architektur von R\n\n3.3.1 R & RStudio\n\n\n\n\n\n💖\n\n\n\n\n\nIsmay & Kim (2020) zeigen eine schöne Analogie, was der Unterschied von R und RStudio ist, s. Abbildung 3.4.1\n\n\n\n\n\n\n\nAbbildung 3.4: R vs. RStudio: R macht die Arbeit, RStudio ist für Komfort und Übersicht\n\n\n\n\nWir verwenden beide Programme. Aber wir öffnen nur RStudio. RStudio findet selbständig R und öffnet diese “heimlich”. Öffnen Sie nicht noch extra R (sonst wäre R zweifach geöffnet).\nHier sehen Sie einen Screenshot von der Oberfläche von RStudio, s. Abbildung 3.5.\n\n\n\n\n\nAbbildung 3.5: So sieht RStudio aus\n\n\n\n3.3.2 Posit Cloud\nPosit Cloud2 ist ein Webdienst von Posit/RStudio (zum Teil kostenlos). Man kann damit online mit R arbeiten. Die Oberfläche ist praktisch identisch zur Desktop-Version, s. Abbildung 3.6. Ein Vorteil ist, dass man als Nutzer nichts installieren muss und dass es auch auf Tablets läuft (im Gegensatz zur Desktop-Version von R). Ein Nachteil ist, dass es etwas langsamer ist und nur für ein gewisses Zeitvolumen kostenlos.\n\n\n\n\n\nAbbildung 3.6: So sieht RStudio Cloud aus. Genau wie RStudio Desktop\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Ihr Dozent Ihnen einen Projektordner bzw. einen Link dazu bereitstellt, ist das komfortabel, da der Dozent dann schon Pakete installieren, Daten bereitstellen und andere Nettigkeit vorbereiten kann für Sie. Allerdings müssen Sie den Projektordner in Ihrem Konto abspeichern, wenn Sie etwas speichern möchten, da Sie vermutlich keine Schreibrechte im Projektordner Ihres Dozenten haben. Klicken Sie dazu auf “Save a permanent copy”, s. Abbildung 3.7.\\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 3.7: Einen Projektordner im eigenen Konto abspeichern, um Schreibrechte zu haben\n\n\nSie können auch von der Cloud exportieren, also Ihre Syntaxdatei herunterladen. Klicken Sie dazu im Reiter “Files” auf More &gt; Export ....\n\n3.3.3 Installation\nLesen Sie hier die Installation von R und seiner Freunde nach.\nKurz gesagt: Laden Sie R von der R-Homepage, genannt “CRAN”3 herunter. R wird für alle gängigen Betriebssystem angeboten.\n\n3.3.4 R-Pakete\nTypisch für R ist sein modularer Aufbau: Man kann eine große Zahl an Erweiterungen (“Pakete”, engl. packages) installieren, alle kostenlos. In R Paketen “wohnen” R-Befehle, also Dinge, die R kann, “Skills” sozusagen. Außerdem können in R-Paketen auch Daten bereitgestellt werden. Damit man die Inhalte eines R-Pakets nutzen kann, muss man es zuerst installieren und dann starten.\nMan kann sich daher ein R-Paket vorstellen wie ein Buch: Wenn R es gelesen hat, dann kennt es die Inhalte. Diese Inhalte könnten irgendwelche Formeln, also Berechnungen sein. Es könnte aber die “Bauanleitung” für ein schönes Diagramm sein.\nIst ein spezielles R-Paket auf Ihrem Computer installiert, so können Sie diese Funktionalität nutzen.\nDie Zahl an diesen “Paketen” ist groß; zur Verdeutlichung s. Abbildung 3.8.\n\n\n\n\nViele Pakete\nEs kommen viele dazu\n\n\n\n\n\n\n\n\n(a) Containershiff mit vielen Paketen, Corey Seeman, CC-BY-NC 20, Flickr.com\n\n\n\n\n\n\n\n\n\n(b) Die Anzahl der R-Pakete ist exponenziell gewachsen\n\n\nEs gibt viele R-Pakete.\n\n\n\n\n\nAbbildung 3.8\n\n\nErweiterungen kennt man von vielen Programmen, sie werden auch Add-Ons, Plug-Ins oder sonstwie genannt. Man siehe zur Verdeutlichung Erweiterungen beim Broswer Chrome, Abbildung 3.9.\n\n\n\n\n\nAbbildung 3.9: Erweiterungen beim Browser Chrome\n\n\nDie Anzahl der R-Pakete ist groß; allein auf dem “offiziellen Web-Store” (nennt sich “CRAN”) von R gibt es ca. 20,000 Pakete (vgl. Abbildung 3.8 (b)); Stand: 2022; Quelle). Und es kommen immer mehr dazu.\n\n3.3.4.1 Pakete installieren\nWie jede Software muss man Pakete (Erweiterungen für R) erst einmal installieren, bevor man sie verwenden kann. Ja, einmal installieren reicht.\nDas geht komfortabel, wenn man beim Reiter Packages auf Install klickt (s. Abbildung 3.10) und dann den Namen des zu installierenden Pakets eingibt.\n\n\n\n\n\n\n\n\n\n(a) Klicken Sie auf “Install” im Reiter “Packages”, um R-Pakete zu installieren\n\n\n\n\n\n\n\n\n\n(b) So kann man R-Pakete installieren in RStudio\n\n\n\n\n\n\nAbbildung 3.10: So installiert man Pakete in R.\n\n\nDann öffnet sich ein Menü, wo man die Namen der gewünschten R-Pakete eingeben kann (s. Abbildung Abbildung 3.11).\n\n\n\n\n\nAbbildung 3.11: Hier den oder die Namen der gewünschten R-Pakete eingeben\n\n\n\n🧑‍🎓Welche R-Pakete sind denn schon installiert?\n\nIm Reiter Packages können Sie nachschauen, welche Pakete auf Ihrem Computer schon installiert sind. Diese Pakete brauchen Sie logischerweise dann nicht noch mal installieren, s. Abbildung 3.12.\n\n\n\n\n\nAbbildung 3.12: So sehen Sie, ob ein R-Paket auf Ihrem System installiert ist\n\n\n\n🧑‍🎓Ja, aber welche R-Pakete “soll” ich denn installieren, welche brauch ich denn?\n\nIm Moment sollten Sie die folgenden Pakete installiert haben:\n\ntidyverse\neasystats\n\nWenn Sie die noch nicht installiert haben sollten, dann können Sie das jetzt ja nachholen.4\n\n\n\n\n\n\nHinweis\n\n\n\nIhre R-Pakete sollten aktuell sein. Klicken Sie beim Reiter Packages auf “Update”, um Ihre R-Pakete zu aktualisieren. Arnold Schwarzenegger rät, Ihre R-Pakete aktuell zu halten, s. Abbildung 3.13.\n\n\n\n\n\n\n\nAbbildung 3.13: R-Pakete sollten stets aktuell sein, so Arnold Schwarzenegger\n\n\n\nmade at https://imgflip.com/memegenerator\n\n\n\n\n\n\n\nVorsicht\n\n\n\nBevor Sie ein R-Paket (oder überhaupt irgendwelche Software) installieren/updaten, sollten Sie das R-Paket schließen/beenden. Sonst schrauben Sie an einem elektrischen Gerät herum, das noch unter Strom steht (nicht gut). Die einfachste Art, alle Pakete zu beenden ist, Session &gt; Restart R zu klicken (in RStudio).\\(\\square\\)\n\n\n\n3.3.4.2 Pakete updaten\nKlicken Sie im Reiter Packages (in RStudio) und dort auf den Button Update.5\nDenken Sie daran, dass Sie das Paket, das Sie updaten/installieren, nicht laufen darf.\n\n3.3.4.3 Pakete starten\nWenn Sie ein Softwareprogramm - nichts anderes sind R-Pakete - installiert haben, müssen Sie es noch starten.\nMerke: Ein bestimmtes Paket muss man nur einmalig installieren. Aber man muss es jedes Mal neu starten, wenn man R (bzw. RStudio) startet.\nSie erkennen leicht, ob ein Paket gestartet ist, wenn Sie ein Häkchen vor dem Namen des Pakets in der Paketliste (Reiter Packages) sehen, s. Abbildung Abbildung 3.10 (a).\nDieses Video verdeutlicht den Unterschied zwischen Installation und Starten eines R-Pakets.\n\n3.3.5 Projekte in R\nEin Projekt in RStudio (s. Abbildung 3.14) ist letztlich ein Ordner, der als “Basis” für eine Reihe von Dateien verwendet wird. Sagen wir, das Projekt heißt cool_stuff. RStudio legt uns diesen Ordner an einem von uns gewählten Platz auf unserem Computer an. Das ist ganz praktisch, weil man dann sagen kann “Hey R, nimmt die Datei ‘daten.csv’”, ohne einen Pfad anzugeben. Vorausgesetzt, die Datei liegt auch im Projektordner (cool_stuff).\nProjekte kann anlegen mit Klick auf das Icon, das einen Quader mit dem Buchstaben R darin anzeigt (s. Abbildung 3.14 (a)). RStudio-Projekte machen Ihr Leben leichter (s. Abbildung 3.14).\n\n\n\n\n\n\n\n\n\n(a) RStudio-Projekte, Beispiele\n\n\n\n\n\n\n\n\n\n(b) RStudio-Projekte sind viel sicherer als das Arbeitsverzeichnis von Hand zu wählen oder mit Pfaden herumzubasteln. Image credit: Allision Horst\n\n\n\n\n\n\nAbbildung 3.14: Nutzen Sie RStudio-Projekte, das macht Ihr Leben leichter.\n\n\n\n3.3.6 Skriptdateien\nDie R-Befehle (“Syntax”) schreiben Sie am besten in eine speziell dafür vorgesehene Textdatei in RStudio. Eine Sammlung von (R-)Computer-Befehlen nennt man auch ein Skript, daher spricht man auch von einer Skriptdatei.\n\n3.3.6.1 So öffnen Sie eine neue Skriptdatei\nUm eine neue R-Skriptdatei zu öffnen, klicken Sie auf das Icon, das ein weißes Blatt mit einem grünen Pluszeichen zeigt, s. Abbildung 3.15.\n\n\n\n\n\n\n\n\n\n(a) So erstellen Sie eine neue Skriptdatei\n\n\n\n\n\n\n\n\n\n(b) Klicken Sie auf das Icon mit dem leeren Blatt und dem grünen Plus\n\n\n\n\n\n\nAbbildung 3.15: Es gibt verschiedene Wege, um eine neue R-Skript-Datei in RStudio zu öffnen.\n\n\n\n3.3.6.2 So speichern Sie Ihre Skripdatei\nVergessen Sie nicht zu speichern, wenn Sie ein tolles Skript geschrieben haben. Dafür gibt es mehrere Möglichkeiten:\n\nStrg+S\nMenü: File &gt; Save\nKlick auf das Icon mit der Diskette, s. Abbildung 3.15.\n\n3.3.6.3 So öffnen Sie eine Skriptdatei\nEine Skriptdatei können Sie in typischer Manier öffnen:\n\nStrg+O\nKlick auf das Icon mit der Akte und dem grünen Pfeil (vgl. Abbildung 3.15)\nMenü: File &gt; Open File...\n\n\n3.3.7 Quarto-Dokumente\nQuarto ist ein Programm zum Erstellen von Texten, in das man R-Syntax einfügen kann. Die Ausgaben der R-Befehle werden dann direkt im Dokument eingebunden. Abbildung 3.16 zeit ein Beispiel für ein Quarto-Dokument.\n\n\n\n\n\n\nHinweis\n\n\n\nQuarto ist eine komfortable und leistungsfähige Methode, um Dokumente mit R-Syntax zu schreiben. Sie sind aber nicht verpflichtet, Quarto zu nutzen. Stattdessen können Sie Ihre Syntax auch in Skriptdateien schreiben. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 3.16: Dokumente schreiben mit Quarto\n\n\nWenn Sie Quarto nutzen möchten, müssen Sie es zunächst installieren, d.h. herunterladen. Dann können Sie in RStudio Quarto-Dateien erstellen.\nEin neues Quarto-Dokument können Sie erstellen mit Klick auf File &gt; New File &gt; Quarto Document ….\nDieses Video gibt Ihnen Einstieg in Quarto.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errisch-für-einsteiger",
    "href": "020-R.html#errisch-für-einsteiger",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.4 Errisch für Einsteiger",
    "text": "3.4 Errisch für Einsteiger\n\n\n\n\n\n\nHinweis\n\n\n\nR ist penibel: So sind name und Name zwei verschiedene Variablen für R. Groß- und Kleinschreibung wird von R genau beachtet! Hingegen ist es R egal, ob Sie zur besseren Übersichtlichkeit Leerzeichen in Ihre Syntax tippen. Ausnahme sind spezielle Operatoren wie &lt;- oder &lt;=.\nEine gute Nachricht: Wenn R etwas von WARNING (bzw. Warnung) sagt, können Sie das zumeist ignorieren. Eine Warnung ist kein Fehler (ERROR) und meistens nicht gravierend oder nicht dringend. Im Zweifel ist Googeln eine gute Idee. Nur wenn R von Error spricht, ist es auch ein Fehler.\\(\\square\\)\n\n\n\n3.4.1 Variablen\nIn jeder Programmiersprache kann man Variablen definieren, so auch in R:\n\nrichtige_antwort = 42\nfalsche_antwort = 43\ntyp = \"Antwort\"\nist_korrekt = TRUE\n\nAlternativ zum Gleichheitszeichen = können Sie auch (synonym) den Zuweisungspfeil &lt;- verwenden. Beides führt zum gleichen Ergebnis. Allerdings ist der Zuweisungspfeil präziser, und sollte daher bevorzugt werden.\nDer Zuweisungspfeil &lt;- bzw. das Gleichheitszeichen = definiert eine neue Variable (oder überschreibt den Inhalt, wenn die Variable schon existiert).\n\nrichtige_antwort &lt;- 42\nfalsche_antwort &lt;- 43\ntyp &lt;- \"Antwort\"\nist_korrekt &lt;- TRUE\n\nDieses Video und dieses Video geben eine Einführung in das Definieren von Variablen in R.\nSie können sich eine Variable wie einen Becher oder Behälter vorstellen, der bestimmte Werte enthält. Auf dem Becher steht (mit Edding geschrieben) der Name des Bechers. Natürlich können Sie die Werte aus dem Becher entfernen und sie durch neue ersetzen (vgl. Abbildung 3.17).\n\n\n\n\n\nAbbildung 3.17: Variablen zuweisen\n\n\nR kann übrigens auch rechnen. Probieren Sie es doch gleich mal hier aus!\n\ndie_summe &lt;- falsche_antwort + richtige_antwort\n\nAber was ist jetzt der Wert, der “Inhalt” der Variable die_summe?\nUm den Wert, d.h. den Inhalt einer Variablen in R auszulesen, geben wir einfach den Namen des Objekts ein:\n\ndie_summe\n## [1] 85\n\nWas passiert wohl, wenn wir die_summe jetzt wie folgt definieren?\n\ndie_summe &lt;- falsche_antwort + richtige_antwort + 1\n\nWer hätt’s geahnt:\n\ndie_summe\n## [1] 86\n\nVariablen können auch “leer” sein:\n\nalter &lt;- NA\nalter\n## [1] NA\n\nNA steht für not available, nicht verfügbar und macht deutlich, dass hier ein Wert fehlt.\n\n🧑‍🎓 Wozu brauche ich bitte fehlende Werte?!\n\nFehlende Werte sind ein häufiges Problem in der Praxis. Vielleicht hat sich die befragte Person geweigert, ihr Alter anzugeben6. Oder als Sie die Daten in Ihren Computer eingeben wollten, ist Ihre Katze über die Tastatur gelaufen und alles war futsch…\n\n3.4.2 Funktionen (“Befehle”)\nDas, was R kann, ist in “Funktionen” hinterlegt. Genauer gesagt ist “Befehl” eine Funktion.\n\nDefinition 3.2 (Funktion) Eine Funktion ist eine Regel, die jedem Eingabewert (auch Argument genannt) einen Ausgabewert zuordnet. Man kann sich Funktionen als Maschinen vorstellen, die Eingabedaten in Ausgabedaten umwandeln, vgl. Abbildung 3.18. \\(\\square\\)\n\n\n3.4.2.1 Eine erste Funktion: Vektoren erstellen\nEin Beispiel für eine solche Funktion könnte sein: “Berechne den Mittelwert dieser Datenreihe” (schauen wir uns gleich an).\nDas geht so:\n\nAntworten &lt;- c(42, 43)\n\nDer Befehl c (c wie combine) fügt mehrere Werte zusammen zu einer “Liste” (einem Vektor).7\n\nDefinition 3.3 Als Vektor bezeichnen wir eine geordnete Folge von Werten. In R kann man sie mit der Funktion c() erstellen. Die Werte eines Vektors bezeichnet man als Elemente. \\(\\square\\)\n\nMit dem Zuweisungspfeil geben wir diesem Vektor einen Namen, hier Antworten. Dieser Vektor besteht aus zwei Werten, zuerst 42, dann kommt 43.\n\nBeispiel 3.2 (Beispiele für Vektoren) Vektoren können (praktisch) beliebig lang sein, z.B. drei Elemente.\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 3)  # x und y sind ungleich (Reihenfolge der Werte)\nz &lt;- c(3.14, 2.71)  \nnamen &lt;- c(\"Anni\", \"Bert\", \"Charli\") # Text-Vektor\n\n\nZwei wichtige Typen von Vektoren sind numerische Vektoren (reelle Zahlen; in R auch als numeric oder double bezeichnet) und Textvektoren, in R auch als String oder character bezeichnet.\n\nBeispiel 3.3 Weitere Beispiel für Funktionen sind:\n\n“Erstelle eine Liste (Vektor) von Werten”.\n“Lade dieses R-Paket.”\n“Gib den größten Wert dieser Datenreihe aus.” \\(\\square\\)\n\n\n\n\n3.4.3 Unsere erste statistische Funktion\nJetzt wird’s ernst. Jetzt kommt die Statistik. 🧟 Berechnen wir also unsere erste statistische Funktion: Den Mittelwert. Puh.\n\nmean(Antworten)\n## [1] 42.5\n\nSie hätten Antworten auch durch c(42, 43) ersetzen können, so haben Sie ja schließlich die Variable gerade definiert.\nR arbeitet so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: mean(Antworten)\n  ⬇️ \nSchritt 1: mean(c(42, 43))\n  ⬇️ \nSchritt 2: 42.5\n\n3.4.3.1 Schema einer Funktion\nAbbildung 3.18 stellt eine Funktion schematisch dar.\n\n\n\n\n\nAbbildung 3.18: Schema einer Funktion\n\n\n\n3.4.3.2 Argumente einer Funktion\nEine Funktion hat einen oder mehrere Inputs, das sind Daten oder Verarbeitungshinweise, die man in die Funktion fun eingibt, bevor sie loslegt. Eine Funktion hat immer (genau) eine Ausgabe (Output), in der das Ergebnis einer Funktion ausgegeben wird.\n\nDefinition 3.4 (Argumente einer Funktion) Die “Trichter” einer (R-)Funktion, in denen man die Eingaben “einfüllt”, nennt man auch Argumente.\\(\\square\\)\n\nSo hat die Funktion mean() z.B. folgende Argumente, s. Listing 3.1.\n\n\nListing 3.1: Die Argumente der R-Funktion mean\n\n\nmean(x, trim = 0, na.rm = FALSE, ...)\n\n\n\n\n\n\nx: das ist der Vektor, für den der Mittelwert berechnet werden soll\n\ntrim = 0: Sollen die extremsten Werte von x lieber “abgeschnitten” werden, also nicht in die Berechnung des Mittelwerts einfließen?\n\nna.rm = FALSE: Wie soll mit fehlenden Werten NA umgegangen werden? Im Standard liefert mean8 NA zurück. R schwenkt sozusagen die rote Fahne, um zu signalisieren, Achtung, Mensch, hier ist irgendwas nicht in Ordnung. Setzt man aber na.rm = TRUE, dann entfernt (remove, rm) R die fehlenden Werte und berechnet den Mittelwert.\n\n... heißt “sonstiges Zeugs, das manchmal eine Rolle spielen könnte”; darum kümmern wir uns jetzt nicht.\n\nEinige Argumente haben einen Standardwert bzw. eine Voreinstellung (engl. default). So wird bei der Funktion mean im Standard nicht getrimmt (trim = 0) und fehlende Werte werden nicht entfernt (na.rm = FALSE).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn ein R-Befehl ein Argument mit Voreinstellung hat, brauchen Sie dieses Argument nicht zu befüllen. In dem Fall wird auf den Wert der Voreinstellung zurückgegriffen. Argumente ohne Voreinstellung - wie x bei mean() - müssen Sie aber auf jeden Fall mit einem Wert befüllen. Man würde also mean zumeist so aufrufen: mean(x). \\(\\square\\)\n\n\nBei jedem R-Befehl haben die Argumente eine bestimmte Reihenfolge, etwa bei mean(): mean(x, trim = 0, na.rm = FALSE, ...).\n(Nur) wenn man die Argumente in ihrer vorgegebenen Reihenfolge anspricht, muss man nicht den Namen des Arguments anführen:\n✅ mean(Antworten, 0, FALSE)\nHält man sic aber nicht an die vorgebene Reihenfolge, so weiß R nicht, was zu tun ist und flüchtet sich in eine Fehlermeldung:\n\nmean(Antworten, FALSE, 0)  # FALSCH, DON'T DO IT 🙅‍♀️\n## Error in mean.default(Antworten, FALSE, 0): 'trim' must be numeric of length one\n\nWenn man die Namen der Argumente anspricht, ist die Reihenfolge egal:\n\nmean(na.rm = FALSE, x = Antworten)  # ok\nmean(trim = 0, x = Antworten, na.rm = TRUE)  # ok\n\nÜbrigens: Leerzeichen sind R fast immer egal. Aus Gründen der Übersichtlichkeit sollte man aber Leerzeichen verwenden. In diesen Fällen sind Leerzeichen nicht erlaubt:\n\n&lt;-\n\n&lt;= etc.\nVariablennamen\n\n3.4.3.3 Achtung bei fehlenden Werten\nSagen wir, wir haben einen fehlenden Wert in unseren Daten:\n\nAntworten &lt;- c(42, 43, NA)\nAntworten\n## [1] 42 43 NA\n\nWenn wir jetzt den Mittelwert berechnen wollen, quittiert R das mit einem schnöden NA. NA steht für not available, ist also ein Hinweis, dass Werte fehlen.\n\nmean(Antworten)\n## [1] NA\n\nR meint es gut mit Ihnen9. Stellen Sie sich vor, dass R Sie auf dieses Problem aufmerksam machen möchte:\n\n🤖 Achtung, lieber Herr und Gebieter, du hast nicht mehr alle Latten am Zaun, will sagen, alle Daten im Vektor!\n\n(Danke, R.)\nMöchten Sie aber lieber R dieses Verhalten austreiben, so befüllen Sie das Argument na.rm mit dem Wert TRUE.10\n\nmean(Antworten, na.rm = TRUE)\n## [1] 42.5\n\n\nÜbungsaufgabe 3.1 (Geben Sie lustige Bedeutungen an, was “NA” noch bedeuten könnte!)  \n\n🤖 Wie wäre es mit “nebulöse Anomalie” oder “nix-checkender Angeber” oder “nölender Automat”.\n\n\n🧑‍🎓 Hm…\n\n\\(\\square\\)\n\n\n3.4.4 Vektorielles Rechnen\n\nDefinition 3.5 Das Rechnen mit Vektoren in R bezeichnen wir als vektorielles Rechnen. \\(\\square\\)\n\nVektorielles Rechnen ist ein praktische Angelegenheit, man kann z.B. folgende Dinge einfach in R ausrechnen.\nGegeben sei x als Vektor (1, 2, 3). Dann können wir die Differenz (Abweichung) jedes Elements von x zum Mittelwert von x komfortabel so ausrechnen:\n\nx - mean(x)\n## [1] -1  0  1\n\nEtwas fancier ausgedrückt: Wir haben die Funktion mit Namen “Differenz” (“Minus-Rechnen”) auf jedes Element von x angewandt. Im Einzelnen haben wir also folgenden drei Differenzen ausgerechnet:\n\n1 - 2\n2 - 2\n3 - 2\n\n\n\n\n\n\n\n\nAbbildung 3.19: Schema des vektoriellen Rechnens: Eine Funktion wird auf jedes Elemnt eines Vektors angewandt\n\n\n\n\n\n3.4.5 R-Quiz\n\nÜbungsaufgabe 3.2 Ihre R-Muskeln sind gestählt? 💪 Noch nicht so ganz ausdefiniert? 😤 Macht nichts! Trainieren Sie sich mit diesem Quiz!\n\n\n3.4.6 Häufige R-Fragen\n\n\nWo finde ich Hilfe zu einer bestimmten Funktion, z.B. fun()? Geben Sie dazu folgenden R-Befehl ein: help(fun).\n\nWenn ich ein R-Paket installiere, fragt mich R manchmal, ob ich auch Pakete installieren, will, die “kompiliert” werden müssen. Soll ich das machen?. Nein, das ist nicht nötig; geben Sie “no” ein.\n\nIn welchem Paket wohnt meine R-Funktion? Suchen Sie nach der Funktion auf dieser Seite.\n\nIch weiß nicht, wie der R-Befehl funktioniert! Vermutlich haben andere Ihr Problem auch, und meistens hat irgendwer das Problem schon gelöst. Am besten suchen Sie mal auf Stackoverflow.\n\nIch muss mal grundlegend verstehen, wozu ein bestimmten R-Paket gut ist. Was tun? Lesen Sie die Dokumenation (“Vignette”) eines R-Pakets durch. Für das Paket dplyr bekommen Sie so einen Überblick über die verfügbaren Vignetten diese Pakets: vignette(package = \"dplyr\"). Dann suchen Sie sich aus der angezeigten Liste eine Vignette raus; mit vignette(\"rowwise\") können Sie sich dann die gewünschte Vignette (z.B. rowwise) anzeigen lassen.\n\nOh nein, ich seh rot, das heißt, R zeigt mir irgendwas in roter Schrift an. Ist jetzt was kaputt? Keine Sorge, R ist in seiner Ausgabe nicht sparsam mit roter Frabe. Solange es nicht als Fehlermeldung (ERROR) erscheint, ist es meist kein Problem.\n\nR hat sich aufgehängt oder bringt einen Fehler an einer Stelle, wo sonst alles funktioniert hat. Probieren Sie auf jeden Fall mal das AEG-Prinzip (Aus-Ein-Gut): sprich R neu starten.\n\nIch suche schon seit einer Stunde einen Fehler und find ihn nicht. Ich habe schon verschiedene Gegenstände vor Wut an die Wand geworfen. Was soll ich tun? Machen Sie eine Pause. Doch, das ist ernst gemeint. Meine Erfahrung: Mit etwas Abstand wird der Kopf klarer und man findet das Problem viel einfacher.11\n\n\n3.4.7 Hilfe?! Erbie!\nR will nicht, so wie Sie wollen? Sie haben das Gefühl, R verweigert störrisch den Dienst, vermutlich rein aus Boshaftigkeit, rein um Sie zu ärgern? Ausführliches Googeln und ChatGPT befragen hat keine Lösung gebracht? Kurz, Sie brauchen die Hilfe eines kundigen Menschens?12\nHier finden Sie eine Anleitung, wie man seinen Hilfeschrei so formuliert (ruft), dass er nicht nur gehört, sondern auch verstanden wird und einen anderen Menschen veranlasst und ermöglicht Ihnen zu helfen.\nAlso: Sie müssen Ihr Problem nachvollziehbar aber prägnant formulieren. Das nennt man auch ein ERBie, ein einfaches, reproduzierbare Beispiel Ihres Problems mit (R-)Syntax:\n\neinfach: die einfachste Syntax, die Ihr Problem bzw. die Fehlermeldung produziert. Es bietet sich an, einen einfachen, allgemein bekannten Datensatz zu verwenden, etwa mtcars\n\nreproduzierbar: Code (z.B. als Textdatei oder in einem Post), der die Fehlermeldung entstehen lässt\n\n\nBeispiel 3.4 (Beispiel für ein Erbie) Problem: Ich verstehe nicht, warum eine Fehlermeldung kommt\nZiel: Ich möchte die Automatikautos filtern (am = 0)\nWas ich schon versucht habe: Ich habe folgende Posts gelesen …, aber ohne Erfolg\nErbie:\n\ndata(mtcars)\nlibrary(dplyr)  # nicht \"tidyverse\", denn \"dplyr\" reicht\n\nmtcars %&gt;% \n  filter(am = 0)  # den kürzesten Code, der Ihren Fehler entstehen lässt!\n## Error in `filter()`:\n## ! We detected a named input.\n## ℹ This usually means that you've used `=` instead of `==`.\n## ℹ Did you mean `am == 0`?\n\nsessionInfo()  # gibt Infos zur R-Version etc. aus\n## R version 4.2.1 (2022-06-23)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur ... 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] see_0.8.0          report_0.5.7       parameters_0.21.3  performance_0.10.8\n##  [5] modelbased_0.8.6   insight_0.19.6     effectsize_0.8.6   datawizard_0.9.0  \n##  [9] correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0    lubridate_1.9.3   \n## [13] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.3        purrr_1.0.2       \n## [17] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.4     \n## [21] tidyverse_2.0.0    knitr_1.45        \n## \n## loaded via a namespace (and not attached):\n##  [1] mvtnorm_1.2-2      lattice_0.21-8     png_0.1-8          zoo_1.8-12        \n##  [5] digest_0.6.33      utf8_1.2.3         R6_2.5.1           evaluate_0.21     \n##  [9] coda_0.19-4        pillar_1.9.0       rlang_1.1.1        multcomp_1.4-25   \n## [13] rstudioapi_0.15.0  Matrix_1.5-4.1     rmarkdown_2.25     labeling_0.4.3    \n## [17] textshaping_0.3.6  splines_4.2.1      htmlwidgets_1.6.2  munsell_0.5.0     \n## [21] compiler_4.2.1     xfun_0.40          systemfonts_1.0.4  pkgconfig_2.0.3   \n## [25] htmltools_0.5.6.1  tidyselect_1.2.0   codetools_0.2-19   fansi_1.0.5       \n## [29] tzdb_0.4.0         withr_2.5.2        MASS_7.3-60        grid_4.2.1        \n## [33] jsonlite_1.8.7     xtable_1.8-4       gtable_0.3.4       lifecycle_1.0.3   \n## [37] magrittr_2.0.3     scales_1.2.1       estimability_1.4.1 cli_3.6.1         \n## [41] stringi_1.7.12     farver_2.1.1       ragg_1.2.5         generics_0.1.3    \n## [45] vctrs_0.6.4        sandwich_3.0-2     TH.data_1.1-2      tools_4.2.1       \n## [49] glue_1.6.2         hms_1.1.3          emmeans_1.8.9      fastmap_1.1.1     \n## [53] survival_3.5-5     yaml_2.3.7         timechange_0.2.0   colorspace_2.1-0\n\nMit dem Paket reprex kann man sich R-Syntax schön formuliert ausgeben lassen. Das ist perfekt, um den Code dann in einem Forum (oder Mail) einzustellen. Dafür müssen Sie nur den Code auswählen, Strg-C drücken und dann reprex::reprex ausführen. Mit Strg-V können Sie die schön formatierte Syntax (sowie die Ausgabe, auch schön formatiert) dann irgendwohin pasten.\n\n\n\n\n\nvia GIFER\n\n\n\n\n\n\n\n\nTipp\n\n\n\nPosten Sie Ihr Erbie bei https://gist.github.com/ als “public gist”. Hier ist ein Beispiel.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#daten-importieren",
    "href": "020-R.html#daten-importieren",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.5 Daten importieren",
    "text": "3.5 Daten importieren\n\n3.5.1 Wo sind meine Daten?\nDamit Sie eine Datendatei importieren können, müssen Sie wissen, wo die Datei ist. Schauen wir uns zwei Möglichkeiten an, wo Ihre Datei liegen könnte.\n\nIrgendwo im Internet, z.B. hier\n\nIrgendwo auf Ihrem Computer, z.B. in Ihrem Projektordner\n\nIn beiden Fällen wird der “Aufenthaltsort” der Datei durch den Pfad13 und den Namen der Datei definiert.\n\n\n\n\n\n\nHinweis\n\n\n\nWir werden in diesem Kurs häufiger mit dem Daten mariokart arbeiten; Sie finden ihn hier.14\n\n\n\n3.5.2 Gebräuchliche Datenformate\nDaten werden in verschiedenen Formaten im Computer abgespeichert; Tabellen häufig als\n\nExcel-Datei\nCSV-Datei\n\nIn der Datenanalyse ist das gebräuchlichste Format für Daten in Tabellenform die CSV-Datei. Das hat den Grund, weil dieses Format technisch schön einfach ist. Für uns Endverbraucher tut das nichts groß zur Sache, die CSV-Datei beherbergt einfach eine brave Tabelle in einer Textdatei, sonst nichts.\n\nÜbungsaufgabe 3.3 (CSV-Datei von innen) 🏋️‍♀️ Öffnen Sie mal eine CSV-Datei mit einem Texteditor (nicht mit Word und auch nicht mit Excel). Schauen Sie sich gut an, was Sie dort sehen und erklären Sie die Datenstruktur. \\(\\square\\)\n\nIn diesem Buch werden wir mit einem Datensatz namens mariokart arbeiten; hallo Mario (s. Abbildung 3.20)!\n\n\n\n\n\nAbbildung 3.20: Hallo, Mario\n\n\n Download \n\n3.5.3 Einlesen aus einem R-Paket\nIhr Datensatz schon in einem R-Paket gespeichert, können Sie ihn aus diesem R-Paket starten. Das ist die bequemste Option. Zum Beispiel “wohnt” der Datensatz mariokart im R-Paket openintro.\n\n\n\n\n\n\nTipp\n\n\n\nEin häufiger Fehler ist, dass man vergisst, dass man zuerst ein R-Paket installieren muss, bevor man es nutzen kann. Auf der anderen Seite muss man ein R-Paket (wie andere Software auch) nur ein Mal installieren - das Paket muss man ein Paket nach jedem Neustart von RStudio mit library() starten.\n\n\n\ndata(\"mariokart\", package = \"openintro\")\n\n\n3.5.4 Einlesen von einer Webseite\nHier ist eine Möglichkeit, Daten (in Form einer Tabelle) von einer Webseite (URL) in R zu importieren:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nEs ist egal, welchen Namen Sie der Tabelle geben. Ich nehme oft d, d die Daten. Außerdem ist d kurz, muss man nicht so viel tippen.\nWerfen wir einen Blick in die Tabelle (engl. to glimpse):\n\nglimpse(d)\n## Rows: 143\n## Columns: 12\n## $ id          &lt;dbl&gt; 150377422259, 260483376854, 320432342985, 280405224677, 17…\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7…\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, …\n## $ cond        &lt;fct&gt; new, used, new, new, new, new, used, new, used, used, new,…\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9…\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00…\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47…\n## $ ship_sp     &lt;fct&gt; standard, firstClass, firstClass, standard, media, standar…\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,…\n## $ stock_photo &lt;fct&gt; yes, yes, no, yes, yes, yes, yes, yes, yes, no, yes, yes, …\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2…\n## $ title       &lt;fct&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW …\n\nHier findet sich eine Erklärung des Datensatzes.\n\n\nDownload einer Datendatei (CSV-Format) von einer Webseite\n\n\n3.5.5 Importieren von Ihrem Computer\nStellen Sie zuerst sicher, dass sich die Datendatei in Ihrem RStudio-Projektordner befindet. Dann können Sie die Datei einfach so importieren:\n\nd &lt;- read.csv(\"mariokart.csv\")\n\nDieses Video erklärt die Schritte des Importierens einer Datendatei von Ihrem Computer.\n\n\n\n\n\n\nHinweis\n\n\n\nEs gibt verschiedene Formate, in denen (Tabellen-)Dateien in einem Computer abgespeichert werden. Die gebräuchlichsten sind CSV und Excel. Es gibt auch mehrere R-Befehle, um Daten in R zu importieren, z.B. read.csv() oder data_read(). Praktischerweise kann der R-Befehl data_read() viele verschiedene Formate automatisch einlesen, so dass wir uns nicht weiter um das Format kümmern brauchen. Der Vorteil von read.csv ist, dass Sie kein Extra-Paket installiert bzw. gestartet haben müssen.\n\n\n\n3.5.6 Dataframes\nEine in R importierte Tabelle (mit bestimmten Eigenschaften) heißt Dataframe. Dataframes sind in der Datenanalyse von großer Bedeutung.\n\nDefinition 3.6 (Dataframe) Ein Dataframe (data frame; auch “Tibble” genannt15) ist ein Datenobjekt in R zur Darstellung von Tabellen. Dataframes bestehen aus einer oder mehreren Spalten. Spalten haben einen Namen, sozusagen einen “Spaltenkopf”. Alle Spalten müssen die gleiche Länge haben; anschaulich gesprochen ist eine Tabelle (in R) rechteckig. Jede Spalte einzeln betrachtet kann als Vektor aufgefasst werden. \\(\\square\\)\n\nTabelle 2.2 ist die Tabelle mit den Mariokart-Daten; etwas präziser gesprochen ein Dataframe mit Namen mariokart. Übrigens ist Tabelle 2.2 in Normalform (Tidy-Format), vgl. Definition 2.9.\n\n\n\n\n\n\nHinweis\n\n\n\nGeben Sie den Namen eines Dataframes ein, um sich den Inhalt anzeigen zu lassen. Beachten Sie, dass Sie die Daten auf diese Weise nur anschauen, nicht ändern können. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n3.5.7 Tabellen in R betrachten\nWenn Sie in R z.B. die Tabelle mariokart in einer Excel-typischen Ansicht betrachten wollen, klicken Sie am besten auf das Tabellen-Icon im Reiter Environment, gleich neben dem Namen mariokart, s. Abbildung 3.21.\n\n\n\n\n\nAbbildung 3.21: Per Klick auf das Tabellen-Icon können Sie eine Tabellenansicht der Tabelle mariokart öffnen\n\n\nAlternativ öffnet der Befehl View(mariokart) die gleiche Ansicht.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-logic",
    "href": "020-R.html#sec-logic",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.6 Logikprüfung",
    "text": "3.6 Logikprüfung\n\n🧑‍🎓 Wer will schon wieder wen prüfen?!\n\nIn diesem Abschnitt schauen wir uns Logikprüfungen an: Wir lassen R prüfen, ob eine Variable einen bestimmten Wert hat oder größer/kleiner als ein Referenzwert ist.\nDefinieren wir zuerst eine Variable, x.\n\nx &lt;- 42\n\nDann fragen wir R, ob diese Variable den Wert 42 hat.\n\nx == 42\n## [1] TRUE\n\n\n🤖 Hallo, Mensch. Ja, diese Variable hat den Wert 42.\n\n(Danke, R.)\nMöchte man mit R prüfen, ob eine Variable x einen bestimmten Wert (“Inhalt”) hat, so schreibt man:\nx == Wert.\n\n\n\n\n\n\nWichtig\n\n\n\nMan beachte das doppelte Gleichheitszeichen. Zur Prüfung auf Gleichheit muss man das doppelte Gleichheitszeichen verwenden.\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEin beliebter Fehler ist es, bei der Prüfung auf Gleichheit, nur ein Gleichheitszeichen zu verwenden, z.B. so: x = 73. Mit einem Gleichheitszeichen prüft man aber nicht auf Gleichheit, sondern man definiert die Variable oder bestimmt ein Funktionsargument, s. Kapitel 3.4.1. \\(\\square\\)\n\n\nTabelle 3.1 gibt einen Überblick über wichtige Logikprüfungen in R.\n\n\n\nTabelle 3.1: Logische Prüfungen in R\n\n\n\n\n\n\nPrüfung.auf\nR-Syntax\n\n\n\nGleichheit\nx == Wert\n\n\nUngleichheit\nx != Wert\n\n\nGrößer als Wert\nx &gt; Wert\n\n\nGrößer oder gleich Wert\nx &gt;= Wert\n\n\nKleiner als Wert\nx &lt; Wert\n\n\nKleiner oder gleich Wert\nx &lt;= Wert\n\n\nLogisches UND\n(x &lt; Wert1) & (x &gt; Wert2)\n\n\nLogisches ODER\n(x &lt; Wert1) | (x &gt; Wert2)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#praxisbezug",
    "href": "020-R.html#praxisbezug",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.7 Praxisbezug",
    "text": "3.7 Praxisbezug\n\n🧑‍🎓Wird R in der Praxis wirklich genutzt? Oder ist R nur der Traum von (vielleicht verwirrten) Profs im Elfenbeinturm?\n\nSchauen wir uns dazu die Suchanfragen bei stackoverflow.com an, dem größten FAQ-Forum für Software-Entwicklung. Wir vergleichen Suchanfragen mit dem Tag [r] zu Suchanfragen mit dem Tag [spss]16. Die Ergebnisse sind in Abbildung Abbildung 3.22 dargestellt.\n\n\n\n\n\n\n\nAbbildung 3.22: Suchanfragen nach R bzw SPSS, Stand 2022-02-24\n\n\n\n\nDas ist grob gerechnet ein Faktor von 200 (der Unterschied von R zu SPSS). Dieses Ergebnis lässt darauf schließen, dass R in der Praxis viel mehr als Excel gebraucht wird.\n\n🧑‍🎓 Aber ist R wirklich ein Werkzeug, das mir im Job hilft?\n\nViele Firmen weltweit nutzen R zur Datenanalyse, wie diese Liste zeigt.\n\n👨‍🏫 R ist der Place-to-be für die Datenanalyse.\n\n\n🧑‍🎓 Aber ist Datenanalyse wirklich etwas, womit ich in Zukunft einen guten Job bekomme?\n\nBerufe mit Bezug zu Daten, Datenanalyse oder, allgemeiner, Künstlicher Intelligenz (artificial intelligence) gehören zu den am meisten wachsenden Berufen:\n\nArtificial intelligence (AI) continues to make a strong showing on our Emerging Jobs lists, which is no surprise. Many jobs that have risen up as a result of AI in ﬁelds like cybersecurity and data science and because it’s is so pervasive many roles may demand more knowledge of AI than you may think. For example, real estate and business development roles. Quelle: LinkedIn",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#aufgaben",
    "href": "020-R.html#aufgaben",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.8 Aufgaben",
    "text": "3.8 Aufgaben\n\nÜbungsaufgabe 3.4 (Statistik-Meme) Suchen Sie ein schönes Meme zum Thema Statistik, Datenanalyse und Data Science. Hier ist ein Startpunkt. \\(\\square\\)\n\n\nTyp-Fehler-R-01\nTyp-Fehler-R-02\nTyp-Fehler-R-03\nTyp-Fehler-R-04\nTyp-Fehler-R-06a\nTyp-Fehler-R-07\nTyp-Fehler-R-08-name-clash\nLogikpruefung1\nLogikpruefung2\nthere-is-no-package\nWertberechnen2\nWertzuweisen_mc\nargumente\nimport-mtcars\nWertzuweisen\nWertpruefen\nwrangle1\nrepro1-sessioninfo",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#vertiefung",
    "href": "020-R.html#vertiefung",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.9 Vertiefung",
    "text": "3.9 Vertiefung\n\n3.9.1 Varianten zu read.csv\n\nHier ist eine weitere Möglichkeit, um Daten von einem Ordner (egal ob dieser sich im Internet oder auf Ihrem Computer befinde) einzulesen, stellt die Funktion data_read bereit:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nd &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nDer Unterschied ist, dass data_read viele Formate von Daten (Excel, CSV, SPSS, …) verkraftet, wohingegen read.csv nur Standard-CSV einlesen kann.\nSchauen wir uns die letzte R-Syntax en Detail an:\nHey R,\nhol das \"Buch\" easystats aus der Bücherei und lies es\ndefiniere als \"d\" die Tabelle,\ndie du unter der angegebenen URL findest.\nIn R gibt es oft viele Möglichkeiten, ein Ziel zu erreichen. Zum Beispiel haben wir hier den Befehl data_read() verwendet, um Daten zu importieren. Andere, gebräuchliche Befehle, die CSV-Dateien importieren, heißen read.csv() (aus dem Standard-R, kein Extra-Paket nötig) und read_csv() (aus dem Meta-Paket tidyverse).\n\n3.9.2 Der Dollar-Operator\nIn Beispiel 3.2 hatten wir Vektoren definiert. Solche Vektoren fliegen sozusagen frei in Ihrem Environment herum (Schauen Sie mal dort nach!) Die Spalten einer Tabelle sind aber auch Vektoren, nur eben nicht frei im Environment, sondern in eine Tabelle eingebunden.\nMöchte man diese Vektoren direkt ansprechen, so kann man das mit dem sog. Dollar-Operator $ tun.\nAngenommen, Sie möchten sich die Verkaufspreise (total_pr) aus der Tabelle mariokart herausziehen, dann können Sie das mit dem Dollar-Operator tun:\n\nmariokart$total_pr\n##   [1]  51.55  37.04  45.50  44.00  71.00  45.00  37.02  53.99  47.00  50.00\n##  [11]  54.99  56.01  48.00  56.00  43.33  46.00  46.71  46.00  55.99 326.51\n##  [21]  31.00  53.98  64.95  50.50  46.50  55.00  34.50  36.00  40.00  47.00\n##  [31]  43.00  31.00  41.99  49.49  41.00  44.78  47.00  44.00  63.99  53.76\n##  [41]  46.03  42.25  46.00  51.99  55.99  41.99  53.99  39.00  38.06  46.00\n##  [51]  59.88  28.98  36.00  51.99  43.95  32.00  40.06  48.00  36.00  31.00\n##  [61]  53.99  30.00  58.00  38.10 118.50  61.76  53.99  40.00  64.50  49.01\n##  [71]  47.00  40.10  41.50  56.00  64.95  49.00  48.00  38.00  45.00  41.95\n##  [81]  43.36  54.99  45.21  65.02  45.75  64.00  36.00  54.70  49.91  47.00\n##  [91]  43.00  35.99  54.49  46.00  31.06  55.60  40.10  52.59  44.00  38.26\n## [101]  51.00  48.99  66.44  63.50  42.00  47.00  55.00  33.01  53.76  46.00\n## [111]  43.00  42.55  52.50  57.50  75.00  48.92  45.99  40.05  45.00  50.00\n## [121]  49.75  47.00  56.00  41.00  46.00  34.99  49.00  61.00  62.89  46.00\n## [131]  64.95  36.99  44.00  41.35  37.00  58.98  39.00  40.70  39.51  52.00\n## [141]  47.70  38.76  54.51\n\nDer Dollar-Operator trennt den Namen der Tabelle vom Namen der Spalte.\nNatürlich können Sie mit dem resultierenden Vektor beliebig weiterarbeiten, etwa ihn in einem anderen Vektor speichern oder eine Funktion anwenden:\n\nverkaufspreise &lt;- mariokart$total_pr\nmean(verkaufspreise)\n## [1] 49.88049\nmean(mariokart$total_pr)  # synonym zur obigen Zeile\n## [1] 49.88049\n\n\n3.9.3 R-Zertifikat bei LinkedIn\nSie können bei LinkedIn ein Zertifikat bekommen, das Ihre R-Kenntnisse dokumentiert. Praktischerweise wird das Zertifikat gleich Ihrem Profil zugeordnet.\n\n3.9.4 R-Funktionen verschachteln\nDas Kombinieren von Funktionen kann kompliziert werden:\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x)-x)) \n## [1] 2\n\nDie Funktion abs(x) gibt den (Absolut-)Betrag von x zurück (entfernt das Vorzeichen, mit anderen Worten).\nHier haben wir die mittlere Absolutabweichung der Elemente von x zum Mittelwert ausgerechnet.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literaturhinweise",
    "href": "020-R.html#literaturhinweise",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.10 Literaturhinweise",
    "text": "3.10 Literaturhinweise\n“Warum R? Warum, R?” heißt ein Kapitel in Sauer (2019), das einiges zum Pro und Contra von R ausführt. In Kapitel 3 in der gleichen Quelle finden sich viele Hinweise, wie man R startet; In Kapitel 4 werden Grundlagen von “Errisch” erläutert; Kapitel 5 führt in Datenstrukturen von R ein (schon etwas anspruchsvoller). Alternativ bietet Kapitel 1 von Ismay & Kim (2020) einen guten und sehr anwenderfreundlichen Überblick. Das Buch hat auch den Vorteil, dass es komplett frei online verfügbar ist. Vergleichbar dazu ist Çetinkaya-Rundel & Hardin (2021), vielleicht einen Tick formaler; auf jeden Fall genau das richtige Niveau für Bachelor-Statistik in angewandten nicht-technischen Studiengängen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literatur",
    "href": "020-R.html#literatur",
    "title": "\n3  Daten einlesen\n",
    "section": "\n3.11 Literatur",
    "text": "3.11 Literatur\n\n\n\n\nÇetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability: A Brief History of a Confused Terminology. Frontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nSauer, S. (2019). Moderne Datenanalyse Mit R: Daten Einlesen, Aufbereiten, Visualisieren Und Modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#footnotes",
    "href": "020-R.html#footnotes",
    "title": "\n3  Daten einlesen\n",
    "section": "",
    "text": "Streng genommen ist RStudio für die Datenanalyse irrelevant, aber RStudio ist praktisch, Sie werden es nicht missen wollen.↩︎\nfrüher hieß der Dienst “RStudio Cloud”↩︎\nCRAN: Comprehensive R Archive Network↩︎\nÜbrigens sind tidyverse und easystats Pakete, die nur dafür da sind, mehrere Pakete zu installieren. So gehören z.B. zu tidyverse die Pakete ggplot (Daten verbildlichen) und dplyr (Datenjudo). Damit wir nicht alle Pakete einzeln installieren und starten müssen, bietet uns das Paket tidyverse den Komfort, alle die Pakete dieser “Sammlung” auf einmal zu starten. Praktisch.↩︎\nWenn die Anzahl der zu aktualisierenden Pakete groß ist, dann besser nicht alle auswählen, sondern nur ein paar. Dann die nächsten paar Pakete usw.↩︎\nDatenschutz!↩︎\nStreng genommen sollte man nicht von einer Liste sprechen, da es in R noch einen anderen Objekttyp gibt, der list heißt, und eine verallgemeinerte Form eines Vektors ist.↩︎\nund viele andere arithmetische Funktionen in R↩︎\n&gt; 🤖 Naja, manchmal.↩︎\nna.rm steht für remove die NA, also fehlenden Werte↩︎\nUnd manchmal ist einem das Problem danach schlichtweg egal.↩︎\nhttps://www.youtube.com/watch?v=2Q_ZzBGPdqE↩︎\nDer Pfad einer Datei sagt, in welchem Ordner und Unterorder und Unter-Unterordner die gesuchte Datei liegt. Ein Pfad könnte z.B. so aussehen: “/Users/sebastiansaueruser/github-repos/statistik1/020-R.qmd”.↩︎\nAuf dieser Webseite finden Sie eine große Zahl an Datensätzen. Nur für den Fall, dass Ihnen langweilig ist.↩︎\nvon “tbl” wie Table↩︎\nDurchgeführt am 2022-02-24, 17:21 CET↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html",
    "href": "030-aufbereiten.html",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "4.1 Lernsteuerung",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#lernsteuerung",
    "href": "030-aufbereiten.html#lernsteuerung",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "4.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n4.1.2 Lernziele\n\nSie können folgende Verben des Datenjudo anwenden: arrange, filter, select, summarise, group_by, mutate.\nSie können R-Befehle mit der “Pfeife” verketten.\n\n4.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n4.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nÜbungsaufgabe 4.1 Importieren Sie den Datensatz mariokart. Probieren Sie alle vorgestellten Verben des Datenjudos aus, zunächst in dem Sie einfach den R-Code kopieren und selber ausführen.\\(\\square\\)\n\n\n4.1.5 Frag den Bot\n\n👨‍🏫 Erkläre einem Fünfjährigen, warum Statistik nützlich ist.\n\n\n🤖 Okay, hör zu. Stell dir vor, du hast viele Spielzeugautos und du willst herausfinden, welches Auto am meisten bespielt wird. Du kannst jeden Tag zählen, wie oft du jedes Auto benutzt hast. Aber das wäre sehr mühsam und könnte schnell durcheinander gebracht werden. Stattdessen kannst du mit Statistik eine einfachere Methode finden. Du kannst zum Beispiel eine Liste machen und jedes Auto mit einer bestimmten Farbe markieren. Dann kannst du jeden Tag einfach zählen, wie oft du jede Farbe verwendet hast. Am Ende kannst du herausfinden, welches Auto am meisten bespielt wurde, indem du siehst, welche Farbe am meisten verwendet wurde. Das ist ein Beispiel dafür, wie Statistik uns dabei helfen kann, Muster in großen Datensätzen zu finden und Entscheidungen zu treffen, ohne alles einzeln zu zählen.\n\nQuelle: ChatGTP 3.5, 2023-02-09",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#datenjudo",
    "href": "030-aufbereiten.html#datenjudo",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.2 Datenjudo",
    "text": "4.2 Datenjudo\n\nDefinition 4.1 (Datenjudo) Mit Datenjudo meint man den Prozess der Aufbereitens, Umformens oder Zusammenfassen von Daten, sowohl für einzelne Beobachtungen (Zeilen einer Datentabelle) oder Variablen (Spalten einer Datentabelle) oder einer ganzen Datentabelle. \\(\\square\\)\n\n\n4.2.1 Die Wahrheit über Data Science\nDenkt man an Data Science, stellt man sich coole Leute vor (in San Francisco oder Berlin), die an abgefahrenen Berechnungen mit hoch komplexen statistischen Modellen für gigantische Datenmengen basteln. Tatsächlich besteht ein großer Teil der Arbeit aus dem Aufbereiten von Daten.\n\n4.2.2 Praxisbezug: Aus dem Alltag des Data Scientisten\nLaut dem Harvard Business Review allerdings, verbringen diese Leute “80%” ihrer Zeit mit dem Aufbereiten von Daten (Bowne-Anderson, 2018). Ja: mit uncoolen Tätigkeiten wie Tippfehler aus Datensätzen entfernen oder die Daten überhaupt nutzbar und verständlich zu machen.\nDas zeigt zumindest, dass das Aufbereiten von Daten a) wichtig ist und b) dass man allein damit schon weit kommen kann. Eine gute Nachricht ist (vielleicht), dass das Aufbereiten von Daten keine aufwändige Mathematik verlangt, stattdessen muss man ein paar Handgriffe und Kniffe kennen. Daher passt der Begriff Datenjudo vielleicht ganz gut. Kümmern wir uns also um das Aufbereiten bzw. Umformen von Daten, um das Datenjudo. 🔢🤹 \\(\\square\\)\n\nBeispiel 4.1 Beispiele für typische Tätigkeiten des Datenjudos sind:\n\nZeilen filtern (z. B. nur Studentis des Studiengangs X)\nZeilen sortieren (z. B. Studenten mit guten Noten in den oberen Zeilen)\nSpalten wählen (z. B. 100 weitere Produkte ausblenden)\nSpalten in eine Zahl zusammenfassen (z. B. Notenschnitt der 1. Klausur)\nTabelle gruppieren (z. B. Analyse getrennt nach Standorten)\nWerte aus einer Spalte verändern oder neue Spalte bilden (z. B. Punkte in Prozent-Richtige umrechnen).\n… \\(\\square\\)\n\n\n\n\n4.2.3 Mach’s einfach\nEs gibt einen (einfachen) Trick, wie man umfangreiche Datenaufbereitung elegant geregelt kriegt, klingt fast zu schön, um wahr zu sein (s. Abbildung 4.1).\n\n\n\n\n\nAbbildung 4.1: Mach’s einfach. Made at imgflip.com, Meme Generator\n\n\nDer Trick besteht darin, komplexe Operationen in mehrere einfache Teilschritte zu zergliedern1. Man könnte vom “Lego-Prinzip” sprechen, s. Abbildung 4.2. Im linken Teil von Abbildung 4.2 sieht man ein (recht) komplexes Gebilde. Zerlegt man es aber in seine Einzelteile, so sind es deutlich einfachere geometrische Objekte wie Dreiecke oder Quadrate (rechter Teil des Diagramms).\n\n\n\n\n\nAbbildung 4.2: Das Lego-Prinzip\n\n\nDamit Sie es selber einfach machen können, müssen Sie selber Hand anlegen. Importieren Sie daher den Datensatz mariokart, z.B. so:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nglimpse(mariokart)\n## Rows: 143\n## Columns: 13\n## $ rownames    &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n## $ id          &lt;dbl&gt; 150377422259, 260483376854, 320432342985, 280405224677, 17…\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7…\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, …\n## $ cond        &lt;chr&gt; \"new\", \"used\", \"new\", \"new\", \"new\", \"new\", \"used\", \"new\", …\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9…\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00…\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47…\n## $ ship_sp     &lt;chr&gt; \"standard\", \"firstClass\", \"firstClass\", \"standard\", \"media…\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,…\n## $ stock_photo &lt;chr&gt; \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2…\n## $ title       &lt;chr&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW …\n\n\nBeispiel 4.2 Sie arbeiten immer noch bei dem großen Online-Auktionshaus. Mittlerweile haben Sie sich den Ruf des “Datenguru” erworben. Vielleicht weil Sie behauptet haben, Data Science sei zu 80% Datenjudo, das hat irgendwie Eindruck geschindet… Naja, jedenfalls müssen Sie jetzt mal zeigen, dass Sie nicht nur schlaue Sprüche draufhaben, sondern auch die Daten ordentlich abbürsten können. Sie analysieren dafür im Folgenden den Datensatz mariokart. Na, dann los.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#die-verben-des-datenjudos",
    "href": "030-aufbereiten.html#die-verben-des-datenjudos",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.3 Die Verben des Datenjudos",
    "text": "4.3 Die Verben des Datenjudos\nIm R-Paket dplyr, das wiederum Teil des R-Pakets tidyverse ist, gibt es eine Reihe von R-Befehlen, die das Datenjudo in eine Handvoll einfacher Verben runterbrechen.2 Die wichtigsten Verben des Datenjudos schauen wir uns im Folgenden an.\nWir betrachten dazu im Folgenden einen einfachen (Spielzeug-)Datensatz, an dem wir zunächst die Verben des Datenjudos vorstellen, s. Tabelle 4.1.\n\n\n\nTabelle 4.1: Ein einfacher Datensatz von schlichtem Gemüt\n\n\n\n\n\n\nid\nname\ngruppe\nnote\n\n\n\n1\nAnni\nA\n2.7\n\n\n2\nBerti\nA\n2.7\n\n\n3\nCharli\nB\n1.7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Verben des Datenjudos wohnen im Paket {dyplr}, welches gestartet wird, wenn Sie library(tidyverse) eingeben. Falls Sie vergessen , das Paket tidyverse zu starten, dann funktionieren diese Befehle nicht.\\(\\square\\)\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nZur Erinnerung: In RStudio können Sie per Klick auf das kleine Tabellen-Icon im Bereich Environment die Tabellenansicht einer Tabelle öffnen, s. Kapitel 3.5.7. \\(\\square\\)\n\n\n\n4.3.1 Tabelle sortieren: arrange\n\nSortieren der Zeilen ist eine einfache, aber häufige Tätigkeit des Datenjudos, s. Abbildung 4.3.\n\n\n\n\n\n\n\nAbbildung 4.3: Sinnbild für das Sortieren einer Tabelle mit arrange()\n\n\n\n\n\nBeispiel 4.3 (Was sind die höchsten Preise?) Sie wollen mal locker anfangen. Daher stellen Sie sich folgende Frage: Was sind denn eigentlich die höchsten Preise, für die das Spiel Mariokart über den Online-Ladentisch geht? Die Spalte des Verkaufspreis heißt offenbar total_pr (s. Tabelle mariokart). In Excel kann die Spalte, nach der man die Tabelle sortieren möchte, einfach anklicken. Ob das in R auch so einfach geht?\n\nmariokart_neu &lt;- arrange(mariokart, total_pr)\nmariokart_neu\n\n\n  \n\n\n\nÜbersetzen wir die R-Syntax ins Deutsche:\nHey R,\narrangiere (sortiere) `mariokart` nach der Spalte `total_pr`\nGar nicht so schwer.\\(\\square\\)\n\nÜbrigens wird in arrange() per Voreinstellung aufsteigend sortiert. Setzt man ein Minus vor der zu sortierenden Spalte, wird umgekehrt, also absteigend sortiert:\n\nmario_sortiert &lt;- arrange(mariokart, -total_pr)\n\n\nÜbungsaufgabe 4.2 Sortierne Sie die Mariokart-Daten absteigend nach der Anzahl der beigelegten Lenkräder.\\(\\square\\)\n\n\n4.3.2 Zeilen filtern: filter\n\nZeilen filtern bedeutet, dass man nur bestimmte Zeilen (Beobachtungen) behalten möchte, die restlichen Zeilen brauchen wir nicht, weg mit ihnen. Wir haben also ein Filterkriterium im Kopf, anhand dessen wir die Tabelle filern, s. Abbildung 4.4.\n\n\n\n\n\n\n\nAbbildung 4.4: Sinnbild für das Filtern einer Tabelle mit filter()\n\n\n\n\n\nBeispiel 4.4 (Ob ein Foto für den Verkaufspreis nützlich ist?) Als nächstes kommt Ihnen die Idee, mal zu schauen, ob Auktionen mit Photo der Ware einen höheren Verkaufspreis erzielen als Auktionen ohne Photo.\n\nmariokart_neu &lt;- filter(mariokart, stock_photo == \"yes\")\nmariokart_neu\n\n\n  \n\n\n\nSie filtern also die Tabelle so, dass nur diese Auktionen im Datensatz verbleiben, welche ein Photo haben, mit anderen Worten, Auktionen (Beobachtungen) bei denen gilt: stock_photo == TRUE.\\(\\square\\)\n\n\n4.3.3 Komplexeres Filtern\nAngestachelt von Ihren Erfolgen möchten Sie jetzt komplexere Hypothesen prüfen: Ob wohl Auktionen von neuen Spielen und zwar mit Photo einen höheren Preis erzielen als die übrigen Auktionen?\nAnders gesagt haben Sie zwei Filterkriterien im Blick: Neuheit cond und Photo stock_photo. Nur diejenigen Auktionen, die sowohl Neuheit als auch Photo erfüllen, möchten Sie näher untersuchen.\n\nmario_filter1 &lt;- filter(mariokart, stock_photo == \"yes\" & cond == \"new\")\nmario_filter1\n\n\n  \n\n\n\nHm. Was ist mit den Auktionen, die entweder über ein Photo verfügen oder neu sind (oder beides)?\n\nmario_filter2 &lt;- filter(mariokart, stock_photo == \"yes\" | cond == \"new\")\nmario_filter2\n\n\n  \n\n\n\nHier könnte man noch viele interessante Hypothesen prüfen, denken Sie sich und tun das auch …\n\nÜbungsaufgabe 4.3 Filtern Sie die Spiele mit nur einem Lenkrad und ohne Versandkosten.\\(\\square\\)\n\n\nÜbungsaufgabe 4.4 Filtern Sie die Spiele mit nur einem Lenkrad mit überdurchschnittlichen Verkaufspreis. Tipp: Nutzen Sie die Funtion describe_distribution(name_der_tabelle), um den Mittelwert einer Variable des Datensatzes zu erfahren (diese Funktion wohnt im R-Paket easystats. \\(\\square\\)\n\n\n4.3.4 Spalten auswählen mit select\n\nEine Tabelle mit vielen Spalten kann schnell unübersichtlich werden. Da lohnt es sich, eine alte goldene Regel zu beachten: Mache die Dinge so einfach wie möglich, aber nicht einfacher. Wählen wir also nur die Spalten aus, die uns interessieren und entfernen wir die restlichen, s. Abbildung 4.5.\n\n\n\n\n\n\n\nAbbildung 4.5: Sinnbild für das Auswählen von Spalten mit select()\n\n\n\n\n\nBeispiel 4.5 (Fokus auf nur zwei Spalten) Ob wohl gebrauchte Spiele deutlich geringere Preise erzielen im Vergleich zu neuwertigen Spielen? Sie entschließen sich, mal ein Stündchen auf die relevanten Daten zu starren.\n\nmario_select1 &lt;- select(mariokart, cond, total_pr)\nmario_select1\n\nAha (?)\\(\\square\\)\n\nDer Befehl select erwartet als Input eine Tabelle und gibt (als Output) eine Tabelle zurück - genau wie die meisten anderen Befehle des Datenjudos. Auch wenn Sie nur eine Spalte auswählen, bleibt es eine Tabelle, eben eine Tabelle mit nur einer Spalte.\nselect erlaubt Komfort; Sie können Spalten auf mehrere Arten auswählen, z.B.\n\nselect(mariokart, 1, 2)  # Spalte 1 und 2\nselect(mariokart, 2:5)  #  Spalten 2 *bis* 5 \nselect(mariokart, -1)  # Alle Spalte *aber nicht* Spalte 1\n\nVertiefte Informationen zum Auswählen von Spalten mit select findet sich hier.\n\n4.3.5 Spalten zu einer Zahl zusammenfassen mit summarise\n\nSo eine lange Spalte mit Zahlen – mal ehrlich: wer blickt da schon durch? Viel besser wäre es doch, die Spalte total_pr zu einer Zahl zusammenzufassen, das ist doch viel handlicher. Kurz entschlossen fassen Sie die Spalte total_pr, den Verkaufspreis, zum Mittelwert zusammen, s. Abbildung 4.6.\n\n\n\n\n\n\n\nAbbildung 4.6: Spalten zu einer einzelnen Zahl zusammenfassen mit summaris()\n\n\n\n\n\nBeispiel 4.6 (Was ist der mittlere Verkaufspreis?) Mit summarise, s. ?lst-summarise, können wir den mittleren Verkaufspreis der Mariokart-Spiele berechnen.\n\nmariokart_neu &lt;- summarise(mariokart, preis_mw = mean(total_pr))\nmariokart_neu\n\n\n  \n\n\n\nAha! Etwa 50€ erzielt so eine Auktion im Schnitt.\\(\\square\\)\n\nÜbersetzen wir ?lst-summarise vom Errischen ins Deutsche:\n\n🧑‍🎓 Hey R, fasse die Zeilen von total_pr aus mariokart zu einer Zahl zusammen, und zwar mit Hilfe des Mittelwerts. Die resultierende Tabelle nennen wir mariokart_neu, sehr kreativ. Und die resultierende Spalte, die einzige inmariokart_neu, nennen wirpreis_mw`.\n\nEin bisschen abstrakter gesprochen, fasst summarise also eine Spalte zu einer (einzelnen) Zahl zusammen, s. Gleichung 4.1.3\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\  \\\\  \\\\ \\\\ \\hline \\end{array} \\qquad \\rightarrow  \\qquad \\begin{array}{|c|} \\hline \\\\  \\hline \\end{array} \\tag{4.1}\\]\n\n4.3.6 Tabelle gruppieren\nEs ist ja gut und schön, zu wissen, was so ein Spiel im Schnitt kostet. Aber viel interessanter wäre es doch, denken Sie sich, zu wissen, ob die neuen Spiele im Schnitt mehr kosten als die alten? Ob R Ihnen so etwas ausrechnen kann?\n\n🤖 Ich tue fast alles für dich. 🧡\n\nAlso gut, R, dann gruppiere die Tabelle, s. Abbildung 4.7.\n\n\n\n\n\n\n\nAbbildung 4.7: Gruppieren von Datensätzen mit group_by()\n\n\n\n\nDurch das Gruppieren wird die Tabelle in “Teiltabellen” - entsprechend der Gruppen - aufgeteilt. Das sieht man der R-Tabelle aber nicht wirklich an. Aber alle nachfolgenden Berechnungen werden für jede Teiltabelle einzeln ausgeführt.\n\nBeispiel 4.7 (Mittlerer Preis pro Gruppe) Gruppieren alleine liefert Ihnen zwei (oder mehrere) Teiltabellen, etwa neue Spiele (Gruppe 1, new) vs. gebrauchte Spiele (Gruppe 2, used). Mit anderen Worten: Wir gruppieren anhand der Variable cond.\n\nmariokart_gruppiert &lt;- group_by(mariokart, cond)\n\nWenn Sie die neue Tabelle betrachte, sehen Sie wenig Aufregendes, nur einen Hinweis, dass die Tabelle gruppiert ist. Jetzt können Sie an jeder Teiltabelle Ihre weiteren Berechnungen vornehmen, etwa die Berechnung des mittleren Verkaufspreises.\n\nsummarise(mariokart_gruppiert, preis_mw = mean(total_pr))\n\n\n  \n\n\n\nLangsam fühlen Sie sich als Datenchecker … 🥷 🦹‍♀ $\n\n\n4.3.7 Spalten verändern mit mutate\n\nImmer mal wieder möchte man Spalten verändern, bzw. deren Werte umrechnen, s. Abbildung 4.8.\n\n\n\n\n\n\n\nAbbildung 4.8: Spalten verändern/neu berechnen mit mutate()\n\n\n\n\n\nBeispiel 4.8 Der Hersteller des Computerspiels Mariokart kommt aus Japan; daher erscheint es Ihnen opportun für ein anstehendes Meeting mit dem Hersteller die Verkaufspreise von Dollar in japanische Yen umzurechnen. Nach etwas Googeln finden Sie einen Umrechnungskurs von 1:133.\n\nmariokart2 &lt;- mutate(mariokart, total_pr_yen = total_pr * 133)\nmariokart2 &lt;- select(mariokart2, total_pr_yen, total_pr)\nmariokart2\n\n\n  \n\n\n\nSicherlich werden Sie Ihre Gesprächspartner schwer beeindrucken.\\(\\square\\)\n\nMit mutate berechnen Sie eine Spalte x (in einer Tabelle) neu. Die Funktion, die Sie in mutate benennen wird für jede Zeile der Spalte x angewendet.\n\nBeispiel 4.9 (Beispiele für Funktionen für mutate) mutate eignet sich, z.B. um Spalten zu addieren, zu multiplizieren oder sonstwie zu transformieren (z.B. den Logarithmus anwenden oder den Mittelwert der Spalte von jeder Zeile abziehen). \\(\\square\\)\n\n\n🧟‍♀️ Statistik, wann braucht man schon sowas!?\n\n\n👨‍🏫 Eigentlich nur dann, wenn man die Fakten gut verstehen will, sonst nicht.\n\n\n4.3.8 Zeilen zählen mit count\n\nArbeitet man mit nominalskalierten Daten, ist (fast) alles, was man tun kann, das Zeilen zählen.4\nMan könnte z.B. fragen, wie viele neue und wie viele alte Spiele in der Tabelle (Dataframe) mariokart vorhanden sind.\n\nBeispiel 4.10 Nach der letzten Präsentation Ihrer Analyse hat Ihre Chefin gestöhnt: “Oh nein, alles so kompliziert. Statistik! Himmel hilf! Kann man das nicht einfacher machen?” Anstelle von irgendwelchen komplizierten Berechnungen (Mittelwert?) möchten Sie ihr beim nächsten Treffen nur zeigen, wie viele Computerspiele neu und wie viele gebraucht sind (in Ihrem Datensatz). Schlichte Häufigkeiten also. Hoffentlich ist Ihre Chefin nicht wieder überfordert…\n\nmariocart_counted &lt;- count(mariokart, cond)\nmariocart_counted\n\n\n  \n\n\n\nAha! Es gibt mehr gebrauchte als neue Spiele.\\(\\square\\)\n\nJetzt könnte man noch den Anteil (engl. proportion) ergänzen: Welcher Anteil (der 143 Spiele in mariokart) ist neu, welcher gebraucht?\n\nmariocart_counted %&gt;% \n  mutate(Anteil = n / sum(n))\n\n\n  \n\n\n\n\n4.3.9 Fazit: Verben am Fließband\ndie Befehle (“Verben”) des Tidyverse sind jeweils für einzelne, typische Aufgaben des Datenaufbereitens (“Datenjudo”) zuständig.\nTypischerweise erwarten diese Befehle eine Tabelle (▥) als Input und liefern eine Tabelle aus Output zurück, s. Abbildung 4.9.\n\n\n\n\n\nflowchart LR\n  A[\"▥\"] --&gt; B[tidyverse-Befehl] --&gt; C[\"▥\"] \n\n\n\n\nAbbildung 4.9: Tidyverse-Befehle erwarten normalerweise eine Tabelle (tibble) als Input und geben auch eine Tabelle zurück als Output",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#sec-pipe",
    "href": "030-aufbereiten.html#sec-pipe",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.4 Die Pfeife",
    "text": "4.4 Die Pfeife\n🚬 👈 Das ist keine Pfeife, wie René Magritte 1929 in seinem berühmten Bild schrieb, s. Abbildung 4.10.\n\n\n\n\n\n\n\n\n\n(a) Das ist keine Pfeife. Sondern ein Bild einer Pfeife.\n\n\n\n\n\n\n%&gt;%\n\n\n\n|&gt;\n\n\n\n\n\nAbbildung 4.10: So sieht die Pfeife in R aus5. Links: Ein Bild einer Pfeife. Mitte und Rechts: Die zwei R-Symbole für eine “Pfeife” (pipe).\n\n\n\n4.4.1 Russische Puppen\nComputerbefehle, und im Speziellen R-Befehle kann man “aufeinander” – oder vielmehr: ineinander – stapeln, so ähnlich wie eine russische Puppe (vgl. Kapitel 3.4.3). Schauen wir uns das in einem Beispiel an. Dazu definieren wir zuerst einen Vektor x aus drei Zahlen:\n\nx &lt;- c(1, 2, 3)\n\nUnd dann kommt unser verschachtelter Befehl:\n\nsum(x - mean(x))\n## [1] 0\n\nWie schon erwähnt, arbeitet R so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: sum(x - mean(x))\n  ⬇️ \nSchritt 1: sum(x - 2)\n  ⬇️ \nSchritt 2: sum(-1, 0, 1)\n  ⬇️ \nSchritt 3: 0. Fertig. Puh. Kompliziert.\nSoweit kann man noch einigermaßen folgen. Aber das Verschachteln kann man noch extremer machen, dann wird’s wild. Schauen Sie sich mal folgende (Pseudo-)Syntax an:6\n\n\nListing 4.1: Eine wild verschachtelte Sequenz von R-Befehlen\n\nfasse_zusammen(gruppiere(wähle_spalten(filter_zeilen(meine_daten))))\n\n\n\n🤯\n\n4.4.2 Die Pfeife zur Rettung\nListing 4.1 ist schon harter Tobak, was für echte Fans. Wäre es nicht einfacher, man könnte Listing 4.1 wie folgt schreiben:\nNimm \"meine_daten\" *und dann*\n  filter gewünschte Zeilen *und dann*\n  wähle gewünschte Spalten *und dann*\n  teile in Subgruppen *und dann*\n  fasse sie zusammen.\n\nDefinition 4.2 (Pfeife) “Und dann” heißt auf Errisch %&gt;% oder |&gt;. Man nennt diesen Befehl “Pfeife” (engl. pipe). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Befehl %&gt;% verknüpft Befehle. Der Shortcut für diesen Befehl ist Strg-Shift-M. Die Pfeife %&gt;% “wohnt” im Paket tidyverse.7\n\n\nMittlerweile8 ist auch im Standard-R eine Pfeife eingebaut. die sieht so aus: |&gt;. Die eingebaute Pfeife funktioniert praktisch gleich zur anderen Pfeife %&gt;%, hat aber den Vorteil, dass Sie nicht tidyverse starten müssen. Da wir tidyverse aber sowieso praktisch immer starten werden, bringt es uns keinen Vorteil, die neuere Pfeife des Standard-R |&gt; zu verwenden.9\n\n\n\n\n\n\n\nflowchart TD\n  A[\"meine Daten 🗳\"] --filter_zeilen--&gt;B[\"▥\"] \n  B --wähle_spalten--&gt; C[\"▥\"]\n  C --gruppiere--&gt; D[\"▥\"]\n  D --fasse_zusammen--&gt; E[\"▥ Fertig. 🤩\"]\n\n\n\n\n\nAbbildung 4.11: Illustration für eine Pfeifensequenz, es geht vorwärts wie am Fließband.\n\n\n\n\n\nUnd jetzt kommt’s: So eine Art von Befehls-Verkettung gibt es in R. Schauen Sie sich mal Listing 4.2 an:\n\n\nListing 4.2: Eine Pfeifen-Befehlssequenz (Pseudo-Syntax)\n\nmeine_daten %&gt;%\n  filter_gewünschte_zeilen() %&gt;%\n  wähle_gewünschte_spalten() %&gt;%\n  gruppiere() %&gt;%\n  fasse_zusammen() \n\n\n\nSo eine Pfeifen-Befehlsequenz ist ein wie ein Fließband, an dem es mehrere Arbeitsstationen gibt, s. Abbildung 4.11. Unser Datensatz wird am Fließband von Station zu Station weitergereicht und an jeder Stelle weiterverarbeitet.\n\n\n\n\n\n\n\nSo könnte Ihre “Pfeifen-Sequenz” aussehen:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")  # Daten einlesen nicht vergessen\n\nlibrary(tidyverse)  # Die Pfeife wohnt auch im Paket \"tidyverse\"\n\n# Hey R:\nmariokart %&gt;%   # nimm die Tabelle \"mariokart\" und dann...\n  filter(total_pr &lt; 100) %&gt;%  # filter nur die günstigen Spiele und dann...\n  select(cond, total_pr) %&gt;%  # wähle die zwei Spalten und dann ...\n  group_by(cond) %&gt;%  # gruppiere die Tabelle nach Zustand des Spiels und dann ...\n  summarise(total_pr_mean = mean(total_pr))  # fasse beide Gruppen nach dem mittleren Preis zusammen\n\n\n  \n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDie Syntax filter(mariokart, total_pr &lt; 100) und die Syntax mariokart |&gt; filter(total_pr &lt; 100) sind identisch.\nAllgemeiner: d |&gt; f(x) = f(d, x).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallbeispiel",
    "href": "030-aufbereiten.html#fallbeispiel",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.5 Fallbeispiel",
    "text": "4.5 Fallbeispiel\n\nÜbungsaufgabe 4.5 Bevor Sie die Lösungen der folgenden Fallbeispiele lesen, versuchen Sie die Aufgaben selber zu lösen. Ja, ich weiß, es ist hart, nicht gleich auf die Lösungen zu schauen! Protipp: Am besten scrollen Sie so, dass Sie die Lösungen nicht gleich sehen.\\(\\square\\)\n\nSie arbeiten als Diener strategischer Assistent der Geschäftsführerin und sind für Faktenchecks und andere Daten-Aufgaben zuständig. Heute sollen Sie zeigen, was Sie können (Schluck).\n\n4.5.1 Forschungsfrage 1\n\n️👩 Ich würde von Ihnen gerne wissen, was das teuerste Spiel ist, aber jeweils für neue und gebrauchte Spiele. Aber nur für Spiele, die mit Foto verkauft wurden!\n\n\nmariokart %&gt;% \n  filter(stock_photo == \"yes\") %&gt;% \n  group_by(cond) %&gt;% \n  summarise(total_pr_max = max(total_pr))\n\n\n  \n\n\n\nDie Funktion max liefert den größten Wert eines Vektors zurück:\n\nx &lt;- c(1, 2, 10)\nmax(x)\n## [1] 10\n\n\n4.5.2 Forschungsfrage 2\n\n️👩️ Ich würde gerne die mittlere Versandpauschale wissen, aber getrennt nach Anzahl der Lenkräder, die dem Spiel beigelegt sind. Und ich will nur Gruppen berücksichtigen, die aus mindestens 10 Spielen bestehen!\n\nWenn wir die Anzahl der Spiele zählen in Abhängigkeit der beigelegten Lenkräder (wheels), bekommen wir eine Tabelle mit zwei Spalten: wheels und n. n zählt, wie viele Spiele (Zeilen) in der jeweiligen Gruppe (“Teiltabelle”) von wheels sind.\n\nmariokart %&gt;%\n  count(wheels)\n\n\n  \n\n\n\nAus dieser Tabellet sehen wir, dass es 3 oder 4 Lenkräder nur selten (2 bzw. 1 Mal) beigelegt wurden und wir solche Spiele herausfiltern sollten bevor wir den Mittelwert der Versankosten ausrechnen:\n\nmariokart %&gt;%\n  filter(wheels &lt; 3) %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(mittlere_versandkosten = mean(ship_pr),\n            anzahl_spiele = n())\n\n\n  \n\n\n\nDie Funktion n() gibt die Anzahl der Zeilen pro Teiltabelle zurück.\n\n4.5.3 Forschungsfrage 3\n\n️👩️ Ich würde gerne den Verkaufspreis in Yen wissen, nicht in Euro. Dann rechne mal den mittleren Verkaufspreis aus und ziehe 10% ab, die wir als Provision unseren Verkäufern zahlen müssen.\n\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  mutate(total_pr_yen = total_pr * 133) %&gt;% \n  summarise(preis_yen_mw = mean(total_pr_yen),\n            preis_yen_mw_minus_10proz = preis_yen_mw - 0.1*preis_yen_mw)\n\n\n  \n\n\n\nWie man sieht kann man in summarise auch mehr als eine Berechnung einstellen. In diesem Fall haben wir zwei Berechnungen angestellt: Einmal den Mittelwert und einmal den Mittelwert minus 10% (des Mittelwerts).\n\nÜbungsaufgabe 4.6 (DYI) Denken Sie sich selber ähnliche Forschungsfragen aus. Stellen Sie diese einer vertrauenswürdigen Kommilitonen bzw. einem vertrauenswürdigen Kommilitonen. Schauen Sie, ob Ihre Aufgabe richtig gelöst wird. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#praxisbezug",
    "href": "030-aufbereiten.html#praxisbezug",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.6 Praxisbezug",
    "text": "4.6 Praxisbezug\nDie Covid19-Epidemie hatte weltweit massive Auswirkungen; auch psychologischer Art wie Vereinsamung, Angst oder Depression. Eine Studie, die die psychologischen Auswirkungen von Mulukom et al. (2020), die unter diesem Projekt bei der Open Science Foundation (OSF) angemeldet ist. Die Daten wurden mit R ausgewertet. Beispielhaft ist hier die R-Syntax zu sehen, die die Autoren zur Datenaufbereitung verwendet haben. Einen guten Teil dieser Syntax kennen Sie aus diesem Kapitel. Diese Studie ist, neben einigen vergleichbaren, ein schönes Beispiel, wie Forschung und Praxis ineinander greifen können: Angewandte Forschung als Beitrag zur Lösung eines akuten Problems, der Corona-Pandemie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "href": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.7 Wie man mit Statistik lügt",
    "text": "4.7 Wie man mit Statistik lügt\nEin (leider) immer mal wieder zu beobachtender “Trick”, um Daten zu frisieren ist, nur die Daten zu berichten, die einem in den Kram passen.\n\nBeispiel 4.11 Ei Analysti 🧑‍🦰 möchte zeigen, dass der Verkaufspreis von Mariokart-Spielen “viel zu niedrig” ist. Es muss ein höherer Wert rauskommen, findet dis Analysti. Der mittlere Verkaufspreis (im Datensatz mariokart) liegt bei 50 Euro.\n\n‍🦰 Kann man den Wert nicht … “kreativ verbessern”? Ein paar Statistik-Tricks anwenden?\n\nUm dieses Ziel zu erreichen, teilt dis Analysti den Datensatz in Gruppen nach Anzahl der dem Spiel beigelegten Lenkräder (wheels). Dann berechnet er den Mittelwert pro Gruppe.\n\nmariokart_wheels &lt;- \nmariokart %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_mean = mean(total_pr),\n            count_n = n())  # n() gibt die Anzahl der Zeilen pro Gruppe an\n\nmariokart_wheels\n\n\n  \n\n\n\nSchließlich berechnet unser Analysti den ungewichteten Mittelwert über diese 5 Gruppen:\n\nmariokart_wheels %&gt;% \n  summarise(mean(pr_mean))\n\n\n  \n\n\n\nUnd das Ergebnis lautet: 56 Euro! Das ist doch schon etwas “besser” als 50 Euro.\nNatürlich ist es falsch und irreführend, hier einen ungewichteten Mittelwert zu berechnen. Der gewichtete Mittelwert würde wiederum zum korrekten Ergebnis, 50 Euro, führen.\\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallstudie",
    "href": "030-aufbereiten.html#fallstudie",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.8 Fallstudie",
    "text": "4.8 Fallstudie\n\n\n\n\n\nAbbildung 4.12: Possierlich: Die Pinguine\n\n\n\nÜbungsaufgabe 4.7 Machen Sie sich zunächst mit dem Pinguin-Datensatz vertraut. Fokussieren Sie sich auf die Zielvariable Gewicht. Die folgende Datenapp ermöglicht Ihnen, die Verteilung des Körpergewichts zu betrachten, wobei sie die Pinguin-Spezies filtern können sowie eine Mindestlänge des Schnabels verlangen können. \\(\\square\\)\n\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\nData\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"daten/penguins.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\nBearbeiten Sie die Fallstudie zu Pinguinen von Allison Horst. Sie können die Teile auslassen, die Themen beinhalten, die nicht in diesem Kapitel vorgestellt wurden.\nDie Verben des Datenjudos werden hier anschaulich illustriert.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#aufgaben",
    "href": "030-aufbereiten.html#aufgaben",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.9 Aufgaben",
    "text": "4.9 Aufgaben\n\n\n\n\n\n\nChatGPT\n\n\n\nNutzen Sie einen Chat-Bot wie ChatGPT, um sich Hilfe für die R-Syntax geben zu lassen. \\(\\square\\)\n\n\n\nwrangle3\nwrangle4\nwrangle5\nwrangle7\nwrangle9\nwrangle10\ntidydata1\naffairs-dplyr\ndplyr-uebersetzen\nhaeufigkeit01\nmariokart-mean1\nmariokart-mean2\nmariokart-mean3\nmariokart-mean4\nmariokart-max1\nmariokart-max2\nfilter01\naffairs-dplyr\nsummarise01\nsummarise02\nmutate01",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#vertiefung",
    "href": "030-aufbereiten.html#vertiefung",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.10 Vertiefung",
    "text": "4.10 Vertiefung\n\n\n\n\n\n\nHinweis\n\n\n\nIn weiterführendem Material werden Sie immer wieder auf Inhalte treffen, die Sie noch nicht kennen, die etwa noch nicht im Unterricht behandelt wurden. Seien Sie unbesorgt: In der Regel können Sie diese Inhalte einfach auslassen, ohne den Anschluss zu verlieren. Einfach ignorieren. 😄\n\n\nHäufig ist es nützlich, die Werte einer Variablen umzukodieren, z.B. “weiblich” in “w” oder in 0. Eine gute Möglichkeit, dies in R umzusetzen, bietet der Befehl case_when(); der Befehl wohnt im Tidyverse. Hier - und an vielen weiteren Stellen im Internet - finden Sie ein Tutorium.\nWer sich tiefer in das Datenjudo mit dem Tidyverse einarbeiten möchte, dem sei z.B. dieser Kurs empfohlen.\nEin gutes und frei verfügbares Buch ist das von Wickham & Grolemund (2018); Kap. 5 behandelt (etwas ausführlicher) die Themen dieses Kapitels.\nDiese Fallstudie hat die Analyse von Flugverspätungen zum Thema.\n\n\nhttps://osf.io/z39us/\n\n\nThe COVIDiSTRESS global survey is an international collaborative undertaking for data gathering on human experiences, behavior and attitudes during the COVID-19 pandemic. In particular, the survey focuses on psychological stress, compliance with behavioral guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures, but multiple further items and scales are included for descriptive statistics, further analysis and comparative mapping between participating countries. Round one data collection was concluded May 30. 2020. To gather comparable data swiftly from across the globe, when the Coronavirus started making a critical impact on societies and individuals, the collaboration and survey was constructed as an urgent collaborative process. Individual contributors and groups in the COVIDiSTRESS network (see below) conducted translations to each language and shared online links by their own best means in each country.\n\nDie Daten stehen zur freien Verfügung. Sie können diese echten Daten eigenständig analysieren. Diese Datei beinhaltet die finalen, aufbereiteten Daten. Achtung: Die Datei ist recht groß, ca. 90 MB.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#exkurs",
    "href": "030-aufbereiten.html#exkurs",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.11 Exkurs",
    "text": "4.11 Exkurs\nDall-E 2 ist eine KI, die “realistische Bilder und Kunst aus einer Beschreibung in natürlicher Sprache” erstellt.\n\n👨‍🏫 I’d like a mixture between robot und professor, in oil painting\n\n\n🤖 … s. Abbildung 4.13\n\n\n\n\n\n\nAbbildung 4.13: Bild erzeugt von künstlicher Intelligenz, Quelle: DALL-E 2, 2023-02-09\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Nutzen künstlicher Intelligenz für die Datenanalyse ist natürlich breiter: Wenn Sie sich z.B. über die Syntax eines bestimmten Befehls (oder allgemeiner: Vorhabens) nicht sicher sind, fragen Sie sich doch mal einen Bot wie ChatGPT.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literaturhinweise",
    "href": "030-aufbereiten.html#literaturhinweise",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.12 Literaturhinweise",
    "text": "4.12 Literaturhinweise\nSauer (2019), Kap. 7, gibt eine Einführung in die Datenaufbereitung (mit Hilfe von R), ähnlich zu den Inhalten dieses Kapitels. Mehr in die Tiefe des “Datenjudo” führen Wickham & Grolemund (2018); der Autor Hadley Wickham ist die Leitfigur in der R-Community schlechthin. Er ist einer der Hauptautoren von den beliebten R-Paketen dplyr und ggplot2.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literatur",
    "href": "030-aufbereiten.html#literatur",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.13 Literatur",
    "text": "4.13 Literatur\n\n\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do, According to 35 Data Scientists. Harvard Business Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, & Farias, M. (2020). Psychological Impact of COVID-19 Pandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nSauer, S. (2019). Moderne Datenanalyse Mit R: Daten Einlesen, Aufbereiten, Visualisieren Und Modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., & Grolemund, G. (2018). R Für Data Science: Daten Importieren, Bereinigen, Umformen, Modellieren Und Visualisieren (F. Langenau, Übers.; 1. Auflage). O’Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#footnotes",
    "href": "030-aufbereiten.html#footnotes",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "Genau darin besteht das Wesen einer Analyse: die Zerlegung eines Objekts in seine Bestandteile.↩︎\nFalls Sie das R-Paket tidyverse noch nicht installiert haben sollten, wäre jetzt ein guter Zeitpunkt dafür.↩︎\nEine Alternative, um eine Spalte zu einer Zahl zusammenzufassen, bietet der “Dollar-Operator” ($): mean(mariokart$total_pr). Der Dollar-Operator trennt hier die Tabelle von der Spalte: tibble$spalte. Im Gegensatz zu den Verben des Tidyverse (die immer einer Tabelle zurückliefern), liefert der Dollar-Operator einen Vektor (Spalte) zurück. (Diese wird von mean dann zu einer einzelnen Zahl zusammengefasst.)↩︎\nJa, das ist traurig.↩︎\nJaja, das ist keine Pfeife, sondern ein Symbol einer Pfeife…↩︎\nEin beliebter Fehler ist es übrigens, nicht die richtige Zahl an schließenden Klammern hinzuschreiben, z.B. fasse_zusammen(gruppiere(wähle_spalten(filter_zeilen(meine_daten)))) FALSCHE ZAHL AN KLAMMERN.↩︎\nGenauer gesagt im Paket magrittr, welches aber under the hood von tidyverse geladen wird. Also nichts, um dass Sie sich kümmern müssten.↩︎\nSeit R 4.1↩︎\nAber auch keinen Nachteil. Unter Tools &gt; Global Options… können Sie einstellen, dass der Shortcut Strg-Shift-M die eingebaute Pfeife verwendet.↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#lernsteuerung",
    "href": "040-verbildlichen.html#lernsteuerung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n5.1.2 Lernziele\n\nSie können erläutern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arte von Datendiagrammen.\nSie können typische Datendiagramme mit R visualisieren.\nSie können zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\n\n\n5.1.4 Wozu das alles?\n\n\n\n\nQuelle: GIPHY\n\n\n\n🥷 Wir müssen die Galaxis retten, Kermit.\n\n\n🐸 Schlock",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heißt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte, s. Abbildung 5.1.\n\n\n\n\n\nAbbildung 5.1: Dinosaurier und Kreis: Gleiche statistischen Kennwerte\n\n\n\nQuelle\n\nIn Abbildung 5.1 sieht man zwei verschiedene “Bilder”, also Datensätze: einmal einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschiedene sind, sind die zentralen statistischen Kennwerte (praktisch) identisch.\nIn die gleiche Bresche schlägt “Anscombes Quartett”, s. Abbildung 5.2: Es zeigt 4 Datensätze, in denen die zentralen Statistiken fast identisch sind, also Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthüllt, was der Statistik (als Kennzahl) verhüllt bleibt.\n\n\n\n\n\n\nWichtig\n\n\n\nStatistische Diagramme können Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier Datensätzen\n\n\n\nQuelle\n\nUnter visueller Cortex ist sehr leistungsfähig. Wir können ohne Mühe eine große Anzahl an Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen.\n\n\n\n\n\n\nTipp\n\n\n\nNutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mächtig.\n\n\n\n5.2.1 Datendiagramm\nEin Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwändiges (und ansprechendes) Datendiagramm) Hier finden Sie ein Beispiel für ein Datendiagramm, das mit R erzeugt wurde (Scherer et al., 2019).\n\n\n5.2.2 Ein Bild hat nicht so viele Dimensionen\nAbbildung 5.3 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer “Dimension” entsprechen. Wie man (nicht) sieht, wird es langsam unübersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die “Dimensionalität” eines Diagramms hat ihre Grenzen, vielleicht bei 4-6 Variablen.\n\n\n\n\n\n\n\nAbbildung 5.3: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\nMöchten wir den Zusammenhang von vielen Variablen, z.B. mehr als 5, verstehen, kommen wir mit Bildern nicht weiter. Dann brauchen wir andere Werkzeuge: statistics to the rescue.\n\n\n\n\n\n\nHinweis\n\n\n\nBei klaren Zusammenhängen und wenig Variablen braucht man keine (aufwändige) Statistik. Ein Bild (Datendiagramm) ist dann (oft) ausreichend. Man könnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. 4-6 Variablen nicht gleichzeitig umgehen kann.\n\n\n\nÜbungsaufgabe 5.1 Wie viele Variablen sind in Abbildung 5.3 dargestellt?1\n\nEine weitere Möglichkeit, mehr Variablen in einem Diagramm unterzubringen, ist, die “Flatlands” zu verlassen, also von 2D auf 3D zu wechseln, s. hier, s. Abbildung 5.4.\n\n\n\n\n\n\n\nAbbildung 5.4: Eine 3D-Karte der Erde\n\n\n\nQuelle: Plotly",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelle 5.1 zeigt eine - sehr kurze Nomenklatur - an Datendigrammen.2\n\n\n\nTabelle 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefülltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefülltes Balkendiagramm\nBoxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir arbeiten hier mit dem Datensatz mariokart. Hilfe bzw. ein Data-Dictionary (Codebook) finden Sie hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung: nominale Variable\n\nDefinition 5.1 (Verteilung) Eine (Häufigkeits-)Verteilung einer Variablen \\(X\\) schlüsselt auf, wie häufig jede Ausprägung von \\(X\\) ist.\\(\\square\\)\n\n\nBeispiel 5.2 Tabelle 5.2 zeigt die Häufigkeitsverteilung von cond aus dem Datensatz mariokart. Die Variable hat 5 Ausprägungen; z.b. kommt die Ausprägung new 59 mal vor.\\(\\square\\)\n\n\n\n\nTabelle 5.2: Häufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. Abbildung 5.5. Wie man sieht, besteht so ein Diagramm als Balken, daher heißt es Balkendiagramm3. Man kann so ein Diagramm um 90° drehen; keine Ausrichtung ist unbedingt besser als die andere.\n\nDefinition 5.2 (Balkendiagramm) Ein Balkendiagramm eignet sich, um Häufigkeiten darzustellen\n\n\n\n\n\n\n\n\nAbbildung 5.5: Häufigkeitsverteilung der Variable cond\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.6: Balkendiagramm mit dem R-Paket DataExplorer\n\n\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. Abbildung 5.6.\nZuerst importieren wir die Daten, s. Listing 5.1.\n\n\nListing 5.1: Mariokart-Daten importieren von einer Webseite\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n\nAußerdem nicht vergessen, das Paket DataExplorer zu starten, s. Listing 5.2.4 In diesem Paket “wohnen” die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden.\n\n\nListing 5.2: Wir starten das R-Paket DataExplorer\n\nlibrary(DataExplorer)\n\n\n\n\n\nListing 5.3: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\nListing 5.4: Syntax zur Erstellung eines Balkendiagramms\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\nDie Syntax ist in Listing 5.4 abgedruckt5 . Übersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz mariokart *und dann*\n  wähle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm.\n\nÜbungsaufgabe 5.2 (Spalten wählen für das Balkendiagramm) Hätten wir andere Spalten ausgewählt, so würde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie können auch mehrere Variablen auf einmal auswählen. Probieren Sie das doch mal aus!\n\n\n\n5.4.2 Verteilung: quantitative Variable\n\n5.4.2.1 Histogramm\nBei einer quantitativen Variablen mit vielen Ausprägungen wäre ein Balkendiagramm nicht so aussagekräftig, s. Abbildung 5.7. Es gibt einfach zu viele Ausprägungen.\n\n\n\n\n\n\n\nAbbildung 5.7: Balkendiagramm für total_pr\n\n\n\n\nDie Lösung: Wir reduzieren die Anzahl der Ausprägungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger Ausprägungen zu bekommen, können wir einfach Gruppen definieren, z.B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 2: 11-15 Dollar …\n\nIn Abbildung 5.8 sind z.B. die Ausprägungen des Verkaufspreis (total_pr) in in Gruppen der Breite von 5 Dollar aufgeteilt worden. Zusätzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\nAbbildung 5.8: Balkendiagramm für total_pr\n\n\n\n\n\nDefinition 5.3 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der Häufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt sind. Die Höhe der Balken zeigt die Häufigkeit der Daten in dieser Gruppe/in diesem Balken6.\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten nicht sehr viele und nicht sehr wenig sein, s. Abbildung 5.9 links bzw. Abbildung 5.9, rechts.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildung 5.9: Nicht zu wenig und nicht zu viele Balken im Balkendiagramm\n\n\nZur Erstellung eines Histogramms können Sie die Syntax Listing 5.5 nützen, vgl. Abbildung 5.10, links.\n\n\nListing 5.5: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 5.10: Eine stetige Verteilung verbildlichen\n\n\n\n5.4.2.2 Dichtediagramm\nAbbildung 5.11 fügt zu Abbildung 5.8 ein Dichtediagramm hinzu (rote Linie). Ein Dichtediagramm ähnelt einem “glattgeschmirgeltem” Histogramm.\n\nDefinition 5.4 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglättet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden.7\n\n\n\n\n\n\n\n\nAbbildung 5.11: Balkendiagramm für total_pr\n\n\n\n\n\nÜbungsaufgabe 5.3 Erstellen Sie das Diagramm Abbildung 5.10, rechtes Teildiagramm!8\\(\\square\\)\n\n\n5.4.2.3 Eigenschaften von Verteilungen\nVerteilungen unterscheiden sich z.B. einerseits in ihrem “typischen” oder “mittleren” Wert9 und anderseits in ihrer Streuung10\n(Diagramme von) Verteilungen können symmetrisch oder schief (nicht symmetrisch) sein, s. Abbildung 5.12.\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildung 5.12: Symmetrische vs. schiefe Verteilung, verbildlicht\n\n\nAbbildung 5.13 zeigt verschiedene Formen von Verteilungen. “Bimodal” meint “zweigipflig” und “multimodal” entsprechend “mehrgipflig”.\n\n\n\n\n\n\n\nAbbildung 5.13: Verschiedene Verteilungsformen\n\n\n\n\nQuelle: ifes/FOM Hochschule\n\n5.4.3 Normalverteilung\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer quantitativen Variablen. Aber sie ist besonders wichtig, und ist daher hier herausgestellt.\nEine Normalverteilung sehen Sie in Abbildung 5.12, links. Sie hat u.a. folgende Eigenschaften:\n\nsymmetrisch\nglockenförmig\nstetig\neingipflig (unimodal)\nMittelwert, Median und Modus sind identisch\n\n\nBeispiel 5.3 Beispiele für normalverteilte Variablen sind Körpergröße von Männern oder Frauen, IQ-Werte, Prüfungsergebnisse, Messfehler, Lebensdauer von Glühbirnen, Gewichte von Brotlaiben, Milchproduktion von Kühen, Brustumfang schottischer Soldaten (Lyon, 2014).\\(\\square\\)\n\nDie Normalverteilung ist von hoher Bedeutung, da sich diese Verteilung unter (recht häufigen) Bedingungen zwangsläufig ergeben muss.\n\nDefinition 5.5 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhängiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\nDieses Phänomen kann man gut anhand des Galton-Bretts veranschaulichen.\n\n\n\n\n\n\n\nParameter der Normalverteilung\n\n\n\nEine Normalverteilung lässt sich exakt beschreiben anhand zweier Parameter: ihres zentralen Werts (Mittelwerts), \\(\\mu\\) und ihrer Streuung (Standardabweichung), \\(\\sigma\\). \\(\\square\\)\n\n\nAbbildung 5.14 zeigt interaktive Beispiele für Normalverteilung. Wählen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler. Quelle\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\n\n\n\n\n\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\n\n\n\n\n\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\n\n\n\n\n\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\n\n\n\n\n\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\n\n\n\n\n\n\nshow_curve = true\n\n\n\n\n\n\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\n\n\n\n\n\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\nAbbildung 5.14: Interaktives Beispiel für Normalverteilungen.\n\n\nKennt man diese beiden Parameter, so kann man einfach angeben, welcher Anteil der Fläche sich in einem bestimmten Bereich befindet, s. Abbildung 5.15.\nDavon leitet sich die “68-95-99-Prozentregel” ab:\n\n\n\\(68\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{,}7\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildung 5.15: Die Flächeninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in Abhängigkeit der SD-Einheiten\n\n\nBy Ainali - Own work, CC BY-SA 3.0",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.5 Zusammenhänge verbildlichen",
    "text": "5.5 Zusammenhänge verbildlichen\n\n5.5.1 Zusammenhang: nominale Variablen\n\nBeispiel 5.4 (Beispiele für Zusammenhänge bei nominalen Variablen)  \n\nHängt Berufserfolg (Führungskraft ja/nein) mit dem Geschlecht zusammen?\nHängt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen Automarke und politische Präferenz einer Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primär bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. Abbildung 5.16.\n\n\n\n\n\n\n\n\n\n(a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten\n\n\n\n\n\n\n\n\n\n(b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\n\n\n\nAbbildung 5.16: Zusammenhang zwischen nominalskalierten Variablen verbildlichen\n\n\nTatsächlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (Abbildung 5.16, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der Hälfte der Fälle.\nAnders sieht es aus für die Frage, ob ein (oder mehrere) Lenkräder dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach “Foto des Produkts dabei” betraf (Abbildung 5.16, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten).\nAnders gesagt: Unterscheiden sich die “Füllhöhe” in den Diagrammen, so gibt es einen Unterschied hinsichtlich “Foto ist dabei” zwischen den beiden Gruppen (linker vs. rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs. gebrauchte Spiele), so spielt z.B. die Variable “Foto dabei” offenbar eine Rolle. Dann hängen Neuwertigkeit und “Foto dabei” also zusammen!\nSo können Sie sich in R ein gefülltes Balkendiagramm ausgeben lassen, s. Abbildung 5.17.\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\nAbbildung 5.17: Ein gefülltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nGefüllte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei Ausprägungen aufweisen, sonst sind die Zusammenhänge nicht mehr so gut zu erkennen.\\(\\square\\)\n\n\n\n5.5.2 Zusammenhang: metrisch\nDen (etwaigen) Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). Abbildung 5.18 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine “Trendgerade” (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schließen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je höher der Startpreis, desto höher der Abschlusspreis, zumindest tendenziell. Diese Gerade liegt “mittig” in den Daten (wir definieren dies später genauer). Diese Trendgerade gibt Aufschluss über “typische” Werte: Welcher Y-Wert ist “typisch” für einen bestimmten X-Wert?\nAbbildung 5.18 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis. Das erkennt man an der sinkenden Trendgeraden.\nDie Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. Abbildung 5.20.\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) negativer, eher schwacher Zusammenhang\n\n\n\n\n\n\nAbbildung 5.18: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\nDefinition 5.6 (Linearer Zusammenhang) Lässt sich die Beziehung zwischen zwei Variablen mit einer Gerade visualisieren, so spricht man von einem linearen Zusammenhang. Ändert man eine der beiden Variablen um einen bestimmten Wert (z.B. 1), so ändert sich die andere um einen proportionalen Weg (z.B. 0.5). \\(\\square\\)\n\nNatürlich könnte man auch nicht-lineare Zusammenhänge untersuchen, aber der Einfachheit halber konzentrieren wir uns mit linearen; Beispiele für nicht-lineare Zusammenhänge sind in Abbildung 5.19 zu sehen.\n\n\n\n\n\n\n\nAbbildung 5.19: Beispiele nichtlinearer Zusammenhänge\n\n\n\n\n\nDefinition 5.7 (Richtig und Stärke eines Zusammenhang) Gleichsinnige (positive) Zusammenhänge erkennt man an aufsteigenden Trendgeraden; gegensinnigen (negative) Zusammenhänge an absteigenden Trendgeraden:\n\n➕ : ⬆️\n➖ : ⬇️\n\nStarke Zusammenhänge erkennt man an schmalen Ellipsen (“Baguette”); schwache Zusammenhänge an breiten Ellipsen (“Torte”):\n\nschwach: 🥮\nstark: 🥖\n\n\\(\\square\\)\n\nAbbildung 5.20 bietet einen Überblick über verschiedene Beispiele von Richtung und Stärke von Zusammenhängen.\n\n\n\n\n\n\n\nAbbildung 5.20: Lineare Zusammenhänge verschiedener Stärke und Richtung\n\n\n\n\n\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgraf\n\nIn Abbildung 5.20 ist für jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und Stärke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht für einen positiven Zusammenhang, ein negatives Vorzeichen für einen negativen Zusammenhang. Der (Absolut-)Wert gibt die Stärke des linearen Zusammenhangs an (Cohen, 1992):\n\n±0: Kein Zusammenhang\n±0.1: schwacher Zusammenhang\n±0.3: mittlerer Zusammenhang\n±0.5: starker Zusammenhang\n±1: perfekter Zusammenhang\n\nAbbildung 5.21 hat die gleiche Aussage, ist aber plakativer, indem Stärke (schwach, stark) und Richtung (positiv, negativ) gegenübergestellt sind.\n\n\n\n\n\n\n\nAbbildung 5.21: Überblick über starke vs. schwache bzw. positive vs. negative Zusammenhänge\n\n\n\n\nMan sieht in Abbildung 5.20 und Abbildung 5.21, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade 11 (blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke Zusammenhänge mit einer schmaler Ellipse einhergehen und schwache Zusammenhänge mit einer breiten Ellipse einhergehen.\nAbbildung 5.22 zeigt interaktive Beispiele für (lineare) Zusammenhänge. Quelle\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.22: Interaktives Beispiel für Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und machmal gehört Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhängen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. Starten Sie dieses Paket, s. Listing 5.2. Außerdem müssen wir noch die Daten importieren, falls noch nicht getan, s. Listing 5.1.\nSo, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf metrische Variablen konzentrieren wollen, wählen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewählten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primär interessiert. Das Ergebnis sieht man in Abbildung 5.23.\n\nmariokart %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildung 5.23: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nAha… Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafür sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur Verkäufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100). Das Ergebnis ist in Abbildung 5.24 zu sehen.\n\nmariokart2 &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nmariokart2 %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildung 5.24: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\n\nOhne Extremwerte schält sich ein deutlicheres Bild (Abbildung 5.24) hervor: Startpreis (start_pr) und Anzahl der Räder (wheels) scheinen am stärksten mit dem Abschlusspreis zusammenzuhängen.\nDas Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle übrigen Variablen kommen jeweils einmal als X-Variable vor.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.6 Unterschiede verbildlichen",
    "text": "5.6 Unterschiede verbildlichen\n\n5.6.1 Unterschied: nominale Variablen\nGute Nachrichten: Für nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von Zusammenhängen als auch von Unterschieden an. Genau genommen zeigt ja Abbildung 5.16 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Photos beiliegen. Und wie man in Abbildung 5.16 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen höher als bei gebrauchten Spielen.12\n\n5.6.2 Unterschied: quantitative Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich unterscheiden. Genauer gesagt untersucht man z.B. oft, ob sich die Mittelwerte der beiden Gruppen zwischen der Zielvariablen deutlich unterscheiden. Das hört sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. Abbildung 5.25.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildung 5.25: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 5.25 zeigt das Histogramm von total_pr, getrennt für neue und gebrauchte Spiele, vgl. Abbildung 5.10. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsfrom, den Boxplot.13\n\n\n\n\n\n\n\n\n\n(a) Y: Abschlusspreis, X: Zustand\n\n\n\n\n\n\n\n\n\n(b) Y: Abschlusspreis, X: Photo dabei?\n\n\n\n\n\n\nAbbildung 5.26: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 5.26 zeigt den Unterschied in den Verteilungen von total_pr, einmal für die neuen Computerspiele (cond == new) und einmal für gebrauchte Spiele (cond == used).\nWas ein “deutlicher”14 Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\nDefinition 5.8 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms.15 Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar.\\(\\square\\)\n\nIn Abbildung 5.27 sieht man die “Übersetzung” von Histogramm (oben) zu einem Boxplot (unten).\n\n\n\n\n\n\n\nAbbildung 5.27: Übersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die “Anatomie” des Boxplots näher an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto größer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie “Antennen” des Boxplots zeigen die Streuung in den kleinsten 25% der Werte (linke Antenne) bzw. die Streuung der größten 25% der Werte (rechte Antennen). Je länger die Antenne, desto größer die Streuung.\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, außerhalb der Antennen gezeigt werden. Daher ist die Antennenlänge auf die 1,5-fache Länge der Box beschränkt. Werte die außerhalb dieses Bereichs liegen (also mehr als das 1,5-fache der Boxlänge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.h. sie ist schief). Gleiches gilt für die Antennenlängen: Sind die Antennen gleich lang, so ist der äußere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der Lenkräder untersucht. Jetzt möchten Sie eine sehr ähnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten Lenkräder? Flink erstellen Sie dazu folgendes Diagramm, Abbildung 5.28, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl Lenkräder (by = \"wheels).\nAber ganz glücklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wäre eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen würde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von Abbildung 5.28) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert.16 Aber wir möchten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir möchten wheels als nominale Variable definieren. Das kann man mit dem Befehle factor(wheels) erreichen (verpackt in mutate), s. Abbildung 5.28, rechts.\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  mutate(wheels = factor(wheels)) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildung 5.28: Abschlusspreis nach Anzahl von beigelegten Lenkrädern\n\n\nSie schlißen aus dem Bild, dass Lenkräder und Preis (positiv) zusammenhängen. Allerdings scheint es wenig Daten für wheels == 4 zu geben. Das prüfen Sie nach:\n\nmariokart2 %&gt;% \n  count(wheels)\n\n\n  \n\n\n\nTatsächlich gibt es (in mariokart2) auch für 3 Lenkräder schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten.\\(\\square\\)\n\nÜbrigens bezeichnet Sie Ihre Chefin nur noch als “Datengott”.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.7 So lügt man mit Statistik",
    "text": "5.7 So lügt man mit Statistik\nDiagramme werden häufig eingesetzt, um die Wahrheit “aufzuhübschen”.\n\n5.7.1 Achsen manipulieren\nAchsen zu stauchen ist ein einfacher Trick, s. Abbildung 5.29.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.29: Stauchen der Y-Achse, um mit Statistik zu lügen\n\n\nNatürlich kann man auch durch “Abschneiden” der Y-Achse einen eindrucksvollen Effekt erzielen, s. Abbildung 5.30.\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.30: Abschneiden der Y-Achse, um mit Statistik zu lügen\n\n\n\n5.7.2 Scheinkorrelation\nMesserli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: Länder), s. Abbildung 5.31. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?)\n\n\n\n\n\nAbbildung 5.31: Schokolodenkonsum und Nobelpreise\n\n\nLeider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhängen, heißt das nicht, dass die Variable die Ursache und die andere die Wirkung sein muss. So könnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In höher entwickelten Ländern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu Ländern mit geringerem Entwicklungsstand.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.8 Praxisbezug",
    "text": "5.8 Praxisbezug\nEin, wie ich finde schlagendes Beispiel zur Stärke von Datendiagrammen ist Abbildung 5.32. Das Diagramm zeigt die Häufigkeit von Masern, vor und nach der Einführung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurück. Das Diagramm und weitere finden sich in ähnlicher Form im Wall Street Journal.\n\n\n\n\n\nAbbildung 5.32: Häufigkeit von Masern und Impfung in den USA, Lizenz: MIT\n\n\nQuellcode Datenquelle\nIn der “freien Wildbahn” findet man häufig sog. “Tortendiagramme”. Zwar sind sie beliebt, doch ist von ihrer Verwendung zumeist abzuraten; vgl. auch hier.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\nEinen Überblick über verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur findet sich bei data-to-vis.\n\n5.9.1 Animation\nEine weitere nützliche Art von Visualisierung sind Karten und Animationen. So zeigt z.B. Abbildung 5.33 die Veränderung der Lebenserwartung (in Jahren) über die letzten Dekaden.\n\n\n\n\n\nAbbildung 5.33: Animation zur Veränderung der Lebenserwartung\n\n\nDer Quellcode der Animation ist hier zu finden.\nIn einigen Situation können Animationen zweckdienlich sein. Außerdem sind sie mitunter nett anzuschauen, s. Abbildung 5.34.\n\n\n\n\n\nAbbildung 5.34: Veränderung des Zusammenhangs von Lebenswertung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\nNatürlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animationen ziemlich atemberaubend.\n\n5.9.2 Schicke Diagramme\nEin Teil der Diagramm dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen, so lautet die etwa die Syntax von Abbildung 5.26 wie folgt.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMöchte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median heraustellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.B.) mit ggpubr, s. Abbildung 5.35.\n\nggviolin(mariokart2, x = \"cond\", y = \"total_pr\",\n         add = \"mean_sd\") \n\n\n\n\n\n\nAbbildung 5.35: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nEin “Violinenplot” hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die “Violine”, desto mehr Beobachtungen gibt es an dieser Stelle. Weitere Varianten zum Violinenplot mit ggpubr finden sich hier.\nÜbrigens sind Modelle - und Diagramme sind Modelle - immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen. Dieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.\nEin weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heißt ggstatsplot.\nAbbildung 5.36 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart2,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrückt statistische Kennzahlen\n)\n\n\n\n\n\n\nAbbildung 5.36: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. Möchte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE.17.\n\n🧑‍🎓 Ich würde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\n👨‍🏫 Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.\n\n\n5.9.3 Farbwahl\nEinige Überlegungen zur Farbwahl findet sich in diesem Post; ausführlichere Erläuterung bietet Wilke (2019), s. Kap. 4.\nSo ist die Farbpalette von Okabe und Ito (vgl. Ichihara et al., 2008) empfehlenswert, da sie auch bei Schwarz-Weiß-Druck und bei Sehschwächen die Farben noch recht gut unterscheiden lässt, s. Abbildung 5.37\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\") +\n  scale_fill_okabeito()\n\n\n\n\n\n\nAbbildung 5.37: Die Farbskala von Okabe und Ito: Geeignet bei Farbseh-Schwächen und für Schwarz-Weiß-Druck. Außerdem nett anzuschauen.\n\n\n\n\n\n5.9.4 Literaturhinweise\nSowohl ggpubr als auch DataExplorer (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2009). Eine neue, gute Einführung in Datenvisualisierung findet sich bei Wilke (2019). Beide Bücher sind kostenfrei online lesbar.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise-1",
    "href": "040-verbildlichen.html#literaturhinweise-1",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.11 Literaturhinweise",
    "text": "5.11 Literaturhinweise\nWilke (2019) gibt einen hervorragenden Überblick über praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In ähnlicher Richtung geht Fisher & Meyer (2018). Hier ist eine Liste von Büchern zum Thema; dort können Sie bei Interesse tiefer suchen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literatur",
    "href": "040-verbildlichen.html#literatur",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.12 Literatur",
    "text": "5.12 Literatur\n\n\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155–159.\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight (First edition). O’Reilly.\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206–213. https://doi.org/10.1117/12.765420\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nScherer, C., Radchuk, V., Staubach, C., Müller, S., Blaum, N., Thulke, H., & Kramer‐Schadt, S. (2019). Seasonal Host Life‐history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812–1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152–2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2009). Ggplot2: Elegant Graphics for Data Analysis. Springer. https://doi.org/10.1007/978-0-387-98141-3\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures (First edition). O’Reilly Media. https://clauswilke.com/dataviz/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5↩︎\nWeitere Nomenklaturen sind möglich, aber wir halten hier die Sache einfach.↩︎\nsynonym: Säulendiagramm↩︎\nNatürlich müssen Sie das Paket einmalig installiert haben, bevor Sie es starten können.↩︎\nZur Erinnerung: %&gt;% nennt man die “Pfeife und lässt sich als”und dann” übersetzen, vgl. Kapitel 4.4.↩︎\nbei konstanter Balkenbreite↩︎\nMit Dichte ist die Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.↩︎\nGrob gesagt: mariokart %&gt;% plot_density().↩︎\nvgl. Kapitel 6.5↩︎\nvgl. Kapitel 7.4.↩︎\nsynonym: Regressionsgerade↩︎\nAber Freunde lassen Freunde keine Tortendiagramme verwenden.↩︎\nÜbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen.↩︎\n“substanzieller”, “bedeutsamer”, “relevanter” oder “(inhaltlich) signifikanter”↩︎\nOb der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack überlassen.↩︎\nVielleicht so, dass in jeder Gruppe gleich viele Wert sind?↩︎\nWeitere Hinweise finden sich auf der Hilfeseite der Funktion↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#lernsteuerung",
    "href": "050-zusammenfassen.html#lernsteuerung",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n6.1.2 Lernziele\n\nSie können gängige Arten von Lagemaße definieren.\nSie können erläutern, inwiefern man ein Lagemaß als ein Modell hernehmen kann.\nSie können Lagemaße mit R berechnen.\n\n6.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n6.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer klassische Mittelwert (arithmetisches Mittel) ist ein prototypisches Beispiel für ein Modell in der Statistik.\n\nÜbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hören, dass der “typische deutsche Mann” 1,80m groß ist (Roser et al., 2013)?1\n\nDie Hälfte der Männer ist größer als 1,80m, die andere Hälfte kleiner.\nDas arithmetische Mittel der Männer beträgt 1,80m.\nDie meisten Männer sind 1,80m groß.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÜbungsaufgabe 6.2 Laut dieser Quelle beträgt der Wert der mittleren Größe deutscher Frauen etwa 1,66m, also 14 cm weniger als bei Männern. \\(\\square\\)\n\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiß nicht \\(\\square\\)\n\n\n\n\nAuf dieser Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So könnte man z.B. sagen, “mehr als 5 cm sind viel”. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\)) beträgt: 2. \\(\\square\\)\n\n\n🧑‍🎓 Zu easy!\n\n\n👨‍🏫 Schon gut! Chill mal. Wird gleich interessanter.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig. 😄\n\nEtwas abstrakter kann man Beispiel 6.1 in folgendem Schaubild darstellen, s. Gleichung 6.1.\n\\[\n\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} = 3 \\cdot \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}\n\\tag{6.1}\\]\nDer Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) für die “typische Note” im Statistikkurs, s. Gleichung 6.2.\n\\[\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} \\qquad \\leftrightarrow  \\qquad \\underbrace{\\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}}_{\\text{\"typischer Vertreter\"}} \\tag{6.2}\\]\n\n\n\n\n\n\nWichtig\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er eine Datenreihe zu einen “typischen Vertreter” zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller Merkmalsträger in gleichem Maße einfließen. Er gibt uns eine (mögliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen.\n\n\nEine nützliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. Abbildung 6.1.\n\n\n\n\n\nAbbildung 6.1: Mittelwert als ausbalancierte Wippe mit Mittelwert 3\n\n\n\nQuelle: Von Maphry - Eigenes Werk, CC BY-SA 4.0\n\nIn “Mathe-Sprech” bezeichnet man den Mittelwert häufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. Gleichung 6.3.\n\\[\\bar {x} =\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.3}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert von \\(X\\), präziser: das arithmetische Mittel, ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n. \\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. Abbildung 6.2 sehen wir die Noten von (dieses Mal) vier Studentis. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert. Bezeichnen wir die Abweichung - auch als “Fehler”, “Rest” oder “Residuum” bezeichnet - der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, “Fehler) und die \\(i\\)-te Note mit \\(x_i\\), so können wir festhalten:\n\\[\\color{ycol}{\\text{y}_i} = \\color{modelcol}{\\bar{x}} + \\color{errorcol}{\\text{e}_i}\\]\nAnders ausgedrückt:\n\\[\\color{ycol}{\\text{Daten}} =     \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe.\nUm Modelle darzustellen, wird in der Datenanalyse häufig folgende Art von Modellgleichung verwendet, s. Gleichung 6.4.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{6.4}\\]\nLies: “Der Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)”. Der Kringel “~”2 soll also hier heißen “… ist eine Funktion von …”.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklärende Variable3 gemeint. Das “Dach” über dem \\(\\color{ycol}{\\text{y}}\\) bedeutet “vorhergesagter Y-Wert” oder “Y-Wert laut dem Modell”. Der tatsächliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\).\n\\[\\color{ycol}{\\text{y}}  = \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (“y-Dach”). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir schreiben können:\n\\[\\color{ycol}{y}  = \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklärt, außer gehen wir von einem Fehler \\(e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In späteren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklären. Würden wir z.B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklären, so würden wir schreiben:\n\\[\\color{modelcol}{\\bar{y}} \\sim \\color{xcol}{\\text{x}} \\] Da wir im Moment aber keine andere Variablen bemühen, um \\(\\color{ycol}{\\text{y}}\\) zu erklären, schreibt man auch:\n\\[\\color{modelcol}{\\bar{y}} \\sim 1\\]\nDiese Schreibweise sieht verwirrend aus. Die \\(1\\) soll aber einfach zeigen, dass wir keine andere Variable zur Erklärung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\).\n\nBeispiel 6.2 (Noten, Mittelwert und Abweichung) Vier Studentis – Anna, Berta, Carl, Dani – haben ihre Statistik-Klausur zurückbekommen (Schluck). Die Noten sehen Sie in Abbildung 6.2, gar nicht so schlecht ausgefallen. Außerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen der einzelnen Noten vom Mittelwert eingezeichnet.\\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken4 in Abbildung 6.2 einmal genauer an.\n\n\n\n\n\n\n\nAbbildung 6.2: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\nJetzt stellen Sie sich vor, Sie würden die vom Mittelwert nach oben ragenden Balkenlängen aneinanderlegen (das sind die gestrichelten. Sehen Sie das vor Ihrem geistigen Auge? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht) jetzt, dass die Gesamtlänge der “Balken nach oben” identisch ist zur Gesamtlänge der nach “unten ragenden Balken”, vgl. Abbildung 6.1.\nPräziser ausgedrückt und ohne Ihre Phantasie zu strapazieren (Gleichung 6.5):\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.5}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDie Summe der Abweichungen vom Mittelwert ist Null.\n\n\n\nÜbungsaufgabe 6.3 Was schätzen Sie, wie hoch das “mittlere” Vermögen des Haushalte in Deutschland in etwa ist?5)\n\n\n\nAuswahl\nAntwort\n\n\n\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\n\n\n\n\n\n50.000 Euro, ca. 60.000 Euro (laut der o.g. Quelle)\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\n\n\n\n\n\nBeispiel 6.3 (Der reichste Mensch der Welt in Ihrem Hörsaal) Kommt der wertvollste Fußballspieler der Welt in Ihren Hörsaal, sagen wir, es ist Kylian Mbappé6. Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro7.\n\n🦹‍♂️ Hey Leute, wie geht’s denn so! Wie viel Kohle verdient ihr eigentlich so?\n\n\n🧑‍🎓 Äh, wir studieren und verdienen fast nix!\n\nDie 100 Studis im Hörsaal schauen verdattert aus der Wäsche: Was ist das für eine komische Frage!? Aber zumindest verteilt der Fußballspieler Autogramme.\n\n\nÜbungsaufgabe 6.4 (Mittleres Einkommen im Hörsaal, mit Kylian Mbappé) Schätzen Sie – im Kopf – das mittlere Vermögen im Hörsaal, gehen Sie davon aus, dass alle der 100 Studentis jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (präziser: das arithmetische Mittel des Einkommens) wie folgt berechnen.8\n\n\nListing 6.1: Wir simulieren Einkommen von 100 Studis plus Mbappé.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100 Mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 Mbappé mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nuller hinter der führenden Eins. 1 Million ist 1000 mal 1000. Anders gesagt: 1 Million = \\(10^6 = 10^3 * 10^3\\). In Taschenrechner oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als “1 Mal 10 hoch 6, also mit 6 im Exponenten”.\n\n\nDer Mittelwert im Hörsaal beträgt also 1,189,109 Euro. Ist das ein gutes Modell für das “typische” Vermögen im Hörsaal?\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. Abbildung 6.3, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell verwendet eine Gerade als Modell der Daten. Es erklärt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildung 6.3: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\nAbbildung 6.3 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit Extremwerte (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (engl. outlier) ist eine Beobachtung, dessen Wert deutlich vom Großteil der anderen Beobachtungen im Datensatz abweicht, z.B. viel größer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R (vgl. Listing 6.1):\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear modell\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl gibt als Koeffizient einen Wert zurück und zwar den Mittelwert von einkommen, Listing 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet, das wird verständlich, wenn man z.B. in Abbildung 6.3 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet.\nDie Syntax des Befehls lm() sieht etwas merkwürdig aus. Ignorieren Sie das fürs Erste, wir besprechen das später (Kapitel 9) ausführlich. lm steht übrigens für “lineares Modell”.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6  Punktmodelle 1",
    "section": "\n6.3 Median als Modell",
    "text": "6.3 Median als Modell\n\n🧑‍🎓 Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert für die Menschen im Hörsaal. Weder für den Mbappé, noch für uns Studis!\n\n\n👨‍🏫 Ja, da habt ihr Recht.\n\n\n⚽ Die Welt ist schon ungerecht!\n\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. Abbildung 6.4) ist der Mittelwert (sehr) wenig aussagekräftig, da er nicht mehr “typische” Werte für die Merkmalsträger beschreibt.\n\n\nAbbildung 6.4 stellt die Verteilung einer mit normal skalierter Achse und einmal mit logarithmischer X-Achse. Die logarithmische X-Achse stellt den Unterschied von Mittelwert (MW) und Median deutlicher heraus als die “normale” (additive) Achse.\n\n\n\n\n\n\n\n\n\n(a) X-Achse in additiver Form\n\n\n\n\n\n\n\n\n\n\n\n(b) X-Achse in multiplikativer Form (logarithmische Darstellung)\n\n\n\n\n\n\nAbbildung 6.4: Die Einkommensverteilung im Hörsaal\n\n\nDer Mittelwert ist Hörsaal ist nicht typisch für die Menschen im Hörsaal: Weder für Mbappé, noch für die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Mittelwert ist empfänglich für Extremwerte: Gibt es einen extremen Wert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wieder und weniger die Mehrheit der gemäßigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenüber Extremwerten).\n\n\n\nBeispiel 6.4 (Das Median-Einkommen einiger Studentinnen) Fünf Studentinnen tauschen sich über ihr Einkommen aus, s. Abbildung 6.5, links. Es handelt sich um eine schiefe Verteilung.\n\n\n\n\n\n\n\n\n\n(a) ID auf der X-Achse, Einkommen auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n\n(b) Einkommen auf der X-Achse, Häufigkeit auf der Y-Achse\n\n\n\n\n\n\nAbbildung 6.5: Das Median-Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\nWir könnten jetzt behaupten, dass Carla das typische Einkommen (für diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\nDefinition 6.4 (Median) Merkmalsausprägung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt. \\(\\square\\)\n\nDer Median ist robust (gegenüber) Extremwerten: Fügt man Extremwerte zu einer Verteilung hinzu, ändert sich der Median zumeist (deutlich) weniger als der Mittelwert.\nAbbildung 6.6 stellt den Median schematisch dar.\n\n\n\n\n\n\n1,60m\n\n\n\n\n\n1,72m\n\n\n\n\n\n1,79m: Median!\n\n\n\n\n\n1,94\n\n\n\n\n\n2,12m\n\n\n\n\n\nAbbildung 6.6: Der Median als der Wert des “mittleren” Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert als der Median wie Objekte mit größerem Wert als der Median.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.5 Bei der Messreihe 1, 2, 3, 4, 5, 6, 8, 9 beträgt der Median 4.5.\\(\\square\\)\n\n\nÜbungsaufgabe 6.5 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhöht sich um das Hundertfache. Wie verändert sich der Median?9 \\(\\square\\)\n\n\nÜbungsaufgabe 6.6 (Wer ist mehr “mittel”? Median oder Mittelwert?)  \n\n🧑‍🎓 Das arithmetische Mittel sollte Mittelwert heißen, weil es die Mitte von zwei Messwerten widerspiegelt, also z.B. von 1 und 10 ist die Mitte 5,5 - also genau beim Mittelwert!\n\n\n👩‍🎓 Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der Größe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion!\\(\\square\\)\n\n\nBeispiel 6.6 (Ein “mittlerer” Preis für Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median für das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist höher als der Median.\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n  \n\n\n\nWie man sieht, ist der Mittelwert größer als der Median, s. Abbildung 6.7\n\n\n\n\n\n\n\nAbbildung 6.7: Das Start-Gebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert größer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell für den “typischen Wert” vorzuziehen.\n\n\n\nÜbungsaufgabe 6.7 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die für einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis möglicherweise über die Gebühr. \\(\\square\\)\n\n\n\nAufgabe\nLösung\n\n\n\nEntfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\n\n\n\nmariokart2 &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# ohne Extremwerte:\nmariokart2 |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n\n  \n\n\n\n\n\n\n\nÜbungsaufgabe 6.8 Was schätzen Sie, wie hoch das mediane Vermögen des Haushalte in Deutschland in etwa ist (Stand 2016)?10)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\\(\\square\\)\n\n\n\n\nÜbungsaufgabe 6.9 Was schätzen Sie, wie groß der Unterschied zwischen medianem und mittlerem (arithm. Mittel) des Jahreseinkommen deutscher Haushalte ungefähr ist?11)\n\n1.000 Euro\n2.000 Euro\n3.000 Euro\n4.000 Euro\n5.000 Euro\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere Hälfte. Er markiert sozusagen eine “50-Prozent-Marke” (der aufsteigend sortierten Beobachtungen). Betrachten wir einmal nur alle Spiele, die für weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. Abbildung 6.8 (a). 50% aller Spiele wurden für weniger als ca. 46 Euro verkauft; 50% aller Spiele für mehr als 46 Euro. Der Median beträgt als 46 Euro.\nJetzt könnten wir nur die günstigere Hälfte betrachten und wieder nach dem Median fragen (d.h. total_pr &lt; 46). Dieser “Median der günstigeren Hälfte” grenzt damit das insgesamt günstigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25%). Den Median nennt man das zweite Quartil (Q2, 50%). Entsprechend heißt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75%).\\(\\square\\)\n\n\nBeispiel 6.7 (Quartile des Verkaufsgebot) Abbildung 6.8 (a) zeigt die Quartile für das Verkaufsgebot.\\(\\square\\)\n\nJetzt könnte man sagen, hey, warum nur in 25%-Stücke die Verteilung aufteilen? Warum nicht in 10%-Schritten?\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleiche Teile unterteilen, nennt man Dezile. \\(\\square\\)\n\nOder vielleicht in 1%-Schritten oder in sonstigen Schnitten? Wo die Quartile in 25%-Schritten aufteilen, teilt in Quantil in \\(p\\)-Prozent-Schritten auf, s. fig-quantile-anim.\n\nDefinition 6.7 (Quantile) Ein p-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht überschritten wird.\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Quantil ist ein Oberbegriff für Quartile, Dezile, etc. \\(\\square\\)\n\n\nAbbildung 6.8 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil für den Datensatz mariokart2.\n\n\n\n\n\n\n\n\n\n(a) Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)\n\n\n\n\n\n\nAbbildung 6.8: Verschiedene Arten von Quantilen.\n\n\nQuantile kann man in R mit dem Befehl quantile() berechnen:\n\nmario_quantile &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(q25 = quantile(total_pr, .25),\n            q50 = quantile(total_pr, .50),\n            q75 = quantile(total_pr, .75))\n\nAbbildung 6.9 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildung 6.9: Verschiedenen Quantile animiert\n\n\nAbbildung 6.10 visualisiert ebenfalls verschiedene Quantile. Man beachte, dass alle Regionen gleiche Flächen (d.h. Wahrscheinlichkeitsmassen) aufweisen.\n\n\n\n\nQuartile\nDezile\nPerzentile\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 6.10: Verschiedene Quantile visualisiert. In jedem Diagramm sind die Regionen gleich groß, beinhalten also (ungefähr) die gleiche Anzahl von Beobachtungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6  Punktmodelle 1",
    "section": "\n6.5 Lagemaße",
    "text": "6.5 Lagemaße\n\n🧑‍🎓 Was ist der Oberbegriff für Median, Mittelwert und so weiter?\n\n\n👩‍🏫 Gute Frage! Wie würden Sie ihn nennen?\n\n\nDefinition 6.8 (Lagemaß) Ein Lagemaß (synonym: Maß der zentralen Tendenz) für eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, zu erwarten, repräsentativ oder “mittel” ansehen sollten.\\(\\square\\)\n\n\nBeispiel 6.8 Typische Lagemaße sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuartile\nQuantile\nMinimum (kleinster Wert)\nMaximum (größter Wert)\nModus (häufigster Wert) \\(\\square\\)\n\n\n\nBerechnen wir Lagemaße für den Mariokart-Datensatz, s. Listing 6.2.12\n\n\nListing 6.2: Syntax zur Berechnung von Lagemaßen\n\n\nmariokart_lagemaße_total_pr &lt;-\n  mariokart %&gt;% \n  summarise(mw = mean(total_pr),\n            md = median(total_pr),\n            q1 = quantile(total_pr, .25),\n            q2 = quantile(total_pr, .5),\n            q3 = quantile(total_pr, .75),\n            min = min(total_pr),\n            max = max(total_pr))\nmariokart_lagemaße_total_pr\n\n\n  \n\n\n\n\n\n\n\n6.5.1 Gruppierte Lagemaße\nHäufig möchte man Statistiken wie Lagemaße für mehrere Teilgruppen – z.B. Mittlere Körpergröße von Frauen vs. Mittlere Körpergröße von Männer – berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage könnte lauten:\n\nUnterscheidet sich die mittlere Körpergröße von Frauen und Männern?\n\nOder vielleicht:\n\nHat das Geschlecht einen Einfluss auf die Körpergröße?\n\nAnders ausgedrückt:\n\nKörpergröße \\(\\color{ycol}{\\text{y}}\\) ist eine Funktion des Geschlechts \\(\\color{xcol}{G}\\).\n\nDie Modellformel könnte also lauten:\n\\[\\color{ycol}{y} \\sim \\color{xcol}{G}\\]\nGruppierte Lagemaße lassen sich in R z.B. so berechnen, s. Listing 6.3, also ähnlich wie in @#lst-mario-lage.\n\n\nListing 6.3: Gruppierte Lagemaße\n\n\nmariokart_lagemaße_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\nmariokart_lagemaße_gruppiert\n\n\n  \n\n\n\n\n\n\nAbbildung 6.11 zeigt ein Beispiel für ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. Abbildung 6.3. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, “globalen” Mittelwert): Innerhalb der Gruppe ohne Lenkräder und innerhalb der Gruppe mit 2 Lenkrädern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering – im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\n\n\n\n\n\n\n\n\n(a) Mittelwert für Verkaufspreis (ungruppiert)\n\n\n\n\n\n\n\n\n\n(b) Mittelwert für Verkaufspreis gruppiert nach Anzahl der Lenkräder\n\n\n\n\n\n\nAbbildung 6.11: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet\n\n\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches für alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heißt ein Punktmodell. Anders gesagt fasst ein Punktmodell eine Wertereihe (häufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem “Punkt” in diesem Sinne, s. Gleichung 6.6.\\(\\square\\)\n\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{6.6}\\]\nMittelwert, Median und Quartile sind Beispiele für Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein “Bild” der Daten, machen Sie uns verständlich - sie sind uns ein Modell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "title": "6  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lügt",
    "text": "6.6 Wie man mit Statistik lügt\nMit Statistik kann man vortrefflich lügen, heißt es. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lässt: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzuführen. Viele Wege führen nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und Unschärfen ohne böse Abwehr aufzudecken, gibt es ein probates Gegenmittel: Transparenz.\n\nStellen Sie hohe Anforderung an die Transparenz einer statistischen Analyse. Nur durch Nachprüfbarkeit können Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation überzeugen.\n\nHier ist eine (nicht abschließende!) Checkliste, was Sie nachprüfen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\n\n\n\n\n\nNr\nCheck\n\n\n\n1\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\n\n\n2\nWurden ausreichend Daten gesammelt (z.B. mind. 20 Beobachtungen pro Gruppe)?\n\n\n3\nWurden alle untersuchten Variablen berichtet?\n\n\n4\nWurden alle durchgeführten Interventionen berichtet?\n\n\n5\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) Begründung?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.9 (Survival-Tipp) Eine Studentin aus dem dem Bachelorstudiengang “Angewandte Medien- und Wirtschaftspsychologie” mit Schwerpunkt Data Science berichtet ihre “Survival-Tipps” für Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich während des Semesters neue Begriffe und ihre Erklärung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in höheren Semestern nach Tipps fragen.\\(\\square\\)\n\n\n\n\n👩‍🎓 Irgendwie kann ich mir R-Code so schlecht merken.\n\n\n👩‍🏫 Frag doch mal ChatGPT, oder einen anderen Chatbot, da bekommt man auch R-Code ausgegegeben.\n\n\nÜbungsaufgabe 6.10 (Übungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Übungsaufgaben.\nSie können sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\n🧑‍🎓 Ich bin ein Student in einem Bachelor-Studiengang für Psychologie. Gerade bereite ich mich auf die Klausur im Fach “Grundlagen der Statistik” vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die Prüfung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: Maße der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.B. Nominalskala vs. Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben.\n\n\\(\\square\\)\n\n\n6.7.1 Datensätze zum Üben\nMittlerweile verfügen Sie die wesentlichen Werkzeuge des Datenjudo. Hier finden Sie einen Überblick an Datensätze, die Sie nach Herzenslust analysieren können.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber später kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekannte Stoff.\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nnasa02\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu z.B. dem Tag EDA an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele Lehrbücher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehören zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel für Lehrbücher sind Mittag & Schüller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Ein Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurückschreckt, ist mit Cetinkaya-Rundel & Hardin (2021) oder Poldrack (2022) gut beraten. Beide Bücher sind online verfügbar. Tipp: Mit dem Browser einfach auf Deutsch übersetzen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literatur",
    "href": "050-zusammenfassen.html#literatur",
    "title": "6  Punktmodelle 1",
    "section": "\n6.10 Literatur",
    "text": "6.10 Literatur\n\n\n\n\nBortz, J., & Schuster, C. (2010). Statistik Für Human- Und Sozialwissenschaftler. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-642-12770-0\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung mit interaktiven Elementen. Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und Spaß im Horrorfach nichttechnischer Studiengänge. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. (2022). Statistical Thinking for the 21st Century. https://statsthinking21.github.io/statsthinking21-core-site/index.html\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height. Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren (1. Auflage 2019). Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., van Aert, R. C. M., & van Assen, M. A. L. M. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7, 1832. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "Ihr Vorstellung updatet sich in in Definition 6.1.↩︎\nDas “Kringel” oder die “Welle” “~” nennt man auch “Tilde”↩︎\nAV, Output-Variable, Zielvariable↩︎\nResiduen, Fehler; häufig mit \\(e\\) wie error bezeichnet↩︎\nQuelle: WSI \\(\\square\\), Abruf 2023-04-19↩︎\nQuelle: https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop, 2023-03-19↩︎\nQuelle: https://www.einkommenmagazin.de/kylian-mbappe-einkommen/, 2023-03-19↩︎\nDie Details der Syntax, z.B. der Befehl rep(), sind von geringer Bedeutung.↩︎\nEr bleibt gleich, verändert sich also nicht: Der Median ist robust, er verändert sich nicht oder kaum, wenn Extremwerte vorliegen.↩︎\nQuelle: WSI, https://www.wsi.de/en/how-is-wealth-distributed-in-germany-14401.htm, Abruf 2023-04-19. Die Antwort lautet: ca. 60 Tsd Euro laut der angegebenen Quelle↩︎\nQuelle: Wikipedia, Abruf 2023-04-19, der Unterschied beträgt knapp 3000 Euro laut der Quelle↩︎\nEs ist übrigens egal, wie sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname – alles okay!↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#lernsteuerung",
    "href": "060-modellguete.html#lernsteuerung",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n7.1.2 Lernziele\n\nSie kennen gängige Maße der Streuung einer Stichprobe und können diese definieren und mit Beispielen erläutern.\nSie können gängige Maße der Streuung einer Stichprobe mit R berechnen.\nSie können die Bedeutung von Streuung für die Güte eines Modells erläutern.\n\n7.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(ggpubr)\n\n\n7.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "href": "060-modellguete.html#warum-sie-die-streuung-ihrer-daten-kennen-sollten",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.2 Warum Sie die Streuung Ihrer Daten kennen sollten",
    "text": "7.2 Warum Sie die Streuung Ihrer Daten kennen sollten\n\n7.2.1 Prof. Weiss-Ois hat eine Idee\n\n\n\n7.2.1.1 Was er sagt\n\n\n“Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!”\n\n\n\n\n\n\n7.2.1.2 Was er NICHT sagt\n\n\n“Allerdings streuten die Werte der Gewichtsveränderung um 10kg um den Mittelwert herum.”\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\n\nWürden Sie die Pille von Prof. I. Ch. Weiss-Ois nehmen?1\n\nja\nnein\nNur wenn ich 100 Euro bekomme\nOkay, für 1000 Euro\\(\\square\\)\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information.\\(\\square\\)\n\n\n\n7.2.2 Wie man seine Kuh über den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss überqueren, nur kann die Kuh nicht schwimmen2.\n\n🧑‍🌾 (Fritz): Sag mal, Karl, ist der Fluss tief?\n\n\n👩‍🌾 (Karla): Nö, im Schnitt nur einen Meter.\n\nAlso führt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, s. Abbildung 7.1.\n\n\n\n\n\nAbbildung 7.1: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\n👩‍🌾 (Karla): Übrigens, Lagemaße sagen nicht alles, Fritz.\n\n\n🧑‍🌾 (Fritz): Läuft die Kuh durch den Fluss, kann sie schwimmen oder ’s ist Schluss.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.3 Woran erkennt man ein gutes Modell?",
    "text": "7.3 Woran erkennt man ein gutes Modell?\nAbbildung 7.2 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen.\n\n\n\n\n\n\n\nAbbildung 7.2: Ein Modell mit wenig Streuung vs. ein Modell mit viel Streuung\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsächlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groß.\n\n\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof. Weiss-Ois) In Abbildung 7.2 sind die Daten zu der Gewichtsveränderung nach Einnahme von “Schlankheitspillen” zweier verschiedener Präparate. Wie man sieht unterscheidet sich die typische (vorhergesagte) Gewichtsveränderung zwischen den beiden Präparaten kaum. Die Streuung allerdings schon. Links sieht man die Gewichtsveränderungen nach Einnahme des Präparats “Dickableibtin extra mild” (c) und rechts das Präparat von Prof. Weiss-Ois “Pfundafliptan Forte”. Welches Präparat würden Sie lieber einnehmen?\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nWir wollen ein präzises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklären, also wenig vom tatsächlichen Wert abweichen. Jedes Modell sollte Informationen über die Präzision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellgüte, d.h. der Präzision der Schätzung des Modellwerts, ist wenig nütze.\\(\\square\\)\n\n\n\n👩‍🎓 Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\n👩‍🏫 Die Frage ist, was wir mit “verbessern” meinen?\n\n\n👩‍🎓 Naja, kürzere Fehlerbalken, ist doch klar!\n\nDa die Anzahl der Lenkräder mit dem Verkaufsgebot zusammenhängt, könnte es vielleicht sein, dass wir die Lenkräder-Anzahl da irgendwie nutzen könnten. Das sollten wir ausprobieren.\nAbbildung 7.3 zeigt, dass die Fehlerbalken kürzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 Lenkrädern vs. mit 0 Lenkrädern) sind die Fehlerbalken jeweils im Durchschnitt kürzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm).3\n\n\n\n\n\n\n\n\n\n(a) Fehlerbalken im einfachen Modell: Ein Mittelwert; viel Streuung insgesamt\n\n\n\n\n\n\n\n\n\n(b) Fehlerbalken im komplexen Modell: Zwei Mittelwerte; wenig Streuung in jeder Gruppe\n\n\n\n\n\n\nAbbildung 7.3: Fehlerbalken in einem einfachen und komplexeren Modell\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.4 Streuungsmaße",
    "text": "7.4 Streuungsmaße\n\nDefinition 7.1 (Streuungsmaße) Ein Streuungsmaß quantifiziert die Variabilität eines Merkmals. \\(\\square\\)\n\nEin einfaches Streuungsmaß ist der Range, definiert als Abstand von größtem und kleinsten Wert eines Merkmals. Dieses Mermals ist aber nicht robust (gegenüber Extremwerten) und sollte daher nur mit Einschränkung verwendet werden.\n\n7.4.1 Der mittlere Abweichungsbalken\n\n🧑‍🎓 Wir müssen jetzt mal präziser werden! Wie können wir die Streuung berechnen?\n\n\n👨‍🏫 Gute Frage! Am einfachsten ist es, wenn wir die mittlere Länge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir wir den “mittleren Abweichungsbalken”, den wir mit \\(\\varnothing e\\) bezeichnen könnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als Mittlere Absolutabweichung (MAA). Er ist so definiert, s. Gleichung 7.1.\n\\[{\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}.} \\tag{7.1}\\]\n\nDefinition 7.2 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte.4\\(\\square\\)\n\n\nBeispiel 7.2 Abbildung 7.4 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE für das Beispiel von Abbildung 7.4 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5\\)\n\n\n\n\n\n\n\n\nAbbildung 7.4: Abweichungsbalken und der MAE\n\n\n\n\nNatürlich können wir R auch die Rechenarbeit überlassen.\n\n🤖 Loving it!!\n\nSchauen Sie: Den Mittelwert (s. Abbildung 7.4) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? Schließlich erklären wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse ist).\nIn R gibt es einen Befehl für ein lineares Modell, er heißt lm.\nDie Syntax von lm() lautet:\nlm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur Erklärung von Y. Aber verwende keine andere Variable zur Erklärung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm1 &lt;- lm(y ~ 1, data = d)\n\nDen MAE können wir uns jetzt so ausgeben lassen:\n\nmae(lm1)\n## [1] 1.5\n\n\n7.4.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein Streuungsmaß, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.\n\nDefinition 7.3 (Interquartilsabstand) Der Interquartilsabstand ist definiert als der die (absolute) Differenz vom 3. Quartil und 1. Quartil.\\(\\square\\)\n\n\nBeispiel 7.3 (IQR im Hörsaal) In einem Statistikkurs betragen die Quartile der Körpergröße: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR beträgt dann: \\(IQR = Q3-Q1 = 1.75m - 1.65m = 0.10m\\), d.h. 10 cm.\\(\\square\\)\n\n\n7.4.3 Streuungsmaße für Normalverteilungen\nNormalverteilungen sind recht häufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu überlegen, wie man diese Verteilungen gut zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett über ihren Mittelwert sowie ihre Standardabweichung beschreiben lässt. Außerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), “verschiebt man den Berg” ja nur zur Seite, ohne seine Form zu verändern, s. Abbildung 7.9.\n\n\n\n\n\n\nHinweis\n\n\n\nHat man normalverteilte Variablen/Abweichungen/Residuen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma\\), \\(s\\)) eine komfortable Maßeinheit der Streuung, denn damit lässt sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\\(\\square\\)\n\n\n\n🧑‍🎓 Aber wie berechnet man jetzt diese Standardabweichung?\n\n\n👨‍🏫 Moment, noch ein kurzer Exkurs zur Varianz …\n\n\n🧑‍🎓 (seufzt)\n\n\n7.4.4 Varianz\n\n7.4.4.1 Intuition\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz einer Variable (z.B. Verkaufspreis von Mariokart) ist, grob gesagt, der typische Abstand eines Verkaufspreis vom mittleren Verkaufspreis.\\(\\square\\)\n\n\n\n\nAbbildung 7.7 illustriert die Varianz:\n\nMan gehe von der Häufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan bilde Quadrate für jeden Datenpunkt mit der Kantenlänge, die dem Abstand des Punktes zum Mittelwert entspricht.\nDie Quadrate quetscht man jetzt wo nötig in rechteckige Formen (ohne dass sich die Fläche ändern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit Seitenlänge \\(n\\) und \\(\\sigma^2\\) anordnen.\n\n\n\n\n\n\n\nAbbildung 7.5: Illustration zur Varianz als “mittlerer Quadratfehler”\n\n\nBy Cmglee - Own work, CC BY-SA 3.0\n\n\nAbbildung 7.6 visualisiert die Varianz für Beispiel 7.2.5\nLinks sind die Abweichungsquadrate dargestellt, rechts die Varianz als “typisches Abweichungsquadrat”.\n\n\n\n\n\n\nHinweis\n\n\n\nDie Varianz ist also ein Maß, das die typische Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als ‘typischer’ Fehlerbalken\n\n\n\n\n\n\nAbbildung 7.6: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\nBildquelle: FOM-ifes\n\nBeispiel 7.4 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. Natürlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.\nZunächst betrachten Sie die Streuung in den Verkaufspreisen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nm &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  m %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47.43\n12.99\n7.20\n83.06\n9.11\n\n\n\n\nStatistiken sind ja schön … aber Bilder sind auch gut, s. Abbildung 7.7. \\(\\square\\)\n\nmariokart %&gt;% \n  mariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_density()\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm mit MW±SD in roter Farbe\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm mit MW±SD in roter Farbe\n\n\n\n\n\n\nAbbildung 7.7: Die Verteilung des Verkaufspreises von Mariokart-Spielen\n\n\n\nWer sich die Berechnung von Hand für pr_maa sparen möchte, kann die Funktion MeanAD aus dem Paket DescTools nutzen.\n\n7.4.4.2 Kochrezept für die Varianz\nUm die Standardabweichung zu berechnen, berechnet man zunächst die Varianz, \\(s^2\\) abgekürzt. Hier ist ein “Kochrezept”6 zur Berechnung der Varianz:\n\nFür alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\)\n\nQuadriere diese Werte\nSummiere dann auf\nTeile durch die Anzahl \\(N\\) der Werte\n\nAls Formel ausgedrückt, lautet die Definition der Varianz7 einer Stichprobe wie folgt, s. Gleichung 7.2.\n\\[{\\displaystyle s^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{N}}\\sum _{i=1}^{n}dy_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.4 (Varianz) Die Varianz (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen, \\(dy_i^2\\), (vom Mittelwert).\\(\\square\\)\n\nDie Varianz steht im engen Verhältnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. Gleichung 7.3.\n\\[{\\displaystyle MSE={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(x_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.\n\n7.4.5 Die Standardabweichung\nKennt man die Varianz, so lässt sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.\n\nDefinition 7.5 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. Gleichung 7.4.\n\\[s := \\sqrt{s^2} \\tag{7.4}\\]\n\\(\\square\\)\n\nDurch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche Größenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groß werden kann).\nAus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(rmse := \\sqrt{mse}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE.\\(\\square\\)\n\n\n\nBeispiel 7.5 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n  \n\n\n\nAh! Das war einfach. Wird auch langsam Zeit für Feierabend.\\(\\square\\)\n\n\nBeispiel 7.6 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. Bevor Sie nach Hause gehen, möchten Sie noch eine Sache anschauen. In einer früheren Analyse (s. Abbildung 7.3) fanden Sie heraus, dass die Fehlerbalken kürzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natürlich prüfen. Sie überlegen: “Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.”\nDas spezifizieren Sie so:\n\nlm1 &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm1)\n## [1] 10.01811\n\nIm nächsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufpreis eine Funktion der Anzahl der Lenkräder ist (ähnlich wie in Abbildung 7.3):\n\nlm2 &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm2)\n## [1] 7.375873\n\nAh! Sehr schön, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach hause!\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.5 Streuung als Modellfehler",
    "text": "7.5 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellgüte auffassen.\nDefinieren wir zunächst als Punktmodell auf Errisch:\n\nlm_mario1 &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne Prädiktoren, sondern als Punktmodell, und zwar schätzen wir den Mittelwert mit den Daten mariokoart.\nDas (Meta-)Paket easystats bietet komfortable Befehle, um die Modellgüte zu berechnen:\n\nmae(lm_mario1)  # Mean absolute error\n## [1] 10.01811\nmse(lm_mario1)  # Mean squared error\n## [1] 655.2874\nrmse(lm_mario1)  # Root mean squared error\n## [1] 25.59858",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#z-transformation",
    "href": "060-modellguete.html#z-transformation",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.6 z-Transformation",
    "text": "7.6 z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie die Frage, wie gut sich die Verkaufspreise mit einer einzeigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. mariokart2.\n\nmariokart2 &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nMit dem R-Paket ggpubr (Funktion gghistogram) lässt sich die Verteilung leicht visualisieren, s. Abbildung 7.8, links.\n\n\n\n\n\n\n\n\n\n(a) Wie nah drängen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert\n\n\n\n\n\n\nAbbildung 7.8: Verteilung von mariokart2\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell für die Daten, bzw. desto höher die Modellgüte.\\(\\square\\)\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie überlegen … und überlegen. Da! Eine Idee!\nMan könnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je größer diese Abweichung, desto schlechter die Modellgüte! Also rechnen Sie diese Abweichung aus.\n\nmariokart2 &lt;-\n  mariokart2 %&gt;% \n  mutate(abw = 47.4 - total_pr)\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.6 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert abzuziehen. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 7.9: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt\n\n\n\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Überlegungen: Woher weiß man, ob 10 Euro oder 20 Euro “viel” Abweichung vom Verkaufspreis ist? Man müsste die Abweichung eines Verkaufpreis zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man könnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, ähnlicher Kennwert zur mittlerer absolute Abweichung ist die SD. Sie haben gehört, dass die SD gebräuchlicher ist als die MAA. Um sich als Checker zu präsentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja ähnlich.\nAlso: Wenn ein Spiel 10 Euro vom Mittelwert abweicht und die SD 10 Euro betragen sollte, dann hätten wir eine “standardisierte”8 Abweichung von 1, weil 10/10=1.\nBegeistert über Ihre Schlauheit machen Sie sich ans Werk.\n\nmariokart2 &lt;-\n  mariokart2 %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. Abbildung 7.10. In Abbildung 7.10 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als standardisiert bezeichnen, da wir sie in Bezug zur “typischen Abweichung”, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildung 7.10: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (“Transformation”) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.7 (z-Werte) z-Werte sind das Resultat der z-Transformation. Für die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i = \\frac{x_i - \\bar{x}}{sd_x}.\\square\\)\n\nz-Werte sind nützlich, weil sie die “relative” Abweichung einzelner Beobachtungen vom Mittelwert anzeigen.\nNach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, Ausreißern), wenn \\(z_i &gt; 2\\) oder \\(z_i &gt; 3\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#fazit",
    "href": "060-modellguete.html#fazit",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.7 Fazit",
    "text": "7.7 Fazit\nDer „gesunde Menschenverstand“ würde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Das ist vernünftig, denn die MAA ist anschaulicher und damit nützlicher als die Varianz und die SD.\nWarum sollte man überhaupt ein unanschauliches Maß wie die Varianz verwenden? Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. Gründe, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:9\n\nDie SD ist sehr nützlich zur Beschreibung der Normalverteilung\nDie Varianz wird häufig verwendet bzw. in Forschungsarbeiten berichtet, also müssen Sie die Varianz kennen.\n\nLiegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenüber Mittelwert basierten Streuungsmaßen (MAA, Varianz, SD).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.8 Aufgaben",
    "text": "7.8 Aufgaben\n\n\n\n\n\n\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag variability an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.9 Literaturhinweise",
    "text": "7.9 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnüglich zu lesenden Buch eine kurzweilige Einführung in die Statistik vor; auch Streuungsmaße haben dabei einen Auftritt. Wer mehr “Lehrbuch-Feeling” sucht, wird bei Çetinkaya-Rundel & Hardin (2021) fündig (das Buch ist online frei verfügbar). Es ist kein Geheimnis, dass Streuungsmaße keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne Streuungsmaße geht’s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonstwo) aus dem Regal ziehen, fündig werden zu diesem Thema. Die Bücher unterscheiden sich meist “nur” in ihrem Anspruch bzw. der didaktischen Aufmachung; für alle ist da was dabei.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literatur",
    "href": "060-modellguete.html#literatur",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.10 Literatur",
    "text": "7.10 Literatur\n\n\n\n\nÇetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. OpenIntro. OpenIntro. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "Ich auf keinen Fall.↩︎\nob es Fritz kann, ist nicht überliefert.↩︎\nAus Gründen der Übersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berücksichtigt und nur Spiele mit 0 oder mit 2 Lenkrädern.↩︎\nWenn man solche Sätze liest, fühlt sich die Formel fast einfacher an.↩︎\nDie Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine…↩︎\nAlgorithmus↩︎\nsog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehörigen Population zu schätzen, teilt man nicht durch \\(N\\), sondern durch \\(N-1\\)↩︎\nabgekürzt manchmal mit std↩︎\nIch wollte noch hinzufügen, dass die Varianz eng verknüpft mit der linearen Algebra, aber ich war nicht sicher, ob das Argument allgemein überzeugen würde.↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#lernsteuerung",
    "href": "070-zusammenhaenge.html#lernsteuerung",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n8.1.2 Lernziele\n\nSie können die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenhänge erläutern.\nSie können die Stärke einer Korrelation einschätzen.\n\n8.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n8.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl1, zu einem “Punkt” sozusagen, zusammengefasst werden kann.\nIn diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. Gleichung 8.1.\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{8.1}\\]\nWo wir in Kapitel 6 eine Variable mit Hilfe eines Lagemaßes beschrieben/dargestellt/zusammengefasst/modelliert haben, tun wir hier das Gleiche für zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen von einander abhängen bzw. miteinander (irgendwie) zusammenhängen. Wir begrenzen auf metrische Variablen.\nDie Verbildlichung2 zweier metrischer Variablen haben wir bereits in Kapitel 5.5.2 kennengelernt. Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal Abbildung 8.1.\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)\n\n\n\n\n\n\n\n\n\n(b) ‘Verwackeltes’ Streudiagramm, um die einzelnen Punkte besser zu erkennen\n\n\n\n\n\n\nAbbildung 8.1: Visualisierung des Zusammenhangs von wheels und total_pr",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.1 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurückbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhängen.3 Gar nicht so schlecht ausgefallen, s. Tabelle 8.1.\\(\\square\\)\n\n\n\n\nTabelle 8.1: Statistiknoten und Lernzeit\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. Abbildung 8.2. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso für \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\). Die Fläche des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\).\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 8.2: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus Abbildung 8.2. Nennen wir das resultierende Rechteck das “Summenrechteck”. Ja, ich weiß, ich strapaziere mal wieder Ihre Phantasie4. Jetzt kommt’s: Je größer die Fläche des Summenrechtecks, desto stärker der (lineare) Zusammenhang.\nBeachten Sie, dass die Flächen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die Füllfarben der Rechtecke verdeutlichen dies, s. Abbildung 8.2. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist. So zeigt Abbildung 8.3 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) überwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ überwiegt).\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten 1 und 3) überwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\n\n\n\n(b) Positive Vorzeichen (Quadranten 1 und 3) überwiegen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildung 8.3: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die Flächen der Abweichungsrechtecke addiert.\n\n\nWir können das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das ändert nichts an der Aussage, aber der Mittelwert hat gegenüber der Summe den Vorteil, dass er unabhängig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck.\nEin Maß für den Zusammenhang von Lernzeit und Klausurpunkte ist also die Fläche des mittleren Abweichungsrechtecks, s. Abbildung 8.4.\n\n\n\n\n\nAbbildung 8.4: Die Kovarianz als mittleres Abweichungsrechteck. Die Fläche der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die Fläche des mittleren Abweichungsrechtecks. Sie ist ein Maß für die Stärke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. Abbildung 8.4.\\(\\square\\)\n\n\n👩‍🎓 Zu viele Bilder! Ich brauch Zahlen.\n\n\n👩‍🏫 Kommen schon!\n\nTabelle 8.2 zeigt die Werte für die X- und Y-Abweichung und die resultierenden Flächen der Abweichungsrechtecke. Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv.\n\n\n\nTabelle 8.2: Werte der Abweichungsrechtecke\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\nx_pos\ny_pos\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51.25\n17\n20.75\nTRUE\nTRUE\n1\n352.75\n\n\n2\n44\n40\n53\n51.25\n-13\n-7.25\nFALSE\nFALSE\n1\n94.25\n\n\n3\n39\n35\n53\n51.25\n-18\n-12.25\nFALSE\nFALSE\n1\n220.50\n\n\n4\n50\n67\n53\n51.25\n14\n-1.25\nTRUE\nFALSE\n-1\n-17.50\n\n\n\n\n\n\n\n\nBerechnen wir als nächstes das mittlere Abweichungsrechteck, die Kovarianz:\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. Gleichung 8.2:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.2}\\]\nGleichung 8.2 in Worten ausgedrückt:\n\nRechne für jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne für jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere für alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die Flächen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.2 (Variablen mit positiver Kovarianz)  \n\nGröße und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf\\(\\square\\)\n\n\n\n\nBeispiel 8.3 (Variablen mit negativer Kovarianz)  \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und Depressivität\\(\\square\\)\n\n\n\nDrei Extrembeispiele für Kovarianz-Werte sind in Abbildung 8.5 dargestellt.\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\n\n\n\n(c) negativer Zusammenhang\n\n\n\n\n\n\nAbbildung 8.5: Verschiedene Werte der Kovarianz\n\n\nBei einer Kovarianz von (ungefähr) 0 ist die Gesamt-Fläche der Abweichungsrechtecke5, wenn man sie pro Quadrant aufsummiert, ungefähr gleich groß, s. Abbildung 8.6. Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so beträgt die Summe in etwa (oder genau) Null.\nDamit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null:\n\\[\\begin{align}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\varnothing \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov} &= 0\n\\end{align}\\]\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\n\n\n\nAbbildung 8.6: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhängig ist von der Skalierung. So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wünschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabhängig davon, ob man Einkommen in Euro, Cent oder Dollar misst. Außerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson löst das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nämlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so führt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) so definieren:\n\nDefinition 8.3 (Korrelationskoeffizient r) Der Korrelationskoeffizient \\(r\\) ist definiert als das mittlere Produkt der z-Wert-Paare: \\(r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i}\\), vgl Cohen et al. (2003). \\(\\square\\)\n\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur für metrische Variablen definiert ist.\n\n\n\n\n\n\nHinweis\n\n\n\nAus dem Korrelationskoeffizienten können Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert6 des Korrelationskoeffizienten gibt die Stärke des linearen Zusammenhangs an. Je näher der Wert bei 1 liegt desto stärker der Zusammenhang.\n\n\n\n\\(r = 0\\): kein linearer Zusammenhang\n\n\\(r = 1\\): perfekter linearer Zusammenhang\\(\\square\\)\n\n\n\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt Abbildung 8.7.\n\n\n\n\n\nAbbildung 8.7: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0\n\n\nDie untere Zeile von Abbildung 8.7 zeigt Beispiele für nicht-lineare Zusammenhänge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammhang besteht.\n\nÜbungsaufgabe 8.1 (Korrelationsspiel) Spielen Sie das Korrelationsspiel: Sie Sehen ein Streudiagramm und müssen den richtigen Korrelationskoeffizienten eingeben.\\(\\square\\)\n\n\nÜbungsaufgabe 8.2 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr Gefühl für die Stärke des Korrelationskoeffizienten zu entwickeln.\\(\\square\\)\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhängt? Schauen wir nach! Die Funktion correlation() (aus dem Paket easystats) erledigt das Rechnen für uns.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  # aus `easystats`\n\n\n  \n\n\n\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nCorrelation Matrix (pearson-method)\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\np-value adjustment method: Holm (1979)\n\n\nSie können auch auf die letzte Zeile, also dem Befehl summary() verzichten. Dann ist die Ausgabe ausführlicher.\n\n8.4.3 Korrelation ≠ Kausation\nEine Studie fand eine starke Korrelation, zwischen der (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. Abbildung 8.8.\n\n\n\n\n\nAbbildung 8.8: Schoki futtern macht schlau?\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nKorrelation (bzw. Zusammenhang) ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.4 (Scheinkorrelation) Störche und Babies: Eine Urban Myth besagt: Die Anzahl der Störche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis.\nEine Erklärung für dieses (nur scheinbare) Paradoxon ist, dass die “Naturbelassenheit” des Landkreises die gemeinsame Ursache für Störche ist (Störche lieben Natur) und für Babies ist (die dortige Kultur begünstigt, mehr Kinder pro Frau).\nCorona und Glatze:\nMacht die Glatze krank? Männer mit Glatze bekommen häufiger Corona (Goren et al., 2020).\n\nBald men at higher risk of severe case of Covid-19, research finds7\n\nEine Erklärung lautet, dass Alter einen Effekt hat auf Glatze (je älter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatz hat) und auf die Schwere des Corona-Verlaufs (ältere Menschen haben deutlich schwerere Corona-Verläufe). \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "title": "8  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lügt",
    "text": "8.5 Wie man mit Statistik lügt\n\n8.5.1 Range-Restriktion\nDurch (nicht-randomisierte) Einschränkung (Restriktion) des Ranges einer (oder beider) Variablen sinkt die Stärke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003) und Abbildung 8.9.\nErstellen wir uns dazu zwei Datensätze mit je zwei Variablen, \\(X\\) und \\(Y\\) der Größe \\(n=100\\). Ein Datensatz ist ohne Einschränkung des Ranges und einer mit. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in Listing 8.1. Wir schränken dann den Range von \\(X\\) ein auf, sagen wir, den Bereich von \\([-0.5, .5]\\) (Datensatz d_filtered).\n\n\nListing 8.1\n\n\nset.seed(42)\nn &lt;- 1e2\nd &lt;-\n  tibble(x = rnorm(n = n, mean = 0, sd = 1),\n         e = rnorm(n = n, mean = 0, sd = .5),\n         y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-\nd |&gt; \n  filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne Einschränkung des Range: Starke Korrelation\n\n\n\n\n\n\n\n\n\n(b) Mit Einschränkung des Range: Schwächere Korrelation\n\n\n\n\n\n\nAbbildung 8.9: Schränkt man den Range einer (oder beider) Variablen ein, so sinkt die Stärke der Korrelation\n\n\n\nÜbungsaufgabe 8.3 (Berechnen Sie die Korrelation) Glauben Sie nicht, prüfen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhängen.\nFalls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, können Sie die Daten so (in mittlerweile gewohnter Manier) importieren:\n\nmariokart &lt;- read.csv(\"mariokart.csv\")\n\nFalls der Datensatz im Unterordner mit Namen “Mein_Unterordner” liegt, so würden Sie folgenden Pfad eingeben:\n\nmariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\")\n\nMan beachte, dass solche sog. relativen Pfade (relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio) nicht mit einem Schrägstrich (Slash) beginnen.\nFalls Sie die Daten nicht auf Ihrem Computer haben, können Sie sie komfortable von z.B. der Webseite von Vincent Arel-Bundock herunterladen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wählen die Variablen von mariokart, die Sie in diesem Fall interessieren – natürlich nur die metrischen – und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\n\n\n\n\n\n\nNamensverwechslung (name clash)\n\n\n\nEs kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein, wie es mir oben in der Syntax passiert ist. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemäß sagt: “Hey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.” Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: “Hey R, nimm gefälligst select aus dem Paket dplyr, dort”wohnt” nämlich select. Auf Errisch spricht sich das so: dplyr::select(...).\\(\\square\\)\n\n\nEtwas schöner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. Tabelle 8.3.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  correlation() \n\n\nTabelle 8.3: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n  \n\n\n\n\n\n\nNeben einigen Statistiken, die wir einfach geflissentlich ausblenden (t und p) beinhaltet die Tabelle eine interessante Information: den Schätzbereich für die Korrelation, gekennzeichnet als 95% CI. Grob gesagt können wir diese Information so interpretieren: “Mit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich.”8\nMöchte man nur einzelne Korrelationskoeffizienten ausrechnen, können wir die Idee des Zusammenfassens, s. Gleichung 8.1, nutzen:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels))\n\n\n  \n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nIm Falle von fehlenden Werte müssen Sie R aus seiner schüchternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n  \n\n\n\n\n\n\n🧑‍🎓 Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket {dataExplorer} bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. Abbildung 8.10.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildung 8.10: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#vertiefung",
    "href": "070-zusammenhaenge.html#vertiefung",
    "title": "8  Punktmodelle 2",
    "section": "\n8.7 Vertiefung",
    "text": "8.7 Vertiefung\nDieser TED-Vortrag informiert zum Thema Scheinkorrelation. Hier finden Sie weitere Beispiele für Scheinkorrelationen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8  Punktmodelle 2",
    "section": "\n8.8 Aufgaben",
    "text": "8.8 Aufgaben\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag association an.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#halbzeitquiz",
    "href": "070-zusammenhaenge.html#halbzeitquiz",
    "title": "8  Punktmodelle 2",
    "section": "\n8.9 Halbzeitquiz",
    "text": "8.9 Halbzeitquiz\nHier geht’s zu einem Quiz zur deskriptiven Statistik (Maße der zentralen Tendenz, Variabilität, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8  Punktmodelle 2",
    "section": "\n8.10 Fallstudien",
    "text": "8.10 Fallstudien\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Übungsaufgaben können theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer Lösung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.\\(\\square\\)\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl. Es ist nicht nötig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Übung, dort, wo Sie es nötig haben.\\(\\square\\)\n\n\n\nEDA zu Flugverspätungen\nYACSDA: Topgear\nExplorative Datenanalyse zum Datensatz “OECD Wellbeing”\nDatensatz flights: Finde den Tag mit den meisten Abflügen\nTidyverse Case Study: Exploring the Billboard Charts",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8  Punktmodelle 2",
    "section": "\n8.11 Literaturhinweise",
    "text": "8.11 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erläutern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schönes, modernes Statistikbuch bietet der Psychologie-Prof Russel Poldrack von der Princeton University (2023); auch dieses Buch ist frei online verfügbar. Tipp: Nutzen Sie die Übersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas höheren Anspruchs.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literatur",
    "href": "070-zusammenhaenge.html#literatur",
    "title": "8  Punktmodelle 2",
    "section": "\n8.12 Literatur",
    "text": "8.12 Literatur\n\n\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGoren, A., Vaño-Galván, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain – A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545–1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "auch Skalar genannt↩︎\nVisualisierung↩︎\n&gt; 🧑‍🎓 Typisches Lehrerbeispiel!!↩︎\nhoffentlich nicht Ihre Geduld↩︎\nBei der Varianz waren es Quadrate, bei der Kovarianz sind es Rechtecke.↩︎\nBetrag↩︎\nhttps://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/, Abruf 2023-03-24↩︎\nBayesianische Interpretation↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#lernsteuerung",
    "href": "080-regression1.html#lernsteuerung",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n9.1.2 Lernziele\n\nSie können ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie können die Bestandteile eines Geradenmodells aufzählen und erläutern.\nSie können die Güte eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie können Geradenmodelle sowie ihre Modellgüte in R berechnen.\n\n9.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.1.4 Benötigte Daten\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nützlich Sache, unter (mindestens) folgenden Voraussetzungen:\n\nSie sind präzise\nWir kennen die Präzision\nJemand interessiert sich für die Vorhersage\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne Prädiktor\n\nBeispiel 9.1 Nach intensiver Beschäftigung mit Statistik sind Sie allgemein als Checker bekannt. Viele jüngere Studentis fragen Sie um Rat. eines Tages kommt ei Studenti, Toni, und fragt: “Welche Statistiknote kann ich in der Klausur erwarten?” Sie entgegnen: “Wie viel hast du denn gelernt?”. Die Antwort: “Sag ich nicht.”\nNach kurzem Überlegen geben sie den Notenschnitt der letzten Klausur als Prognose für dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).\nZuerst importieren Sie die Daten der letzten Klausur1:\n\nnoten2 &lt;- read.csv(\"daten/noten2.csv\")\n\n Download \nDann rechnen Sie den Mittelwert aus:\n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n  \n\n\n\nIhre Antwort lautet also: “Im Schnitt haben die Studis bei der letzten Klausur gut 70% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorhersage machen, sorry!”\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Kenntnis eines Prädiktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert für jede Beobachtung, s. Abbildung 9.1. Wir nutzen den Mittelwert als Punktmodell für den Klausurerfolg.\\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\n9.2.2 Nullmodell (Punktmodell)\nModelle ohne Prädiktor, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null Prädiktoren hat, nennt man es auch manchmal “Nullmodell”.\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##       71.08\n\nlm steht für “lineares Modell”, die 1 sagt, dass es keine Prädiktoren gibt. In dem Fall wird der Mittelwert als Gerade verwendet. Der zurückgemeldete Koeffizient (Intercept) ist hier der Modell des Punktmodells. Da es ein Punktmodell ist, sagt es für alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nDie Regressionsgleichung lautet demnach: y_pred = 71.08. In Worten: “Wir sagen für jede Beobachtung einen Wert von ca. 71 vorher”.\n\n9.2.3 Vorhersagen mit Prädiktor\n\nBeispiel 9.2 (Toni verrät die Lernzeit) Dis Studenti, Toni, entschließt sich dann doch noch, die Lernzeit zu verraten: “Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.” Jetzt müssen Sie erstmal nachdenken: “Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 Stunden gelernt hat?”\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. Abbildung 9.2, a).2\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: “Bei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. Könnte mit dem Bestehen eng werden.” Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.\\(\\square\\)\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen. Mit einem Lineal könnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. Abbildung 9.2, b).\n\n\n\n\n\n\n\n\n\n(a) Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)\n\n\n\n\n\n\n\n\n\n(b) Eine ‘Trendgerade’ (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet.\n\n\n\n\n\n\nAbbildung 9.2: Noten und Lernzeit: Rohdaten und Modell\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell für die Daten, s. Abbildung 9.2, rechts. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden.\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt für alle Beobachtungen den gleichen Wert vorher. Abbildung 9.1 und Abbildung 9.2 stellen ein Punktmodell einem Geradenmodell gegenüber.\nIn einem Geradenmodell wird nicht mehr (notwendig) für jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.1 Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). Häufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet: \\(f(\\color{xcol}{x})=\\color{ycol}{y}=\\color{beta1col}{m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + \\color{beta1col}{b_1} \\color{xcol}{x}\\) .3\nDas “Dach” über y, \\(\\color{modelcol}{\\hat{y}}\\), drückt aus, dass es sich den den geschätzten, bzw. vom Modell vorhergesagten (“modellierten”) Wert für \\(\\color{ycol}{y}\\) handelt, nicht das tatsächliche (empirische, beobachtete) \\(\\color{ycol}{y}\\). \\(\\square\\)\n\nAbbildung 9.3 skizziert die Elemente einer Regression.\n\n\n\n\n\nAbbildung 9.3: Achsenabschnitt und Steigung einer Regressionsgeraden\n\n\nBildquelle: Basierend auf diesem Diagramm von Henri Menke\n\n\n\n\n\n\nDas einfache lineare Modell\n\n\n\nDas einfache lineare Modell nimmt den Wert einer abhängigen metrischen Variablen, y als lineare Funktion von unabhängigen Variablen, x an, plus einem Fehlerterm, e. \\(\\square\\)\n\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned}\\]\nMit:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschätzter y-Achsenabschnitt laut Modell\n\n\\(\\color{beta1col}{\\beta_1}\\): geschätzte Steigung laut Modell\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nJe nach Datenlage können sich Regressionsgerade in Steigung oder Achsenabschnitt unterscheiden, s. Abbildung 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildung 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher Modellgüte\n\n\nAbbildung 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie können Punkte per Klick/Touch hinzufügen.\n\n\n\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\nQuelle\n\n\n\nAbbildung 9.5: Interaktives Beispiel für eines lineares Modell. Fügen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert. “Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurück!”\nDas sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{X}=0\\) gibt der Achsenabschnitt zurück. Schnell skizzieren Sie dazu ein Diagramm, s. Abbildung 9.6. Puh, die Antwort wird Toni nicht gefallen …\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 9.6: Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf Abbildung 9.6 zu schauen, können Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n🧑‍🎓 Hey R, predicte mir mal auf Basis vom Modell “lm1” den Lernerfolg für Toni, wenn der x=0 Stunden lernt.\n\n\n🤖 Okay, ich predicte mit Modell “lm1” und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)\ntonis_lernzeit\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit)\n##        1 \n## 8.603032\n\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. Gleichung 9.2 :\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.1}\\]\nLies: “Laut meinem Modell ist mein (geschätztes) \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)”.\nWir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist:\n\\[\\color{ycol}{AV} \\sim \\color{xcol}{UV} \\tag{9.2}\\]\nWir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\nGleichung 9.2 können Sie so ins Errische übersetzen:\n\nlm(y ~ x, data = meine_daten)\n\nlm steht für “lineares Modell”, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade4.\n\nBeispiel 9.4 (Zahlen für Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: “Jetzt hör mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir präzise Zahlen!”.\n\n\nlm1 &lt;- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      8.6030       0.8794\n\nR gibt Ihnen die beiden Koeffizienten für die Gerade aus. Den Namen des Objekts können Sie frei aussuchen, z.B. mein_erstes_lm.\nDie Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x\n8.6 ist der Achsenabschnitt, d.h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.h. die Steigung der Regressionsgeraden: Für jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 10 Stunden gelernt, würden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 10\ny_pred &lt;- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17.4\n\n\nBeispiel 9.5 (Vorhersage für Klausurerfolg, nächster Versuch) Sie versuchen, noch etwas Gutes für Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dürfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  # Der Befehl `tibble` erstellt eine Tabelle in R.\n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit2)\n##       1 \n## 72.7999\n\nDie Syntax von predict lautet:\npredict(name_des_objekts, newdata = tabelle_mit_prädiktorwerten)\n\n\n\n\n\n\nHinweis\n\n\n\nMit predict bekommt man eine Vorhersage; im Standard eine “Punkt-Vorhersage”, eine einzelne Zahl.\\(\\square\\)\n\n\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagten Wert für eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, \\(e_i\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Residuen beim Geradenmodell (lm1)\n\n\n\n\n\n\n\n\n\n(b) Residuen beim Punktmodell (lm0)\n\n\n\n\n\n\nAbbildung 9.7: Vorhersagefehler als Abweichungsbalken\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben5:\n\nmae(lm0)\n## [1] 11.18385\nmae(lm1)\n## [1] 7.954085\n\nVergleichen wir MAE im Nullmodell mit MAE in lm1:\n\nverhaeltnis_fehler_mae &lt;- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.7112118\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm1 haben die mittlere (Absolut-)Länge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.2 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)).\\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngrößen wie MAE oder MSE.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist.\\(\\square\\)\n\n\nNatürlich können wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen6.\n\nmse(lm0)\n## [1] 192.7863\nmse(lm1)\n## [1] 106.4519\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.5521755\n\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\nDie Regressionskoeffizienten7 b0 und b1 wählt man so, dass die Residuen minimal sind, s. Abbildung 9.8.\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildung 9.8: Bildquelle: Karsten Lübke, FOM Hochschule\n\n\nGenauer gesagt wird die Summe der quadrierten Residuen minimiert, s. Gleichung 9.3.\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene Möglichkeiten, um die Koeffizienten zu berechnen8. Eine schöne Darstellung dazu findet sich bei Kaplan (2009).\n“Von Hand” können Sie die Optimierung von b0 und b1 in dieser App der FOM-Hochschule ausprobieren.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r-quadrat-als-maß-der-modellgüte",
    "href": "080-regression1.html#r-quadrat-als-maß-der-modellgüte",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.4 R-Quadrat als Maß der Modellgüte",
    "text": "9.4 R-Quadrat als Maß der Modellgüte\nAnders gesagt, wir haben uns um \\(1 - 0.55\\) verbessert:\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.4478245\n\n\nDefinition 9.3 (R-Quadrat) Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen von lm0 zum gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). R-Quadrat (\\(R^2\\)) eines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein Maß der Modellgüte: Je größer \\(R^2\\), desto besser die Vorhersage. Da es ein Anteilsmaß9 ist, liegt der Wertebereich zwischen 0 uns 1. Im Nullmodell liegt R-Quadrat per Definition bei 0. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable erklärt.\nWir können R-Quadrat (\\(R^2\\)) uns von R z.B. so ausgeben lassen:\n\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\)10, s. Abbildung 9.9.\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation, r ≅ 0 und R2 ≅ 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefähr) parallel zur X-Achse\n\n\n\n\n\n\n\n\n\n(b) Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert\n\n\n\n\n\n\nAbbildung 9.9: Extremfälle von R-Quadrat: 0 und 1\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man für jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\), vorhersagen würde.\n\n\n\n\n\n\nHinweis\n\n\n\nJe größer R-Quadrat, desto besser erklärt das Modell die Daten (desto besser der “Fit”, sagt man).\n\n\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der Größe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 Modellgüte\nDie Residuen (Vorhersagefehler) bestimmen die Modellgüte: Sind die Residuen im Schnitt groß, so ist die Modellgüte gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur Verfügung: R-Quadrat, r11, MSE, RMSE, MAE, …\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\)12) und Steigung (\\(beta_1\\)) sind nur eingeschränkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abhängigkeiten nicht kennt. Nur aufgrund eines statistischen Zusammenhangs darf man keine kausalen Abhängigkeiten annehmen. Ohne eine guten Grund für eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der Modellgüte und den Vorhersagen begnügen. Was auch was wert ist.\n\n9.5.2.1 Achsenabschnitt (b0)\n“Im Modell lm1 liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=8.6\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) können also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten.” Leider ist es häufig so, dass Prädiktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nützt.\n\nBeispiel 9.6 (Regression Größe und Gewicht) Nutzt man Körpergröße und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von Körpergröße wenig nützlich, da es keine Menschen gibt der Größe 0.\\(\\square\\)\n\n\n9.5.2.2 Geradensteigung (b1)\n“Im Modell lm1 beträgt der Regressionskoeffizient b1 \\(0.88\\). Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von b1.”\n\n\n\n\n\n\nVorsicht\n\n\n\nHäufig liest man, der “Effekt des Prädiktors” auf die AV betrage z.B. \\(0.88\\). “Effekt” ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort “Effekt” mit Vorsicht genießen. Manche sprechen daher auch von einem “statistischen Effekt”.\\(\\square\\).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lügt",
    "href": "080-regression1.html#wie-man-mit-statistik-lügt",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lügt",
    "text": "9.6 Wie man mit Statistik lügt\nDer Unterschied in Modellgüte zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) Maß der Modellgüte und da \\(r = \\sqrt{R^2}\\), darf \\(r\\) nicht wie \\(R^2\\) als Maß der Modellgüte interpretiert werden. Abbildung 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildung 9.10: Zusammenhang von r und R-Quadrat\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dürfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie möchten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs. Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz. Auf geht’s!\nDaten laden:13\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloßem Rumprobieren überlegen Sie und schauen dann in Abbildung 8.10 nach, welche Variable am stärksten korreliert mit total_pr; es resultiert lm3:\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n\n\n\n\nTabelle 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in Tabelle 9.1 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut lm3 etwa 36 Euro finaler Verkaufspreis erwarten. Pro Euro an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.14.\nDie Regressionsgleichung von lm3 lautet demnach:\ntotal_pr_pred = 36.25 + 4.34*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36.25€ “Sockelbetrag” plus 4.34 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (“expectations”) des Verkaufspreises in Abhängigkeit vom Wert der UV (ship_pr) auch schätzen (“to estimate”) lassen, und zwar so15:\n\nestimate_expectation(lm3) %&gt;% head()  # nur die ersten paar vorhergesagten Werte\n\n\n  \n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\n🤖 Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert für total_pr für einen bestimmten Wert von ship_pr.\n\n\n🧑‍🎓 Kann ich auch predict benutzen? Ich würde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n\n🤖 Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen\n)\n\n\npredict(lm3, newdata = neue_daten)\n##        1        2 \n## 40.58276 53.59442\n\nAber nützlich wäre noch, das Modell (bzw. die Schätzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.B. so, s. Abbildung 10.10.\n\nestimate_expectation(lm3) %&gt;% plot()\n\n\n\n\n\n\nAbbildung 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heißt sinngemäß “schätze den zu erwartenden Wert”. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie “gut” das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13.0632\n\nDas Modell erklärt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nmae(lm3)\n## [1] 13.0632\n\nIm nächsten Meeting erzählen Sie Ihrem Chef “Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!”. Hört sich gut an. Allerdings hätte ihr Chef es gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie stellt die Prüfungsleistung “Prognosewettbewerb” einführend dar. Es empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten.\\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei Kaggle ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet.\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition Ames House Prices.\n\nBeschreibung\nZiel/Aufgabe\nSpielregeln\n\n9.8.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n9.8.3 Daten\nWenn Sie sich nicht bei Kaggle einloggen möchten, können Sie die Daten von Kaggle herunterladen und zwar hier.\nIm Einzelnen müssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Code book, d.h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\nSie können auch so auf die Daten zugreifen:\n\nd_train_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\nDas Code Book können Sie hier einsehen und herunterladen.\n\n9.8.4 Prognosedatei\nDie Prognosedatei soll prinzipiell so aussehen:\n\n\n\n  \n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - für welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice ist Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar?\nLos geht’s!\n\n9.8.5 Daten importieren\nWir starten die üblichen R-Pakete und importieren die Daten (d):\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\nd_train_path &lt;- \"daten/ames-kaggle/train.csv\"\nd_test_path &lt;- \"daten/ames-kaggle/test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Beispiel gehen wir davon aus, dass die Dateien train.csv und test.csv in einem Unterordner namens daten/ames-kaggle liegen. Sie müssen sie dort abspeichern. Dieser Ornder muss ein Unterordner Ihres aktuellen R-Projekts sein.\\(\\square\\)\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn das Importieren von der Festplatte nicht klappt … Es ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.\\(\\square\\)\n\n\n\nd_train &lt;- read_csv(d_train_path_online)\nd_test &lt;- read_csv(d_test_path_online)\n\n\n9.8.6 Ein erster Blick in die Daten\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, Tabelle 9.2.\n\ndescribe_distribution(d_train)\n\n\nTabelle 9.2: Verteilung der metrischen Variablen im ames-Datensatz\n\n\n\n  \n\n\n\n\n\n\n\n9.8.7 Ein erstes Vorhersagemodell\n\n9.8.7.1 Welche Variablen eignen sich zur Vorhersage?\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller Prädiktoren mit der abhängigen Variablen16 zu berechnen, s. Tabelle 9.3.\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\nTabelle 9.3: Korrelation der Prädiktoren (UV) mit der AV\n\n\n\nCorrelation Matrix (pearson-method)\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt\ndf\np\n\n\n\nOverallQual\nSalePrice\n0.79\n(0.77, 0.81)\n49.36\n1458\n&lt; .001***\n\n\nGrLivArea\nSalePrice\n0.71\n(0.68, 0.73)\n38.35\n1458\n&lt; .001***\n\n\nGarageCars\nSalePrice\n0.64\n(0.61, 0.67)\n31.84\n1458\n&lt; .001***\n\n\nGarageArea\nSalePrice\n0.62\n(0.59, 0.65)\n30.45\n1458\n&lt; .001***\n\n\nTotalBsmtSF\nSalePrice\n0.61\n(0.58, 0.64)\n29.67\n1458\n&lt; .001***\n\n\n1stFlrSF\nSalePrice\n0.61\n(0.57, 0.64)\n29.08\n1458\n&lt; .001***\n\n\nFullBath\nSalePrice\n0.56\n(0.52, 0.59)\n25.85\n1458\n&lt; .001***\n\n\nTotRmsAbvGrd\nSalePrice\n0.53\n(0.50, 0.57)\n24.10\n1458\n&lt; .001***\n\n\nYearBuilt\nSalePrice\n0.52\n(0.48, 0.56)\n23.42\n1458\n&lt; .001***\n\n\nYearRemodAdd\nSalePrice\n0.51\n(0.47, 0.54)\n22.47\n1458\n&lt; .001***\n\n\nGarageYrBlt\nSalePrice\n0.49\n(0.44, 0.53)\n20.66\n1377\n&lt; .001***\n\n\nMasVnrArea\nSalePrice\n0.48\n(0.44, 0.52)\n20.69\n1450\n&lt; .001***\n\n\nFireplaces\nSalePrice\n0.47\n(0.43, 0.51)\n20.16\n1458\n&lt; .001***\n\n\nBsmtFinSF1\nSalePrice\n0.39\n(0.34, 0.43)\n16.00\n1458\n&lt; .001***\n\n\nLotFrontage\nSalePrice\n0.35\n(0.30, 0.40)\n13.01\n1199\n&lt; .001***\n\n\nWoodDeckSF\nSalePrice\n0.32\n(0.28, 0.37)\n13.10\n1458\n&lt; .001***\n\n\n2ndFlrSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.87\n1458\n&lt; .001***\n\n\nOpenPorchSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.71\n1458\n&lt; .001***\n\n\n\np-value adjustment method: Holm (1979) Observations: 1201-1460\n\n\n\n\n\nAha! Ein Menge Information.17\nDiese Variablen sind einigermaßen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n9.8.7.2 Modell 1\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im Großen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stärksten mit der Zielvariable korreliert und ist daher ein guter Kandidat für die Vorhersage.\n\nm1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(m1)  # aus easystats\n\n\n  \n\n\n\nWie gut ist das Modell?\n\nrmse(m1)  # aus easystats\n## [1] 48589.45\n\nIm Schnitt liegen wir ca. 56 Tausend Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die Modellgüte:\n\nr2(m1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\n\n9.8.7.3 Model 2\nBerechnen wir als nächstes ein Modell mit mehreren UV, m2.\n\n\n\n\n\n\nHinweis\n\n\n\nMann kann mehrere UV (Prädiktorvariablen) in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur “als UV nimm UV1 und UV2 und …”. \\(\\square\\)\n\n\n\nm2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m2)\n\nTabelle 9.4 zeigt die Koeffizienten von m2.\n\n\n\nTabelle 9.4: Modellparameter von m1\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1456)\np\n\n\n\n(Intercept)\n-98832.49\n4842.90\n(-1.08e+05, -89332.69)\n-20.41\n&lt; .001\n\n\nOverallQual\n27104.83\n1072.18\n(25001.64, 29208.01)\n25.28\n&lt; .001\n\n\nGrLivArea\n50.67\n2.55\n(45.67, 55.68)\n19.86\n&lt; .001\n\n\nGarageCars\n21298.96\n1807.06\n(17754.23, 24843.69)\n11.79\n&lt; .001\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells m2 für die Daten von d_train?\n\nrmse(m2)\n## [1] 40566.42\n\nIm Schnitt liegen unsere Vorhersagen ca. 40 Tausend Dollar daneben. Ist das gut?\n\nr2(m1)\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\nOb die Modellgüte (R-Quadrat, RMSE, etc.) “gut” oder “hoch” ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen.\n\n9.8.7.4 Nullmodell\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Prädiktoren. Man nennt es das “Nullmodell”. In diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnomdells?\n\nrmse(m0)\n## [1] 79415.29\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben.\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.8 Vorhersagen im Test-Datensatz\nWir haben jetzt unseren Champion, m1. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample präzise sein werden? Oder himmelweit daneben? Enttäusche uns nicht!\nHier sind die Vorhersagen:\n\nm1_pred &lt;- predict(m1, newdata = d_test)\nhead(m1_pred)\n##        1        2        3        4        5        6 \n## 130972.9 176408.7 130972.9 176408.7 267280.3 176408.7\n\n\n1\n\npredicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus d_test\n\n2\n\nzeige den “Kopf” der Vorhersagen (m1_pred), d.h. die ersten paar Vorhersagen\n\n\n\n\nDie Vohersagen fügen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = m1_pred)\n\n\n9.8.9 Einreichen!\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhesagen ein.\nFür die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten id und SalePrice:\n\nm1_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\nKaggle möchte keine fehlenden Werten in den Vorhersagen, also prüfen wir das mal:\n\nm1_subm %&gt;% \n  drop_na() %&gt;%\n  nrow()\n## [1] 1459\n\n\n1\n\nLass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2\n\nzähle die Anzahl der Zeilen\n\n\n\n\nOh, das ist eine Zeile weniger! Wir haben also einen fehlenden Wert!\nFiltern wir die Spalte SalePrice mal nach “ist NA”:\n\nm1_subm %&gt;% # &lt;1)\n  filter(is.na(SalePrice))\n\n\n  \n\n\n\nÜbersetzen wir die Syntax auf Deutsch:\n\nNimm zuerst die Tabelle m1_smb\nFilter dann so, dass du nur Zeilen hast, für die gilt, “hier ist ein NA in der Spalte SalePrice\n\nAh, da ist er, der fehlende Wert, in Zeile 2577! Hinfort!\nWir ersetzen die fehlenden Werte in SalePrice mit dem Mittelwert von SalePrice:\n\nm1_subm_nona &lt;-\n  m1_subm %&gt;%\n  mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE)))\n\nDie Syntax wieder auf Deutsch:\n\nDefiniere m1_subm_nona wie folgt\nNimm m1_subm und dann\nVerändere die Spalte SalePrice und zwar so, dass NAs ersetzt werden durch den Mittelwert von SalePrice\n\n\nUnd? Gib es jetzt noch fehlende Werte?\n\nm1_subm_nona %&gt;% \n  filter(is.na(SalePrice))\n\n\n  \n\n\n\nNein! Die Ergebnistabelle hat null Zeilen. “No NA” - Keine NAs, keine fehlenden Werte mehr.\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.18\n\nwrite_csv(m1_subm_nona, \"daten/ames-kaggle/m1-subm.csv\")\n\nUnd dann laden Sie diese Datei, m1_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn.\nDas Modell erzielte einen Score von 0.55521.\n\n9.8.10 Debrief\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele Ansätze, dieses Modell zu verbessern.\nHier sind einige Fragen, die Sie sich dazu stellen können:\n\nWelche Prädiktoren sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn ein Prädiktor schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche Prädiktoren quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n…\n\nViel Spielraum für Ihre Kreativität!",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nEine Aufgabe, die eine Einführung zum Kaggle-Wettbewerb Ames House Prices bietet, finden Sie hier im Datenwerk.\nSuchen Sie beim Datenwerk auch nach diesen Aufgaben:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\n\nSchauen Sie sich die Aufgaben beim Datenwerk an, vor allem die Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff; vielleicht können Sie einige Aufgaben nicht lösen. Ignorieren Sie einfach diese Aufgaben.\nBeachten Sie die Hinweise zu den Aufgaben.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere Einführung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte Einführung in Statistik inklusive der Regressionsanalyse findet sich bei Cetinkaya-Rundel & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literatur",
    "href": "080-regression1.html#literatur",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.11 Literatur",
    "text": "9.11 Literatur\n\n\n\n\nCetinkaya-Rundel, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed (S. xxviii, 703). Lawrence Erlbaum Associates Publishers.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "Diese Syntax wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls müssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.↩︎\nDie Daten stehen hier zum Download bereit.↩︎\nDie Nomenklatur mit \\(b_0, b_1\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, ...\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage über eine Population, nicht nur über eine Stichprobe, machen möchte.↩︎\nan anderer Stelle in diesem Buch unscharf als “Trendgerade” bezeichnet.↩︎\naus dem Paket easystats↩︎\nWer mag, kann den MSE auch von Hand berechnen: mean((noten2$y-mean(noten2$y))^2)↩︎\nhier synonym: Modellparameter↩︎\ndie sind aber nicht in diesem Buch zu finden↩︎\nProzentzahl↩︎\nBei Modellen mit einem Prädiktor; gibt es mehrere Prädiktoren gilt die Beziehung nur wenn die Prädiktoren alle paarweise unabhängig sind.↩︎\nals Korrelation von tatsächlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)↩︎\nlies: “beta Null”↩︎\nUnd die üblichen Pakete starten, nicht vergessen.↩︎\nDie Spalte 95 CI gibt einen Schätzbereich für den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um Schätzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schließlich nur eine Stichprobe der Größe \\(n=143\\).↩︎\nDie Funktion stammt aus easystats↩︎\ndie vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt↩︎\nWenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: Führen Sie die Syntax schrittweise aus. Zuerst d_train ausführen und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausführen, wieder die Ausgabe betrachten, usw.↩︎\nEs bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#lernsteuerung",
    "href": "090-regression2.html#lernsteuerung",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n10.1.2 Lernziele\n\nSie können Regressionsmodelle für Forschungsfragen mit binärer, nominaler und metrischer UV erläutern und in R anwenden.\nSie können Interaktionseffekte in Regressionsmodellen erläutern und in R anwenden.\nSie können den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erläutern und in R anwenden.\nSie können Modelle nutzen, um Vorhersagen anhand neuer Daten zu erstellen.\n\n10.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(yardstick)  # für Modellgüte im Test-Sample\nlibrary(easystats)\n\n\n10.1.4 Benötigte Daten\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD.1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "href": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: Gläserne Kunden",
    "text": "10.2 Forschungsbezug: Gläserne Kunden\nLineare Modelle2 sind ein altes, aber mächtiges Werkzeug. Sie gehören immernoch zum Standard-Repertoire moderner Analystis.\n\nBeispiel 10.1 (Wie gut kann man Ihre Persönlchkeit auf Basis des Facebook-Profils vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Kosinski et al. (2013), wie gut Persönlichkeitszüge durch Facebook-Daten (Likes etc.) vorhergesagt werden können. Die Autoren resümieren:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten über hohe Modellgüte (\\(r\\)) zwischen den tatsächlichen persönlichen Attributen und den vorhergesagten Werten Ihres Modells, s. Abbildung 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also ähnlich zu dem in diesem Kapitel vorgestellten Methoden.\nNeben der analytischen Stärke der Regressionsanalyse zeigt das Beispiel auch, wie gläsern Konsument:innen im Internet sind.\\(\\square\\)\n\n\n\n\n\n\nAbbildung 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach ewtas Abwechslung. Viel Geld verdienen und Ruhm und Anerkennung sind ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehören, und daher den schnöden Mammon nicht so hoch schätzen sollten. Sie entschließen sich, Ihre hochgeschätzten Analyse-Skills für etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels.\nBeim Deutschen Wetterdienst, DWD haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen resultiert ein schöner Datensatz, den Sie jetzt analysieren wollen3:\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\nEin Data-Dictionary für den Datensatz können Sie hier herunterladen.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Data-Dictionary (Codebook) erklärt einen Datensatz. Oft bedeutet das, das für jede Spalte der Datentabelle erklärt wird, was die Spalte bedeutet.\\(\\square\\)\n\n\nIn Tabelle 10.1 und Abbildung 10.2 kann man sich die Daten en Detail anschauen (Temperatur und Niederschlag im Zeitverlauf).\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celcius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlage (mm) im Verlauf der Jahre\n\n\n\n\n\nVeränderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildung 10.2: Veränderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\n\n\n\nTabelle 10.1: Wetterdaten für Deutschland\n\n\n\n  \n\n\n\n\n\n\nHervorragend!\nAn die Arbeit! 💪\n\n\n10.3.1 metrische UV\n\n10.3.1.1 Modell Wetter1\nSie stellen sich nun folgende Forschungsfrage:\n\n🧑‍🎓 Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in Tabelle 10.2 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelle 10.2: Modellparameter von lm_wetter1\n\n\n\n  \n\n\n\n\n\n\nLaut Ihrem Modell wurde es pro Jahr um 0.01 Grad wärmer, pro Jahrzehnt also 0.1 und pro Jahrhundert 1 Grad.\n\n🧑‍🎓 Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\n👨‍🏫 Mit der Ruhe, das schauen Sie sich später an.\n\n\n10.3.1.2 Punkt- vs. Bereichsschätzung\nIn tbl-lm-wetter1 finden sich zwei Arten von Information für den Wert des Achsenabschnitts (b0) und des Regressionsgewichts von year(b1):\n\nPunktschätzungen In der Spalte Coefficient sehen Sie den “Best-Guess” für den entsprechenden Koeffizienten in der Population. Das is sozusagen der Wert für den sich das Modell festlegen würde, wenn es sonst nichts sagen dürfte.\nBereichschätzungen Cleverer als Punktschätzungen sind Bereichsschätzungen (Intervallschätzungen): Hier wird ein Bereich plausibler Werte für den entsprechenden Wert angegeben. Der “Bereich plausibler Werte” wird auch als Konfidenzintervall (engl. confidence intervall, CI) bezeichnet. Entsprechend gibt CI_low die Untergrenze des Bereichs plausibler Werte und CI_high die Obergrenze aus. So können wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschätzt wird.\n\n💡 Merke: Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschätzt.\n\n10.3.1.3 Modell Wetter1a\nDas Modell lm_wetter1, bzw. die Schätzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. Abbildung 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. Abbildung 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. für Niederschlag\n\nAuf dieser Basis erstellen wir ein neues lineares Modell, s. Tabelle 10.3.\n\nlm_wetter1a &lt;- lm(temp ~ year, data = wetter_summ)\nparameters(lm_wetter1a)\n\n\n\n\nTabelle 10.3: Modellparameter von lm_wetter1a\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(140)\np\n\n\n\n(Intercept)\n-14.14\n2.70\n(-19.48, -8.79)\n-5.23\n&lt; .001\n\n\nyear\n0.01\n1.38e-03\n(8.86e-03, 0.01)\n8.38\n&lt; .001\n\n\n\n\n\n\n\n\nplot(estimate_relation(lm_wetter1)) \nplot(estimate_relation(lm_wetter1a))\n\n\n\n\n\n\n\n\n\n(a) Jeder Punkt ist ein Tag (viel Overplotting, wenig nützlich)\n\n\n\n\n\n\n\n\n\n(b) Jeder Punkt ist ein Jahr (wetter_summ)\n\n\n\n\n\n\nAbbildung 10.3: Die Veränderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD)\n\n\n\n🧑‍🎓 Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der Y-Wert an der Stelle X=0, s. Kapitel 9.5.\nIn den Wetterdaten wäre Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extraplieren, ganz ohne dass wir dafür Daten haben, s. Abbildung 10.4.\n\n\n\n\n\nAbbildung 10.4: Du sollst nicht ein Modell weit außerhalb seines Datenbereichs extrapolieren\n\n\nSinnvoller ist es da, z.B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezöge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn für dieses Jahr haben wir Daten.\nHat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es üblich, z.B. den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten.\nSo zentriert man eine Verteilung:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist übrigens 1951:\n\nwetter %&gt;% \n  summarise(mean(year))\n\n\n  \n\n\n\nDie Steigung (d.h. der Regressionskoeffizient für year_c) bleibt unverändert, nur der Achsenabschnitt ändert sich, s. Tabelle 10.4.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert)\n\n\n\n\nTabelle 10.4: Modellparameter von lm_wetter1_zentriert\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n8.49\n0.04\n(8.42, 8.57)\n219.43\n&lt; .001\n\n\nyear c\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celcius. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\n\n\n\n\n\n\nReferenzwert entspricht Null\n\n\n\nDer Referenzwert bzw. der Wert der Referenzgruppe entspricht dem Y-Wert bei x=0 im Regressionsmodell.\\(\\square\\)\n\n\nWie gut erklärt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklärt das Modell mit year_c4 aber nicht. Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.B. die Jahreszeit eine große Rolle für die Temperatur. Das haben wir nicht berücksichtigt.\n\n🧑‍🎓 Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##       1 \n## 9.65775\n\n\n🧑‍🎓 Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5° Celcius.5\n\n\n👨‍🏫 Wir brauchen ein besseres Modell! Zum Glück haben wir ambitionierte Nachwuchs-Wissenschaftler:innen.\n\nDie Veränderung der auf fünf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in Abbildung 10.5 dargestellt. Links ist eine grobe Temperatur-rasterung zu sehenR (Daten ab 1753)6; rechts eine feinere (Daten ab 1881)7.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020\n\n\n\nAbbildung 10.5: \n\nBildquelle; Lizenz: GeoNutzV\n\n10.3.3 Binäre UV\n\nDefinition 10.1 (Binäre Variable) Eine binäre UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei Ausprägungen: 0 und 1.\\(\\square\\)\n\n\nBeispiel 10.3 (Binäre Variablen) Das sind zum Beispiel weiblich mit den Ausprägungen 0 (nein) und 1 (ja) oder before_1950 mit 1 für Jahre früher als 1950 und 0 ansonsten.\\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\n🧑‍🎓 Ob es in der zweiten Hälfte des 20. Jahrhunderts wohl wärmer warm, im Durchschnitt, als vorher?\\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite Hälfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Überlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.4.4) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prüfe ob as Jahr größer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht größer als 1950, das dritte schon.\nJa, so könnte das klappen! Diese Syntax übertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten für Gesamt-Deutschland\n\nScheint zu klappen!\nJetzt ein lineares Modell dazu berechnen:\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\nDie Parameter des Modells lassen darauf schließen, dass es tatsächlich wärmer war nach 1950, und zwar im Schnitt offenbar ein gutes halbes Grad, s. Abbildung 10.6.\n\n\n\n\n\n\nDer Schätzbereich für den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied\n\n\n\n\n\nWie man sieht, überlappen die Temperaturen dennoch beträchtlich; aufgrund des starken Overplotting ist dieses Diagramm alles andere als ideal\n\n\n\n\n\nAbbildung 10.6: Modell temp ~ after_1950\n\n\nLeider zeigt ein Blick zum r2, dass die Vorhersagegüte des Modells zu wünschen übrig lässt8. \\(\\square\\)\n\n\n\n\n\n\nLineare Modelle verkraften nur metrische Variablen\n\n\n\nUm die Koeffizienten eines linearen Modells auszurechnen, benötigt man eine metrische X- und eine metrische Y-Variable. Hier haben wir aber keine richtige metrische X-Variable9, sondern eine logische Variable mit den Werten TRUE und FALSE.\\(\\square\\)\n\n\nUm die X-Variable in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R für uns ohne viel Ankündigung durchführt.\n\n\n\n\n\n\nHinweis\n\n\n\nHat ein nominaler Prädiktor zwei Stufen, so überführt10 lm() diese Variable in eine binäre Variable. Da eine binäre Variable metrisch ist, kann die Regression in gewohnter Weise durchgeführt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binäre Variable. Man beachte, dass der ursprüngliche Datensatz nicht geändert wird, nur während der Analyse von lm wird die Umwandlung der Variable 11 druchgeführt.\\(\\square\\)\n\n\n\n🤖 Eine 1 kannst du als “Ja! Richtig!” verstehen und eine0 als “Nein! Falsch!”\n\n\nafter_1950 wird in eine Indikatorvariable umgewandelt:\n\n\n\n\n\nid\nafter_1950\n\n\n\n1\nTRUE\n\n\n2\nFALSE\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\nafter_1950TRUE\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\nBeispiel 10.5 (Beispiel: ‘Geschlecht’ in eine binäre Variable umwandeln.) Angeonmen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umgewandeln. Da “Frau” alphabetisch vor “Mann” kommt, nimmt R “Frau” als erste Stufe bzw. als Referenzgruppe. “Mann” ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann).\\(\\square\\)\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\nEin lineares Modell mit binärer UV ist nichts anderes die Differenz der Gruppenmittelwerte zu berechnen:\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n  \n\n\n\nDie Interpretation eines linearen Modells mit binärer UV veranschaulicht Abbildung 10.7: Der Achsenabschnitt (b0) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (Abbildung 10.7 zeigt nur die Daten für den Monat Juli im Bundesland Bayern, der Einfachheit und Übersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildung 10.7: Sinnbild zur Interpretation eines linearen Modells mit binärer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten für das Modell mit binärer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (b0)\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (b0) + Steigung der Regressionsgeraden (b1)\n\n\nFür die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nBei nominalen (und auch bei binären) Variablen ist \\(\\color{beta1col}{\\beta_1}\\) ein Schalter; bei metrischen Variablen ein Dimmer.12 \\(\\square\\)\n\n\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineare Modell13 mit einer mehrstufigen14 (nominalskalierten) UV.15\n\nBeispiel 10.6 Ob es wohl substanzielle16 Temperaturunterschiede zwischen den Bundesländern gibt?\n\nBefragen wir dazu ein lineares Modell, s. Tabelle 10.5.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\nparameters(lm_wetter_region)\n\n\n\n\nTabelle 10.5: Modellparameter für lm_wetter_region\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27152)\np\n\n\n\n(Intercept)\n8.25\n0.16\n(7.93, 8.56)\n51.62\n&lt; .001\n\n\nregion (Bayern)\n-0.63\n0.23\n(-1.07, -0.19)\n-2.79\n0.005\n\n\nregion (Brandenburg)\n0.57\n0.23\n(0.13, 1.02)\n2.53\n0.011\n\n\nregion (Brandenburg/Berlin)\n0.58\n0.23\n(0.14, 1.03)\n2.59\n0.010\n\n\nregion (Hessen)\n0.11\n0.23\n(-0.33, 0.56)\n0.51\n0.612\n\n\nregion (Mecklenburg-Vorpommern)\n0.08\n0.23\n(-0.37, 0.52)\n0.34\n0.732\n\n\nregion (Niedersachsen)\n0.52\n0.23\n(0.07, 0.96)\n2.29\n0.022\n\n\nregion (Niedersachsen/Hamburg/Bremen)\n0.52\n0.23\n(0.08, 0.96)\n2.31\n0.021\n\n\nregion (Nordrhein-Westfalen)\n0.80\n0.23\n(0.35, 1.24)\n3.53\n&lt; .001\n\n\nregion (Rheinland-Pfalz)\n0.46\n0.23\n(0.02, 0.90)\n2.03\n0.042\n\n\nregion (Saarland)\n0.71\n0.23\n(0.27, 1.16)\n3.16\n0.002\n\n\nregion (Sachsen)\n-0.04\n0.23\n(-0.48, 0.40)\n-0.18\n0.853\n\n\nregion (Sachsen-Anhalt)\n0.55\n0.23\n(0.11, 1.00)\n2.45\n0.014\n\n\nregion (Schleswig-Holstein)\n0.17\n0.23\n(-0.27, 0.62)\n0.76\n0.446\n\n\nregion (Thueringen)\n-0.48\n0.23\n(-0.92, -0.03)\n-2.11\n0.035\n\n\nregion (Thueringen/Sachsen-Anhalt)\n0.10\n0.23\n(-0.34, 0.54)\n0.43\n0.664\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariablen um. Genauer gesagt ist es immer eine Indikatorvariablen weniger als es Stufen in der nominalskalierten Variablen gibt.\n\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland (aus Gründen der Einfachheit hier nur mit 3 Bundesländern). Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt:\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWü\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\nAuch im Fall mehrerer Ausprägungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binären Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 1. Regressionsgeraden (b1)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 2. Regressionsgeraden (b2)\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts ausgewählt wurde) nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.\n\n\n\n\n\n\nHinweis\n\n\n\nBei einer Variable vom Typ character wählt R den alphabetisch ersten Wert als Referenzgruppe für ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. \\(\\square\\)\n\n\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-Württemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewählt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird.\\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. Abbildung 10.8.\n\n\n\n\n\n\n\nAbbildung 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). Die Achsen wurden um 90° gedreht, damit man die Namen der Bundesländer besser lessen kann.\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht außer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechnen!\n\n🤖 Endlich geht’s weiter! Ergebnisse in Tabelle 10.6! \\(\\square\\)\n\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelle 10.6: Modellparameter für lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschied im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. Abbildung 10.9, links.17 Oh nein: R betrachtet month als numerische Variable! Aber “Monat” bzw. “Jahreszeit” sollte nominal sein.\n\n🤖 Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\n👩 Okay, R, wir müssen month in eine nominale Zahl transformieren. Wie geht das?\n\n\n🤖 Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heißt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau.\\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. Tabelle 10.7.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor)\n\n\n\n\nTabelle 10.7: Modellparameter von lm_wetter_month_factor\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27156)\np\n\n\n\n(Intercept)\n56.95\n0.64\n(55.68, 58.21)\n88.56\n&lt; .001\n\n\nmonth factor (2)\n-9.95\n0.91\n(-11.73, -8.17)\n-10.94\n&lt; .001\n\n\nmonth factor (3)\n-7.78\n0.91\n(-9.56, -6.00)\n-8.56\n&lt; .001\n\n\nmonth factor (4)\n-8.49\n0.91\n(-10.27, -6.71)\n-9.34\n&lt; .001\n\n\nmonth factor (5)\n4.74\n0.91\n(2.96, 6.53)\n5.22\n&lt; .001\n\n\nmonth factor (6)\n14.34\n0.91\n(12.56, 16.12)\n15.77\n&lt; .001\n\n\nmonth factor (7)\n24.36\n0.91\n(22.57, 26.14)\n26.74\n&lt; .001\n\n\nmonth factor (8)\n17.52\n0.91\n(15.74, 19.31)\n19.24\n&lt; .001\n\n\nmonth factor (9)\n1.93\n0.91\n(0.15, 3.72)\n2.12\n0.034\n\n\nmonth factor (10)\n2.29\n0.91\n(0.51, 4.08)\n2.52\n0.012\n\n\nmonth factor (11)\n0.89\n0.91\n(-0.89, 2.68)\n0.98\n0.327\n\n\nmonth factor (12)\n5.20\n0.91\n(3.42, 6.99)\n5.71\n&lt; .001\n\n\n\n\n\n\n\n\nSehr schön! Jetzt haben wir eine Referenzgruppe (Monat 1, d.h. Januar) und 11 Unterschiede zum Januar, s. Abbildung 10.9, rechts.\n\n\n\n\n\n\nlm_wetter_month, Monat fälschlich als metrische Variable\n\n\n\n\n\nlm_wetter_month_text, Monat korrekt als nominale Variable (aber mit viel Overplotting, das müsste man besser machen)\n\n\n\n\n\nAbbildung 10.9: Niederschlagsunterschiede pro Monat (ein Punkt ist ein Jahr); aufgrund der vielen Datenpunkte ist das Diagramm wenig übersichtlich (Overplotting).\n\n\nMöchte man die Referenzgruppe eines Faktors ändern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geänderte Reihenfolge aus:18:\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 Binäre plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binären) UV plus einer metrischen UV.19\n\nBeispiel 10.12 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\n👨‍🏫 Ich muss mal kurz auf eine Sache hinweisen…\n\n\n\n\n\n\n\nFaktorvariable\n\n\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich für nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten Ausprägungen (“Faktorstufen”) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht.\nDas kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche Ausprägungen in Ihrer Variable möglich sind.\\(\\square\\)\n\n\n\nBeispiel 10.10 (Beispiel für eine Faktorvariable)  \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\n\nBeispiel 10.11 (Filtern verändert die Faktorstufen nicht) Wenn Sie von der Faktorvariablen20 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.B. nur die ersten beiden Elemente übrig bleiben mit allein der Ausprägung \"f\", merkt sich R trotzdem, dass es zwei Faktorstufen gibt (\"f\" und \"m\").\nGenaus so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. Möchten Sie die herausgefilterten Faktorstufen “löschen”, so können Sie einfach die Faktorvariable neu berechnen (mit factor).\\(\\square\\)\n\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  mutate(month_factor = factor(month))  # Faktor (und damit die Faktorstufen) neu berechnen\n\nOkay. Wie spezifiziert man jetzt das lineare Modell?\\(\\square\\)\n\nHat man mehrere (“multiple”) X-Variablen21, so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.B. temp ~ year_c + month.\n\n\n\n\n\n\nMultiple Regression\n\n\n\nEine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y ~ x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\n\nDie Veränderung der monatlichen Temperatur (10-Jahres-Mittel) ist in Abbildung 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schöner aus).\n\n\n\n\n\n\nModellgleichung\n\n\n\nDas Pluszeichen hat in der Modellgleichung22 keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur “und noch folgende UV…”.\\(\\square\\)\n\n\nDie obige Modellgleichung liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, data = wetter_month_1_7)\n\nDie Modellparameter sind in Tabelle 10.8 zu sehen.\n\n\n\nTabelle 10.8: Modellparameter von lm_year_month\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4525)\np\n\n\n\n(Intercept)\n56.94\n0.68\n(55.60, 58.27)\n83.57\n&lt; .001\n\n\nyear c\n0.03\n0.01\n(5.59e-03, 0.05)\n2.43\n0.015\n\n\nmonth factor (7)\n24.37\n0.97\n(22.48, 26.27)\n25.25\n&lt; .001\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (b0, (Intercept)): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57 mm pro Quadratmeter.\nRegressionskoeffizient für Jahr (b1, year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.02 mm an (im Referenzmonat).\nRegressionskoeffizient für Monat (b2, month [7]) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25 mm über dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7.\nIm Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0.\n\n🧑‍🎓 Puh, kompliziert!\n\n\n👨‍🏫 Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. Beispiel 10.13.\n\n\nBeispiel 10.13 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag für Januar im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"1\"))\npredict(lm_year_month, newdata = neue_daten)\n##        1 \n## 58.92171\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nAlle Regressionskoeffizienten beziehen sich auf den Y-Wert unter der Annahme, dass alle übrigen Prädiktoren den Wert Null (bzw. Referenzwert) aufweisen.\\(\\square\\)\n\n\nVisualisieren wir uns die geschätzten Erwartungswert pro Prädiktorwert, s. Abbildung 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildung 10.10: Temperaturverlauf über die Jahre für zwei Monate. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von (Okabe & Ito, 2023) ersetzt (s. Hinweise hier). Das ist nicht unbedingt nötig, aber robuster bei Schwarz-Weiß-Druck und bei Sehschwächen, vgl. Kapitel 5.9.3.\nDie erklärte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht würden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dürfen?\nNicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. Abbildung 10.11.\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\nplot(estimate_expectation(lm_year_month_interaktion)) +\n  scale_color_okabeito()  # schönes Farbschema\n\n\n\n\n\n\nAbbildung 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die Veränderung im Verlauf der Jahre ist unterschiedlich für die Monate (Janur vs. Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator : fügt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\n\n\n\n\n\nWichtig\n\n\n\nEinen Interaktionseffekt von x1 und x2 kennzeichnet man mit dem Doppelpunkt-Operator:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\n\nIn Worten:\n\n“y wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.”\n\nWie man in Abbildung 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel.\n\n\n\n\n\n\nHinweis\n\n\n\nSind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor.\\(\\square\\)\n\n\n\nBeispiel 10.14 (Interaktionseffekt von Niederschlag und Monat) Wie ist die Veränderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich für die Monate: Im Juli nahm der Niederschlag ab, im Januar zu.\\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von “dem” (statistischen) Effekt eines Prädiktors (afu die Y-Variable) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.B. Monat) unterscheidet der Effekt.23\nBetrachten wir die Parameterwerte des Interaktionsmodells (parameters(lm_year_month_interaktion)), s. Tabelle 10.9.\n\n\n\nTabelle 10.9: Modellparameter von lm_year_month_interaktion\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4524)\np\n\n\n\n(Intercept)\n56.91\n0.68\n(55.59, 58.24)\n84.21\n&lt; .001\n\n\nyear c\n0.13\n0.02\n(0.10, 0.16)\n7.80\n&lt; .001\n\n\nmonth factor (7)\n24.37\n0.96\n(22.50, 26.25)\n25.45\n&lt; .001\n\n\nyear c × month factor (7)\n-0.20\n0.02\n(-0.25, -0.16)\n-8.62\n&lt; .001\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die Zeile year c × month factor [7]. Sie gibt die Stärke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre ändert: Im Monat \"7\" ist der Effekt von year_c um 0.20 mm geringer: Die Regressionsgerade neigt sich mehr nach “unten” im Monat Juli, da der Koeffizient kleiner als Null ist.\nDie Regressionsgleichung lautet: precip_pred = 56.91 + 0.13*year_c + 24.37*month_factor_7 - 0.20*year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert für Y an unter der Annahme, dass alle Prädiktoren den Wert Null aufweisen. In diesem Fall gibt der Achsenabschnitt also den Niederschlag für den Janur des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in Y an, wenn der jeweilige Prädiktorwert um 1 steigt, die übrigen Prädiktoren aber den Wert 0 aufweisen.\\(\\square\\)\n\n\nDas R-Quadrat von lm_year_month_interaktion beträgt übrigens:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. Abbildung 10.12. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n3D-Animation\nInteraktives 3D-Diagramm\n2D-Diagramm für 3D-Modell\n\n\n\n\n\nAnimation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklärt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.12\n\n\nGrundsätzlich kann man viele Prädiktoren in ein (lineares) Modell aufnehmen.\nBetrachten wir z. B. folgendes lineares Modell mit zwei metrischen UV.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\n\n\n\n\n\n\n\nAbbildung 10.13: Lineares Modell mit 2 metrischen UV (und 1 metrische AV)\n\n\n\nJedes der beiden Regressionsgewichte in lm_mario_2uv entspricht der Steigung in der beiden Achsen in Abbildung 10.13, d.h. die Steigung für start_pr bzw. die Steigung für ship_pr.\n\n10.4.2 Viele UV ins Modell?\nWir könnten im Prinzip alle Variablen unserer Datentabelle als Prädiktoren in das Regressionsmodell aufnehmen. Die Frage ist nur: macht es Sinn?\nHier sind einige Richtlinien, die helfen, welche Prädiktoren (und wie viele) man in ein Modell aufnehmen sollte (Gelman et al., 2021a, S. 199f):\n\nMan sollte alle Prädiktoren aufnehmen, von denen anzunehmen ist, dass Sie Ursachen für die Zielvariablen sind\nBei Prädiktoren mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen\nPrädiktoren mit kleinem Schätzbereich (95 CI) sollten tendenziell im Modell belassen werden, da sie die Modellgüte verbessern",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.15 (Prognose des Verkaufspreis) Ganz können Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen möglichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld.\\(\\square\\)\n\n\n10.5.1 Modell “all-in”\nUm die Güte Ihrer Vorhersagen zu prüfen, teilt Ihr Chef den Datensatz in zwei zufällige Teile.\n\n🧔‍♂️ Ich teile den Datensatz mariokart zufällig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (“trainieren”) und ihre Güte zu prüfen. Den Teil nenne ich “Trainingssample”, hört sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die Güte deiner Vorhersagen in dem verbleibenden Teil, die übrigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten auf Ihrer Festplatte liegen, z.B. im Unterordner daten, dann könne Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"daten/mariokart_train.csv\")\n\nAlternativ können Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die “All-in-Strategie”: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.979\n\nDer Punkt in total_pr ~ . heißt “alle Variablen in der Tabelle (außer total_pr)”.\n\n🧔‍♂️ Hey! Das ist ja fast perfekte Modellgüte!\n\n\n🦹‍♀️ Vorsicht: Wenn ein Angebot aussieht wie “too good to be true”, dann ist es meist auch too good to be true.\n\n\n\n\n\n\n\nOverfitting\n\n\n\nDer Grund für den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. Weiß man, welcher Titel zu welcher Auktion gehört, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nützen die Titel der Auktionen im Train-Sample nichts für andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stützen. Merke: Höchst idiografische Informationen wie Namen, Titel etc. sind nicht nützlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\\(\\square\\)\n\n\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in eval(predvars, data, env): object 'V1' not found\n\nOh nein! Was ist los!? Eine Fehlermeldung!\n\n\n\n\n\n\nVorsicht\n\n\n\nNominalskalierte Prädiktorvariablen mit vielen Ausprägungen, wie title sind problematisch. Kommt eine Ausprägung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. Häufig ist es sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting führen.\\(\\square\\)\n\n\n\n10.5.2 Modell “all-in”, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. Nächster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, V1, id))\n\nWir entfernen auch die Spalte V1 und id, da sie ebenfalls keine Informatione bergen.\n\nlm_allin_no_title &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist ja durchaus ordentlich. Schauen wir uns noch den rmse (die SD der Vorhersagefehler) an24:\n\n🤖 Gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title)\n## [1] 20.22998\n\n\n\n\n\n\n\nName Clash\n\n\n\nIm Paket yardstick gibt es eine Funktion namens rmse und im Paket performance, Teil des Meta-Pakets easystats ebenfalls. Da sind Probleme vorprogrammiert. Das ist so als würde die Lehrerin rufen: “Schorsch, komm her!”. Dabei gibt es zwei Schorsche in der Klasse: Den Müllers Schorsch und den Meiers Schorsch. Sonst kommen beide, was die Lehrerin nicht will. Die Lehrerin müsste also rufen: “Müller Schorsch, komm her!”. Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den “Nachnamen” des Befehls: paketname::funktion ist wie Müller::Schorsch. In unserem Fall also: performance::rmse Endlich weiß R wieder, was zu tun ist!\\(\\square\\)\n\n\nSie rennen zu Ihrem Chef, der jetzt die Güte Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\n🧔‍♂️ Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das “Test-Sample”.\n\nIhr Chef schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n  \n\n\n\n\n🧔‍♂️ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nHier sind Ihre Vorhersagen25:\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title, newdata = mariokart_test)\n\nHier sind Ihre ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##        1        2        3        4        5        6 \n## 28.62826 53.85885 53.28035 54.03619 41.75512 46.57713\n\nDies Vorhersagen fügen wir noch der Ordnung halber in die Tabelle mit den Test-Daten:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title, newdata = mariokart_test))\n\nOkay, was ist jetzt der mittlere Vorhersagefehler?\nUm die Vorhersagegüte im Test-Sample auszurechnen26, nutzen wir die Funktionen des R-Paketes yardstick27:\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\n\nIhr mittlerer Vorhersagefehler (MAE) liegt bei ca. 13 Euro.28\n\n🧔‍♂️ Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n  \n\n\n\n\n🧔‍♂️ 17%, nicht berauschend, aber immerhin!\n\n\n\n\n\n\n\nModellgüte im Test-Sample meist geringer als im Train-Sample\n\n\n\nWie das Beispiel zeigt, ist die Modellgüte im Test-Sample (leider) oft geringer als im Train-Sample. Die Modellgüte im Train-Sample ist mitunter übermäßig optimistisch. Dieses Phänomen bezeichnet man als Overfitting.\\(\\square\\)\n\n\n\n\n\n\n\n\nTipp\n\n\n\nBevor man Vorhersagen eines Modells einreicht, bietet es sich, die Modellgüte in einem neuen Datensatz, als einem Test-Sample, zu überprüfen.\\(\\square\\)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste Schätzung der Güte Ihres Modells erfahren möchten, bietet sich folgendes Vorgehen an (vgl. Abbildung 10.14):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrüfen Sie die Modellgüte im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie können sie z.B. so bewerkstelligen:\n\nlibrary(rsample)\nmariokart &lt;- read_csv(\"daten/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"daten\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split bestimmt für jede Zeile (Beobachtung) zufällig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt29; das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafür, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wäre nämlich blöd für Ihr Modell, wenn im Train-Sample z.B. nur die teuren, und im Test-Sample nur die günstigen Spiele landen würde.30 In so einem Fall würde sich Ihr Modell unnötig schwer tun.\nIm nächsten Schritt können Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsächlich aufteilen.31\n\nmariokart_train &lt;- training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- testing(meine_aufteilung)  # Assessment-Sample\n\nIch persönliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kürzer zu tippen und einheitlich. Sie können aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, außerdem Kürze und aussagekräftige Namen.\n\n10.6.2 Train- vs. Test-Sample\n\nDefinition 10.2 (Train-Sample) Den Datensatz, für die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\nDas Train-Sample stellt die bekannten Daten dar; aus denen können wir lernen, d.h. unser Modell berechnen.\n\nDefinition 10.3 (Test-Sample) Den Datensatz, für den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\nDas Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiß, was der Wert der AV ist.\nDer Zusammenhang dieser verschiedenen, aber zusammengehörigen Arten von Stichproben ist in Abbildung 10.14 dargestellt.\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildung 10.14: Verschiedene Arten von zusammengehörigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden “abwanderungsgefährdet” sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (“customer churn”). Es gibt eine ganze Reihe von Untersuchungen dazu, z.B. die von Lalwani et al. (2022). Die Forschis versuchen anhand von Daten und u.a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von über 80% in Ihrem (besten) Vorhersagemodell.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lügt",
    "href": "090-regression2.html#wie-man-mit-statistik-lügt",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lügt",
    "text": "10.8 Wie man mit Statistik lügt\n\n10.8.1 Pinguine drehen durch\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von Schnabellänge (bill length) und Schnabeltiefe (bill depth) interessiert, s. Abbildung 10.15.\n\n\n\n\n\nAbbildung 10.15: Schnabellänge und Schnabeltiefe\n\n\nDas Team hat in schweißtreibender eiszapfentreibender Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und überlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von Schnabellänge und Schnabeltiefe. Das könnte einen Nobelpreis wert sein. Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")\n\n\n\n\n\n\n\nHier sind die statistischen Details, s. Tabelle 10.10.\n\nlm1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelle 10.10: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(340)\np\n\n\n\n(Intercept)\n20.89\n0.84\n(19.23, 22.55)\n24.75\n&lt; .001\n\n\nbill length mm\n-0.09\n0.02\n(-0.12, -0.05)\n-4.46\n&lt; .001\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf veröffentlicht eine verfeindete Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von Schnabelllänge und Schnabeltiefe.\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\", color = \"species\")\n\n\n\n\n\n\n\nOh nein! Was ist hier nur los? Daten lügen nicht, oder doch?\nHier sind die statistischen Details der zweiten Analyse, s. Tabelle 10.11. Im zweiten Modell kam species als zweiter Prädiktor neu ins Modell (zusätlich zur Schnabellänge).\n\nlm2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelle 10.11: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(338)\np\n\n\n\n(Intercept)\n10.59\n0.68\n(9.25, 11.94)\n15.51\n&lt; .001\n\n\nbill length mm\n0.20\n0.02\n(0.17, 0.23)\n11.43\n&lt; .001\n\n\nspecies (Chinstrap)\n-1.93\n0.22\n(-2.37, -1.49)\n-8.62\n&lt; .001\n\n\nspecies (Gentoo)\n-5.11\n0.19\n(-5.48, -4.73)\n-26.67\n&lt; .001\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDaten alleine reichen nicht\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse - Gesamtdaten oder Subgruppen - die richtige ist. Nicht-exprimentelle Studien können zu grundverschiedenen Ergebnissen führen, jenachdem ob Prädiktoren dem Modell hinzugefügt oder weggenommen werden. \\(\\square\\)\n\n\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere nie Modellkoeffizienten ohne ein Kausalmodell.\\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lässt man besser die Finger von der Interpretation der Modellkoeffizienten und begnügt sich mit der Beschreibung der Modellgüte und mit Vorhersage32. Wer das nicht glaubt, der betrachte Abbildung 10.16, links.33 Ei Forschi stellt das Modell m1: y ~ x auf und interpretiert dann b1: “Ist ja klar, X hat einen starken positiven Effekt auf Y!”.\nIn der nächsten Studie nimmt dis Forschi dann eine zweite Variable, group (z.B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. Abbildung 10.16, rechts!\nDieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt “echt”, also kausal, ist. Handelt es sich aber um “nicht echte”, also nicht-kausale Zusammenhänge, um Scheinzusammenhänge also, so können sich die Modellkoeffizienten dramatisch verändern (sogar das Vorzeichen kann wechseln34), wenn man das Modell verändert, also Variablen hinzufügt oder wegnimmt.\nWenn man die kausalen Abhängigkeiten nicht kennt, weiß man also nicht, ob die Zusammenhänge kausal oder nicht-kausal sind. Man weiß also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker Zusammenhang; b1 ist stark positiv\n\n\n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, in jeder der beiden Gruppen ist der Zusammenhang praktisch Null, b1 = 0\n\n\n\n\n\n\nAbbildung 10.16: Fügt man in ein Modell eine Variable hinzu, können sich die Koeffizienten massiv ändern. In beiden Diagrammen wurden die gleichen Daten verwendet.\n\n\nMan könnte höchstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.B. “Dort wo es viele Störche gibt, gibt es auch viele Babies”.35 Leider ist unser Gehirn auf kausale Zusammenhänge geprägt: Es fällt uns schwer, Zusammenhänge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulässig kausal interpretiert - von Laien und Wissenschaftlern auch.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fazit",
    "href": "090-regression2.html#fazit",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.9 Fazit",
    "text": "10.9 Fazit\nIn diesem Kapitel haben Sie lineare Modelle gelernt, die über einfache Modelle der Art y ~ x hinausgehen. Dazu gehören multiple Modelle, das sind Modelle mit mehr als einer UV (Prädiktor) und auch Interaktionsmodelle. Außerdem haben Sie sich mit einem Datensatz von gesamtgesellschaftlichen Nutzen beschäftigt - sehr schön. Das Fallbeispiel zum Schluss war vielleicht erhellend insofern, als dass ein gutes Modell im Train-Sample nicht (notwendig) zu guten Vorhersagen im Test-Sample führt.\n\n\n\n\n\n\nWichtig\n\n\n\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. Abbildung 10.17. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n(a) So ging es Ihnen gestern\n\n\n\n\n\n\n\n\n\n(b) So wird es Ihnen morgen ergehen, wenn Sie dran bleiben\n\n\n\n\n\n\nAbbildung 10.17: Statistik, Sie und Party: Gestern und (vielleicht) morgen.\n\n\nQuelle: imgflip",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausführlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker Flugverspätungen\n\nSource\nVorhersage von Flugverspätungen\n\n10.10.2 Filmerlöse\nVorhersagen von Filmerlösen",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklärt die lineare Regression mit Hilfe von Drachen. 🐉 Sehenswert.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nWenn es ein Standardwerk für Regressionsanalyse geben könnte, dann vielleicht das neueste Buch von Andrew Gelman, einer der bekanntesten Statistiker (Gelman et al., 2021b). Sein Buch ist für Sozialwissenschaftler geschrieben, also nicht für typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literatur",
    "href": "090-regression2.html#literatur",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.14 Literatur",
    "text": "10.14 Literatur\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021a). Regression and Other Stories. Cambridge University Press.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021b). Regression and Other Stories. Cambridge University Press.\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private Traits and Attributes Are Predictable from Digital Records of Human Behavior. Proceedings of the National Academy of Sciences, 110(15), 5802–5805. https://doi.org/10.1073/pnas.1218772110\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing. Archives for Scientific Computing, 104(2), 271–294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "Lizenzhinweis: Datenbasis: Deutscher Wetterdienst, eigene Elemente ergänzt.↩︎\nsynonym: Regressionsanalysen↩︎\nTemperatur: Grad Celcius, Niederschlag (precip) mm Niederschlag pro Quadratmeter↩︎\nyear und year_c sind gleich stark mit temp korreliert, daher wird sich die Modellgüte nicht unterscheiden.↩︎\nQuelle: Umweltbundesamt↩︎\nQuelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3↩︎\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/↩︎\nr2(lm_wetter_bin_uv)↩︎\nUV↩︎\nsynonym: transformiert↩︎\nTransformation↩︎\nIch danke Karsten Lübke für diese Idee.↩︎\nfür uns synonym: Regressionsmodell↩︎\ndrei oder mehr Stufen bzw. Ausprägungen↩︎\nSo ein Modell ist von den Ergebnissen her praktisch identisch zu einer einfachen Varianzanalyse.↩︎\nwie könnte man dieses Wort eigentlich definieren?↩︎\nplot(estimate_expectation(lm_wetter_month)↩︎\nZum Dollar-Operator s. Kapitel 3.9.2↩︎\nSo ein Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ancova) bezeichnet werden.↩︎\nsynonym: nominalskalierte Variable↩︎\nPrädiktoren, unabhängige Variablen, X-Variablen↩︎\nsynonym: Regressionsformel↩︎\nEffekt ist hier immer statistisch, nie kausal gemeint.↩︎\nder Befehl wohnt im Paket performance, Teil des Metapakets easystats↩︎\nengl. predictions; to predict: vorhersagen↩︎\nwir verwenden dazu die Funktionen mae und rsq↩︎\nwelches Sie vielleicht noch installieren müssen.↩︎\nWir haben hier yardstick::mae geschrieben und nicht nur mae, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens mae gibt. Name-Clash-Alarm! R könnte daher den anderen mae meinen als Sie, was garantiert zu Verwirrung führt. Entweder bei R oder bei Ihnen.↩︎\nvgl. help(initial_split)↩︎\nAnderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B.↩︎\ninitial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgeführt.↩︎\nsynonym: Prognose↩︎\nQuelle↩︎\ndas nennt man dann Simpsons Paradox↩︎\nDas Störche-Babies-Beispiel passt auch zu Abbildung 10.16.↩︎",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html",
    "href": "100-abschluss.html",
    "title": "\n11  Abschluss\n",
    "section": "",
    "text": "11.1 Lernsteuerung",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#lernsteuerung",
    "href": "100-abschluss.html#lernsteuerung",
    "title": "\n11  Abschluss\n",
    "section": "",
    "text": "11.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n11.1.2 Lernziele\nkein neuer Stoff\nZiel dieses Kapitels ist es, den Stoff des Moduls zu wiederholen und zu konsolidieren.\n\n11.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n11.1.4 Benötigte Daten\n\n\ndata(mtcars)",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#herzlichen-glückwünsch",
    "href": "100-abschluss.html#herzlichen-glückwünsch",
    "title": "\n11  Abschluss\n",
    "section": "\n11.2 Herzlichen Glückwünsch!",
    "text": "11.2 Herzlichen Glückwünsch!\n\nHerzlichen Glückwunsch - Sie haben diesen Kurs abgeschlossen! Es sei denn, Sie haben nur ein bisschen durchgeschaut. Dann war es hoffentlich zumindest interessant. 😄",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#wie-gehts-weiter",
    "href": "100-abschluss.html#wie-gehts-weiter",
    "title": "\n11  Abschluss\n",
    "section": "\n11.3 Wie geht’s weiter?",
    "text": "11.3 Wie geht’s weiter?\nEs gibt viele weiterführende Bücher und Kurse. Ein logischer nächster Schritt ist es, sich mit Inferenzstatistik zu beschäftigen. Dazu bietet sich z.B. der Kurs Start:Bayes! an, zufälligerweise aus der Feder des gleichen Autors…\nWenn Sie sich breiter (nicht tiefer) mit Data Literacy beschäftigen wollen, bietet sich der Online-Kurs des KI-Campus an. Es gibt viele Online-Kurse, die sich anbieten, wenn Sie im Thema moderne Datenanalyse fit werden wollen. Schauen Sie doch mal z.B. bei Coursera oder ähnlichen Anbietern vorbei.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#aufgabensammlungen",
    "href": "100-abschluss.html#aufgabensammlungen",
    "title": "\n11  Abschluss\n",
    "section": "\n11.4 Aufgabensammlungen",
    "text": "11.4 Aufgabensammlungen\nAuf dem Datenwerk finden Sie reichlich Aufgaben zur Prüfungsvorbereitung.\nU.a. folgende Tags sind für diesen Kurs relevant:\n\nR\nassociation\ndatawrangling\ndplyr\nlagemaße\nstreuungsmaß\nvariablelevles\nyacsda",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#quizze",
    "href": "100-abschluss.html#quizze",
    "title": "\n11  Abschluss\n",
    "section": "\n11.5 Quizze",
    "text": "11.5 Quizze\nHier geht’s zu einem Quiz zur deskriptiven Statistik (Maße der zentralen Tendenz, Variabilität, Verteilungsformen, Normalverteilung, Korrelation).\nHier geht’s zu einem Quiz zum Thema Verteilungen.",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#fallstudien",
    "href": "100-abschluss.html#fallstudien",
    "title": "\n11  Abschluss\n",
    "section": "\n11.6 Fallstudien",
    "text": "11.6 Fallstudien\n\n11.6.1 Datenvisualisierung\nFallstudien – NUR Datenvisualisierung\n\nvis-gapminder\nvis-penguins\nvis-mtcars\nAufgabe zur Datenvisualisierung des Diamantenpreises\n\n11.6.2 Explorative Datenanalyse\nFALLSTUDIEN - NUR EXPLORATIVE DATENANALYSE\n\nLouise E. Sinks: TidyTuesday Week 18: Portal Project\nLouise E. Sinks: TidyTuesday Week 17: London Marathon\nLouise E. Sinks: TidyTuesday Week 16: Neolithic Founder Crops\nDatenjudo mit Pinguinen\nData-Wrangling-Aufgaben zur Lebenserwartung\nCase study: data vizualization on flight delays using tidyverse tools\nFallstudie Flugverspätungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten Flugverspätungen, Datensatz ‘nycflights13’\nCleaning and visualizing genomic data: a case study in tidy analysis\nTidyverse Case Study: Exploring the Billboard Charts\nAnalyse einiger RKI-Coronadaten: Eine reproduzierbare Fallstudie\nOpenCaseStudies - Health Expenditure\nOpen Case Studies: School Shootings in the United States - includes dashboards\nOpen Case Studies: Disparities in Youth Disconnection\nYACSDA Seitensprünge\nThe Open Case Study Search provides a nice collection of helpful case studies.\nifes@FOM Fallstudienseite\n\n11.6.3 Lineare Modelle\nFALLSTUDIEN - NUR LINEARE MODELLE\n\nBeispiel für Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel für Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel für Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von Flugverspätungen\nModelling movie successes: linear regression\nMovies\nFallstudie Einfache lineare Regression in Base-R, Anfängerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\nFallstudie zum Beitrag verschiedener Werbeformate zum Umsatz; eine Fallstudie in Python, aber mit etwas Erfahrung wird man den Code einfach in R umsetzen können (wenn man nicht in Python schreiben will)\nPractical Linear Regression with R: A case study on diamond prices\nCase Study: Italian restaurants in NYC\nVorhersage-Modellierung des Preises von Diamanten\nModellierung Diamantenpreis 2",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#faq",
    "href": "100-abschluss.html#faq",
    "title": "\n11  Abschluss\n",
    "section": "\n11.7 FAQ",
    "text": "11.7 FAQ\nWerfen Sie auch einen Blick in typische R-Fragen.\n\n11.7.1 SD berechnen\nFRAGE: Macht es einen Unterschied, ob man dafür den Befehlt summary() oder den Befehl sd() verwendet? Bei mir kommen da nämlich unterschiedliche Zahlen raus.\nANTWORT: summary() gibt nicht SD aus, sondern nur den IQR (IQR = Q3-Q3).\n\ndata(mtcars)\nsd(mtcars$mpg)\n## [1] 6.026948\nsummary(mtcars$mpg)\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   10.40   15.43   19.20   20.09   22.80   33.90\n\n\n11.7.2 count vs. filter\nFRAGE: Wann benutzt man count() und wann filter()?\nANTWORT: Mit filter plus dem Zählen der übrig gebliebenen Zeilen erreicht man etwas Ähnliches wie mit count:\n\nmtcars |&gt; \n  filter(am == 0) |&gt; \n  nrow()\n## [1] 19\n\n\nmtcars |&gt; \n  count(am)\n\n\n  \n\n\n\n\n11.7.3 1000\nFRAGE: gibt es einen Unterschied zwischen 10^3 und 1e3? Es kommen nämlich unterschiedliche Ergebnisse raus.\nANTWORT: Nein, beide Schreibweisen meinen das Gleiche, nämlich die Zahl 1000.\n\n10^3 == 1000 \n## [1] TRUE\n1e3 == 1000\n## [1] TRUE",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  },
  {
    "objectID": "100-abschluss.html#literaturhinweise",
    "href": "100-abschluss.html#literaturhinweise",
    "title": "\n11  Abschluss\n",
    "section": "\n11.8 Literaturhinweise",
    "text": "11.8 Literaturhinweise\nDiese Literaturliste empfiehlt Ihnen Lehrbücher zu grundlegenden Themen der Datenanalyse (mit R).",
    "crumbs": [
      "Modellieren",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Abschluss</span>"
    ]
  }
]