[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik1",
    "section": "",
    "text": "Vorwort\nWillkommen bei Statistik1!\nDieses Buch fÃ¼hrt in die Grundlagen der Statistik ein mit einem Schwerpunkt auf Vorhersagen (Prognosen). Es ist ein angewandtes Buch fÃ¼r AnfÃ¤nger. Anders gesagt: Sie lernen, Daten aufzubereiten und mit Hilfe einfacher Modelle Vorhersagen abzuleiten. Dieses Buch soll Freude an der Statistik bereiten und hat nur ein Thema: Vorhersagen mittels moderner statistischen Methoden. Alle Inhalte dieses Buch erklÃ¤ren einen Aspekt der statistischen Prognose-Modellierung. Viele StatistikbÃ¼cher gibt es schon auf dieser Welt, braucht es da noch eines? Ja, es gibt viele StatistikbÃ¼cher, aber (meines Wissens) in deutscher Sprache keines, das Freude beim Lernen vermittelt, sich auf statistische Prognose-Modellierung konzentriert und moderne Werkzeuge einsetzt. Diese LÃ¼cke soll dieses Buch schlieÃŸen. Freude am Lernen, beim Angstgegner Statistik, wie soll das gehen? Viele VerstÃ¤ndnisschwierigkeiten rÃ¼hren daher, dass LehrbÃ¼cher kompliziert geschrieben sind. Solcher Didaktik liegt offenbar die Ãœberlegung zugrunde, dass die Konzepte prÃ¤zise und nuanciert erlÃ¤utert sein mÃ¼ssten. Meiner Ansicht nach wird da das Ziel mit dem Weg verwechselt: Am Anfang darf eine ErklÃ¤rung ruhig etwas grober sein. Ãœberblicken die Leserinnen und Leser die Materie einigermaÃŸen, kÃ¶nnen sie sich im nÃ¤chsten Schritt mit den Details vertraut machen, was PrÃ¤zision und Tiefe verlangt. DarÃ¼ber hinaus verwendet dieses Buch eine lockere Sprache fÃ¼r einen entspannten Lesefluss. FÃ¼r einigen Komfort beim Lesen wurde gesorgt: Lernziele, Definitionen, Beispiele, Ãœbungen, Hinweise, Fehlerquellen, Tipps, Literatur, Querverweise, QR-Codes zu externen Medien und andere Hilfsmittel mehr werden im Buch verwendet; an ErklÃ¤rbildern wurde nicht gespart.\n\nâ€œStatistische Modelleâ€ ist ein sperriger Begriff, aber er sagt nur, dass es darum geht, fachliche Fragen in statistisch greifbare Bausteine zu gieÃŸen. Ein Beispiel: Studentin Anna fragt sich, ob sie die PrÃ¼fung besteht, wenn Sie 42 Stunden bÃ¼ffelt? Student Bert meint, dass motivierte Studis am meisten vom Lernen profitieren. Studentin Carla ist hingegen Ã¼berzeugt, dass Lernen nix bringt, sondern dass die Intelligenz allein fÃ¼r den PrÃ¼fungserfolg verantwortlich sei. Damit haben wir drei (noch eher unprÃ¤zise) Modelle. Die Statistik hat die Aufgabe, ein (wissenschaftliches) Modell in ein statistisches zu Ã¼bersetzen, um mÃ¶glichst prÃ¤zise Antworten (fÃ¼r eine Forschungsfrage) zu liefern; dafÃ¼r sind Zahlen hilfreich. Wenn Anna, Bert und Carla ihre Ãœberlegungen fachlich schÃ¤rfen, auf wissenschaftlichen Theorien aufbauen und dann in statistische Sprache Ã¼bersetzen, kÃ¶nnen sie mit Antworten von der Statistik rechnen, manchmal sogar mit prÃ¤zisen. Was nicht heiÃŸt, dass diese Antworten immer richtig oder nÃ¼tzlich sind. Tja, das Leben ist nicht leicht.\nMit Blick auf den Spagat zwischen Theorie und Anwendung irrt das Buch (bzw. sein Autor) zugunsten der Seite der Anwendung. Ich wollte lieber befÃ¤higen, praktische Probleme zu lÃ¶sen, als tiefen theoretischen Einblick zu vermitteln. Meine Hoffnung ist, dass die Freude am KÃ¶nnen beflÃ¼gelt, sich im nÃ¤chsten Schritt tiefer mit der Materie zu beschÃ¤ftigen. Ist es nicht auch so im Alltag? Was Freude macht, wo sich Erfolge einstellen, dort vertiefen wir uns gerne weiter.\nDa sich das Buch auf ein Thema, Modellierung in der Statistik, konzentriert, bleiben andere Themen auÃŸen vor, vor allem Inferenzstatistik. Vielleicht freut sich die eine oder der andere, von diesem Thema verschont zu sein. Ich denke, dass Modellierung fÃ¼r die Forschung und fÃ¼r die Praxis ein zentraler Gedanke ist; fÃ¼r zwei groÃŸe Themen erscheint mir dieses Buch zu eng.\nWenn Sie Fragen oder Feedback haben, bin ich fÃ¼r Ihre Hinweise dankbar. Stellen Sie sie gerne hier ein: https://github.com/sebastiansauer/statistik1/issues. Die Online-Version dieses Buches ist frei verfÃ¼gbar und unter der CC-BY-NC-SA-4.0-Lizenz publiziert.\n\n\n\nCC BY NC SA 4.0\n\n\nEine gedruckte Version kÃ¶nnen Sie als Softcover oder Hardcover bei Amazon kaufen (ISBN Softcover: 979-8343798951; Hardcover: 979-8311581899).\nDieses Buch ist meinen Kindern Laurenz und Martha gewidmet. Und allen anderen Menschen, die noch viel lernen wollen. Die Fragen meiner Studierenden sind der Grund fÃ¼r vieles, was ich gelernt habe; dafÃ¼r bin ich dankbar.\nIch wÃ¼nsche Ihnen viel Freude und Erfolg beim Lernen!\nIhr\nSebastian Sauer",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "005-orga.html",
    "href": "005-orga.html",
    "title": "\n1Â  Organisatorisches\n",
    "section": "",
    "text": "1.1 Es geht um Ihren Lernerfolg\nMeister Yoda rÃ¤t: Lesen Sie die folgenden Hinweise, s. AbbildungÂ 1.1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#es-geht-um-ihren-lernerfolg",
    "href": "005-orga.html#es-geht-um-ihren-lernerfolg",
    "title": "\n1Â  Organisatorisches\n",
    "section": "",
    "text": "AbbildungÂ 1.1: Lesen die Inhalte du musst (imgflip, 2024).\n\n\n\n1.1.1 Lernziele\n\nDie Studierenden sind mit wesentlichen Methoden der explorativen Datenanalyse vertraut und kÃ¶nnen diese selbstÃ¤ndig anwenden.\nDie Studierenden kÃ¶nnen gÃ¤ngige Forschungsfragen in lineare Modelle Ã¼bersetzen, diese auf echte DatensÃ¤tze anwenden und die Ergebnisse interpretieren.\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nWas lerne ich hier?\nSie lernen das Handwerk der Datenanalyse mit einem Schwerpunkt auf Vorhersage (Prognose). Anders gesagt: Sie lernen, Daten aufzubereiten und aus Daten Vorhersagen abzuleiten. Zum Beispiel: Kommt ein Student zu Ihnen und sagt â€œIch habe 42 Stunden fÃ¼r die Klausur gelernt, welche Note kann ich in der Klausur erwarten?â€. Darauf Ihre Antwort: â€œAuf Basis meiner Daten und meines Modells mÃ¼sstest du eine 2,7 schreiben!â€ AuÃŸerdem lernen Sie, wie man die GÃ¼te einer Vorhersage auf Stichhaltigkeit prÃ¼ft. Denn Vorhersagen kann man ja in jeder Eckkneipe oder beim Wahrsager bekommen. Wir wollen aber belastbare Vorhersagen und wollen zumindest wissen, wie (un)sicher eine Vorhersage ist.\nWarum ist das wichtig?\nWir wollen nicht auf Leuten vertrauen, die behaupten, sie wÃ¼ssten, was fÃ¼r uns gut ist. Wir wollen selber die Fakten beurteilen kÃ¶nnen.\nWozu brauche ich das im Job?\nDatenanalyse spielt bereits heute in vielen Berufen eine Rolle. Tendenz stark zunehmend.\nWozu brauche ich das im Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es Ã¼blich, statistische Ergebnisse quantitativ zu analysieren.\nIst Statistik nicht sehr abstrakt?\nDer Schwerpunkt dieses Kurses liegt auf Anwenden und Tun; Ã¤hnlich dem Erlernen eines Handwerks. Theorien und Abstraktionen stehen in diesem Buch nur am Rand.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas World Economic Forum (2020) berichtet zu den â€œTop 20 job roles in increasing and decreasing demand across industriesâ€ (S. 30, Abb. 22): â€œ1. Data Analysts und Scientists, 2. AI and Machine Learning Specialists, 3. Big Data Specialistsâ€.\n\n1.1.3 Was ist hier das Erfolgsgeheimnis?\nDas Lesen einer Schwimmfibel nutzt wenig, wenn Sie Freischwimmer werden wollen. Es hilft nichts: Rein in die Fluten! Wenn das Wasser nicht tief ist und man jederzeit im Trockenen Pause machen kann, steht Ihrem Fortschritt beim Lernen nichts im Weg. Ich gebe zu, der Vergleich ist nicht gerade subtil. Aber es ist so: Sie lernen durch Tun (Lovett & Greenhouse, 2000). Dieses Buch bietet dafÃ¼r reichhaltige Gelegenheit. Nutzen Sie sie. Jedes Kapitel fÃ¼hrt am Ende eine Reihe von Aufgaben auf, alle mit LÃ¶sungen. So kÃ¶nnen Sie Ihren Lernfortschritt testen. Dass Schwierigkeiten auftreten, wenn man etwas Neues lernt, ist normal. Das geht fast allen so. Ihren Lernerfolg kann nur eine Sache gefÃ¤hrden: Wenn Sie aufgeben. Bleiben Sie dran, und der Erfolg wird sich einstellen! AbbildungÂ 1.2 zeigt Daten von \\(n=1646\\) Studierenden, die zeigen, dass regelmÃ¤ÃŸiges Ãœben und Dranbleiben mit Erfolg einhergeht (Sauer, 2017). Dran bleiben ist der SchlÃ¼ssel zum Erfolg. Ãœben Sie regelmÃ¤ÃŸig. Geben Sie bei Schwierigkeiten nicht auf. \n\n\n\n\n\nAbbildungÂ 1.2: Der Zusammenhang von Lernzeit (1: gering bis 5: hoch) von Klausurerfolg\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDran bleiben ist der SchlÃ¼ssel zum Erfolg. Ãœben Sie regelmÃ¤ÃŸig. Geben Sie bei Schwierigkeiten nicht auf. ğŸ‹ï¸â€â™‚ï¸ğŸ”ğŸ”‘âœ¨ \\(\\square\\)\n\n\n\n\n\nHaben Sie Motivation nÃ¶tig? Dann schauen Sie sich das Video mit einer Ansprache zur Motivation an.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.4 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie Folgendes mitbringen:\n\nBereitschaft, Neues zu lernen\nBereitschaft, bei Schwierigkeiten nicht gleich aufzugeben\nKenntnis grundlegender Methoden wissenschaftlichen Arbeitens\n\nWas Sie nicht brauchen, sind besondere Mathe- oder Statistik-Vorkenntnisse.\n\n1.1.5 Ãœberblick Ã¼ber das Buch\nAbb. AbbildungÂ 1.3 gibt einen Ãœberblick Ã¼ber den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen, zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Grundlagen des Modellieren]\n      direction TB\n      M1[Punktmodelle] --&gt; Vis[Verbildlichen]\n      Vis --&gt; U[Ungewissheit]\n\n    end\n    subgraph N[Geradenmodelle]\n      direction TB\n      G1[Geradenmodelle 1] --&gt; G2[Geradenmodelle 2]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\nAbbildungÂ 1.3: Ãœberblick Ã¼ber den Inhalt und Verlauf des Buches\n\n\n\n\n\nDas Diagramm zeigt auch den Ablauf einer typischen Datenanalyse. NatÃ¼rlich kann man sich auch andere sinnvolle Darstellungen dieses Ablaufs vorstellen.\n\n\n\n1.1.6 PDF-Version\nSie kÃ¶nnen die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#lernhilfen",
    "href": "005-orga.html#lernhilfen",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nAuf der Webseite â€œDatenwerkâ€ wird eine groÃŸe Zahl an Aufgaben bereitgestellt.1\n\n\n\nAm Ende jedes Kapitels dieses Buchs finden Sie eine Auswahl an Aufgabennamen, die Sie im Datenwerk finden. Beachten Sie die Hinweise zu den Aufgaben.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuÃŸerdem tauchen im Verlauf jedes Kapitels Ãœbungsaufgaben an verschiedenen Stellen auf, so dass Sie den jeweiligen Stoff sofort Ã¼ben und Ihr VerstÃ¤ndnis prÃ¼fen kÃ¶nnen.   Das Buch verweist auf eine Reihe von Online-Materialien. So ist der gesamte R-Code fÃ¼r dieses Buch auf dem Github-Repo dieses Buches zu finden: https://github.com/sebastiansauer/statistik1.\n\n\n\nSchauen Sie sich mal den YouTube-Kanal sebastiansauerstatistics an und dann z.B. die Playlist â€œRâ€. Dort finden Sie Videos zum Thema dieses Buches.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Gleichungen werden zum Teil Farben verwendet, diese haben folgende Bedeutung:\n\nY bzw. AbhÃ¤ngige Variable\nX bzw. UnabhÃ¤ngige Variable\ne bzw. Fehlerterm\nb0 bzw. Achsenabschnitt\nb1 bzw. Steigung (Regressionsgewicht)\nm bzw. y-Dach bzw. Modellwert\n\nIn Diagrammen werden auch Farben verwendet, die haben allerdings keine feste Bedeutung, sondern dienen der Ãœbersichtlichkeit.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#software",
    "href": "005-orga.html#software",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.3 Software",
    "text": "1.3 Software\n\n1.3.1 R\nSie benÃ¶tigen R, RStudio und einige R-Pakete fÃ¼r diesen Kurs. Dieses Buch enthÃ¤lt â€œmittelâ€ viel R. Auf fortgeschrittene R-Techniken wurde aber komplett verzichtet. Dem einen AnfÃ¤nger oder der anderen AnfÃ¤ngerin mag es dennoch als â€œviel Codeâ€ erscheinen. Es wÃ¤re ja auch mÃ¶glich gewesen, auf R zu verzichten und stattdessen eine â€œKlick-Softwareâ€ zu verwenden. JASP oder Jamovi sind Beispiele fÃ¼r tolle Software aus dieser Kategorie. Ich glaube aber, der Verzicht auf eine Skriptsprache (R) wÃ¤re ein schlechter Dienst an den Studentis. Mit Blick auf eine â€œHigh-Tech-Zukunftâ€ sollte man zumindest mit etwas Computer-Code vertraut sein. Auf Computercode zu verzichten, erschiene mir daher fahrlÃ¤ssig fÃ¼r die â€œZukunftsfestigkeitâ€ der Ausbildung. Sie finden den R-Code fÃ¼r jedes Kapitel im Github-Repositorium dieses Buches.2\n\n\nDas sind Sie nach der LektÃ¼re dieses Buchs (Horst, 2024)\n\n\n1.3.2 R-Pakete\nIn den meisten Kapiteln dieses Buches benÃ¶tigen Sie die folgenden zwei R-Pakete: tidyverse und easystats.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nWeitere Hinweise zu R finden Sie in Kapitel 3.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#benÃ¶tigte-daten",
    "href": "005-orga.html#benÃ¶tigte-daten",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.4 BenÃ¶tigte Daten",
    "text": "1.4 BenÃ¶tigte Daten\nIn den meisten Kapiteln dieses Buches analysieren wir Daten; meist ist das der Datensatz mariokart, wo Auktionen zu diesem Computerspiel in einigen Merkmalen aufgefÃ¼hrt sind. Sie kÃ¶nnen den Datensatz auf folgende Art importieren, s. ListingÂ 1.1. Keine Sorge, wenn Ihnen im Moment nicht klar ist, was Sie mit dem R-Code anfangen sollen. Sie lernen das NÃ¶tige in Kapitel 3.\n\n\n\nListingÂ 1.1: Mariokart-Datensatz importieren\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\n\nmariokart &lt;- read.csv(mariokart_path)\n\n\n\n\nEin Data-Dictionary (Codebook) finden Sie in Anhang B.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#hinweise",
    "href": "005-orga.html#hinweise",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.5 Hinweise",
    "text": "1.5 Hinweise\n\nYouTube-Playlists zu Statistik\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird id.R. nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine PrÃ¼fung in diesem Modul ist in jedem Semester mÃ¶glich.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#prÃ¼fung",
    "href": "005-orga.html#prÃ¼fung",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.6 PrÃ¼fung",
    "text": "1.6 PrÃ¼fung\nDie folgenden Hinweise sind dem Hinweisbuch des Autors entnommen. Lesen Sie auch die Ã¼brigen Hinweise dort.3\n\n1.6.1 PrÃ¼fungleistung\nDie PrÃ¼fungsleistung besteht aus einer Hauptleistung (keine Bonusleistung).\nDie Hauptleistung besteht aus einer Projektarbeit im Form eines Prognosewettbewerbs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.6.2 Zum Prognosewettbewerb\nIm Hinweisbuch finden Sie Hinweise zur PrÃ¼fung.4\n\n1.6.3 PrÃ¼fungsrelevanter Stoff\nBeachten Sie die Hinweise zum prÃ¼fungsrelevanten Stoff.5\n\n1.6.4 Wie kann ich mich auf die PrÃ¼fung vorbereiten?\nHier finden Sie Hinweise zur PrÃ¼fungsvorbereitung.6\n\n1.6.5 Allgemeine PrÃ¼fungshinweise\nDie folgenden Hinweise gelten grundsÃ¤tzlich, d.\\(\\,\\)h. soweit nicht anders in der jeweiligen PrÃ¼fung bzw. der jeweiligen Aufgabe angegeben. Nichtbeachten von PrÃ¼fungshinweisen kann zu Punkteabzug oder Nichtbestehen fÃ¼hren. Lesen Sie sich diese Hinweise im eigenen Interesse sorgfÃ¤ltig durch. Die Kenntnis dieser Hinweise wird bei der Begutachtung vorausgesetzt.\nFÃ¼r eine einfachere Kommunikation kontaktieren Sie mich per E-Mail bei Fragen, die nur Sie betreffen. Bei Fragen von allgemeinem Interesse (z.\\(\\,\\)B. â€œBis wann mÃ¼ssen wir die Arbeit abgeben?â€) nutzen Sie bitte (sofern verfÃ¼gbar) das Kursforum, damit die Kommilitonen auch von dem Austausch profitieren.\nBeachten Sie die allgemeinen PrÃ¼fungshinweise.7\n\n1.6.6 Lieblingsfehler\nVermeiden Sie diese hÃ¤ufigen Fehler im Prognosewettbewerb.8\n\n1.6.7 Fazit\nğŸ€ğŸ€ğŸ€VIEL ERFOLG!ğŸ€ğŸ€ğŸ€",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#sec-greek",
    "href": "005-orga.html#sec-greek",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.7 Griechische Buchstaben",
    "text": "1.7 Griechische Buchstaben\nIn diesem Buch werden ein paar (wenige) griechische Buchstaben verwendet, die in der Statistik Ã¼blich sind. HÃ¤ufig werden griechische Buchstaben verwendet, um eine Grundgesamtheit (Population) zu beschreiben (die meistens unbekannt ist). Lateinische (â€œnormaleâ€) Buchstaben werden demgegenÃ¼ber verwendet, um eine Stichprobe (Datensatz, vorliegende Daten) zu beschreiben. TabelleÂ 1.1 stellt diese Buchstaben zusammen mit ihrer Aussprache und Bedeutung vor.\n\n\nTabelleÂ 1.1: Griechische Buchstaben, die in diesem Buch verwendet werden\n\n\n\nZeichen\nAussprache\nBuchstabe\nBedeutung in der Statistik\n\n\n\n\\(\\beta\\)\nbeta\nb\nRegressionskoeffizent\n\n\n\\(\\mu\\)\nmÃ¼\nm\nMittelwert\n\n\n\\(\\sigma\\)\nsigma\ns\nStreuung\n\n\n\\(\\Sigma\\)\nSigma\nS\nSummenzeichen\n\n\n\\(\\rho\\)\nrho\nr\nKorrelation (nach Pearson)\n\n\n\n\n\n\nMehr griechische Buchstaben finden sich z.\\(\\,\\)B. in Wikipedia.9",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#zitation",
    "href": "005-orga.html#zitation",
    "title": "\n1Â  Organisatorisches\n",
    "section": "\n1.8 Zitation",
    "text": "1.8 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2024). Statistik1. https://statistik1.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren kÃ¶nnen:\n@book{sauer_statistik1,\n    title = {Statistik1},\n    rights = {CC-BY-NC},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2024},\n}\nHier ist die DOI:\n\n\nDOI\n\n\n\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024). Yoda Jealous Girl Friend Meme [Artwork]. https://imgflip.com\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive Theory to Statistics Instruction. The American Statistician, 54(3), 196â€“206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nSauer, S. (2017). Dataset â€™Predictors of Performance in Stats Testâ€™ [Data set]. Open Science Framework. https://doi.org/10.17605/OSF.IO/SJHUY\n\n\nWorld Economic Forum. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#footnotes",
    "href": "005-orga.html#footnotes",
    "title": "\n1Â  Organisatorisches\n",
    "section": "",
    "text": "https://sebastiansauer.github.io/Datenwerk/â†©ï¸\nhttps://github.com/sebastiansauer/statistik1/tree/main/R-code-for-all-chaptersâ†©ï¸\nhttps://hinweisbuch.netlify.app/â†©ï¸\nhttps://hinweisbuch.netlify.app/080-hinweise-pruefung-prognosewettbewerb-frameâ†©ï¸\nhttps://hinweisbuch.netlify.app/010-hinweise-pruefung-allgemein-frame#pr%C3%BCfungsrelevanter-stoffâ†©ï¸\nhttps://hinweisbuch.netlify.app/150-hinweise-pruefungsvorbereitung-frameâ†©ï¸\nhttps://hinweisbuch.netlify.app/010-hinweise-pruefung-allgemein-frameâ†©ï¸\nhttps://hinweisbuch.netlify.app/170-beispiele-fehler-prognosewettbewerb-frameâ†©ï¸\nhttps://de.wikipedia.org/wiki/Griechisches_Alphabetâ†©ï¸",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html",
    "href": "010-rahmen.html",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "2.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nAbbildungÂ 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Ãœberblick Ã¼ber das Thema dieses Kapitels im Kontext aller Kapitel. AbbildungÂ 2.1 zeigt, dass unser Vorgehen in diesem Buch einem FlieÃŸband gleicht: Schritt fÃ¼r Schritt, in der richtigen Reihenfolge, vom Anfang bis Ende, erarbeiten wir unser â€œDatenproduktâ€.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#einstieg",
    "href": "010-rahmen.html#einstieg",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "AbbildungÂ 2.1: Datenanalyse als eine Abfolge am FlieÃŸband (Horst, 2024)\n\n\n\n2.1.1 Lernziele\n\nSie kÃ¶nnen eine Definition von Statistik wiedergeben.\nSie kÃ¶nnen eine Definition von Daten wiedergeben.\nSie kÃ¶nnen den Begriff Tidy-Daten erlÃ¤utern.\nSie kÃ¶nnen Beispiele fÃ¼r verschiedene Skalenniveaus nennen.\n\n2.1.2 Einstieg\n\nÃœbungsaufgabe 2.1 (Hallo, Statistik) Gehen Sie in Kleingruppen zusammen (3-4 Personen). Stellen Sie sich anhand der Schlagworte einander vor:\n\n(wissenschaftliche) Interessen\nErwartung an diesen Kurs\nVorkenntnisse in Statistik (und in R)\n\nWenn Sie wollen: FÃ¼gen Sie einen Fun Fact hinzu. \\(\\square\\)\n\n\nÃœbungsaufgabe 2.2 (Frag jetzt) Die Lehrkraft stellt Ihnen ein Forum zur VerfÃ¼gung, auf dem Sie anonym Fragen an die Lehrkraft richten kÃ¶nnen (z.\\(\\,\\)B. auf frag.jetzt).\nStellen Sie dort Ihre Fragen ein; voten Sie die Fragen Ihrer Kommilitonis auf oder ab. Die Lehrkraft beantwortet dann die Fragen mit den meisten Upvotes. \\(\\square\\)\n\n\n2.1.3 Erfolgsgrezept\nDrei Faktoren beeinflussen Ihren Lernerfolg: 1) Ihre Lehrkraft, 2) Ihre Mitarbeit im Unterricht und 3) Ihr Eigenstudium zuhause (Vor- bzw. Nachbereitung des Unterrichts), s. AbbildungÂ 2.2.\n\n\n\n\n\nflowchart TD\n  subgraph Lehrkraft\n    F[\"ğŸ”¥\"]\n  end\n  subgraph A[Mitarbeit]\n    C[\"ğŸªµ\"]\n  end\n  subgraph E[Eigenstudium]\n    D[\"ğŸŒ³\"] \n  end  \n\n\n\n\nAbbildungÂ 2.2: Ihr Lernerfolg besteht aus drei Komponenten: Der Lehrkraft, Ihrer Mitarbeit im Unterricht und Ihrem Eigenstudium, also Ihrer Vor- bzw. Nachbereitung zuhause.\n\n\n\n\nEine gute Lehrkraft ist wie der Funke, der eine (Lern-)Flamme entzÃ¼ndet. Aber es braucht Brennmaterial, einen Holzscheit, das ist Ihre Konzentration im Unterricht. Ein Holzscheit allein reicht nicht aus; es braucht mehr Brennmaterial, um das Feuer am Leben zu erhalten: Ihr Eigenstudium, das stetige, selbstÃ¤ndige BeschÃ¤ftigen mit der Materie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "href": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.2 Was ist Statistik und wozu ist sie gut?",
    "text": "2.2 Was ist Statistik und wozu ist sie gut?\nDie Aufgabe von Statistik ist es, Modelle zu bilden durch Zusammenfassen von Daten. Modelle machen es uns einfacher, schwierige Sachverhalte zu verstehen. Zentral ist dabei die Analyse von VariabilitÃ¤t der Daten. Daten kommen in verschiedenen Varianten vor, typischerweise in Tabellenform, mÃ¶glichst im sog. Tidy-Format.\nIn diesem Buch werden die Begriffe Statistik, Datenanalyse und Data Science synonym verwendet.\n\nÃœbungsaufgabe 2.3 (Nutzen von Statistik) Fragen Sie einen Chatbot (wie ChatGPT), was der Nutzen von Statistik ist. Diskutieren Sie die Antwort. \\(\\square\\)\n\nDas versteht ChatGPT unter Statistik:\n\nğŸ§‘â€ğŸ“ Was ist Statistik? Bitte definiere verstÃ¤ndlich.\n\n\nğŸ¤– Statistik ist eine Wissenschaft, die sich mit der Sammlung, Analyse, Interpretation, PrÃ¤sentation und Ãœbertragung von Daten beschÃ¤ftigt. Ziel ist es, Muster und Trends in den Daten zu erkennen und verlÃ¤ssliche Schlussfolgerungen Ã¼ber eine grÃ¶ÃŸere Gruppe (z.\\(\\,\\)B. BevÃ¶lkerung) auf der Basis einer Stichprobe (Teilmenge) zu treffen. Die Statistik hilft uns bei der Beantwortung von Fragen, indem sie uns dabei hilft, die Unsicherheit in den Daten zu messen und zu verstehen1.\n\nGar nicht schlecht! Es gibt mehrere Definition von Statistik. DefinitionÂ 2.1 zeigt eine.\n\nDefinition 2.1 (Statistik) Statistik fasst Werte zusammen, quantifiziert deren Unterschiedlichkeit und beschreibt die Ungewissheit unserer SchlÃ¼sse (Kaplan, 2009; Poldrack, 2023) . \\(\\square\\)\n\nBetrachten wir die drei BestimmungsstÃ¼cke einer Definition von Statistik genauer: 1. Daten zusammenfassen, 2. Unterschiedlichkeit quantifizieren und 3. Ungewissheit beschreiben.\n\n2.2.1 Daten zusammenfassen\nAbbildungÂ 2.3 verdeutlicht das Prinzip des Zusammenfassens von Daten. Einfach ausgedrÃ¼ckt: Eine Menge von Zahlen wird zu einer einzelnen Zahl â€œzusammengedampftâ€. Eine einzelne Zahl ist wesentlich besser zu verstehen als eine groÃŸe Menge von Zahlen. Bei vielen Zahlen wÃ¼rde man den Ãœberblick verlieren.\n\n\n\n\n\n\n\n\n\n\n(a) Zusammengefasst zu einem Punkt\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Zusammengefasst zu einer Geraden\n\n\n\n\n\n\nAbbildungÂ 2.3: Daten zusammenfassen. (a) Zusammenfassen einer Variable zu einem Punktwert, hier zum Mittelwert. (b) Zusammenfassen zweier Variablen zu einer Geraden.\n\n\n\n\n2.2.2 Unterschiedlichkeit quantifizieren\nEine allgegenwÃ¤rtige Tatsache ist, dass die Dinge der Welt sich unterscheiden, etwa, dass Tiere einer Gattung sich in ihrer GrÃ¶ÃŸe unterscheiden. So sind nicht alle Menschen gleich groÃŸ, nicht alle BÃ¼cher gleich lang oder nicht alle Tage gleich warm. Daher ist eine zentrale Idee von statistischen Analysen, die Unterschiedlichkeit der Dinge zu beschreiben, prÃ¤ziser gesagt: die Variation zu quantifizieren. Betrachten wir dazu das Beispiel in AbbildungÂ 2.4. Im Team der Basketballer gibt es (vergleichsweise) geringe Variation in der KÃ¶rpergrÃ¶ÃŸe â€“ alle sind groÃŸ, Ã¤hnlich groÃŸ. Im Team der Schachspieler gibt es (vergleichsweise) hohe Variation: Einige Personen sind groÃŸ, andere klein.\n\n\n\n\n\n\n\nAbbildungÂ 2.4: Wenig Variation in der KÃ¶rpergrÃ¶ÃŸe bei den Basketballern. Alles lange Kerle. Viel Variation bei den Schachspielern: Manche sind klein, andere groÃŸ. Die vertikalen, vom Mittelwert (MW) abgehenenden Balken zeigen die Abweichungen der jeweiligen KÃ¶rpergrÃ¶ÃŸe zum Mittelwert. Hinweis: Die Y-Achse startet nicht bei Null.\n\n\n\n\n\nEine Abweichung (auch Residuum) genannt, zeigt die Differenz von Mittelwert und dem Wert der KÃ¶rpergrÃ¶ÃŸe bei der jeweiligen Person. Nehmen wir an, wir sprechen allgemein von einer Person \\(i\\). Wir bezeichnen das Merkmal KÃ¶rpergrÃ¶ÃŸe mit \\(X\\) und den Mittelwert der KÃ¶rpergrÃ¶ÃŸe mit als \\(\\bar{x}\\) (â€œx querâ€). Dann kÃ¶nnen wir das Residuum der \\(i\\)-ten Person mit \\(r_i\\) bezeichnen und entsprechend definieren.\n\nDefinition 2.2 (Residuum) Das Residuum des Merkmals \\(X\\) der \\(i\\)-ten Beobachtung ist definiert als die Differenz vom Wert \\(x_i\\) und einem Referenzwert, etwa dem Mittelwert (\\(\\bar{x}\\)), d.\\(\\,\\)h.: \\(r_i = x_i - \\bar{x}.\\square\\)\n\n\n2.2.3 Ungewissheit beschreiben\n\nBeispiel 2.1 Anna hat eine Statistik-Klausur geschrieben. Sie hat keine Ahnung, ob sie bestehen wird. Berta hingegen ist sich sehr sicher, dass sie bestanden hat. Die beiden Studentinnen unterscheiden sich also stark in der Ungewissheit hinsichtlich ihrer EinschÃ¤tzung zum Klausurerfolg, s. AbbildungÂ 2.5. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Was Anna denkt\n\n\n\n\n\n\n\n\n\n(b) Was Berta denkt\n\n\n\n\n\n\nAbbildungÂ 2.5: Die Ungewissheit, die wir Ereignissen zuschreiben, kann variieren. Anna ist sich maximal unsicher, ob sie besteht. Berta ist sich ziemlich sicher, dass sie besteht.\n\n\n\nBeispiel 2.2 Sagen wir, Sie haben sich mit einem zwielichten Statistiker auf ein GlÃ¼cksspiel eingelassen: Er wirft eine MÃ¼nze 10 Mal; bei Kopf gewinnt er, bei Zahl Sie. Nun hat der Statistiker von den 10 WÃ¼rfen 8 Mal gewonnen. Sie sind sich ziemlich sicher, dass dieser Typ Sie Ã¼ber den Tisch gezogen hat. Allerdings sind Sie nicht ganz sicher, und beweisen kÃ¶nnen Sie es leider auch nicht. Der zwielichte Statistiker ist sich ganz sicher: Er weiÃŸ, dass er Sie Ã¼ber den Tisch gezogen hat. Er weiÃŸ, dass seine MÃ¼nze gezinkt ist. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "href": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.3 Was ist das Ziel Ihrer Analyse?",
    "text": "2.3 Was ist das Ziel Ihrer Analyse?\n\n2.3.1 Arten von Zielen\nStatistische Analysen kÃ¶nnen drei Arten von Zielen verfolgen, s. AbbildungÂ 2.6.\n\n\n\n\n\ngraph TD\n  subgraph Ziele\n    A[beschreiben]\n    B[vorhersagen]\n    C[erklÃ¤ren]\n  end\n\n\n\n\nAbbildungÂ 2.6: Zielarten einer Datenanalyse\n\n\n\n\n\nBeispiel 2.3 Â \n\n\nBeschreiben: Wie groÃŸ ist der Gender-Paygap in der Branche X im Zeitraum Y?\n\nVorhersagen: Wenn ich 100 Stunden auf die Statistikklausur lerne, welche Note kann ich dann erwarten?\n\nErklÃ¤ren: Wie viel bringt mir das Lernen auf die Statistikklausur? \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 2.4 Benennen Sie Beispiele fÃ¼r die die drei Zielarten von Datenanalysen! \\(\\square\\)\n\n\n2.3.2 Forschungsfrage\nEine Forschungsfrage ist die Leitfrage Ihrer Analyse. Sie definiert, was Sie herausfinden wollen. HÃ¤ufig fragen Forschungsfragen: â€œHat X einen (kausalen) Einfluss auf Y?â€\nEine Forschungsfrage weist hÃ¤ufig folgende Struktur auf, s. AbbildungÂ 2.7.\n\n\n\n\n\ngraph LR\n    I[Input bzw. X] --&gt; O[Output bzw. Y]\n\n\n\n\nAbbildungÂ 2.7: Struktur eine Forschungsfrage\n\n\n\n\n\nBeispiel 2.4 (Forschungsfragen) Â \n\nHat Lernen (X) einen Einfluss auf den PrÃ¼fungserfolg (Y)?\n\n\nVerringert Joggen (X) die Menge des HÃ¼ftgolds (Y)?\n\n\nUm welchen Betrag erhÃ¶ht sich der Umsatz (Y), wenn wir 1000 Euro mehr fÃ¼r Werbung ausgeben? (X)\n\n\nVerringert intensive Handynutzung (X) die KonzentrationsfÃ¤higkeit (Y)? \\(\\square\\)\n\n\n\nBeispiel 2.5 (Forschungsfrage: Produktmerkmale und VerkaufserlÃ¶s) Nach dem Studium haben Sie bei einem groÃŸen Online-Auktionshaus angeheuert. Da Sie angaben, sich im Studium intensiv, naja, ein bisschen, mit Statistik beschÃ¤ftigt zu haben, hat man Sie in die Abteilung fÃ¼r Forschung und Entwicklung (F&E) gesteckt. Heute ist es Ihre Aufgabe, Auktionen zur Spielekonsole Wii zu analysieren, genauer gesagt geht es um das Spiel Mariokart. Ihre Forschungsfrage lautet:\n\nWelche Produktmerkmale stehen mit einem hohen VerkaufserlÃ¶s in Zusammenhang? \\(\\square\\)\n\n\n\n2.3.3 Aus der Forschung: Smartphone-Brain-Drain ğŸ“±ğŸ§ ğŸš«\nWard et al. (2017) untersuchten die Forschungsfrage, ob die bloÃŸe Gegenwart eines Handys (z.\\(\\,\\)B. wenn es vor Ihnen auf dem Tisch liegt) dazu fÃ¼hrt, dass man abgelenkt wird und daher schlechtere kognitive Leistungen zeigt.\nDie Autoren formulieren ihre Hypothese leider nicht explizit, aber sie lÃ¤sst sich implizit aus dem Text herauslesen (S. 142):\n\nFirst, smartphones may redirect the orientation of conscious attention away from the focal task and toward thoughts or behaviors associated with oneâ€™s phone. Prior research provides ample evidence that â€¦ this digital distraction adversely affects both performance â€¦ and enjoyment.\n\nSpÃ¤ter prÃ¤zisieren sie ihre Hypothese (S. 143):\n\nIn two experiments, we test the hypothesis that the mere presence of oneâ€™s own smartphone reduces available cognitive capacity.\n\nDie Ergebnisse unterstÃ¼tzen ihre Hypothese, s. AbbildungÂ 2.8. Die kognitive Leistung (Y-Achse) ist sowohl in der KapazitÃ¤t des ArbeitsgedÃ¤chtnisses als auch in der fluiden Intelligenz geringer, wenn das Handy auf dem Schreibtisch liegt, als wenn es nicht im Raum ist, so die Studie. Am besten ist die kognitive Leistung, wenn das Handy nicht im Raum ist. \\(\\square\\)\n\n\n\n\n\nAbbildungÂ 2.8: Handy in Sichtweite verringert die kognitiven Ressourcen, Ward et al. (2017), S. 145\n\n\n\n\n\n\nÃœbungsaufgabe 2.5 Fragen Sie einen Bot (z.\\(\\,\\)B. ChatGPT) zum Stand der Forschung hinsichtlich der Braindrain-Forschungsfrage. Diskutieren Sie die Antwort, auch in ihren Grenzen. \\(\\square\\)\n\n\n2.3.4 Der Prozess der Datenanalyse\nDatenanalyse ist eine Art des ProblemlÃ¶sens. Anders gesagt, man macht es nicht zum SpaÃŸ (jedenfalls nicht alle von uns), sondern um ein Ziel zu erreichen, also ein Problem zu lÃ¶sen. Daher analysiert man nicht gleich zu Anfang wild drauf los. ZunÃ¤chst 1) klÃ¤rt man das Problem und das Ziel. Dann 2) plant man das Vorgehen, z.\\(\\,\\)B. welche Daten man erheben mÃ¶chte. Als nÃ¤chstes 3) erhebt man die Daten und bereitet sie auf. SchlieÃŸlich kann man sie 4) endlich analysieren. Aber Daten sprechen nicht fÃ¼r sich, man muss sie 5) interpretieren und SchlÃ¼sse daraus ziehen. Dazu gehÃ¶rt auch, dass man die SchwÃ¤chen der eigenen Analyse kritisch beleuchtet, vgl. AbbildungÂ 2.9. Diesen Ablauf nennt man auch das PPDAC-Modell (MacKay & Oldford, 2000):\n\nP: Problem (Problem und Ziel und Sachgegenstand verstehen)\nP: Plan (Vorgehen planen)\nD: Data (Daten erheben und aufbereiten)\nA: Analysis (Daten analysieren)\nC: Conclusions (Schlussfolgerungen ziehen)\n\n\n\n\n\n\ngraph LR\n    Problem --&gt; Plan --&gt; Data --&gt; Analysis --&gt; Conclusions --&gt; Problem\n\n\n\n\nAbbildungÂ 2.9: Datenanalyse als Prozess: Das PPDAC-Modell\n\n\n\n\nAus einer weniger abstrakten, eher praktischen Perspektive kann man von der Abfolge der â€œsieben Schritten der Datenanalyseâ€ sprechen, s. AbbildungÂ 2.10.\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Grundlagen des Modellieren]\n      direction TB\n      M1[Punktmodelle] --&gt; Vis[Verbildlichen]\n      Vis --&gt; U[Ungewissheit]\n\n    end\n    subgraph N[Modellieren]\n      direction TB\n      G1[Modelle] --&gt; G2[Ungewissheit]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\nAbbildungÂ 2.10: Datenanalyse als Prozess: Die sieben Schritte der Datenanalyse",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-sind-daten",
    "href": "010-rahmen.html#was-sind-daten",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.4 Was sind Daten?",
    "text": "2.4 Was sind Daten?\n\nDefinition 2.3 (Daten) Daten sind eine geordnete Folge von Zeichen. \\(\\square\\)\n\nTabellen sind oft das geeignete Format fÃ¼r die Untersuchung von Daten. TabelleÂ 2.1 zeigt ein Beispiel fÃ¼r Daten. Die erste Spalte id ist nur eine laufende Nummer. Sie dient dazu, die einzelnen Beobachtungen (hier Studierenden) identifizieren zu kÃ¶nnen und birgt ansonsten keine Information. Beispiele fÃ¼r ID-Variablen sind Matrikelnummer, Personalausweisnummern oder Bestellnummern.\n\n\n\nTabelleÂ 2.1: So sehen Daten in Form einer Tabelle aus.\n\n\n\n\nid\nname\nnote\n\n\n\n1\nAnna\n1.3\n\n\n2\nBerta\n2.3\n\n\n3\nCarla\n3.0\n\n\n\n\n\n\n\n\n\nBeispiel 2.6 (Daten zur Forschungsfrage 2) Hier ist ein Auszug der Daten zur Tabelle mariokart, s. TabelleÂ 2.2.\n\n\n\nTabelleÂ 2.2: Auszug aus der Tabelle mariokart\n\n\n\n\nn_bids\nstart_pr\ntotal_pr\nwheels\n\n\n\n20\n0.99\n52\n1\n\n\n13\n0.99\n37\n1\n\n\n16\n0.99\n46\n1\n\n\n18\n0.99\n44\n1\n\n\n20\n0.01\n71\n2\n\n\n19\n0.99\n45\n0\n\n\n\n\n\n\n\n\nEine ErklÃ¤rung (Data-Dictionary) aller Variablen des Datensatzes mariokart findet sich Auf openintro.org2 oder im Anhang, s. @#sec-data-dict. \\(\\square\\)\n\n\nDefinition 2.4 (Data-Dictionary) Eine ErklÃ¤rung, was die Variablen (Spalten) einer Datentabelle bedeuten, nennt man Codebook or Data-Dictionary. \\(\\square\\)\n\nIn den Spalten einer Tabelle stehen Merkmale (Variablen) von den Dingen, die untersucht werden, z.\\(\\,\\)B. Patienten, Kunden oder Videospiele. Die untersuchten Dinge nennt man Beobachtungseinheiten. Die Beobachtungseinheiten stehen in den Zeilen einer Tabelle. Eine Variable kann man sich als einen BehÃ¤lter vorstellen, auf dem mit einem Stift geschrieben steht, welcher Inhalt darin ist, s. AbbildungÂ 2.11.\n\nDefinition 2.5 (Variable) Eine Variable ist ein Platzhalter fÃ¼r ein Merkmal, das verschiedene AusprÃ¤gungen annehmen kann. \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 2.11: Wir definieren eine Variable â€œtempâ€ mit dem Inhalt â€œ9â€.\n\n\n\nDefinition 2.6 (Beobachtungseinheit) Beobachtungseinheiten sind die Dinge, die wir untersuchen (beobachten). Beobachtungseinheiten sind die TrÃ¤ger von Variablen. \\(\\square\\)\n\nTabelleÂ 2.1 enthÃ¤lt drei Variablen (id, Name und Note) und Note) und drei Beobachtungseinheiten (Anna, Berta und Carla). Beobachtungseinheiten werden auch kurz als Beobachtungen bezeichnet.\n\nDefinition 2.7 (Wert) Ein Wert ist der Inhalt einer Variablen. \\(\\square\\)\n\nIn AbbildungÂ 2.11 ist der Wert von temp 9. In TabelleÂ 2.1 nimmt die Variable name die Werte Anna, Berta und Carla an.\n\nDefinition 2.8 (AusprÃ¤gung) Als AusprÃ¤gungen bezeichnet man die verschiedenen Werte einer Variablen. \\(\\square\\)\n\n\nBeispiel 2.7 In einer Studie wurden zehn Probanden untersucht. Die Variable geschlecht dokumentiert die Geschlechter der Personen:\n\ngeschlecht &lt;- c(\"Mann\", \"Frau\", \"Frau\", \"Frau\", \"Mann\",\n                \"Frau\", \"Mann\", \"Mann\", \"divers\", \"Frau\")\ngeschlecht\n##  [1] \"Mann\"   \"Frau\"   \"Frau\"   \"Frau\"   \"Mann\"   \"Frau\"   \"Mann\"   \"Mann\"  \n##  [9] \"divers\" \"Frau\"\n\nDie Variable enthÃ¤lt drei AusprÃ¤gungen: divers, Frau, Mann. \\(\\square\\)\n\n\n\n\n\n\n\nTipp\n\n\n\nGerade haben Sie etwas Computer-Syntax gesehen, genauer gesagt, Befehle aus der Programmiersprache R. Bisher haben wir diese Befehle nicht kennengelernt. Sie verstehen Sie vermutlich (nicht ganz). Ignorieren Sie diese Befehle einfach erst einmal.\n\n\n\n2.4.1 Tidy Data\n\nDefinition 2.9 (Tidy Data) Unter Tidy Data (tidy data, â€œNormalformâ€) versteht man eine Tabelle, in der jede Zeile eine Beobachtungseinheit darstellt, jede Spalte eine Variable und jede Zelle der Tabelle einen Wert. (ZusÃ¤tzlich ist noch eine â€œKopfzeileâ€ erlaubt, in der die Namen der Variablen stehen.) \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 2.12: Tidy-Data-Sinnbild (Wickham, 2023)\n\n\nTabelleÂ 2.1 ist ein Beispiel fÃ¼r Tidy-Data. AbbildungÂ 2.12 zeigt ein Sinnbild fÃ¼r Tidy-Data (Wickham & Grolemund, 2018). FÃ¼r eine statistische Analyse ist es oft sinnvoll, dass die Daten im Tidy-Format vorliegen. Der Vorteil des Tidy-Formats ist es, dass man weiÃŸ, wie die Daten aufgebaut sind. AuÃŸerdem kÃ¶nnen Statistikprogramme oft mit dieser Form am besten umgehen, s. AbbildungÂ 2.13.\n\n\n\n\n\nAbbildungÂ 2.13: Immer schÃ¶n Ordnung halten â€¦ (Horst, 2023)\n\n\n\nBeispiel 2.8 Ihre Firma produziert zwei Produkte: HÃ¤mmer und NÃ¤gel. Im Folgenden sind zwei Tabellen dargestellt, die die gleichen Informationen darstellen: den Umsatz Ihrer Firma fÃ¼r zwei Jahre. Einmal ist dazu eine Nicht-Tidy-Tabelle (TabelleÂ 2.3; Breitformat) und einmal eine Tidy-Tabelle (TabelleÂ 2.4; Langformat) verwendet. \\(\\square\\)\n\n\n\n\nTabelleÂ 2.3: Beispiel fÃ¼r eine NICHT-Tidy-Tabelle (Breitformat)\n\n\n\n\nProdukt\nUmsatz_2021\nUmsatz_2022\nUmsatz_2023\n\n\n\nHÃ¤mmer\n10\n11\n12\n\n\nNÃ¤gel\n15\n10\n5\n\n\n\n\n\n\n\n\n\n\n\nTabelleÂ 2.4: Beispiel fÃ¼r eine Tidy-Tabelle (Langformat)\n\n\n\n\nProdukt\nUmsatz_2021\nUmsatz_2022\nUmsatz_2023\n\n\n\nHÃ¤mmer\n10\n11\n12\n\n\nNÃ¤gel\n15\n10\n5\n\n\n\n\n\n\n\n\n\nÃœbungsaufgabe 2.6 Suchen Sie ein Beispiel fÃ¼r eine Konfiguration einer Tabelle im Lang- vs.Â Breitformat. \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Wozu braucht man Tidy Data?\n\n\nğŸ‘©â€ğŸ« In vielen Software-Programmen der Datenanalyse weiÃŸt man z.\\(\\,\\)B. der X- oder Y-Variable eine Spalte einer Tabelle zu. MÃ¶chte man etwa die VerÃ¤nderung des Umsatzes im Verlauf der Jahre visualisieren oder analysieren, so braucht es die Spalten â€˜Jahrâ€™ und â€˜Umsatzâ€™, also ein Tidy-Format, TabelleÂ 2.3 bzw. TabelleÂ 2.4.\n\nAbbildungÂ 2.14 stellt auf Basis einer â€œTidy-Tabelleâ€ (TabelleÂ 2.4) ein Diagramm dar. Ohne Tidy-Daten wÃ¤re dieses Diagramm nicht (so einfach) zu erstellen gewesen.\n\n\n\n\n\n\n\nAbbildungÂ 2.14: Beispiel fÃ¼r eine Visualisierung auf Basis einer Tidy-Tabelle, vgl. TabelleÂ 2.4\n\n\n\n\n\n2.4.2 Je mehr, desto besser (?)\nWas Daten betrifft, kÃ¶nnte man behaupten: â€œViel hilft vielâ€ oder â€œJe mehr, desto besserâ€. NatÃ¼rlich unter sonst gleichen UmstÃ¤nden.3 Viel DatenmÃ¼ll ist natÃ¼rlich nicht besser als ein paar knappe, wasserdichte Fakten!\n\nBeispiel 2.9 Um Ihre eigene LehraktivitÃ¤t zu organisieren, wollen Sie sich ein Bild machen, wie viel Ihre Nebensitzerinner und Nebensitzer im HÃ¶rsaal so lernen. Sie blicken nach links und fragen â€œwie viel lernst du so?â€. Sie blicken nach recht und wiederholen die Frage gerichtet an den Kommilitonen, der rechts neben Ihnen sitzt. Dann addieren Sie die zwei Zahlen (unter der Annahme, dass Sie zwei Zahlen bekommen haben), und teilen durch zwei, um den Mittelwert zu erhalten. \\(\\square\\)\n\nEin kritischer Geist kÃ¶nnte anmerken, dass Sie besser die Untersuchung nicht gemacht hÃ¤tten (auch wenn Sie, vielleicht ohne zu wollen, eine statistische Untersuchung angestellt haben). Denn bei so wenig befragten Personen ist die Ungenauigkeit Ihrer SchÃ¤tzung der typischen Lernzeit bei Studierenden einfach zu hoch. AbbildungÂ 2.15 veranschaulicht, dass man einen Mittelwert genauer schÃ¤tzen kann, wenn man auf eine grÃ¶ÃŸere Stichprobe zurÃ¼ckgreift. Das Teilbild links zeigt den Mittelwert einer Stichprobe mit \\(n=20\\) Beobachtungen. Das Teilbild rechts zeigt den Mittelwert einer Stichprobe mit \\(n=200\\) Beobachtungen (jeweils aus der gleichen Grundgesamtheit). Wie man sieht, ist im linken Teilbild die Streuung (Variation) hÃ¶her als im rechten Teilbild.\n\n\n\n\n\nAbbildungÂ 2.15: SchÃ¤tzgenauigkeit als Funktion der StichprobengrÃ¶ÃŸe: Die vertikale Linie zeigt den wahren Mittelwert. Kleinere Stichproben-Mittelwerte schanken (variieren) mehr um den Mittelwert herum als grÃ¶ÃŸere Stichproben.\n\n\nBildquelle: Karsten LÃ¼bke\n\n\n\n\n\n\nWichtig\n\n\n\nMehr Daten = genauere Ergebnisse (unter sonst gleichen UmstÃ¤nden)\n\n\n\nÃœbungsaufgabe 2.7 (Live-Experiment zum Effekt der StichprobengrÃ¶ÃŸe) In diesem Live-Experiment untersuchen wir den Effekt der StichprobengrÃ¶ÃŸe auf die Streuung des Mittelwerts in der Stichprobe. Streuen die Ergebnisse mehr in kleinen Stichproben als in groÃŸen? Probieren wir es aus!\nIn diesem Experiment werfen Sie (in kleinen Gruppen) eine MÃ¼nze (auf faire Art und Weise) und notieren das Ergebnis (Kopf oder Zahl). Uns interessiert dabei die Frage, ob die Ergebnisse bei kleinen Stichproben (\\(n=5\\) MÃ¼nzwÃ¼rfe) anders streuen als in groÃŸen Stichproben (\\(n=20\\) MÃ¼nzwÃ¼rfe).\n\n\n\nSie brauchen nur experimentierfreudige Partner (Kleingruppen mit 2-4 Personen), eine faire MÃ¼nze und dann kannâ€™s los gehen! Scannen Sie den QR-Code, um mit dem Experiment zu starten.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Daten aller Versuche kÃ¶nnen Sie hier einsehen.4 \\(\\square\\)\n\n\nBeispiel 2.10 (Dorfschulen machen die schlauesten SchÃ¼ler?!) In einer Pressemitteilung sei zu lesen, dass die besten SchÃ¼ler in den Dorfschulen zu finden seien. (Das ist eine fiktive Geschichte.) Mit etwas Recherche finden Sie heraus, dass diese Aussage auf belastbaren Daten beruht: TatsÃ¤chlich sind die Notendurchschnitte auf den kleinen Dorfschulen deutlich besser als in den groÃŸen Schulen in der Stadt. Also stimmt die Behauptung der Pressemitteilung? Die gute Landluft lÃ¤sst das Hirn wachsen? Sie recherchieren noch etwas weiter in den Daten. Dann fÃ¤llt Ihnen auf: Die schlechtesten SchÃ¼ler kommen auch aus den Dorfschulen! Eine statistische ErklÃ¤rung bietet sich an: In den Dorfschulen gibt es nur wenig Kinder und vergleichsweiseâ€š kleine Klassen â€“ die Stichproben sind also klein. Bei kleinen Stichproben gibt es viel Variation um den Mittelwert herum, s. AbbildungÂ 2.15, und zwar nach oben (guter Notenschnitt) und nach unten (schlechter Notenschnitt). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#sec-arten-variablen",
    "href": "010-rahmen.html#sec-arten-variablen",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.5 Arten von Variablen",
    "text": "2.5 Arten von Variablen\n\n2.5.1 Nach Position in der Forschungsfrage\nAngenommen, Ihre Forschungsfrage lautet:\n\nHat Lernen einen Einfluss auf den PrÃ¼fungserfolg?\n\nIn dem Fall gilt: Lernen ist die Input-Variable, X-Variable, Ursache, unabhÃ¤ngig Variable (UV). PrÃ¼fungserfolg ist die Output-Variable, Y-Variable, Wirkung, abhÃ¤ngige Variable (AV). AbbildungÂ 2.16 stellt diese beiden â€œPositionenâ€ einer Variable dar. Die erste Position ist vor dem Pfeil (X). Die zweite Position ist nach dem Pfeil (Y).\n\n\n\n\n\ngraph LR\n    X[\"Lernen&lt;br&gt;(UV, X, PrÃ¤diktor)\"] --&gt; Y[\"gute Note&lt;br&gt;(AV, Y, Kriterium)\"]\n\n\n\n\nAbbildungÂ 2.16: X und Y als synonyme Bezeichnungen fÃ¼r Input- und Output-Variablen einer Forschungsfrage\n\n\n\n\n\nÃœbungsaufgabe 2.8 Ãœberlegen Sie sich eine Forschungsfrage, die eine UV und eine AV enthÃ¤lt. Nennen Sie einer anderen Person diese Forschungsfrage und fragen Sie, was die UV und die AV ist. Bei richtiger Antwort belohnen Sie groÃŸzÃ¼gig. \\(\\square\\)\n\n\n2.5.2 Nach dem Skalenniveau\n\nDefinition 2.10 (Skalenniveau) Der Begriff Skalenniveau wird verwendet, um die Art und Menge der Information, die in Variablen enthalten ist, zu benennen. Diese Klassifikation basiert auf den Eigenschaften der Daten und den mathematischen Operationen, die sinnvoll auf diese Daten angewendet werden kÃ¶nnen. \\(\\square\\)\n\nAbbildungÂ 2.17 gibt einen Ãœberblick Ã¼ber typisch verwendete Skalenniveaus.\n\n\n\n\n\ngraph TD\n    Variablen --&gt; qualitativ\n    Variablen --&gt; quantitativ\n    qualitativ --&gt; nominal\n    qualitativ --&gt; ordinal\n    quantitativ --&gt; Intervallniveau\n    quantitativ --&gt; VerhÃ¤ltnisniveau\n\n\n\n\nAbbildungÂ 2.17: Skalenniveaus\n\n\n\n\n\nBeispiel 2.11 (Beispiele fÃ¼r Skalenniveaus) Beispiele zu den Skalenniveaus sind in TabelleÂ 2.5 aufgefÃ¼hrt. \\(\\square\\)\n\n\n\n\nTabelleÂ 2.5: Beispiele fÃ¼r Skalenniveaus\n\n\n\n\nVariable\nSkalenniveau\n\n\n\nHaarfarbe\nNominalskala\n\n\nAugenfarbe\nNominalskala\n\n\nGeschlecht\nNominalskala\n\n\nAutomarke\nNominalskala\n\n\nPartei\nNominalskala\n\n\nLieblingsessen\nOrdinalskala\n\n\nMedaillen beim 100-Meter-Lauf\nOrdinalskala\n\n\nUniranking\nOrdinalskala\n\n\nIQ\nIntervallskala\n\n\nExtraversion\nIntervallskala\n\n\nTemperatur in Celsius\nIntervallskala\n\n\nTemperatur in Fahrenheit\nIntervallskala\n\n\nTemperatur in Kelvin\nVerhÃ¤ltnisskala\n\n\nKÃ¶rpergrÃ¶ÃŸe\nVerhÃ¤ltnisskala\n\n\nGeschwindigkeit\nVerhÃ¤ltnisskala\n\n\nLÃ¤nge\nVerhÃ¤ltnisskala\n\n\n\n\n\n\n\n\nJenachdem, Ã¼ber welches Skalenniveau eine Variable verfÃ¼gt, sind verschiedenen Rechenoperationen erlaubt, s. TabelleÂ 2.6 . Zu diesen Rechenoperationen zÃ¤hlen: Das Testen auf Gleichheit (Symbol: \\(=\\)), das Ordnen der GrÃ¶ÃŸe nach (Symbol: \\(\\preceq\\)), das Addieren (und Subtrahieren; Symbol: \\(+\\)) und das Multiplizieren (und Dividieren; Symbol: \\(\\cdot\\)).\n\n\n\nTabelleÂ 2.6: Erlaubte Rechenoperationen nach Skalenniveau\n\n\n\n\nSkalenniveau\nQuantitativ\n=\nâ‰¼\n+\nÃ—\n\n\n\nNominalniveau\nnein\nâœ…\nâŒ\nâŒ\nâŒ\n\n\nOrdinalniveau\nnein\nâœ…\nâœ…\nâŒ\nâŒ\n\n\nIntervallniveau\nja\nâœ…\nâœ…\nâœ…\nâŒ\n\n\nVerhÃ¤ltnisniveau\nja\nâœ…\nâœ…\nâœ…\nâœ…\n\n\n\n\n\n\n\n\nWas soll das bedeuten, â€œRechenoperationenâ€? Schauen wir uns fÃ¼r jedes Skalenniveau ein â€œRechenbeispielâ€ an.\nNominalskala: Die Variable Geschlecht ist nominalskaliert. Das bedeutet, dass ihre AusprÃ¤gungen Frau und Mann z.\\(\\,\\)B. nicht (sinnvoll) addiert oder sonstwie â€œverrechnetâ€ werden kÃ¶nnen. Man kÃ¶nnte, z.\\(\\,\\)B. um das Eintippen zu erleichtern, Frauen mit 1 kodieren und MÃ¤nner mit 2. Damit darf man aber nicht rechnen! Nicht addieren, nicht multiplizieren, etc. Es macht keinen Sinn zu sagen: â€œIch habe eine Frau und einen Mann in meiner Tabelle, das ist im Schnitt ein diverses Geschlecht, weil der Mittelwert von 1 und 2 ist 1,5!â€ Die einzige â€œRechenoperationâ€, die man auf der Nominalskala machen darf, ist die PrÃ¼fung auf Gleichheit: Mann kann feststellen, ob ein Objekt gleich zu einem anderen ist oder unterschiedlich. Also ob zwei Personen das gleiche Geschlecht haben oder von unterschiedlichem Geschlecht sind. Anders ausgedrÃ¼ckt:\n\nğŸ‘© \\(\\ne\\) ğŸ‘¨\nğŸ‘© \\(=\\) ğŸ‘©\nğŸ‘¨ \\(=\\) ğŸ‘¨\n\nOrdinalskala: Diese Skala stellt einer Rangordnung dar. Eine Rangordnung ist etwa die geordnete Abfolge Ihrer Leibgerichte (1. Pizza, 2. Spagetthi, 3. Schnitzel). Etwas â€œformalerâ€ ausgedrÃ¼ckt, z.\\(\\,\\)B.:\nğŸ• \\(\\succ\\) ğŸ \\(\\succ\\) ğŸ¥©\nDas komische Zeichen \\(\\succ\\) soll heiÃŸen: â€œIst auf meiner Liste von Leibgerichten weiter oben, mag ich lieberâ€. Man kann aber nicht sagen, â€œIch mag aber Pizza um 42\\(\\,\\)% mehr als die Spaghetti und die um 73\\(\\,\\)% mehr als ein Schnitzel!â€ Zumindest kann man das nicht ohne weitere Informationen und Annahmen. Es gibt also Dinge auf der Welt, die man leicht in eine Rangordnung bringen kann, aber die man nur schwer in der GrÃ¶ÃŸe der Unterschiede bemessen kann. Das ist die Ordinalskala. Die Ordinalskale erlaubt also, Objekte zu ordnen (hinsichtlich eines Merkmals). Die AbstÃ¤nde zwischen den Objekten kÃ¶nnen dabei nicht quantifiziert werden.\nIntervallskala: Das ist vielleicht eine Ãœberraschung fÃ¼r Sie: Wenn die Temperatur heute bei 10\\(\\,\\)Â°C liegt und morgen 5\\(\\,\\)Â°C â€“ dann ist es heute nicht doppelt so warm wie morgen. Ja, 10 ist das Doppelte von 5. Aber 10\\(\\,\\)Â°C ist nicht doppelt so warm wie 20\\(\\,\\)Â°C. Wenn Sie das verwundert: Das ist normal, so geht es vielen Leuten, wenn sie das zum ersten Mal hÃ¶ren. Der Grund, warum es nicht sinnvoll (â€œerlaubtâ€) ist, VerhÃ¤ltnisse (wie doppelt/halb so viel etc.) auf der Celsius-Skala zu bilden, ist, dass der Nullpunkt der Skala, 0\\(\\,\\)Â°C, kein echter, physikalischer Nullpunkt ist. Bei 0\\(\\,\\)Â°C liegt eben nicht Null WÃ¤rmeenergie vor. Stattdessen wurde mit 0\\(\\,\\)Â°C eine WÃ¤rmenergiemenge gewÃ¤hlt, die fÃ¼r uns Menschen praktisch, da augenfÃ¤llig ist: der Gefrierpunkt von Wasser. Was bei der Intervallskala erlaubt ist, ist das Addieren (und Subtrahieren): heute 10\\(\\,\\)Â°C, morgen 5\\(\\,\\)Â°C, das ist ein Unterschied von 5\\(\\,\\)Â°C. Oder: Im Schnitt waren es 7,5\\(\\,\\)Â°C, das ist genau in der Mitte von 5 und 10\\(\\,\\)Â°C. AbbildungÂ 2.18 versinnbildlicht die Intervallskala.\n\n\n\n\n\n\n\nAbbildungÂ 2.18: Ein MetermaÃŸ steckt im trÃ¼ben Wasser. Auf dem MetermaÃŸ kÃ¶nnen wir die aufgedruckten Zahlen ablesen. Aber wir wissen nicht, ob der MetermaÃŸ auf dem Boden steht. Wir wissen demnach nicht, ob der vom MetermaÃŸ angegebene Nullpunkt der wahre Nullpunkt (Meeresboden) ist.\n\n\n\n\nVerhÃ¤ltnisskala: Eine VerhÃ¤ltnisskala ist das, was man sich gemeinhin unter einer metrische Variable vorstellt: Man kann â€œnormalâ€ rechnen, alle Rechenoperationen sind erlaubt. ZuzÃ¼glich zu denen, die auch in anderen, â€œniedrigerenâ€, Skalenniveaus erlaubt sind, ist das das Bilden von VerhÃ¤ltnissen â€“ Multiplizieren (und damit auch Dividieren).\nAuÃŸerdem kÃ¶nnen quantitative Variablen wie folgt untergliedert werden:\n\n\nstetige Variablen, das sind Variablen, bei denen man zwischen zwei AusprÃ¤gungen immer noch eine weitere quetschen kann. So gibt es einen Wert fÃ¼r die KÃ¶pergrÃ¶ÃŸe zwischen 1.60â€¯m und 1.61â€¯m. Und einen Wert zwischen 1.601â€¯m und 1.602â€¯m, etc.\n\ndiskrete Variablen, das sind metrische Variablen, die nur bestimmte AusprÃ¤gungen haben, hÃ¤ufig sind das die natÃ¼rlichen Zahlen mit Null: \\(0, 1,2,...\\). Ein Beispiel wÃ¤re die Anzahl der Kinder in einer Familie.\n\nFragen nach Skalenniveaus gehÃ¶ren zu den LieblingsprÃ¼fungsfragen in diesem Themenbereich. Sie sind gut beraten, sich gerade mit dieser Frage intensiver zu beschÃ¤ftigen. Auch in thematisch angrenzenden FÃ¤chern wird immer wieder die Frage nach dem Skalenniveau aufgeworfen. Das belegt die hohe Relevanz des Themas.\n\nÃœbungsaufgabe 2.9 Ãœberlegen Sie sich fÃ¼r einige Variablen die Skalenniveaus und befragen Sie dann interessierte Mitmenschen dazu. \\(\\square\\)\n\n\n\n\nIn diesem Video gibt es noch ausfÃ¼hrlichere ErklÃ¤rung zum Thema Skalenniveaus.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#modelle",
    "href": "010-rahmen.html#modelle",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.6 Modelle",
    "text": "2.6 Modelle\nWoran denken Sie beim Wort â€œModellâ€? Vielleicht an Behaims Globus oder an Spielzeugautos, s. AbbildungÂ 2.19?\n\n\n\n\n\nAbbildungÂ 2.19: Matchbox-Autos sind Modelle fÃ¼r Autos, (Spurzem, 2017)\n\n\n\nDefinition 2.11 (Modelle) Modelle sind ein vereinfachtes Abbild der RealitÃ¤t, eine ReprÃ¤sentation (Kaplan, 2009). \\(\\square\\)\n\n\nBeispiel 2.12 (Beispiele fÃ¼r Modelle) Puppen sind Modelle fÃ¼r Babys, Landkarten fÃ¼r Landstriche und das Atommodell von Nils Bohr ist ein Modell fÃ¼r Atome. \\(\\square\\)\n\nAuch in der Statistik nutzen wir Modelle. Helfen Sie Prof.Â Weiss-Ois: Er blickt nicht durch, s. BeispielÂ 7.1. Gerne wÃ¼rde er wissen, wie viele Stunden seine Studierenden auf die PrÃ¼fung lernen. Aber mit so vielen Zahlen kann er nicht umgehen â€¦ Geben Sie ihm ein Modell: Sagen Sie ihm, wie lang die Studis typischerweise lernen â€“ Sagen Sie ihm ein einfach den Mittelwert der Lernzeiten, das sind 9.6 Stunden.\n\nBeispiel 2.13 (Prof Weiss-Ois blickt nicht durch) Â \n\nğŸ§‘â€ğŸ« Vorher: 12, 8, 10, 11, 10, 9, 13, 9, 14, 9, 12, 14, 7, 9, 9, 11, 9, 4, 5, 12, 9, 6, 9, 12, 13, 9, 9, 6, 10 â€¦ Oh je, so viele Zahlen! Ich check nix! Wie viel lernen denn jetzt meine Studis?!\n\n\nğŸ§‘â€ğŸ« Ah, 9.6 Stunden! Yeah, jetzt weiÃŸ ich, wie viel die Studis so typischerweise lernen. Viel zu wenig natÃ¼rlich!\n\n\n\n\nProf.Â I. Ch. Weiss-Ois hat den Mittelwert verstanden â€¦ \\(\\square\\)\n\nDer Nutzen von Modellen ist, dass sie komplexe Sachverhalte vereinfachen und damit oft Ã¼berhaupt erst dem VerstÃ¤ndnis oder einer Untersuchung zugÃ¤nglich machen: Modelle ermÃ¶glichen VerstÃ¤ndnis. In der Datenanalyse bzw. Statistik (die beiden Begriffe werden hier weitgehend synonym gebraucht) fassen Modelle oft viele Daten prÃ¤gnant zusammen, z.\\(\\,\\)B. zu einer einzelnen Kennzahl. Das VerrÃ¼ckte an Modellen ist, dass man Informationen wegwirft, um eine (andere, hoffentlich nÃ¼tzlichere) Information zu bekommen (Stigler, 2016). Weniger ist mehr?!",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#praxisbezug",
    "href": "010-rahmen.html#praxisbezug",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.7 Praxisbezug",
    "text": "2.7 Praxisbezug\nWir leben im Datenzeitalter; Daten durchdringen alle Bereiche des beruflichen, gesellschaftlichen und privaten Lebens. Die Datenanalyse hat sich in den letzten Jahren massiv verÃ¤ndert, da Datenmengen und -methoden einen regelrechten Boom erlebt haben. Diese Entwicklung ist durchaus auch kritisch zu betrachten; viele Menschen betrachten die Entwicklung im Datenzeitalter â€“ Stichwort kÃ¼nstliche Intelligenz â€“ mit Sorge. Egal ob man Daten als Segen oder Fluch betrachtet, in beiden FÃ¤llen ist es wichtig, mit Daten umgehen zu kÃ¶nnen. Mit der wachsenden Bedeutung von Daten wÃ¤chst in gleichem MaÃŸe die Bedeutung von Datenanalyse. Denn Daten ohne Sinn sind nutzlos. Aus diesem Grund kann man sagen, dass Datenanalyse (und damit auch Statistik als eine spezielle Art von Datenanalyse) zu stark nachgefragten Jobs gehÃ¶ren.\nLaut dem Entgeltatlas der Bundesagentur fÃ¼r Arbeit liegt ein typisches Gehalt von Data Scientisten bei knapp 6000 Euro pro Monat (in der Altersgruppe von 25 bis 54)5. Laut dem Gehaltsreporter liegt das Einstiegsgehalt dieser Berufsgruppe bei knapp 50000 Euro pro Jahr.6",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "010-rahmen.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.8 Wie man mit Statistik lÃ¼gt",
    "text": "2.8 Wie man mit Statistik lÃ¼gt\nDas File-Drawer-Problem: Sie haben ein tolles Experiment durchgefÃ¼hrt, viel Arbeit, viel Stress, endlich geschafft, puh. Von den 20 Variablen (als AV, s. Kapitel 2.5), die Sie untersucht haben, zeigt nur 1 einen interessanten Effekt, leider. 1 von 20, das hÃ¶rt sich nicht so toll an. WÃ¤re es da nicht â€œelegantâ€, die 19 Variablen ohne schÃ¶nen Effekt einfach in der Schublade liegen zu lassen bis zum Sankt-Nimmerleins-Tag? Dann kÃ¶nnten Sie stattdessen als Ergebnis nur die eine Variable mit schÃ¶nen Ergebnis prÃ¤sentieren, ganz ohne widersprechende Befunde.\nDieser Versuchung zu widerstehen, kann schwer sein. Es ist aber gefÃ¤hrlich, missliebige Ergebnisse zu verschweigen: Die anderen Menschen bekommen dann ein falsches Bild der Ergebnislage; man spricht von Publikationsbias (Marks-Anglin, Arielle and Chen, Yong, 2020). Wer Ergebnisse verschweigt, verzerrt die gesamte Befundlage (Rothstein, 2014) â€“ ein Fall von wissenschaftlichem Fehlverhalten.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#aufgaben",
    "href": "010-rahmen.html#aufgaben",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.9 Aufgaben",
    "text": "2.9 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nvariation01\nDef-Statistik01\ntidy1\nSkalenniveau1a\nZiele-Statistik\nvariation02\nSkalenniveau1b\ntidydata1",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#vertiefung",
    "href": "010-rahmen.html#vertiefung",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.10 Vertiefung",
    "text": "2.10 Vertiefung\n\n2.10.1 Excel fÃ¼r KÃ¶nner\nIn vielen Organisationen werden Exceltabellen fÃ¼r bestimmte Zwecke der Datenverarbeitung verwendet. Excel und Ã¤hnliche Programme haben bestimmte StÃ¤rken und Vorteile, aber auch gewisse Nachteile und SchwÃ¤chen; das liegt daran, dass Excel fÃ¼r bestimmte Aufgaben besser und fÃ¼r andere weniger gut geeignet ist. Wenn man mit Excel arbeitet, wiederholen sich erfahrungsgemÃ¤ÃŸ immer wieder die gleichen Fehler bzw. kommt es wiederholt zu einer suboptimalen Vorgehensweise zum Aufbau einer Exceltabelle. Der Artikel von Broman & Woo (2018) zeigt anhand einiger praktischer Tipps, wie man Exceltabellen so aufbaut, dass Fehler minimiert werden.\n\nÃœbungsaufgabe 2.10 (Fassen Sie den Artikel von Broman & Woo (2018) zusammen) Die Lehrkraft teilt Sie dazu in Gruppen ein und weist jeder Gruppe einen Abschnitt des Artikels zu. Fassen Sie das Wesentliche (und nur das Wesentliche) zum Artikel an einem geeigneten Ort zusammen (z.\\(\\,\\)B. auf einem Online-Whiteboard). \\(\\square\\)\n\n\n2.10.2 Sind Sie sÃ¼chtig nach Ihrem Handy?\n\n\n\nSind Sie sÃ¼chtig nach Ihrem Handy? Lassen Sie uns eine kleine Studie dazu (ggf. live im HÃ¶rsaal) durchfÃ¼hren. FÃ¼llen Sie diese Umfrage zum Thema Smartphonse-Sucht aus (anonym und kein Muss).\n\n\n\n\n\n\n\n\n\n\n\n\n\nKernstÃ¼ck der Umfrage ist die Smartphone-Sucht-Skala (Kwon et al., 2013). Eine Studie fand, dass ca. ein Siebtel der Studierenden sÃ¼chtig nach ihrem Smartphone ist (Haug et al., 2015); demnach kÃ¶nnte dem Thema eine hohe Bedeutsamkeit zukommen.\n\n2.10.3 Datenprofi plaudert aus dem NÃ¤hkÃ¤stchen\nInspiration von einer Praktikerin der Datenanalyse: Caitlin Hudon verrÃ¤t in diesem Video, welche Fehler Sie sie in in den acht Jahren ihrer Berufserfahrung gemacht hat und was sie daraus gelernt hat.7",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literaturhinweise",
    "href": "010-rahmen.html#literaturhinweise",
    "title": "\n2Â  Rahmen\n",
    "section": "\n2.11 Literaturhinweise",
    "text": "2.11 Literaturhinweise\nEinen Einblick in die Fundamente statistischer Analyse bietet Stigler (2016). Ã‡etinkaya-Runde & Hardin (2021) stellen grundlegende Konzepte der Analyse von Daten im Kapitel 1, â€œHello dataâ€, vor. Downey (2023) illustriert statistische Ãœberraschungsmoment auf unterhaltsame, und vor allem: sofataugliche Art.\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization in Spreadsheets. The American Statistician, 72(1), 2â€“10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., & Schaub, M. P. (2015). Smartphone Use and Smartphone Addiction among Young People in Switzerland. Journal of Behavioral Addictions, 4(4), 299â€“307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHorst, A. (2023). Tidy Data [Artwork]. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The Smartphone Addiction Scale: Development and Validation of a Short Version for Adolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific Method, Statistical Method and the Speed of Light. Statistical Science, 15(3), 254â€“278. https://doi.org/10.1214/ss/1009212817\n\n\nMarks-Anglin, Arielle and Chen, Yong. (2020). A Historical Review of Publication Bias. Research Synthesis Methods, 11(6), 725â€“742. https://doi.org/10.1002/jrsm.1452\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley StatsRef: Statistics Reference Online. John Wiley. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSpurzem, L. (2017). VW 1303 von Wiking in 1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG\n\n\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press.\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain Drain: The Mere Presence of Oneâ€™s Own Smartphone Reduces Available Cognitive Capacity. Journal of the Association for Consumer Research, 2(2), 140â€“154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild [Artwork]. https://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., & Grolemund, G. (2018). R fÃ¼r Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren (F. Langenau, Ãœbers.). Oâ€™Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#footnotes",
    "href": "010-rahmen.html#footnotes",
    "title": "\n2Â  Rahmen\n",
    "section": "",
    "text": "Release 2023-Janâ†©ï¸\nhttps://www.openintro.org/data/index.php?data=mariokartâ†©ï¸\nCeteris paribus auf Latein, hÃ¶rt sich gleich viel schlauer an.â†©ï¸\nhttps://tinyurl.com/3w8ke2n2â†©ï¸\nAbrufdatum: 1.2.23; https://web.arbeitsagentur.de/entgeltatlas/beruf/129987â†©ï¸\nhttps://gehaltsreporter.de/gehaelter-von-a-bis-z/it/data-scientist/â†©ï¸\nhttps://youtu.be/O5lP6XcopdQ?si=7UsS6xbeYjnorGhxâ†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "020-R.html",
    "href": "020-R.html",
    "title": "3Â  Daten einlesen",
    "section": "",
    "text": "3.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#einstieg",
    "href": "020-R.html#einstieg",
    "title": "3Â  Daten einlesen",
    "section": "",
    "text": "3.1.1 Lernziele\n\nSie kÃ¶nnen R und RStudio starten.\nSie kÃ¶nnen R-Pakete installieren und starten.\nSie kÃ¶nnen Variablen in R zuweisen und auslesen.\nSie kÃ¶nnen Daten in R importieren.\nSie kÃ¶nnen den Begriff Reproduzierbarkeit definieren.\n\n3.1.2 Ãœberblick\nAbbildungÂ 3.1 veranschaulicht den typischen Lernverlauf in der Datenanalyse (und mit R): HÃ¶hen und Tiefen sind normal.\n\n\n\n\n\nAbbildungÂ 3.1: Life is a roller-coaster. You just have to ride it (Horst, 2024).\n\n\n\n3.1.3 Ab diesem Kapitel benÃ¶tigen Sie R\nBitte stellen Sie sicher, dass Sie R (R Core Team, 2024) fÃ¼r dieses Kapitel einsatzbereit haben. Weiter unten in diesem Kapitel finden Sie Installationshinweise (Kapitel 3.3). Falls Sie dieses Kapitel zum ersten Mal bzw. sich noch nicht mit R auskennen, werden Sie vielleicht einigen Inhalten begegnen, die Sie noch nicht gleich verstehen. Keine Sorge, das ist normal. Mit etwas Ãœbung wird Ihnen bald alles schnell von der Hand gehen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errrstkontakt",
    "href": "020-R.html#errrstkontakt",
    "title": "3Â  Daten einlesen",
    "section": "\n3.2 Errrstkontakt",
    "text": "3.2 Errrstkontakt\n\n3.2.1 Warum R?\nGrÃ¼nde, die fÃ¼r den Einsatz von R (R Core Team, 2024) sprechen:\n\nğŸ†“ R ist kostenlos, andere Softwarepakete fÃ¼r Datenanalyse sind teuer. ğŸ’¸\nğŸ“– R und R-Befehle sind quelloffen, d.\\(\\,\\)h. man kann sich die zugrundeliegenden Computerbefehle anschauen. Jeder kann prÃ¼fen, ob R vernÃ¼nftig arbeitet. Alle kÃ¶nnen beitragen.\nğŸ†• R hat die neuesten Methoden.\nğŸ«‚ R hat eine groÃŸe Community.\nğŸª¡ R ist maÃŸgeschneidert fÃ¼r Datenanalyse.\n\nAllerdings gibt es auch abweichende Meinungen, s. AbbildungÂ 3.2.\n\n\n\n\n\nAbbildungÂ 3.2: Manche finden Excel cooler als R, nicht wahr, Bill Gates? (imgflip, 2024a)\n\n\n\n3.2.2 R und Reproduzierbarkeit\n\nDefinition 3.1 (Reproduzierbarkeit) Ein (wissenschaftlicher) Befunde ist reproduzierbar, wenn andere Personen mit der Analysemethodik zum gleichen Ergebnis (wie in der ursprÃ¼nglichen Analyse) kommen (Plesser, 2018). \\(\\square\\)\n\n\nDefinitionÂ 3.1 ist, etwas Ã¼berspitzt, in AbbildungÂ 3.3 wiedergegeben.\n\n\n\nğŸ”¢ + ğŸ¤– + ğŸ”¬ = ğŸ¤©\n\n\n\nAbbildungÂ 3.3: Daten + Syntax + genaue Beschreibung der Messungen = reproduzierbar\n\n\n\nBeispiel 3.1 (Aus der Forschung: Reproduzierbarkeit in der Psychologie) Â \n\nğŸ§‘â€ğŸ“ Wie steht es um die Reproduzierbarkeit in der Psychologie? Sind die Befunde zuverlÃ¤ssig?\n\nObels et al. (2020) haben die Reproduzierbarkeit in psychologischen Studien untersucht. Sie berichten folgendes Ergebnis (S. 229):\n\nWe examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles.\n\nInsgesamt war also etwa jede dritte Studie reproduzierbar. Da gibt es noch viel Luft nach oben! \\(\\square\\)\n\n\n\n3.2.3 R & RStudio\nWenn wir sagen, â€œwir arbeiten mit Râ€, dann heiÃŸt das in unserem Fall, wir arbeiten mit R und mit RStudio.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 3.4: R und eine GUI wie RStudio arbeiten gut zusammen.\n\n\nIsmay & Kim (2020) zeigen in einer schÃ¶nen Analogie, was den Unterschied von R und RStudio ausmacht, s. AbbildungÂ 3.5. (Streng genommen ist RStudio fÃ¼r die Datenanalyse irrelevant, aber RStudio ist praktisch, Sie werden es nicht missen wollen.)\n\n\n\n\n\nAbbildungÂ 3.5: R vs.Â RStudio: R macht die Arbeit, RStudio ist fÃ¼r Komfort und Ãœbersicht zustÃ¤ndig (Ismay & Kim, 2020).\n\n\nKurz gesagt: Das eigentlich Arbeiten besorgt R. FÃ¼r den Komfort die Ãœbersicht ist RStudio zustÃ¤ndig. Auch eine Art von Arbeitsteilung!\n\n\n\n\n\n\nHinweis\n\n\n\n\nR: ğŸ‹ï¸â€â™€ï¸\nRStudio: ğŸ’… \\(\\square\\)\n\n\n\n\nHier sehen Sie einen Screenshot von der OberflÃ¤che von RStudio, s. AbbildungÂ 3.6.\n\n\n\n\n\nAbbildungÂ 3.6: So sieht RStudio aus",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-install-r",
    "href": "020-R.html#sec-install-r",
    "title": "3Â  Daten einlesen",
    "section": "\n3.3 Installation von R und RStudio",
    "text": "3.3 Installation von R und RStudio\n\n3.3.1 Installation von R\nR ist ein Softwarepaket fÃ¼r statistische Berechnungen. Laden Sie es fÃ¼r Ihr Betriebssytem herunter unter https://cloud.r-project.org. Wenn Sie beim Herunterladen gefragt werden, dass Sie einen â€œMirrorâ€ auswÃ¤hlen sollen, heiÃŸt das, Sie sollen einen Computer (Server) wÃ¤hlen, von dem Sie R herunterladen. Der sollte mÃ¶glichst nicht zu weit weg stehen, dann spart es vielleicht etwas Zeit und Bandbreite. Wenn Sie die Installationsdatei heruntergeladen haben, Ã¶ffnen Sie diese Datei (Doppelklick) und Sie werden durch die Installation gefÃ¼hrt. (Sie benÃ¶tigen Admin-Rechte auf Ihrem Computer.)\n\nWindows\nMacOS\nLinux\n\n3.3.2 Installation von RStudio Desktop\nRStudio ist eine graphische BenutzeroberflÃ¤che (graphical user interface, GUI) fÃ¼r R, plus ein paar Goodies (in Form einer intergrierten Entwicklungsumgebung (integrated development environment, IDE). Laden Sie die Desktop-Version von RStudio herunter fÃ¼r Ihr Betriebssystem (Windows, MacOS, Linux) vom Anbieter (Posit) herunter.1 Wenn Sie die Installationsdatei heruntergeladen haben, Ã¶ffnen Sie diese Datei (Doppelklick) und Sie werden durch die Installation gefÃ¼hrt. (Sie benÃ¶tigen u. U. Admin-Rechte auf Ihrem Computer.)\n\n3.3.3 Posit/RStudio Cloud\nPosit Cloud bzw. RStudio Cloud (https://rstudio.cloud/) ist ein Webdienst von Posit (zum Teil kostenlos), also ein RStudio online: Man kann damit online mit R arbeiten. Sie kÃ¶nnen es als Alternative zur Installation von RStudio Desktop (was auf Ihrem Computer lÃ¤uft) verwenden. Ein Vorteil von RStudio Cloud ist, dass man als Nutzer nichts installieren muss und dass es auch auf Tablets lÃ¤uft (im Gegensatz zur Desktop-Version von RStudio). Ein Nachteil ist, dass es etwas langsamer ist und nur fÃ¼r ein gewisses Zeitvolumen kostenlos. Sie mÃ¼ssen sich erst ein Konto beim Anbieter anlegen, um den Dienst nutzen zu kÃ¶nnen.\nDie OberflÃ¤che RStudio Cloud ist praktisch identisch zur Desktop-Version, s. AbbildungÂ 3.7.\n\n\n\n\n\nAbbildungÂ 3.7: So sieht RStudio Cloud aus. Fast genau wie RStudio Desktop\n\n\nWenn Ihnen jemand (z.\\(\\,\\)B. eine Lehrkraft) einen RStudio-Cloud-Projektordner bzw. einen Link dazu bereitstellt, ist das komfortabel, da die Lehrkraft dann schon Pakete installieren, Daten bereitstellen und andere Nettigkeit vorbereiten kann fÃ¼r Sie. Allerdings mÃ¼ssen Sie den Projektordner in Ihrem eigenen Konto abspeichern, wenn Sie etwas speichern mÃ¶chten, da Sie vermutlich keine Schreibrechte im Projektordner dieser nettern Person (Ihrer Lehrkraft) haben. Klicken Sie dazu auf â€œSave a permanent copyâ€, s. AbbildungÂ 3.8.\n\n\n\n\n\nAbbildungÂ 3.8: Einen Projektordner im eigenen Konto abspeichern, um Schreibrechte zu haben\n\n\nSie kÃ¶nnen auch von der Cloud exportieren, also Ihre Syntaxdatei herunterladen. Klicken Sie dazu im Reiter â€œFilesâ€ auf More &gt; Export.\n\n\n\n\n\n\nHinweis\n\n\n\nRStudio starten, nicht R. \\(\\square\\)\n\n\nWir verwenden beide Programme (R und RStudio). Aber wir Ã¶ffnen nur RStudio. RStudio findet selbstÃ¤ndig R und Ã¶ffnet dieses â€œheimlichâ€. Ã–ffnen Sie nicht noch extra R (sonst wÃ¤re R zweifach geÃ¶ffnet). Anstelle von RStudio Desktop (auf Ihrem Computer/Desktop) kÃ¶nnen Sie auch die RStudio Cloud (die Online-Version) starten",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-r-pckgs",
    "href": "020-R.html#sec-r-pckgs",
    "title": "3Â  Daten einlesen",
    "section": "\n3.4 R-Pakete",
    "text": "3.4 R-Pakete\nTypisch fÃ¼r R ist sein modularer Aufbau: Man kann eine groÃŸe Zahl an Erweiterungen (â€œPaketeâ€, engl. packages) installieren, alle kostenlos. In R Paketen â€œwohnenâ€ R-Befehle, also Dinge, die R kann, â€œSkillsâ€ sozusagen. AuÃŸerdem kÃ¶nnen in R-Paketen auch Daten bereitgestellt werden. Damit man die Inhalte eines R-Pakets nutzen kann, muss man es zuerst installieren und dann verfÃ¼gbar machen (â€œstartenâ€). Man kann sich daher ein R-Paket vorstellen wie ein Buch: Wenn R es gelesen hat, dann kennt es die Inhalte. Diese Inhalte kÃ¶nnten irgendwelche Formeln, also Berechnungen sein. Es kÃ¶nnte aber die â€œBauanleitungâ€ fÃ¼r ein schÃ¶nes Diagramm sein. Ist ein spezielles R-Paket auf Ihrem Computer installiert, so kÃ¶nnen Sie diese FunktionalitÃ¤t nutzen. Die Anzahl der R-Pakete ist groÃŸ; allein auf dem â€œoffiziellen Web-Storeâ€ (nennt sich â€œCRANâ€) von R gibt es ca. 20,000 Pakete (Hornik et al., 2023). Und es kommen immer mehr dazu.\nErweiterungen kennt man von vielen Programmen, sie werden auch Add-Ons, Plug-Ins oder sonstwie genannt. Man siehe zur Verdeutlichung Erweiterungen beim Broswer Chrome, AbbildungÂ 3.9.\n\n\n\n\n\nAbbildungÂ 3.9: Erweiterungen beim Browser Chrome\n\n\nWie jede Software muss man Pakete (Erweiterungen fÃ¼r R) erst einmal installieren, bevor man sie verwenden kann. Ãœbrigens, einmal installieren reicht. Das Installieren geht komfortabel, wenn man beim Reiter Packages auf Install klickt und dann den Namen des zu installierenden Pakets eingibt.\nAbbildungÂ 3.11 verdeutlicht, wo Sie in RStudio klicken mÃ¼ssen, um Pakete zu installieren.\n\n\n\n\n\nAbbildungÂ 3.10: Geben Sie den Namen des zu installierenden R-Pakets in dieser Maske ein\n\n\n\n\n\n\n\nAbbildungÂ 3.11: So kann man R-Pakete installieren in RStudio\n\n\n\nğŸ§‘â€ğŸ“ Welche R-Pakete sind denn schon installiert?\n\n\nğŸ§‘â€ğŸ« Im Reiter Packages kÃ¶nnen Sie nachschauen, welche Pakete auf Ihrem Computer schon installiert sind.\n\nDiese Pakete brauchen Sie logischerweise dann nicht noch mal installieren, s. AbbildungÂ 3.12; es sei denn, Sie wollen das Paket updaten.\n\n\n\n\n\nAbbildungÂ 3.12: So sehen Sie, ob ein bestimmtes R-Paket auf Ihrem System installiert ist\n\n\nAlternativ kÃ¶nnen Sie zum Installieren von Paketen auch den Befehl install.packages() verwenden. Also zum Beispiel install.packages(tidyverse), um das Paket tidyverse zu installieren.\n\nğŸ§‘â€ğŸ“ Ja, aber welche R-Pakete â€œsollâ€ ich denn installieren, welche brauche ich denn?\n\n\n\nğŸ§‘â€ğŸ« Im Moment sollten Sie die folgenden Pakete installiert haben: tidyverse und easystats.\n\n\nWenn Sie die noch nicht installiert haben sollten, dann kÃ¶nnen Sie das jetzt nachholen. Ãœbrigens sind tidyverse (Wickham et al., 2019) und easystats (LÃ¼decke et al., 2022) Pakete, die nur dafÃ¼r da sind, mehrere Pakete zu installieren. So gehÃ¶ren z.\\(\\,\\)B. zu tidyverse die Pakete ggplot (Daten verbildlichen) und dplyr (Datenjudo). Damit wir nicht alle Pakete einzeln installieren und starten mÃ¼ssen, bietet uns das Paket tidyverse den Komfort, alle die Pakete dieser â€œSammlungâ€ auf einmal zu starten. Praktisch.\nBevor Sie ein R-Paket (oder Ã¼berhaupt irgendwelche Software) installieren/updaten, sollten Sie das entsprechende R-Paket schlieÃŸen/beenden. Sonst schrauben Sie sozusagen an einem elektrischen GerÃ¤t herum, das noch unter Strom steht (nicht gut). Die einfachste Art, alle Pakete zu beenden ist, Session &gt; Restart R zu klicken (in RStudio).\nWenn Sie ein Softwareprogramm installiert haben, mÃ¼ssen Sie es noch starten, bevor Sie es nutzen kÃ¶nnen. Sie erkennen leicht, ob ein Paket bereitgestellt (gestartet) ist, wenn Sie ein HÃ¤kchen vor dem Namen des Pakets in der Paketliste (Reiter Packages) sehen. Ein bestimmtes R-Paket muss man nur einmalig installieren. Aber man muss es jedes Mal neu starten, wenn man R (bzw. RStudio) startet.\nDieses Video verdeutlicht den Unterschied zwischen Installation und Starten eines R-Pakets.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#mit-r-arbeiten",
    "href": "020-R.html#mit-r-arbeiten",
    "title": "3Â  Daten einlesen",
    "section": "\n3.5 Mit R arbeiten",
    "text": "3.5 Mit R arbeiten\n\n3.5.1 Projekte in R\nEin Projekt in RStudio ist letztlich ein Ordner, der als â€œBasisâ€ fÃ¼r eine Reihe von zusammengehÃ¶rigen Dateien verwendet wird. Sagen wir, Sie nennen Ihr Projekt cool_stuff. RStudio legt uns diesen Ordner an einem von uns gewÃ¤hlten Platz auf unserem Computer an. Das ist ganz praktisch, weil man dann sagen kann â€œHey R, nimm die Datei â€˜daten.csvâ€™â€, ohne, dass man dabei einen Pfad angeben mÃ¼sste. Vorausgesetzt, die Datei liegt auch im Projektordner (cool_stuff). RStudio-Projekte kann anlegen mit Klick auf das Icon, das einen Quader mit dem Buchstaben R darin anzeigen. Nutzen Sie RStudio-Projekte, das macht Ihr Leben leichter. RStudio-Projekte zu nutzen ist praktischer als das Arbeitsverzeichnis von Hand zu wÃ¤hlen oder mit Pfaden herumzubasteln.\nHier sehen Sie Beispiele fÃ¼r RStudio-Projekte, s. AbbildungÂ 3.13.\n\n\n\n\n\nAbbildungÂ 3.13: RStudio-Projekte, Beispiele\n\n\n\n3.5.2 Skriptdateien\nDie R-Befehle (â€œSyntaxâ€) schreiben Sie am besten in eine speziell dafÃ¼r vorgesehene Textdatei in RStudio. Eine Sammlung von (R-)Computer-Befehlen nennt man auch ein Skript, daher spricht man bei Dateien, die Syntax enthalten, von einer Skriptdatei.\nUm eine neue R-Skriptdatei zu erstellen, gibt es mehrere Wege. Einer ist: klicken Sie auf das Icon, das ein weiÃŸes Blatt mit einem grÃ¼nen Pluszeichen zeigt, s. AbbildungÂ 3.14.\n\n\n\n\n\n\n\n\n\n(a) Klick auf Icon\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Auswahl im Menu\n\n\n\n\n\n\nAbbildungÂ 3.14: Es gibt verschiedene Wege, um eine neue R-Skript-Datei in RStudio zu Ã¶ffnen. (a) Per Klick auf das Icon. (b) Im MenÃ¼ File, auf R Script klicken.\n\n\nVergessen Sie nicht zu speichern, wenn Sie ein tolles Skript geschrieben haben. DafÃ¼r gibt es mehrere MÃ¶glichkeiten:\n\nTastaturkÃ¼rzel Strg+S\n\nMenÃ¼: File &gt; Save\n\nKlick auf das Icon mit der Diskette, s. AbbildungÂ 3.14.\n\nEine existierende Skriptdatei kÃ¶nnen Sie in typischer Manier Ã¶ffnen:\n\nTastaturkÃ¼rzel Strg+O\n\nMenÃ¼: File &gt; Open File â€¦\n\nKlick auf das Icon mit der Akte und dem grÃ¼nen Pfeil, s. AbbildungÂ 3.14\n\n\n3.5.3 Quarto-Dokumente\nQuarto2 ist ein (kostenloses) Programm zum Erstellen von PDF-, HTML- oder anderen Dokumentformaten, in die man R-Syntax einfÃ¼gen kann. Die Ausgaben der R-Befehle werden dann direkt ins Ausgabedokument eingebunden. Quarto ist in RStudio integriert. Quarto ist eine komfortable und leistungsfÃ¤hige Methode, um Dokumente mit R-Syntax zu anzreichern. Sie sind aber nicht verpflichtet, Quarto zu nutzen. Stattdessen kÃ¶nnen Sie Ihre Syntax auch in Skriptdateien schreiben.\nAbbildungÂ 3.15 zeit ein Beispiel fÃ¼r ein Quarto-Dokument.\n\n\n\n\n\nAbbildungÂ 3.15: Dokumente schreiben mit Quarto. Quelle: Posit\n\n\nWenn Sie Quarto nutzen mÃ¶chten, mÃ¼ssen Sie es zunÃ¤chst installieren, d.\\(\\,\\)h. herunterladen. Dann kÃ¶nnen Sie in RStudio Quarto-Dateien erstellen. Ein neues Quarto-Dokument kÃ¶nnen Sie erstellen mit Klick auf File &gt; New File &gt; Quarto Document.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errisch-fÃ¼r-einsteiger",
    "href": "020-R.html#errisch-fÃ¼r-einsteiger",
    "title": "3Â  Daten einlesen",
    "section": "\n3.6 Errisch fÃ¼r Einsteiger",
    "text": "3.6 Errisch fÃ¼r Einsteiger\n\n3.6.1 Variablen\nIn jeder Programmiersprache kann man Variablen definieren, so auch in R:\n\nrichtige_antwort = 42\nfalsche_antwort = 43\ntyp = \"Antwort\"\nist_korrekt = TRUE  # wahr\nist_falsch = FALSE  # falsch\n\nAlternativ zum Gleichheitszeichen = kÃ¶nnen Sie auch (synonym) den Zuweisungspfeil &lt;- verwenden (Kleiner-Als-Zeichen gefolgt vom Minus-Zeichen). Beides fÃ¼hrt zum gleichen Ergebnis. Allerdings ist der Zuweisungspfeil prÃ¤ziser, und sollte daher bevorzugt werden. Der Zuweisungspfeil &lt;- bzw. das Gleichheitszeichen = definiert eine neue Variable (oder Ã¼berschreibt den Inhalt, wenn die Variable schon existiert).\n\n\nrichtige_antwort &lt;- 42\n\nSie kÃ¶nnen sich eine Variable wie einen Becher oder BehÃ¤lter vorstellen, der bestimmte Werte enthÃ¤lt, z.\\(\\,\\)B. den Wert â€œ9â€ (fÃ¼r 9\\(\\,\\)Â° Celsius. Auf dem Becher steht die Bezeichnung des Bechers geschrieben, z.\\(\\,\\)B. â€œTemperaturâ€. NatÃ¼rlich kÃ¶nnen Sie die Werte aus dem Becher entfernen und sie durch neue ersetzen (vgl. AbbildungÂ 3.16).\n\n\n\n\n\nAbbildungÂ 3.16: Variablen zuweisen: Der Variable mit dem Namen temp weisen wir den Wert 9 zu.\n\n\nR kann Ã¼brigens auch rechnen. Probieren Sie es doch gleich mal hier aus!\n\ndie_summe &lt;- falsche_antwort + richtige_antwort\n\nAber was ist jetzt der Wert, der â€œInhaltâ€ der Variable die_summe?\nUm den Wert, d.\\(\\,\\)h. den Inhalt einer Variablen in R auszulesen, geben wir einfach den Namen des Objekts ein:\n\ndie_summe\n## [1] 85\n\nWas passiert wohl, wenn wir die_summe jetzt wie folgt definieren?\n\ndie_summe &lt;- falsche_antwort + richtige_antwort + 1\n\nWer hÃ¤ttâ€™s geahnt:\n\ndie_summe\n## [1] 86\n\nVariablen kÃ¶nnen auch â€œleerâ€ sein:\n\nalter &lt;- NA  # NA wie \"not available\", nicht vorhanden\nalter\n## [1] NA\n\nNA steht fÃ¼r not available, nicht verfÃ¼gbar und macht deutlich, dass hier ein Wert fehlt.\n\nğŸ§‘â€ğŸ“ Wozu brauche ich bitte fehlende Werte?!\n\nFehlende Werte sind ein hÃ¤ufiges Problem in der Praxis. Vielleicht hat sich die befragte Person geweigert, ihr Alter anzugeben (Datenschutz!). Oder als Sie die Daten in Ihren Computer eingeben wollten, ist Ihre Katze Ã¼ber die Tastatur gelaufen und alles war futschâ€¦\n\n3.6.2 Funktionen (â€œBefehleâ€)\nDas, was R kann, ist in â€œFunktionenâ€ hinterlegt. Genauer gesagt ist ein â€œBefehlâ€ an R eine Funktion.\n\nDefinition 3.2 (Funktion) Eine Funktion ist eine Regel, die jedem Eingabewert (auch Argument genannt) einen Ausgabewert zuordnet. Man kann sich Funktionen als Maschinen vorstellen, die Eingabedaten in Ausgabedaten umwandeln, vgl. AbbildungÂ 3.17. \\(\\square\\)\n\nEin Beispiel fÃ¼r eine solche Funktion kÃ¶nnte sein: â€œBerechne den Mittelwert dieser Datenreiheâ€ (schauen wir uns gleich an). Das geht so:\n\nAntworten &lt;- c(42, 43)\n\nDer Befehl c (c wie combine) fÃ¼gt mehrere Werte zusammen zu einer â€œListeâ€ (einem Vektor). (Streng genommen sollte man nicht von einer Liste sprechen, da es in R noch einen anderen Objekttyp gibt, der list heiÃŸt, und eine verallgemeinerte Form eines Vektors ist.) Mit dem Zuweisungspfeil geben wir diesem Vektor einen Namen, hier Antworten. Dieser Vektor besteht aus zwei Werten, zuerst 42, dann kommt 43. Zwei wichtige Typen von Vektoren sind numerische Vektoren (reelle Zahlen; in R auch als numeric oder double bezeichnet) und Textvektoren, in R auch als String oder character bezeichnet.\n\nDefinition 3.3 (Vektor) Als Vektor (Datenreihe) bezeichnen wir eine geordnete Folge von Werten. In R kann man sie mit der Funktion c erstellen. Die Werte eines Vektors bezeichnet man als Elemente. \\(\\square\\)\n\n\nBeispiel 3.2 (Beispiele fÃ¼r Vektoren) Vektoren kÃ¶nnen (praktisch) beliebig lang sein, z.\\(\\,\\)B. drei Elemente.\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 3)  # x und y sind ungleich (Reihenfolge der Werte)\nz &lt;- c(3.14, 2.71)  \nnamen &lt;- c(\"Anni\", \"Bert\", \"Charlie\") # Text-Vektor\n\n\n\nBeispiel 3.3 Weitere Beispiel fÃ¼r Funktionen sind:\n\nâ€œErstelle eine Liste (Vektor) von Wertenâ€.\nâ€œLade dieses R-Paket.â€\nâ€œGib den grÃ¶ÃŸten Wert dieser Datenreihe aus.â€ \\(\\square\\)\n\n\n\n\n3.6.3 Unsere erste statistische Funktion\nJetzt wirdâ€™s ernst. Jetzt kommt die Statistik. ğŸ§Ÿ Berechnen wir also unsere erste statistische Funktion: Den Mittelwert. Puh.\n\nmean(Antworten)\n## [1] 42\n\nSie hÃ¤tten Antworten auch durch c(42, 43) ersetzen kÃ¶nnen, so haben Sie ja die Variable Antworten im letzten Abschnitt definiert.\nR arbeitet so einen â€œverschachteltenâ€ Befehl von innen nach auÃŸen ab:\nStart: mean(Antworten)\nâ¬‡ï¸ \nSchritt 1: mean(c(42, 43))\nâ¬‡ï¸ \nSchritt 2: 42.5\nAbbildungÂ 3.17 stellt eine Funktion schematisch dar.\n\n\n\n\n\nAbbildungÂ 3.17: Schema einer Funktion\n\n\nEine Funktion hat einen oder mehrere Eingaben (Argumente, Inputs; s. AbbildungÂ 3.17), das sind Daten oder Verarbeitungshinweise, die man in die Funktion fun eingibt, bevor die Funktion loslegt. Eine Funktion hat immer (genau) eine Ausgabe (Output), in der das Ergebnis der Funktion ausgegeben wird.\nSo hat die Funktion mean z.\\(\\,\\)B. folgende Argumente, s. ListingÂ 3.1.\n\n\nListingÂ 3.1: Die Argumente der R-Funktion mean\n\n\nmean(x, trim = 0, na.rm = FALSE, ...)\n\n\n\n\n\n\nx: das ist der Vektor, fÃ¼r den der Mittelwert berechnet werden soll\n\ntrim = 0: Sollen die extremsten Werte von x lieber â€œabgeschnittenâ€ werden, also nicht in die Berechnung des Mittelwerts einflieÃŸen?\n\nna.rm = FALSE: Wie soll mit fehlenden Werten NA umgegangen werden? Im Standard liefert mean (und viele andere arithmetische Funktionen in R) NA zurÃ¼ck. R schwenkt sozusagen die rote Fahne, um zu signalisieren: Achtung, Mensch, hier ist irgendwas nicht in Ordnung. Setzt man aber na.rm = TRUE, dann entfernt (remove, rm) R die fehlenden Werte und berechnet den Mittelwert, ohne weitere Hinweise zu den fehlenden Werten.\n\n... heiÃŸt â€œsonstiges Zeugs, das manchmal eine Rolle spielen kÃ¶nnteâ€; darum kÃ¼mmern wir uns jetzt nicht.\n\nEinige Argumente haben einen Standardwert bzw. eine Voreinstellung (engl. default). So wird bei der Funktion mean im Standard nicht getrimmt (trim = 0) und fehlende Werte werden nicht entfernt (na.rm = FALSE).\nWenn ein R-Befehl ein Argument mit Voreinstellung hat, brauchen Sie dieses Argument nicht zu befÃ¼llen. In dem Fall wird auf den Wert der Voreinstellung zurÃ¼ckgegriffen. Argumente ohne Voreinstellung â€“ wie x bei mean â€“ mÃ¼ssen Sie aber auf jeden Fall mit einem Wert befÃ¼llen. Man wÃ¼rde also mean zumeist so aufrufen: mean(x).\nBei jedem R-Befehl haben die Argumente eine bestimmte Reihenfolge, etwa bei mean: mean(x, trim = 0, na.rm = FALSE, ...). (Nur) wenn man die Argumente in ihrer vorgegebenen Reihenfolge anspricht, muss man nicht den Namen des Arguments anfÃ¼hren:\nâœ… mean(Antworten, 0, FALSE)\nHÃ¤lt man sich aber nicht an die vorgebene Reihenfolge, so weiÃŸ R nicht, was zu tun ist und flÃ¼chtet sich in eine Fehlermeldung:\n\nmean(Antworten, FALSE, 0)  # FALSCH, DON'T DO IT \n## Error in mean.default(Antworten, FALSE, 0): 'trim' must be numeric of length one\n\nWenn man die Namen der Argumente anspricht, ist die Reihenfolge egal:\n\nmean(na.rm = FALSE, x = Antworten)  # ok\nmean(trim = 0, x = Antworten, na.rm = TRUE)  # ok\n\nÃœbrigens: Leerzeichen sind R fast immer egal. Aus GrÃ¼nden der Ãœbersichtlichkeit sollte man aber Leerzeichen verwenden. In folgenden FÃ¤llen sind Leerzeichen nicht erlaubt: In Operatoren wie &lt;- oder &lt;= (und andere logische Operatoren, s. TabelleÂ 3.1) und in Variablennamen.\n\n3.6.4 Vorsicht bei fehlenden Werten\nSagen wir, wir haben einen fehlenden Wert in unseren Daten:\n\nAntworten &lt;- c(42, 43, NA)\nAntworten\n## [1] 42 43 NA\n\nWenn wir jetzt den Mittelwert berechnen wollen, quittiert R das mit einem schnÃ¶den NA. NA steht fÃ¼r not available, ist also ein Hinweis, dass Werte fehlen.\n\nmean(Antworten)\n## [1] NA\n\nR meint es gut mit Ihnen.3 Stellen Sie sich vor, dass R Sie auf dieses Problem aufmerksam machen mÃ¶chte:\n\nğŸ¤– Achtung, NAs, fehlende Werte, lieber Herr und Gebieter, du hast nicht mehr alle Latten am Zaun, will sagen, alle Daten im Vektor!\n\n(Danke, R.)\nMÃ¶chten Sie aber lieber R dieses Verhalten austreiben, so befÃ¼llen Sie das Argument na.rm mit dem Wert TRUE (na.rm steht fÃ¼r remove die NA, entferne die fehlenden Werte).\n\nmean(Antworten, na.rm = TRUE)\n## [1] 42\n\n\n3.6.5 Vektorielles Rechnen\n\nDefinition 3.4 (Vektorielles Rechnen) Das Rechnen mit Vektoren in R bezeichnen wir als vektorielles Rechnen. \\(\\square\\)\n\nVektorielles Rechnen ist ein praktische Angelegenheit, man kann z.\\(\\,\\)B. folgende Dinge einfach in R ausrechnen. Gegeben sei x als Vektor (1, 2, 3). Dann kÃ¶nnen wir die Differenz (Abweichung) jedes Elements von x zum Mittelwert von x komfortabel so ausrechnen:\n\nx - mean(x)\n## [1] -1  0  1\n\nEtwas eleganter ausgedrÃ¼ckt: Wir haben die Funktion mit Namen â€œDifferenzâ€ (â€œMinus-Rechnenâ€) auf jedes Element von x angewandt. Im Einzelnen haben wir also folgenden drei Differenzen berechnet:\n\n1 - 2\n2 - 2\n3 - 2\n\nDiese drei Rechenschritte sind symbolisch in AbbildungÂ 3.18 dargestellt.\n\n\n\n\n\n\n\nAbbildungÂ 3.18: Schema des vektoriellen Rechnens: Eine Funktion wird auf jedes Element eines Vektors angewandt. Hier: \\(1-2=-1; 2-2=0; 3-2=1\\)\n\n\n\n\n\n3.6.6 Ich brauche R-Hilfe!\n\n\nWo finde ich Hilfe zu einer bestimmten Funktion, z.\\(\\,\\)B. fun? Geben Sie dazu folgenden R-Befehl ein: help(fun). Alternativ geben Sie den Namen der Funktion in RStudio im Suchfeld beim Reiter Help ein. Oder Googeln.\n\nWenn ich ein R-Paket installiere, fragt mich R manchmal, ob ich auch Pakete installieren, will, die â€œkompiliertâ€ werden mÃ¼ssen. Soll ich das machen? Nein, das ist zumeist nicht nÃ¶tig; geben Sie â€œnoâ€ ein.\n\nIn welchem Paket wohnt meine R-Funktion? Suchen Sie nach der Funktion auf der Webseite RDocumentation4.\n\nIch weiÃŸ nicht, wie der R-Befehl funktioniert! Vermutlich haben andere Ihr Problem auch, und meistens hat irgendwer das Problem schon gelÃ¶st. Am besten suchen Sie mal auf www.stackoverflow.com.\n\nIch muss mal grundlegend verstehen, wozu ein bestimmten R-Paket gut ist. Was tun? Lesen Sie die Dokumenation (â€œVignetteâ€) eines R-Pakets durch. FÃ¼r das Paket dplyr bekommen Sie so einen Ãœberblick Ã¼ber die verfÃ¼gbaren Vignetten diese Pakets: vignette(package = \"dplyr\"). Dann suchen Sie sich aus der angezeigten Liste eine Vignette raus; mit vignette(\"rowwise\") kÃ¶nnen Sie sich dann die gewÃ¼nschte Vignette (z.\\(\\,\\)B. rowwise) anzeigen lassen.\n\nOh nein, ich seh rot, das heiÃŸt, R zeigt mir irgendwas in roter Schrift an. Ist jetzt was kaputt? Keine Sorge, R ist in seiner Ausgabe nicht sparsam mit roter Farbe. Solange es nicht als Fehlermeldung (ERROR) erscheint, ist es meist kein Problem.\n\nR hat sich aufgehÃ¤ngt oder bringt einen Fehler an einer Stelle, wo sonst alles funktioniert hat. Probieren Sie auf jeden Fall mal das AEG-Prinzip (Aus-Ein-Gut): Sprich, R neu starten.\n\nIch suche schon seit einer Stunde einen Fehler und finde ihn nicht. Ich habe schon verschiedene GegenstÃ¤nde vor Wut an die Wand geworfen. Was soll ich tun? Machen Sie eine Pause. Doch, das ist ernst gemeint. Meine Erfahrung: Mit etwas Abstand wird der Kopf klarer und man findet das Problem viel einfacher. (Und manchmal ist einem das Problem danach schlichtweg egal.)\n\nIrgendwie reagiert R komisch, vielleicht hat es sich aufgehÃ¤ngt? Starten Sie R neu. Klicken Sie auf Session &gt; Restart R.\n\nIch muss mal klar Schiff machen und alle (oder einige) Variablen lÃ¶schen. Wie werd ich das Zeug wieder los? Beim Neustart von R werden alle Objekte (Variablen) gelÃ¶scht. Einzelne Objekte kÃ¶nnen Sie selektiv lÃ¶schen mit dem Befehl rm, so lÃ¶scht rm(mariokart) das Objekt namens mariokart.\n\n\n\n\n\n\n\nVorsicht\n\n\n\nR ist penibel: So sind name und Name zwei verschiedene Variablen fÃ¼r R. GroÃŸ- und Kleinschreibung wird von R streng beachtet.\n\n\nEine gute Nachricht: Wenn R etwas von WARNING (bzw. Warnung) sagt, kÃ¶nnen Sie das zumeist ignorieren. Eine Warnung ist kein Fehler (ERROR) und meistens nicht gravierend oder nicht dringend. Ihre Syntax lÃ¤uft trotzdem durch. Im Zweifel ist Googeln eine gute Idee. Nur wenn R von Error spricht, ist es auch ein Fehler und Ihre Syntax lÃ¤uft nicht durch.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#mit-daten-arbeiten",
    "href": "020-R.html#mit-daten-arbeiten",
    "title": "3Â  Daten einlesen",
    "section": "\n3.7 Mit Daten arbeiten",
    "text": "3.7 Mit Daten arbeiten\n\n3.7.1 Wo sind meine Daten?\nDamit Sie eine Datendatei importieren kÃ¶nnen, mÃ¼ssen Sie wissen, wo die Datei ist. Schauen wir uns zwei MÃ¶glichkeiten an, wo Ihre Datei liegen kÃ¶nnte.\n\nIrgendwo im Internet\nIrgendwo auf Ihrem Computer, z.\\(\\,\\)B. in Ihrem R-Projektordner\n\nIn beiden FÃ¤llen wird der â€œAufenthaltsortâ€ der Datei durch den Pfad und den Namen der Datei definiert. Der Pfad einer Datei gibt an, in welchem Ordner und Unterordner (und Unter-Unterordner) die gesuchte Datei liegt. Ein Pfad kÃ¶nnte z.\\(\\,\\)B. so aussehen: /Users/sebastiansaueruser/github-repos/statistik1/.\n\n\n\n\n\n\nHinweis\n\n\n\nWir werden in diesem Kurs hÃ¤ufiger mit dem Daten mariokart arbeiten; Sie finden ihn online.5\n\n\n\n3.7.2 GebrÃ¤uchliche Datenformate\nDaten werden in verschiedenen Formaten im Computer abgespeichert; Tabellen hÃ¤ufig als Excel-Datei (.XSL oder .XLSX) oder als CSV-Datei (.CSV).\nIn der Datenanalyse ist das gebrÃ¤uchlichste Format fÃ¼r Daten in Tabellenform die CSV-Datei. Der Grund ist die technische Einfachheit dieses Formats.. FÃ¼r uns Endverbraucher tut das nichts groÃŸ zur Sache, die CSV-Datei beherbergt einfach eine brave Tabelle in einer Textdatei, sonst nichts. Daher kÃ¶nnen Sie jede CSV-Datei mit einem normalen Texteditor Ã¶ffnen. In diesem Buch werden wir mit einem Datensatz namens mariokart arbeiten.\nHallo Mario, s. AbbildungÂ 3.19!\n\n\n\n\n\nAbbildungÂ 3.19: Hallo, Mario\n\n\n Download CSV   Download XLSX \n\nÃœbungsaufgabe 3.1 (CSV-Datei Ã¶ffnen) Â \n\n\nAufgabe\nLÃ¶sung\n\n\n\nÃ–ffnen Sie die CSV-Datei mariokart.csv mit einem Texteditor (nicht mit Word und auch nicht mit Excel). Schauen Sie sich gut an, was Sie dort sehen und erklÃ¤ren Sie die Datenstruktur.\n\n\nEine CSV-Datei reprÃ¤sentiert eine Datentabelle. Eine Spaltengrenze wird mittels eines Kommas dargestellt (man kann auch andere Zeichen wÃ¤hlen, um Spalten voneinander abzugrenzen).\nHier sind die ersten paar Zeilen von mariokart.csv:\nV1,id,duration,n_bids,cond,start_pr,ship_pr,total_pr,ship_sp,seller_rate,stock_photo,wheels,title\n1,150377422259,3,20,new,0.99,4,51.55,standard,1580,yes,1,~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW ~~\n2,260483376854,7,13,used,0.99,3.99,37.04,firstClass,365,yes,1,Mariokart Wii Nintendo with wheel - Mario Kart Nintendo\n3,320432342985,3,16,new,0.99,3.5,45.5,firstClass,998,no,1,Mario Kart Wii (Wii)\n4,280405224677,3,18,new,0.99,0,44,standard,7,yes,1,Brand New Mario Kart Wii Comes with Wheel. Free Ship\n5,170392227765,1,20,new,0.01,0,71,media,820,yes,2,BRAND NEW NINTENDO 1 WII MARIO KART WITH 2 WHEELS +GAME\n\n\n\n\n\n3.7.3 Daten importieren\nSie kÃ¶nnen Daten aus verschiedenen Quellen in R importieren: Aus einem R-Paket, von einer Webseite oder von Ihrem Computer. Dabei ist es egal, ob Sie die Desktop- oder die Cloud-Version von RStudio nutzen.\nIst Ihr Datensatz schon in einem R-Paket gespeichert, kÃ¶nnen Sie ihn aus diesem R-Paket starten. Das ist die bequemste Option. Zum Beispiel â€œwohntâ€ der Datensatz mariokart im R-Paket openintro.\n\n\n\n\n\n\nTipp\n\n\n\nHÃ¤ufig wird vergessen, dass ein R-Paket vor der Nutzung installiert werden muss.\n\n\nAuf der anderen Seite muss man ein R-Paket (wie andere Software auch) nur ein Mal installieren â€“ Allerdings muss man ein Paket nach jedem Neustart von R bzw. von RStudio mit library starten.\n\ndata(\"mariokart\", package = \"openintro\") # Paket muss installiert sein\n\nEine Data-Dictionary fÃ¼r mariokart findet sich in Anhang B. Online findet sich eine ErklÃ¤rung (Data-Dictionary) des Datensatzes.6\nDer Befehl read.csv bietet eine MÃ¶glichkeit, Daten (in Form einer Tabelle) von einer Webseite (URL) in R zu importieren, s. ListingÂ 3.2.\n\n\n\nListingÂ 3.2: Mariokart-Datensatz importieren (mit read.csv)\n\nmariokart &lt;- read.csv(paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets/\",\n  \"csv/openintro/mariokart.csv\"))\n\n\n\n\nEs liegt bei Ihnen, welchen Namen Sie der Tabelle geben. Ich persÃ¶nlich wÃ¤hle oft den Namen d, d die Daten. d ist ein kurzer Namen, muss man nicht so viel tippen. Auf der anderen Seite ist d nicht gerade ein prÃ¤ziser Name. Werfen Sie einen Blick in die Tabelle (engl. to glimpse).\n\nglimpse(d)\n## Rows: 143\n## Columns: 12\n## $ id          &lt;dbl&gt; 1.5e+11, 2.6e+11, 3.2e+11, 2.8e+11, 1.7e+11, 3.6e+11, 1â€¦\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1â€¦\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, â€¦\n## $ cond        &lt;fct&gt; new, used, new, new, new, new, used, new, used, used, nâ€¦\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 1â€¦\n## $ ship_pr     &lt;dbl&gt; 4.0, 4.0, 3.5, 0.0, 0.0, 4.0, 0.0, 3.0, 4.0, 4.0, 3.0, â€¦\n## $ total_pr    &lt;dbl&gt; 52, 37, 46, 44, 71, 45, 37, 54, 47, 50, 55, 56, 48, 56,â€¦\n## $ ship_sp     &lt;fct&gt; standard, firstClass, firstClass, standard, media, stanâ€¦\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 48â€¦\n## $ stock_photo &lt;fct&gt; yes, yes, no, yes, yes, yes, yes, yes, yes, no, yes, yeâ€¦\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2â€¦\n## $ title       &lt;fct&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND Nâ€¦\n\nSie kÃ¶nnen Datendateien von verschiedenen Webseiten herunterladen, s. AbbildungÂ 3.20.\n\n\n\n\n\nAbbildungÂ 3.20: Download einer Datendatei (CSV-Format) von einer Webseite\n\n\nSie kÃ¶nnen auch von Ihrem Computer aus Daten in RStudio importieren. Gehen wir davon aus, dass sich die Datendatei im gleichen Ordner wie die R-Datei (.R- oder .qmd-Datei) befindet, in der Sie den Befehl zum Importieren schreiben. Dann kÃ¶nnen Sie die Datei einfach so importieren:\n\nd &lt;- read.csv(\"mariokart.csv\")\n\n\n\n\nDieses Video erklÃ¤rt die Schritte des Importierens einer Datendatei von Ihrem Computer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDas Importieren von Ihrem Computer zu RStudio Cloud ist identisch zum Importieren von Ihrem Computer in RStudio Desktop. Nur dass Sie die Datendatei vorab hochladen mÃ¼ssen, schlieÃŸlich ist RStudio Cloud in der Cloud und nicht auf Ihrem Computer. Klicken Sie dazu auf das Icon Upload im Reiter Files, s. AbbildungÂ 3.21. WÃ¤hlen Sie am besten den Ordner als Ziel, in dem sich auch die R-Datei, von der aus Sie den Befehl zum Daten importieren schreiben, befindet.\n\n\n\n\n\nAbbildungÂ 3.21: Hochladen von Dateien zu RStudio Cloud\n\n\nEs gibt verschiedene Formate, in denen (Tabellen-)Dateien in einem Computer abgespeichert werden. Die gebrÃ¤uchlichsten sind CSV und XLSX. Es gibt auch mehrere R-Befehle, um Daten in R zu importieren, z.\\(\\,\\)B. read.csv oder data_read. Praktischerweise kann der R-Befehl data_read viele verschiedene Formate automatisch einlesen, so dass wir uns nicht weiter um das Format kÃ¼mmern brauchen. Der Vorteil von read.csv ist, dass Sie kein Extra-Paket installiert bzw. gestartet haben mÃ¼ssen.\nDie GUI (BenutzeroberflÃ¤che) von RStudio erlaubt es Ihnen auch, Daten per Klick, also ohne R-Befehle, zu importieren. Sie kÃ¶nnen Ã¼ber diese Maske sowohl CSV-Dateien, Excel-Dateien (XLS, XLSX) oder Daten-Dateien aus anderen Statistik-Programmen (z.\\(\\,\\)B. SPSS) importieren auf diese Weise. Zur Erinnerung: CSV-Dateien sind Textdateien, klicken Sie in dem Fall also From Text. Ich empfehle dort die Variante From Text (readr) â€¦ zu wÃ¤hlen. In der sich Ã¶ffnenden Maske kÃ¶nnen Sie unter Browse die zu importierende Datendatei auswÃ¤hlen. Mit Klick auf Import wird die Datei schlieÃŸlich in R importiert.\nMan klicke hier, um Daten in RStudio zu importieren, AbbildungÂ 3.22.\n\n\n\n\n\nAbbildungÂ 3.22: Daten importieren per Klick\n\n\n\n3.7.4 Dataframes\nEine in R importierte Tabelle (mit bestimmten Eigenschaften) heiÃŸt Dataframe. Dataframes sind in der Datenanalyse von groÃŸer Bedeutung. TabelleÂ 2.2 ist die Tabelle mit den Mariokart-Daten; etwas prÃ¤ziser gesprochen ein Dataframe mit Namen mariokart. Ãœbrigens ist TabelleÂ 2.2 in Normalform (Tidy-Format), vgl. DefinitionÂ 2.9.\n\nDefinition 3.5 (Dataframe) Ein Dataframe (engl. data frame; auch â€œTibbleâ€ genannt; von â€œtblâ€ wie Table) ist ein Datenobjekt in R zur Darstellung von Tabellen. Dataframes bestehen aus einer oder mehreren Spalten. Spalten haben einen Namen, sozusagen einen â€œSpaltenkopfâ€. Alle Spalten mÃ¼ssen die gleiche LÃ¤nge haben; anschaulich gesprochen ist eine Tabelle (in R) rechteckig. Jede Spalte einzeln betrachtet kann als Vektor aufgefasst werden. \\(\\square\\)\n\nGeben Sie den Namen eines Dataframes ein, um sich den Inhalt anzeigen zu lassen. Beachten Sie, dass Sie die Daten auf diese Weise nur anschauen, nicht Ã¤ndern kÃ¶nnen.\n\n\n\n\n\n\n\n3.7.5 Tabellen in R betrachten\nWenn Sie in R z.\\(\\,\\)B. die Tabelle mariokart in einer Excel-typischen Ansicht betrachten wollen, klicken Sie am besten auf das Tabellen-Icon im Reiter Environment, gleich neben dem Namen mariokart, s. AbbildungÂ 3.23. Alternativ Ã¶ffnet der Befehl View(mariokart) die gleiche Ansicht.\n\n\n\n\n\nAbbildungÂ 3.23: Per Klick auf das Tabellen-Icon kÃ¶nnen Sie eine Tabellenansicht der Tabelle mariokart Ã¶ffnen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-logic",
    "href": "020-R.html#sec-logic",
    "title": "3Â  Daten einlesen",
    "section": "\n3.8 LogikprÃ¼fung",
    "text": "3.8 LogikprÃ¼fung\n\nğŸ§‘â€ğŸ“ Wer will schon wieder wen prÃ¼fen?!\n\nIn diesem Abschnitt schauen wir uns LogikprÃ¼fungen an: Wir lassen R prÃ¼fen, ob eine Variable einen bestimmten Wert hat oder grÃ¶ÃŸer/kleiner als ein Referenzwert ist. Definieren wir zuerst eine Variable, x.\n\nx &lt;- 42\n\nDann fragen wir R, ob diese Variable den Wert 42 hat.\n\nx == 42\n## [1] TRUE\n\n\nğŸ¤– Hallo, Mensch. Ja, diese Variable hat den Wert 42.\n\nDanke, R. MÃ¶chte man mit R prÃ¼fen, ob eine Variable x einen bestimmten Wert (â€œInhaltâ€) hat, so schreibt man: x == Wert. Man beachte das doppelte Gleichheitszeichen. Zur PrÃ¼fung auf Gleichheit muss man das doppelte Gleichheitszeichen verwenden.\n\n\n\n\n\n\nVorsicht\n\n\n\nEin beliebter Fehler ist es, bei der PrÃ¼fung auf Gleichheit, nur ein Gleichheitszeichen zu verwenden, z.\\(\\,\\)B. so: x = 73. Mit einem Gleichheitszeichen prÃ¼ft man aber nicht auf Gleichheit, sondern man definiert die Variable oder bestimmt ein Funktionsargument, s. Kapitel 3.6.1.\n\n\nTabelleÂ 3.1 gibt einen Ãœberblick Ã¼ber wichtige LogikprÃ¼fungen in R. Um das Zeichen fÃ¼r das logische ODER, | auf einer Mac-Tastatur zu erhalten, drÃ¼ckt man Option+7. Bei Windows drÃ¼ckt man Alt Gr + &lt;.\n\n\n\nTabelleÂ 3.1: Logische PrÃ¼fungen in R\n\n\n\n\nPrÃ¼fung.auf\nR-Syntax\n\n\n\nGleichheit\nx == Wert\n\n\nUngleichheit\nx != Wert\n\n\nGrÃ¶ÃŸer als Wert\nx &gt; Wert\n\n\nGrÃ¶ÃŸer oder gleich Wert\nx &gt;= Wert\n\n\nKleiner als Wert\nx &lt; Wert\n\n\nKleiner oder gleich Wert\nx &lt;= Wert",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#praxisbezug",
    "href": "020-R.html#praxisbezug",
    "title": "3Â  Daten einlesen",
    "section": "\n3.9 Praxisbezug",
    "text": "3.9 Praxisbezug\n\nğŸ§‘â€ğŸ“ R in der Praxis wirklich genutzt? Oder ist R nur der Traum von (vielleicht verwirrten) Profs im Elfenbeinturm?\n\nSchauen wir uns dazu die Suchanfragen bei www.stackoverflow.com an, dem grÃ¶ÃŸten FAQ-Forum fÃ¼r Software-Entwicklung. Wir vergleichen Suchanfragen mit dem Tag [r] zu Suchanfragen mit dem Tag [spss] (SPSS ist eine an Hochschulen verbreitete Statistik-Software). Die Ergebnisse sind in Abbildung AbbildungÂ 3.24 dargestellt.7 Das ist grob gerechnet ein Faktor von 200 (der Unterschied von R zu SPSS). Dieses Ergebnis lÃ¤sst darauf schlieÃŸen, dass R in der Praxis viel mehr als SPSS gebraucht wird.\n\n\n\n\n\n\n\nAbbildungÂ 3.24: Suchanfragen nach R bzw SPSS, Stand 2022-02-24\n\n\n\n\n\nğŸ§‘â€ğŸ“ Aber ist R wirklich ein Werkzeug, das mir im Job hilft?\n\n\nğŸ§‘â€ğŸ« Viele Firmen weltweit nutzen R zur Datenanalyse.8\n\n\nğŸ‘©â€ğŸ“ R ist der Place-to-be fÃ¼r die Datenanalyse.\n\n\nğŸ§‘â€ğŸ“ Aber ist Datenanalyse wirklich etwas, womit ich in Zukunft einen guten Job bekomme?\n\n\nğŸ§‘â€ğŸ« Berufe mit Bezug zu Daten, Datenanalyse oder, allgemeiner, KÃ¼nstlicher Intelligenz (artificial intelligence) gehÃ¶ren zu den stark wachsenden Berufen (Berger, 2019.)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#aufgaben",
    "href": "020-R.html#aufgaben",
    "title": "3Â  Daten einlesen",
    "section": "\n3.10 Aufgaben",
    "text": "3.10 Aufgaben\n\nÃœbungsaufgabe 3.2 (Statistik-Meme) Suchen Sie ein schÃ¶nes Meme zum Thema Statistik, Datenanalyse und Data Science. \\(\\square\\)\n\n\nÃœbungsaufgabe 3.3 (R-Quiz) Â \n\n\n\nIhre R-Muskeln sind gestÃ¤hlt? ğŸ’ª Oder noch nicht so ganz? ğŸ˜¤ Macht nichts! Trainieren Sie sich mit dem R-Quiz auf der Datenwerk-Webseite! \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nTyp-Fehler-R-01\nTyp-Fehler-R-02\nTyp-Fehler-R-03\nTyp-Fehler-R-04\nTyp-Fehler-R-06a\nTyp-Fehler-R-07\nTyp-Fehler-R-08-name-clash\nLogikpruefung1\nLogikpruefung2\nthere-is-no-package\nWertberechnen2\nWertzuweisen_mc\nargumente\nimport-mtcars\nWertzuweisen\nWertpruefen\nwrangle1\nrepro1-sessioninfo\nmw-berechnen\n\nNoch nicht genug? Checken Sie alle Aufgaben mit dem Tag R auf dem Datenwerk aus.9\n\n\n\n\n\n\nHinweis\n\n\n\nDie Webseite Datenwerk stellt eine Reihe von Aufgaben zum Thema Statistik bereit. \\(\\square\\)\n\n\nJeder Aufgabe sind im Datenwerk ein oder mehrere SchlagwÃ¶rter (Tags) zugeordnet. Wenn Sie auf ein Schlagwort klicken, sehen Sie die Liste der Aufgaben mit diesem Schlagwort. Es kann aber sein, dass Sie einige Aufgabe nicht lÃ¶sen kÃ¶nnen, da Wissen vorausgesetzt wird, das Sie (noch) nicht haben. Lassen Sie sich davon nicht ins Boxhorn jagen. Ignorieren Sie solche Aufgaben fÃ¼rs Erste.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#vertiefung",
    "href": "020-R.html#vertiefung",
    "title": "3Â  Daten einlesen",
    "section": "\n3.11 Vertiefung",
    "text": "3.11 Vertiefung\n\n3.11.1 Alternativen zu read.csv\n\nEine weitere MÃ¶glichkeit, um Daten von einem Ordner (egal ob dieser sich im Internet oder auf Ihrem Computer befindet) einzulesen, stellt die Funktion data_read bereit:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nd &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nDer Unterschied ist, dass data_read eine Vielzahl an Formaten von Daten (XLSX, CSV, SPSS, â€¦) verkraftet, wohingegen read.csv nur Standard-CSV einlesen kann.\nSchauen wir uns die letzte R-Syntax im Detail an:\nHey R,\nhol das \"Buch\" easystats aus der BÃ¼cherei und lies es\ndefiniere als \"d\" die Tabelle,\ndie du unter der angegebenen URL findest.\nIn R gibt es oft viele MÃ¶glichkeiten, ein Ziel zu erreichen. Zum Beispiel haben wir hier den Befehl data_read verwendet, um Daten zu importieren. Andere, gebrÃ¤uchliche Befehle, die CSV-Dateien importieren, heiÃŸen read.csv (aus dem Standard-R, kein Extra-Paket nÃ¶tig) und read_csv (aus dem Meta-Paket tidyverse).\n\n3.11.2 Importieren von Excel-Tabellen\nMit der Funktion data_read aus easystats kann man viele verschiedene Datenformate importieren, auch Excel-Tabellen (.xls, .xlsx).\nAls Beispiel betrachten wir den Datensatz extra aus dem R-Paket pradadata10. In diesem Datensatz werden die Ergebnisse einer Umfrage zu den Korrelaten von Extraversion beschrieben. Details zu der zugrunde liegenden Studie finden Sie hier: https://osf.io/4kgzh.11 Laden Sie die Excel-Datei herunter. Angenommen, Sie speichern die Excel-Datei in einem Unterordner namens daten Ihres aktuellen Projektordners. Dann kÃ¶nnen Sie die Daten so importieren:\n\nlibrary(easystats)\nextra &lt;- data_read(\"data/extra.xls\")\n\n Download XLS   Download CSV \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCSV-Dateien werden auf vielen Computern als eine Datei erkannt, die Excel Ã¶ffnen kann und das auch tut, wenn man eine CSV-Datei doppelklickt. Dennoch ist das CSV-Format keine Datei im Excel-Format, sondern eine einfache Text-Datei, die auch mit jedem Text-Editor geÃ¶ffnet und bearbeitet werden kann. Alternativ kÃ¶nnen Sie in RStudio auch Excel-Dateien ohne R-Code importieren.\n\n3.11.3 Der Dollar-Operator\nIn DefinitionÂ 3.4 hatten wir Vektoren definiert. Solche Vektoren fliegen sozusagen frei in Ihrem Environment herum (Schauen Sie mal dort nach!) Die Spalten einer Tabelle sind aber auch Vektoren, nur eben nicht frei im Environment, sondern in eine Tabelle eingebunden. MÃ¶chte man diese Vektoren direkt ansprechen, so kann man das mit dem sog. Dollar-Operator $ tun. Angenommen, Sie mÃ¶chten sich die Verkaufspreise (total_pr) aus der Tabelle mariokart herausziehen, dann kÃ¶nnen Sie das mit dem Dollar-Operator tun:\n\nmariokart$total_pr |&gt; head()  # nur die ersten paar Werte zeigen\n## [1] 52 37 46 44 71 45\n\nDer Dollar-Operator trennt den Namen der Tabelle vom Namen der Spalte. NatÃ¼rlich kÃ¶nnen Sie mit dem resultierenden Vektor beliebig weiterarbeiten, etwa ihn in einem anderen Vektor speichern oder eine Funktion anwenden:\n\nverkaufspreise &lt;- mariokart$total_pr\nmean(verkaufspreise)\nmean(mariokart$total_pr)  # synonym zur obigen Zeile\n## [1] 50\n## [1] 50\n\n\n3.11.4 R-Zertifikat bei LinkedIn\nSie kÃ¶nnen bei LinkedIn12 (oder anderen Anbietern) ein Zertifikat erhalten, das Ihre R-Kenntnisse dokumentiert.\n\n3.11.5 R-Funktionen verschachteln\nDas Kombinieren von Funktionen kann kompliziert werden:\n\n\n\nListingÂ 3.3: Verschachtelte Funktionen\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x)-x)) \n## [1] 2\n\n\n\n\nDie Funktion abs(x) gibt den (Absolut-)Betrag von x zurÃ¼ck (entfernt das Vorzeichen).\nVerschachtelte AusdrÃ¼cke lesen sich von innen nach auÃŸen (und werden in dieser Reihenfolge abgearbeitet). FÃ¼r unser Beispiel (ListingÂ 4.2):\n\nBerechne den Mittelwert von x\n\nZiehe vom Mittelwert jeweils die Elemente von x ab\nNimm vom Ergebnis jeweils den Absolutwert\nSummiere diese Werte\n\nKurz gesagt: Hier haben wir die mittlere Absolutabweichung der Elemente von x zum Mittelwert ausgerechnet.\n\n3.11.6 R und Friends updaten\nIrgendwann werden wir mit unsere Version von R und RStudio veraltet sein. Installieren Sie dann einfach die neue Version von R und RStudio wie oben beschrieben, s. Kapitel 3.3.\nSo updaten Sie Ihre R-Pakete: Klicken Sie im Reiter Packages (in RStudio) auf Update. Wenn die Anzahl der zu aktualisierenden Pakete groÃŸ ist, dann besser nicht alle auswÃ¤hlen, sondern nur ein paar. Dann die nÃ¤chsten paar Pakete usw. Denken Sie daran, dass Sie die Software (R, RStudio, R-Paket), die Sie updaten/installieren, nicht gerade laufen darf.\nIhre R-Pakete sollten aktuell sein. Klicken Sie beim Reiter Packages auf â€œUpdateâ€, um Ihre R-Pakete zu aktualisieren. Arnold Schwarzenegger rÃ¤t, Ihre R-Pakete aktuell zu halten, s. AbbildungÂ 3.25.\n\n\n\n\n\nAbbildungÂ 3.25: R-Pakete sollten stets aktuell sein, so Arnold Schwarzenegger (imgflip, 2024b)\n\n\n\n3.11.7 BenÃ¶tigte Daten\nSie benÃ¶tigen in den meisten Kapiteln dieses Buches den Datensatz mariokart, der entweder online13 oder Ã¼ber R-Paket openintro importiert werden kann.\nImport via Download:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nImport via R-Paket:\n\n# Das Paket 'openintro' muss installiert sein:\ndata(mariokart, package = \"openintro\")",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literaturhinweise",
    "href": "020-R.html#literaturhinweise",
    "title": "3Â  Daten einlesen",
    "section": "\n3.12 Literaturhinweise",
    "text": "3.12 Literaturhinweise\nâ€œWarum R? Warum, R?â€ heiÃŸt ein Kapitel in Sauer (2019), das einiges zum Pro und Contra von R ausfÃ¼hrt. Kapitel 3 in derselben Quelle enthÃ¤lt Hinweise zum Starten von R. Kapitel 4 erlÃ¤utert die Grundlagen von â€œErrischâ€. Kapitel 5 fÃ¼hrt in die Datenstrukturen von R ein (etwas anspruchsvoller als in diesem Kapitel). Alternativ bietet Kapitel 1 von Ismay & Kim (2020) einen guten und anwenderfreundlichen Ãœberblick. Das Buch hat auch den Vorteil, dass es komplett frei online verfÃ¼gbar ist. Vergleichbar dazu ist Ã‡etinkaya-Runde & Hardin (2021), vielleicht einen Tick formaler; auf jeden Fall genau das richtige Niveau fÃ¼r Bachelor-Statistik in angewandten nicht-technischen StudiengÃ¤ngen.\n\n\n\n\n\nBerger, G. (2019, Dezember 10). The Jobs of Tomorrow: LinkedInâ€™s 2020 Emerging Jobs Report. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nHornik, K., Ligges, U., & Zeileis, A. (2023). Changes on CRAN. The R Journal, 15, 295â€“296.\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024a). Imageflip Bill Gates Meme [Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nLÃ¼decke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., ThÃ©riault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229â€“237. https://doi.org/10.1177/2515245920918872\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability: A Brief History of a Confused Terminology. Frontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nR Core Team. (2024). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., FranÃ§ois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., MÃ¼ller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., â€¦ Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#footnotes",
    "href": "020-R.html#footnotes",
    "title": "3Â  Daten einlesen",
    "section": "",
    "text": "https://posit.co/download/rstudio-desktop/â†©ï¸\nhttps://quarto.org/â†©ï¸\nğŸ¤– Naja, manchmal.â†©ï¸\nhttps://www.rdocumentation.org/â†©ï¸\nAuf dieser Webseite https://vincentarelbundock.github.io/Rdatasets/articles/data.html finden Sie den Datensatz mariokart sowie eine groÃŸe Zahl an weiteren DatensÃ¤tzen. Nur fÃ¼r den Fall, dass Ihnen langweilig ist.â†©ï¸\nhttps://vincentarelbundock.github.io/Rdatasets/doc/openintro/mariokart.htmlâ†©ï¸\nDie Daten wurden am 2022-02-24, 17:21 CET, abgerufen.â†©ï¸\nwie diese Liste zeigt: https://www.quora.com/Which-organizations-use-R?share=1 zeigtâ†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/#category=Râ†©ï¸\nhttps://github.com/sebastiansauer/pradadataâ†©ï¸\nEin Daten-Dictionary findet sich hier: https://github.com/sebastiansauer/statistik1/raw/main/data/extra-dictionary.md.â†©ï¸\nhttps://www.linkedin.com/help/linkedin/answer/a510481â†©ï¸\n Ã¼ber diese Internetadresse: https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csvâ†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html",
    "href": "030-aufbereiten.html",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "4.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#einstieg",
    "href": "030-aufbereiten.html#einstieg",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "4.1.1 Lernziele\n\nSie kÃ¶nnen folgende Verben des Datenjudo anwenden: arrange, filter, select, summarise, group_by, mutate.\nSie kÃ¶nnen R-Befehle mit der â€œPfeifeâ€ verketten.\n\n\nÃœbungsaufgabe 4.1 (Mariokart importieren) Importieren Sie den Datensatz mariokart, s. Kapitel 3.7.3. Probieren Sie alle in diesem Kapitel vorgestellten Verben des Datenjudos aus, zunÃ¤chst, indem Sie einfach den R-Code kopieren und selber ausfÃ¼hren. Danach Ã¼berlegen Sie sich Varianten. \\(\\square\\)\n\n\n4.1.2 R-Code zum Copy-Pasten\nSie finden den R-Code fÃ¼r jedes Kapitel hier. \\(\\square\\)\n\n4.1.3 Frag den Bot\n\nğŸ§‘â€ğŸ“ ErklÃ¤re einem FÃ¼nfjÃ¤hrigen, warum Statistik nÃ¼tzlich ist.\n\n\nğŸ¤– Okay, hÃ¶r zu. Stell dir vor, du hast viele Spielzeugautos und du willst herausfinden, welches Auto am meisten bespielt wird. Du kannst jeden Tag zÃ¤hlen, wie oft du jedes Auto benutzt hast. Aber das wÃ¤re sehr mÃ¼hsam und kÃ¶nnte schnell durcheinander gebracht werden. Stattdessen kannst du mit Statistik eine einfachere Methode finden. Du kannst zum Beispiel eine Liste machen und jedes Auto mit einer bestimmten Farbe markieren. Dann kannst du jeden Tag einfach zÃ¤hlen, wie oft du jede Farbe verwendet hast. Am Ende kannst du herausfinden, welches Auto am meisten bespielt wurde, indem du siehst, welche Farbe am meisten verwendet wurde. Das ist ein Beispiel dafÃ¼r, wie Statistik uns dabei helfen kann, Muster in groÃŸen DatensÃ¤tzen zu finden und Entscheidungen zu treffen, ohne alles einzeln zu zÃ¤hlen.1\n\n\n4.1.4 Quiz zum Einstieg\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwa mittels der Plattform antworte.jetzt. Alternativ Ã¼berlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\nDefinition 4.1 (Datenjudo) Mit Datenjudo meint man den Prozess der Aufbereitens, Umformens oder Zusammenfassen von Daten, sowohl fÃ¼r einzelne Beobachtungen (Zeilen einer Datentabelle) oder Variablen (Spalten einer Datentabelle) oder einer ganzen Datentabelle. \\(\\square\\)\n\n\n4.1.5 Praxisbezug: Aus dem Alltag des Datenwissenschaftlers\nDenkt man an Data Science, stellt man sich coole Leute vor (in San Francisco oder Berlin), die an abgefahrenen Berechnungen mit hoch komplexen statistischen Modellen fÃ¼r gigantische Datenmengen basteln. Laut dem Harvard Business Review, verbringen Data Scientisten allerdings â€œ80\\(\\,\\)%â€ ihrer Zeit mit dem Aufbereiten von Daten (Bowne-Anderson, 2018). Ja: mit uncoolen TÃ¤tigkeiten wie Tippfehler aus DatensÃ¤tzen entfernen oder die Daten Ã¼berhaupt nutzbar und verstÃ¤ndlich zu machen.\nDas zeigt zumindest, dass das Aufbereiten von Daten a) wichtig ist und b) dass man allein damit schon weit kommen kann. Eine gute Nachricht ist (vielleicht), dass das Aufbereiten von Daten keine aufwÃ¤ndige Mathematik verlangt, stattdessen muss man ein paar Handgriffe und Kniffe kennen. Daher passt der Begriff Datenjudo vielleicht ganz gut. KÃ¼mmern wir uns also um das Aufbereiten bzw. Umformen von Daten, um das Datenjudo. ğŸ”¢ğŸ¤¹ \\(\\square\\)\n\nBeispiel 4.1 (Beispiel fÃ¼r Datenjudo) Beispiele fÃ¼r typische TÃ¤tigkeiten des Datenjudos sind:\n\nZeilen filtern (z.\\(\\,\\)B. nur Studierenden des Studiengangs X)\nZeilen sortieren (z.\\(\\,\\)B. Studierenden mit guten Noten in den oberen Zeilen)\nSpalten wÃ¤hlen (z.\\(\\,\\)B. 100 langweilige Spalten ausblenden)\nSpalten in eine Zahl zusammenfassen (z.\\(\\,\\)B. Notenschnitt der 1. Klausur)\nTabelle gruppieren (z.\\(\\,\\)B. Analyse getrennt nach Standorten)\nWerte aus einer Spalte verÃ¤ndern oder neue Spalte bilden (z.\\(\\,\\)B. Punkte in Prozent-Richtige umrechnen).\nâ€¦ \\(\\square\\)\n\n\n\n\n4.1.6 Machâ€™s einfach\nKlingt fast zu schÃ¶n, um wahr zu sein (s. AbbildungÂ 4.1).\n\n\n\n\n\nAbbildungÂ 4.1: Machâ€™s einfach (imgflip, 2024a)\n\n\nEs gibt einen (einfachen) Trick, wie man umfangreiche Datenaufbereitung elegant geregelt kriegt. Der Trick besteht darin, komplexe Operationen in mehrere einfache Teilschritte zu zergliedern. (In gewisser Weise besteht das Wesen einer Analyse eben darin: die Zerlegung eines Gegenstands in seine Bestandteile.) Man kÃ¶nnte vom â€œLego-Prinzipâ€ sprechen, s. AbbildungÂ 4.2. Im linken Teil von AbbildungÂ 4.2 sieht man ein (recht) komplexes Gebilde. Zerlegt man es aber in seine Einzelteile, so sind es deutlich einfachere geometrische Objekte wie Dreiecke oder Kreise (rechter Teil des Diagramms). Damit Sie es selber einfach machen kÃ¶nnen, mÃ¼ssen Sie selber Hand anlegen. Importieren Sie daher den Datensatz mariokart, s. Kapitel 3.7.3.\n\n\n\n\n\nAbbildungÂ 4.2: Das Lego-Prinzip (Sauer, 2019)\n\n\nWerfen wir einen Blick hinein (to glimpse):\n\nglimpse(mariokart)\n\n\nBeispiel 4.2 (Der Datenguru in Aktion) Sie arbeiten immer noch bei dem groÃŸen Online-Auktionshaus. Mittlerweile haben Sie sich den Ruf des â€œDatenguruâ€ erworben. Vielleicht, weil Sie behauptet haben, Data Science sei zu 80% Datenjudo, das hat irgendwie Eindruck geschindet â€¦ Naja, jedenfalls mÃ¼ssen Sie jetzt mal zeigen, dass Sie nicht nur schlaue SprÃ¼che draufhaben, sondern auch die Daten ordentlich abbÃ¼rsten kÃ¶nnen. Sie analysieren dafÃ¼r im Folgenden den Datensatz mariokart. Na, dann los. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#die-verben-des-datenjudos",
    "href": "030-aufbereiten.html#die-verben-des-datenjudos",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.2 Die Verben des Datenjudos",
    "text": "4.2 Die Verben des Datenjudos\nIm R-Paket dplyr, das wiederum Teil des R-Pakets tidyverse ist, gibt es eine Reihe von R-Befehlen, die das Datenjudo in eine Handvoll einfacher Verben herunterbrechen. (Falls Sie das R-Paket tidyverse noch nicht installiert haben sollten, wÃ¤re jetzt ein guter Zeitpunkt dafÃ¼r.) Die wichtigsten Verben des Datenjudos schauen wir uns im Folgenden an. Wir betrachten dazu im Folgenden einen einfachen (Spielzeug-)Datensatz, an dem wir zunÃ¤chst die Verben des Datenjudos vorstellen, s. TabelleÂ 4.1.\n\n\n\nTabelleÂ 4.1: Ein einfacher Datensatz von schlichtem GemÃ¼t\n\n\n\n\nid\nname\ngruppe\nnote\n\n\n\n1\nAnni\nA\n2.7\n\n\n2\nBerti\nA\n2.7\n\n\n3\nCharli\nB\n1.7\n\n\n\n\n\n\n\n\nDie Verben des Datenjudos wohnen im Paket dplyr, welches gestartet wird, wenn Sie library(tidyverse) eingeben. Falls Sie vergessen, das Paket tidyverse zu starten, dann funktionieren diese Befehle nicht.\n\n\n\n\n4.2.1 Tabelle sortieren: arrange\n\nSortieren der Zeilen ist eine einfache, aber hÃ¤ufige TÃ¤tigkeit des Datenjudos, s. AbbildungÂ 4.3.\n\n\n\n\n\n\n\nAbbildungÂ 4.3: Sinnbild fÃ¼r das Sortieren einer Tabelle mit arrange: Hier wurden die Noten aufsteigend sortiert.\n\n\n\n\n\nBeispiel 4.3 (Was sind die hÃ¶chsten Preise?) Sie wollen mal locker anfangen. Daher stellen Sie sich folgende Frage: Was sind denn eigentlich die hÃ¶chsten Preise, fÃ¼r die das Spiel Mariokart Ã¼ber den Online-Ladentisch geht? Die Spalte fÃ¼r den Verkaufsprei heiÃŸt offenbar total_pr (s. Datensatz mariokart). In Excel kann die Spalte, nach der man die Tabelle sortieren mÃ¶chte, einfach anklicken. Ob das in R auch so einfach geht?\nDie Funktion arrange macht es uns ziemlich einfach, s. TabelleÂ 4.2.\n\narrange(mariokart, total_pr)\n\n\nTabelleÂ 4.2: Die Datentabelle, (aufsteigend) sortiert nach total_pr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n2.6e+11\n1\n17\nused\n0.99\n0\n29\nstandard\n4982\nyes\n0\n\n\n1.2e+11\n1\n12\nused\n0.01\n0\n30\nstandard\n7284\nyes\n0\n\n\n2.6e+11\n1\n7\nused\n0.99\n0\n31\nstandard\n4982\nyes\n0\n\n\n3.2e+11\n7\n14\nused\n1.99\n0\n31\nmedia\n166\nyes\n0\n\n\n1.8e+11\n10\n3\nused\n30.00\n0\n31\npriority\n19\nno\n0\n\n\n1.1e+11\n1\n16\nused\n0.01\n0\n31\nstandard\n7284\nyes\n0\n\n\n\n\n\n\n\n\nÃœbersetzen wir die R-Syntax ins Deutsche:\nHey R,\narrangiere (sortiere) `mariokart` \nnach der Spalte `total_pr` (aufsteigend).\nGar nicht so schwer. \\(\\square\\)\n\nÃœbrigens wird in arrange per Voreinstellung aufsteigend sortiert. Setzt man ein Minus vor der zu sortierenden Spalte, wird umgekehrt, also absteigend sortiert:\n\nmario_sortiert &lt;- arrange(mariokart, -total_pr)\n\n\nÃœbungsaufgabe 4.2 Sortieren Sie die Mariokart-Daten absteigend nach der Anzahl der beigelegten LenkrÃ¤der. \\(\\square\\)\n\n\n4.2.2 Zeilen filtern: filter\n\nZeilen filtern bedeutet, dass man nur bestimmte Zeilen (Beobachtungen) behalten mÃ¶chte, die restlichen Zeilen brauchen wir nicht, weg mit ihnen. Wir haben also ein Filterkriterium im Kopf, anhand dessen wir die Tabelle filern, s. AbbildungÂ 4.4.\n\n\n\n\n\n\n\nAbbildungÂ 4.4: Sinnbild fÃ¼r das Filtern einer Tabelle mit filter: Gruppe B wurde entfernt, also wurde nach Gruppe A gefiltert.\n\n\n\n\n\nBeispiel 4.4 (Ob ein Foto fÃ¼r den Verkaufspreis nÃ¼tzlich ist?) Als nÃ¤chstes kommt Ihnen die Idee, mal zu schauen, ob Auktionen mit â€œStock-Photoâ€ Ware einen hÃ¶heren Verkaufspreis erzielen als Auktionen ohne solche Totos.\n\nmariokart_neu &lt;- filter(mariokart, stock_photo == \"yes\")\n\n\nmariokart_neu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4\n52\nstandard\n1580\nyes\n1\n\n\n2.6e+11\n7\n13\nused\n0.99\n4\n37\nfirstClass\n365\nyes\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4\n45\nstandard\n270144\nyes\n0\n\n\n1.2e+11\n1\n13\nused\n0.01\n0\n37\nstandard\n7284\nyes\n0\n\n\n\n\n\nSie filtern also die Tabelle so, dass nur diese Auktionen im Datensatz verbleiben, welche mind. ein Foto haben, mit anderen Worten, Auktionen (Beobachtungen) bei denen gilt: stock_photo == TRUE. \\(\\square\\)\n\nAngestachelt von Ihren Erfolgen mÃ¶chten Sie jetzt komplexere Hypothesen prÃ¼fen: Erzielen Auktionen von neuen Spielen und zwar mit Foto einen hÃ¶heren Preis als die Ã¼brigen Auktionen? Anders gesagt haben Sie zwei Filterkriterien im Blick: Neuheit cond und Foto stock_photo. Nur diejenigen Auktionen, die sowohl Neuheit als auch Foto erfÃ¼llen, mÃ¶chten Sie nÃ¤her untersuchen (Filtern mit dem logischen UND):\n\nmario_filter1 &lt;- \n  filter(mariokart,  # \"&\" heiÃŸt UND:\n         stock_photo == \"yes\" & cond == \"new\")\n\n\nmario_filter1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4\n52\nstandard\n1580\nyes\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4\n45\nstandard\n270144\nyes\n0\n\n\n3.0e+11\n1\n15\nnew\n1.00\n3\n54\nupsGround\n4858\nyes\n2\n\n\n2.9e+11\n1\n15\nnew\n1.00\n3\n55\nupsGround\n4858\nyes\n2\n\n\n\n\n\nHm. Was ist mit den Auktionen, die entweder Ã¼ber (mind.) ein Foto verfÃ¼gen oder auch neu sind, oder beides (Filtern mit dem logischen ODER)?\n\nmario_filter2 &lt;- \n  filter(mariokart,  # \"|\" heiÃŸt ODER:\n         stock_photo == \"yes\" | cond == \"new\")\n\n\nmario_filter2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4.0\n52\nstandard\n1580\nyes\n1\n\n\n2.6e+11\n7\n13\nused\n0.99\n4.0\n37\nfirstClass\n365\nyes\n1\n\n\n3.2e+11\n3\n16\nnew\n0.99\n3.5\n46\nfirstClass\n998\nno\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0.0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0.0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4.0\n45\nstandard\n270144\nyes\n0\n\n\n\n\n\nZur Erinnerung: Logische Operatoren sind in Kapitel 3.8 erlÃ¤utert.\n\nÃœbungsaufgabe 4.3 Hier kÃ¶nnte man noch viele interessante Hypothesen prÃ¼fen, denken Sie sich und tun das auch. \\(\\square\\)\n\n\nÃœbungsaufgabe 4.4 Filtern Sie die Spiele mit nur einem Lenkrad und ohne Versandkosten. \\(\\square\\)\n\n\nÃœbungsaufgabe 4.5 Filtern Sie die Spiele mit nur einem Lenkrad, die einen Ã¼berdurchschnittlichen Verkaufspreis erzielen. Tipp: Nutzen Sie die Funktion describe_distribution, um den Mittelwert einer Variable des Datensatzes zu erfahren (diese Funktion wohnt im R-Paket easystats). \\(\\square\\)\n\n\n4.2.3 Spalten auswÃ¤hlen mit select\n\nEine Tabelle mit vielen Spalten kann schnell unÃ¼bersichtlich werden. Da lohnt es sich, eine goldene Regel zu beachten: Mache die Dinge so einfach wie mÃ¶glich, aber nicht einfacher. WÃ¤hlen wir also nur die Spalten aus, die uns interessieren und entfernen wir die restlichen, s. AbbildungÂ 4.5 als Beispiel.\n\n\n\n\n\n\n\nAbbildungÂ 4.5: Sinnbild fÃ¼r das AuswÃ¤hlen von Spalten mit select\n\n\n\n\n\nBeispiel 4.5 (Fokus auf nur zwei Spalten) Ob wohl gebrauchte Spiele deutlich geringere Preise erzielen im Vergleich zu neuwertigen Spielen? Sie entschlieÃŸen sich, mal ein StÃ¼ndchen auf die relevanten Daten zu starren. DafÃ¼r wÃ¤hlen Sie mit select die relevanten Spalten aus. \\(\\square\\)\n\n\nmario_select1 &lt;- select(mariokart, cond, total_pr)\n\nDer Befehl select erwartet als Input eine Tabelle und gibt (als Output) eine Tabelle zurÃ¼ck â€“ genau wie die meisten anderen Befehle des Datenjudos. Auch wenn Sie nur eine Spalte auswÃ¤hlen, bleibt es eine Tabelle, eben eine Tabelle mit nur einer Spalte.\nselect erlaubt Komfort; Sie kÃ¶nnen Spalten auf mehrere Arten auswÃ¤hlen:\n\nselect(mariokart, 1, 2)  # Spalten 1 und 2\nselect(mariokart, 2:5)  #  Spalten 2 *bis* 5 \nselect(mariokart, -1)  # Alle Spalte *auÃŸer* Spalte 1\n\n\nÃœbungsaufgabe 4.6 WÃ¤hlen Sie die Spalten total_pr, cond sowie die zweite Spalte der Tabelle mariokart aus!2 \\(\\square\\)\n\nVertiefte Informationen zum AuswÃ¤hlen von Spalten mit select finden sich auf der Hilfeseite der Funktion.3\n\n4.2.4 Spalten zu einer Zahl zusammenfassen mit summarise\n\n\nBeispiel 4.6 (Was ist der mittlere Verkaufspreis?) Mit summarise, s. ListingÂ 4.1, kÃ¶nnen wir den mittleren Verkaufspreis der Mariokart-Spiele berechnen (50). \\(\\square\\)\n\nSo eine lange Spalte mit Zahlen â€“ mal ehrlich: Wer blickt da schon durch? Machen wir uns das Leben leichter, indem wir eine lange Spalte mit Zahlen zu einer einzigen Zahl zusammenfassen. Sagen wir, drei Studierende â€“ Anni, Berti, Charli â€“ haben eine Statistikklausur geschrieben. Die Noten waren 2.7, 2.7 und 1.7. Damit lag der Notenschnitt (der Mittelwert) bei 2.4; s. AbbildungÂ 4.6.\n\n\n\n\n\n\n\nAbbildungÂ 4.6: Spalten zu einer einzelnen Zahl zusammenfassen mit summarise: Hier wurden die Noten anhand des Mittelwerts zusammengefasst.\n\n\n\n\nFassen wir als NÃ¤chstes die Spalte total_pr zu einer Zahl zusammen, und zwar zum Mittelwert. Dann wissen wir, fÃ¼r welchen Preis ein Spiel im Durchschnitt verkauft wird, s. ListingÂ 4.1.\n\n\n\nListingÂ 4.1: Die R-Funktion summarise fasst einen Vektor zu einer einzelnen Zahl zusammen.\n\nmariokart_mittelwert &lt;- summarise(mariokart,\n                                  preis_mw = mean(total_pr))\nmariokart_mittelwert\n\n\n\n\n\n\npreis_mw\n\n\n50\n\n\n\n\nAha! Etwa 50 Dollar erzielte so eine Auktion im Durchschnitt. Ein bisschen abstrakter gesprochen fasst summarise eine Spalte zu einer (einzelnen) Zahl zusammen, s. ListingÂ 4.1.\nEine Alternative, um eine Spalte zu einer Zahl zusammenzufassen, bietet der â€œDollar-Operatorâ€ ($): mean(mariokart$total_pr). Der Dollar-Operator trennt hier die Tabelle von der Spalte: tibble$spalte. Im Gegensatz zu den Verben des Tidyverse (die immer einer Tabelle zurÃ¼ckliefern), liefert der Dollar-Operator einen Vektor (Spalte) zurÃ¼ck. (Diese wird von mean dann zu einer einzelnen Zahl zusammengefasst.)\nAuf welche Art zusammengefasst werden soll, z.\\(\\,\\)B. anhand des Mittelwerts oder Maximalwerts, muss noch zusÃ¤tzlich innerhalb von summarise angegeben werden.\n\n\nÃœbungsaufgabe 4.7 Identifizieren Sie den hÃ¶chsten Kaufpreis eines Mariokart-Spiels!4 \\(\\square\\)\n\n\nÃœbungsaufgabe 4.8 Identifizieren Sie den Mittelwert der Versandkostenpauschale!5 \\(\\square\\)\n\n\n4.2.5 Tabelle gruppieren\nEs ist ja gut und schÃ¶n, zu wissen, was so ein Spiel im Schnitt kostet. Aber viel interessanter wÃ¤re es doch, denken Sie sich, zu wissen, ob die neuen Spiele im Schnitt mehr kosten als die alten? Ob R Ihnen so etwas ausrechnen kann?\n\nğŸ§‘â€ğŸ“ Hallo R, kannst du mir die mittleren Verkaufspreise von alten und neuen Spielen ausrechnen?\n\n\nğŸ¤– Ich tue fast alles fÃ¼r dich. ğŸ§¡\n\nAlso gut, R, dann gruppiere die Tabelle, s. AbbildungÂ 4.7.\n\n\n\n\n\n\n\nAbbildungÂ 4.7: Gruppieren von DatensÃ¤tzen mit group_by: Hier wurde anhand der Variable gruppe gruppiert.\n\n\n\n\nDurch das Gruppieren wird die Tabelle in â€œTeiltabellenâ€ â€“ entsprechend der Gruppen â€“ aufgeteilt. Das sieht man der R-Tabelle aber nicht wirklich an. Aber alle nachfolgenden Berechnungen werden fÃ¼r jede Teiltabelle einzeln ausgefÃ¼hrt.\n\nBeispiel 4.7 (Mittlerer Preis pro Gruppe) Gruppieren alleine liefert Ihnen zwei (oder mehrere) Teiltabellen, etwa neue Spiele (Gruppe 1, new) vs.Â gebrauchte Spiele (Gruppe 2, used). Mit anderen Worten: Wir gruppieren anhand der Variable cond.\n\nmariokart_gruppiert &lt;- group_by(mariokart, cond)\n\nWenn Sie die neue Tabelle betrachte, sehen Sie wenig Aufregendes, nur einen Hinweis, dass die Tabelle gruppiert ist. Jetzt kÃ¶nnen Sie an jeder Teiltabelle Ihre weiteren Berechnungen vornehmen, etwa die Berechnung des mittleren Verkaufspreises.\n\nsummarise(mariokart_gruppiert, preis_mw = mean(total_pr))\n\n\n\ncond\npreis_mw\n\n\n\nnew\n54\n\n\nused\n47\n\n\n\n\n\nAh, die neuen Spiele sind teuerer, wer hÃ¤ttâ€™s gedacht! Langsam fÃ¼hlen Sie sich wie ein Datenchecker â€¦ ğŸ¥· ğŸ¦¹â€â™€\\(\\square\\)\n\n\nÃœbungsaufgabe 4.9 Â \n\n\nAufgabe\nLÃ¶sung\n\n\n\nBerechnen Sie den mittleren und maximalen Verkaufspreis getrennt fÃ¼r Spiele mit und ohne Foto!\n\n\n\nmariokart_gruppiert_foto &lt;- group_by(mariokart, stock_photo)\n\nmariokart_verkaufspreis_foto &lt;- \n  summarise(mariokart_gruppiert_foto,\n            total_pr_avg = mean(total_pr),\n            total_pr_max = max(total_pr))\n\nmariokart_verkaufspreis_foto\n\n\n\nstock_photo\ntotal_pr_avg\ntotal_pr_max\n\n\n\nno\n54\n327\n\n\nyes\n48\n75\n\n\n\n\n\n\n\n\nBei Auktionen mit Foto wird im Schnitt ein hÃ¶herer Preis erzielt als ohne Foto. \\(\\square\\)\n\n\n4.2.6 Spalten verÃ¤ndern mit mutate\n\nImmer mal wieder mÃ¶chte man Spalten verÃ¤ndern, bzw. deren Werte umrechnen, s. AbbildungÂ 4.8.\n\n\n\n\n\n\n\nAbbildungÂ 4.8: Spalten verÃ¤ndern/neu berechnen mit mutate\n\n\n\n\n\nBeispiel 4.8 Der Hersteller des Computerspiels Mariokart kommt aus Japan; daher erscheint es Ihnen opportun fÃ¼r ein anstehendes Meeting mit dem Hersteller die Verkaufspreise von Dollar in japanische Yen umzurechnen. Nach etwas Googeln finden Sie einen Umrechnungskurs von 1:133.\n\nmariokart_yen &lt;- \n  mutate(mariokart, total_pr_yen = total_pr * 133)\nmariokart_yen &lt;- select(mariokart_yen, total_pr_yen, total_pr)\nmariokart_yen |&gt; head()  # nur die ersten paar Zeilen\n\n\n\ntotal_pr_yen\ntotal_pr\n\n\n\n6856\n52\n\n\n4926\n37\n\n\n6052\n46\n\n\n5852\n44\n\n\n9443\n71\n\n\n5985\n45\n\n\n\n\n\nSicherlich werden Sie Ihre GesprÃ¤chspartner beeindrucken. \\(\\square\\)\n\nMit mutate berechnen Sie eine Spalte x (in einer Tabelle) neu. Die Funktion, die Sie in mutate benennen wird fÃ¼r jede Zeile der Spalte x angewendet.\n\nBeispiel 4.9 (Beispiele fÃ¼r Funktionen fÃ¼r mutate) mutate eignet sich, z.\\(\\,\\)B. um Spalten zu addieren, zu multiplizieren oder sonst wie zu transformieren (z.\\(\\,\\)B. den Logarithmus anwenden oder den Mittelwert der Spalte von jeder Zeile abziehen). \\(\\square\\)\n\n\nÃœbungsaufgabe 4.10 Â \n\n\nAufgabe\nLÃ¶sung\n\n\n\nRechnen Sie die Dauer der Auktionen von Tagen in Wochen um.\n\n\n\nmariokart_duration_wochen &lt;- \n  mutate(mariokart, duration_week = duration / 7)\n\nmariokart_duration_wochen &lt;-\n   select(mariokart_duration_wochen, duration, duration_week)\nmariokart_duration_wochen |&gt; head()  # nur die ersten paar Zeilen\n\n\n\nduration\nduration_week\n\n\n\n3\n0.43\n\n\n7\n1.00\n\n\n3\n0.43\n\n\n3\n0.43\n\n\n1\n0.14\n\n\n3\n0.43\n\n\n\n\n\n\n\n\n\n\nÃœbungsaufgabe 4.11 Â \n\n\nAufgabe\nLÃ¶sung\n\n\n\nRechnen Sie wieder die Dauer der Auktionen von Tagen in Wochen um, aber runden Sie die Wochen auf ganze Wochen.\n\n\n\nmariokart_duration_wochen &lt;- \n  mutate(mariokart, duration_week = duration / 7)\n\nmariokart_duration_wochen_gerundet &lt;-\n  mutate(mariokart_duration_wochen, duration_week_gerundet =\n           round(duration_week, digits = 0))\n\nmariokart_duration_wochen_schmal &lt;-\n  select(mariokart_duration_wochen_gerundet, duration, \n         duration_week, duration_week_gerundet)\nmariokart_duration_wochen_schmal |&gt; head()\n\n\n\nduration\nduration_week\nduration_week_gerundet\n\n\n\n3\n0.43\n0\n\n\n7\n1.00\n1\n\n\n3\n0.43\n0\n\n\n3\n0.43\n0\n\n\n1\n0.14\n0\n\n\n3\n0.43\n0\n\n\n\n\n\n\n\n\n\n\nğŸ§Ÿâ€â™€ï¸ï¸ Statist â€“ wann braucht man schon sowas!?\n\n\nğŸ¤– Eigentlich nur dann, wenn man die Fakten gut verstehen will, sonst nicht.\n\n\n4.2.7 Zeilen zÃ¤hlen mit count\n\nArbeitet man mit nominalskalierten Daten, ist (fast) alles, was man mit den Daten tun kann, die entsprechenden Zeilen der Tabelle zu zÃ¤hlen: Man kÃ¶nnte z.\\(\\,\\)B. fragen, wie viele neue und wie viele alte Spiele in der Tabelle (Dataframe) mariokart vorhanden sind.\n\nBeispiel 4.10 Nach der letzten PrÃ¤sentation Ihrer Analyse hat Ihre Chefin gestÃ¶hnt: â€œOh nein, alles so kompliziert. Statistik! Himmel hilf! Kann man das nicht einfacher machen?â€ Anstelle von irgendwelchen komplizierten Berechnungen (Mittelwert?) mÃ¶chten Sie ihr beim nÃ¤chsten Treffen nur zeigen, wie viele Computerspiele neu und wie viele gebraucht sind (in Ihrem Datensatz). Schlichte HÃ¤ufigkeiten also. Hoffentlich ist Ihre Chefin nicht wieder Ã¼berfordert â€¦\n\nmariocart_counted &lt;- count(mariokart, cond)\nmariocart_counted\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\nAha! Es gibt mehr gebrauchte als neue Spiele. \\(\\square\\)\n\nJetzt kÃ¶nnte man noch den Anteil (engl. proportion) ergÃ¤nzen: Welcher Anteil (der 143 Spiele in mariokart) ist neu, welcher gebraucht?\n\nmutate(mariocart_counted, Anteil = n / sum(n))\n\n\n\ncond\nn\nAnteil\n\n\n\nnew\n59\n0.41\n\n\nused\n84\n0.59\n\n\n\n\n\n\nÃœbungsaufgabe 4.12 ZÃ¤hlen Sie, wie viele der Auktionen ein Stock-Foto enthalten.6 \\(\\square\\)\n\n\nÃœbungsaufgabe 4.13 ZÃ¤hlen Sie Sie, wie viele Auktionen ein Foto enthalten â€“ innerhalb der gebrauchten Spiele und innerhalb der neuen Spiele. Anders gesagt: Teilen Sie den Datensatz sowohl nach Zustand als auch nach Foto auf und zÃ¤hlen Sie jeweils, wie viele Spiele/Auktionen in die jeweilige Gruppe gehÃ¶ren.7 \\(\\square\\)\n\n\n4.2.8 Verben am FlieÃŸband\nDie Befehle (â€œVerbenâ€) des Tidyverse sind jeweils fÃ¼r einzelne, typische Aufgaben des Datenaufbereitens (â€œDatenjudoâ€) zustÃ¤ndig. Typischerweise erwarten diese Befehle eine Tabelle () als Input und liefern eine Tabelle aus Output zurÃ¼ck, s. AbbildungÂ 4.9. Die Verben des Datenjudos werden beim â€œTidydatatutorâ€ anschaulich illustriert.8\n\n\n\n\n\nflowchart LR\n  A[\"â–¥\"] --&gt; B[tidyverse-Befehl] --&gt; C[\"â–¥\"] \n\n\n\n\nAbbildungÂ 4.9: Tidyverse-Befehle erwarten normalerweise eine Tabelle (â€œTibbleâ€) als Input und geben auch eine Tabelle zurÃ¼ck als Output",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#sec-pipe",
    "href": "030-aufbereiten.html#sec-pipe",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.3 Die Pfeife",
    "text": "4.3 Die Pfeife\nğŸš¬ ğŸ‘ˆDas ist keine Pfeife, wie RenÃ© Magritte 1929 in seinem berÃ¼hmten Bild schrieb, s. AbbildungÂ 4.10.\n\n\n\n\n\n\n\n\n\n\n\n\n%&gt;%\n\n\n\n\n|&gt;\n\n\n\n\n\n\nAbbildungÂ 4.10: So sieht die Pfeife in R aus (Jaja, das ist keine Pfeife, sondern ein Symbol einer Pfeife â€¦). Links: Ein Bild einer Pfeife (M7, 2004). Mitte und Rechts: Die zwei R-Symbole fÃ¼r eine â€œPfeifeâ€ (pipe).\n\n\n\n4.3.1 Russische Puppen\nComputerbefehle, und im Speziellen R-Befehle, kann man â€œaufeinanderâ€ â€“ oder vielmehr: ineinander â€“ stapeln, so Ã¤hnlich wie eine russische Puppe (vgl. Kapitel 3.6.3). Schauen wir uns das in einem Beispiel an. Dazu definieren wir zuerst einen Vektor x aus drei Zahlen:\n\nx &lt;- c(1, 2, 3)\n\nUnd dann kommt unser verschachtelter Befehl:\n\nsum(x - mean(x))\n## [1] 0\n\nWie schon erwÃ¤hnt, arbeitet R so einen â€œverschachteltenâ€ Befehl von innen nach auÃŸen ab:\nStart: sum(x - mean(x))\nâ¬‡ï¸ \nSchritt 1: sum(x - 2)\nâ¬‡ï¸ \nSchritt 2: sum(-1, 0, 1)\nâ¬‡ï¸ \nSchritt 3: 0. Fertig. Ganz schÃ¶n kompliziert!\nSoweit kann man noch einigermaÃŸen folgen. Aber das Verschachteln kann man noch extremer machen, dann wirdâ€™s wild. Schauen Sie sich mal folgende (Pseudo-)Syntax an:\n\n\nListingÂ 4.2: Eine wild verschachtelte Sequenz von Pseudo-Befehlen\n\nfasse_zusammen(\n  gruppiere(\n    wÃ¤hle_spalten(\n      filter_zeilen(meine_daten))))\n\n\n\nEin beliebter Fehler ist es Ã¼brigens, nicht die richtige Zahl an schlieÃŸenden Klammern hinzuschreiben, z.\\(\\,\\)B. d(c(b(a(meine_daten)). Falsche Zahl an Klammern!\n\n4.3.2 Die Pfeife zur Rettung\nListingÂ 4.2 ist schon harter Tobak, was fÃ¼r echte Fans. WÃ¤re es nicht einfacher, man kÃ¶nnte ListingÂ 4.2 wie folgt schreiben:\nNimm \"meine_daten\" *und dann*\n  filter die gewÃ¼nschte Zeilen *und dann*\n  wÃ¤hle die gewÃ¼nschte Spalten *und dann*\n  teile in Subgruppen *und dann*\n  fasse diese zusammen.\n\nDefinition 4.2 (Pfeife) â€œUnd dannâ€ heiÃŸt auf Errisch %&gt;% oder (synonym) |&gt;. Man nennt diesen Befehl â€œPfeifeâ€ (engl. pipe). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Befehl %&gt;% verknÃ¼pft Befehle. Der Shortcut fÃ¼r diesen Befehl ist Strg-Shift-M. Die Pfeife %&gt;% â€œwohntâ€ im Paket tidyverse.9\n\n\nMittlerweile (Seit R 4.1) ist auch im Standard-R eine Pfeife eingebaut. Die sieht so aus: |&gt;. Die eingebaute Pfeife funktioniert praktisch gleich zur anderen Pfeife, %&gt;%, hat aber den Vorteil, dass Sie nicht tidyverse starten mÃ¼ssen. Da wir tidyverse aber sowieso praktisch immer starten werden, bringt es uns keinen Vorteil, die neuere Pfeife des Standard-R |&gt; zu verwenden. Aber auch keinen Nachteil. Unter Tools &gt; Global Options â€¦ kÃ¶nnen Sie einstellen, welche der beiden Pfeifen-Varianten der Shortcut Strg-Shift-M verwenden soll.\n\n\n\n\n\nflowchart LR\n  A[\"â–¥\"] --filter&lt;br&gt;zeilen--&gt;B[\"â–¥\"] \n  B --wÃ¤hle&lt;br&gt;spalten--&gt; C[\"â–¥\"]\n  C --gruppiere--&gt; D[\"â–¥\"]\n  D --fasse&lt;br&gt;zusammen--&gt; E[\"â–¥\"]\n\n\n\n\nAbbildungÂ 4.11: Illustration fÃ¼r eine Pfeifensequenz, es geht vorwÃ¤rts wie am FlieÃŸband.\n\n\n\n\n\n\nListingÂ 4.3: Eine Pfeifen-Befehlssequenz (Pseudo-Syntax)\n\nmeine_daten %&gt;%\n  filter_gewÃ¼nschte_zeilen() %&gt;%\n  wÃ¤hle_gewÃ¼nschte_spalten() %&gt;%\n  gruppiere() %&gt;%\n  fasse_zusammen() \n\n\n\nUnd jetzt kommtâ€™s: So eine Art von Befehls-Verkettung gibt es in R. Schauen Sie sich mal ListingÂ 4.3 an im Vergleich zu ListingÂ 4.2. So eine Pfeifen-Befehlsequenz ist ein wie ein FlieÃŸband, an dem es mehrere Arbeitsstationen gibt, s. AbbildungÂ 4.11. Unser Datensatz wird am FlieÃŸband von Station zu Station weitergereicht und an jeder Stelle weiterverarbeitet. So kÃ¶nnte Ihre â€œPfeifen-Sequenzâ€ fÃ¼r den Mariokart-Datensatz aussehen, s. ListingÂ 4.4.\n\n\n\nListingÂ 4.4: Mariokart am FlieÃŸband: Die â€˜Pfeifen-Syntaxâ€™\n\n# Hey R, nimm die Tabelle \"mariokart\":\nmariokart %&gt;%  \n   # filter nur die gÃ¼nstigen Spiele:\n  filter(total_pr &lt; 100) %&gt;% \n  # wÃ¤hle die zwei Spalten:\n  select(cond, total_pr) %&gt;%  \n  # gruppiere die Tabelle nach Zustand des Spiels:\n  group_by(cond) %&gt;%  \n  # fasse beide Gruppen nach dem mittleren Preis zusammen:\n  summarise(total_pr_mean = mean(total_pr))  \n\n\n\n\n\nEndprodukt einer Pfeifen-Syntax\n\ncond\ntotal_pr_mean\n\n\n\nnew\n54\n\n\nused\n43\n\n\n\n\n\nDie Syntax filter(mariokart, total_pr &lt; 100) und die Syntax mariokart |&gt; filter(total_pr &lt; 100) sind identisch. Allgemeiner: d |&gt; f(x) = f(d, x).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#beispiele-fÃ¼r-forschungsfragen",
    "href": "030-aufbereiten.html#beispiele-fÃ¼r-forschungsfragen",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.4 Beispiele fÃ¼r Forschungsfragen",
    "text": "4.4 Beispiele fÃ¼r Forschungsfragen\nBevor Sie die LÃ¶sungen der folgenden Fallbeispiele lesen, versuchen Sie die Aufgaben selbst zu lÃ¶sen. Ja, ich weiÃŸ, es ist hart, nicht gleich auf die LÃ¶sungen zu schauen!\n\nÃœbungsaufgabe 4.14 (Das teuerste Spiel?) Sie arbeiten als strategischer Assistent der GeschÃ¤ftsfÃ¼hrerin und sind fÃ¼r Faktenchecks und andere Daten-Aufgaben zustÃ¤ndig. Heute sollen Sie zeigen, was Sie kÃ¶nnen (Schluck).\n\nğŸ‘© Ich wÃ¼rde von Ihnen gerne wissen, was das teuerste Spiel ist, aber jeweils fÃ¼r neue und gebrauchte Spiele. Aber nur fÃ¼r Spiele, die mit Foto verkauft wurden!\n\nLÃ¶sung\n\nmariokart %&gt;% \n  filter(stock_photo == \"yes\") %&gt;% \n  group_by(cond) %&gt;% \n  summarise(total_pr_max = max(total_pr))\n\n\n\ncond\ntotal_pr_max\n\n\n\nnew\n75\n\n\nused\n62\n\n\n\n\n\nDie Funktion max liefert den grÃ¶ÃŸten Wert eines Vektors zurÃ¼ck:\n\nx &lt;- c(1, 2, 10)\nmax(x)\n## [1] 10\n\nDas teuerste Spiel mit Foto kostet 75 Dollar, wenn es neu ist und 62, wenn es gebraucht ist. \\(\\square\\)\n\n\nÃœbungsaufgabe 4.15 (Die mittlere Versandpauschale?) Â \n\nğŸ‘© Ich wÃ¼rde gerne die mittlere Versandpauschale wissen, aber getrennt nach Anzahl der LenkrÃ¤der, die dem Spiel beigelegt sind. Und ich will nur Gruppen berÃ¼cksichtigen, die aus mindestens 10 Spielen bestehen!\n\nLÃ¶sung\nWenn wir die Anzahl der Spiele zÃ¤hlen in AbhÃ¤ngigkeit der beigelegten LenkrÃ¤der (wheels), bekommen wir eine Tabelle mit zwei Spalten: wheels und n. n zÃ¤hlt, wie viele Spiele (Zeilen) in der jeweiligen Gruppe (â€œTeiltabelleâ€) von wheels sind.\n\nmariokart %&gt;%\n  count(wheels)\n\n\n\nwheels\nn\n\n\n\n0\n37\n\n\n1\n52\n\n\n2\n51\n\n\n3\n2\n\n\n4\n1\n\n\n\n\n\nAus dieser Tabelle sehen wir, dass 3 oder 4 LenkrÃ¤der nur selten (2 bzw. 1 Mal) beigelegt wurden und wir solche Spiele herausfiltern sollten, bevor wir den Mittelwert der Versandkosten ausrechnen:\n\nmariokart %&gt;%\n  filter(wheels &lt; 3) %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(mittlere_versandkosten = mean(ship_pr),\n            anzahl_spiele = n())\n\n\n\nwheels\nmittlere_versandkosten\nanzahl_spiele\n\n\n\n0\n2.7\n37\n\n\n1\n3.6\n52\n\n\n2\n2.9\n51\n\n\n\n\n\nDie Funktion n gibt die Anzahl der Zeilen pro Teiltabelle zurÃ¼ck.\nDie mittleren Versandkosten bewegen sich also zwischen 2.7 Dollar und 3.6 Dollar, je nach Anzahl der beigelegten LenkrÃ¤der. \\(\\square\\)\n\n\nÃœbungsaufgabe 4.16 (Verkaufspreis in Yen?) Â \n\nğŸ‘© Ich wÃ¼rde gerne den Verkaufspreis in Yen wissen, nicht in Euro. Dann rechne mal den mittleren Verkaufspreis aus und ziehe 10 % ab, die wir als Provision unseren VerkÃ¤ufern zahlen mÃ¼ssen.\n\nLÃ¶sung\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  mutate(total_pr_yen = total_pr * 133) %&gt;% \n  summarise(\n    preis_yen_mw = mean(total_pr_yen),\n    preis_yen_mw_minus_10proz = preis_yen_mw - 0.1*preis_yen_mw)\n\n\n\npreis_yen_mw\npreis_yen_mw_minus_10proz\n\n\n6634\n5971\n\n\n\n\nWie man sieht kann man in summarise auch mehr als eine Berechnung einstellen. In diesem Fall haben wir zwei Berechnungen angestellt: Einmal den Mittelwert und einmal den Mittelwert minus 10% (des Mittelwerts).\n\n\nÃœbungsaufgabe 4.17 (Do It Yourself) Denken Sie sich selber Ã¤hnliche Forschungsfragen aus. Stellen Sie diese einer vertrauenswÃ¼rdigen Kommilitonen bzw. einem vertrauenswÃ¼rdigen Kommilitonen. DIY! Schauen Sie, ob Ihre Aufgabe richtig gelÃ¶st wird. PrÃ¼fen Sie streng â€¦ \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#praxisbezug",
    "href": "030-aufbereiten.html#praxisbezug",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.5 Praxisbezug",
    "text": "4.5 Praxisbezug\nDie Covid19-Epidemie hatte weltweit massive Auswirkungen; auch psychologischer Art wie Vereinsamung, Angst oder Depression. Mulukom et al. (2020) berichten eine Studie, die die psychologischen Auswirkungen untersucht; die Studie ist unter der Projekt-ID tsjnb bei der Open Science Foundation (OSF), &lt;https://osf.io/tsjnb/&gt;, angemeldet. Die Daten wurden mit R ausgewertet. Beispielhaft ist unter https://osf.io/4b9p2 die R-Syntax zu sehen, die die Autoren zur Datenaufbereitung verwendet haben. Einen guten Teil dieser Syntax kennen Sie aus diesem Kapitel. Diese Studie ist, neben einigen vergleichbaren, ein schÃ¶nes Beispiel, wie Forschung und Praxis ineinander greifen kÃ¶nnen: Angewandte Forschung als Beitrag zur LÃ¶sung eines akuten Problems, der Corona-Pandemie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "030-aufbereiten.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.6 Wie man mit Statistik lÃ¼gt",
    "text": "4.6 Wie man mit Statistik lÃ¼gt\nEin (leider) immer mal wieder zu beobachtender â€œTrickâ€, um Daten zu frisieren ist, nur die Daten zu berichten, die einem in den Kram passen.\n\nBeispiel 4.11 Eine Analystin ğŸ‘© mÃ¶chte zeigen, dass der Verkaufspreis von Mariokart-Spielen â€œviel zu niedrigâ€ ist. Es muss ein hÃ¶herer Wert rauskommen, findet die Analystin. Der mittlere Verkaufspreis (im Datensatz mariokart) liegt bei 50 Euro.\n\nğŸ‘© Kann man den Wert nicht â€¦ â€œkreativ verbessernâ€? Ein paar Statistik-Tricks anwenden?\n\nUm dieses Ziel zu erreichen, teilt die Analystin den Datensatz in Gruppen nach Anzahl der dem Spiel beigelegten LenkrÃ¤der (wheels). Dann wird der Mittelwert pro Gruppe berechnet.\n\nmariokart_wheels &lt;- \nmariokart %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_mean = mean(total_pr),\n            count_n = n())  # `n` gibt die Anzahl der Zeilen pro Gruppe an\n\nmariokart_wheels\n\n\n\nwheels\npr_mean\ncount_n\n\n\n\n0\n41\n37\n\n\n1\n44\n52\n\n\n2\n61\n51\n\n\n3\n70\n2\n\n\n4\n65\n1\n\n\n\n\n\nSchlieÃŸlich berechnet unsere Analystin den ungewichteten Mittelwert Ã¼ber diese 5 Gruppen:\n\nmariokart_wheels %&gt;% \n  summarise(mean(pr_mean))\n\n\n\nmean(pr_mean)\n\n\n56\n\n\n\n\nUnd das Ergebnis lautet: 56 Euro! Das ist doch schon etwas â€œbesserâ€ als 50 Euro.\nNatÃ¼rlich ist es falsch und irrefÃ¼hrend, hier einen ungewichteten Mittelwert zu berechnen. Der gewichtete Mittelwert wÃ¼rde wiederum zum korrekten Ergebnis, 50 Euro, fÃ¼hren. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallstudien",
    "href": "030-aufbereiten.html#fallstudien",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.7 Fallstudien",
    "text": "4.7 Fallstudien\n\n4.7.1 Die Pinguine\n\n\n\n\n\nAbbildungÂ 4.12: Possierlich: Die Pinguine (Horst, 2024)\n\n\n\nÃœbungsaufgabe 4.18 Machen Sie sich zunÃ¤chst mit dem Pinguin-Datensatz vertraut. Sie finden den Datensatz penguins im R-Paket palmerpenguins, das Sie auf gewohnte Art installieren kÃ¶nnen (vgl. Kapitel 3.4); im Internet findet man den Datensatz auch als CSV-Datei. Fokussieren Sie Ihre Analyse auf die Zielvariable Gewicht. \\(\\square\\)\n\nDie folgende Datenapp ermÃ¶glicht Ihnen, die Verteilung des KÃ¶rpergewichts zu betrachten, wobei sie die Pinguin-Spezies filtern kÃ¶nnen sowie eine MindestlÃ¤nge des Schnabels verlangen kÃ¶nnen.\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\nData\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"data/penguins.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\nBearbeiten Sie die Fallstudie zu Pinguinen von Allison Horst. Sie kÃ¶nnen die Teile auslassen, die Themen beinhalten, die nicht in diesem Kapitel vorgestellt wurden.\nForschungsfragen:\n\nWas ist das mediane Gewicht von Pinguinen, gruppiert nach Spezies und nach Gewicht?\nWie viele Pinguine gibt es pro Spezies?\nWie viel wiegt der schwerste und der leichteste Pinguin pro Spezies?\n\n4.7.2 Fallstudie COVIDiSTRESS\n\n\n\nStudie COVIDiSTTRESS (Lieberoth et al., 2022)\n\nLesen Sie die Beschreibung der Studie COVIDiSTRESS (Lieberoth et al., 2022). Hier ist ein Abstract:\n\nThe COVIDiSTRESS global survey is an international collaborative undertaking for data gathering on human experiences, behavior and attitudes during the COVID-19 pandemic. In particular, the survey focuses on psychological stress, compliance with behavioral guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures, but multiple further items and scales are included for descriptive statistics, further analysis and comparative mapping between participating countries. Round one data collection was concluded May 30. 2020. To gather comparable data swiftly from across the globe, when the Coronavirus started making a critical impact on societies and individuals, the collaboration and survey was constructed as an urgent collaborative process. Individual contributors and groups in the COVIDiSTRESS network (see below) conducted translations to each language and shared online links by their own best means in each country.\n\nDie Daten stehen unter https://osf.io/z39us zur freien VerfÃ¼gung. Sie kÃ¶nnen diese echten Daten eigenstÃ¤ndig analysieren.\nDiese Datei beinhaltet die finalen, aufbereiteten Daten. Achtung: Die Datei ist recht groÃŸ, ca. 90 MB.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#aufgaben",
    "href": "030-aufbereiten.html#aufgaben",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.8 Aufgaben",
    "text": "4.8 Aufgaben\n\n\n\n\n\n\nChatGPT\n\n\n\nNutzen Sie einen Chat-Bot wie ChatGPT, um sich Hilfe fÃ¼r die R-Syntax geben zu lassen.\n\n\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nwrangle3\nwrangle4\nwrangle5\nwrangle7\nwrangle9\nwrangle10\ntidydata1\naffairs-dplyr\ndplyr-uebersetzen\nhaeufigkeit01\nmariokart-mean1\nmariokart-mean2\nmariokart-mean3\nmariokart-mean4\nmariokart-max1\nmariokart-max2\nfilter01\naffairs-dplyr\nsummarise01\nsummarise02\nmutate01\nwrangle3",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#vertiefung",
    "href": "030-aufbereiten.html#vertiefung",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.9 Vertiefung",
    "text": "4.9 Vertiefung\n\n4.9.1 Fortgeschrittenes R\n\n\n\n\n\n\nHinweis\n\n\n\nIn weiterfÃ¼hrendem Material werden Sie immer wieder auf Inhalte treffen, die Sie noch nicht kennen, die etwa noch nicht im Unterricht behandelt wurden. Seien Sie unbesorgt: In der Regel kÃ¶nnen Sie diese Inhalte einfach auslassen, ohne den Anschluss zu verlieren. Einfach ignorieren.\n\n\nHÃ¤ufig ist es nÃ¼tzlich, die Werte einer Variablen umzukodieren, z.\\(\\,\\)B. â€œweiblichâ€ in â€œwâ€ oder in 0. Eine gute MÃ¶glichkeit, dies in R umzusetzen, bietet der Befehl case_when; der Befehl wohnt im Tidyverse.10 Im Datenwerk finden Sie dazu Ãœbungen, etwa mutate03.\n\n4.9.2 Hilfe?! Erbie!\nR will nicht, so wie Sie wollen? Sie haben das GefÃ¼hl, R verweigert stÃ¶rrisch den Dienst, vermutlich rein aus Boshaftigkeit, rein um Sie zu Ã¤rgern? AusfÃ¼hrliches Googeln und ChatGPT befragen hat keine LÃ¶sung gebracht? Kurz, Sie brauchen die Hilfe eines kundigen Menschens? Sie sollten Ihren Hilfeschrei so artikulieren, dass er nicht nur gehÃ¶rt, sondern auch verstanden wird und einen anderen Menschen veranlasst und ermÃ¶glicht, Ihnen zu helfen.\nAlso: Sie mÃ¼ssen Ihr Problem nachvollziehbar, aber prÃ¤gnant formulieren. Das nennt man auch ein ERBie: ein einfaches, reproduzierbares Beispiel Ihres Problems mit (R-)Syntax:\n\n\neinfach: die einfachste Syntax, die Ihr Problem bzw. die Fehlermeldung produziert. Es bietet sich an, einen einfachen, allgemein bekannten Datensatz zu verwenden, etwa mtcars\n\n\nreproduzierbar: Code (z.\\(\\,\\)B. als Textdatei oder in einem Post), der die Fehlermeldung entstehen lÃ¤sst\n\n\nBeispiel 4.12 (Beispiel fÃ¼r ein Erbie) Problem: Ich verstehe nicht, warum folgende Fehlermeldung kommt.\nZiel: Ich mÃ¶chte die Automatikautos filtern (am = 0).\nWas ich schon versucht habe: Ich habe folgende Posts gelesen â€¦, aber ohne Erfolg.\nErbie:\n\ndata(mtcars)\nlibrary(dplyr)  # nicht \"tidyverse\", denn \"dplyr\" reicht\n\nmtcars %&gt;% \n  filter(am = 0)  # den kÃ¼rzesten Code, der Ihren Fehler entstehen lÃ¤sst!\n\nsessionInfo()  # gibt Infos zur R-Version etc. aus\n\nError in `filter()`\nMit dem Paket reprex kann man sich R-Syntax schÃ¶n formuliert ausgeben lassen. Das ist perfekt, um den Code dann in einem Forum (oder Mail) einzustellen. DafÃ¼r mÃ¼ssen Sie nur den Code auswÃ¤hlen, Strg-c drÃ¼cken und dann reprex::reprex ausfÃ¼hren. Mit Strg-v kÃ¶nnen Sie die schÃ¶n formatierte Syntax (sowie die Ausgabe, auch schÃ¶n formatiert) dann irgendwohin pasten.\n\n\n\n\nHelp me help you (imgflip, 2024b)\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\nPosten Sie Ihr Erbie bei https://gist.github.com/ als â€œpublic gistâ€. Hier ist ein Beispiel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.9.3 Zertifikate und Online-Kurse\nSie kÃ¶nnen zu den Inhalten dieses Kapitels Zertifikate erwerben (teilweise kostenlos), indem Sie einen Online-Kurs absolvieren, bei z.\\(\\,\\)B. folgenden Anbietern â€“ Das ist keine Werbung fÃ¼r spezifische Anbieter und kein umfassender Ãœberblick und keine Kaufempfehlung.\n\nLinkedIn: R Courses\nGoogle/Coursera: Data Analysis with R Programming\nDuke University/Coursera: Data Analysis with R Specialization",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#exkurs",
    "href": "030-aufbereiten.html#exkurs",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.10 Exkurs",
    "text": "4.10 Exkurs\nDall-E 2 ist eine KI, die â€œrealistische Bilder und Kunst aus einer Beschreibung in natÃ¼rlicher Spracheâ€ erstellt.\n\nğŸ‘¨â€ğŸ« Iâ€™d like a mixture between robot und professor, in oil painting\n\n\nğŸ¤– â€¦ s. AbbildungÂ 4.13\n\n\n\n\n\n\nAbbildungÂ 4.13: Bild erzeugt von kÃ¼nstlicher Intelligenz, Quelle: DALL-E 2, 2023-02-09\n\n\nDer Nutzen kÃ¼nstlicher Intelligenz fÃ¼r die Datenanalyse ist natÃ¼rlich breiter: Wenn Sie sich z.\\(\\,\\)B. Ã¼ber die Syntax eines bestimmten Befehls (oder allgemeiner: Vorhabens) nicht sicher sind, fragen Sie sich doch mal einen Bot wie ChatGPT.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literaturhinweise",
    "href": "030-aufbereiten.html#literaturhinweise",
    "title": "\n4Â  Daten umformen\n",
    "section": "\n4.11 Literaturhinweise",
    "text": "4.11 Literaturhinweise\nSauer (2019), Kap. 7, gibt eine EinfÃ¼hrung in die Datenaufbereitung (mit Hilfe von R), Ã¤hnlich zu den Inhalten dieses Kapitels. Mehr in die Tiefe des â€œDatenjudoâ€ fÃ¼hren; der Autor Hadley Wickham ist in der R-Community sehr bekannt. Er ist einer der Hauptautoren von beliebten R-Paketen wie dplyr und ggplot2. Wickham & Grolemund (2018) Kap. 5 behandeln (etwas ausfÃ¼hrlicher) die Themen dieses Kapitels.\nWer sich tiefer in das Datenjudo mit dem Tidyverse einarbeiten mÃ¶chte, dem sei z.\\(\\,\\)B. dieser Kurs empfohlen.\n\n\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do, According to 35 Data Scientists. Harvard Business Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024a). Imageflip One does not simply [Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Tom Cruise Meme [Artwork]. https://imgflip.com\n\n\nLieberoth, A., Rasmussen, J., Stoeckli, S., Tran, T., Ä†epuliÄ‡, D.-B., Han, H., Lin, S.-Y., Tuominen, J., Travaglino, G., & Vestergren, S. (2022). COVIDiSTRESS Global Survey. https://doi.org/10.17605/OSF.IO/Z39US\n\n\nM7. (2004). Savinelliâ€™s Italian Smoking Pipe [Artwork]. https://commons.wikimedia.org/wiki/File:Pipa_savinelli.jpg\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, & Farias, M. (2020). Psychological Impact of COVID-19 Pandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., & Grolemund, G. (2018). R fÃ¼r Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren (F. Langenau, Ãœbers.). Oâ€™Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#footnotes",
    "href": "030-aufbereiten.html#footnotes",
    "title": "\n4Â  Daten umformen\n",
    "section": "",
    "text": "Quelle: ChatGTP 3.5, 2023-02-09â†©ï¸\nselect(mariokart, total_pr, cond, 2)â†©ï¸\nhttps://tidyr.tidyverse.org/reference/tidyr_tidy_select.htmlâ†©ï¸\nsummarise(mariokart, hoechster_preis = max(total_pr))â†©ï¸\nsummarise(mariokart, mw_versand = mean(total_pr))â†©ï¸\ncount(mariokart, stock_photo)â†©ï¸\ncount(mariokart, stock_photo, cond)â†©ï¸\nhttps://tidydatatutor.comâ†©ï¸\nGenauer gesagt im Paket magrittr, welches aber von tidyverse geladen wird. Also nichts, um das Sie sich kÃ¼mmern mÃ¼ssten.â†©ï¸\nhttps://www.statology.org/dplyr-case_when/â†©ï¸",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#einstieg",
    "href": "040-verbildlichen.html#einstieg",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Lernziele\n\nSie kÃ¶nnen erlÃ¤utern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arten von Datendiagrammen.\nSie kÃ¶nnen typische Datendiagramme mit R visualisieren.\nSie kÃ¶nnen zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.2 BenÃ¶tigte R-Pakete und Daten\nNeben den Ã¼blichen Paketen tidyverse (Wickham et al., 2019) und easystats (LÃ¼decke et al., 2022) benÃ¶tigen Sie in diesem Kapitel noch DataExplorer (Cui, 2024) und optional ggpubr (Kassambara, 2023) und ggstatsplot (Patil, 2021). Wir arbeiten wieder mit dem Datensatz mariokart, s. Kapitel 3.7.3.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\nlibrary(ggpubr)  # optional, Datenvisualisierung\nlibrary(ggstatsplot)  # optional, Datenvisualisierung\n\n\n5.1.3 Quiz zum Einstieg\n\n\n\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwa mittels der Plattform antworte.jetzt. Alternativ Ã¼berlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Wozu das alles?\n\n\nGroÃŸe Aufgaben warten â€¦ (imgflip, 2024)\n\n\nğŸ¥· Wir mÃ¼ssen die Galaxis retten, Kermit!\n\n\nğŸ¸ Schlock",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heiÃŸt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte (Fitzmaurice, 2017). In AbbildungÂ 5.1 sieht man verschiedene â€œBilderâ€, also DatensÃ¤tze: etwa einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschieden sind, sind die zentralen statistischen Kennwerte (praktisch) identisch. In dieselbe Bresche schlÃ¤gt â€œAnscombes Quartettâ€ (Anscombe, 1973). Es zeigt vier DatensÃ¤tze, in denen die zentralen Statistiken fast identisch sind, also Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthÃ¼llt, was der Statistik (als Kennzahl) verhÃ¼llt bleibt. Statistische Diagramme kÃ¶nnen Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. Unter visueller Cortex ist sehr leistungsfÃ¤hig. Wir kÃ¶nnen ohne MÃ¼he eine groÃŸe Anzahl an visuellen Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen. Nutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mÃ¤chtig.\n\n\n\n\n\nAbbildungÂ 5.1: Dinosaurier und Kreis: Gleiche statistische Kennwerte (Fitzmaurice, 2017)\n\n\nAbbildungÂ 5.2 zeigt Anscombes Quartett.\n\n\n\n\n\nAbbildungÂ 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier DatensÃ¤tzen\n\n\n\nDefinition 5.1 (Datendiagramm) Ein Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwÃ¤ndiges (und ansprechendes) Datendiagramm) Â \n\n\nAuf Basis des Korruptionsindex von Transparency International (2017) erstellt Wilke (2024) ein Diagramm zum Zusammenhang vom Entwicklungsindex (Lebenserwartung, Bildung, Einkommen; vgl. Hou et al. (2015)) und Korruption, jeweils auf Landesebene, s. AbbildungÂ 5.3.\nEs finden sich in der Literatur (im Internet) viele weitere Beispiele fÃ¼r handwerklich meisterhaft erstelle Datendiagramme, die in vielen FÃ¤llen mit R erstellt werden (vgl. Scherer et al., 2019). \\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.3: Der Zusammenhang von Entwicklungindex und und Korruption\n\n\n\n\n\nAbbildungÂ 5.4 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer â€œDimensionâ€ entsprechen. Wie man (nicht) sieht, wird es langsam unÃ¼bersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die â€œDimensionalitÃ¤tâ€ eines Diagramms hat ihre Grenzen, vielleicht bei vier bis sechs Variablen. MÃ¶chten wir den Zusammenhang von vielen Variablen verstehen, kommen wir mit Bildern oft nicht weiter. Dann brauchen wir andere Werkzeuge: Statistik, komm zu Hilfe. Bei klaren ZusammenhÃ¤ngen und wenig Variablen braucht man keine (aufwÃ¤ndige) Statistik. Ein Bild, also ein Datendiagramm, ist dann oft ausreichend. Man kÃ¶nnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. vier bis sechs Variablen nicht gleichzeitig umgehen kann.\n\n\n\n\n\n\n\nAbbildungÂ 5.4: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\n\n\nÃœbungsaufgabe 5.1 Wie viele Variablen sind in AbbildungÂ 5.4 dargestellt?1",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelleÂ 5.1 zeigt eine â€“ sehr kurze Nomenklatur â€“ von Datendiagrammen. Weitere Nomenklaturen sind mÃ¶glich, aber wir halten hier die Sache einfach. Wer an Vertiefung interessiert ist, findet bei data-to-vis einen Ãœberblick Ã¼ber verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur: https://www.data-to-viz.com/.\n\n\n\nTabelleÂ 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefÃ¼lltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefÃ¼lltes Balkendiagramm\nBoxplot",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung einer nominalen Variable\n\nDefinition 5.2 (Verteilung) Eine (HÃ¤ufigkeits-)Verteilung einer Variablen \\(X\\) schlÃ¼sselt auf, wie hÃ¤ufig jede AusprÃ¤gung von \\(X\\) ist. \\(\\square\\)\n\n\nBeispiel 5.2 TabelleÂ 5.2 zeigt die HÃ¤ufigkeitsverteilung von cond (condition, also der Zustand des Artikels, neu oder gebraucht) aus dem Datensatz mariokart. Die Variable hat 2 AusprÃ¤gungen; z.\\(\\,\\)B. kommt die AusprÃ¤gung new 59 mal vor. \\(\\square\\)\n\n\n\n\nTabelleÂ 5.2: HÃ¤ufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. AbbildungÂ 5.5. Wie man sieht, besteht so ein Diagramm aus Balken, daher heiÃŸt es Balkendiagramm. Man kann so ein Diagramm um 90\\(\\,\\)Â° drehen, s. AbbildungÂ 5.5; keine Ausrichtung ist grundsÃ¤tzlich besser als die andere.\n\nDefinition 5.3 (Balkendiagramm) Ein Balkendiagramm ist eine grafische Darstellung von Werten, zumeist fÃ¼r die HÃ¤ufigkeiten bestimmter Kategorien, also AusprÃ¤gungen nominaler Variablen. Dabei werden rechteckige Balken verwendet, und die LÃ¤nge eines Balkens ist proportional zur dargestellten HÃ¤ufigkeit. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) horizontale Balken\n\n\n\n\n\n\n\n\n\n(b) vertikale Balken\n\n\n\n\n\n\nAbbildungÂ 5.5: HÃ¤ufigkeitsverteilung der Variable cond\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. AbbildungÂ 5.5; wir betrachten gleich die Syntax. Zuerst importieren wir die Daten, s. ListingÂ 3.2. AuÃŸerdem nicht vergessen, das Paket DataExplorer mit dem Befehl library zu starten. (NatÃ¼rlich mÃ¼ssen Sie das Paket einmalig installiert haben, bevor Sie es starten kÃ¶nnen.) In diesem Paket â€œwohnenâ€ die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden. ListingÂ 5.1 zeigt die Syntax, um ein Balkendiagramm zu erstellen. Auf der Hilfeseite der Funktion finden Sie weitere Details zur Funktion.\n\n\n\nListingÂ 5.1: Syntax zur Erstellung eines Balkendiagramms\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.6: Ein Balkendiagramm. Unglaublich.\n\n\n\n\nDie Syntax ist in ListingÂ 5.1 abgedruckt (Zur Erinnerung: %&gt;% nennt man die â€œPfeife und lÃ¤sst sich alsâ€und dannâ€ Ã¼bersetzen, vgl. Kapitel 4.3). Ãœbersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz `mariokart` *und dann*\n  wÃ¤hle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm. Fertig!\n\nÃœbungsaufgabe 5.2 (Spalten wÃ¤hlen fÃ¼r das Balkendiagramm) HÃ¤tten wir andere Spalten ausgewÃ¤hlt, so wÃ¼rde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie kÃ¶nnen auch mehrere Variablen auf einmal auswÃ¤hlen. Probieren Sie das doch mal aus! \\(\\square\\)\n\n\nÃœbungsaufgabe 5.3 (Visualisieren Sie die Verteilung von stock_photo!) Erstellen Sie ein geeignetes Diagramm, um die HÃ¤ufigkeit jeder AusprÃ¤gung von stock_photo (Datensatz mariokart) darzustellen.\nLÃ¶sung\n\nmariokart |&gt; \n  select(stock_photo) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\nMit plot_bar aus DataExplorer kann man Balkendiagramme darstellen. \\(\\square\\)\n\n\n\n5.4.2 Verteilung einer quantitativen Variable\nBei einer quantitativen Variablen mit vielen AusprÃ¤gungen wÃ¤re ein Balkendiagramm nicht so aussagekrÃ¤ftig, s. AbbildungÂ 5.7 (links). Es gibt einfach zu viele AusprÃ¤gungen.\nDie LÃ¶sung: Wir reduzieren die Anzahl der AusprÃ¤gungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger AusprÃ¤gungen zu bekommen, kÃ¶nnen wir einfach Gruppen definieren, z.\\(\\,\\)B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 3: 11-15 Dollar\nâ€¦\n\nIn AbbildungÂ 5.7 (rechts) sind z.\\(\\,\\)B. die AusprÃ¤gungen des Verkaufspreises (total_pr) in Gruppen der Breite von 5 Dollar aufgeteilt worden. ZusÃ¤tzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\n\n\n(a) Balkendiagramm\n\n\n\n\n\n\n\n\n\n(b) Histogramm\n\n\n\n\n\n\nAbbildungÂ 5.7: Balkendiagramm vs.Â Histogramm fÃ¼r den Gesamtpreis (total_pr)\n\n\n\nDefinition 5.4 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der HÃ¤ufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt werden. Die HÃ¶he der Balken zeigt die HÃ¤ufigkeit der Daten in dieser Gruppe/in diesem Balken (bei konstanter Balkenbreite).\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten werder sehr viele noch zu wenige sein, s. AbbildungÂ 5.8 (links) bzw. AbbildungÂ 5.8 (rechts). Zur Erstellung eines Histogramms kÃ¶nnen Sie die Syntax ListingÂ 5.2 nutzen, vgl. AbbildungÂ 5.9, links.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildungÂ 5.8: Nicht zu wenig und nicht zu viele Balken im Histogramm\n\n\n\n\n\nListingÂ 5.2: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 5.9: Eine stetige Verteilung verbildlichen\n\n\n\nÃœbungsaufgabe 5.4 (Visualisieren Sie die Verteilung von ship_pr anhand eines Histogramms!) Â \n\nmariokart |&gt; \n  select(ship_pr) |&gt; \n  plot_histogram()\n\n\n\n\n\n\n\n\nAbbildungÂ 5.10 fÃ¼gt zum Histogramm ein Dichtediagramm hinzu (durchgezogene Linie). Ein Dichtediagramm Ã¤hnelt einem â€œglattgeschmirgeltenâ€ Histogramm.\n\nDefinition 5.5 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglÃ¤ttet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden. (Mit Dichte ist die relative Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.)\n\n\n\n\n\n\n\n\nAbbildungÂ 5.10: Histogramm und Dichtediagramm (Linie) fÃ¼r total_pr\n\n\n\n\n\nÃœbungsaufgabe 5.5 Erstellen Sie das Diagramm AbbildungÂ 5.9, rechtes Teildiagramm!2\\(\\square\\)\n\nVerteilungen unterscheiden sich z.\\(\\,\\)B. in ihrem â€œtypischenâ€ oder â€œmittlerenâ€ Wert (vgl. Kapitel 6.5), aber auch in ihrer Streuung (vgl. Kapitel 7.3). (Diagramme von) Verteilungen kÃ¶nnen symmetrisch oder schief (nicht symmetrisch) sein, s. AbbildungÂ 5.11. AbbildungÂ 5.12 zeigt verschiedene Formen von Verteilungen. â€œBimodalâ€ meint â€œzweigipfligâ€ und â€œmultimodalâ€ entsprechend â€œmehrgipfligâ€.3\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildungÂ 5.11: Symmetrische vs.Â schiefe Verteilung, verbildlicht\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.12: Verschiedene Verteilungsformen\n\n\n\n\n\nÃœbungsaufgabe 5.6 (Verteilungsform von total_pr?) Benennen Sie die am besten passende Verteilungsform fÃ¼r die Variable total_pr.\nLÃ¶sung\n\nmariokart |&gt; \n  select(total_pr) |&gt; \n  plot_density()\n\n\n\n\n\n\n\nDie Verteilung ist rechtsschief. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#spezialfall-normalverteilung",
    "href": "040-verbildlichen.html#spezialfall-normalverteilung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.5 Spezialfall Normalverteilung",
    "text": "5.5 Spezialfall Normalverteilung\n\n5.5.1 Grundlagen\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer stetigen quantitativen Variablen. Aber sie ist besonders wichtig, und wird daher hier besonders hervorgehoben. Eine Normalverteilung sehen Sie in AbbildungÂ 5.11, links. Die Normalverteilung ist in der Statistik von hoher Bedeutung, da sie sich unter (recht hÃ¤ufigen) Bedingungen zwangslÃ¤ufig ergeben muss und vielseitig Verwendung findet.\n\nDefinition 5.6 (Normalverteilung) Normalverteilungen haben eine charakteristische symmetrische Glockenform. Normalverteilungen kÃ¶nnen sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden GrÃ¶ÃŸen (â€œParameterâ€) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. AbbildungÂ 5.13. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\\(\\square\\)\n\nEine normalverteilte Zufallsvariable \\(X\\) mit einem bestimmten Mittelwert und einer bestimmten Streuung schreibt man kurz so:\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma)\\]\n\n\n\n\n\nAbbildungÂ 5.13: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\n\nBeispiel 5.3 Beispiele fÃ¼r normalverteilte Variablen sind KÃ¶rpergrÃ¶ÃŸe von MÃ¤nnern oder Frauen, IQ-Werte, einige PrÃ¼fungsergebnisse, Messfehler, Lebensdauer von GlÃ¼hbirnen, Gewichte von Brotlaiben, Milchproduktion von KÃ¼hen, Brustumfang schottischer Soldaten (Lyon, 2014). \\(\\square\\)\n\n\nDefinition 5.7 (Normalverteilung) Eine Normalverteilung ist eine spezielle Art von Verteilung einer quantitativen Variablen. Sie ist symmetrisch, glockenfÃ¶rmig, stetig, unimodal und ihr Mittelwert, Median und Modus identisch. Sie lÃ¤sst sich durch zwei Parameter vollstÃ¤ndig beschreiben: Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)). \\(\\square\\)\n\n\n\n\n\nAbbildungÂ 5.14 zeigt interaktive Beispiele fÃ¼r Normalverteilung. WÃ¤hlen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler.4\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\nshow_curve = true\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.14: Interaktives Beispiel fÃ¼r Normalverteilungen.\n\n\n\n5.5.2 FlÃ¤che unter der Kurve\nKennt man die beiden Parameter der Normalverteilung, Mittelwert und Streuung (SD, \\(\\sigma\\)), einer Normalverteilung, so kann man einfach angeben, welcher Anteil der FlÃ¤che (unter der Kurve) der Normalverteilung sich in einem bestimmten Bereich befindet, s. AbbildungÂ 5.15.\nDavon leitet sich die â€œ68-95-99.7-Prozentregelâ€ ab, die angibt, in welchem Bereich sich welcher Anteil der FlÃ¤che befindet:\n\n\n\\(68\\,\\%\\) im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{.}7\\,\\%\\) im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildungÂ 5.15: Die FlÃ¤cheninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in AbhÃ¤ngigkeit der Streuung (Ainali, 2007)\n\n\n\n5.5.3 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. AbbildungÂ 5.16:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nÃœbungsaufgabe 5.7 (Wie schlau muss man (nicht) sein?) Â \n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehÃ¶ren?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, â€¦ der Leute nicht Ã¼berschritten?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 5.16: Visualisierung der theoretischen IQ-Verteilung\n\n\n\n5.5.4 Vertiefung: Entstehung einer Normalverteilung\n\nDefinition 5.8 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhÃ¤ngiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\n\n\n\nDie Entstehhung einer Normalverteilung kann man gut anhand des Galton-Bretts veranschaulichen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhÃ¤nge-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.6 ZusammenhÃ¤nge verbildlichen",
    "text": "5.6 ZusammenhÃ¤nge verbildlichen\n\n5.6.1 Zusammenhang nominaler Variablen\n\nBeispiel 5.4 (Beispiele fÃ¼r ZusammenhÃ¤nge bei nominalen Variablen) Â \n\nHÃ¤ngt Berufserfolg (FÃ¼hrungskraft ja/nein) mit dem Geschlecht zusammen?\nHÃ¤ngt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen der bevorzugten Automarke und der PrÃ¤ferenz fÃ¼r eine politische Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primÃ¤r bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. AbbildungÂ 5.17. TatsÃ¤chlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (AbbildungÂ 5.17, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der HÃ¤lfte der FÃ¤lle.\n\n\n\n\n\n\n\n\n\n\n(a) starker Zusammenhang\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) schwacher Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 5.17: Zusammenhang zwischen nominalskalierten Variablen verbildlichen. (a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten. (b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\nAnders sieht es aus fÃ¼r die Frage, ob ein (oder mehrere) LenkrÃ¤der dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach â€œFoto des Produkts dabeiâ€ betraf (AbbildungÂ 5.17, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten). Bildlich gesprochen: Unterscheiden sich die â€œFÃ¼llhÃ¶heâ€ in den Diagrammen, so gibt es einen Unterschied hinsichtlich â€œFoto ist dabeiâ€ zwischen den beiden Gruppen (linker vs.Â rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs.Â gebrauchte Spiele), so spielt z.\\(\\,\\)B. die Variable â€œFoto dabeiâ€ offenbar eine Rolle. Dann hÃ¤ngen Neuwertigkeit und â€œFoto dabeiâ€ also zusammen!\nSo kÃ¶nnen Sie sich in R ein gefÃ¼lltes Balkendiagramm ausgeben lassen, z.\\(\\,\\)B. mit plot_bar(mariokart, by = \"cond\") (Paket DataExplorer). Diese Darstellung eignet sich, um ZusammenhÃ¤nge zwischen zwei zweistufigen nominalskalierten Variablen zu verbildlichen. Die verschiedenen Werte der FÃ¼llfarbe werden den Stufen der Variablen cond zugewiesen, s. ListingÂ 5.3.\n\n\n\nListingÂ 5.3: R-Syntax fÃ¼r ein gefÃ¼lltes Balkendiagramm\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.18: Ein gefÃ¼lltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\nGefÃ¼llte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei AusprÃ¤gungen aufweisen, sonst sind die ZusammenhÃ¤nge nicht mehr so gut zu erkennen. AuÃŸerdem sollten die Balken auf gleiche LÃ¤nge (100%) ausgerichtet sein.\n\nÃœbungsaufgabe 5.8 (Zusammenhang visualisieren) Visualisieren Sie den Zusammenhang der beiden nominalen Variablen cond und wheels!\n\nmariokart |&gt; \n  # Mache aus einer metrischen eine nominale Variable: \n  mutate(wheels = factor(wheels)) |&gt; \n  select(cond, wheels) |&gt; \n  plot_bar(by = \"cond\")\n\nLÃ¶sung\nwheels ist als metrische Variable (int: Integer, d.\\(\\,\\)h. Ganzzahl) formatiert im Datensatz mariokart. Wir mÃ¼ssen Sie zunÃ¤chst als Faktorvariable umformatieren, damit R sie als nominal skalierte Variable erkennt. \\(\\square\\)\n\n\n5.6.2 Zusammenhang bei metrischen Variablen\nDen Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). AbbildungÂ 5.19 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine â€œTrendgeradeâ€ (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schlieÃŸen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je hÃ¶her der Startpreis, desto hÃ¶her der Abschlusspreis, zumindest tendenziell. Diese Gerade verlÃ¤uft â€œmittigâ€ in den Daten (wir definieren das spÃ¤ter genauer). Diese Trendgerade gibt Aufschluss Ã¼ber â€œtypischeâ€ Werte: Welcher Y-Wert ist â€œtypischâ€ fÃ¼r einen bestimmten X-Wert? AbbildungÂ 5.19 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis (tendenziell). Das erkennt man an der sinkenden Trendgeraden. Die Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. AbbildungÂ 5.21.\n\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) negativer, schwacher Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 5.19: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\n\nDefinition 5.9 (Linearer Zusammenhang) LÃ¤sst sich die Beziehung zweier Variablen gut mit einer Geraden beschreiben, so spricht man von einem linearen Zusammenhang. Ã„ndert man eine der beiden Variablen um einen bestimmten Wert (z.\\(\\,\\)B. 1), so Ã¤ndert sich die andere um einen proportionalen Wert (z.\\(\\,\\)B. 0.5). Gleichsinnige (positive) ZusammenhÃ¤nge erkennt man an aufsteigenden Trendgeraden \\(\\nearrow\\); gegensinnige (negative) ZusammenhÃ¤nge an absteigenden Trendgeraden \\(\\searrow\\). \\(\\square\\)\n\nNatÃ¼rlich kÃ¶nnte man auch nicht-lineare ZusammenhÃ¤nge untersuchen, aber der Einfachheit halber konzentrieren wir uns hier auf lineare; Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge sind in AbbildungÂ 5.20 zu sehen.\n\n\n\n\n\n\n\nAbbildungÂ 5.20: Beispiele nichtlinearer ZusammenhÃ¤nge\n\n\n\n\nStarke ZusammenhÃ¤nge erkennt man an schmalen Ellipsen (â€œBaguetteâ€ ğŸ¥–); schwache ZusammenhÃ¤nge an breiten Ellipsen (â€œTorteâ€ ğŸ¥®). AbbildungÂ 5.21 bietet einen Ãœberblick Ã¼ber verschiedene Beispiele von Richtung und StÃ¤rke von ZusammenhÃ¤ngen.5 In AbbildungÂ 5.21 ist fÃ¼r jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und StÃ¤rke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht fÃ¼r einen positiven Zusammenhang, ein negatives Vorzeichen fÃ¼r einen negativen Zusammenhang. Der (Absolut-)Wert gibt die StÃ¤rke des linearen Zusammenhangs an. Cohen (1992) hat folgende Faustregeln angegeben:\n\n\n\\(r\\approx 0\\): Kein Zusammenhang\n\n\\(r \\pm .1\\): schwacher Zusammenhang\n\n\\(r \\pm .3\\): mittlerer Zusammenhang\n\n\\(r \\pm .5\\): starker Zusammenhang\n\n\\(r = 1\\): perfekter Zusammenhang\n\n\n\n\n\n\n\n\nAbbildungÂ 5.21: Lineare ZusammenhÃ¤nge verschiedener StÃ¤rke und Richtung\n\n\n\n\nAbbildungÂ 5.22 hat die gleiche Aussage wie AbbildungÂ 5.21, ist aber plakativer, indem StÃ¤rke (schwach, stark) und Richtung (positiv, negativ) gegenÃ¼bergestellt sind. Man sieht in AbbildungÂ 5.21 und AbbildungÂ 5.22, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade (synonym: Regressionsgerade; blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke ZusammenhÃ¤nge mit einer schmalen Ellipse einhergehen und schwache ZusammenhÃ¤nge mit einer breiten Ellipse einhergehen.\n\n\n\n\n\n\n\nAbbildungÂ 5.22: Ãœberblick Ã¼ber starke vs.Â schwache bzw. positive vs.Â negative ZusammenhÃ¤nge\n\n\n\n\nAbbildungÂ 5.23 zeigt interaktive Beispiele fÃ¼r (lineare) ZusammenhÃ¤nge.6\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 5.23: Interaktives Beispiel fÃ¼r Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und manchmal gehÃ¶rt Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhÃ¤ngen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. AuÃŸerdem mÃ¼ssen wir noch die Daten importieren, falls noch nicht getan, s. ListingÂ 3.2. So, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf einige metrische Variablen konzentrieren wollen, wÃ¤hlen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewÃ¤hlten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primÃ¤r interessiert. Das Ergebnis sieht man in AbbildungÂ 5.24. \\(\\square\\)\n\n\nmariokart %&gt;% \n  select(n_bids, start_pr, total_pr) %&gt;% \n  plot_scatterplot(by = \"total_pr\", nrow = 1)\n\n\n\n\n\n\nAbbildungÂ 5.24: Der Zusammenhang einiger metrischer Variablen mit Abschlusspreis\n\n\n\n\nAha. Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafÃ¼r sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur VerkÃ¤ufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100), s. ListingÂ 5.4.\n\n\n\nListingÂ 5.4: Mariokart ohne Extremwerte\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n\n\n\nDas Ergebnis ist in AbbildungÂ 5.25 zu sehen.\n\nmariokart_no_extreme %&gt;% \n  select(duration, n_bids, start_pr, \n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildungÂ 5.25: Der Zusammenhang metrischer Variablen mit Abschlusspreis - ohne Extremwerte\n\n\n\n\nOhne Extremwerte schÃ¤lt sich ein deutlicheres Bild hervor: Startpreis (start_pr) und Anzahl der RÃ¤der (wheels) scheinen am stÃ¤rksten mit dem Abschlusspreis zusammenzuhÃ¤ngen. Das Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle Ã¼brigen Variablen kommen jeweils einmal als X-Variable vor. \\(\\square\\)\n\nÃœbungsaufgabe 5.9 Â \n\n\nZuammenhang visualisieren\nLÃ¶sung\n\n\n\nVisualisieren Sie den Zusammenhang der beiden metrischen Variablen start_pr und total_pr. Verwenden Sie den Datensatz ohne Extremwerte wie oben definiert.\n\n\n\nmariokart_no_extreme |&gt; \n  select(start_pr, total_pr) |&gt; \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\n\nZuerst wÃ¤hlt man die Spalten (mit select), die man visualisieren mÃ¶chte, dann ruft man die Funktion plot_scatterplot auf. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.7 Unterschiede verbildlichen",
    "text": "5.7 Unterschiede verbildlichen\n\n5.7.1 Unterschiede bei nominalen Variablen\nGute Nachrichten: FÃ¼r nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von ZusammenhÃ¤ngen als auch von Unterschieden an. Genau genommen zeigt ja AbbildungÂ 5.17 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Fotos beiliegen. Und wie man in AbbildungÂ 5.17 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen hÃ¶her als bei gebrauchten Spielen.\nAber Freunde lassen Freunde keine Tortendiagramme verwenden.\n\n5.7.2 Unterschiede bei quantitativen Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich (substanziell) unterscheiden. So untersucht man z.\\(\\,\\)B. oft, ob sich die Mittelwerte zweier Gruppen hinsichtlich der Zielvariablen deutlich unterscheiden. Das hÃ¶rt sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. AbbildungÂ 5.26.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildungÂ 5.26: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von AbbildungÂ 5.26 zeigt das Histogramm von total_pr, getrennt fÃ¼r neue und gebrauchte Spiele, vgl. AbbildungÂ 5.9. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsform, den Boxplot.7 Was ein â€œdeutlicherâ€ (substanzieller, bedeutsamer, relevanter oder signifikanter) Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\n\nDefinition 5.10 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms. Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar. \\(\\square\\)\n\nIn AbbildungÂ 5.27 sieht man die â€œÃœbersetzungâ€ von Histogramm (oben) zu einem Boxplot (unten). Ob der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack Ã¼berlassen.\n\n\n\n\n\n\n\nAbbildungÂ 5.27: Ãœbersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die â€œAnatomieâ€ des Boxplots nÃ¤her an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto grÃ¶ÃŸer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie â€œAntennenâ€ des Boxplots zeigen die Streuung in den kleinsten 25\\(\\,\\)% der Werte (linke Antenne) bzw. die Streuung der grÃ¶ÃŸten 25\\(\\,\\)% der Werte (rechte Antenne). Je lÃ¤nger die Antenne, desto grÃ¶ÃŸer die Streuung (in den Ã¤uÃŸeren Vierteln).\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, auÃŸerhalb der Antennen gezeigt werden. Daher ist die AntennenlÃ¤nge auf die 1.5-fache LÃ¤nge der Box beschrÃ¤nkt. Werte die auÃŸerhalb dieses Bereichs liegen (also mehr als das 1.5-fache der BoxlÃ¤nge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50\\(\\,\\)% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.\\(\\,\\)h. sie ist schief). Gleiches gilt fÃ¼r die AntennenlÃ¤ngen: Sind die Antennen gleich lang, so ist der Ã¤uÃŸere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der LenkrÃ¤der untersucht. Jetzt mÃ¶chten Sie eine sehr Ã¤hnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten LenkrÃ¤der? Flink erstellen Sie dazu folgendes Diagramm, AbbildungÂ 5.28, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl LenkrÃ¤der (by = \"wheels\"). \\(\\square\\)\n\nAber ganz glÃ¼cklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wÃ¤re eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen wÃ¼rde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von AbbildungÂ 5.28) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert. Vielleicht wird so gruppiert, dass in jeder Gruppe gleich viele Werte sind? Aber wir mÃ¶chten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir mÃ¶chten wheels als nominale Variable definieren. Das kann man mit dem Befehl factor(wheels) erreichen (verpackt in mutate), s. AbbildungÂ 5.28 rechts.\n\nmariokart_no_extreme |&gt; \n  select(total_pr, wheels) %&gt;% \n  # Probieren Sie den Code mit bzw. ohne folgender Zeile:\n  mutate(wheels = factor(wheels)) |&gt;  # wheels als nominale Variable\n  plot_boxplot(by = \"wheels\")  # Boxplot mit \"wheels\" auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildungÂ 5.28: Abschlusspreis nach Anzahl von beigelegten LenkrÃ¤dern\n\n\nSie schlieÃŸen aus dem Bild, dass LenkrÃ¤der und Preis (positiv) zusammenhÃ¤ngen. Allerdings scheint es wenig Daten fÃ¼r wheels == 4 zu geben. Das prÃ¼fen Sie nach:\n\nmariokart_no_extreme %&gt;% \n  count(wheels)\n\n\n  \n\n\n\nTatsÃ¤chlich gibt es (in mariokart_no_extreme) auch fÃ¼r 3 LenkrÃ¤der schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten. Ãœbrigens bezeichnet Sie Ihre Chefin nur noch als â€œDatengottâ€.\n\nÃœbungsaufgabe 5.10 (Visualisieren Sie den Unterschied im Verkaufspreis zwischen gebrauchten und neuen Spielen.) Es gibt mehrere Diagrammtypen, die sich anbieten; mehrere LÃ¶sungen sind also mÃ¶glich.\nLÃ¶sung\n\nmariokart_no_extreme |&gt; \n  select(cond, total_pr) |&gt; \n  plot_boxplot(by = \"cond\")\n\n\n\n\n\n\n\nBoxplots sind eine gute MÃ¶glichkeit, die Verteilung einer metrischen Variablen, aufgebrochen auf mehrere Gruppen, zu visualisieren. \\(\\square\\)\n\n\n\nÃœbungsaufgabe 5.11 (Verkaufspreis im Vergleich) Visualisieren Sie den Unterschied im Verkaufspreis abhÃ¤ngig von ship_pr; betrachten Sie ship_pr als ein Gruppierungsvariable. Interpretieren Sie das Ergebnis.\nLÃ¶sung\n\nmariokart_no_extreme |&gt; \n  select(ship_pr, total_pr) |&gt; \n  plot_boxplot(by = \"ship_pr\")\n\n\n\n\n\n\n\nplot_boxplot gruppiert metrische Variablen, wie ship_pr automatisch in fÃ¼nf Gruppen (mit gleichen Ranges). Wir mÃ¼ssen also nichts tun, um die metrische Variable ship_pr in eine Gruppierungsvariable (Faktorvariable) umzuwandeln. Es sieht so aus, als wÃ¼rde der Median zwischen den Gruppen leicht steigen, mit Ausnahme der mittleren Gruppe. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lÃ¼gt-man-mit-statistik",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.8 So lÃ¼gt man mit Statistik",
    "text": "5.8 So lÃ¼gt man mit Statistik\nDiagramme werden mitunter eingesetzt, um die Wahrheit â€œaufzuhÃ¼bschenâ€. Achsen zu stauchen, ist ein recht beliebter Trick, s. AbbildungÂ 5.30. NatÃ¼rlich kann man auch durch â€œAbschneidenâ€ der Y-Achse einen eindrucksvollen Effekt erzielen, s. AbbildungÂ 5.31. Scheinkorrelationen als â€œechteâ€, also kausale Effekte zu verkaufen, ist ein anderer Trick, den man immer mal wieder beobachten kann. Ein Beispiel: Messerli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: LÃ¤nder), s. AbbildungÂ 5.29. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?) Leider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhÃ¤ngen, heiÃŸt das nicht, dass die eine Variable die Ursache und die andere die Wirkung sein muss. So kÃ¶nnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In hÃ¶her entwickelten LÃ¤ndern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu LÃ¤ndern mit geringerem Entwicklungsstand.\n\n\n\n\n\nAbbildungÂ 5.29: Schokoladenkonsum und Nobelpreise\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.30: Strecken und Stauchen der Achse(n), um mit Statistik zu lÃ¼gen\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildungÂ 5.31: Abschneiden der Y-Achse, um mit Statistik zu lÃ¼gen",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.9 Praxisbezug",
    "text": "5.9 Praxisbezug\nEin, wie ich finde, schlagendes Beispiel zur StÃ¤rke von Datendiagrammen ist AbbildungÂ 5.32. Das Diagramm zeigt die HÃ¤ufigkeit von Masern, vor und nach der EinfÃ¼hrung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurÃ¼ck.\n\n\n\n\n\nAbbildungÂ 5.32: HÃ¤ufigkeit von Masern und Impfung in den USA (Moore, 2015)\n\n\nIn der â€œfreien Wildbahnâ€ findet man hÃ¤ufig sog. â€œTortendiagrammeâ€. Zwar sind sie beliebt, doch von ihrer Verwendung ist zumeist abzuraten, denn bei TortenstÃ¼cken ist es schwer, die GrÃ¶ÃŸe zu vergleichen.\nFreunde lassen Freunde keine Tortendiagramme zeichnen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2\nvis-gapminder\nboxplots-de1a\ndiamonds-histogramm-vergleich\nwozu-balkendiagramm\ndiamonds-histogram\nn-vars-diagram\n\nWeitere Aufgaben zum Thema Datenvisualisierung finden Sie im Datenwerk unter dem Tag vis.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.11 Vertiefung",
    "text": "5.11 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\n\n5.11.1 Animation\nEine weitere nÃ¼tzliche Art von Visualisierung sind Karten, 3D-Bilder und Animationen. So zeigt z.\\(\\,\\)B. AbbildungÂ 5.33 die VerÃ¤nderung der Lebenserwartung (in Jahren) Ã¼ber die letzten Dekaden.8\n\n\n\n\n\nAbbildungÂ 5.33: Animation zur VerÃ¤nderung der Lebenserwartung\n\n\nIn einigen Situation kÃ¶nnen Animationen zweckdienlich sein. AuÃŸerdem sind sie mitunter nett anzuschauen, s. AbbildungÂ 5.34.\n\n\n\n\n\nAbbildungÂ 5.34: VerÃ¤nderung des Zusammenhangs von Lebenserwartung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatÃ¼rlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animation ziemlich beeindruckend. 9\n\n5.11.2 Schicke Diagramme\nEin Teil der Diagramme dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMÃ¶chte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median herausstellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.\\(\\,\\)B.) mit ggpubr und der Funktion ggviolin, s. AbbildungÂ 5.35.\n\nggviolin(mariokart_no_extreme, \n         x = \"cond\", y = \"total_pr\", add = \"mean_sd\") \n\n\n\n\n\n\nAbbildungÂ 5.35: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nWeitere Varianten zum Violinenplot mit ggpubr finden sich hier.10\nEin â€œViolinenplotâ€ hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die â€œViolineâ€, desto mehr Beobachtungen gibt es an dieser Stelle. Ãœbrigens sind Modelle â€“ und Diagramme sind Modelle â€“ immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen.\nDieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.11 Ein weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heiÃŸt ggstatsplot.12 AbbildungÂ 5.36 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.13\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart_no_extreme,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrÃ¼ckt statist. Details\n)\n\n\n\n\n\n\nAbbildungÂ 5.36: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. MÃ¶chte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE. (Weitere Hinweise finden sich auf der Hilfeseite der Funktion der Funktion.)\n\nğŸ‘©â€ğŸ« Ich wÃ¼rde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\nğŸ§‘â€ğŸ“ Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.14\n\n\n5.11.3 Farbwahl\nEinige Ãœberlegungen zur Farbwahl findet sich bei Wilke (2019), Kap. 4. Die Farbpalette von Okabe und Ito ist (vgl. Ichihara et al., 2008) empfehlenswert, das sie Ã¼ber Ã¼ber optisch gut unterscheidbarer und klar benennbare Farben verfÃ¼gt. AuÃŸerdem erlaubt sie bei SehschwÃ¤chen die Farben noch recht gut zu unterscheiden, s. AbbildungÂ 5.37. MÃ¶chte man sie fÃ¼r Schwarz-WeiÃŸ-Druck verwenden, kann man angeben, dass als erste Farbe Schwarz verwendet werden soll; dazu nutzt man den Paramter palette = \"black_first\". Alternativ kann man hÃ¤ndisch eine helle Farbe und eine dunkle Farbe als Kontrast aussuchen.\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\", notch = TRUE) +\n  scale_fill_okabeito(palette = \"black_first\")\n  #scale_fill_manual(values = c(\"#0072B2\", \"#E69F00\"))\n\n\n\n\n\n\nAbbildungÂ 5.37: Die Farbpalette von Okabe und Ito: Geeignet bei Farbseh-SchwÃ¤chen. AuÃŸerdem nett anzuschauen. Die Einkerbungen (engl. notches) zeigen ein 95%-Konfidenzintervall fÃ¼r den Median.\n\n\n\n\nMit fill = cond erreicht man, dass die FÃ¼llfarbe der Variable cond zugeordnet wird: Jeder Wert von cond (new/used) bekommt eine eigene Farbe. Welche das ist, hÃ¤ngt vom verwendeten Farbschema ab. Hier wird das Farbscheme von Okabe und Ito verwendet (Ichihara et al., 2008).\n\nÃœbungsaufgabe 5.12 Schauen Sie sich die Farbpalette von Okabe und Ito einmal nÃ¤her an, z.\\(\\,\\) so:\n\nlibrary(scales)\nlibrary(see)\nshow_col(okabeito_colors())\n\nDie FÃ¼llfarbe eines Diagramms, z.\\(\\,\\) in AbbildungÂ 5.37, kÃ¶nnen Sie Ã¤ndern, indem Sie scale_fill_okabeito ersetzen durch scale_fill_manual(values = c(\"#0072B2\", \"#E69F00\")). Probieren Sie dabei verschiedene Farben aus. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise",
    "href": "040-verbildlichen.html#literaturhinweise",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "\n5.12 Literaturhinweise",
    "text": "5.12 Literaturhinweise\nSowohl ggpubr (Kassambara, 2023) als auch DataExplorer (Cui, 2024) (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 (Wickham, 2016) auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2016). Eine neuere, gute EinfÃ¼hrung in Datenvisualisierung findet sich bei Wilke (2019). Beide BÃ¼cher sind kostenfrei online lesbar. Wilke (2019) gibt einen hervorragenden Ãœberblick Ã¼ber praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In Ã¤hnlicher Richtung geht Fisher & Meyer (2018).\nHier ist eine Liste von BÃ¼chern zum Thema; dort kÃ¶nnen Sie bei Interesse tiefer suchen.\n\n\n\n\nAinali. (2007). Standard Deviation Diagram Micro [Artwork]. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17â€“21.\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155â€“159.\n\n\nCui, B. (2024). DataExplorer: Automate Data Exploration and Treatment. https://CRAN.R-project.org/package=DataExplorer\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight. Oâ€™Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The Dynamics of Human Development Index. The Social Science Journal, 52(3), 331â€“347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206â€“213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024). Imageflip Kermit Meme [Artwork]. https://imgflip.com\n\n\nInternational, T. (2017, Januar 25). Corruption Perceptions Index 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nKassambara, A. (2023). ggpubr: â€™ggplot2â€™ Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr\n\n\nLÃ¼decke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., ThÃ©riault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nMoore, B. (2015, April 9). Recreating the Vaccination Heatmaps in R. Benomics. https://benjaminlmoore.wordpress.com/2015/04/09/recreating-the-vaccination-heatmaps-in-r/\n\n\nPatil, I. (2021). Visualizations with statistical details: The â€™ggstatsplotâ€™ approach. Journal of Open Source Software, 6(61), 3167. https://doi.org/10.21105/joss.03167\n\n\nScherer, C., Radchuk, V., Staubach, C., MÃ¼ller, S., Blaum, N., Thulke, H., & Kramerâ€Schadt, S. (2019). Seasonal Host Lifeâ€history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812â€“1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152â€“2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., FranÃ§ois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., MÃ¼ller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., â€¦ Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. Oâ€™Reilly. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/Practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5Â  Daten verbildlichen\n",
    "section": "",
    "text": "5â†©ï¸\nGrob gesagt: mariokart %&gt;% plot_density().â†©ï¸\nQuelle: ifes/FOM Hochschule, https://github.com/FOM-ifes/VL-Vorlesungsfolienâ†©ï¸\nQuelle: https://observablehq.com/@mcmcclur/the-normal-modelâ†©ï¸\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgrafâ†©ï¸\nQuelle: https://observablehq.com/d/bb7ad3ecfb1ac2a6â†©ï¸\nÃœbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen: https://github.com/cxli233/FriendsDontLetFriends#1-friends-dont-let-friends-make-bar-plots-for-means-separation.â†©ï¸\nDer Quellcode der Animation ist hier zu finden: https://gist.github.com/rafapereirabr/0d68f7ccfc3af1680c4c8353cf9ab345.â†©ï¸\nhttps://www.tylermw.com/wp-content/uploads/2019/06/featuredmeasles.mp4â†©ï¸\nhttps://rpkgs.datanovia.com/ggpubr/reference/ggviolin.htmlâ†©ï¸\nhttps://www.autodesk.com/research/publications/same-stats-different-graphsâ†©ï¸\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.mdâ†©ï¸\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md#gghistostatsâ†©ï¸\nhttps://flowingdata.com/category/visualization/ugly-visualization/â†©ï¸",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benÃ¶tigen Sie die Ã¼blichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.\nlibrary(tidyverse)\nlibrary(easystats)\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#einstieg",
    "href": "050-zusammenfassen.html#einstieg",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Lernziele\n\nSie kÃ¶nnen gÃ¤ngige Arten von LagemaÃŸe definieren.\nSie kÃ¶nnen erlÃ¤utern, inwiefern man ein LagemaÃŸ als ein Modell verstehen kann.\nSie kÃ¶nnen LagemaÃŸe mit R berechnen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer â€œklassischeâ€ Mittelwert (das arithmetische Mittel) ist ein prototypisches Beispiel fÃ¼r ein Modell in der Statistik.\n\nÃœbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hÃ¶ren, dass der â€œtypische deutsche Mannâ€ 1.80 m groÃŸ ist (vgl. Roser et al., 2013)?\n\nDie HÃ¤lfte der MÃ¤nner ist grÃ¶ÃŸer als 1.80\\(\\,\\)m, die andere HÃ¤lfte kleiner.\nDas arithmetische Mittel der MÃ¤nner betrÃ¤gt 1.80\\(\\,\\)m.\nDie meisten MÃ¤nner sind 1.80\\(\\,\\)m groÃŸ.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÃœbungsaufgabe 6.2 Laut dem Statistischen Bundesamt (2023-003-27) betrÃ¤gt der Wert der mittleren GrÃ¶ÃŸe deutscher Frauen etwa 1.66\\(\\,\\)m, also 14\\(\\,\\)cm weniger als bei MÃ¤nnern.1 \\(\\square\\)\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiÃŸ nicht \\(\\square\\)\n\n\n\n\nAuf diese Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So kÃ¶nnte man z.\\(\\,\\)B. sagen, â€œmehr als 5 cm sind vielâ€. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\)) betrÃ¤gt: 2. \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Zu easy!\n\n\nğŸ§‘â€ğŸ« Schon gut! Chill mal. Wird gleich spannender.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig!\n\nEtwas abstrakter kann man BeispielÂ 6.1 in folgendem Schaubild darstellen, s. AbbildungÂ 6.1.\n\n\n\n\n\nAbbildungÂ 6.1: Visualisierung von BeispielÂ 6.1\n\n\nDas Beispiel zeigt uns: Der Mittelwert eines Vektors \\(X\\) ist die Zahl, die \\(n\\) mal multipliziert, gleich ist mit der Summe der \\(n\\) Elemente von \\(X\\). Der Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) fÃ¼r die â€œtypische Noteâ€ im Statistikkurs, s. AbbildungÂ 6.5.\n\n\n\n\n\n\n\n\nAbbildungÂ 6.2: Der Mittelwert als â€œtypisches Elementâ€ eines Vektors\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er einen Vektor (eine â€œDatenreiheâ€) zu einen â€œtypischen Vertreterâ€ zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller MerkmalstrÃ¤ger in gleichem MaÃŸe einflieÃŸen. Er gibt uns eine (mÃ¶gliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen. Eine nÃ¼tzliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. AbbildungÂ 6.3. In â€œMathe-Sprechâ€ bezeichnet man den Mittelwert hÃ¤ufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. GleichungÂ 6.1.\n\n\n\n\n\nAbbildungÂ 6.3: Mittelwert als ausbalancierte Wippe mit Mittelwert 3 (Maphry, 2009)\n\n\n\\[\\bar {x} :=\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.1}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert (MW, mean) von \\(X\\) (prÃ¤ziser: das arithmetische Mittel des Merkmals \\(X\\)) ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n\\). Den Mittelwert von \\(X\\) bezeichnet man auch mit \\(\\bar {x}\\). \\(\\square\\)\n\n\nBeispiel 6.2 Angenommen, wir haben eine Reihe von Noten: 1, 2, 3. Der Mittelwert der Noten betrÃ¤gt dann 2: \\(\\bar{X} = \\frac{1}{3}\\sum (1+2+3) = 6/3 = 2\\). \\(\\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. AbbildungÂ 6.4 sehen wir die Noten von (dieses Mal) vier Studentinnen. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert.\nBezeichnen wir die Abweichung â€“ auch als â€œFehlerâ€, â€œRestâ€ oder â€œResiduumâ€ bezeichnet â€“ der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, Fehler) und die \\(i\\)-te Note mit \\(\\color{ycol}{y_i}\\), so kÃ¶nnen wir mit GleichungÂ 6.2 festhalten:\n\\[\\color{ycol}{\\text{y}_i} \\color{black}{ = } \\color{modelcol}{\\;\\bar{x}\\;} + \\color{errorcol}{\\;\\text{e}_i} \\tag{6.2}\\]\nAnders ausgedrÃ¼ckt (s. GleichungÂ 6.3):\n\\[\\color{ycol}{\\text{Daten}} \\color{black}{ = } \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}} \\tag{6.3}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe. Um Modelle darzustellen, wird in der Datenanalyse hÃ¤ufig folgende Art von Modellgleichung verwendet, s. GleichungÂ 6.4.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{ x}} \\tag{6.4}\\]\nLies: â€œDer Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)â€. Der Kringel â€œ~â€ soll also hier heiÃŸen â€œist eine Funktion vonâ€. Das â€œKringelâ€ oder die â€œWelleâ€ ~ nennt man auch â€œTildeâ€.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklÃ¤rende Variable (synonym: AV, Output-Variable, Zielvariable) gemeint. Das â€œDachâ€ Ã¼ber dem \\(\\color{ycol}{\\text{y}}\\) bedeutet â€œvorhergesagter Y-Wertâ€ oder â€œY-Wert laut dem Modellâ€. Der tatsÃ¤chliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\), s. GleichungÂ 6.5.\n\\[\\color{ycol}{y} \\color{black}{\\, = \\,} \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}} \\tag{6.5}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (â€œy-Dachâ€). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir mit GleichungÂ 6.6 schreiben kÃ¶nnen:\n\\[\\color{ycol}{y}  \\color{black}{\\, =\\, } \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e} \\tag{6.6}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklÃ¤rt, auÃŸer gehen wir von einem Fehler \\(\\color{errorcol}e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In spÃ¤teren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklÃ¤ren. WÃ¼rden wir z.\\(\\,\\)B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklÃ¤ren, so wÃ¼rden wir schreiben (s. GleichungÂ 6.7):\n\\[\\color{modelcol}{\\bar{y}} \\color{black}  {\\, \\sim \\,} \\color{xcol}{\\text{ x}} \\tag{6.7}\\]\nDa wir im Moment aber keine andere Variablen bemÃ¼hen, um \\(\\color{ycol}{\\text{y}}\\) zu erklÃ¤ren, schreibt man mit GleichungÂ 6.8 auch:\n\\[\\color{modelcol}{\\bar{y}}\\;\\;  \\color{black}{\\sim \\; 1} \\tag{6.8}\\]\nDiese Schreibweise sieht anfangs verwirrend aus. Die \\(1\\) soll aber nur zeigen, dass wir keine andere Variable zur ErklÃ¤rung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\). Der mathematische Hintergrund liegt in der Art, wie man Matrizen multipliziert.\n\nBeispiel 6.3 (Noten, Mittelwert und Abweichung) Vier Studentinnen â€“ Anna, Berta, Carl, Dani â€“ haben ihre Statistik-Klausur zurÃ¼ckbekommen (Schluck). Die Noten sehen Sie in AbbildungÂ 6.4; gar nicht so schlecht ausgefallen. AuÃŸerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen Residuen, Fehler; hÃ¤ufig mit \\(e\\) wie error bezeichnet) der einzelnen Noten vom Mittelwert eingezeichnet. \\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken in AbbildungÂ 6.4 einmal genauer an. Jetzt stellen Sie sich vor, Sie wÃ¼rden die vom Mittelwert nach oben ragenden BalkenlÃ¤ngen aneinanderlegen (das sind die gestrichelten. KÃ¶nnen Sie sich das vorstellen? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht), dass die GesamtlÃ¤nge der â€œnach oben ragenden Balkenâ€ identisch ist zur GesamtlÃ¤nge der nach â€œunten ragenden Balkenâ€. GleichungÂ 6.9 drÃ¼ckt das prÃ¤ziser und ohne Ihre Phantasie zu strapazieren aus.\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.9}\\]\nWie man in GleichungÂ 6.9 sieht, ist die Summe der Abweichungen vom Mittelwert Null.\n\n\n\n\n\n\n\nAbbildungÂ 6.4: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\n\nÃœbungsaufgabe 6.3 Was schÃ¤tzen Sie, wie hoch das mittlere VermÃ¶gen (arithmetisches Mittel) der Haushalte in Deutschland in etwa ist (im Jahr 2021 auf Basis einer Umfrage) (Bundesbank, 2023)?2 \\(\\square\\)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.000 Euro\n\n\n\nBeispiel 6.4 (Der wertvollste FuÃŸballer der Welt in Ihrem HÃ¶rsaal) Kommt der wertvollste FuÃŸballspieler der Welt in Ihren HÃ¶rsaal, sagen wir, es ist Kylian MbappÃ© (Transfermarkt, 2024). Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro (Arad, 2024). Der FuÃŸballer ist gut gelaunt:\n\nğŸ¦¹ Hey Leute, wie gehtâ€™s denn so! Wie viel Kohle habt ihr eigentlich so?\n\n\nğŸ§‘â€ğŸ“ Ã„h, wir studieren und verdienen fast nix!\n\nDie 100 Studis im HÃ¶rsaal schauen verdattert aus der WÃ¤sche: Was ist das fÃ¼r eine komische Frage!? Aber zumindest verteilt der FuÃŸballspieler Autogramme.\n\n\nÃœbungsaufgabe 6.4 (Mittleres Einkommen im HÃ¶rsaal, mit Kylian MbappÃ©) SchÃ¤tzen Sie â€“ im Kopf â€“ das mittlere VermÃ¶gen im HÃ¶rsaal, gehen Sie davon aus, dass alle der 100 Studierenden jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (prÃ¤ziser: das arithmetische Mittel des Einkommens) wie folgt berechnen, s. ListingÂ 6.1. (Die Details der Syntax, z.\\(\\,\\)B. der Befehl rep, sind von geringer Bedeutung.)\n\n\nListingÂ 6.1: Wir simulieren Einkommen von 100 Studis plus MbappÃ©.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100-mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 MbappÃ© mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nullen hinter der fÃ¼hrenden Eins: 1000000. In Taschenrechner- oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als â€œ1 Mal 10 hoch 6, also mit 6 im Exponentenâ€.\n\n\nDer Mittelwert im HÃ¶rsaal betrÃ¤gt also 1,189,109 Euro, etwas mehr als eine Million. Ist das ein gutes Modell fÃ¼r das typische VermÃ¶gen im HÃ¶rsaal?3\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. AbbildungÂ 6.5, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell beschreibt die Daten durch eine Gerade. Es erklÃ¤rt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildungÂ 6.5: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet; einmal mit Extremwerte (a), einmal ohne (b).\n\n\nAbbildungÂ 6.5 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit (farbig markierten) Extremwerten (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (AusreiÃŸer; outlier) ist eine Beobachtung, deren Wert deutlich vom GroÃŸteil der anderen Beobachtungen im Datensatz abweicht, z.\\(\\,\\)B. viel grÃ¶ÃŸer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R mit dem Befehl lm.\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear model\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl lm gibt hier mit der Ausgabe Coeffients (Koeffizient) einen einzelnen Wert zurÃ¼ck und zwar den Mittelwert von einkommen, vgl. auch ListingÂ 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet. Das wird verstÃ¤ndlich, wenn man z.\\(\\,\\)B. in AbbildungÂ 6.5 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet. Die Syntax des Befehls lm() sieht etwas merkwÃ¼rdig aus. Ignorieren Sie das fÃ¼rs Erste, wir besprechen das spÃ¤ter (Kapitel 9) ausfÃ¼hrlich. lm steht Ã¼brigens fÃ¼r â€œlineares Modellâ€.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.3 Der Median als Modell",
    "text": "6.3 Der Median als Modell\n\nğŸ§‘â€ğŸ“ Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert fÃ¼r die Menschen im HÃ¶rsaal. Weder fÃ¼r MbappÃ©, noch fÃ¼r uns Studis!\n\n\nğŸ§‘â€ğŸ« Ja, da habt ihr Recht.\n\n\nâš½ Die Welt ist schon ungerecht!\n\nAbbildungÂ 6.6 stellt die Verteilung des Einkommens im HÃ¶rsaal dar. Zur Erinnerung: 4.0+e07 bedeutet \\(4 \\cdot 10^{07} = 40000000\\), eine 4 gefolgt von 7 Nullen.  \n\n\n\n\n\n\n\n\nAbbildungÂ 6.6: Die Einkommensverteilung im HÃ¶rsaal\n\n\n\n\n\nDer Mittelwert ist HÃ¶rsaal ist nicht typisch fÃ¼r die Menschen im HÃ¶rsaal: Weder fÃ¼r MbappÃ©, noch fÃ¼r die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos. Der Mittelwert ist anfÃ¤llig fÃ¼r Extremwerte: Gibt es einen Extremwert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wider und weniger die Mehrheit der gemÃ¤ÃŸigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenÃ¼ber Extremwerten).\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. AbbildungÂ 6.6) ist der Mittelwert (sehr) wenig aussagekrÃ¤ftig, da er nicht mehr â€œtypischeâ€ Werte fÃ¼r die MerkmalstrÃ¤ger beschreibt.\n\n\n\nBeispiel 6.5 (Das Median-Einkommen einiger Studentinnen) FÃ¼nf Studentinnen tauschen sich Ã¼ber ihr Einkommen aus, s. AbbildungÂ 6.7, links. Es handelt sich um eine schiefe Verteilung. Wir kÃ¶nnten jetzt behaupten, dass Carla das typische Einkommen (fÃ¼r diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.7: Das Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\n\n\n\n\nDefinition 6.4 (Median) Die MerkmalsausprÃ¤gung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt, nennt man Median. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.5 (Alle mal aufstehen) Auf GeheiÃŸ der Lehrkraft stehen jetzt alle Studis bitte auf und sortieren sich der GrÃ¶ÃŸe nach im Raum, schÃ¶n in einer Reihe aufgestellt. Die KÃ¶rpergrÃ¶ÃŸe der Person in der Mitte der Reihe, zu der also gleich viele Personen zu links wie zu rechts stehen, das ist der Medien dieser Datenreihe, vgl. AbbildungÂ 6.8. \\(\\square\\)\n\nDer Median ist robust gegenÃ¼ber Extremwerten: FÃ¼gt man Extremwerte zu einer Verteilung hinzu, Ã¤ndert sich der Median zumeist (deutlich) weniger als der Mittelwert. AbbildungÂ 6.8 stellt den Median schematisch dar.\n\n\n\n\n\n\n1.60 m\n\n\n\n\n\n1.72 m\n\n\n\n\n\n1.79 m\n\n\n\n\n\n1.94\n\n\n\n\n\n2.12 m\n\n\n\n\n\nAbbildungÂ 6.8: Der Median als der Wert des â€œmittlerenâ€ Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert wie mit grÃ¶ÃŸerem Wert als der Median. In dieser Abbildung ist der Median (1.79 m) farbig markiert.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.6 Bei der Messreihe 1,2,3 betrÃ¤gt der Median 2. Bei der Messreihe 1, 2 betrÃ¤gt der Median 1.5. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.6 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhÃ¶ht sich um das Hundertfache. Wie verÃ¤ndert sich der Median?4 \\(\\square\\)\n\n\nÃœbungsaufgabe 6.7 (Wer ist mehr â€œmittelâ€? Median oder Mittelwert?) Â \n\nğŸ§‘â€ğŸ“ Das arithmetische Mittel sollte Mittelwert heiÃŸen, weil es die Mitte des Abstands zweier Zahlen widerspiegelt, also z.\\(\\,\\)B. von 1 und 10 ist die Mitte 5.5 â€“ also genau beim Mittelwert!\n\n\nğŸ‘© Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der GrÃ¶ÃŸe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion! \\(\\square\\)\n\n\nBeispiel 6.7 (Ein â€œmittlererâ€ Preis fÃ¼r Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median fÃ¼r das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist hÃ¶her als der Median.\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n\nprice_mw\nprice_md\n\n\n8.8\n1\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 6.9: Das Startgebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\nWie man sieht, ist der Mittelwert grÃ¶ÃŸer als der Median, s. AbbildungÂ 6.9. \\(\\square\\)\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert grÃ¶ÃŸer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell fÃ¼r den â€œtypischen Wertâ€ vorzuziehen.\n\nÃœbungsaufgabe 6.8 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die fÃ¼r einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis mÃ¶glicherweise Ã¼ber die GebÃ¼hr.\nEntfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\nLÃ¶sung\n\nmariokart_no_extreme &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n# ohne Extremwerte:\nmariokart_no_extreme |&gt; \n  summarise(total_pr_mittelwert_no_extreme = mean(total_pr),\n            total_pr_median_no_extreme = median(total_pr))\n\n\n\ntotal_pr_mittelwert\ntotal_pr_median\n\n\n50\n46\n\n\n\n\ntotal_pr_mittelwert_no_extreme\ntotal_pr_median_no_extreme\n\n\n47\n46\n\n\n\n\nWie man sieht, verÃ¤ndert sich der Mittelwert, wenn man die Extremwerte entfernt. FÃ¼r den Median trifft das nicht zu, er bleibt, wo er ist. \\(\\square\\)\n\n\nÃœbungsaufgabe 6.9 (Das mediane VermÃ¶gen in Deutschland) Was schÃ¤tzen Sie, wie hoch das mediane VermÃ¶gen der Haushalte in Deutschland im Jahr 2021 in etwa war (Bundesbank, 2023)?5\n\n50 Tsd Euro\n100 Tsd Euro\n150 Tsd Euro\n200 Tsd Euro\n300 Tsd Euro\\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere HÃ¤lfte. Er markiert sozusagen eine â€œ50-Prozent-Markeâ€ (der aufsteigend sortierten Werte). Betrachten wir einmal nur alle Spiele, die fÃ¼r weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. AbbildungÂ 6.10. 50\\(\\,\\)% dieser Spiele wurden fÃ¼r weniger als ca. 46 Euro verkauft und 50% fÃ¼r mehr als 46 Euro. Der Median betrÃ¤gt als 46 Euro.\nJetzt kÃ¶nnten wir nur die gÃ¼nstigere HÃ¤lfte betrachten und wieder nach dem Median fragen (d.\\(\\,\\)h. total_pr &lt; 46). Dieser â€œMedian der billigeren HÃ¤lfteâ€ grenzt damit das insgesamt billigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro. Jetzt kÃ¶nnte man sagen, hey, warum nur in 25\\(\\,\\)%-StÃ¼cke die Verteilung aufteilen? Warum nicht in 10\\(\\,\\)%-Schritten? Oder vielleicht in 1\\(\\,\\)%-Schritten oder in sonstigen Schritten? Wo die Quartile in 25\\(\\,\\)%-Schritten aufteilen, teilt ein Quantil in \\(p\\)-Prozent-Schritten auf. S. AbbildungÂ 6.11 dazu.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25\\(\\,\\)%). Den Median nennt man das zweite Quartil (Q2, 50\\(\\,\\)%). Entsprechend heiÃŸt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75\\(\\,\\)%). \\(\\square\\)\n\n\nBeispiel 6.8 (Quartile des Verkaufsgebot) AbbildungÂ 6.10 zeigt die Quartile fÃ¼r das Verkaufsgebot. \\(\\square\\)\n\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleich groÃŸe Teile unterteilen, nennt man Dezile. â€œGleich groÃŸâ€ heiÃŸt, dass in jedem Dezil gleich viele Werte (nÃ¤mlich 10 %) liegen. \\(\\square\\)\n\nAbbildungÂ 6.10 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil fÃ¼r den Datensatz mariokart2.\n\n\n\n\n\n\n\nAbbildungÂ 6.10: Q1, Q2 und Q3 fÃ¼r das Schlussgebot (nur Spiele fÃ¼r weniger als 100 Euro) in einem Dichtediagramm\n\n\n\n\n\nDefinition 6.7 (Quantile) Ein \\(p\\)-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht Ã¼berschritten wird. Ein Quantil ist ein Oberbegriff fÃ¼r Quartile, Dezile etc. \\(\\square\\)\n\nQuantile kann man in R mit dem Befehl quantile berechnen:\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(\n    q25 = quantile(total_pr, .25),  # 1. Quartil\n    q50 = quantile(total_pr, .50),  # 2. Quartil\n    q75 = quantile(total_pr, .75))  # 3. Quartil\n\nAbbildungÂ 6.11 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildungÂ 6.11: Verschiedene Quantile animiert\n\n\nAbbildungÂ 6.12 visualisiert verschiedene Quantile. Man beachte, dass alle Regionen gleichgroÃŸe FlÃ¤chen aufweisen.\n\n\n\n\n\n\n\n\n\n(a) 10%-Schritte: Dezile\n\n\n\n\n\n\n\n\n\n(b) 1%-Schritte: Perzentile\n\n\n\n\n\n\nAbbildungÂ 6.12: Verschiedene Quantile visualisiert\n\n\n\n6.4.1 Beispiel: Quantile der IQ-Verteilung\nZur Erinnerung: Die Verteilung des IQ wird gewÃ¶hnlich als normalverteilt mit Mittelwert gleich 100 und Streuung gleich 15 angenommen.\nBetrachten wir einige hÃ¤ufig verwendete Quantile fÃ¼r die IQ-Verteilung, s. AbbildungÂ 6.13.\n\n\n\n\n\n\n\nAbbildungÂ 6.13: Verschiedene Quantile der Normalverteilung",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.5 LagemaÃŸe",
    "text": "6.5 LagemaÃŸe\n\nğŸ§‘â€ğŸ“ Was ist der Oberbegriff fÃ¼r Median, Mittelwert und so weiter?\n\n\nğŸ§‘â€ğŸ« Gute Frage! Wie wÃ¼rden Sie ihn nennen?\n\n\nDefinition 6.8 (LagemaÃŸ) Ein LagemaÃŸ (synonym: MaÃŸ der zentralen Tendenz) fÃ¼r eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, erwartbar, reprÃ¤sentativ oder â€œmittelâ€ ansehen sollten. \\(\\square\\)\n\nGebrÃ¤uchliche LagemaÃŸe sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuantile wie z.\\(\\,\\)B. Quartile\nMinimum (kleinster Wert)\nMaximum (grÃ¶ÃŸter Wert)\nModus (hÃ¤ufigster Wert)\n\nBerechnen wir LagemaÃŸe fÃ¼r den Mariokart-Datensatz, z.\\(\\,\\)B. mit describe_distribution(mariokart), s. ListingÂ 6.2. Es ist Ã¼brigens egal, wie Sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname â€“ alles okay!\n\n\n\nListingÂ 6.2: Syntax zur Berechnung von LagemaÃŸen\n\ndescribe_distribution(mariokart) |&gt;  \n  # Einige Spalten interessieren uns hier nicht:\n  select(-Skewness, -Kurtosis, -n, n_Missing)\n\n\n\n\nHÃ¤ufig mÃ¶chte man Statistiken wie LagemaÃŸe fÃ¼r mehrere Teilgruppen â€“ z.\\(\\,\\)B. Mittlere KÃ¶rpergrÃ¶ÃŸe von Frauen vs.Â mittlere KÃ¶rpergrÃ¶ÃŸe von MÃ¤nnern â€“ berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage kÃ¶nnte lauten: â€œUnterscheidet sich der Mittelwert der KÃ¶rpergrÃ¶ÃŸe von Frauen und MÃ¤nnern?â€ Oder vielleicht: â€œHÃ¤ngt das Geschlecht mit der KÃ¶rpergrÃ¶ÃŸe zusammen?â€ Anders ausgedrÃ¼ckt: KÃ¶rpergrÃ¶ÃŸe \\(y\\) ist eine Funktion des Geschlechts \\(G\\). Die Modellformel kÃ¶nnte also lauten: \\({y} \\;{ \\sim } \\; {G}\\). Gruppierte LagemaÃŸe lassen sich in R z.\\(\\,\\)B. so berechnen, s. ListingÂ 6.3.\n\n\n\nListingÂ 6.3: Gruppierte LagemaÃŸe\n\nmariokart_lagemaÃŸe_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\n\n\n\n\n\n\nTabelleÂ 6.1: Gruppierte Mittelwerte\n\n\n\n\nwheels\nmw\n\n\n\n0\n41\n\n\n1\n44\n\n\n2\n61\n\n\n3\n70\n\n\n4\n65\n\n\n\n\n\n\n\n\nAbbildungÂ 6.15 zeigt ein Beispiel fÃ¼r ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. AbbildungÂ 6.5. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, â€œglobalenâ€ Mittelwert): Innerhalb der Gruppe ohne LenkrÃ¤der und innerhalb der Gruppe mit 2 LenkrÃ¤dern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering â€“ im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches fÃ¼r alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heiÃŸt Punktmodell. Anders gesagt, fasst ein Punktmodell eine Wertereihe (hÃ¤ufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem â€œPunktâ€ in diesem Sinne, s. AbbildungÂ 6.14. \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 6.14: Die deskriptive Statistik fasst eine Spalte zu einer einzelnen Zahl zusammen.\n\n\nMittelwert, Median und Quartile sind Beispiele fÃ¼r Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein â€œBildâ€ der Daten, machen sie uns verstÃ¤ndlich â€“ sie sind uns also ein Modell.\n\n\n\n\n\n\n\n\n\n\n(a) ungruppiert\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) gruppiert\n\n\n\n\n\n\nAbbildungÂ 6.15: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet. (a) ungruppiert; (b) gruppiert nach Anzahl der LenkrÃ¤der.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lÃ¼gt",
    "text": "6.6 Wie man mit Statistik lÃ¼gt\nEs heiÃŸt, mit Statistik kÃ¶nne man vortrefflich lÃ¼gen. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lÃ¤sst: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzufÃ¼hren. Viele Wege fÃ¼hren nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und UnschÃ¤rfen ohne bÃ¶se Absicht aufzudecken, gibt es ein probates Gegenmittel: Transparenz. Analysen sollten transparent sein: Das Vorgehen und die zugrundeliegenden Entscheidungen sollte man offenlegen. Hier ist eine (nicht abschlieÃŸende!) Checkliste, was Sie nachprÃ¼fen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\nWurden ausreichend Daten gesammelt (z.\\(\\,\\)B. mind. 20 Beobachtungen pro Gruppe)?\nWurden alle untersuchten Variablen berichtet?\nWurden alle durchgefÃ¼hrten Interventionen berichtet?\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) BegrÃ¼ndung?\n\n\nStellen Sie hohe Anforderungen an die Transparenz einer statistischen Analyse. Nur durch NachprÃ¼fbarkeit kÃ¶nnen Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation Ã¼berzeugen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.9 (Survival-Tipp) Eine Studentin aus dem Bachelorstudiengang Angewandte Medien- und Wirtschaftspsychologie mit Schwerpunkt Data Science berichtet ihre â€œSurvival-Tippsâ€ fÃ¼r Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich wÃ¤hrend des Semesters neue Begriffe und ihre ErklÃ¤rung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in hÃ¶heren Semestern nach Tipps zu fragen. \\(\\square\\)\n\n\n\n\nğŸ§‘â€ğŸ“ Irgendwie kann ich mir R-Code so schlecht merken.\n\n\nğŸ§‘â€ğŸ« Frag doch mal ChatGPT oder einen anderen Chatbot â€“ dort bekommt man auch R-Code ausgegegeben.\n\n\nÃœbungsaufgabe 6.10 (Ãœbungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Ãœbungsaufgaben. Sie kÃ¶nnen sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\nğŸ§‘â€ğŸ“ Ich bin Student in einem Bachelor-Studiengang. Gerade bereite ich mich auf die Klausur im Fach â€œGrundlagen der Statistikâ€ vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die PrÃ¼fung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: MaÃŸe der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.\\(\\,\\)B. Nominalskala vs.Â Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der folgenden Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber spÃ¤ter kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekanntem Stoff.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\nSchauen Sie sich auch mal auf datenwerk.netlify.app die Aufgaben zu z.\\(\\,\\)B. dem Tag EDA an.\n\nÃœbungsaufgabe 6.11 Mittlerweile verfÃ¼gen Sie einige wesentliche Werkzeuge des Datenjudo. Hier finden Sie einen Ãœberblick an DatensÃ¤tze, die Sie nach Herzenslust analysieren kÃ¶nnen.6 \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6Â  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele LehrbÃ¼cher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehÃ¶ren zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel fÃ¼r LehrbÃ¼cher sind Mittag & SchÃ¼ller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Einen Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurÃ¼ckschreckt, ist mit Ã‡etinkaya-Runde & Hardin (2021) oder Poldrack (2023) gut beraten. Beide BÃ¼cher sind online verfÃ¼gbar. Tipp: Mit dem Browser lÃ¤sst sich englischer Text auf einer Webseite auf auf Deutsch Ã¼bersetzen.\n\n\n\n\nArad, C. (2024, Juni 5). Kylian Mbappe: Gehalt und VermÃ¶gen im Ãœberblick (2024). ftd.de. https://www.ftd.de/vermoegen/mbappe-gehalt-vermoegen/\n\n\nBortz, J., & Schuster, C. (2010). Statistik FÃ¼r Human- und Sozialwissenschaftler. Springer. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBundesamt, S. (2023-003-272023-003-27). KÃ¶rpermaÃŸe nach Altersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household Wealth and Finances in Germany: Results of the 2021 Household Wealth Survey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMaphry. (2009). Seesaw with Mean [Artwork]. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung mit interaktiven Elementen. Springer. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und SpaÃŸ im Horrorfach nichttechnischer StudiengÃ¤nge. Springer. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height [Data set]. In Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359â€“1366. https://doi.org/10.1177/0956797611417632\n\n\nTransfermarkt. (2024). Die wertvollsten FuÃŸball-Spieler. https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop/spielerposition_id/8/page/12\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., Aert, R. C. M. van, & Assen, M. A. L. M. van. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6Â  Punktmodelle 1",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Average_human_height_by_countryâ†©ï¸\n316 Tsd Euroâ†©ï¸\nNein. Es beschreibt weder das VermÃ¶gen der Studierenden noch das des FuÃŸballers gut.â†©ï¸\nEr bleibt gleich, verÃ¤ndert sich also nicht: Der Median ist robust, er verÃ¤ndert sich nicht oder kaum, wenn Extremwerte vorliegen.â†©ï¸\nca. 84 Tsd Euroâ†©ï¸\nhttps://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/â†©ï¸",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benÃ¶tigen Sie die Ã¼blichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.\nlibrary(tidyverse)\nlibrary(easystats)\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#einstieg",
    "href": "060-modellguete.html#einstieg",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "7.1.1 Lernziele\n\nSie kennen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe und kÃ¶nnen diese definieren und anhand von Beispielen erlÃ¤utern.\nSie kÃ¶nnen gÃ¤ngige MaÃŸe der Streuung einer Stichprobe mit R berechnen.\nSie kÃ¶nnen die Bedeutung von Streuung fÃ¼r die GÃ¼te eines Modells erlÃ¤utern.\n\n\nÃœbungsaufgabe 7.1 (Freiwillige vor!) FÃ¼r diese kleine Live-Demonstration brauchen wir einige Freiwillige. Die Lehrkraft teilt die Freiwilligen in zwei Gruppen ein: Gruppe Gleich-GroÃŸ und Gruppe Verschieden-GroÃŸ. Erkennen Sie, dass die Unterschiedlichkeit der GrÃ¶ÃŸe in Gruppe Gleich-GroÃŸ gering ist, aber in Gruppe Verschieden-GroÃŸ hoch? \\(\\square\\)\n\n\n7.1.2 Die Schlankheitspille von Prof.Â Weiss-Ois\nProf.Â Weiss-Ois hat eine Erfindung gemacht, eine SchlankheitspilleğŸ’Š (flaticon, 2024).\n\n\n\n\n\n\nWas er sagt: â€œIch habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1\\(\\,\\)kg reduziert!â€\n\n\n\nÂ \n\n\n\n\nWas er NICHT sagt: â€œAllerdings streuten die Werte der GewichtsverÃ¤nderung um 10\\(\\,\\)kg um den Mittelwert herum.â€\n\n\n\n\n\nAbbildungÂ 7.1: Prof.Â Weiss-Oiss prÃ¤sentiert seine neue Schlankheitspille. WÃ¼rden Sie Sie einnehmen?\n\n\nWÃ¼rden Sie die Pille von Prof.Â I. Ch. Weiss-Ois nehmen? Auf jeden Fall? Wenn Sie 1000\\(\\,\\)Euro bekommen? Nur, wenn man Ihnen Geld zahlt? Auf keinen Fall?\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information: Bei Prof.Â Weiss-Oisâ€™ Pille kann es sein, dass Sie 10\\(\\,\\)kg zunehmen, wenn Sie die Pille einnehmen.\n\n7.1.3 Wie man seine Kuh Ã¼ber den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss Ã¼berqueren, nur kann die Kuh nicht schwimmen (ob Fritz es kann, ist nicht Ã¼berliefert).\n\nğŸ‘¨â€ğŸŒ¾ (Fritz): Sag mal, Karla, ist der Fluss tief?\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): NÃ¶, im Schnitt nur einen Meter.\n\nAlso fÃ¼hrt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, da im FloÃŸ ersoffen, s. AbbildungÂ 7.2.\n\n\n\n\n\nAbbildungÂ 7.2: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\nğŸ‘©â€ğŸŒ¾ (Karla): Ãœbrigens: LagemaÃŸe sagen nicht alles, Fritz.\n\n\nğŸ‘¨â€ğŸŒ¾ (Fritz): LÃ¤uft die Kuh durch den Fluss, kann sie schwimmen oder â€™s ist Schluss.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Streuung ihrer Daten zu kennen, ist eine wesentliche Information. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.2 Woran erkennt man ein gutes Modell?",
    "text": "7.2 Woran erkennt man ein gutes Modell?\nAbbildungÂ 7.3 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs.Â ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen. Die vertikalen Balken in AbbildungÂ 7.3 kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale Linie). Je lÃ¤nger die vertikalen â€˜Abstandsbalkenâ€™ insgesamt, desto grÃ¶ÃŸer die Streuung. Die X-Achse (id) reiht die Versuchspersonen auf.\n\n\n\n\n\n\n\nAbbildungÂ 7.3: Wenig (links) vs.Â viel Streuung (rechts).\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsÃ¤chlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groÃŸ.\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof.Â Weiss-Ois) In AbbildungÂ 7.3 sind die Daten zu der GewichtsverÃ¤nderung nach Einnahme von â€œSchlankheitspillenâ€ zweier verschiedener PrÃ¤parate. Wie man sieht, unterscheidet sich die typische (vorhergesagte, mittlere) GewichtsverÃ¤nderung zwischen den beiden PrÃ¤paraten kaum. Die Streuung allerdings schon. Links sieht man die GewichtsverÃ¤nderungen nach Einnahme des PrÃ¤parats â€œDickableibtin extra mildâ€ und rechts das PrÃ¤parat von Prof.Â Weiss-Oisâ€™ â€œPfundafliptan Forteâ€. Welches PrÃ¤parat wÃ¼rden Sie lieber einnehmen?\\(\\square\\)\n\nWir wollen ein prÃ¤zises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklÃ¤ren, also wenig vom tatsÃ¤chlichen Wert abweichen. Jedes Modell sollte Informationen Ã¼ber die PrÃ¤zision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der ModellgÃ¼te, d.\\(\\,\\)h. der PrÃ¤zision der SchÃ¤tzung des Modellwerts, ist wenig nÃ¼tze.\n\nğŸ§‘â€ğŸ“ Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\nğŸ§‘â€ğŸ« Die Frage ist, was wir mit â€œverbessernâ€ meinen?\n\n\nğŸ§‘â€ğŸ“ Naja, kÃ¼rzere Fehlerbalken, ist doch klar!\n\nIm Beispiel von Mariokart: Da die Anzahl der LenkrÃ¤der mit dem Verkaufspreis zusammenhÃ¤ngt, kÃ¶nnte es vielleicht sein, dass wir die LenkrÃ¤der-Anzahl zur Vorhersage nutzen kÃ¶nnten. Das sollten wir ausprobieren. AbbildungÂ 7.4 zeigt, dass die Fehlerbalken kÃ¼rzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 LenkrÃ¤dern vs.Â mit 0 LenkrÃ¤dern) sind die Fehlerbalken jeweils im Durchschnitt kÃ¼rzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm). Aus GrÃ¼nden der Ãœbersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berÃ¼cksichtigt und nur Spiele mit 0 oder mit 2 LenkrÃ¤dern.\n\n\n\n\n\n\n\n\n\n(a) Einfaches Modell\n\n\n\n\n\n\n\n\n\n(b) Komplexeres Modell\n\n\n\n\n\n\nAbbildungÂ 7.4: Fehlerbalken in einem einfachen und komplexeren Modell. (a) Fehlerbalken im einfachen Modell. Ein Mittelwert; viel Streuung insgesamt, y ~ 1. (b) Fehlerbalken im komplexeren Modell. Zwei Mittelwerte; weniger Streuung in jeder Gruppe, y ~ G. Die geringere Streuung erkennt man daran, dass die vertikalen Abstandsbalken im Schnitt kÃ¼rzer sind als im einfachen Modell.\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.3 StreuungsmaÃŸe",
    "text": "7.3 StreuungsmaÃŸe\n\nDefinition 7.1 (StreuungsmaÃŸe) Ein StreuungsmaÃŸ quantifiziert die VariabilitÃ¤t (Unterschiedlichkeit, Streuung) eines Merkmals. \\(\\square\\)\n\n\nDefinition 7.2 (Spannweite) Ein einfaches StreuungsmaÃŸ ist die Spannweite (Range) \\(R\\), definiert als Differenz von grÃ¶ÃŸtem und kleinsten Wert eines Merkmals X: \\(R := X_{max} - X_{min}. \\square\\)\n\n\nBeispiel 7.2 Angenommen, wir haben einen Datensatz zum Merkmal â€œAlterâ€ mit den Werte 1, 23, 42, 100. Dann betrÃ¤gt der Range: \\(R = 100 - 1 = 99\\). Das bedeutet, dass die Werte des Merkmals sich Ã¼ber 99 Einheiten (Jahre in diesem Fall) verteilen. \\(\\square\\)\n\nDie Spannweite ist aber nicht robust (gegenÃ¼ber Extremwerten) und sollte daher nur mit EinschrÃ¤nkung verwendet werden.\n\n7.3.1 Der mittlere Abweichungsbalken\n\nğŸ§‘â€ğŸ“ Wir mÃ¼ssen jetzt mal prÃ¤ziser werden! Wie kÃ¶nnen wir die Streuung berechnen?\n\n\nğŸ§‘â€ğŸ« Gute Frage! Am einfachsten ist es, wenn wir die mittlere LÃ¤nge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir den â€œmittleren Abweichungsbalkenâ€, den wir mit \\(\\bar{e}\\) (â€œe querâ€) bezeichnen kÃ¶nnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als mittlere Absolutabweichung (MAA), s. GleichungÂ 7.1.\n\nDefinition 7.3 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte. (Wenn man solche SÃ¤tze liest, fÃ¼hlt sich die Formel fast einfacher an.)\n\\[{\\displaystyle \\mathrm {MAE} :={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}=\\bar{e}.  \\; \\square} \\tag{7.1}\\]\n\n\nBeispiel 7.3 AbbildungÂ 7.5 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE fÃ¼r das Beispiel von AbbildungÂ 7.5 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5 \\; \\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 7.5: Abweichungsbalken und der MAE\n\n\n\n\nNatÃ¼rlich kÃ¶nnen wir R auch die Rechenarbeit Ã¼berlassen.\n\nğŸ¤– Loving it!\n\nSchauen Sie: Den Mittelwert (s. AbbildungÂ 7.5) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? SchlieÃŸlich erklÃ¤ren wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse verlÃ¤uft). In R gibt es einen Befehl, um ein lineares Modell zu berechnen, er heiÃŸt lm. Die Syntax von lm() lautet: lm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur ErklÃ¤rung von Y. Aber verwende keine andere Variable zur ErklÃ¤rung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm_ohne_x_var &lt;- lm(y ~ 1, data = d)\n\nDen MAE kÃ¶nnen wir uns jetzt so ausgeben lassen:\n\nmae(lm_ohne_x_var)  # aus dem Paket easystats\n## [1] 1.5\n\n\n7.3.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein StreuungsmaÃŸ, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.\\(\\,\\)B. der MAA oder die Varianz und die Standardabweichung. AbbildungÂ 7.6 stellt den IQR (und einige Quantile) fÃ¼r den Verkaufspreise von Mariokart-Spielen dar.\n\nDefinition 7.4 (Interquartilsabstand) Der Interquartilsabstand ist definiert als die (absolute) Differenz des 3. Quartils und 1. Quartils: \\(IQR := Q_3-Q_1. \\; \\square\\)\n\n\nBeispiel 7.4 (IQR im HÃ¶rsaal) In einem Statistikkurs betragen die Quartile der KÃ¶rpergrÃ¶ÃŸe: Q1: 1.65m, Q2 (Median): 1.70m, Q3: 1.75m. Der IQR betrÃ¤gt dann: \\(IQR = Q_3-Q_1 = 1.75\\,m - 1.65\\,m = 0.10\\,m\\), d.\\(\\,\\)h. 10\\(\\,\\)cm. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildungÂ 7.6: IQR, Q1, Q2 und Q3 fÃ¼r das Schlussgebot (nur Spiele fÃ¼r weniger als 100 Euro)\n\n\n\n7.3.3 StreuungsmaÃŸe fÃ¼r Normalverteilungen\nNormalverteilungen sind recht hÃ¤ufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu Ã¼berlegen, wie man diese Verteilungen kompakt zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett Ã¼ber ihren Mittelwert sowie ihre Standardabweichung beschreiben lÃ¤sst (Lyon, 2014). AuÃŸerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), â€œverschiebt man den Bergâ€ nur zur Seite, ohne die Form zu verÃ¤ndern, s. AbbildungÂ 7.7.\n\n\n\n\n\n\n\nAbbildungÂ 7.7: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt. Rechts: unzentrierte Verteilung; links: zentriert.\n\n\n\n\nHat man normalverteilte Variablen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma, s\\)) eine geeignete MaÃŸeinheit der Streuung, denn damit lÃ¤sst sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\n\nğŸ§‘â€ğŸ“ Aber wie berechnet man jetzt diese Standardabweichung?\n\n\nğŸ§‘â€ğŸ« Moment, noch ein kurzer Exkurs zur Varianz â€¦\n\n\nğŸ§‘â€ğŸ“ (seufzt)\n\n\n7.3.4 Varianz\nDie Varianz einer Variable (z.\\(\\,\\)B. Verkaufspreis von Mariokart) ist der mittlere quadrierte Abstand jedes Verkaufspreises vom Mittelwert.\n\n\n\nAbbildungÂ 7.10 illustriert die Varianz als â€œmittlerer Quadratfehlerâ€:\n\nMan gehe von der HÃ¤ufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan zeichnet fÃ¼r jeden Datenpunkt ein Quadrat mit einer KantenlÃ¤nge, die seinem Abstand zum Mittelwert entspricht.\nDiese Quadrate werden, wo nÃ¶tig, in Rechtecke umgeformt (bei gleichbleibender FlÃ¤che) und so angeordnet, dass sie ein Rechteck mit den SeitenlÃ¤ngen \\(n\\) und \\(\\sigma^2\\) bilden.\n\n\n\n\n\n\n\n\nAbbildungÂ 7.8: Varianz (Cmglee, 2015)\n\n\n\n\n\nAbbildungÂ 7.9 visualisiert die Varianz fÃ¼r BeispielÂ 7.3.1 Links sind die Abweichungsquadrate dargestellt, rechts die Varianz als â€œtypisches Abweichungsquadratâ€. Die Varianz ist also ein MaÃŸ, das die typische quadrierte Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als â€˜typischerâ€™ Fehlerbalken\n\n\n\n\n\n\nAbbildungÂ 7.9: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\n\nBeispiel 7.5 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. NatÃ¼rlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann. Dazu berechnen Sie die Streuung in den Verkaufspreisen, s. ListingÂ 7.1 bzw. TabelleÂ 7.1. \\(\\square\\)\n\n\n\n\nListingÂ 7.1: Berechnung der Streuung des Verkaufspreises als Indikator fÃ¼r die ModellgÃ¼te des Mittelwerts\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  mariokart_no_extreme %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\n\n\nTabelleÂ 7.1: Kennwerte der Streuung fÃ¼r den Mariokart-Datensatz\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47\n13\n7.2\n83\n9.1\n\n\n\n\n\n\n\nStatistiken sind ja schÃ¶n â€¦ aber Bilder sind auch gut, s. AbbildungÂ 7.10. Datendiagramme eignen sich gut, um (grob) die Streuung einer Variable zu erfassen.\n\nmariokart %&gt;% \n  mariokart_no_extreme %&gt;%   # ohne Extremwerte\n  select(total_pr) %&gt;% \n  plot_density()  # oder plot_violin\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm\n\n\n\n\n\n\nAbbildungÂ 7.10: Die Verteilung des Verkaufspreises von Mariokart-Spielen mit MWÂ±SD farblich markiert\n\n\nWer sich die Berechnung von Hand fÃ¼r pr_maa sparen mÃ¶chte (s. ListingÂ 7.1), kann die Funktion MeanAD aus dem Paket DescTools nutzen. Um die Standardabweichung zu berechnen, berechnet man zunÃ¤chst die Varianz, \\(s^2\\) abgekÃ¼rzt. Hier ist ein â€œKochrezeptâ€ (Algorithmus) zur Berechnung der Varianz:\n\nFÃ¼r alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\).\nQuadriere diese Werte.\nSummiere dann auf.\nTeile durch die Anzahl \\(n\\) der Werte.\n\nAls Formel ausgedrÃ¼ckt lautet die Definition der Varianz von \\(Y\\) bei einer Stichprobe der GrÃ¶ÃŸe \\(n\\) wie folgt, s. GleichungÂ 7.2. (Hier geht es um die sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehÃ¶rigen Population zu schÃ¤tzen, teilt man nicht durch \\(n\\), sondern durch \\(n-1\\).)\n\\[{\\displaystyle s^{2}:={\\frac {1}{n}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{n}}\\sum _{i=1}^{n}e_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.5 (Varianz) Die Varianz von \\(Y\\) (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen (vom Mittelwert von \\(Y\\)), \\(e_i^2\\). \\(\\square\\)\n\nDie Varianz steht im engen VerhÃ¤ltnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. GleichungÂ 7.3.\n\\[{\\displaystyle MSE:={\\frac {1}{n}}\\sum _{i=1}^{N}\\left(y_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells: \\(\\hat{y} = \\bar{y}\\).\n\n7.3.5 Die Standardabweichung\n\nDefinition 7.6 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. GleichungÂ 7.4.\n\\[s := \\sqrt{s^2} \\square \\tag{7.4}\\]\n\nKennt man die Varianz, so lÃ¤sst sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen. Durch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche GrÃ¶ÃŸenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groÃŸ werden kann). Die Standardabweichung ist also ein MaÃŸ, das grob (!) gesagt die â€œtypischeâ€ Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst. Aus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(RMSE := \\sqrt{MSE}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE. \\(\\square\\)\n\n\n\nBeispiel 7.6 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution, s. TabelleÂ 7.2.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n\n\nTabelleÂ 7.2: Ausgabe der Funktion describe_distribution (Auszug)\n\n\n\n\nVariable\nMean\nSD\nIQR\nn\n\n\ntotal_pr\n50\n26\n13\n143\n\n\n\n\n\n\n\n\nğŸ§‘â€ğŸ“ Ah! Das war einfach. Reicht auch mal fÃ¼r heute. \\(\\square\\)\n\n\n\nBeispiel 7.7 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So war auch der heutige Tag. Bevor Sie nach Hause gehen, mÃ¶chten Sie noch eine Sache anschauen. In einer frÃ¼heren Analyse (s. AbbildungÂ 7.4) fanden Sie heraus, dass die Fehlerbalken kÃ¼rzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natÃ¼rlich prÃ¼fen. Sie Ã¼berlegen: â€œOkay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.â€\nDas spezifizieren Sie so:\n\nlm_mario_ohne_x_var &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm_mario_ohne_x_var)  # ModellgÃ¼te bzw. Modellfehler\n## [1] 10\n\nIm nÃ¤chsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufspreis eine Funktion der Anzahl der LenkrÃ¤der ist (Ã¤hnlich wie in AbbildungÂ 7.4):\n\nlm_wheels &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm_wheels)\n## [1] 7.4\n\nAh! Sehr schÃ¶n, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach Hause! \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Der â€œgesunde Menschenverstandâ€ wÃ¼rde den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Warum brauche ich dann die SD?\n\n\n\nğŸ§‘â€ğŸ« Ja, die MAA ist anschaulicher und insofern nÃ¼tzlicher als die Varianz und die SD. Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. Allerdings ist die SD nÃ¼tzlich zur Beschreibung der Normalverteilung. AuÃŸerdem wird die Varianz hÃ¤ufig verwendet bzw. in Forschungsarbeiten berichtet, daher hilft es Ihnen, wenn Sie die Varianz kennen. Liegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenÃ¼ber Mittelwert basierten StreuungsmaÃŸen (MAA, Varianz, SD).",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.4 Streuung als Modellfehler",
    "text": "7.4 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufspreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der ModellgÃ¼te auffassen.\nDefinieren wir zunÃ¤chst als Punktmodell auf Errisch:\n\nlm_mario_ohne_x_var &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne UV (PrÃ¤diktoren), sondern als Punktmodell, und zwar schÃ¤tzen wir den Mittelwert mit den Daten mariokart. Modelle ohne UV nennt man auch â€œNullmodellâ€. Das (Meta-)Paket easystats bietet komfortable Befehle, um die ModellgÃ¼te zu berechnen:\n\nmae(lm_mario_ohne_x_var)  # Mean absolute error\nmse(lm_mario_ohne_x_var)  # Mean squared error\nrmse(lm_mario_ohne_x_var)  # Root mean squared error\n## [1] 10\n## [1] 655\n## [1] 26",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#die-z-transformation",
    "href": "060-modellguete.html#die-z-transformation",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.5 Die z-Transformation",
    "text": "7.5 Die z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie, wie gut sich die Verkaufspreise mit einer einzigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. ListingÂ 7.2.\n\n\n\nListingÂ 7.2: Mariokart ohne Extremwerte\n\nmariokart_no_extreme &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n\n\n\nAbbildungÂ 7.11 (links) zeigt, dass es einige Streuung um den Mittelwert herum gibt. AbbildungÂ 7.11 (rechts) zeigt die (um den Mittelwert) zentrierten Daten.\n\n\n\n\n\n\n\n\n\n\n(a) Wie nah drÃ¤ngen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert: zentrierte Daten\n\n\n\n\n\n\nAbbildungÂ 7.11: Verteilung von mariokart_no_extreme\n\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell fÃ¼r die Daten und desto hÃ¶her ist die ModellgÃ¼te.\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie Ã¼berlegen â€¦ und Ã¼berlegen. Da! Eine Idee!\nMan kÃ¶nnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je grÃ¶ÃŸer diese Abweichung, desto schlechter die ModellgÃ¼te! Also rechnen Sie diese Abweichung aus, ListingÂ 7.3.\n\n\n\nListingÂ 7.3: Zentrieren einer Variablen\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw = 47.4 - total_pr) # zentriert = messwert - mittelwert\n\n\n\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.7 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert zu subtrahieren. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Ãœberlegungen: Woher weiÃŸ man, ob 10 Euro oder 20 Euro â€œvielâ€ Abweichung vom Verkaufspreis ist? Man mÃ¼sste die Abweichung eines Verkaufspreises zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man kÃ¶nnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, Ã¤hnlicher Kennwert zur MAA ist die SD. Sie haben gehÃ¶rt, dass die SD gebrÃ¤uchlicher sei als die MAA. Um sich als Checker zu prÃ¤sentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja Ã¤hnlich.\nAlso: Wenn ein Spiel 10 Dollar vom Mittelwert abweicht und die SD 10 Dollar betragen sollte, dann hÃ¤tten wir eine â€œstandardisierteâ€ (abgekÃ¼rzt manchmal mit std) Abweichung von 1, weil 10/10=1. Begeistert Ã¼ber Ihre Geistesblitze machen Sie sich ans Werk.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. AbbildungÂ 7.12. In AbbildungÂ 7.12 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als z-standardisiert bezeichnen, da wir sie in Bezug zur â€œtypischen Abweichungâ€, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildungÂ 7.12: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (â€œTransformationâ€) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (aus Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.8 (z-Werte) z-Werte sind das Resultat der z-Transformation. FÃ¼r die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i := \\frac{x_i - \\bar{x}}{sd_x}.\\;\\square\\)\n\nz-Werte sind nÃ¼tzlich, weil sie die â€œrelativeâ€ Abweichung einzelner Beobachtungen vom Mittelwert anzeigen. Nach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, AusreiÃŸern), wenn \\(z_i \\ge 2.5\\) (Shimizu, 2022).\n\nDefinition 7.9 (Standardnormalverteilung) Eine Standardnormalverteilung ist eine Normalverteilung mit Mittelwert gleich 0 und Standardabweichung gelich 1. Man schreibt kurz: \\(X \\sim \\mathcal{N}(0, 1)\\quad \\square\\).\n\nMan kann jeder Normalverteilung in eine Standardnormalverteilung Ã¼berfÃ¼hren mit der z-Transformation.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.6 Aufgaben",
    "text": "7.6 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nmariokart-sd2\nmariokart-sd3\nKennwert-robust\nsummarise04\nsummarise05\nvis-mariokart-variab\nsd-vergleich\nnasa01\nStreuung-Histogramm\nmariokart-sd1\nsummarise06\nmariokart-desk01\n\n\nÃœbungsaufgabe 7.2 (Analysieren Sie den Datensatz zur Handynutzung) Â \n\n\n\nDie Forschungsfrage einer Studie fragt, ob Handynutzung die KonzentrationsfÃ¤higkeit verringert. Nehmen Sie ggf. an der Studie (Umfrage) teil (sie ist anonym und dauert drei Minuten).\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaden Sie den Datensatz zur Handynutzung von Google-Docs herunter.2 Berechnen Sie dann gÃ¤ngige deskriptive Statistiken und visualisieren Sie sie. \\(\\square\\)\nLÃ¶sung: Daten importieren\nSie kÃ¶nnen die Daten entweder selber herunterladen oder aber die folgende Version des Datensatzes verwenden. In beiden FÃ¤llen ist es nÃ¼tzlich, den (absoluten oder relativen) Pfad anzugeben:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\n\n\n\n\n\n\n\n\n\nDann kÃ¶nnen Sie die Daten wie gewohnt importieren:\n\nsmartphone_raw &lt;- read.csv(data_path)\n\nLÃ¶sung: Daten aufbereiten\nDie Spaltennamen sind sehr unschÃ¶n. Lassen Sie uns daher die Spaltennamen umbenennen (aber vorab sichern):\n\nitem_labels &lt;- names(smartphone_raw)\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:ncol(smartphone_raw))\n\nCheck:\n\nglimpse(smartphone_raw)\n## Rows: 70\n## Columns: 18\n## $ item1  &lt;chr&gt; \"21/03/2024 15:36:52\", \"05/04/2024 10:24:58\", \"05/04/2024 10â€¦\n## $ item2  &lt;chr&gt; \"15:31:00\", \"10:23:00\", \"10:40:00\", \"11:14:00\", \"12:33:00\", â€¦\n## $ item3  &lt;int&gt; 3, 4, 3, 3, 5, 5, 5, 5, 1, 2, 5, 3, 2, 2, 2, 5, 3, 1, 2, 4, â€¦\n## $ item4  &lt;int&gt; 5, 3, 3, 3, 4, 3, 3, 6, 2, 4, 5, 1, 1, 2, 3, 3, 4, 3, 2, 4, â€¦\n## $ item5  &lt;int&gt; 3, 3, 1, 5, 1, 3, 2, 4, 3, 2, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, â€¦\n## $ item6  &lt;int&gt; 4, 2, 4, 3, 5, 4, 6, 3, 2, 5, 6, 4, 2, 6, 5, 5, 5, 5, 5, 4, â€¦\n## $ item7  &lt;int&gt; 4, 3, 2, 3, 3, 1, 3, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 2, 2, 2, â€¦\n## $ item8  &lt;int&gt; 1, 3, 1, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 4, 1, 1, 2, 2, 1, 2, â€¦\n## $ item9  &lt;int&gt; 2, 6, 1, 3, 6, 5, 5, 2, 2, 5, 6, 1, 1, 5, 4, 6, 2, 4, 3, 4, â€¦\n## $ item10 &lt;int&gt; 2, 5, 5, 3, 4, 3, 1, 5, 1, 5, 3, 4, 3, 5, 4, 4, 4, 5, 3, 2, â€¦\n## $ item11 &lt;int&gt; 5, 6, 6, 5, 6, 6, 5, 6, 4, 3, 6, 4, 4, 5, 3, 6, 6, 4, 4, 5, â€¦\n## $ item12 &lt;int&gt; 1, 3, 1, 2, 5, 2, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, â€¦\n## $ item13 &lt;int&gt; 4, 3, 4, 2, 4, 2, 5, 3, 1, 1, 4, 1, 3, 4, 1, 3, 5, 2, 1, 4, â€¦\n## $ item14 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item15 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item16 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦\n## $ item17 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", â€¦\n## $ item18 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦\n\n\n7.6.1 Komplette LÃ¶sung\nğŸ˜\n\n\n\n7.6.2 Fallstudie zur Lebenszufriedenheit\nDie OECD fÃ¼hrt eine weltweite Studie zur Lebenszufriedenheit durch.3 Arbeiten Sie die die Fallstudie â€œoecd-yacsdaâ€ im Datenwerk durch, um ein tieferes VerstÃ¤ndnis fÃ¼r die Lebenszufriedenheit in verschiedenen LÃ¤ndern der Welt zu bekommen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "\n7.7 Literaturhinweise",
    "text": "7.7 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnÃ¼glich zu lesenden Buch eine kurzweilige EinfÃ¼hrung in die Statistik vor; auch StreuungsmaÃŸe haben dabei einen Auftritt. Wer mehr â€œLehrbuch-Feelingâ€ sucht, wird bei Ã‡etinkaya-Runde & Hardin (2021) fÃ¼ndig (das Buch ist online frei verfÃ¼gbar). Es ist kein Geheimnis, dass StreuungsmaÃŸe keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne StreuungsmaÃŸe gehtâ€™s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonst wo) aus dem Regal ziehen, fÃ¼ndig werden zu diesem Thema. Die BÃ¼cher unterscheiden sich meist â€œnurâ€ in ihrem Anspruch bzw. der didaktischen Aufmachung; fÃ¼r jeden Geschmack ist da was dabei.\n\n\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric Visualisation of the Variance of the Example Distribution (2, 4, 4, 4, 5, 5, 7, 9) on w:Standard Deviation. [Artwork]. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nflaticon. (2024). Professor [Artwork]. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nShimizu, Y. (2022). Multiple Desirable Methods in Outlier Detection of Univariate Data With R Source Codes. Frontiers in Psychology, 12, 819854. https://doi.org/10.3389/fpsyg.2021.819854",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7Â  ModellgÃ¼te\n",
    "section": "",
    "text": "Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine â€¦â†©ï¸\nhttps://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharingâ†©ï¸\nhttps://www.oecd.org/wise/measuring-well-being-and-progress.htmâ†©ï¸",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>ModellgÃ¼te</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1 Einstieg\nIn diesem Kapitel benÃ¶tigen Sie die Ã¼blichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#einstieg",
    "href": "070-zusammenhaenge.html#einstieg",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Lernziele\n\nSie kÃ¶nnen die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenhang erlÃ¤utern.\nSie kÃ¶nnen die StÃ¤rke einer Korrelation einschÃ¤tzen.\n\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n8.1.2 Zum Einstieg\n\nÃœbungsaufgabe 8.1 Â \n\nSuchen Sie sich eine vertrauenswÃ¼rdige Partnerin oder einen vertrauenswÃ¼rdigen Partner. Im Zweifel reicht die erste Person, die Sie sehen. ğŸ˜\n\nFragne Sie diese Person nach je zwei Variablen, die wie folgt zusammenhÃ¤ngen:\n\n\ngleichsinnig (Viel von dem einen, viel von dem anderen)\ngegensinnig (viel von dem einen, wenig von dem anderen)\nScheinzusammenhang (hÃ¤ngt zusammen, ist aber nicht â€œechtâ€ bzw. kausal) \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl, zu einem â€œPunktâ€ sozusagen, zusammengefasst werden kann. In diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. AbbildungÂ 8.1. WÃ¤hrend wir in Kapitel 6 eine Variable mit Hilfe eines LagemaÃŸes beschrieben (bzw. dargestellt, zusammengefasst, modelliert) haben, tun wir hier das Gleiche fÃ¼r zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen voneinander (statistisch) abhÃ¤ngen bzw. miteinander (in welcher Form auch immer) zusammenhÃ¤ngen. Wir begrenzen uns auf metrische Variablen.\n\n\n\n\n\nAbbildungÂ 8.1: Zwei Spalten werden zu einer Zahl zusammengefasst\n\n\n\n\n\n\n\n\n\n\n\nDie Verbildlichung (Visualisierung) zweier metrischer Variablen haben wir bereits in Kapitel 5.6.2 kennengelernt. Zur Verdeutlichung wie ein Zusammenhang zweier metrischer Variablen aussehen kann, hilft noch einmal AbbildungÂ 8.2.\n\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Verwackeltes Streudiagramm\n\n\n\n\n\n\nAbbildungÂ 8.2: Visualisierung des Zusammenhangs von wheels und total_pr. (a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung). (b) â€˜Verwackeltesâ€™ Streudiagramm, um die einzelnen Punkte besser zu erkennen",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\nDie StÃ¤rke des linearen Zusammenhangs zweier metrischer Variablen kann man gut mithilfe von Abweichungsrechtecken veranschaulichen. Los gehtâ€™s!\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.1 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurÃ¼ckbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhÃ¤ngen.1 Gar nicht so schlecht ausgefallen wie gedacht â€¦, s. TabelleÂ 8.1. \\(\\square\\)\n\n\n\n\nTabelleÂ 8.1: Punkte in der Statistikklausur (x, 0-100) und Lernzeit (y, 0-100)\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. AbbildungÂ 8.3. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso fÃ¼r \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\). Die FlÃ¤che des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\). \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 8.3: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus AbbildungÂ 8.3. Nennen wir das resultierende Rechteck das â€œSummenrechteckâ€. Ja, ich weiÃŸ, ich strapaziere mal wieder Ihre Phantasie. Jetzt kommtâ€™s: Je grÃ¶ÃŸer die FlÃ¤che des Summenrechtecks ist, desto stÃ¤rker der (lineare) Zusammenhang. Beachten Sie, dass die FlÃ¤chen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nachdem, in welchem der vier Quadranten sie stehen. Die FÃ¼llfarben der Rechtecke verdeutlichen dies, s. AbbildungÂ 8.3. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist. So zeigt AbbildungÂ 8.4 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Teildiagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (oben-rechts und unten-links) Ã¼berwiegt; im rechten Teildiagramm ist es umgekehrt: Die Rechtecke in Quadranten mit negativem Vorzeichen Ã¼berwiegen (oben-links und unten-rechts).\n\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten rechts-oben und links-unten) Ã¼berwiegen, was in einer positiven Kovarianz resultiert\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Negative Vorzeichen (Quadranten links-oben und rechts-unten) Ã¼berwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildungÂ 8.4: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die FlÃ¤chen der Abweichungsrechtecke addiert.\n\n\n\nWir kÃ¶nnen das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das Ã¤ndert nichts an der Aussage, aber der Mittelwert hat gegenÃ¼ber der Summe den Vorteil, dass er in seiner Aussage unabhÃ¤ngig ist von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck. Ein MaÃŸ fÃ¼r den Zusammenhang von Lernzeit und Klausurpunkte ist also die FlÃ¤che des mittleren Abweichungsrechtecks, s. AbbildungÂ 8.5.\n\n\n\n\n\nAbbildungÂ 8.5: Die Kovarianz als mittleres Abweichungsrechteck. Die FlÃ¤che der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die FlÃ¤che des mittleren Abweichungsrechtecks. Sie ist ein MaÃŸ fÃ¼r die StÃ¤rke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. AbbildungÂ 8.5. \\(\\square\\)\n\n\nğŸ§‘â€ğŸ“ Zu viele Bilder! Ich brauch Zahlen.\n\n\nğŸ§‘â€ğŸ« Kommen gleich!\n\nTabelleÂ 8.2 zeigt beispielhaft, wie sich die Kovarianz berechnet. Berechnen wir als NÃ¤chstes das mittlere Abweichungsrechteck, die Kovarianz, fÃ¼r die Noten und Lernzeit der vier Studierenden aus TabelleÂ 8.1. Sie betrÃ¤gt 162.\nWenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv.\n\n\n\nTabelleÂ 8.2: Werte der Abweichungsrechtecke. avg: average (Mittelwert), cov_sign: Vorzeichen der Kovarianz,_pos: positiver Wert auf der entsprechenden Achse (x/y), xy_area: Produkt von x_delta und y_delta\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51\n17\n20.8\n1\n353\n\n\n2\n44\n40\n53\n51\n-13\n-7.2\n1\n94\n\n\n3\n39\n35\n53\n51\n-18\n-12.2\n1\n220\n\n\n4\n50\n67\n53\n51\n14\n-1.2\n-1\n-18\n\n\n\n\n\n\n\n\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. GleichungÂ 8.1:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.1}\\]\nGleichungÂ 8.1 in Worten ausgedrÃ¼ckt:\n\nRechne fÃ¼r jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne fÃ¼r jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere fÃ¼r alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die FlÃ¤chen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.2 (Variablen mit positiver Kovarianz) Â \n\nGrÃ¶ÃŸe und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf \\(\\square\\)\n\n\n\n\nBeispiel 8.3 (Variablen mit negativer Kovarianz) Â \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und DepressivitÃ¤t\\(\\square\\)\n\n\n\nZwei Extrembeispiele fÃ¼r Kovarianz-Werte sind in AbbildungÂ 8.6 dargestellt.\n\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\nAbbildungÂ 8.6: Verschiedene Werte der Kovarianz\n\n\n\nBei einer Kovarianz von (ungefÃ¤hr) Null ist die Gesamt-FlÃ¤che der Abweichungsrechtecke, wenn man sie pro Quadrant aufsummiert, (ungefÃ¤hr) gleich groÃŸ, s. AbbildungÂ 8.7. Zur Erinnerung: Bei der Varianz waren es Quadrate; bei der Kovarianz sind es jetzt Rechtecke.\nAddiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen), so betrÃ¤gt die Summe in etwa (bzw. genau) Null. Damit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null, s. GleichungÂ 8.2: Wenn die Summe der Aweichungsrechtecke Null ist, dann ist auch ihr Mittelwert (MW) Null. Damit ist die Kovarianz Null.\n\\[\\begin{aligned}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{MW} \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov}(X, Y) &= 0\n\\end{aligned} \\tag{8.2}\\]\n\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke\n\n\n\n\n\n\nAbbildungÂ 8.7: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus; ihre FlÃ¤che addiert zu 0.\n\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhÃ¤ngig ist von der Skalierung. So steigt die Kovarianz z.\\(\\,\\)B. um den Faktor 100, wenn man eine Variable (z.\\(\\,\\)B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wÃ¼nschenswert, denn der Zusammenhang zwischen z.\\(\\,\\)B. Einkommen und Lebenszufriedenheit ist unabhÃ¤ngig davon, ob man Einkommen in Euro, Cent oder Dollar misst. AuÃŸerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson (1896) lÃ¶st das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nÃ¤mlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so fÃ¼hrt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) definieren wie in DefinitionÂ 8.3.\n\nDefinition 8.3 (Korrelationskoeffizient \\(r\\)) Der Korrelationskoeffizient \\(r\\) (nach Pearson) ist definiert als das mittlere Produkt der z-Wert-Paare, s. GleichungÂ 8.3, vgl. Cohen et al. (2003). Er ist ein MaÃŸ des linearen Zusammenhangs zweier metrischer Variablen. Der Wertebereich ist \\([-1;1]\\), wobei 0 keinen linearen Zusammenhang anzeigt und \\(|r|=1\\) perfekten linearen Zusammenhang. \\(\\square\\)\n\n\\[r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i} \\tag{8.3}\\]\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur fÃ¼r metrische Variablen definiert ist. Aus dem Korrelationskoeffizienten kÃ¶nnen Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert (Betrag) des Korrelationskoeffizienten gibt die StÃ¤rke des linearen Zusammenhangs an. Je nÃ¤her der Wert bei 1 liegt, desto stÃ¤rker ist der (lineare) Zusammenhang.\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt AbbildungÂ 8.8.\n\n\n\n\n\nAbbildungÂ 8.8: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden (DenisBoigelot, 2011)\n\n\nDie untere Zeile von AbbildungÂ 8.8 zeigt Beispiele fÃ¼r nicht-lineare ZusammenhÃ¤nge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammenhang besteht.\n\nÃœbungsaufgabe 8.2 (Korrelationsspiel) Spielen Sie das Korrelationsspiel2: Sie Sehen ein Streudiagramm und mÃ¼ssen den richtigen Korrelationskoeffizienten eingeben. \\(\\square\\)\n\n\nÃœbungsaufgabe 8.3 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist3 findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr GefÃ¼hl fÃ¼r die StÃ¤rke des Korrelationskoeffizienten zu entwickeln. \\(\\square\\)\n\nEine Korrelation von \\(r = 0\\) bedeutet, dass es keinen linearen Zusammenhang gibt; eine Korrelation von \\(|r| = 1\\) meint einen perfekten linearen Zusammenhang. Aber was ist ein â€œschwacherâ€, â€œmittlererâ€ oder â€œstarkerâ€ Zusammenhang? Cohen (1988) hat dazu grobe (!) Richtlinien vorgeschlagen, s. TabelleÂ 8.3.\n\n\nTabelleÂ 8.3: Interpretation von (absoluten) Korrelationskoeffizienten\n\n\n\n\\(|r|\\)\nGrobe Interpretation\n\n\n\n0.01 â€“ 0.09\nsehr schwach\n\n\n0.10 â€“ 0.29\nschwach\n\n\n0.30 â€“ 0.49\nmittel\n\n\nâ‰¥0.50\nstark\n\n\n\n\n\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhÃ¤ngt? Schauen wir nach! Die Funktion correlation (aus dem Paket easystats) erledigt das Rechnen fÃ¼r uns, s. TabelleÂ 8.4.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  |&gt;  # aus `easystats`\n  summary()\n\n\n\n\nTabelleÂ 8.4: Korrelation berechnen mittels der Funktion correlation aus easystats\n\n\n\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\n\n\n\n\n\nSie kÃ¶nnen auch auf die letzte Zeile, also dem Befehl summary verzichten. Dann ist die Ausgabe ausfÃ¼hrlicher.\n\n8.4.3 Korrelation ist nicht Kausation\nEine Studie fand eine starke Korrelation zwischen der (HÃ¶he des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. AbbildungÂ 8.9.\n\n\n\n\n\nAbbildungÂ 8.9: Schoki futtern macht schlau? (Messerli, 2012)\n\n\nKorrelation (bzw. Zusammenhang) ist ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.4 (Scheinkorrelation: StÃ¶rche und Babys) Ein Mythos besagt: Die Anzahl der StÃ¶rche pro Landkreis korreliert mit der Anzahl der Babys in diesem Landkreis (vgl. Matthews, 2000). Eine mÃ¶gliche ErklÃ¤rung fÃ¼r dieses (nur scheinbare) Paradoxon ist, dass die â€œNaturbelassenheitâ€ des Landkreises die gemeinsame Ursache von StÃ¶rchen ist (StÃ¶rche lieben Natur) und Babys ist (die Gegebenheiten bei hoher Naturbelassenheit begÃ¼nstigteine hÃ¶here Zahl von Kindern pro Frau). Wir mÃ¼ssen die ErklÃ¤rung keinesfalls glauben; sie soll das Beispiel nur konkreter machen. Uns geht es hier nur um die Erkennung von Scheinkorrelation. \\(\\square\\)\n\n\nBeispiel 8.5 (Glatze macht Corona?) Kahle MÃ¤nner aufgepasst! Macht eine Glatze krank? MÃ¤nner mit Glatze bekommen hÃ¤ufiger Corona (Goren et al., 2020): â€œBald men at higher risk of severe case of Covid-19, research findsâ€. Eine alternative ErklÃ¤rung lautet, dass Alter einen Effekt hat auf Glatze (je Ã¤lter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatze hat) und auf die Schwere des Corona-Verlaufs (Ã¤ltere Menschen haben deutlich schwerere Corona-VerlÃ¤ufe). \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lÃ¼gt",
    "text": "8.5 Wie man mit Statistik lÃ¼gt\n\n8.5.1 EinschrÃ¤nkung der Spannweite\nDurch (nicht-randomisierte) EinschrÃ¤nkung (Restriktion) der Spannweite einer (oder beider) Variablen sinkt die StÃ¤rke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003); s. AbbildungÂ 8.10.\nErstellen wir uns dazu zwei DatensÃ¤tze mit je zwei Variablen, \\(X\\) und \\(Y\\) und mit Umfang \\(n=100\\). Einer der beiden DatensÃ¤tze sei mit EinschrÃ¤nkung der Spannweite und einer ohne. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in ListingÂ 8.1. Man kann sich mit dem Befehl rnorm(n, m, sd) \\(n\\) normalverteilte Variablen mit Mittelwert \\(m\\) und Streuung \\(sd\\) von R erzeugen lassen. Wir schrÃ¤nken dann den Wertebereich von \\(X\\) ein auf, sagen wir, auf \\([-0.5, .5]\\) (Datensatz d_filtered), s. ListingÂ 8.1.\n\n\n\nListingÂ 8.1: Korrelation mit eingeschrÃ¤nkter Spannweite\n\nn &lt;- 1e2\nd &lt;- tibble(x = rnorm(n = n, mean = 0, sd = 1),\n            e = rnorm(n = n, mean = 0, sd = .5),\n            y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-  # Range-EinschrÃ¤nkung:\nd |&gt; filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne EinschrÃ¤nkung des Range: Starke Korrelation\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Mit EinschrÃ¤nkung des Range: SchwÃ¤chere Korrelation\n\n\n\n\n\n\nAbbildungÂ 8.10: SchrÃ¤nkt man den Range einer (oder beider) Variablen ein, so sinkt die StÃ¤rke der Korrelation\n\n\n\n\nÃœbungsaufgabe 8.4 (Berechnen Sie die Korrelation) Glauben Sie nicht, prÃ¼fen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhÃ¤ngen. Falls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, kÃ¶nnen Sie die Daten so (in mittlerweile gewohnter Manier) importieren: mariokart &lt;- read.csv(\"mariokart.csv\") Falls der Datensatz im Unterordner mit Namen â€œMein_Unterordnerâ€ liegt, so wÃ¼rden Sie folgenden Pfad eingeben: mariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\"). Man beachte, dass solche sog. relativen Pfade, wie Mein_Unterordner/, die relativ zu Ihrem Arbeitsverzeichnis, d.\\(\\,\\)h. Ihr Projektverzeichnis in R-Studio, liegen, nicht mit einem SchrÃ¤gstrich (Slash) beginnen. Falls Sie die Daten nicht auf Ihrem Computer haben, kÃ¶nnen Sie sie bequem von z.\\(\\,\\)B. der Webseite von Vincent Arel-Bundock herunterladen. Den Pfad hatten wir in ListingÂ 1.1 definiert.\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wÃ¤hlen die Variablen von mariokart, die Sie in diesem Fall interessieren â€“ natÃ¼rlich nur die metrischen â€“ und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\nAchtung, Namensverwechslung! Es kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.\\(\\,\\)B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemÃ¤ÃŸ sagt: â€œHey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.â€ Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: â€œHey R, nimm gefÃ¤lligst select aus dem Paket dplyr, dortâ€wohntâ€ nÃ¤mlich select. Auf Errisch spricht sich das so: dplyr::select(...).\nEtwas schÃ¶ner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. TabelleÂ 8.5.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nTabelleÂ 8.5: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nwheels\nseller_rate\ntotal_pr\nship_pr\nstart_pr\nn_bids\n\n\n\nduration\n-0.30**\n-0.15\n-0.04\n0.27*\n0.13\n-0.12\n\n\nn_bids\n-0.08\n-0.11\n0.13\n0.03\n-0.63***\n\n\n\nstart_pr\n0.16\n0.28*\n0.07\n0.03\n\n\n\n\nship_pr\n0.05\n-0.02\n0.54***\n\n\n\n\n\ntotal_pr\n0.33**\n0.01\n\n\n\n\n\n\nseller_rate\n-0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Sternchen in TabelleÂ 8.5 geben die sog. statistische Signifikanz der Korrelation an; ein Thema, das wir einfach gekonnt ignorieren.\nMÃ¶chte man nur einzelne Korrelationskoeffizienten ausrechnen, kÃ¶nnen wir die Idee des Zusammenfassens, s. AbbildungÂ 8.1, nutzen: mariokart %&gt;% summarise(korrelation = cor(total_pr, wheels)).\nIm Falle von fehlenden Werte mÃ¼ssen Sie den Befehl cor aus seiner schÃ¼chternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor.\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\nğŸ§‘â€ğŸ“ Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket dataExplorer bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. AbbildungÂ 8.11.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildungÂ 8.11: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.7 Aufgaben",
    "text": "8.7 Aufgaben\nSchauen Sie sich auch mal auf der Webseite Datenwerk4 die Aufgaben zu dem Tag association an.\n\nnasa02\nmariokart-korr1\nmariokart-korr2\nmariokart-korr3\nmariokart-korr4\nkorr01\nkorr02\n\n\n\n\nTesten Sie Ihr Wissen mit einem Quiz zur deskriptiven Statistik (MaÃŸe der zentralen Tendenz, VariabilitÃ¤t, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.8 Fallstudien",
    "text": "8.8 Fallstudien\nBitte verstehen Sie die folgenden Fallstudien als eine Auswahl. Es ist nicht nÃ¶tig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Ãœbung, dort, wo Sie es nÃ¶tig haben.\n\n\nYACSDA: EDA zu FlugverspÃ¤tungen5 im Datenwerk unter dem Tag flights-yacsda-eda zu finden.\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Ãœbungsaufgaben kÃ¶nnen theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer LÃ¶sung anhand von Konzepten bzw. R-Befehlen, die Sie kennen. \\(\\square\\)\n\n\n\n\nYACSDA: Topgear6\n\n\nDatensatz flights: Finde den Tag mit den meisten AbflÃ¼gen7\n\n\nTidyverse Case Study: Exploring the Billboard Charts8",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8Â  Punktmodelle 2",
    "section": "\n8.9 Literaturhinweise",
    "text": "8.9 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erlÃ¤utern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schÃ¶nes, modernes Statistikbuch bietet Poldrack (2023); auch dieses Buch ist frei online verfÃ¼gbar. Tipp: Nutzen Sie die Ãœbersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas hÃ¶heren Anspruchs. Was ist Scheinkorrelation und was ist â€œechteâ€ Korrelation? Dieser Unterschied â€“ der fÃ¼r die Wissenschaft zentral ist â€“ wird von Pearl & Mackenzie (2018) auf entspannte Art erlÃ¤utert; nebenbei lernt man einiges zur Geschichte der Wissenshaft.\nHier finden Sie weitere Beispiele fÃ¼r Scheinkorrelationen. Dieser TED-Vortrag informiert zum Thema Scheinkorrelation.\n\n\n\n\nCohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed. Lawrence Erlbaum.\n\n\nDenisBoigelot. (2011). English: Redesign File:Correlation_examples.Png Using Vector Graphics (SVG File) [Artwork]. https://commons.wikimedia.org/w/index.php?curid=15165296\n\n\nGoren, A., VaÃ±o-GalvÃ¡n, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain â€“ A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545â€“1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562â€“1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPearl, J., & Mackenzie, D. (2018). The Book of Why: The New Science of Cause and Effect. Basic Books.\n\n\nPearson, K. (1896). VII. Mathematical Contributions to the Theory of Evolution.â€”III. Regression, Heredity, and Panmixia. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 187, 253â€“318. https://doi.org/10.1098/rsta.1896.0007\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8Â  Punktmodelle 2",
    "section": "",
    "text": "ğŸ§‘â€ğŸ“ Typisches Lehrerbeispiel!â†©ï¸\nhttps://gallery.shinyapps.io/correlation_game/â†©ï¸\nhttps://rpsychologist.com/correlation/â†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/â†©ï¸\nhttps://sebastiansauer.github.io/Datenwerk/posts/flights-yacsda-edaâ†©ï¸\nhttps://data-se.netlify.app/2021/02/11/yacda-topgear/â†©ï¸\nhttps://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/â†©ï¸\nhttps://www.njtierney.com/post/2017/11/07/tidyverse-billboard/â†©ï¸",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benÃ¶tigen Sie die Ã¼blichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#einstieg",
    "href": "080-regression1.html#einstieg",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Lernziele\n\nSie kÃ¶nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie kÃ¶nnen die Bestandteile eines Geradenmodells aufzÃ¤hlen und erlÃ¤utern.\nSie kÃ¶nnen die GÃ¼te eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie kÃ¶nnen Geradenmodelle sowie ihre ModellgÃ¼te in R berechnen.\n\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nÃ¼tzliche Sache, unter (mindestens) folgenden Voraussetzungen: 1. Sie sind prÃ¤zise; 2. Wir wissen, wie prÃ¤zise; 3. Jemand interessiert sich fÃ¼r die Vorhersage. Die Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne UV\n\nBeispiel 9.1 Nach intensiver BeschÃ¤ftigung mit Statistik sind Sie allgemein als Daten-Checker bekannt. Viele Studierende fragen Sie um Rat. Eines Tages kommt eine Studentin zu Ihnen, Toni, und fragt: â€œWelche Statistiknote kann ich in der Klausur erwarten?â€ Sie entgegnen: â€œWie viel hast du denn gelernt?â€. Die Antwort: â€œSage ich nicht.â€ Nach kurzem Ãœberlegen geben Sie den Notenschnitt der letzten Klausur als Prognose fÃ¼r diese Person. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in ListingÂ 9.1 wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls mÃ¼ssen Sie die Daten erst herunterladen1:\n\n\n\nListingÂ 9.1: Wenn der Datensatz â€˜noten2â€™ im Unterordner â€˜Notenâ€™ liegt.\n\nnoten2 &lt;- read.csv(\"data/noten2.csv\")\n\n\n\n\n Download \n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n\nmw\n\n\n91\n\n\n\n\nIhre Ãœberlegung: â€œIm Schnitt haben die Studis bei der letzten Klausur ungefÃ¤hr 91.12 erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.\\(\\,\\)B. wie viel du gelernt hast, kann ich dir keine genauere Vorhersage machen. Sorry!â€ \\(\\square\\)\n\nOhne Kenntnis einer UV (PrÃ¤diktor) (wie z.\\(\\,\\)B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert fÃ¼r jede Beobachtung, s. AbbildungÂ 9.1. Wir nutzen den Mittelwert als Punktmodell fÃ¼r den Klausurerfolg. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildungÂ 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\nDefinition 9.1 (Nullmodell (Punktmodell)) Modelle ohne UV, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null UV hat, nennt man es auch manchmal Nullmodell. \\(\\square\\)\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n# results: show\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        91.1\n\nlm steht fÃ¼r â€œlineares Modellâ€, die 1 sagt, dass es keine PrÃ¤diktoren gibt. In dem Fall wird der Mittelwert, 91, als Gerade verwendet. Der zurÃ¼ckgemeldete Koeffizient (Intercept) ist in diesem Fall der einzige Koeffizient des Modells. Da es ein Punktmodell ist, sagt es fÃ¼r alle Beobachtungen (hier Studierenden) den gleichen Wert vorher, nÃ¤mlich 91.\n\n9.2.2 Vorhersagen mit UV\n\nBeispiel 9.2 (Toni verrÃ¤t die Lernzeit) Toni entschlieÃŸt sich dann doch noch, die Lernzeit zu verraten: â€œOkay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.â€ Jetzt mÃ¼ssen Sie erstmal nachdenken: â€œWie viele Klausurpunkte sage ich vorher, wenn Toni 42 Stunden gelernt hat?â€\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. AbbildungÂ 9.2, (a).\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: â€œBei 42 Stunden Lernzeit solltest du so 83 Punkte bekommen. KÃ¶nnte mit dem Bestehen eng werden.â€ Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen. \\(\\square\\)\n\nDer â€œTrendâ€ (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen: Je mehr Lernzeit, desto mehr Klausurpunkte. Mit einem Lineal kÃ¶nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. AbbildungÂ 9.2, (b).\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm\n\n\n\n\n\n\n\n\n\n(b) Streudigramm mit â€˜Trendgeradeâ€™\n\n\n\n\n\n\nAbbildungÂ 9.2: Noten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt markiert.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell fÃ¼r die Daten, s. AbbildungÂ 9.2, b. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden. Ein Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt fÃ¼r alle Beobachtungen den gleichen Wert vorher. AbbildungÂ 9.1 und AbbildungÂ 9.2 stellen ein Punktmodell einem Geradenmodell gegenÃ¼ber.\nIn einem Geradenmodell wird nicht mehr (notwendig) fÃ¼r jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.2 (Gerade) Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). \\(\\square\\)\n\nManchmal wird (z.\\(\\,\\)B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet:\n\n\\(f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + \\color{beta1col}{b_1} \\color{xcol}{x}\\) .\nDie Nomenklatur mit \\(\\color{beta0col}{b_0}, \\color{beta1col}{b_1}\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, \\ldots\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage Ã¼ber eine Population, nicht nur Ã¼ber eine Stichprobe, machen mÃ¶chte.\nDas â€œDachâ€ Ã¼ber y, \\(\\color{modelcol}{\\hat{y}}\\) (sprich: â€œy-Dachâ€), drÃ¼ckt aus, dass es sich den den geschÃ¤tzten, bzw. vom Modell vorhergesagten (â€œmodelliertenâ€) Wert fÃ¼r \\(\\color{ycol}{y}\\) handelt, nicht der tatsÃ¤chliche (empirische, beobachtete) Wert von \\(\\color{ycol}{y}\\). AbbildungÂ 9.3 skizziert die Elemente einer Regression.\n\n\n\n\n\nAbbildungÂ 9.3: Achsenabschnitt (\\(\\beta_0\\)) und Steigung (\\(\\beta_1\\)) einer Regressionsgeraden (Menk, 2014)\n\n\n\n\nDefinition 9.3 (Das einfache lineare Modell) Das einfache lineare Modell beschreibt den Wert einer abhÃ¤ngigen metrischen Variablen, \\(\\color{ycol}{y}\\), als lineare Funktion von einer (oder mehreren) unabhÃ¤ngigen Variablen, \\(\\color{xcol}{x}\\), plus einem Fehlerterm, \\(\\color{errorcol}{e}\\) bzw. \\(\\color{errorcol}{\\epsilon}\\), s. GleichungÂ 9.1. \\(\\square\\)\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned} \\tag{9.1}\\]\nDie Variablen in GleichungÂ 9.1 haben folgende Bedeutung:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschÃ¤tzter y-Achsenabschnitt laut Modell (engl. intercept)\n\n\\(\\color{beta1col}{\\beta_1}\\): geschÃ¤tzte Steigung (Regressionsgewicht) laut Modell (engl. slope)\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nIn GleichungÂ 9.1 schreiben wir \\(\\color{ycol}{y}\\) und nicht \\(\\color{modelcol}{\\hat{y}}\\), weil wir den tatsÃ¤chlichen, beobachteten Wert von \\(\\color{ycol}{y}\\) als Summe von vorhergesagtem Wert, \\(\\color{modelcol}{\\hat{y}}\\) und Modellfehler, \\(\\color{errorcol}{\\epsilon}\\) beschreiben.\nJe nach Datenlage kÃ¶nnen sich Regressionsgeraden in Steigung oder Achsenabschnitt unterscheiden, s. AbbildungÂ 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildungÂ 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher ModellgÃ¼te\n\n\nAbbildungÂ 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie kÃ¶nnen Punkte per Klick/Touch hinzufÃ¼gen.\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"RÂ²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\nAbbildungÂ 9.5: Interaktives Beispiel fÃ¼r eines lineares Modell. FÃ¼gen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert: â€œOkay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurÃ¼ck!â€ Das sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{x}=0\\) gibt der Achsenabschnitt zurÃ¼ck. Schnell skizzieren Sie dazu ein Diagramm, s. AbbildungÂ 9.6. Puh, die Antwort wird Toni nicht gefallen â€¦ \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildungÂ 9.6: Der Achsenabschnitt: Wie viele Punkte kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf AbbildungÂ 9.6 zu schauen, kÃ¶nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\nğŸ§‘â€ğŸ« Hey R, predicte mir mal auf Basis vom Modell â€œlm_toniâ€ den Lernerfolg fÃ¼r Toni, wenn der x=0 Stunden lernt.\n\n\nğŸ¤– Okay, ich predicte mit Modell â€œlm_toniâ€ und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)  # `tibble` erstellt einen Dataframe\n\n\npredict(lm_toni, newdata = tonis_lernzeit)\n##  1 \n## 46\n\npredict erwartet fÃ¼r das Argument newdata einen Dataframe. In diesem Beispiel heiÃŸt er tonis_lernzeit.\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall spezifizieren wie GleichungÂ 9.2 dargestellt.\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.2}\\]\nLies: â€œLaut meinem Modell ist mein vorhergesagtes \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)â€. Wir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist: \\(\\color{ycol}{AV} \\sim \\color{xcol}{UV}\\).\nWir werden als Funktion nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns vom Computer ausrechnen. GleichungÂ 9.2 kÃ¶nnen Sie so ins Errische Ã¼bersetzen: lm(y ~ x, data = meine_daten).\nlm steht fÃ¼r â€œlineares Modellâ€, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade (an anderer Stelle in diesem Buch unscharf als â€œTrendgeradeâ€ bezeichnet).\n\nBeispiel 9.4 (Zahlen fÃ¼r Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: â€œJetzt hÃ¶r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sage mir prÃ¤zise Zahlen!â€.\n\n\nlm_toni &lt;- lm(y ~ x, data = noten2)\nlm_toni\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      46.191        0.879\n\nR gibt Ihnen die beiden Koeffizienten fÃ¼r die Gerade aus. Den Namen des Objekts kÃ¶nnen Sie frei aussuchen, z.\\(\\,\\)B. mein_erstes_lm. Die Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x.\n8.6 ist der Achsenabschnitt, d.\\(\\,\\)h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.\\(\\,\\)h. die Steigung der Regressionsgeraden: FÃ¼r jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen, gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 73 Stunden gelernt, wÃ¼rden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 73\ny_pred &lt;- 46 + 0.88*lernzeit\ny_pred\n## [1] 110\n\n\nBeispiel 9.5 (Vorhersage fÃ¼r Klausurerfolg, nÃ¤chster Versuch) Sie versuchen, noch etwas Gutes fÃ¼r Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dÃ¼rfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  \n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n\nx\n\n\n73\n\n\n\n\n\npredict(lm_toni, newdata = tonis_lernzeit2)\n##   1 \n## 110\n\nDie Syntax von predict lautet:\npredict(modell, newdata = tabelle_mit_prÃ¤diktorwerten)\nDie Funktion predict liefert eine Vorhersage fÃ¼r ein ein Modell, z.\\(\\,\\)B. lm_toni, und fÃ¼r einen bestimmten Dataframe (der die Werte der UV enthalten muss).\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagtem Wert fÃ¼r eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsÃ¤chlichen Wert nennt man Vorhersagefehler (error, \\(e\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Geradenmodell (lm_toni)\n\n\n\n\n\n\n\n\n\n(b) Punktmodell (lm0)\n\n\n\n\n\n\nAbbildungÂ 9.7: Vorhersagefehler als Abweichungsbalken. (a) Beim Geradenmodell, sind die Vorhersagefehler (Abweichungsbalken) kleiner (kÃ¼rzer) als in (b), beim Punktmodell.\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt? Lassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket easystats):\n\nmae(lm0)\nmae(lm_toni)\n## [1] 11\n## [1] 8\n\nVergleichen wir MAE im Nullmodell mit MAE in lm_toni:\n\nverhaeltnis_fehler_mae &lt;- mae(lm_toni) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm_toni haben die mittlere AbsolutlÃ¤nge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.4 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Verteilung der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)). \\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere KenngrÃ¶ÃŸen wie MAE oder MSE. Ein Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist. NatÃ¼rlich kÃ¶nnen wir â€“ in Analogie zur Varianz â€“ auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen. Wer mag, kann den MSE auch von Hand berechnen: mean((noten2$y - mean(noten2$y))^2).\n\nmse(lm0)\nmse(lm_toni)\n## [1] 193\n## [1] 106\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm_toni)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n\nBetrachtet man die MSE, so kann man eine Verbesserung um 0.45 auf 0.55 feststellen.\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen? Die Regressionskoeffizienten (hier synonym: Modellparameter) \\(\\beta_0\\) und \\(\\beta_1\\) wÃ¤hlt man so, dass die Residuen minimal sind. Genauer gesagt wird die Summe der quadrierten Residuen minimiert, s. GleichungÂ 9.3.\nAbbildungÂ 9.8 veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildungÂ 9.8: Bildquelle: Karsten LÃ¼bke, FOM Hochschule\n\n\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene Methoden, um die Koeffizienten zu berechnen (die aber nicht in diesem Buch zu finden sind). Eine schÃ¶ne Darstellung dazu findet sich bei Kaplan (2009).\nâ€œVon Handâ€ kÃ¶nnen Sie die Optimierung von \\(\\beta_0\\) und \\(\\beta1\\) in dieser App der FOM-Hochschule2 ausprobieren.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r2-als-maÃŸ-der-modellgÃ¼te",
    "href": "080-regression1.html#r2-als-maÃŸ-der-modellgÃ¼te",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.4 \\(R^2\\) als MaÃŸ der ModellgÃ¼te",
    "text": "9.4 \\(R^2\\) als MaÃŸ der ModellgÃ¼te\nDas Modell lm_toni weist noch 0.55 der Fehlerstreuung (MSE) des Nullmodells auf. Anders gesagt, wir haben uns ( (bzw. das Modell hat sich) um \\(1 - 0.55\\) verbessert.\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n\n\nDefinition 9.5 (\\(R^2\\)-Quadrat) Der Anteil der Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen zwischen lm0 und dem gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). Das R-Quadrat (\\(R^2\\)) eines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein MaÃŸ der ModellgÃ¼te: Je grÃ¶ÃŸer \\(R^2\\), desto besser ist die Vorhersage. Da es ein AnteilsmaÃŸ ist, liegt der Wertebereich zwischen 0 und 1. Im Nullmodell betrÃ¤gt R-Quadrat per Definition Null. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable, \\(y\\), erklÃ¤rt. Wir kÃ¶nnen R-Quadrat (\\(R^2\\)) uns von R z.\\(\\,\\)B. so ausgeben lassen:\n\nr2(lm_toni)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\), vgl. AbbildungÂ 9.9.\n\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Perfekte Korrelation\n\n\n\n\n\n\nAbbildungÂ 9.9: ExtremfÃ¤lle von \\(R^2\\): 0 und 1. (a) Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefÃ¤hr) parallel zur X-Achse. (b) Perfekte Korrelation, r = 1 und \\(R^2\\) = 1: Die Prognose ist gleich dem beobachtetem Wert.\n\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man fÃ¼r jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\) , vorhersagen wÃ¼rde. Je grÃ¶ÃŸer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser â€œerklÃ¤rtâ€ das Modell die Daten (desto besser der â€œFitâ€ des Modells zu den Daten, sagt man).\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der GrÃ¶ÃŸe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 ModellgÃ¼te\nDie Residuen (Vorhersagefehler) bestimmen die ModellgÃ¼te: Sind die Residuen im Schnitt groÃŸ, so ist die ModellgÃ¼te gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur VerfÃ¼gung: \\(R^2\\), \\(r\\) (als Korrelation von tatsÃ¤chlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)), MSE, RMSE, MAE, â€¦\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\)) und Steigung (\\(\\beta_1\\)) sind nur eingeschrÃ¤nkt zu interpretieren, wenn man die zugrundeliegenden kausalen AbhÃ¤ngigkeiten nicht kennt. Allein aufgrund eines statistischen Zusammenhangs darf man keine kausalen AbhÃ¤ngigkeiten annehmen. Ohne eine zugrundeliegende Theorie fÃ¼r eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der ModellgÃ¼te und den Vorhersagen begnÃ¼gen. Was auch was wert ist.\nIm Modell lm_toni liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=46.19\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) kÃ¶nnen also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten, laut lm_toni. Leider ist es hÃ¤ufig so, dass UV mit Wert 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nÃ¼tzt.\n\nBeispiel 9.6 (Regression GrÃ¶ÃŸe und Gewicht) Nutzt man KÃ¶rpergrÃ¶ÃŸe und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von KÃ¶rpergrÃ¶ÃŸe wenig nÃ¼tzlich, da es keine Menschen gibt der GrÃ¶ÃŸe 0. \\(\\square\\)\n\nSo interpretiert man die Geradensteigung, \\(\\beta_1\\): â€œIm Modell lm_toni betrÃ¤gt der Regressionskoeffizient \\(\\beta_1 = 0.88\\). Zwei Studentinnen, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von \\(\\beta_1\\)â€.\n\n\n\n\n\n\nVorsicht\n\n\n\nHÃ¤ufig liest man, der â€œEffekt der UVâ€ auf die AV betrage z.\\(\\,\\)B. \\(0.88\\). â€œEffektâ€ ist aber ein Wort, das man leicht kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort â€œEffektâ€ mit Vorsicht genieÃŸen. Manche sprechen daher auch von einem â€œstatistischen Effektâ€, um zu verdeutlichen, dass keine Kausalaussage impliziert ist. \\(\\square\\)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "080-regression1.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lÃ¼gt",
    "text": "9.6 Wie man mit Statistik lÃ¼gt\nDer Unterschied in ModellgÃ¼te zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) MaÃŸ der ModellgÃ¼te und da \\(r = \\sqrt{R^2}\\), dÃ¼rfen Unterschiede in \\(r\\) nicht auf die gleiche Weise interpretiert werden wie Unterschiede in \\(R^2\\). AbbildungÂ 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildungÂ 9.10: Der Zusammenhang von r und R-Quadrat ist nicht linear.\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dÃ¼rfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie mÃ¶chten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin. Genaue Vorhersagen sind von hoher betriebswirtschaftlicher Relevanz. Mariokart-Daten laden, am besten ohne Extremwerte, s. ListingÂ 5.4 und los gehtâ€™s (und die Ã¼blichen Pakete starten, nicht vergessen)!\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloÃŸem Rumprobieren Ã¼berlegen Sie und schauen dann nach, welche Variable am stÃ¤rksten korreliert mit total_pr; es resultiert lm3. Dann lassen Sie sich die Modellparameter ausgeben, s. TabelleÂ 9.1.\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\n\n\n\n\nTabelleÂ 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Dollar, wie man in TabelleÂ 9.1 sieht: Ein Spiel, das mit null Dollar Preis startet, kann laut lm3 etwa 36 Dollar finaler Verkaufspreis erwarten. Pro Dollar an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Dollar. (Die Spalte 95 CI gibt einen SchÃ¤tzbereich fÃ¼r den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um SchÃ¤tzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schlieÃŸlich nur eine Stichprobe der GrÃ¶ÃŸe \\(n = 143\\).) Die Regressionsgleichung von lm3 lautet demnach: total_pr_pred = 36 + 4*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36 Dollar â€œSockelbetragâ€ plus 4 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (â€œexpectationsâ€) des Verkaufspreises in AbhÃ¤ngigkeit vom Wert der UV (ship_pr) auch schÃ¤tzen (â€œto estimateâ€) lassen, und zwar so mit estimate_expectation(lm3), s. TabelleÂ 9.2.\n\n\n\nTabelleÂ 9.2: Die vorhergesagten (predicted) Werte und die Abweichungen vom vorhergesagten Wert (Residuals)\n\n\n\nModel-based Predictions\n\nship_pr\nPredicted\nSE\n95% CI\nResiduals\n\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-2.04\n\n\n3.99\n53.55\n1.87\n(49.85, 57.25)\n-16.51\n\n\n3.50\n51.43\n1.82\n(47.82, 55.03)\n-5.93\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n7.75\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n34.75\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-8.59\n\n\n\nVariable predicted: total_pr\n\n\n\n\n\nâ€œAh, bei 4 Dollar Versandkosten ist laut dem Modell knapp 54 Dollar Verkaufspreis zu erwartenâ€, fassen Sie sich die Ausgabe zusammen.\n\nğŸ¤– Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert fÃ¼r total_pr fÃ¼r einen bestimmten Wert von ship_pr.\n\n\nğŸ§‘â€ğŸ“ Kann ich auch predict benutzen? Ich wÃ¼rde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Dollar liegen.\n\n\nğŸ¤– Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n\n\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n\nAber nÃ¼tzlich wÃ¤re noch, das Modell (bzw. die SchÃ¤tzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.\\(\\,\\)B. so, s. AbbildungÂ 10.10.\n\nestimate_prediction(lm3, by = \"ship_pr\") %&gt;% plot()\n\n\n\n\n\n\nAbbildungÂ 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heiÃŸt sinngemÃ¤ÃŸ â€œschÃ¤tze den zu erwartenden Wertâ€. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie â€œgutâ€ das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13\n\nDas Modell erklÃ¤rt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n\n\nmae(lm3)\n## [1] 13\n\nIm nÃ¤chsten Meeting erzÃ¤hlen Sie Ihrer Chefin â€œIch kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!â€. HÃ¶rt sich gut an. Allerdings hÃ¤tte es Ihre Chefin gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie fÃ¼hrt in die PrÃ¼fungsleistung â€œPrognosewettbewerbâ€ ein. Es empfiehlt sich fÃ¼r Sie, diese Fallstudie sorgsam zu bearbeiten. \\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei kaggle.com ein. Kaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. In dieser Fallstudie nehmen Sie teil an der Kaggle-Competition â€œHouse Prices - Advanced Regression Techniquesâ€, die Sie auf der Kaggle-Webseite finden. Dort finden Sie auch eine nÃ¤here Beschreibung, das Ziel und die Spielregeln des Wettbewerbs.\n\nBeschreibung\nZiel/Aufgabe\nSpielregeln\n\n9.8.2 Daten\nSie kÃ¶nnen die Daten von www.kaggle.com herunterladen. Im Einzelnen mÃ¼ssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Codebook, d.\\(\\,\\)h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von HÃ¤usern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von HÃ¤usern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen, s. TabelleÂ 9.3\n\n\nSie kÃ¶nnen auch Ã¼ber das Github-Repo statistik1, Ordner data auf die Daten zugreifen:\n\nd_train_path_online &lt;- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-train.csv\")\n\nd_test_path_online &lt;- paste0(\n\"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-test.csv\")\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab. Importieren wir die Daten aus dem Unterordner data in R (davon ausgehend, dass der Unterordner data ein Unterordner Ihres aktuellen R-Projekts ist):\n\nd_train_path &lt;- \"data/kaggle-train.csv\"\nd_test_path &lt;- \"data/kaggle-test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\nWenn das Importieren von Ihrem Computer nicht klappen sollte â€¦ Es ist zwar hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fÃ¼rs Erste kÃ¶nnen Sie die Daten auch von oben angegeben Online-Pfad importieren.\n\n9.8.3 Prognosedatei\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthÃ¤lt. Sie soll prinzipiell so aussehen wie in TabelleÂ 9.3 dargestellt.\n\n\n\nTabelleÂ 9.3: Beispiel fÃ¼r den Aufbau der Prognose-Datei\n\n\n\n\nid\nSalePrice\n\n\n\n1461\n169277\n\n\n1462\n187758\n\n\n1463\n183584\n\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist â€“ fÃ¼r welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice enthÃ¤lt Ihre Vorhersage fÃ¼r den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt. Alles klar? Los gehtâ€™s!\n\n9.8.4 Ein erster Blick in die Daten\nSchauen Sie sich zu Beginn einmal die Verteilung der metrischen Variablen, z.\\(\\,\\)B. mit describe_distribution(d_train) an.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nId\n730.50\n421.61\n730.50\n(1.00, 1460.00)\n0.00\n-1.20\n1460\n0\n\n\nMSSubClass\n56.90\n42.30\n50.00\n(20.00, 190.00)\n1.41\n1.58\n1460\n0\n\n\nLotFrontage\n70.05\n24.28\n21.00\n(21.00, 313.00)\n2.16\n17.45\n1201\n259\n\n\nLotArea\n10516.83\n9981.26\n4060.00\n(1300.00, 2.15e+05)\n12.21\n203.24\n1460\n0\n\n\nOverallQual\n6.10\n1.38\n2.00\n(1.00, 10.00)\n0.22\n0.10\n1460\n0\n\n\nOverallCond\n5.58\n1.11\n1.00\n(1.00, 9.00)\n0.69\n1.11\n1460\n0\n\n\nYearBuilt\n1971.27\n30.20\n46.00\n(1872.00, 2010.00)\n-0.61\n-0.44\n1460\n0\n\n\nYearRemodAdd\n1984.87\n20.65\n37.00\n(1950.00, 2010.00)\n-0.50\n-1.27\n1460\n0\n\n\nMasVnrArea\n103.69\n181.07\n166.00\n(0.00, 1600.00)\n2.67\n10.08\n1452\n8\n\n\nBsmtFinSF1\n443.64\n456.10\n712.75\n(0.00, 5644.00)\n1.69\n11.12\n1460\n0\n\n\nBsmtFinSF2\n46.55\n161.32\n0.00\n(0.00, 1474.00)\n4.26\n20.11\n1460\n0\n\n\nBsmtUnfSF\n567.24\n441.87\n585.00\n(0.00, 2336.00)\n0.92\n0.47\n1460\n0\n\n\nTotalBsmtSF\n1057.43\n438.71\n503.50\n(0.00, 6110.00)\n1.52\n13.25\n1460\n0\n\n\nX1stFlrSF\n1162.63\n386.59\n509.75\n(334.00, 4692.00)\n1.38\n5.75\n1460\n0\n\n\nX2ndFlrSF\n346.99\n436.53\n728.00\n(0.00, 2065.00)\n0.81\n-0.55\n1460\n0\n\n\nLowQualFinSF\n5.84\n48.62\n0.00\n(0.00, 572.00)\n9.01\n83.23\n1460\n0\n\n\nGrLivArea\n1515.46\n525.48\n649.75\n(334.00, 5642.00)\n1.37\n4.90\n1460\n0\n\n\nBsmtFullBath\n0.43\n0.52\n1.00\n(0.00, 3.00)\n0.60\n-0.84\n1460\n0\n\n\nBsmtHalfBath\n0.06\n0.24\n0.00\n(0.00, 2.00)\n4.10\n16.40\n1460\n0\n\n\nFullBath\n1.57\n0.55\n1.00\n(0.00, 3.00)\n0.04\n-0.86\n1460\n0\n\n\nHalfBath\n0.38\n0.50\n1.00\n(0.00, 2.00)\n0.68\n-1.08\n1460\n0\n\n\nBedroomAbvGr\n2.87\n0.82\n1.00\n(0.00, 8.00)\n0.21\n2.23\n1460\n0\n\n\nKitchenAbvGr\n1.05\n0.22\n0.00\n(0.00, 3.00)\n4.49\n21.53\n1460\n0\n\n\nTotRmsAbvGrd\n6.52\n1.63\n2.00\n(2.00, 14.00)\n0.68\n0.88\n1460\n0\n\n\nFireplaces\n0.61\n0.64\n1.00\n(0.00, 3.00)\n0.65\n-0.22\n1460\n0\n\n\nGarageYrBlt\n1978.51\n24.69\n41.00\n(1900.00, 2010.00)\n-0.65\n-0.42\n1379\n81\n\n\nGarageCars\n1.77\n0.75\n1.00\n(0.00, 4.00)\n-0.34\n0.22\n1460\n0\n\n\nGarageArea\n472.98\n213.80\n244.50\n(0.00, 1418.00)\n0.18\n0.92\n1460\n0\n\n\nWoodDeckSF\n94.24\n125.34\n168.00\n(0.00, 857.00)\n1.54\n2.99\n1460\n0\n\n\nOpenPorchSF\n46.66\n66.26\n68.00\n(0.00, 547.00)\n2.36\n8.49\n1460\n0\n\n\nEnclosedPorch\n21.95\n61.12\n0.00\n(0.00, 552.00)\n3.09\n10.43\n1460\n0\n\n\nX3SsnPorch\n3.41\n29.32\n0.00\n(0.00, 508.00)\n10.30\n123.66\n1460\n0\n\n\nScreenPorch\n15.06\n55.76\n0.00\n(0.00, 480.00)\n4.12\n18.44\n1460\n0\n\n\nPoolArea\n2.76\n40.18\n0.00\n(0.00, 738.00)\n14.83\n223.27\n1460\n0\n\n\nMiscVal\n43.49\n496.12\n0.00\n(0.00, 15500.00)\n24.48\n701.00\n1460\n0\n\n\nMoSold\n6.32\n2.70\n3.00\n(1.00, 12.00)\n0.21\n-0.40\n1460\n0\n\n\nYrSold\n2007.82\n1.33\n2.00\n(2006.00, 2010.00)\n0.10\n-1.19\n1460\n0\n\n\nSalePrice\n1.81e+05\n79442.50\n84075.00\n(34900.00, 7.55e+05)\n1.88\n6.54\n1460\n0\n\n\n\n\n\n\n9.8.5 Ein erstes Vorhersagemodell\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller UV mit der AV zu berechnen, s.  ListingÂ 9.2.\n\n\n\nListingÂ 9.2: Welche Variablen korrelieren stÃ¤rker als .3?\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der HÃ¶he des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\n\n\nTabelleÂ 9.4: Korrelation der UV mit der AV\n\n\n\n\n\n\n\nAha! Ein Menge Information â€¦ Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: FÃ¼hren Sie die Syntax schrittweise aus. Zuerst d_train ausfÃ¼hren und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausfÃ¼hren, wieder die Ausgabe betrachten, usw. Die als Output von ListingÂ 9.2 aufgefÃ¼hrten Variablen sind einigermaÃŸen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage. TabelleÂ 9.5 zeigt die Parameter von lm_immo1.\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im GroÃŸen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stÃ¤rksten mit der Zielvariable korreliert und daher ein guter Kandidat fÃ¼r die Vorhersage.\n\nlm_immo1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(lm_immo1)  # aus easystats\n\n\n\n\nTabelleÂ 9.5: Parameter von lm_immo1\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-96206.08\n\n\nOverallQual\n45435.80\n\n\n\n\n\n\n\n\nWie gut ist das Modell?\n\nrmse(lm_immo1)  # aus easystats\n## [1] 48589\n\nIm Schnitt liegen wir 4.86^{4} Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die ModellgÃ¼te:\n\nr2(lm_immo1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\nMan kann mehrere UV in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur â€œals UV nimm UV1 und UV2 und â€¦â€. Berechnen wir als nÃ¤chstes ein Modell mit mehreren UV, lm_immo2.\n\nlm_immo2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(lm_immo2)\n\nTabelleÂ 9.6 zeigt die Koeffizienten von lm_immo2.\n\n\n\nTabelleÂ 9.6: Modellparameter von lm_immo2\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-98832.49\n\n\nOverallQual\n27104.83\n\n\nGrLivArea\n50.67\n\n\nGarageCars\n21298.96\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells lm_immo2 fÃ¼r die Daten von d_train?\n\nrmse(lm_immo2)\n## [1] 40566\n\nIm Schnitt liegen unsere Vorhersagen 4.06^{4} Dollar daneben. Ist das gut? Betrachten wir noch \\(R^2\\):\n\nr2(lm_immo2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n\nOb die ModellgÃ¼te (R-Quadrat, RMSE, etc.) â€œgutâ€ bzw. â€œhochâ€ ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen.\nZum Vergleich berechnen wir das maximal einfache Modell: ohne UV. Man nennt es das Nullmodell. In diesem Modell sagen wir fÃ¼r jedes Haus einfach den mittleren Preis aller HÃ¤user vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnodells?\n\nrmse(m0)\n## [1] 79415\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben. Das R-Quadrat der Nullmodells ist per Definition null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.6 Vorhersagen im Test-Datensatz mit lm_immo2\n\nWir haben jetzt unseren Champion, lm_immo2. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample prÃ¤zise sein werden? Oder himmelweit daneben? EnttÃ¤usche uns nicht! Hier sind die Vorhersagen:\n\nlm_immo2_pred &lt;- predict(lm_immo2, newdata = d_test)\nhead(lm_immo2_pred)\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n\n\n1\n\nErstelle eine Vorhersage anhand der Regressionsgerade von lm_immo1 und zwar anhand der Daten aus d_test.\n\n2\n\nZeige den â€œKopfâ€ der Vorhersagen (lm_immo1_pred), d.\\(\\,\\)h. die ersten paar Vorhersagen.\n\n\n\n\nDie Vorhersagen fÃ¼gen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = lm_immo2_pred)\n\n\n9.8.7 Einreichen!\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhersagen ein. FÃ¼r die Prognosedatei (submission file) brauchen wir nur die Spalten id und SalePrice:\n\nlm_immo2_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab. Es bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfÃ¼gt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.\n\nwrite_csv(lm_immo2_subm, \"data/ames-kaggle/lm_immo2_subm.csv\")\n\nUnd dann laden Sie diese Datei, lm2_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn. Das Modell erzielte einen Score von 0.55521.\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele AnsÃ¤tze, dieses Modell zu verbessern. Hier sind einige Fragen, die Sie sich dazu stellen kÃ¶nnen:\n\nWelche UV sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn eine UV schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche UV quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\nâ€¦\n\nViel Spielraum fÃ¼r Ihre KreativitÃ¤t!",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\names-kaggle1\n\nSchauen Sie sich auch weitere Aufgaben des Datenwerks an, vor allem mit den Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff dieses Kapitels; vielleicht kÃ¶nnen Sie einige Aufgaben nicht lÃ¶sen. Ignorieren Sie einfach diese Aufgaben.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9Â  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere EinfÃ¼hrung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte EinfÃ¼hrung in Statistik inklusive der Regressionsanalyse findet sich bei Ã‡etinkaya-Runde & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003).\n\n\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed. Lawrence Erlbaum.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMenk. (2014, Juli 29). Linear Regression [Computer Code]. https://texample.net/tikz/examples/linear-regression/",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9Â  Geradenmodelle 1",
    "section": "",
    "text": "https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/noten.csvâ†©ï¸\nhttps://fomshinyapps.shinyapps.io/KleinsteQuadrate/â†©ï¸",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Einstieg",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#einstieg",
    "href": "090-regression2.html#einstieg",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Lernziele\n\nSie kÃ¶nnen Regressionsmodelle fÃ¼r Forschungsfragen mit binÃ¤rer, nominaler und metrischer UV erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen Interaktionseffekte in Regressionsmodellen erlÃ¤utern und in R anwenden.\nSie kÃ¶nnen den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erlÃ¤utern und in R anwenden.\n\n10.1.2 BenÃ¶tigte R-Pakete\nNeben den Ã¼blichen Paketen tidyverse (Wickham et al., 2019) und easystats (LÃ¼decke et al., 2022) benÃ¶tigen Sie in diesem Kapitel noch yardstick (Kuhn et al., 2024) und optional ggpubr (Kassambara, 2023).\n\nlibrary(tidyverse)\nlibrary(yardstick)  # fÃ¼r ModellgÃ¼te im Test-Sample\nlibrary(easystats)\nlibrary(ggpubr)  # Daten visualisieren, optional\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n10.1.3 BenÃ¶tigte Daten\nDieses Mal arbeiten wir nicht nur mit den Mariokartdaten, sondern auch mit Wetterdaten.\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- paste0(\n  \"https://raw.githubusercontent.com/sebastiansauer/\",\n  \"statistik1/main/data/wetter-dwd/precip_temp_DWD.csv\")\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD (2025a, 2025b) Ein Data-Dictionary fÃ¼r den Datensatz kÃ¶nnen Sie hier herunterladen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "href": "090-regression2.html#forschungsbezug-glÃ¤serne-kunden",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: GlÃ¤serne Kunden",
    "text": "10.2 Forschungsbezug: GlÃ¤serne Kunden\nLineare Modelle (synonym: Regressionsanalysen) sind ein altes, aber mÃ¤chtiges Werkzeug. Sie gehÃ¶ren immer noch zum Standard-Repertoire moderner Analystinnen und Analysten. Die WirkmÃ¤chtigkeit von linearen Modellen zeigt sich (leider?!) in folgendem Beispiel.\n\nBeispiel 10.1 (Wie gut kann man Ihre PersÃ¶nlichkeit auf Basis Ihrer Social-Media-Posts vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Kosinski et al. (2013), wie gut PersÃ¶nlichkeitszÃ¼ge durch Facebook-Daten (Likes etc.) vorhergesagt werden kÃ¶nnen. Die Autoren resÃ¼mieren im Abstract:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten Ã¼ber eine hohe ModellgÃ¼te (gemessen mit dem Korrelationskoeffizienten \\(r\\)) zwischen den tatsÃ¤chlichen persÃ¶nlichen Attributen und den vorhergesagten Werten Ihres Modells, s. AbbildungÂ 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also Ã¤hnlich den in diesem Kapitel vorgestellten Methoden. Neben der analytischen StÃ¤rke der Regressionsanalyse zeigt das Beispiel auch, wie glÃ¤sern man im Internet ist! \\(\\square\\)\n\n\n\n\n\n\nAbbildungÂ 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values (Kosinski et al., 2013)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach etwas Abwechslung. Viel Geld verdienen ist ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehÃ¶ren, und daher den schnÃ¶den Mammon nicht so hoch schÃ¤tzen sollten. Sie entschlieÃŸen sich, Ihre hochgeschÃ¤tzten Analyse-Skills fÃ¼r etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels. \\(\\square\\)\n\nBeim Deutschen Wetterdienst, DWD, haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen, resultiert ein schÃ¶ner Datensatz, den Sie jetzt analysieren mÃ¶chten. (Im Datensatz ist die Temperatur ist in Grad Celsius angegeben; der Niederschlag (precip) in mm Niederschlag pro Quadratmeter.) Hervorragend! An die Arbeit!\n\nAbbildungÂ 10.2 zeigen die Wetterdaten animiert.\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celsius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlag (mm) im Verlauf der Jahre\n\n\n\n\n\nVerÃ¤nderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildungÂ 10.2: VerÃ¤nderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\n\n10.3.1 Metrische UV\nIn diesem Abschnitt untersuchen wir lineare Modelle mit einer oder mehreren metrischen UV (und einer metrischen AV).\nSie stellen sich nun folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ« Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in TabelleÂ 10.1 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelleÂ 10.1: Modellparameter von lm_wetter1\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n-14.25\n(-17.87, -10.63)\n\n\nyear\n0.01\n(9.80e-03, 0.01)\n\n\n\n\n\n\n\n\nLaut dem Modell wurde es pro Jahr im Schnitt um 0.01\\(\\,\\)Â°C wÃ¤rmer, pro Jahrzehnt also 0.1\\(\\,\\)Â°C und pro Jahrhundert 1\\(\\,\\)Â°C.\n\nğŸ§‘â€ğŸ“ Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\nğŸ§‘â€ğŸ« Mit der Ruhe, das schauen wir uns spÃ¤ter an.\n\nIn TabelleÂ 10.1 finden sich zwei Arten von Information fÃ¼r den Wert des Achsenabschnitts (\\(\\beta_0\\)) und des Regressionsgewichts von year (\\(\\beta _1\\)):\n\nPunktschÃ¤tzungen In der Spalte Coefficient sehen Sie den â€œBest-Guessâ€ (PunktschÃ¤tzer) fÃ¼r den entsprechenden Koeffizienten in der Population. Das ist sozusagen der Wert, fÃ¼r den sich das Modell festlegen wÃ¼rde, wenn es sonst nichts sagen dÃ¼rfte.\nBereichschÃ¤tzungen Cleverer als PunktschÃ¤tzungen sind BereichsschÃ¤tzungen (IntervallschÃ¤tzungen): Hier wird ein Bereich plausibler Werte fÃ¼r den entsprechenden Koeffizienten angegeben. In der Spalte CI sehen Sie die untere bzw. die obere Grenze eines â€œBereichs plausibler Werteâ€. Dieser SchÃ¤tzbereich wird auch als Konfidenzintervall (engl. confidence interval, CI) bezeichnet. Ein Konfidenzintervall ist mit einer Sicherheit zwischen 0 und 1 angegeben, z.B. 95\\(\\,\\)% (0.95). Grob gesagt bedeutet ein 95\\(\\,\\)%-Kondidenzintervall, dass wir uns (laut Modell) zu 95\\(\\,\\)% sicher sein kÃ¶nnen, dass der wahre Werte sich in diesem Bereich befindet. In TabelleÂ 10.1 kÃ¶nnen wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschÃ¤tzt wird. Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschÃ¤tzt (unter sonst gleichen UmstÃ¤nden).\n\n\nDefinition 10.1 (Konfidenzintervall) Ein Konfidenzintervall (confidence interval, CI) gibt einen SchÃ¤tzbereich plausibler Werte fÃ¼r einen Populationswert an, auf Basis der SchÃ¤tzung, die uns die Stichprobe liefert. \\(\\square\\)\n\nDas Modell lm_wetter1, bzw. die SchÃ¤tzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. AbbildungÂ 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. AbbildungÂ 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert. Auf dieser Basis erstellen wir ein neues lineares Modell, lm_wetter1_pro_jahr, s. TabelleÂ 10.2.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. fÃ¼r Niederschlag\n\n\n# Summierte Daten (nach Jahr), aber gleiche Modellformel:\nlm_wetter1_pro_jahr &lt;- lm(temp ~ year, data = wetter_summ) \nparameters(lm_wetter1_pro_jahr) |&gt; \n  select(Parameter, Coefficient)\n\n\n\n\nTabelleÂ 10.2: Modellparameter von lm_wetter1a\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-14.14\n\n\nyear\n0.01\n\n\n\n\n\n\n\n\nKomfortabel ist es, das Modell lm_wetter1_pro_jahr mit plot(estimate_relation(lm_wetter1_pro_jahr)) zu plotten.\n\n\n\n\n\n\n\n\n\n\n(a) Ein Punkt pro Tag\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Ein Punkt pro Jahr\n\n\n\n\n\n\nAbbildungÂ 10.3: Die VerÃ¤nderung der mittleren Temperatur in Deutschland im Zeitverlauf [DWD2025]. Links: Jeder Punkt ist ein Tag (viel Overplotting, wenig nÃ¼tzlich). Rechts: Jeder Punkt ist ein Jahr (wetter_summ). AuÃŸerdem ist die Regressionsgerade dargestellt.\n\n\n\n\nğŸ§‘â€ğŸ“ Moment mal, der Achsenabschnitt liegt bei etwa -14 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der \\(Y\\)-Wert an der Stelle \\(x=0\\), s. Kapitel 9.5.\nIn den Wetterdaten wÃ¤re Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extrapolieren, ganz ohne, dass wir dafÃ¼r Daten haben, s. https://xkcd.com/605/. Sinnvoller ist es da, z.\\(\\,\\)B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezÃ¶ge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn fÃ¼r dieses Jahr haben wir Daten. Hat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es nÃ¼tzlich den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten, s. DefinitionÂ 7.7 und ListingÂ 7.3.\n\n\n\n\n\nAbbildungÂ 10.4: Du sollst nicht ein Modell weit auÃŸerhalb seines Datenbereichs extrapolieren\n\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist Ã¼brigens 1951, wie etas Datenjudo zeigt: wetter %&gt;% summarise(mean(year))\nDie Steigung (d.\\(\\,\\)h. der Regressionskoeffizient fÃ¼r year_c) bleibt durch das Zentrieren unverÃ¤ndert, nur der Achsenabschnitt Ã¤ndert sich, s. TabelleÂ 10.3.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert) |&gt; \n  select(Coefficient, Parameter, CI_low, CI_high)\n\n\n\n\nTabelleÂ 10.3: Modellparameter von lm_wetter1_zentriert\n\n\n\nFixed Effects\n\nCoefficient\nParameter\nCI\n\n\n\n8.49\n(Intercept)\n(8.42, 8.57)\n\n\n0.01\nyear_c\n(9.80e-03, 0.01)\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5\\(\\,\\)Â°C. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49\\(\\,\\)Â°C plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\nWie gut erklÃ¤rt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklÃ¤rt das Modell mit year_c aber nicht. (year und year_c sind gleich stark mit temp korreliert, daher wird sich die ModellgÃ¼te nicht unterscheiden.). Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.\\(\\,\\)B. die Jahreszeit eine groÃŸe Rolle fÃ¼r die Temperatur. Das haben wir nicht berÃ¼cksichtigt.\n\nğŸ§‘â€ğŸ“ Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##   1 \n## 9.7\n\n\nğŸ§‘â€ğŸ“ Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5Â° Celsius (Wilke, 2013).\n\n\nğŸ§‘â€ğŸ« Wir brauchen ein besseres Modell! Zum GlÃ¼ck haben wir ambitionierten Wissenschaftsnachwuchs.\n\nDie VerÃ¤nderung der auf fÃ¼nf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in AbbildungÂ 10.5 dargestellt. Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)1; rechts eine feinere (Daten ab 1881)2.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020 (Habitator terrae, 2021)\n\n\n\nAbbildungÂ 10.5: \n\n\n10.3.3 BinÃ¤re UV\n\nDefinition 10.2 (BinÃ¤re Variable) Eine binÃ¤re UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei AusprÃ¤gungen: 0 und 1. \\(\\square\\)\n\n\nBeispiel 10.3 (BinÃ¤re Variablen) Das sind zum Beispiel weiblich mit den AusprÃ¤gungen 0 (nein) und 1 (ja) oder before_1950 mit 1 fÃ¼r Jahre frÃ¼her als 1950 und 0 ansonsten. \\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\nğŸ§‘â€ğŸ“ Ob es in der zweiten HÃ¤lfte des 20. Jahrhunderts wohl wÃ¤rmer war, im Durchschnitt, als vorher? \\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite HÃ¤lfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Ãœberlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.6.5) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prÃ¼fe, ob as Jahr grÃ¶ÃŸer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht grÃ¶ÃŸer als 1950, das dritte schon. Ja, so kÃ¶nnte das klappen! Diese Syntax Ã¼bertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten fÃ¼r Gesamt-Deutschland\n\nScheint zu klappen! Jetzt ein lineares Modell dazu berechnen, s. TabelleÂ 10.4.\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\n\n\n\nTabelleÂ 10.4: Parameter von lm_wetter_bin_uv\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n8.18\n(8.06, 8.29)\n\n\nafter_1950TRUE\n0.64\n(0.48, 0.80)\n\n\n\n\n\n\n\n\nDie Parameterwerte des Modells lassen darauf schlieÃŸen, dass es tatsÃ¤chlich wÃ¤rmer geworden ist nach 1950, und zwar offenbar ein gutes halbes Grad, s. AbbildungÂ 10.6.\n\n\n\n\n\n\n\n\n\n\n(a) Mittelwertsunterschied als Regressionsparameter\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Mittelwertsunterschied als Verteilungsvergleich\n\n\n\n\n\n\nAbbildungÂ 10.6: Modell: temp ~ after_1950, (a) Der SchÃ¤tzbereich fÃ¼r den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied. (b) Der Unterschied sieht in dieser Darstellung nicht groÃŸ aus.\n\n\n\nLeider zeigt ein Blick zum Ergebnis der Funktion r2, dass die VorhersagegÃ¼te des Modells zu wÃ¼nschen Ã¼brig lÃ¤sst (r2(lm_wetter_bin_uv)). Wir brauchen ein besseres Modell.\nUm die Koeffizienten eines linearen Modells auszurechnen, benÃ¶tigt man eine metrische UV und eine metrische AV. Hier haben wir aber keine richtige metrische UV, sondern eine logische Variable mit den Werten TRUE und FALSE. Um die UV in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R fÃ¼r uns ohne viel AnkÃ¼ndigung durchfÃ¼hrt: Umwandling in eine oder mehrere binÃ¤re Variablen, s. DefinitionÂ 10.2.\nHat eine nominale UV zwei Stufen, so Ã¼berfÃ¼hrt (synonym: transformiert) lm diese Variable in eine binÃ¤re Variable. Da eine binÃ¤re Variable wie eine metrische angesehen werden kann, kann die Regression in gewohnter Weise durchgefÃ¼hrt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binÃ¤re Variable (s. TabelleÂ 10.4). Man beachte, dass der ursprÃ¼ngliche Datensatz nicht geÃ¤ndert wird, nur wÃ¤hrend der Analyse von lm wird die Umwandlung der Variable durchgefÃ¼hrt.\nIn unserem Fall liegt mit after_1950 eine logische Variable mit den Werten TRUE und FALSE vor. TRUE und FALSE werden von R automatisch als 1 bzw. als 0 verstanden. Also: Eine logische Variable ist schon eine binÃ¤re Variable.\n\nğŸ¤– Eine 1 kannst du als â€œJa! Richtig!â€ verstehen und eine 0 als â€œNein! Falsch!â€\n\n\nBeispiel 10.5 (Beispiel: â€˜Geschlechtâ€™ in eine binÃ¤re Variable umwandeln.) Angenommen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umwandeln. Da â€œFrauâ€ alphabetisch vor â€œMannâ€ kommt, nimmt R â€œFrauâ€ als erste Stufe bzw. als Referenzgruppe. â€œMannâ€ ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann). \\(\\square\\)\n\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nEin lineares Modell mit binÃ¤rer UV zeigt nichts anderes als die Differenz der Gruppenmittelwerte. \\(\\square\\)\n\n\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n\nafter_1950\ntemp_mean\n\n\n\nFALSE\n8.2\n\n\nTRUE\n8.8\n\n\n\n\n\nDie Interpretation eines linearen Modells mit binÃ¤rer UV veranschaulicht AbbildungÂ 10.7: Der Achsenabschnitt (\\(\\beta_0\\)) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (AbbildungÂ 10.7 zeigt nur die Daten fÃ¼r den Monat Juli im Bundesland Bayern, der Einfachheit und Ãœbersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildungÂ 10.7: Sinnbild zur Interpretation eines linearen Modells mit binÃ¤rer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten fÃ¼r das Modell mit binÃ¤rer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (\\(\\beta_0\\))\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (\\(\\beta_0\\)) + Steigung der Regressionsgeraden (\\(\\beta_1\\))\n\n\nFÃ¼r die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\nBei nominalen (und auch bei binÃ¤ren) Variablen kann man \\({\\beta_1}\\) als einen Schalter verstehen; bei metrischen Variablen als einen Dimmer.3 \\(\\square\\)\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineares Modell (fÃ¼r uns synonym: Regressionsmodell) mit einer mehrstufigen (nominalskalierten) UV. So ein Modell ist von den Ergebnissen her praktisch identisch zu einer Varianzanalyse mit einer einzigen UV.\n\nBeispiel 10.6 Ob es wohl substanzielle Temperaturunterschiede zwischen den BundeslÃ¤ndern gibt?\n\nBefragen wir dazu ein lineares Modell; in TabelleÂ 10.5 sind fÃ¼r jeden Parameter der PunktschÃ¤tzer (Koeffizient) und der zugehÃ¶rige SchÃ¤tzbereich (Konfidenzintervall) mit Ober- und Untergrenze angegeben.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\n\n\n\n\nTabelleÂ 10.5: Modellparameter fÃ¼r lm_wetter_region\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n8.25\n(7.93, 8.56)\n\n\nregionBayern\n-0.63\n(-1.07, -0.19)\n\n\nregionBrandenburg\n0.57\n(0.13, 1.02)\n\n\nregionBrandenburg/Berlin\n0.58\n(0.14, 1.03)\n\n\nregionHessen\n0.11\n(-0.33, 0.56)\n\n\nregionMecklenburg-Vorpommern\n0.08\n(-0.37, 0.52)\n\n\nregionNiedersachsen\n0.52\n(0.07, 0.96)\n\n\nregionNiedersachsen/Hamburg/Bremen\n0.52\n(0.08, 0.96)\n\n\nregionNordrhein-Westfalen\n0.80\n(0.35, 1.24)\n\n\nregionRheinland-Pfalz\n0.46\n(0.02, 0.90)\n\n\nregionSaarland\n0.71\n(0.27, 1.16)\n\n\nregionSachsen\n-0.04\n(-0.48, 0.40)\n\n\nregionSachsen-Anhalt\n0.55\n(0.11, 1.00)\n\n\nregionSchleswig-Holstein\n0.17\n(-0.27, 0.62)\n\n\nregionThueringen\n-0.48\n(-0.92, -0.03)\n\n\nregionThueringen/Sachsen-Anhalt\n0.10\n(-0.34, 0.54)\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariable um. Genauer gesagt ist es immer eine Indikatorvariable weniger als es Stufen in der nominalskalierten Variablen gibt. Allgemein gilt: Hat eine nominale Variable \\(k\\) Stufen, so wird diese Variable von lm in \\(k-1\\) binÃ¤re Variablen umgewandelt.\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland â€“ aus GrÃ¼nden der Einfachheit hier nur mit drei BundeslÃ¤ndern. Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt.\n\n\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWÃ¼\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\n\\(\\quad \\rightarrow\\)\n\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\n\nAuch im Fall mehrerer AusprÃ¤gungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binÃ¤ren Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (\\(\\beta_0\\))\nMittelwert der 2. Gruppe: Achsenabschnitt (\\(\\beta_0\\)) + Steigung der 1. Regressionsgeraden (\\(\\beta_1\\))\nMittelwert der 3. Gruppe: Achsenabschnitt (\\(\\beta_0\\)) + Steigung der 2. Regressionsgeraden (\\(\\beta_2\\))\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts) ausgewÃ¤hlt wurde nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt. Bei einer Variable vom Typ character wÃ¤hlt R den alphabetisch ersten Wert als Referenzgruppe fÃ¼r ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt.\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-WÃ¼rttemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewÃ¤hlt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird. \\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. AbbildungÂ 10.8.\n\n\n\n\n\n\n\nAbbildungÂ 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben).\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht auÃŸer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechne! \\(\\square\\)\n\n\nğŸ¤– Endlich gehtâ€™s weiter! Ergebnisse findest du in TabelleÂ 10.6!\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelleÂ 10.6: Modellparameter fÃ¼r lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschiede im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. AbbildungÂ 10.9, links (plot(estimate_expectation(lm_wetter_month)). Oh nein: R betrachtet month als numerische Variable! Aber â€œMonatâ€ bzw. â€œJahreszeitâ€ sollte nominal sein.\n\nğŸ¤– Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\nğŸ‘© Okay, R, wir mÃ¼ssen month in eine nominale Variable transformieren. Wie geht das?\n\n\nğŸ¤– Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heiÃŸt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau. \\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. TabelleÂ 10.7.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor) |&gt; \n  select(Parameter, Coefficient)\n\n\n\n\nTabelleÂ 10.7: Modellparameter von lm_wetter_month_factor (nur die ersten paar Parameter)\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n57.0\n\n\nmonth_factor2\n-9.9\n\n\nmonth_factor3\n-7.8\n\n\nmonth_factor4\n-8.5\n\n\nmonth_factor5\n4.7\n\n\nmonth_factor6\n14.3\n\n\n\n\n\n\n\n\nSehr schÃ¶n! Jetzt haben wir eine Referenzgruppe (Monat 1, d.\\(\\,\\)h. Januar) und 11 Unterschiede zum Januar, s. AbbildungÂ 10.9.\n\nÃœbungsaufgabe 10.1 In Ã¤hnlicher Form zu AbbildungÂ 10.9 kÃ¶nnten Sie auch die Regressionsgewichte wie folgt plotten: parameters(lm_wetter_month_factor) |&gt; plot(). Was sind die Unterschiede zu AbbildungÂ 10.9?4 \\(\\square\\)\n\n\nggerrorplot(data = wetter,\n            x = \"month_factor\",\n            y = \"precip\",\n            desc_stat = \"mean_sd\")\n\n\n\n\n\n\nAbbildungÂ 10.9: Niederschlagsmengen nach Monaten (Mittelwerte plus SD)\n\n\n\n\nMÃ¶chte man die Referenzgruppe eines Faktors Ã¤ndern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geÃ¤nderte Reihenfolge aus:5\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 BinÃ¤re plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binÃ¤ren) UV plus einer metrischen UV. Ein solches Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ANCOVA) bezeichnet werden.\n\nBeispiel 10.10 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\nğŸ§‘â€ğŸ« Ich muss mal kurz auf eine Sache hinweisen â€¦\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich fÃ¼r nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten AusprÃ¤gungen (â€œFaktorstufenâ€) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht. Das kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche AusprÃ¤gungen in Ihrer Variable mÃ¶glich sind. \\(\\square\\)\n\n\nBeispiel 10.11 (Beispiele fÃ¼r Faktorvariablen) Â \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\nFiltern verÃ¤ndert die Faktorstufen nicht. Wenn Sie von der Faktorvariablen6 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.\\(\\,\\)B. nur die ersten beiden Elemente Ã¼brig bleiben mit allein der AusprÃ¤gung \"f\", merkt sich R trotzdem, dass die Variable laut Definition zwei Faktorstufen besithzt (\"f\" und \"m\").\nGenau so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. MÃ¶chten Sie die herausgefilterten Faktorstufen â€œlÃ¶schenâ€, so kÃ¶nnen Sie einfach die Faktorvariable neu definieren (mit factor).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  # Faktor (und damit die Faktorstufen) neu definieren:\n  mutate(month_factor = factor(month))\n\nHat man mehrere (â€œmultipleâ€) X-Variablen (PrÃ¤diktoren, unabhÃ¤ngige Variablen), so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.\\(\\,\\)B. temp ~ year_c + month.\n\nDefinition 10.3 (Multiple Regression) Eine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y \\sim x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\nDie VerÃ¤nderung der monatlichen Temperatur (10-Jahres-Mittel) ist in AbbildungÂ 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schÃ¶ner aus).\nDas Pluszeichen hat in der Modellgleichung (synonym: Regressionsformel) keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur â€œund noch folgende UV â€¦â€.\nDie Modellgleichung von lm_year_month liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, \n                    data = wetter_month_1_7)\n\nDie Modellparameter sind in TabelleÂ 10.8 zu sehen.\n\n\n\nTabelleÂ 10.8: Modellparameter von lm_year_month\n\n\n\nFixed Effects\n\nCoefficient\nParameter\nCI\n\n\n\n56.94\n(Intercept)\n(55.60, 58.27)\n\n\n0.03\nyear_c\n(5.59e-03, 0.05)\n\n\n24.37\nmonth_factor7\n(22.48, 26.27)\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (\\(\\beta_0\\), Intercept): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57\\(\\,\\)mm pro Quadratmeter.\nRegressionskoeffizient fÃ¼r Jahr (\\(\\beta_1\\), year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.03\\(\\,\\)mm an (im Referenzmonat).\nRegressionskoeffizient fÃ¼r Monat (\\(\\beta_2\\), month_factor7) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25\\(\\,\\)mm Ã¼ber dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7. Im Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0. Demnach erwarten wir laut Modell lm_year_month im Juli des Referenzjahres 81.31\\(\\,\\)mm Niederschlag. Die Werte der Regressionskoeffizienten sind TabelleÂ 10.8 entnommen.\n\nğŸ§‘â€ğŸ“ Puh, kompliziert!\n\n\nğŸ§‘â€ğŸ« Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. BeispielÂ 10.12.\n\n\nBeispiel 10.12 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag fÃ¼r Juli im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"7\"))\npredict(lm_year_month, newdata = neue_daten)\n##  1 \n## 83\n\nDas Modell erwartet Niederschlag in HÃ¶he von 83.3\\(\\,\\)mm. Mit predict kann man sich Vorhersagen eines Modells ausgeben lassen. \\(\\square\\)\n\nAlle Regressionskoeffizienten beziehen sich auf die AV unter der Annahme, dass alle Ã¼brigen UV den Wert Null (bzw. Referenzwert) aufweisen.\nVisualisieren wir uns die geschÃ¤tzten Erwartungswert pro Wert der UV, s. AbbildungÂ 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildungÂ 10.10: Niederschlag fÃ¼r Januar (month 1) und Juli (month 7) im Verlauf der Jahre. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von Okabe & Ito (2023) ersetzt (s. Barrett, 2021). Das ist nicht unbedingt nÃ¶tig, aber robuster bei SehschwÃ¤chen, vgl. Kapitel 5.11.3. Die erklÃ¤rte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht wÃ¼rden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dÃ¼rfen? Nicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. ListingÂ 10.1.\n\n\n\nListingÂ 10.1: Ein Interaktionsmodell spezifiziert man in dieser Art: y ~ x1 + x2 + x1:x2\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\n\n\n\nVisualisiert ist das Modell in AbbildungÂ 10.11.\n\nplot(estimate_relation(lm_year_month_interaktion)) \n\n\n\n\n\n\n\n\nAbbildungÂ 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die VerÃ¤nderung im Verlauf der Jahre ist unterschiedlich fÃ¼r die Monate (Januar vs.Â Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator (:) fÃ¼gt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\nDefinition 10.4 (Interaktionseffekt) Einen Interaktionseffekt von x1 und x2 kennzeichnet man in R mit dem Doppelpunkt-Operator, x1:x2:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\nIn Worten:\n\ny wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.\n\nWie man in AbbildungÂ 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel. Sind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor. In diesem Fall ist der Interaktionsffekt ungleich Null. \\(\\square\\)\n\nBeispiel 10.13 (Interaktionseffekt von Niederschlag und Monat) Wie ist die VerÃ¤nderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich fÃ¼r die Monate: Im Juli nahm der Niederschlag ab, im Januar zu. \\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von â€œdemâ€ (statistischen) Effekt einer UV (auf die AV) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.\\(\\,\\)B. Monat) unterscheidet der Effekt des Jahres auf die Niederschlagsmenge. (â€œEffektâ€ ist hier immer statistisch, nie kausal gemeint.) Betrachten wir die Parameterwerte des Interaktionsmodells, s. TabelleÂ 10.9.\n\n\n\nTabelleÂ 10.9: Modellparameter von lm_year_month_interaktion\n\n\n\n\nParameter\nCoefficient\nCI_low\nCI_high\n\n\n\n(Intercept)\n56.91\n55.59\n58.24\n\n\nyear_c\n0.13\n0.10\n0.16\n\n\nmonth_factor7\n24.37\n22.50\n26.25\n\n\nyear_c:month_factor7\n-0.20\n-0.25\n-0.16\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die unterste Zeile fÃ¼r den Parameter year c Ã— month factor [7]. Sie gibt die StÃ¤rke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre Ã¤ndert: Pro Jahr ist die Zunahme an Niederschlag um 0.20\\(\\,\\)mm geringer als im Referenzmonat (Januar). Damit resultiert fÃ¼r Juli insgesamt ein positiver Effekt: 0.13 - -0.20 = 0.07. Insgesamt lautet die Regressionsgleichung: precip_pred = 56.91 + 0.13 * year_c + 24.37 * month_factor_7 - 0.20 * year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert der AV an unter der Annahme, dass alle UV den Wert Null aufweisen. \\(\\square\\)\n\n\nWenn eine Beobachtung in allen UV den Wert 0 hat, so gibt der Achsenabschnitt den Niederschlag fÃ¼r den Januar des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in der AV an, wenn der jeweilige Wert der UV um 1 steigt, die Ã¼brigen UV aber den Wert 0 aufweisen.\nDas \\(R^2\\) von lm_year_month_interaktion betrÃ¤gt Ã¼brigens nur geringfÃ¼gig mehr als im Modell ohne Interaktion:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138\n\nDa man Modelle so einfach wie mÃ¶glich halten sollte, kÃ¶nnten wir auf den Interaktionseffekt im Modell verzichten. Der Interaktionseffekt verbessert die ModellgÃ¼te nur geringfÃ¼gig. Falls wir aber von einer starken Theorie ausgehen, die den Interaktionseffekt verlangt, hÃ¤tten wir einen triftigen Grund, den Interaktionseffekt im Modell zu belassen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. AbbildungÂ 10.12, oder im 2D-Raum, s. AbbildungÂ 10.13. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n\n\nWinkel 1\n\n\n\n\n\nWinkel 2\n\n\n\n\n\nWinkel 3\n\n\n\n\n\nAbbildungÂ 10.12: Ein lineares Modell, y ~ x1 + x2 mit zwei UV im 3D-Raum.\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.13: 2D-Diagramm fÃ¼r 3D-Modell\n\n\n\n\n\n\n\n\n3D-Animation\n2D-Diagramm fÃ¼r 3D-Modell\n\n\n\n\n\n\n\n\n(a) Animation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklÃ¤rt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildungÂ 10.14\n\n\nGrundsÃ¤tzlich kann man viele UV in ein (lineares) Modell aufnehmen. Betrachten wir z.\\(\\,\\)B. folgendes lineares Modell mit zwei metrischen UV, lm_mario_2uv.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, \n                   data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\n10.4.2 Viele UV ins Modell?\nWir kÃ¶nnten im Prinzip alle Variablen unserer Datentabelle als UV in das Regressionsmodell aufnehmen. Die Frage ist nur: Macht das Sinn? Hier sind einige Richtlinien, die helfen, welche Variablen (und wie viele) man als UV in ein Modell aufnehmen sollte [Gelman et al. (2021);. S. 199], wenn das Ziel eine mÃ¶glichst hohe ModellgÃ¼te ist:\n\nMan sollte alle Variablen aufnehmen, von denen anzunehmen ist, dass Sie Ursachen fÃ¼r die Zielvariablen sind.\nBei UV mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen.\nUV, die vergleichsweise exakt geschÃ¤tzt werden (der Bereich 95 CI ist klein), sollten tendenziell im Modell belassen werden, da sie die ModellgÃ¼te verbessern.\n\nIst das Ziel hingegen, eine Theorie bzw. ein wissenschaftliches Modell zu Ã¼berprÃ¼fen, so sollte man genau die UV in das Modell aufnehmen, die die Theorie verlangt.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.14 (Prognose des Verkaufspreis) Ganz kÃ¶nnen Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen mÃ¶glichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld. \\(\\square\\)\n\n\n10.5.1 Modell â€œall-inâ€\nUm die GÃ¼te Ihrer Vorhersagen zu prÃ¼fen, teilt Ihre Chefin den Datensatz in zwei zufÃ¤llige Teile.\n\nğŸ‘©â€ğŸ’¼ Ich teile den Datensatz mariokart zufÃ¤llig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (â€œtrainierenâ€) und ihre GÃ¼te zu prÃ¼fen. Den Teil nenne ich â€œTrain-Sampleâ€, hÃ¶rt sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die GÃ¼te deiner Vorhersagen in dem verbleibenden Teil, die Ã¼brigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten in Ihrem Computer zu finden sind, z.\\(\\,\\)B. im Unterordner data, dann kÃ¶nnen Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"data/mariokart_train.csv\")\n\nAlternativ kÃ¶nnen Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die â€œAll-in-Strategieâ€: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.980\n\nDer Punkt in total_pr ~ . heiÃŸt â€œalle Variablen in der Tabelle (auÃŸer total_pr)â€.\n\nğŸ‘©â€ğŸ’¼ Hey! Das ist ja fast perfekte ModellgÃ¼te!\n\n\nğŸ¦¹â€â™€ï¸ï¸ Vorsicht: Wenn ein Angebot aussieht wie â€œtoo good to be trueâ€, dann ist es meist auch too good to be true.\n\nDer Grund fÃ¼r den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. WeiÃŸ man, welcher Titel zu welcher Auktion gehÃ¶rt, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nÃ¼tzen die Titel der Auktionen im Train-Sample nichts fÃ¼r andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stÃ¼tzen. Merke: HÃ¶chst idiografische Informationen wie Namen, Titel etc. sind nicht nÃ¼tzlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$xlevels): factor title has new levels MARIO KART FOR NINTENDO Wii WITH 2 WHEELS + GAME, Mario Kart Wii (Wii) COMPLETE , Mario Kart Wii (Wii) game , Mario Kart Wii (Wii) game and 2 wheels!, Mario Kart Wii (Wii) Game and Steering Wheel, Mario Kart Wii (Wii) Includes Steering Wheel!, MarioKart (Wii) w/ wheel\n\nOh nein! Was ist los!? Eine Fehlermeldung!\nNominalskalierte UV mit vielen AusprÃ¤gungen, wie title sind problematisch. Kommt eine AusprÃ¤gung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. HÃ¤ufig ist es ohnehin sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting fÃ¼hren.\n\n10.5.2 Modell â€œall-inâ€, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. NÃ¤chster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, id))\n\nlm_allin_no_title_no_id &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title_no_id) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist durchaus ordentlich.\n\nğŸ¤– Das haben wir gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title_no_id)\n## [1] 20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSie rennen zu Ihrer Chefin, die jetzt die GÃ¼te Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\nğŸ‘©â€ğŸ’¼ Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das â€œTest-Sampleâ€.\n\nIhre Chefin schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n\nid\ntotal_pr\n\n\n\n1.2e+11\n37\n\n\n2.9e+11\n55\n\n\n1.8e+11\n56\n\n\n1.8e+11\n56\n\n\n3.5e+11\n65\n\n\n1.1e+11\n46\n\n\n\n\n\n\nğŸ‘©â€ğŸ’¼ï¸ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nBerechnen wir die Vorhersagen (engl. predictions; to predict: vorhersagen):\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title_no_id, newdata = mariokart_test)\n\nHier sind die ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##  1  2  3  4  5  6 \n## 29 54 53 54 42 47\n\nDiese Vorhersagen fÃ¼gen wir noch der Ordnung halber in die Tabelle mit den Test-Daten ein:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title_no_id, \nnewdata = mariokart_test))\n\nğŸ‘©â€ğŸ’¼ï¸ Okay, was ist jetzt der mittlere Vorhersagefehler?\nUm die VorhersagegÃ¼te im Test-Sample auszurechnen (wir verwenden dazu die Funktionen mae und rsq, nutzen wir die Funktionen des R-Paketes yardstick (welches Sie vielleicht noch installieren mÃ¼ssen):\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nmae\nstandard\n10\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrmse\nstandard\n13\n\n\n\n\nIhr mittlerer Vorhersagefehler (RMSE) liegt bei ca. 13 Euro. Ãœbrigens haben wir hier yardstick::rmse geschrieben und nicht nur rmse, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens rmse gibt. Name-Clash-Alarm! R kÃ¶nnte daher den anderen rmse meinen als Sie, was garantiert zu Verwirrung fÃ¼hrt. (Entweder bei R oder bei Ihnen.)\n\nğŸ‘©â€ğŸ’¼ Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrsq\nstandard\n0.17\n\n\n\n\n\nğŸ‘´ï¸ 17%, nicht berauschend, aber immerhin!\n\nWie das Beispiel zeigt, ist die ModellgÃ¼te im Test-Sample (leider) oft geringer als im Train-Sample. Die ModellgÃ¼te im Train-Sample ist mitunter Ã¼bermÃ¤ÃŸig optimistisch. Dieses PhÃ¤nomen bezeichnet man als Overfitting (Gelman et al., 2021). Bevor man Vorhersagen eines Modells bei der Chefin einreicht, bietet es sich, die ModellgÃ¼te in einem neuen Datensatz, also einem Test-Sample, zu Ã¼berprÃ¼fen.\nWir haben hier die Funktion rsq aus dem Paket yardstick verwendet, da r2 nur die ModellgÃ¼te im Train-Sample ausrechnen kann. rsq kann die ModellgÃ¼te fÃ¼r beliebige Vorhersagewerte berechen, also sowohl aus dem Train- oder dem Test-Sample.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste SchÃ¤tzung der GÃ¼te Ihres Modells erhalten mÃ¶chten, bietet sich folgendes Vorgehen an (vgl. AbbildungÂ 10.15):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrÃ¼fen Sie die ModellgÃ¼te im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie kÃ¶nnen sie z.\\(\\,\\)B. so bewerkstelligen:\n\nlibrary(rsample)  # ggf. noch installieren\nmariokart &lt;- read_csv(\"data/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"data\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split wÃ¤hlt fÃ¼r jede Zeile (Beobachtung) zufÃ¤llig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt;7 das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafÃ¼r, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wÃ¤re nÃ¤mlich blÃ¶d fÃ¼r Ihr Modell, wenn im Train-Sample z.\\(\\,\\)B. nur die teuren, und im Test-Sample nur die gÃ¼nstigen Spiele landen wÃ¼rde. Anderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B. In so einem Fall wÃ¼rde sich Ihr Modell unnÃ¶tig schwer tun. Im nÃ¤chsten Schritt kÃ¶nnen Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsÃ¤chlich aufteilen. initial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgefÃ¼hrt.\n\nmariokart_train &lt;- \n  training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- \n  testing(meine_aufteilung)  # Assessment-Sample\n\ntraining wÃ¤hlt die Zeilen aus, die in das Train-Sample ihres Train-Samples, d.h. Ihr Analyse-Sample, kommen sollen. testing wÃ¤hlt die Zeilen aus, die in das Test-Sample ihres Train-Samples, d.h. Ihr Assessment-Sample, kommen sollen.\nIch persÃ¶nliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kÃ¼rzer zu tippen und einheitlich. Sie kÃ¶nnen aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, auÃŸerdem KÃ¼rze und aussagekrÃ¤ftige Namen.\n\n10.6.2 Train- vs.Â Test-Sample\nDas Train-Sample stellt die bekannten Daten dar; aus denen kÃ¶nnen wir lernen, d.\\(\\,\\)h. unser Modell berechnen. Das Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiÃŸ, was der Wert der AV ist. Der Zusammenhang dieser verschiedenen, aber zusammengehÃ¶rigen Arten von Stichproben ist in AbbildungÂ 10.15 dargestellt.\n\nDefinition 10.5 (Train-Sample) Den Datensatz, fÃ¼r die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\n\nDefinition 10.6 (Test-Sample) Den Datensatz, fÃ¼r den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildungÂ 10.15: Verschiedene Arten von zusammengehÃ¶rigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden â€œabwanderungsgefÃ¤hrdetâ€ sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (â€œcustomer churnâ€). Es gibt eine ganze Reihe von Untersuchungen dazu, z.\\(\\,\\)B. die von Lalwani et al. (2022). Das Forschungsteam versuchen anhand von Daten und u.\\(\\,\\)a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von Ã¼ber 80\\(\\,\\)% im (besten) Vorhersagemodell.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "href": "090-regression2.html#wie-man-mit-statistik-lÃ¼gt",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lÃ¼gt",
    "text": "10.8 Wie man mit Statistik lÃ¼gt\n\n10.8.1 Pinguine drehen auf\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von SchnabellÃ¤nge (bill length) und Schnabeltiefe (bill depth) interessiert, s. AbbildungÂ 10.16.\n\n\n\n\n\nAbbildungÂ 10.16: SchnabellÃ¤nge und Schnabeltiefe; Horst (2024)\n\n\nDas Team hat in schweiÃŸtreibender (eiszapfentreibender) Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und Ã¼berlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von SchnabellÃ¤nge und Schnabeltiefe, s. AbbildungÂ 10.17. Das ist bestimmt einen Nobelpreis wert Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")  # aus `ggpubr`\n\n\n\n\n\n\nAbbildungÂ 10.17: Negativer Zusammenhang von SchanbellÃ¤nge und Schnabeltiefe\n\n\n\n\nHier sind die statistischen Details, s. TabelleÂ 10.10.\n\nlm_ping1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelleÂ 10.10: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n20.89\n\n\nbill_length_mm\n-0.09\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf verÃ¶ffentlicht eine andere Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von SchnabelllÃ¤nge und Schnabeltiefe, s. AbbildungÂ 10.18.\n\n\n\n\n\n\n\nAbbildungÂ 10.18: Der Zusammenhang von SchnabelllÃ¤nge und Schnabeltiefe pro Gruppe von Pinguinen: Die Regressionsgruppe pro Gruppe steigt. Hingegen sinkt die Regressionsgerade ohne Beachtung der Gruppen (schwarze gestrichelte Linie)\n\n\n\n\nOh nein! Was ist hier nur los? Daten lÃ¼gen nicht?! Oder doch?!\nHier sind die statistischen Details der zweiten Analyse, s. TabelleÂ 10.11. Im zweiten Modell (lm2) kam species als zweite UV neu ins Modell (zusÃ¤tzlich zur SchnabellÃ¤nge).\n\nlm_ping2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelleÂ 10.11: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n10.6\n\n\nbill_length_mm\n0.2\n\n\nspeciesChinstrap\n-1.9\n\n\nspeciesGentoo\n-5.1\n\n\n\n\n\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse â€“ Gesamtdaten oder Subgruppen â€“ die richtige ist. Nicht-exprimentelle Studien kÃ¶nnen zu grundverschiedenen Ergebnissen fÃ¼hren, je nachdem, ob weitere UV dem Modell hinzugefÃ¼gt oder weggenommen werden.\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere Modellkoeffizienten nur kausal, wenn du ein Kausalmodell hast. \\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lÃ¤sst man besser die Finger von der Interpretation der Modellkoeffizienten und begnÃ¼gt sich mit der Beschreibung der ModellgÃ¼te und mit Vorhersage (synonym: Prognose). Wer das nicht glaubt, der betrachte AbbildungÂ 10.19, links. Ein Forscher stellt das Modell m1: y ~ x auf und interpretiert dann b1: â€œIst ja klar, X hat einen starken positiven Effekt auf Y!â€ In der nÃ¤chsten Studie nimmt der Forscher dann eine zweite Variable, group (z.\\(\\,\\)B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. AbbildungÂ 10.19, rechts! Dieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt â€œechtâ€, also kausal, ist. Handelt es sich aber um â€œnicht echteâ€, also nicht-kausale ZusammenhÃ¤nge, um ScheinzusammenhÃ¤nge also, so kÃ¶nnen sich die Modellkoeffizienten dramatisch verÃ¤ndern, wenn man das Modell verÃ¤ndert, also Variablen hinzufÃ¼gt oder aus dem Modell entfernt. Sogar das Vorzeichen des Effekts kann wechseln; das nennt man dann Simpsons Paradox (Gelman et al., 2021), Wenn man die kausalen AbhÃ¤ngigkeiten nicht kennt, weiÃŸ man also nicht, ob die ZusammenhÃ¤nge kausal oder nicht-kausal sind. Dann bleibt unklar, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker positiver Zusammenhang\n\n\n\n\nÂ \n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, kein Zusammenhang in beiden Gruppe\n\n\n\n\n\n\nAbbildungÂ 10.19: FÃ¼gt man in ein Modell eine Variable hinzu, kÃ¶nnen sich die Koeffizienten massiv Ã¤ndern. In beiden Diagrammen wurden die gleichen Daten verwendet. (a) starker positiver Zusammenhang, (b) kein Zusammenhang in beiden Gruppen\n\n\n\nMan kÃ¶nnte hÃ¶chstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.\\(\\,\\)B. â€œDort wo es viele StÃ¶rche gibt, gibt es auch viele Babysâ€ (Matthews, 2000).8 Leider ist unser Gehirn auf kausale ZusammenhÃ¤nge geprÃ¤gt: Es fÃ¤llt uns schwer, ZusammenhÃ¤nge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulÃ¤ssig kausal interpretiert â€“ von Laien und Wissenschaftlern ebenfalls.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#was-war-noch-mal-das-erfolgsgeheimnis",
    "href": "090-regression2.html#was-war-noch-mal-das-erfolgsgeheimnis",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.9 Was war noch mal das Erfolgsgeheimnis?",
    "text": "10.9 Was war noch mal das Erfolgsgeheimnis?\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. AbbildungÂ 10.20.\n\n\n\n\n\n\n\n\n\n(a) Sie gestern\n\n\n\n\n\n\n\n\n\n(b) Sie morgen\n\n\n\n\n\n\nAbbildungÂ 10.20: Statistik, Sie und Party: Gestern und (vielleicht) morgen. Wenn Sie dran bleiben, wird die Statistik Ihre beste Freundin (imgflip, 2024).",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausfÃ¼hrlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker FlugverspÃ¤tungen 2023\n\nSource\nVorhersage von FlugverspÃ¤tungen\n\n10.10.2 FilmerlÃ¶se\nVorhersagen von FilmerlÃ¶sen",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklÃ¤rt die lineare Regression mit Hilfe von Drachen. ğŸ‰ Sehenswert.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlÃ¤gigen Ãœbungsaufgaben bereit. Sie kÃ¶nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1\nmario-compare-models",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nEin empfehlenswertes Buch fÃ¼r Regressionsanalyse ist das Buch von Andrew Gelman zum Thema â€œRegression und andere Geschichtenâ€ (Gelman et al., 2021). Sein Buch ist fÃ¼r Sozialwissenschaftler geschrieben, also nicht fÃ¼r typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel. Eine Alternative bietet Sauer (2019).\n\n\n\n\nBarrett, M. (2021). Ggokabeito: â€™Okabe-Itoâ€™ Scales for â€™Ggplot2â€™ and â€™Ggraphâ€™ [Manual]. https://CRAN.R-project.org/package=ggokabeito\n\n\nDeutscher Wetterdienst. (2025a). Regional averages DE, monthly air temperature mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/air_temperature_mean/.\n\n\nDeutscher Wetterdienst. (2025b). Regional averages DE, monthly precipitation mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/precipitation/.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHabitator terrae. (2021). Deutsch: FÃ¼nfjÃ¤hrig Gemittelte Abweichung Der Lufftemperatur in Deutschland Vom LangjÃ¤hrigem Mittel 1951 Bis 1980 [Diagramm]. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nKassambara, A. (2023). ggpubr: â€™ggplot2â€™ Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private Traits and Attributes Are Predictable from Digital Records of Human Behavior. Proceedings of the National Academy of Sciences, 110(15), 5802â€“5805. https://doi.org/10.1073/pnas.1218772110\n\n\nKuhn, M., Vaughan, D., & Hvitfeldt, E. (2024). yardstick: Tidy Characterizations of Model Performance. https://CRAN.R-project.org/package=yardstick\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing, 104(2), 271â€“294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLÃ¼decke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., ThÃ©riault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., FranÃ§ois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., MÃ¼ller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., â€¦ Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWilke, S. (2013, Juni 26). Trends der Lufttemperatur [Bericht]. Umweltbundesamt; Umweltbundesamt. https://www.umweltbundesamt.de/daten/klima/trends-der-lufttemperatur",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10Â  Geradenmodelle 2\n",
    "section": "",
    "text": "Quelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3â†©ï¸\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/â†©ï¸\nIch danke Karsten LÃ¼bke fÃ¼r diese Idee.â†©ï¸\nIn AbbildungÂ 10.9? wird nicht der SchÃ¤tzbereich fÃ¼r die Regressionsgewichte dargestellt, sondern stattdessen die SD der AV.â†©ï¸\nZum Dollar-Operator s. Kapitel 3.11.3â†©ï¸\nsynonym: nominalskalierte Variableâ†©ï¸\nvgl. help(initial_split)â†©ï¸\nDas StÃ¶rche-Babys-Beispiel passt auch zu AbbildungÂ 10.19.â†©ï¸",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Ainali. (2007). Standard deviation diagram micro [Artwork]. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American\nStatistician, 27(1), 17â€“21.\n\n\nArad, C. (2024, June 5). Kylian Mbappe: Gehalt und VermÃ¶gen im\nÃœberblick (2024). ftd.de. https://www.ftd.de/vermoegen/mbappe-gehalt-vermoegen/\n\n\nBarrett, M. (2021). Ggokabeito: â€™Okabe-Itoâ€™\nScales for â€™Ggplot2â€™ and â€™ggraphâ€™ [Manual]. https://CRAN.R-project.org/package=ggokabeito\n\n\nBerger, G. (2019, December 10). The Jobs of\nTomorrow: LinkedInâ€™s 2020 Emerging Jobs\nReport. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nBortz, J., & Schuster, C. (2010). Statistik fÃ¼r\nHuman- und Sozialwissenschaftler.\nSpringer. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do,\nAccording to 35 Data Scientists. Harvard\nBusiness Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization\nin Spreadsheets. The American Statistician,\n72(1), 2â€“10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nBundesamt, S. (2023-003-272023-003-27). KÃ¶rpermaÃŸe nach\nAltersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household wealth and finances in\nGermany: Results of the 2021 household wealth\nsurvey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nÃ‡etinkaya-Runde, M., & Hardin, J. (2021). Introduction to\nModern Statistics. https://openintro-ims.netlify.app/\n\n\nÃ‡etinkaya-Rundel, M., Diez, D., Bray, A., Kim, A. Y., Baumer, B., Ismay,\nC., Paterno, N., & Barr, C. (2024). Openintro: Datasets and\nsupplemental functions from â€™OpenIntroâ€™ textbooks and labs. https://CRAN.R-project.org/package=openintro\n\n\nCmglee. (2015). English: Geometric visualisation of the\nvariance of the example distribution (2, 4, 4, 4, 5, 5, 7, 9) on\nw:Standard deviation. [artwork]. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155â€“159.\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003).\nApplied multiple regression/correlation analysis for the behavioral\nsciences, 3rd ed. Lawrence Erlbaum.\n\n\nCui, B. (2024). DataExplorer: Automate data exploration and\ntreatment. https://CRAN.R-project.org/package=DataExplorer\n\n\nDenisBoigelot. (2011). English: Redesign\nFile:Correlation_examples.png using vector\ngraphics (SVG file) [Artwork]. https://commons.wikimedia.org/w/index.php?curid=15165296\n\n\nDeutscher Wetterdienst. (2025a). Regional averages DE, monthly air\ntemperature mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/air_temperature_mean/.\n\n\nDeutscher Wetterdienst. (2025b). Regional averages DE, monthly\nprecipitation mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/precipitation/.\n\n\nDowney, A. (2023). Probably overthinking it: How to use data to\nanswer questions, avoid statistical traps, and make better\ndecisions. The University of Chicago Press.\n\n\nFisher, D., & Meyer, M. (2018). Making data visual: A practical\nguide to using visualization for insight. Oâ€™Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different\nGraphs: Generating Datasets with Varied\nAppearance and Identical Statistics through\nSimulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nflaticon. (2024). Professor [Artwork]. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoren, A., VaÃ±o-GalvÃ¡n, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur,\nA., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H.,\nKovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K.\n(2020). A preliminary observation: Male pattern hair loss\namong hospitalized COVID-19 patients in Spain\nâ€“ A potential clue to the role of androgens in\nCOVID-19 severity. Journal of Cosmetic\nDermatology, 19(7), 1545â€“1547. https://doi.org/10.1111/jocd.13443\n\n\nHabitator terrae. (2021). Deutsch: FÃ¼nfjÃ¤hrig gemittelte\nAbweichung der Lufftemperatur in\nDeutschland vom langjÃ¤hrigem Mittel 1951 bis\n1980 [diagramm]. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., &\nSchaub, M. P. (2015). Smartphone use and smartphone addiction among\nyoung people in Switzerland. Journal of Behavioral\nAddictions, 4(4), 299â€“307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHornik, K., Ligges, U., & Zeileis, A. (2023). Changes on CRAN.\nThe R Journal, 15, 295â€“296.\n\n\nHorst, A. (2023). Tidy Data [Artwork]. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The dynamics of\nHuman Development Index. The Social Science\nJournal, 52(3), 331â€“347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito,\nK. (2008). Color universal design: The selection of four easily\ndistinguishable colors for all color vision types. Color\nImaging XIII: Processing,\nHardcopy, and Applications,\n6807, 206â€“213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024a). Imageflip Bill Gates Meme\n[Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Kermit Meme [Artwork].\nhttps://imgflip.com\n\n\nimgflip. (2024c). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nimgflip. (2024d). Imageflip One does not\nsimply [Artwork]. https://imgflip.com\n\n\nimgflip. (2024e). Imageflip Tom Cruise Meme\n[Artwork]. https://imgflip.com\n\n\nimgflip. (2024f). Yoda Jealous Girl Friend Meme\n[Artwork]. https://imgflip.com\n\n\nInternational, T. (2017, January 25). Corruption Perceptions\nIndex 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via\ndata science: A ModernDive into R and the\nTidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nKaplan, D. T. (2009). Statistical modeling: A fresh approach.\nCreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKassambara, A. (2023). Ggpubr: â€™ggplot2â€™ based publication ready\nplots. https://CRAN.R-project.org/package=ggpubr\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private traits\nand attributes are predictable from digital records of human behavior.\nProceedings of the National Academy of Sciences,\n110(15), 5802â€“5805. https://doi.org/10.1073/pnas.1218772110\n\n\nKuhn, M., Vaughan, D., & Hvitfeldt, E. (2024). Yardstick: Tidy\ncharacterizations of model performance. https://CRAN.R-project.org/package=yardstick\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The smartphone\naddiction scale: Development and validation of a short version for\nadolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022).\nCustomer churn prediction system: A machine learning approach.\nComputing, 104(2), 271â€“294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLieberoth, A., Rasmussen, J., Stoeckli, S., Tran, T., Ä†epuliÄ‡, D.-B.,\nHan, H., Lin, S.-Y., Tuominen, J., Travaglino, G., & Vestergren, S.\n(2022). COVIDiSTRESS global survey. https://doi.org/10.17605/OSF.IO/Z39US\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive\nTheory to Statistics Instruction. The American\nStatistician, 54(3), 196â€“206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nLÃ¼decke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E.,\nThÃ©riault, R., & Makowski, D. (2022). Easystats: Framework for easy\nstatistical modeling, visualization, and reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nLyon, A. (2014). Why are Normal Distributions Normal?\nThe British Journal for the Philosophy of Science,\n65(3), 621â€“649. https://doi.org/10.1093/bjps/axs046\n\n\nM7. (2004). Savinelliâ€™s Italian smoking pipe\n[Artwork]. https://commons.wikimedia.org/wiki/File:Pipa_savinelli.jpg\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific\nMethod, Statistical Method and the\nSpeed of Light. Statistical Science,\n15(3), 254â€“278. https://doi.org/10.1214/ss/1009212817\n\n\nMaphry. (2009). Seesaw with mean [Artwork]. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMarks-Anglin, Arielle and Chen, Yong. (2020). A historical review of\npublication bias. Research Synthesis Methods, 11(6),\n725â€“742. https://doi.org/10.1002/jrsm.1452\n\n\nMatthews, R. (2000b). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nMatthews, R. (2000a). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36â€“38. https://doi.org/10.1111/1467-9639.00013\n\n\nMenk. (2014, July 29). Linear regression [computer code]. https://texample.net/tikz/examples/linear-regression/\n\n\nMesserli, F. H. (2012). Chocolate Consumption,\nCognitive Function, and Nobel Laureates.\nNew England Journal of Medicine, 367(16), 1562â€“1564.\nhttps://doi.org/10.1056/NEJMon1211064\n\n\nMittag, H.-J., & SchÃ¼ller, K. (2020). Statistik: Eine EinfÃ¼hrung\nmit interaktiven Elementen. Springer. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMoore, B. (2015, April 9). Recreating the vaccination heatmaps in\nR. Benomics. https://benjaminlmoore.wordpress.com/2015/04/09/recreating-the-vaccination-heatmaps-in-r/\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, &\nFarias, M. (2020). Psychological impact of COVID-19\npandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of Open Data and Computational\nReproducibility in Registered Reports in\nPsychology. Advances in Methods and Practices in\nPsychological Science, 3(2), 229â€“237. https://doi.org/10.1177/2515245920918872\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!:\nErfolg und SpaÃŸ im Horrorfach nichttechnischer StudiengÃ¤nge.\nSpringer. https://doi.org/10.1007/978-3-658-04605-7\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design\n(CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nPatil, I. (2021). Visualizations with statistical\ndetails: The â€™ggstatsplotâ€™ approach.\nJournal of Open Source Software, 6(61),\n3167. https://doi.org/10.21105/joss.03167\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: The new\nscience of cause and effect. Basic Books.\n\n\nPearson, K. (1896). VII. Mathematical\ncontributions to the theory of evolution.â€”III.\nRegression, heredity, and panmixia. Philosophical\nTransactions of the Royal Society of London. Series A, Containing Papers\nof a Mathematical or Physical Character, 187, 253â€“318. https://doi.org/10.1098/rsta.1896.0007\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability:\nA Brief History of a Confused Terminology.\nFrontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nPoldrack, R. A. (2023). Statistical thinking: Analyzing data in an\nuncertain world. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nR Core Team. (2024). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height [Data set]. In Our World in\nData. https://ourworldindata.org/human-height\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley\nStatsRef: Statistics Reference Online.\nJohn Wiley. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSauer, S. (2017). Dataset â€™predictors of performance in stats\ntestâ€™ [Data set]. Open Science Framework. https://doi.org/10.17605/OSF.IO/SJHUY\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen,\naufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nScherer, C., Radchuk, V., Staubach, C., MÃ¼ller, S., Blaum, N., Thulke,\nH., & Kramerâ€Schadt, S. (2019). Seasonal host lifeâ€history processes\nfuel disease dynamics at different spatial scales. Journal of Animal\nEcology, 88(11), 1812â€“1824. https://doi.org/10.1111/1365-2656.13070\n\n\nShimizu, Y. (2022). Multiple Desirable Methods in\nOutlier Detection of Univariate Data With R Source\nCodes. Frontiers in Psychology, 12, 819854. https://doi.org/10.3389/fpsyg.2021.819854\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011).\nFalse-Positive Psychology: Undisclosed\nFlexibility in Data Collection and Analysis\nAllows Presenting Anything as Significant.\nPsychological Science, 22(11), 1359â€“1366. https://doi.org/10.1177/0956797611417632\n\n\nSpurzem, L. (2017). VW 1303 von Wiking in\n1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG\n\n\nStigler, S. M. (2016). The seven pillars of statistical wisdom.\nHarvard University Press.\n\n\nTransfermarkt. (2024). Die wertvollsten FuÃŸball-Spieler. https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop/spielerposition_id/8/page/12\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross,\nA., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., &\nBurke, D. S. (2013). Contagious Diseases in the\nUnited States from 1888 to the Present.\nNew England Journal of Medicine, 369(22), 2152â€“2158.\nhttps://doi.org/10.1056/NEJMms1215400\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain\nDrain: The Mere Presence of Oneâ€™s\nOwn Smartphone Reduces Available Cognitive Capacity.\nJournal of the Association for Consumer Research,\n2(2), 140â€“154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data\nanalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild [Artwork].\nhttps://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D.,\nFranÃ§ois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M.,\nPedersen, T. L., Miller, E., Bache, S. M., MÃ¼ller, K., Ooms, J.,\nRobinson, D., Seidel, D. P., Spinu, V., â€¦ Yutani, H. (2019). Welcome to\nthe tidyverse. Journal of Open Source\nSoftware, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWickham, H., & Grolemund, G. (2018). R fÃ¼r Data Science: Daten\nimportieren, bereinigen, umformen, modellieren und visualisieren\n(F. Langenau, Trans.). Oâ€™Reilly. https://r4ds.had.co.nz/index.html\n\n\nWilke, C. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures. Oâ€™Reilly. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg\n\n\nWilke, S. (2013, June 26). Trends der Lufttemperatur [Bericht].\nUmweltbundesamt; Umweltbundesamt. https://www.umweltbundesamt.de/daten/klima/trends-der-lufttemperatur\n\n\nWorld Economic Forum. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Geradenmodelle",
      "Literatur"
    ]
  },
  {
    "objectID": "110-definitions.html",
    "href": "110-definitions.html",
    "title": "Anhang A â€” Definitionen",
    "section": "",
    "text": "Abweichungsrechteck: DefinitionÂ 8.1, s. S. \nAusprÃ¤gung: DefinitionÂ 2.8, s. S. \nBalkendiagramm: DefinitionÂ 5.3, s. S. \nBeobachtungseinheit: DefinitionÂ 2.6, s. S. \nBinÃ¤re Variable: DefinitionÂ 10.2, s. S. \nBoxplot: DefinitionÂ 5.10, s. S. \nData-Dictionary: DefinitionÂ 2.4, s. S. \nDataframe: DefinitionÂ 3.5, s. S. \nDaten: DefinitionÂ 2.3, s. S. \nDatendiagramm: DefinitionÂ 5.1, s. S. \nDatenjudo: DefinitionÂ 4.1, s. S. \nDezile: DefinitionÂ 6.6, s. S. \nDichtediagramm: DefinitionÂ 5.5, s. S. \nDas einfache lineare Modell: DefinitionÂ 9.3, s. S. \nExtremwert: DefinitionÂ 6.3, s. S. \nFehlerstreuung: DefinitionÂ 9.4, s. S. \nFunktion: DefinitionÂ 3.2, s. S. \nGerade: DefinitionÂ 9.2, s. S. \nHistogramm: DefinitionÂ 5.4, s. S. \nInteraktionseffekt: DefinitionÂ 10.4, s. S. \nInterquartilsabstand: DefinitionÂ 7.4, s. S. \nKonfidenzintervall: DefinitionÂ 10.1, s. S. \nKovarianz: DefinitionÂ 8.2, s. S. \nLagemaÃŸ: DefinitionÂ 6.8, s. S. \nLinearer Zusammenhang: DefinitionÂ 5.9, s. S. \nLineares Modell: DefinitionÂ 6.2, s. S. \nMittlere Absolutabweichung: DefinitionÂ 7.3, s. S. \nMedian: DefinitionÂ 6.4, s. S. \nModelle: DefinitionÂ 2.11, s. S. \nMultiple Regression: DefinitionÂ 10.3, s. S. \nMittelwert: DefinitionÂ 6.1, s. S. \nNormalverteilung: DefinitionÂ 5.7, s. S. \nEntstehung einer Normalverteilung: DefinitionÂ 5.8, s. S. \nNullmodell (Punktmodell): DefinitionÂ 9.1, s. S. \nPfeife: DefinitionÂ 4.2, s. S. \nPunktmodell: DefinitionÂ 6.9, s. S. \nQuantile: DefinitionÂ 6.7, s. S. \nQuartile: DefinitionÂ 6.5, s. S. \nKorrelationskoeffizient \\(r\\): DefinitionÂ 8.3, s. S. \n\\(R^2\\)-Quadrat: DefinitionÂ 9.5, s. S. \nSpannweite: DefinitionÂ 7.2, s. S. \nReproduzierbarkeit: DefinitionÂ 3.1, s. S. \nResiduum: DefinitionÂ 2.2, s. S. \nStandardabweichung: DefinitionÂ 7.6, s. S. \nSkalenniveau: DefinitionÂ 2.10, s. S. \nStatistik: DefinitionÂ 2.1, s. S. \nStreuungsmaÃŸe: DefinitionÂ 7.1, s. S. \nTest-Sample: DefinitionÂ 10.6, s. S. \nTidy Data: DefinitionÂ 2.9, s. S. \nTrain-Sample: DefinitionÂ 10.5, s. S. \nVariable: DefinitionÂ 7.5, s. S. \nVarianz: DefinitionÂ 7.5, s. S. \nVektorielles Rechnen: DefinitionÂ 3.4, s. S. \nVektor: DefinitionÂ 3.3, s. S. \nVerteilung: DefinitionÂ 5.2, s. S. \nWert: DefinitionÂ 2.7, s. S. \nz-Werte: DefinitionÂ 7.8, s. S. \nZentrieren: DefinitionÂ 7.7, s. S.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "120-mariokart.html",
    "href": "120-mariokart.html",
    "title": "Anhang B â€” Data-Dictionary fÃ¼r Mariokart",
    "section": "",
    "text": "In diesem Datensatz werden Auktionen zum Videospiel Wii Mario Kart beim Online-Auktionshaus Ebay dargestellt. Die Daten wurden im Oktober 2009 gesammelt. Es handelt sich um einen Dataframe mit 143 Beobachtungen (Auktionen) und 12 Spalten (Variablen). Die Preise sind in US-Dollar angegeben. Die Quelle des Datensatzes ist das R-Paket openintro (Ã‡etinkaya-Rundel et al., 2024). Alternativ ist der Datensatz online zu finden: https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv. Mit help(mariokart) wird die Hilfeseite zum Datensatz geÃ¶ffnet (dazu muss das Paket openintro bereitgestellt sein).\nTabelleÂ B.1 zeigt das Data-Dictionary.\n\n\n\nTabelleÂ B.1: Data-Dictionary fÃ¼r Mariokart\n\n\n\n\nVariable\nErklÃ¤rung\n\n\n\nid\nID der Auktion\n\n\nduration\nDauer der Auktion in Tagen\n\n\nn_bids\nAnzahl der Gebote\n\n\ncond\nZustand (new/used)\n\n\nstart_pr\nAnfangspreis bei der Auktion\n\n\nship_pr\nVersangebÃ¼hr\n\n\ntotal_pr\nGesamtpreis (inkl. VersandgebÃ¼hr)\n\n\nship_sp\nVersandmethode bzw. -geschwindigkeit\n\n\nseller_rate\nBewertung des VerkÃ¤ufers; das ist die Differenz zwischen positiven und negativen Bewertungen\n\n\nstock_photo\nLag der Auktion ein \"stock photo\" bei? Wenn ein Foto in vielen Auktionen benutzt wurde, wird es \"stock photo\" genannt.\n\n\nwheels\nAnzahl der enthaltenen Wii-RÃ¤der\n\n\ntitle\nName der Auktion\n\n\n\n\n\n\n\n\n\n\n\n\nÃ‡etinkaya-Rundel, M., Diez, D., Bray, A., Kim, A. Y., Baumer, B., Ismay, C., Paterno, N., & Barr, C. (2024). openintro: Datasets and Supplemental Functions from â€™OpenIntroâ€™ Textbooks and Labs. https://CRAN.R-project.org/package=openintro",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Data-Dictionary fÃ¼r Mariokart</span>"
    ]
  },
  {
    "objectID": "130-autor.html",
    "href": "130-autor.html",
    "title": "Anhang C â€” Zum Autor",
    "section": "",
    "text": "Professor Dr.Â habil. Sebastian Sauer arbeitet als Hochschullehrer an der Hochschule Ansbach und unterrichtet dort Statistik und verwandte FÃ¤cher. Sein Interesse gilt den Neuentwicklungen an statistischen Analyseverfahren und deren Anwendung auf sozialwissenschaftliche Probleme. Neben dem â€œWieâ€ der Datenanalyse beschÃ¤ftigen ihn die Grenzen und Gefahren, die die moderne Datenwissenschaft fÃ¼r den Einzelnen und die Zivilgesellschaft mit sich bringt. AuÃŸerdem interessiert er sich fÃ¼r die Frage, wie die Psychologie zur KlÃ¤rung von Problemen mit gesellschaftlicher Relevanz beitragen kann. Er ist Autor einiger FachbÃ¼cher und Fachartikel.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>C</span>Â  <span class='chapter-title'>Zum Autor</span>"
    ]
  }
]