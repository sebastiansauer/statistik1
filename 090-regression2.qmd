
# Geradenmodelle 2




## Einstieg









### Lernziele


- Sie k√∂nnen Regressionsmodelle f√ºr Forschungsfragen mit bin√§rer, nominaler und metrischer UV erl√§utern und in R anwenden.
- Sie k√∂nnen Interaktionseffekte in Regressionsmodellen erl√§utern und in R anwenden.
- Sie k√∂nnen den Anwendungszweck von Zentrieren und *z*-Transformationen zur besseren Interpretation von Regressionsmodellen erl√§utern und in R anwenden.


### Ben√∂tigte R-Pakete

Neben den √ºblichen Paketen `tidyverse` [@wickham2019a] und `easystats` [@easystats] ben√∂tigen Sie in diesem Kapitel noch `yardstick` [@kuhn2024] und optional `ggpubr` [@kassambara2023].



```{r}
#| message: false
library(tidyverse)
library(yardstick)  # f√ºr Modellg√ºte im Test-Sample
library(easystats)
library(ggpubr)  # Daten visualisieren, optional
```


```{r libs-hidden}
#| include: false
library(ggpubr)
library(plotly)
library(ggrepel)
library(scatterplot3d)

source("children/colors.R")
```




```{r}
#| include: false

source("_common.R")
```







{{< include children/colors.qmd >}}



### Ben√∂tigte Daten

Dieses Mal arbeiten wir nicht nur mit den Mariokartdaten,
sondern auch mit Wetterdaten.

::: {.content-visible when-format="html"}

```{r import-mariokart-csv}
mariokart_path <- "https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv"
mariokart <- read.csv(mariokart_path)

wetter_path <- paste0(
  "https://raw.githubusercontent.com/sebastiansauer/",
  "statistik1/main/data/wetter-dwd/precip_temp_DWD.csv")
wetter <- read.csv(wetter_path)
```


{{< downloadthis data/wetter.csv dname = "wetter" >}}

:::

 

::: {.content-visible when-format="pdf"}

```{r import-mariokart-csv2}
wetter_path <- paste0(
  "https://raw.githubusercontent.com/sebastiansauer/",
  "statistik1/main/data/wetter-dwd/precip_temp_DWD.csv")
wetter <- read.csv(wetter_path)
```

:::

Die Wetterdaten stammen vom [DWD](https://opendata.dwd.de/) [@dwd2023, @dwd2023a]
Ein *Data-Dictionary* f√ºr den Datensatz k√∂nnen Sie [hier](https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/wetter-dwd-data-dict.md) herunterladen.





## Forschungsbezug: Gl√§serne Kunden


Lineare Modelle (synonym: Regressionsanalysen) sind ein altes, aber m√§chtiges Werkzeug.
Sie geh√∂ren immer noch zum Standard-Repertoire moderner Analystinnen und Analysten.
Die Wirkm√§chtigkeit von linearen Modellen zeigt sich (leider?!) in folgendem Beispiel.

:::{#exm-kosinski}
### Wie gut kann man Ihre Pers√∂nlichkeit auf Basis Ihrer Social-Media-Posts  vorhersagen?

In einer Studie mit viel Medienresonanz untersuchten @kosinski2013, 
wie gut Pers√∂nlichkeitsz√ºge durch Facebook-Daten (Likes etc.) vorhergesagt werden k√∂nnen.
Die Autoren res√ºmieren im Abstract:

>   We show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.

Die Autoren berichten √ºber eine hohe Modellg√ºte (gemessen mit dem Korrelationskoeffizienten $r$) 
zwischen den tats√§chlichen pers√∂nlichen Attributen 
und den vorhergesagten Werten Ihres Modells, s. @fig-pnas1.
Das eingesetzte statistische Modell beruht auf einem linearen Modell, 
also √§hnlich den in diesem Kapitel vorgestellten Methoden.
Neben der analytischen St√§rke der Regressionsanalyse zeigt das Beispiel auch, 
wie gl√§sern man im Internet ist! $\square$
:::


![Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values 5@kosinski2013](img/pnas.kosinski.1218772110fig03.jpeg){#fig-pnas1 width="50%"}




## Wetter in Deutschland


:::{#exm-wetterdaten}
### Wetterdaten
Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach etwas Abwechslung. 
Viel Geld verdienen ist ja schon ganz nett,
aber dann fiel Ihnen ein, dass Sie ja zu Generation Z geh√∂ren, 
und daher den schn√∂den Mammon nicht so hoch sch√§tzen sollten.
Sie entschlie√üen sich, Ihre hochgesch√§tzten Analyse-Skills f√ºr etwas einzusetzen,
das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels. $\square$
:::

Beim [Deutschen Wetterdienst, DWD](https://www.dwd.de/DE/Home/home_node.html), haben Sie sich Wetterdaten von Deutschland heruntergeladen.
Nach etwas [Datenjudo, auf das wir hier nicht eingehen wollen,](https://data-se.netlify.app/2022/07/24/preparing-german-weather-data/) 
resultiert ein sch√∂ner Datensatz, den Sie jetzt analysieren m√∂chten.
(Im Datensatz ist die Temperatur ist in Grad Celsius angegeben; der Niederschlag  (`precip`) in mm Niederschlag pro Quadratmeter.)
Hervorragend! An die Arbeit!  


<!-- In @tbl-wetter  kann man sich die Daten en Detail anschauen (Temperatur und Niederschlag im Zeitverlauf). -->

::::: {.content-visible when-format="html" unless-format="epub"}

@fig-wetter-anim zeigen die Wetterdaten animiert.


::::{#fig-wetter-anim}

:::{.panel-tabset}

### Temperaturverlauf

![Temperatur (Grad Celsius) im Verlauf der Jahre](img/wetter1.gif)


### Niederschlagsverlauf

![Niederschlag (mm) im Verlauf der Jahre](img/wetter2.gif)

### Monatstemperaturverlauf

![Ver√§nderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte](img/wetter3.gif)

:::

Ver√§nderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts

::::
:::::






### Metrische UV

In diesem Abschnitt untersuchen wir lineare Modelle mit einer oder mehreren metrischen UV (und einer metrischen AV).

Sie stellen sich nun folgende Forschungsfrage:

>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?

Die Modellparameter von `lm_wetter1` sind in @tbl-lm-wetter1 zu sehen.

```{r}
#| results: hide
lm_wetter1 <- lm(temp ~ year, data = wetter)
parameters(lm_wetter1)
```

```{r}
#| echo: false
#| label: tbl-lm-wetter1
#| tbl-cap: "Modellparameter von lm_wetter1"
parameters(lm_wetter1) |> 
  select(Parameter, Coefficient, CI_low, CI_high) |> 
  print_md()
```


Laut dem Modell wurde es pro Jahr im Schnitt um 0.01 Grad w√§rmer, pro Jahrzehnt also 0.1 Grad und pro Jahrhundert 1 Grad.


>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!

>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Mit der Ruhe, das schauen wir uns sp√§ter an.





In @tbl-lm-wetter1 finden sich zwei Arten von Information f√ºr den Wert des Achsenabschnitts ($\beta_0$) und des Regressionsgewichts von `year` ($\beta _1$):

1. *Punktsch√§tzungen* In der Spalte `Coefficient` sehen Sie den "Best-Guess" (Punktsch√§tzer) f√ºr den entsprechenden Koeffizienten in der Population. 
Das ist sozusagen der Wert, f√ºr den sich das Modell festlegen w√ºrde, wenn es sonst nichts sagen d√ºrfte.

2. *Bereichsch√§tzungen* Cleverer als Punktsch√§tzungen sind Bereichssch√§tzungen (Intervallsch√§tzungen): Hier wird ein Bereich plausibler Werte f√ºr den entsprechenden Koeffizienten angegeben. In der Spalte "CI" sehen Sie die untere bzw. die obere Grenze eines "Bereichs plausibler Werte". Dieser Sch√§tzbereich wird auch als *Konfidenzintervall* (engl. confidence interval, CI) bezeichnet.
Ein Konfidenzintervall ist mit einer Sicherheit zwischen 0 und 1 angegeben, z.B. 95% (0.95).
Grob gesagt bedeutet ein 95%-Kondidenzintervall, dass wir uns zu 95% sicher sein k√∂nnen, dass der wahre Werte sich in diesem Bereich befindet.
In @tbl-lm-wetter1 k√∂nnen wir ablesen, dass das Regressionsgewicht von `year` irgendwo zwischen praktisch Null (0.009) 
und ca. 0.01 Grad gesch√§tzt wird.
Je schmaler das Konfidenzintervall, desto genauer wird der Effekt gesch√§tzt 
(unter sonst gleichen Umst√§nden). 


:::{#def-konfidenzintervall}
### Konfidenzintervall

Ein Konfidenzintervall (confidence interval, CI) 
gibt einen Sch√§tzbereich plausibler Werte f√ºr einen Populationswert an, 
  auf Basis der Sch√§tzung, die uns die Stichprobe liefert. $\square$
:::




Das Modell `lm_wetter1`, bzw. die Sch√§tzungen zu den erwarteten Werten, 
kann mich sich so ausgeben lassen, s. @fig-wetter1, links.
Allerdings sind das zu viele Datenpunkte. 
Wir sollten es vielleicht anders visualisieren, s. @fig-wetter1, rechts.
Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.
Auf dieser Basis erstellen wir ein neues lineares Modell, `lm_wetter1a`,  s. @tbl-lm-wetter1a.

```{r}
wetter_summ <-
  wetter %>% 
  group_by(year) %>% 
  summarise(temp = mean(temp),
            precip = mean(precip))  # precipitation: engl. f√ºr Niederschlag
```



```{r}
#| results: hide
lm_wetter1a <- lm(temp ~ year, data = wetter_summ)
parameters(lm_wetter1a) |> 
  select(Parameter, Coefficient)
```

```{r}
#| echo: false
#| label: tbl-lm-wetter1a
#| tbl-cap: "Modellparameter von lm_wetter1a"
parameters(lm_wetter1a) %>%
  select(Parameter, Coefficient) |> print_md()
```

Dann plotten wir das Modell mit `plot(estimate_relation(lm_wetter1a))` und das Modell `lm_wetter1` entsprechend, s. @fig-wetter1.

```{r}
#| label: fig-wetter1
#| echo: false
#| fig-cap: "Die Ver√§nderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD). Links: Jeder Punkt ist ein Tag (viel Overplotting, wenig n√ºtzlich). Rechts: Jeder Punkt ist ein Jahr (wetter_summ). Au√üerdem ist die Regressionsgerade dargestellt."
#| layout: [[45,-10, 45], [100]]
#| out-width: 100%
#| fig-subcap:
#|   - Ein Punkt pro Tag
#|   - Ein Punkt pro Jahr
plot(estimate_relation(lm_wetter1)) + theme_large_text() +
  labs(title = "")
plot(estimate_relation(lm_wetter1a)) + theme_large_text() +
   labs(title = "")
```


>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?


### UV zentrieren

Zur Erinnerung: Der Achsenabschnitt ($\beta_0$; engl. *intercept*) ist definiert als der $Y$-Wert an der Stelle $x=0$, s. @sec-interpret-reg-mod.


In den Wetterdaten w√§re Jahr=0 Christi Geburt. 
Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht,
ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extrapolieren,
ganz ohne, dass wir daf√ºr Daten haben, s. <https://xkcd.com/605/>.
Sinnvoller ist es da, z.$\,$B. einen *Referenzwert* festzulegen, etwa 1950.
Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null.
Damit bez√∂ge sich der Achsenabschnitt auf das Jahr 1950,
was Sinn macht, denn f√ºr dieses Jahr haben wir Daten.
Hat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet,
so ist es n√ºtzlich den Mittelwert (der UV) als Referenzwert zu nehmen.
Diese Transformation bezeichnet man als *Zentrierung* (engl. centering) der Daten, s. @def-zentrieren und @lst-zentrieren.


:::: {.content-visible when-format="html" unless-format="epub"}

![Du sollst nicht ein Modell weit au√üerhalb seines Datenbereichs extrapolieren](img/extrapolating.png){#fig-extrapolation width=75%}
::::





```{r}
wetter <-
  wetter %>% 
  mutate(year_c = year - mean(year))  # "c" wie centered
```

Das mittlere Jahr in unserer Messwertereihe ist √ºbrigens 1951, wie etas Datenjudo zeigt: `wetter %>% summarise(mean(year))`



Die Steigung (d.$\,$h. der Regressionskoeffizient f√ºr `year_c`) bleibt durch das Zentrieren unver√§ndert,
nur der Achsenabschnitt √§ndert sich, s. @tbl-lm_wetter1_zentriert.

```{r}
#| results: hide
lm_wetter1_zentriert <- lm(temp ~ year_c, data = wetter)
parameters(lm_wetter1_zentriert) |> 
  select(Coefficient, Parameter, CI_low, CI_high)
```


```{r}
#| echo: false
#| label: tbl-lm_wetter1_zentriert
#| tbl-cap: "Modellparameter von lm_wetter1_zentriert"
parameters(lm_wetter1_zentriert) |> 
  select(Coefficient, Parameter, CI_low, CI_high) %>% 
  print_md()
```

Jetzt ist die Interpretation des Achsenabschnitts komfortabel:
Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celsius.
Die Regressionsgleichung lautet: `temp_pred = 8.49 + 0.01*year_c`.
In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.


Wie gut erkl√§rt unser Modell die Daten?

```{r}
r2(lm_wetter1_zentriert)  # aus `{easystats}`
```

Viel Varianz des Wetters erkl√§rt das Modell mit `year_c` aber nicht. (`year` und `year_c` sind gleich stark mit `temp` korreliert, daher wird sich die Modellg√ºte nicht unterscheiden.).
Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.$\,$B. die Jahreszeit eine gro√üe Rolle f√ºr die Temperatur. Das haben wir nicht ber√ºcksichtigt.


>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"}  Wie warm ist es laut unserem Modell dann im Jahr 2051?

```{r}
predict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))
```


>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5¬∞ Celsius [@wilke2013].


>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Wir brauchen ein besseres Modell! Zum Gl√ºck haben wir ambitionierten Wissenschaftsnachwuchs.


:::: {.content-visible when-format="html"}
Die Ver√§nderung der auf f√ºnf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in @fig-temp-de dargestellt.
Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)^[Quelle: <https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3>]; rechts eine feinere (Daten ab 1881)^[Quelle: <https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/>].


:::{#fig-temp-de}
![Temperaturverlauf in Deutschland von 1753 bis 2020 [@earth_deutsch_2021]](img/temp-de.gif){width="50%"}

![](img/legende.png)
:::
::::

### Bin√§re UV


:::{#def-binvar}
### Bin√§re Variable
Eine *bin√§re* UV, auch *Indikatorvariable* oder *Dummyvariable* genannt, 
hat nur zwei Auspr√§gungen: 0 und 1. $\square$
:::


:::{#exm-bin}
### Bin√§re Variablen 
Das sind zum Beispiel *weiblich* mit den Auspr√§gungen `0` (nein) und `1` (ja) oder *before_1950* mit `1` f√ºr Jahre fr√ºher als 1950 und `0` ansonsten. $\square$
:::

:::{#exm-binuv}
Hier interessiert Sie folgende Forschungsfrage: 

>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Ob es in der zweiten H√§lfte des 20. Jahrhunderts wohl w√§rmer war, im Durchschnitt, als vorher? $\square$

:::

Aber wie erstellen Sie eine Variable `after_1950`, um die zweite H√§lfte des 20. Jahrhunderts (und danach) zu fassen?
Nach einigem √úberlegen kommen Sie auf die Idee, 
das vektorisierte Rechnen von R (s. @sec-veccalc) auszunutzen:

```{r}
year <- c(1940, 1950, 1960)
after_1950 <- year > 1950  # pr√ºfe, ob as Jahr gr√∂√üer als 1950 ist
after_1950
```

Die ersten zwei Jahre  von `year` sind nicht gr√∂√üer als 1950, das dritte schon.
Ja, so k√∂nnte das klappen! Diese Syntax √ºbertragen Sie auf Ihre `wetter`-Daten:

```{r}
wetter <-
  wetter %>% 
  mutate(after_1950 = year > 1950) %>% 
  filter(region != "Deutschland")  # ohne Daten f√ºr Gesamt-Deutschland
```


Scheint zu klappen!
Jetzt ein lineares Modell dazu berechnen, s. @tbl-lm-wetter-bin-uv.

```{r}
lm_wetter_bin_uv <- lm(temp ~ after_1950, data = wetter)
```

```{r}
#| echo: false
#| label: tbl-lm-wetter-bin-uv
#| tbl-cap: "Parameter von `lm_wetter_bin_uv`"
parameters(lm_wetter_bin_uv) |>
  select(Parameter, Coefficient, CI_high, CI_low) |> 
  print_md()
```


Die Parameterwertre des Modells lassen darauf schlie√üen, 
dass es tats√§chlich w√§rmer geworden ist nach 1950, 
und zwar im Schnitt 
offenbar ein gutes halbes Grad, s. @fig-wetter2.



```{r}
#| echo: false
#| label: fig-wetter2
#| layout: [[45,-10, 45], [100]]
#| fig-cap: "Modell: `temp ~ after_1950`, (a) Der Sch√§tzbereich f√ºr den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied. (b) Der Unterschied sieht in dieser Darstellung nicht gro√ü aus."
#| fig-subcap: 
#|   - "Mittelwertsunterschied als Regressionsparameter"
#|   - "Mittelwertsunterschied als Verteilungsvergleich"


lm_wetter_bin_uv |> 
  parameters() |> 
  plot() +
  theme_large_text() +
    theme(legend.position = "none") 

wetter |> 
  ggplot(aes(x = after_1950, y = temp)) +
  geom_boxplot(alpha = .5) +
  #geom_violin(alpha = .5) +
  stat_summary(fun = mean, 
               geom = "point", color = okabeito_colors()[1], 
               alpha = .7,
               size = 5) +  # Add mean points
  stat_summary(fun = mean, 
               geom = "line", 
               aes(group = 1), color = okabeito_colors()[2], 
               linewidth = 1) +  # Connect means | 
  theme_large_text()
```




Leider zeigt ein Blick zum Ergebnis der Funktion `r2`, dass die Vorhersageg√ºte des Modells zu w√ºnschen √ºbrig l√§sst (`r2(lm_wetter_bin_uv)`).
Wir brauchen ein besseres Modell.

Um die Koeffizienten eines linearen Modells auszurechnen,
ben√∂tigt man eine metrische UV und eine metrische AV.
Hier haben wir aber keine richtige metrische UV,
sondern eine *logische* Variable mit den Werten `TRUE` und `FALSE`.
Um die UV in eine metrische Variable umzuwandeln, 
gibt es einen einfachen Trick,
den R f√ºr uns ohne viel Ank√ºndigung durchf√ºhrt: 
Umwandling in eine oder mehrere *bin√§re* Variablen, s. @def-binvar.


Hat eine nominale UV *zwei* Stufen, so √ºberf√ºhrt (synonym: transformiert) `lm` diese Variable in *eine* bin√§re Variable.
Da eine bin√§re Variable wie eine metrische angesehen werden kann, 
kann die Regression in gewohnter Weise durchgef√ºhrt werden.
Wenn Sie die Ausgabe der Parameter betrachten, 
so sehen Sie die neu erstellte bin√§re Variable (s. @tbl-lm-wetter-bin-uv).
Man beachte, dass der urspr√ºngliche Datensatz nicht ge√§ndert wird, 
nur w√§hrend der Analyse von `lm` wird die Umwandlung der Variable  durchgef√ºhrt.

In unserem Fall liegt mit `after_1950` eine *logische* Variable mit den Werten `TRUE` und `FALSE` vor.
`TRUE` und `FALSE` werden von R automatisch als `1` bzw. als `0` verstanden. 
Also: Eine logische Variable ist schon eine bin√§re Variable.


>    [ü§ñ]{.content-visible when-format="html"}[\emoji{robot}]{.content-visible when-format="pdf"} Eine `1` kannst du als "Ja! Richtig!" verstehen und eine `0` als "Nein! Falsch!"


::::: {.content-visible when-format="html"}

:::{#exm-bin-trans}
### Beispiel: 'Geschlecht' in eine bin√§re Variable umwandeln.

Angenommen wir haben eine Variable `geschlecht` 
mit den zwei Stufen `Frau` und `Mann`
und wollen diese in eine Indikatorvariable umwandeln.
Da "Frau" alphabetisch vor "Mann" kommt, 
nimmt R "Frau" als *erste* Stufe bzw. als *Referenzgruppe*. 
"Mann" ist dann die zweite Stufe, 
die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird.
`lm` wandelt uns diese Variable in `geschlechtMann` 
um mit den zwei Stufen `0` (kein Mann, also Frau) und `1` (Mann). $\square$
:::


:::: {layout="[ 40, 20, 40 ]"}
::: {#first-column}


```{r}
#| echo: false

d2 <- tribble(
  ~id, ~geschlecht, ~geschlechtMann,
  1,   "Mann",       1,
  2,  "Frau",       0
)

d2[1:2] %>% knitr::kable()
```

:::

::: {#sec-col}
$\qquad \rightarrow$
:::

::: {#third-col}
```{r}
#| echo: false

d2 <- tribble(
  ~id, ~geschlecht, ~geschlechtMann,
  1,   "Mann",       1,
  2,  "Frau",        0
)

d2[c(1,3)] %>% knitr::kable()

```
:::
::::
:::::

:::{.callout-important}
Ein lineares Modell mit bin√§rer UV zeigt nichts anderes als die Differenz der Gruppenmittelwerte. $\square$
:::

```{r}
wetter %>% 
  group_by(after_1950) %>% 
  summarise(temp_mean = mean(temp))
```

Die Interpretation eines linearen Modells mit bin√§rer UV veranschaulicht @fig-binvar: 
Der Achsenabschnitt ($\beta_0$) entspricht dem Mittelwert der 1. Gruppe.
Der Mittelwert der 2. Gruppe entspricht der *Summe* aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. 
(@fig-binvar zeigt nur die Daten f√ºr den Monat Juli im Bundesland Bayern, der Einfachheit und √úbersichtlichkeit halber.)

```{r}
#| echo: false
#| label: fig-binvar
#| out-width: "75%"
#| fig-cap: Sinnbild zur Interpretation eines linearen Modells mit bin√§rer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)

wetter4 <-
  wetter |> 
  filter(month == 7, region == "Bayern") |> 
  mutate(after1950_TRUE = ifelse(after_1950, 1, 0)) 

lm4 <- lm(temp ~ after1950_TRUE, data = wetter4)

wetter4 %>% 
  ggplot(aes(x = after1950_TRUE, y = temp)) +
  geom_jitter(alpha = .5, width = .2) +
  #geom_violin(alpha = .7) +
  theme_minimal() +
  geom_hline(yintercept = coef(lm4)[1], linetype = "dashed") +
  geom_hline(yintercept = coef(lm4)[1] + coef(lm4)[2], linetype = "dashed") +
  geom_abline(slope =  coef(lm4)[2], intercept =  coef(lm4)[1], color = "grey20") +
  stat_summary(fun = "mean", color = "grey20") +
  annotate("point", x = 0, y = coef(lm4)[1], 
           color = beta0col, size = 5) +
  annotate("label", x = 0, y = coef(lm4)[1], 
           color = beta0col, label = "hat(beta)[0]",
           parse = TRUE, hjust = "left") +
  geom_segment(x = 1, y = coef(lm4)[1], yend = coef(lm4)[1] + coef(lm4)[2], 
               color = beta1col,
               linewidth = 1.2,
             arrow = arrow(length = unit(0.03, "npc"))) +
  annotate("label", x = 1, y = coef(lm4)[1] +  coef(lm4)[2]*0.5, 
           color = beta1col, label = "hat(beta)[1]",
           parse = TRUE, hjust = 2) +
  scale_x_continuous(breaks = c(0, 1)) +
  coord_cartesian(ylim = c(16, 18)) +
  annotate("label", x = c(0, 1), y = 16, label = c("bis 1950", "nach 1950"))
  
```

Fassen wir die Interpretation der Koeffizienten f√ºr das Modell mit bin√§rer UV zusammen:

1. Mittelwert der 1. Gruppe (bis 1950): [Achsenabschnitt ($\beta_0$)]{.beta0col}
2. Mittelwert der 2. Gruppe (nach 1950): [Achsenabschnitt ($\beta_0$)]{.beta0col} + [Steigung der Regressionsgeraden ($\beta_1$)]{.beta1col}


::: {.content-visible unless-format="epub"}
F√ºr die Modellwerte $\color{modelcol}{\hat{y}}$ gilt also:

- Temperatur laut Modell bis 1950: $\color{modelcol}{\hat{y}} = \color{beta0col}{\beta_0} = 17.7$ 

- Temperatur laut Modell bis 1950: $\color{modelcol}{\hat{y}} = \color{beta0col}{\beta_0} +  \color{beta1col}{\beta_1}= \color{beta0col}{17.7} + \color{beta1col}{0.6} = 18.3$ 
:::


:::: {.content-visible when-format="epub"}
F√ºr die Modellwerte ${\hat{y}}$ gilt also:

- Temperatur laut Modell bis 1950: ${\hat{y}} = {\beta_0} = 17.7$ 

- Temperatur laut Modell bis 1950: ${\hat{y}} = {\beta_0} + {\beta_1}= {17.7} + {0.6} = 18.3$ 
::::





Bei *nominalen* (und auch bei *bin√§ren*) Variablen kann man ${\beta_1}$ als einen *Schalter* verstehen; bei *metrischen* Variablen als einen *Dimmer*.^[Ich danke Karsten L√ºbke f√ºr diese Idee.] $\square$


### Nominale UV

In diesem Abschnitt betrachten wir ein lineares Modell (f√ºr uns synonym: Regressionsmodell) mit einer mehrstufigen (nominalskalierten) UV. 
So ein Modell ist von den Ergebnissen her praktisch identisch zu einer   *Varianzanalyse* mit einer einzigen UV.


:::{#exm-wetter2}
Ob es wohl substanzielle Temperaturunterschiede zwischen den Bundesl√§ndern gibt?
:::

Befragen wir dazu ein lineares Modell; 
in @tbl-lm_wetter_region sind f√ºr jeden Parameter der Punktsch√§tzer (Koeffizient)
und das zugeh√∂rige Sch√§tzbereich (Konfidenzintervall) 
mit Ober- und Untergrenze angegeben.



```{r}
#| results: false
lm_wetter_region <- lm(temp ~ region, data = wetter)
```


```{r}
#| echo: false
#| label: tbl-lm_wetter_region
#| tbl-cap: "Modellparameter f√ºr `lm_wetter_region`"
#| message: false
lm_wetter_region_params <- 
  parameters(lm_wetter_region) 

lm_wetter_region_params |> 
  select(Parameter, Coefficient, CI_high, CI_low)
```

Hat die nominalskalierte UV mehr als zwei Stufen, 
so transformiert `lm` sie in mehr als eine Indikatorvariable um.
Genauer gesagt ist es immer eine Indikatorvariable 
weniger als es Stufen in der nominalskalierten Variablen gibt.
Allgemein gilt: Hat eine nominale Variable $k$ Stufen, so wird diese Variable von `lm` in $k-1$ bin√§re Variablen umgewandelt.




Betrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte `Bundesland` -- aus Gr√ºnden der Einfachheit hier nur mit *drei* Bundesl√§ndern. 
Damit `lm` arbeiten kann, wird `Bundesland` in *zwei* Indikatorvariablen umgewandelt.


:::: {layout="[ 30, 10, 60 ]"}
::: {#first-column-bu}

```{r}
#| echo: false

d <- tribble(
  ~id, ~Bundesland, ~BL_Bayern, ~BL_Bra,
  1,   "BaW√º",       0,   0,
  2,  "Bayern",       1,  0,
  3, "Brandenburg",   0,  1
)

d[1:2] %>% knitr::kable()
```

:::

::: {#second-column-bu}
<br />
<br />
$\quad \rightarrow$
:::


::: {#third-column-bu}
```{r}
#| echo: false

d[c(1,3, 4)] %>% knitr::kable()
```
:::
::::






Auch im Fall mehrerer Auspr√§gungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei bin√§ren Variablen:



1. Mittelwert der 1. Gruppe: Achsenabschnitt ($\beta_0$)
2. Mittelwert der 2. Gruppe: Achsenabschnitt ($\beta_0$) + Steigung der 1. Regressionsgeraden ($\beta_1$)
3. Mittelwert der 3. Gruppe: Achsenabschnitt ($\beta_0$) + Steigung der  2. Regressionsgeraden ($\beta_2$)
4. usw.

Es kann nervig sein, dass das Bundesland, 
welches als *Referenzgruppe* (sprich als Gruppe des Achsenabschnitts) ausgew√§hlt wurde nicht explizit in der Ausgabe angegeben ist.
Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.
Bei einer Variable vom Typ `character` w√§hlt R den alphabetisch ersten Wert als Referenzgruppe f√ºr ein lineares Modell aus. Bei einer Variable vom Typ `factor` ist die Reihenfolge bereits festgelegt, vgl. @sec-faktorvar.
Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. 





:::{#exm-baw√º}
### Achsenabschnitt in wetter_lm2
Da Baden-W√ºrttemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgew√§hlt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird. $\square$
:::



Am einfachsten verdeutlicht sich `lm_wetter_region` vielleicht mit einem Diagramm, s. @fig-bin-nom.



```{r}
#| echo: false
#| label: fig-bin-nom
#| out-width: 100%
#| fig-cap: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). 

wetter_summ <- 
  wetter %>% 
  group_by(region) %>% 
  summarise(temp = mean(temp)) %>% 
  mutate(id = 0:15) %>% 
  ungroup() %>%
  mutate(grandmean = mean(temp),
         delta = temp - grandmean)

wetter_summ %>%  
# filter(region != "Deutschland") %>% 
  ggplot(aes(y = region, x = temp)) +
  theme_minimal() +
  geom_label(aes(label = paste0("b", id),
                 x = grandmean + delta), 
             vjust = 1,
             size = 2) +
  #stat_summary(fun = "mean", color = "grey20") + 
  geom_vline(xintercept = coef(lm_wetter_region)[1], linetype = "dashed", color = okabeito_colors()[2]) +
  coord_cartesian(xlim = c(7, 10), ylim = c(0, 16))  +
  
  #coord_flip() +
  annotate("label",
           y = 1,
           x = coef(lm_wetter_region)[1],
           vjust = 1,
           label = paste0("b0"),
           #size = 6,
           color = beta0col) +
  annotate("point", 
           y = 1, 
           x = coef(lm_wetter_region)[1], 
           color = beta0col,
           #vjust = 1,
           size = 4) +
  geom_segment(aes(yend = region, xend = temp), 
               x = coef(lm_wetter_region)[1])  +
    geom_point() +
  labs(y = "",
       x = "Temperatur")
```



:::{#exm-months}
### Niederschlagsmenge im Vergleich der Monate

Eine weitere Forschungsfrage, die Sie nicht au√üer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation).
Los R, rechne! $\square$
:::

>    [ü§ñ]{.content-visible when-format="html"}[\emoji{robot}]{.content-visible when-format="pdf"} Endlich geht's weiter! [Ergebnisse findest du in @tbl-lm_wetter-month!]{.content-visible when-format="html"}



```{r}
#| results: hide
lm_wetter_month <- lm(precip ~ month, data = wetter)
parameters(lm_wetter_month)
```

```{r}
#| echo: false
#| eval: !expr knitr:::is_html_output()
#| label: tbl-lm_wetter-month
#| tbl-cap: Modellparameter f√ºr lm_wetter_month
parameters(lm_wetter_month) %>% print_md()
```


Ja, da scheint es deutliche Unterschiede im Niederschlag zu geben. 
Wir brauchen ein Diagramm zur Verdeutlichung, s. @fig-wetter-month, links (`plot(estimate_expectation(lm_wetter_month)`).
Oh nein:  R betrachtet `month` als numerische Variable! 
Aber "Monat" bzw. "Jahreszeit" sollte nominal sein.

>    [ü§ñ]{.content-visible when-format="html"}[\emoji{robot}]{.content-visible when-format="pdf"} Aber `month` ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!

>    [üë©]{.content-visible when-format="html"}[\emoji{woman}]{.content-visible when-format="pdf"} Okay, R, wir m√ºssen  `month` in eine nominale Variable transformieren. Wie geht das?


>    [ü§ñ]{.content-visible when-format="html"}[\emoji{robot}]{.content-visible when-format="pdf"} Dazu kannst du den Befehl `factor` nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch hei√üt das, dass dann eine Zahl als Text gesehen wird.


:::{#exm-factor}
Transformiert man `42` mit `factor`, so wird aus `42` `"42"`. Aus der Zahl wird ein Text.
Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau. $\square$
:::

```{r}
wetter <-
  wetter %>% 
  mutate(month_factor = factor(month))
```

Jetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. @tbl-lm_wetter_month_factor.

```{r}
#| results: hide
lm_wetter_month_factor <- lm(precip ~ month_factor, data = wetter)
parameters(lm_wetter_month_factor) |> 
  select(Parameter, Coefficient)
```

```{r}
#| echo: false
#| label: tbl-lm_wetter_month_factor
#| tbl-cap: "Modellparameter von lm_wetter_month_factor (nur die ersten paar Parameter)"
parameters(lm_wetter_month_factor) |> 
  select(Parameter, Coefficient) 
```



Sehr sch√∂n! Jetzt haben wir eine Referenzgruppe (Monat 1, d.$\,$h. Januar) und 11 Unterschiede zum Januar, s. @fig-wetter-month. 

:::{#exr-fig-wetter-month}
In √§hnlicher Form k√∂nnten Sie auch die Regressionsgewichte wie folgt plotten: `parameters(lm_wetter_month_factor) |> plot()`. Was sind die Unterschiede zu @fig-wetter-month?^[In @fig-wetter-month? wird nicht der Sch√§tzbereich f√ºr die Regressionsgewichte dargestellt, sondern stattdessen die SD der AV.]  $\square$
:::


```{r}
#| label: fig-wetter-month
#| fig-cap: "Niederschlagsmengen nach Monaten (Mittelwerte plus SD)"

wetter_summ2 <- wetter %>%
  group_by(month_factor) %>%
  summarise(
    mean_precip = mean(precip, na.rm = TRUE),
    sd_precip = sd(precip, na.rm = TRUE),
    n_precip = n() # Optional: for standard error calculation
  )

ggerrorplot(data = wetter_summ2,
            x = "month_factor",
            y = "mean_precip",
            ymin = "mean_precip - sd_precip",
            ymax = "mean_precip + sd_precip",
            ylab = "Niedeschlag",
            xlab = "Monat")

```





M√∂chte man die Referenzgruppe eines Faktors √§ndern, 
kann man dies mit `relevel` tun:

```{r}
wetter <-
  wetter %>% 
  mutate(month_factor = relevel(month_factor, ref = "7"))
```

So sieht dann die ge√§nderte Reihenfolge aus:^[Zum Dollar-Operator s. @sec-dollar-op]

```{r}
levels(wetter$month_factor)
```



### Bin√§re plus metrische UV {#sec-faktorvar}

In diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer *zweistufigen* (bin√§ren) UV plus einer *metrischen* UV. 
Ein solches Modell kann auch als *Kovarianzanalyse* (engl. analysis of covariance, ANCOVA) bezeichnet werden.

:::{#exm-rain1}
Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren?
Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).

```{r def-wetter-month}
wetter_month_1_7 <-
  wetter %>% 
  filter(month == 1  | month == 7) 
```


>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Ich muss mal kurz auf eine Sache hinweisen ‚Ä¶

Eine Faktorvariable ist einer der beiden Datentypen in R, die sich f√ºr nominalskalierte Variablen anbieten: 
Textvariablen (`character`) und Faktor-Variablen (`factor`).
Ein wichtiger Unterschied ist, dass die erlaubten Auspr√§gungen ("Faktorstufen") bei einer Faktor-Variable mitgespeichert werden, 
bei der Text-Variable nicht.
Das kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche Auspr√§gungen in Ihrer Variable m√∂glich sind. $\square$
:::


:::{#exm-factor1}
### Beispiele f√ºr Faktorvariablen

```{r def-geschlecht-factor}
geschlecht <- c("f", "f", "m")
geschlecht_factor <- factor(geschlecht)
geschlecht_factor
```
:::


Filtern ver√§ndert die Faktorstufen nicht.
Wenn Sie von der Faktorvariablen^[synonym: nominalskalierte Variable] `geschlecht` das 3. Element (`"m"`) herausfiltern, 
so dass z.$\,$B. nur die ersten beiden Elemente √ºbrig bleiben mit allein der Auspr√§gung `"f"`, merkt sich R trotzdem, dass die Variable laut Definition
*zwei* Faktorstufen besithzt (`"f"` und `"m"`).

Genaus so ist es, wenn Sie aus `wetter` nur die Monate  `"1"` und `"7"` herausfiltern:
R merkt sich, dass es 12 Faktorstufen gibt. 
M√∂chten Sie die herausgefilterten Faktorstufen "l√∂schen", 
so k√∂nnen Sie einfach die Faktorvariable neu definieren (mit `factor`).


```{r wetter-month-1-7}
wetter_month_1_7 <-
  wetter %>% 
  filter(month == 1  | month == 7) %>% 
  # Faktor (und damit die Faktorstufen) neu definieren:
  mutate(month_factor = factor(month))
```



Hat man mehrere ("multiple") X-Variablen (Pr√§diktoren, unabh√§ngige Variablen), 
so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.$\,$B. `temp ~ year_c + month`.


:::{#def-mult-regr}
### Multiple Regression
Eine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:

$y \sim x_1 + x_2 + \ldots + x_n \qquad \square$
:::



::: {.content-visible when-format="html"}

Die Ver√§nderung der monatlichen Temperatur (10-Jahres-Mittel) ist in @fig-wetter-anim, c) dargestellt (aber mit allen 12 Monaten, sieht sch√∂ner aus).
:::





Das Pluszeichen hat in der Modellgleichung (synonym: Regressionsformel) *keine* arithmetische Funktion. 
Es wird nichts addiert.
In der Modellgleichung sagt das Pluszeichen nur "und noch folgende UV ‚Ä¶". 


Die Modellgleichung von `lm_year_month` liest sich also so:

>    Temperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats


```{r lm-year-month-def}
lm_year_month <- lm(precip ~ year_c + month_factor, 
                    data = wetter_month_1_7)
```

Die Modellparameter sind in @tbl-lm-year-month zu sehen.

```{r lm-year-month-params}
#| echo: false
#| label: tbl-lm-year-month
#| tbl-cap: "Modellparameter von lm_year_month"
parameters(lm_year_month) %>% 
  select(Coefficient, Parameter, CI_low, CI_high) |> 
  print_md()
```



Die Modellkoeffizienten sind so zu interpretieren:

1. Achsenabschnitt ($\beta_0$, `(Intercept`)): Im Referenzjahr (1951) im *Referenzmonat Januar* lag die Niederschlagsmenge bei 57$\,$mm pro Quadratmeter.
2. Regressionskoeffizient f√ºr Jahr ($\beta_1$, `year_c`): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.03$\,$mm an (im Referenzmonat).
3. Regressionskoeffizient f√ºr Monat ($\beta_2$, `month [7]`) Im Monat `7` (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25$\,$mm √ºber dem mittleren Wert des Referenzmonats (Januar).


Die Regressiongleichung von `lm_year_month` lautet: 
`precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7`.
Im Monat Juli ist `month_factor_7 = 1`, 
ansonsten (Januar) ist `month_factor = 0`. 
Demnach erwarten wir laut Modell `lm_year_month` im Juli des Referenzjahres `r 56.94 + 24.37`$\,$mm Niederschlag.
Die Werte der Regressionskoeffizienten sind @tbl-lm-year-month entnommen.

>    [üßë‚Äçüéì]{.content-visible when-format="html"}[\emoji{student}]{.content-visible when-format="pdf"} Puh, kompliziert!

>    [üßë‚Äçüè´]{.content-visible when-format="html"}[\emoji{teacher}]{.content-visible when-format="pdf"} Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. @exm-niederschlag1.



:::{#exm-niederschlag1}
### Niederschlag laut Modell Im Juli 2020?
Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag f√ºr Juli im Jahr 2020!

```{r predict-lm-year-month}
neue_daten <- tibble(year_c = 2020-1951,
                     month_factor = factor("7"))
predict(lm_year_month, newdata = neue_daten)
```

Mit `predict` kann man sich Vorhersagen eines Modells ausgeben lassen. $\square$
:::




Alle Regressionskoeffizienten beziehen sich auf die AV *unter der Annahme, dass alle √ºbrigen UV den Wert Null (bzw. Referenzwert) aufweisen*.




Visualisieren wir uns die gesch√§tzten Erwartungswert pro Wert der UV, 
s. @fig-lm3: `plot(estimate_expectation(lm_year_month))`

```{r plot-lm3}
#| label: fig-lm3
#| fig-cap: "Niederschlag f√ºr Januar (month 1) und Juli (month 7) im Verlauf der Jahre. Man beachte, dass die Regressionsgeraden _parallel_ sind."
#| echo: false
#| fig-asp: 0.5

ggplot(wetter_month_1_7) +
  aes(x = year_c, 
      y = precip, 
      color = month_factor,
      group = month_factor) +
  geom_point2(alpha = .1) +
  scale_color_okabeito() +
  geom_abline(slope = coef(lm_year_month)[2],
              intercept = coef(lm_year_month)[1], 
              color = okabeito_colors()[1], size = 2,
              linetype = "1111") +
  geom_abline(slope = coef(lm_year_month)[2],
              intercept = coef(lm_year_month)[1] + coef(lm_year_month)[3], color = okabeito_colors()[2], size = 2) +
  annotate("label", x = Inf,
           y = predict(lm_year_month, newdata = tibble(year_c = 50, month_factor = factor("1"))),
           label = "month 1", hjust = 1.1) +
  scale_x_continuous(limits = c(-100, 100)) +
  theme(legend.position = "none") +
  annotate("label", x = Inf,
           y = predict(lm_year_month, newdata = tibble(year_c = 50, month_factor = factor("7"))),
           label = "month 7", hjust = 1.1)

```

Mit `scale_color_okabeito` haben wir die Standard-Farbpalette durch die von  [@okabeito] ersetzt [s. @barrett2021].
Das ist nicht unbedingt n√∂tig, 
aber robuster bei Sehschw√§chen, vgl. @sec-farbwahl.
Die erkl√§rte Varianz von `lm_year_month` liegt bei:
```{r}
r2(lm_year_month)
```



### Interaktion

Eine Modellgleichung der Form `temp ~ year + month` zwingt die Regressionsgeraden dazu, parallel zu verlaufen.
Aber vielleicht w√ºrden sie besser in die Punktewolken passen, 
wenn wir ihnen erlauben, auch *nicht* parallel verlaufen zu d√ºrfen?
Nicht-parallele Regressionsgeraden erlauben wir, 
indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. @lst-lm-interact.


```{r lm_year_month_interaktion}
#| lst-label: lst-lm-interact
#| lst-cap: "Ein Interaktionsmodell spezifiziert man in dieser Art: y ~ x1 + x2 + x1:x2"
lm_year_month_interaktion <- lm(
  precip ~ year_c + month_factor + year_c:month_factor, 
  data = wetter_month_1_7)
```

Visualisiert ist das Modell in @fig-wetter-interakt.

```{r plot-lm_year_month_interaktion}
#| results: hide
#| eval: false
plot(estimate_relation(lm_year_month_interaktion)) 
```


```{r plot-precip-interaction}
#| echo: false
#| label: fig-wetter-interakt
#| fig-asp: 0.5
#| fig-cap: "Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die Ver√§nderung im Verlauf der Jahre ist unterschiedlich f√ºr die Monate (Januar vs. Juli). Die beiden Regressionsgeraden sind _nicht_ parallel."

d <- tibble(
    year_c = 100,  # Adjust x-position slightly for better spacing
    precip = c(
      predict(lm_year_month_interaktion, newdata = tibble(year_c = 50, month_factor = factor("7"))),
      predict(lm_year_month_interaktion, newdata = tibble(year_c = 50, month_factor = factor("1")))
    ),
    label = c("month 7", "month 1"),
    month_factor = c("7", "1")
  )

ggplot(wetter_month_1_7) +
  aes(x = year_c, 
      y = precip, 
      color = month_factor,
      linetype = month_factor,
      group = month_factor) +
  geom_point(alpha = .2, aes(shape = month_factor)) +  # Removed geom_point2 (assuming it was a typo)
  geom_smooth(method = "lm", size = 2, fullrange = TRUE) +
  scale_color_okabeito() +
  scale_x_continuous(limits = c(-100, 125)) +
  theme(legend.position = "none") +
  geom_label_repel(
    data = d,

    aes(x = year_c, y = precip, label = label),
    hjust = 1.1,
    nudge_x = 5,  # Nudges labels slightly to the right
    nudge_y = 0.1,  # Adjusts vertical spacing to reduce overlap
    direction = "y",  # Moves labels along the y-axis
    segment.color = "gray50",  # Draws connecting line
    size = 5
  ) 
```



Der *Doppelpunkt-Operator* (`:`) f√ºgt der Regressionsgleichung einen *Interaktionseffekt* hinzu, 
in diesem Fall die Interaktion von Jahr (`year_c`) und Monat (`month_factor`):


`precip ~ year_c + month_factor + year_c:month_factor`


:::{#def-interakt}
### Interaktionseffekt
Einen Interaktionseffekt von x1 und x2 kennzeichnet man in R mit dem Doppelpunkt-Operator, `x1:x2`:

`y ~ x1 + x2 + x1:x2` $\square$
:::

In Worten: 

>   y wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.



Wie man in @fig-wetter-interakt sieht, sind die beiden Regressionsgeraden *nicht parallel*.
Sind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel,
so liegt ein *Interaktionseffekt* vor.
In diesem Fall ist der Interaktionsffekt ungleich Null. $\square$


:::{#exm-interakt-precip}
### Interaktionseffekt von Niederschlag und Monat

Wie ist die Ver√§nderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)?
*Das kommt darauf an, welchen Monat man betrachtet*.
Der Effekt der Zeit ist *unterschiedlich* f√ºr die Monate:
Im Juli nahm der Niederschlag ab, im Januar zu. $\square$
:::

Liegt ein Interaktionseffekt vor, 
kann man nicht mehr von "dem" (statistischen) Effekt einer UV (auf die AV) sprechen.
Vielmehr muss man unterscheiden: 
Je nach Gruppe (z.$\,$B. Monat) unterscheidet der Effekt des Jahres auf die Niederschlagsmenge.
("Effekt" ist hier immer statistisch, nie kausal gemeint.)
Betrachten wir die Parameterwerte des Interaktionsmodells, 
s. @tbl-lm_year_month_interaktion.



```{r} 
#| echo: false
#| label: tbl-lm_year_month_interaktion
#| tbl-cap: "Modellparameter von lm_year_month_interaktion"
parameters(lm_year_month_interaktion) %>% select(Parameter, Coefficient, CI_low, CI_high)
```

Neu bei der Ausgabe zu diesem Modell ist die unterste Zeile f√ºr den Parameter `year c √ó month factor [7]`.
Sie gibt die St√§rke des Interaktionseffekts an.
<!-- Da die Null nicht im Sch√§tzbereich (`95 CI`) liegt, ist der Interaktionseffekt offenbar nicht Null, also vorhanden (zumindest laut unserem Modell^[unser Modell k√∂nnte ja auch falsch sein.]. -->
Die Zeile zeigt, 
wie unterschiedlich sich die die Niederschlagsmenge 
zwischen den beiden Monaten im Verlauf der Jahre √§ndert: 
Pro Jahr ist die Zunahme an Niederschlag um 0.20$\,$mm geringer
als im Referenzmonat (Januar).
Damit resultiert f√ºr Juli insgesamt ein positiver Effekt: 
`0.13 - -0.20 = 0.07`.
Insgesamt lautet die Regressionsgleichung:
`precip_pred = 56.91 + 0.13 * year_c + 24.37 * month_factor_7 - 0.20 * year_c:month_factor_7`.


:::{.callout-important}
Der Achsenabschnitt gibt den Wert der AV an unter der Annahme, dass alle UV den Wert Null aufweisen. $\square$
:::

Wenn eine Beobachtung in allen UV den Wert 0 hat, 
so gibt der Achsenabschnitt  den Niederschlag f√ºr den Januar des Jahres 1951 an.
Die Regressionskoeffizienten geben die Zunahme in der AV an, 
wenn der jeweilige Wert der UV um 1 steigt, 
die √ºbrigen UV aber den Wert 0 aufweisen. 





Das $R^2$ von `lm_year_month_interaktion` betr√§gt √ºbrigens 
nur geringf√ºgig mehr als im Modell ohne Interaktion:

```{r}
r2(lm_year_month_interaktion)  # aus `{easystats}`
```

Da man Modelle so einfach wie m√∂glich halten sollte,
k√∂nnten wir auf den Interaktionseffekt im Modell verzichten.
Der Interaktionseffekt verbessert die Modellg√ºte nur geringf√ºgig.
Falls wir aber von einer starken Theorie ausgehen,
die den Interaktionseffekt verlangt,
h√§tten wir einen triftigen Grund, 
den Interaktionseffekt im Modell zu belassen.



## Modelle mit vielen UV


### Zwei metrische UV




:::::{.content-visible when-format="html" unless-format="epub"}


Ein Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. @fig-3d-regr.
Im 3D-Raum wird die Regressionsgerade zu einer *Regressionsebene.*

::::{#fig-3d-regr}


:::{.panel-tabset}

#### 3D-Animation

![Animation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erkl√§rt](img/regression_plane_rotation.gif){#fig-regression-plane-rotation}

<!-- #### 3D-Diagramme f√ºr Modelle mit zwei Pr√§diktoren -->

```{r}
#| include: false

df_3d <-
  tibble(x1 = rnorm(mean = 0, sd = 1, n=  100),
         x2 =  rnorm(mean = 0, sd = 1, n=  100),
         y = 3 + 2*x1 + x2 + rnorm(mean = 0, sd = 0.1, n = 100)
         )

lm3d <- lm(y ~ x1 + x2, data = df_3d)
```



<!-- ```{r} -->
<!-- #| label: Ein interaktives 3D-Diagramm und Regressionsebene -->
<!-- #| echo: false -->
<!-- #| eval: !expr knitr:::is_html_output() -->

<!-- source("children/3d.R") -->
<!-- scatterplot_3d_with_trace -->
<!-- ``` -->

#### 2D-Diagramm f√ºr 3D-Modell

```{r}
#| label: 2D-Diagramm f√ºr 3D-Modell
#| echo: false
lm3d_expect <- estimate_relation(lm3d)
plot(lm3d_expect)
```


:::

::::

:::::


::::: {.content-visible when-format="pdf"}

Ein Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. @fig-3d-regr-statisch, oder im 2D-Raum, s. @fig-3d-regr-2d.
Im 3D-Raum wird die Regressionsgerade zu einer *Regressionsebene.*



::: {#fig-3d-regr-statisch layout-ncol=3}


![Winkel 1](img/3d_scatter1.png)

![Winkel 2](img/3d_scatter2.png)

![Winkel 3](img/3d_scatter3.png)


Ein lineares Modell, `y ~ x1 + x2` mit zwei UV im 3D-Raum.

:::



```{r}
#| fig-cap: 2D-Diagramm f√ºr 3D-Modell
#| echo: false
#| out-width: 75%
#| label: fig-3d-regr-2d
lm3d_expect <- estimate_relation(lm3d)
plot(lm3d_expect)
```

:::::


```{r}
#| echo: false
data(mariokart, package = "openintro")
```

Grunds√§tzlich kann man viele UV in ein (lineares) Modell aufnehmen.
Betrachten wir z.$\,$B. folgendes lineares Modell mit zwei metrischen UV.

```{r}
lm_mario_2uv <- lm(total_pr ~ start_pr + ship_pr, 
                   data = mariokart %>% filter(total_pr < 100))
```

<!-- , s. auch @fig-mario-2uv. -->

::: {.content-visible when-format="html" unless-fromat="epub"}


<!-- @fig-mario-2uv-dyn visualisiert das Modell `lm_mario2v` in einem 3D-Diagramm. -->


```{r}
#| include: false
lm_coefs <- coef(lm_mario_2uv)

mariokart_no_extreme <- 
  mariokart |> 
  filter(total_pr < 100)

start_seq <- seq(0, 70, by = 1)
ship_seq <- seq(0, 10, by = 1)

Verkaufspreis <- t(outer(start_seq, ship_seq,
            function(x,y) {lm_coefs[1] + lm_coefs[2]*x + lm_coefs[3]*y}))
```




Jedes der beiden Regressionsgewichte in `lm_mario_2uv` entspricht der Steigung in der beiden Achsen in @fig-mario-2uv-dyn,
d.$\,$h. die Steigung f√ºr `start_pr` bzw. die Steigung f√ºr `ship_pr`.

:::



:::: {.content-visible when-format="pdf"}

@fig-3d-regr-statisch visualisiert das Modell `lm_mario2v` in einem 3D-Diagramm (betrachtet aus verschiedenen Winkeln).



::: {#fig-3d-regr-statisch layout-ncol=3}


![Winkel 1](img/3d_scatter_mario1.png)

![Winkel 2](img/3d_scatter_mario2.png)


![Winkel 3](img/3d_scatter_mario3.png)

Das Modell `lm_mario2v` mit 2 metrischen UV (und 1 metrische AV) als 3D-Diagramm

:::
::::


### Viele UV ins Modell?

Wir k√∂nnten im Prinzip alle Variablen unserer Datentabelle 
als UV in das Regressionsmodell aufnehmen.
Die Frage ist nur: Macht das Sinn?
Hier sind einige Richtlinien, die helfen, welche Variablen (und wie viele) 
man als UV in ein Modell aufnehmen sollte [@gelman_regression_2021;. S. 199],
wenn das Ziel eine m√∂glichst hohe Modellg√ºte ist:

1. Man sollte alle Variablen aufnehmen, von denen anzunehmen ist, dass Sie Ursachen f√ºr die Zielvariablen sind.
2. Bei UV mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen.
3. UV, die vergleichsweise exakt gesch√§tzt werden (der Bereich `95 CI` ist klein), sollten tendenziell im Modell belassen werden, da sie die Modellg√ºte verbessern.

Ist das Ziel hingegen, eine Theorie bzw. ein wissenschaftliches Modell zu √ºberpr√ºfen,
so sollte man genau die UV in das Modell aufnehmen,
die die Theorie verlangt.




## Fallbeispiel zur Prognose


:::{#exm-prognose}
### Prognose des Verkaufspreis
Ganz k√∂nnen Sie von Business-Welt und ihren Gratifikationen nicht lassen, 
trotz Ihrer wissenschaftlichen Ambitionen.
Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen m√∂glichst exakt vorherzusagen. 
Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld. $\square$
:::

### Modell "all-in"

Um die G√ºte Ihrer Vorhersagen zu pr√ºfen, teilt Ihre Chefin den Datensatz in zwei zuf√§llige Teile.


>    [üë©‚Äçüíº]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"} Ich teile den Datensatz `mariokart` zuf√§llig in zwei Teile.
Den ersten Teil kannst du nutzehn, um Modelle zu berechnen ("trainieren") und ihre G√ºte zu pr√ºfen. Den Teil nenne ich "Train-Sample", h√∂rt sich cool an, oder? 
Im Train-Sample ist ein Anteil (`frac`tion) von 70% der Daten, okay? 
Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, 
kommst du und wir berechnen die G√ºte deiner Vorhersagen in dem verbleibenden Teil, die √ºbrigen 30% der Daten. 
Diesen Teil nennen wir Test-Sample, alles klar?


```{r mariokart-train-test}
#| echo: false
#| eval: false
# library(readr)
#write_csv(mariokart_train, "data/mariokart_train.csv")
#write_csv(mariokart_test, "data/mariokart_test.csv")
```

Wenn die Daten in Ihrem Computer zu finden sind, z.$\,$B. im Unterordner `data`,
dann k√∂nnen Sie sie von dort importieren:

```{r}
#| eval: false
mariokart_train <- read.csv("data/mariokart_train.csv")
```

Alternativ k√∂nnen Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:

::: {.content-visible when-format="html"}

```{r}
mariokart_train <- read.csv("https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_train.csv")
```

Dann importieren wir auf gleiche Weise Test-Sample in R:

```{r}
mariokart_test <- read.csv("https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_test.csv")
```

:::


::: {.content-visible when-format="pdf"}

```{r import-mariokart-train-pdf}
mariokart_train_path <- paste0( "https://raw.githubusercontent.com/sebastiansauer/",
"statistik1/main/data/mariokart_train.csv")

mariokart_train <- read.csv(mariokart_train_path)
```

Dann importieren wir auf gleiche Weise Test-Sample in R:

```{r import-mariokart-test-pdf}
mariokart_test_path <- paste0(
 "https://raw.githubusercontent.com/sebastiansauer/",
 "statistik1/main/data/mariokart_test.csv")

mariokart_test <- read.csv(mariokart_test_path)
```

:::


Also los. Sie probieren mal die "All-in-Strategie": 
Alle Variablen rein in das Modell.
Viel hilft viel, oder nicht?


```{r lm-all-in}
lm_allin <- lm(total_pr ~ ., data = mariokart_train)
r2(lm_allin)  # aus easystats
```


Der Punkt in `total_pr ~ . ` hei√üt "alle Variablen in der Tabelle (au√üer `total_pr`)".



>    [üë©‚Äçüíº]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"} Hey! Das ist ja fast perfekte Modellg√ºte!

>    [ü¶π‚Äç‚ôÄÔ∏è]{.content-visible when-format="html"}[\emoji{woman-supervillain}]{.content-visible when-format="pdf"}Ô∏è Vorsicht: Wenn ein Angebot aussieht wie "too good to be true", dann ist es meist auch too good to be true.






Der Grund f√ºr den fast perfekten Modellfit ist die Spalte `Title`.
Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt.
Wei√ü man, welcher Titel zu welcher Auktion geh√∂rt, 
kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen.
Leider n√ºtzen die Titel der Auktionen im Train-Sample *nichts* f√ºr andere Auktionen.
Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein,
wenn wir uns auf die Titel der Auktionen im Test-Sample st√ºtzen.
Merke: H√∂chst idiografische Informationen wie Namen, 
Titel etc. sind nicht n√ºtzlich,
um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen. $\square$




Probieren wir also die Vorhersage im Test-Sample:

```{r lm-allin-predict-error}
#| error: true
predict(lm_allin, newdata = mariokart_test)
```



Oh nein! Was ist los!? Eine Fehlermeldung!


Nominalskalierte UV mit vielen Auspr√§gungen, wie `title` sind problematisch.
Kommt eine Auspr√§gung von `title` im Test-Sample vor,
die es *nicht* im Train-Sample gab, so resultiert ein Fehler beim `predict`en.
H√§ufig ist es ohnehin sinnvoll, auf diese Variable zu verzichten,
da diese Variablen oft zu Overfitting f√ºhren. 


### Modell "all-in", ohne Titelspalte

Okay, also auf die Titelspalte sollten wir vielleicht besser verzichten.
N√§chster Versuch.

```{r mariokart-train2}
mariokart_train2 <-
  mariokart_train %>% 
  select(-c(title, id))

lm_allin_no_title_no_id <- lm(total_pr ~ ., data = mariokart_train2)
r2(lm_allin_no_title_no_id) 
```



Das R-Quadrat ist durchaus ordentlich.


>    [ü§ñ]{.content-visible when-format="html"}[\emoji{robot}]{.content-visible when-format="pdf"} Das haben wir gut gemacht!


```{r performance-lm-allin-no-title}
performance::rmse(lm_allin_no_title_no_id)
```


<!-- :::{.callout-caution} -->
<!-- ### Name Clash -->
<!-- Im Paket `yardstick` gibt es eine Funktion namens `rmse` und im Paket `performance`, Teil des Meta-Pakets `easystats` ebenfalls. -->
<!-- Da sind Probleme vorprogrammiert. -->
<!-- Das ist so als w√ºrde die Lehrerin rufen: "Schorsch, komm her!".  -->
<!-- Dabei gibt es zwei Schorsche in der Klasse: Den M√ºllers Schorsch und den Meiers Schorsch. -->
<!-- Sonst kommen beide, was die Lehrerin nicht will. -->
<!-- Die Lehrerin m√ºsste also rufen: "M√ºller Schorsch, komm her!". -->
<!-- Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den "Nachnamen" des Befehls: -->
<!-- `paketname::funktion` ist wie `M√ºller::Schorsch`.  -->
<!-- In unserem Fall also: `performance::rmse` -->
<!-- Endlich wei√ü R wieder, was zu tun ist!$\square$ -->
<!-- ::: -->


Sie rennen zu Ihrer Chefin, die jetzt die G√ºte Ihrer Vorhersagen in den *restlichen* Daten bestimmen soll.

>    [üë©‚Äçüíº]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"} Da wir dein Modell in diesem Teil des Komplett-Datensatzes *testen*, nennen wir diesen Teil das "Test-Sample".



Ihre Chefin schaut sich die Verkaufspreise im Test-Sample an:

```{r}
mariokart_test %>% 
  select(id, total_pr) %>% 
  head()
```

>    [üë©‚Äçüíº]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"}Ô∏è Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!

Berechnen wir die Vorhersagen (engl. predictions; to predict: vorhersagen):

```{r}
lm_allin_predictions <- predict(lm_allin_no_title_no_id, newdata = mariokart_test)
```


Hier sind die ersten paar Vorhersagen:

```{r}
head(lm_allin_predictions)
```

Diese Vorhersagen f√ºgen wir noch der Ordnung halber in die Tabelle 
mit den Test-Daten ein:

```{r}
mariokart_test <-
  mariokart_test %>% 
  mutate(lm_allin_predictions = predict(lm_allin_no_title_no_id, 
newdata = mariokart_test))
```


[üë¥]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"}Ô∏è Okay, was ist jetzt der mittlere Vorhersagefehler?




Um die Vorhersageg√ºte im Test-Sample auszurechnen (wir verwenden dazu die Funktionen `mae` und `rsq`, 
nutzen wir die Funktionen des R-Paketes `yardstick` (welches Sie vielleicht noch installieren m√ºssen):
 
```{r}
#| eval: false
library(yardstick)

yardstick::mae(data = mariokart_test,
               truth = total_pr,  # echter Verkaufspreis
               estimate = lm_allin_predictions)  # Ihre Vorhersage
yardstick::rmse(data = mariokart_test,
               truth = total_pr,  # echter Verkaufspreis
               estimate = lm_allin_predictions)  # Ihre Vorhersage
```

```{r mae-rmse-lm-all-n}
#| echo: false
library(yardstick)

yardstick::mae(data = mariokart_test,
               truth = total_pr,  # echter Verkaufspreis
               estimate = lm_allin_predictions) |>  # Ihre Vorhersage
  knitr::kable()
yardstick::rmse(data = mariokart_test,
               truth = total_pr,  # echter Verkaufspreis
               estimate = lm_allin_predictions)  |>  # Ihre Vorhersage
  knitr::kable()
```


Ihr mittlerer Vorhersagefehler (RMSE) liegt bei ca. 13 Euro. √úbrigens haben wir hier `yardstick::rmse geschrieben und nicht nur `rmse()`, 
da es sowohl im Paket `performance` ( Teil des Metapakets `easystats`) als auch im Paket `yardstick` (Teil des Metapakets `tidymodels`) 
einen Befehl des Namens `rmse` gibt. Name-Clash-Alarm! 
R k√∂nnte daher den anderen `rmse` meinen als Sie, 
was garantiert zu Verwirrung f√ºhrt. (Entweder bei R oder bei Ihnen.)

>    [üë©‚Äçüíº]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"} Ganz okay.

Wie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?


```{r}
#| eval: false
# `rsq ` ist auch aus dem Paket yardstick:
rsq(data = mariokart_test,
    truth = total_pr,  # echter Verkaufspreis
    estimate = lm_allin_predictions)  # Ihre Vorhersage
```


```{r rsq-lm-all-in-preds}
#| echo: false
# `rsq ` ist auch aus dem Paket yardstick:
rsq(data = mariokart_test,
    truth = total_pr,  # echter Verkaufspreis
    estimate = lm_allin_predictions)  |>   # Ihre Vorhersage 
knitr::kable()
```




>    [üë¥]{.content-visible when-format="html"}[\emoji{old-man}]{.content-visible when-format="pdf"}Ô∏è 17%, nicht berauschend, aber immerhin!



Wie das Beispiel zeigt, ist die Modellg√ºte im Test-Sample (leider) oft *geringer* als im Train-Sample. 
Die Modellg√ºte im Train-Sample ist mitunter √ºberm√§√üig optimistisch.
Dieses Ph√§nomen bezeichnet man als *Overfitting* [@gelman2021].
Bevor man Vorhersagen eines Modells bei der Chefin einreicht, 
bietet es sich, die Modellg√ºte in einem neuen Datensatz, 
also einem Test-Sample, zu √ºberpr√ºfen. 

Wir haben hier die Funktion `rsq` aus dem Paket `yardstick` verwendet,
da `r2` nur die Modellg√ºte im Train-Sample ausrechnen kann.
`rsq` kann die Modellg√ºte f√ºr beliebige Vorhersagewerte berechen, 
also sowohl aus dem Train- oder dem Test-Sample.


## Vertiefung: Das Aufteilen Ihrer Daten

### Analyse- und Assessment-Sample

Wenn Sie eine robuste Sch√§tzung der G√ºte Ihres Modells erhalten m√∂chten,
bietet sich folgendes Vorgehen an (vgl. @fig-sample-types):


1. Teilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.
2. Berechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem *Validation-Sample*).
3. Pr√ºfen Sie die Modellg√ºte im zweiten Teil Ihres Datensatzes (dem  *Assessment-Sample*)

<!-- Das ist ein Hauf von "Samples".  -->
<!-- Zur Verdeutlichung zeigt @fig-samples Ihnen noch mal die Unterteilung dieser Stichproben-Arten. -->





Diese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch *Validierungsaufteilung* (validation split); Sie k√∂nnen sie z.$\,$B. so bewerkstelligen:


```{r}
library(rsample)  # ggf. noch installieren
mariokart <- read_csv("data/mariokart.csv")  # Wenn die CSV-Datei in einem Unterordner mit Namen "data" liegt


meine_aufteilung <- initial_split(mariokart, strata = total_pr)
```



```{r}
#| echo: false
set.seed(42)
meine_aufteilung <- initial_split(mariokart, strata = total_pr)
```


`initial_split` w√§hlt f√ºr jede Zeile (Beobachtung) zuf√§llig aus, 
ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll.
Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt;^[vgl. `help(initial_split)`]
das ist eine sinnvolle Aufteilung.
Das Argument `strata` sorgt daf√ºr, dass die Verteilung der AV in beiden Stichproben gleich ist.
Es w√§re n√§mlich bl√∂d f√ºr Ihr Modell, wenn im Train-Sample z.$\,$B. nur die teuren, und im Test-Sample nur die g√ºnstigen Spiele landen w√ºrde. Anderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B.
In so einem Fall w√ºrde sich Ihr Modell unn√∂tig schwer tun.
Im n√§chsten Schritt k√∂nnen Sie anhand anhand der von `initial_split` bestimmten Aufteilung die Daten tats√§chlich aufteilen. `initial_split` sagt nur, welche Zeile in welche der beiden Stichproben kommen *soll*. Die eigentliche Aufteilung wird aber noch nicht durchgef√ºhrt.


```{r}
mariokart_train <- 
  training(meine_aufteilung)  # Analyse-Sample
mariokart_test <- 
  testing(meine_aufteilung)  # Assessment-Sample
```

`training` w√§hlt die Zeilen aus, die in das Train-Sample ihres Train-Samples, d.h. Ihr Analyse-Sample, kommen sollen.
`testing`  w√§hlt die Zeilen aus, die in das Test-Sample ihres Train-Samples, d.h. Ihr Assessment-Sample, kommen sollen.

Ich pers√∂nliche nenne die Tabelle mit den Daten gerne `d_analysis` bzw. `d_assess`,
das ist k√ºrzer zu tippen und einheitlich.
Sie k√∂nnen aber auch ein eigenes Namens-Schema nutzen;
was aber hilfreich ist, ist Konsistenz in der Benamung,
au√üerdem K√ºrze und aussagekr√§ftige Namen.

### Train- vs. Test-Sample



Das Train-Sample stellt die bekannten Daten dar; aus denen k√∂nnen wir lernen, 
d.$\,$h. unser Modell berechnen.
Das Test-Sample  stellt das Problem der wirklichen Welt dar: 
Neue Beobachtungen, von denen man (noch) nicht wei√ü, was der Wert der AV ist.
Der Zusammenhang dieser verschiedenen, 
aber zusammengeh√∂rigen Arten von Stichproben ist in @fig-sample-types dargestellt.


:::{#def-trainsample}
### Train-Sample
Den Datensatz, f√ºr die Sie sowohl UV *als auch AV* vorliegen haben, nennt man Train-Sample. $\square$
:::

:::{#def-testsample}
### Test-Sample
Den Datensatz, f√ºr den Sie *nur* Daten der UV, aber nicht zu der AV vorliegen haben, nennt man *Test-Sample*. $\square$
:::


```{mermaid}
%%| label: fig-sample-types
%%| fig-cap: Verschiedene Arten von zusammengeh√∂rigen Stichprobenarten im Rahmen einer Prognosemodellierung
%%| fig-height: 2


flowchart TD
  S[Samples] 
  TS[Train-Sample]
  TT[Test-Sample]
  AS[Analyse-Sample]
  AssS[Assessment-Sample]

  S-->TT
  S-->TS
  TS-->AS
  TS-->AssS
  
```




## Praxisbezug

Ein Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden "abwanderungsgef√§hrdet" sind, 
also vielleicht in Zukunft bald nicht mehr unsere Kunden sind ("customer churn").
Es gibt eine ganze Reihe von Untersuchungen dazu, 
z.$\,$B. die von @lalwani2022.
Das Forschungsteam versuchen anhand von Daten und u.$\,$a. auch der linearen Regression vorherzusagen, 
welche Kunden abgewandert sein werden. 
Die Autoren berichten von einer Genauigkeit von √ºber 80$\,$% im (besten) Vorhersagemodell.


## Wie man mit Statistik l√ºgt

### Pinguine drehen auf

Ein Forscher-Team untersucht Pinguine von der [Palmer Station, Antarktis](https://pallter.marine.rutgers.edu/). 
Das Team ist am Zusammenhang von Schnabell√§nge (*bill length*) 
und Schnabeltiefe (*bill depth*) interessiert, s. @fig-peng-bill.


![Schnabell√§nge und Schnabeltiefe; @horst_statistics_2024](https://allisonhorst.github.io/palmerpenguins/reference/figures/culmen_depth.png){#fig-peng-bill width="50%"}

Das Team hat in ~~schwei√ütreibender~~ eiszapfentreibender Arbeit $n=344$ Tiere
vermessen bei antarktischen Temperaturen. Hier sind die Daten:

::: {.content-visible when-format="html"}

```{r}
penguins <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv")
```
:::


::: {.content-visible when-format="pdf"}

```{r}
penguins_path <- paste0(
  "https://vincentarelbundock.github.io/",
  "Rdatasets/csv/palmerpenguins/penguins.csv")

penguins <- read.csv(penguins_path)
```
:::




### Analyse 1: Gesamtdaten

Man untersucht, rechnet und √ºberlegt. Ah! Jetzt haben wir es!
Klarer Fall: Ein *negativer* Zusammenhang von Schnabell√§nge und Schnabeltiefe, 
s. @fig-peng-simpson1. 
Das ist bestimmt einen Nobelpreis wert  Schnell publizieren!

```{r}
#| label: fig-peng-simpson1
#| out-width: 75%
#| fig-cap: "Negativer Zusammenhang von Schanbell√§nge und Schnabeltiefe"
ggscatter(penguins, x = "bill_length_mm", y = "bill_depth_mm", 
          add = "reg.line")  # aus `ggpubr`
```

Hier sind die statistischen Details, s. @tbl-peng-simpson1.

```{r}
lm_ping1 <- lm(bill_depth_mm ~ bill_length_mm, data = penguins)
```

```{r}
#| echo: false
#| label: tbl-peng-simpson1
#| out-width: 75%
#| tbl-cap: "Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm"
parameters(lm_ping1) |> select(Parameter, Coefficient)
```



### Analyse 2: Aufteilung in Arten (Gruppen)

Kurz darauf ver√∂ffentlicht eine andere Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. 
Aber mit *gegenteiligem* Ergebnis: 
Bei *jeder Rasse* von (untersuchten) Pinguinen gilt: 
Es gibt einen *positiven* Zusammenhang von Schnabelll√§nge und Schnabeltiefe, s. @fig-penguins-groups.

```{r}
#| fig-cap: "Der Zusammenhang von Schnabelll√§nge und Schnabeltiefe pro Gruppe von Pinguinen: Die Regressionsgruppe pro Gruppe steigt. Hingegen sinkt die Regressionsgerade ohne Beachtung der Gruppen (schwarze gestrichelte Linie)"
#| label: fig-penguins-groups
#| out-width: 75% 
#| echo: false
ggscatter(penguins, x = "bill_length_mm", y = "bill_depth_mm", 
          add = "reg.line", color = "species") +
          geom_abline(slope = coef(lm_ping1)[2], 
          intercept = coef(lm_ping1)[1],
          size = 2,
          linetype = "dashed")
```


Oh nein! Was ist hier nur los? 
Daten l√ºgen nicht?! Oder doch?!


Hier sind die statistischen Details der zweiten Analyse, s. @tbl-peng-simpson2. 
Im zweiten Modell (`lm2`) kam `species` als zweite UV 
neu ins Modell (zus√§tzlich zur Schnabell√§nge).

```{r}
lm_ping2 <- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)
```

```{r}
#| echo: false
#| label: tbl-peng-simpson2
#| tbl-cap: "Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm"
parameters(lm_ping2) |> select(Parameter, Coefficient)
```




Ohne Hintergrundwissen oder ohne weitere Analysen kann *nicht* entschieden werden,
welche Analyse -- Gesamtdaten oder Subgruppen -- die richtige ist.
Nicht-exprimentelle Studien k√∂nnen zu grundverschiedenen Ergebnissen f√ºhren,
je nachdem, ob weitere UV dem Modell hinzugef√ºgt oder weggenommen werden. 




### Vorsicht bei der Interpretation von Regressionskoeffizienten

:::{.callout-important}
Interpretiere  Modellkoeffizienten nur kausal, wenn du ein Kausalmodell hast. $\square$
:::

Nur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt,
macht es Sinn, die Modellkoeffizienten kausal zu interpretieren.
Andernfalls l√§sst man besser die Finger von der Interpretation der Modellkoeffizienten und
begn√ºgt sich mit der Beschreibung der Modellg√ºte und mit Vorhersage (synonym: Prognose).
Wer das nicht glaubt, der betrachte @fig-confounder, links.
Ein Forscher stellt das Modell `m1: y ~ x` auf und  interpretiert dann `b1`: 
"Ist ja klar, X hat einen starken positiven Effekt auf Y!".

In der n√§chsten Studie nimmt der Forscher dann eine zweite Variable, 
`group` (z.$\,$B. Geschlecht) in das Modell auf: `m2: y ~ x + g`.
Oh Schreck! Jetzt ist `b1` auf einmal nicht mehr stark positiv, 
sondern praktisch Null, und zwar in jeder Gruppe, s. @fig-confounder, rechts!

Dieses Umschwenken der Regressionskoeffizienten kann *nicht* passieren,
wenn der Effekt "echt", also kausal, ist. 
Handelt es sich aber um "nicht echte", also nicht-kausale Zusammenh√§nge, 
um *Scheinzusammenh√§nge* also.
So k√∂nnen sich die Modellkoeffizienten dramatisch ver√§ndern 
(sogar das Vorzeichen kann wechseln; das nennt man dann *Simpsons Paradox* [@gelman2021]),
wenn man das Modell ver√§ndert, also Variablen hinzuf√ºgt oder aus dem Modell entfernt.

Wenn man die kausalen Abh√§ngigkeiten nicht kennt,
wei√ü man also nicht, ob die Zusammenh√§nge kausal oder nicht-kausal sind.
Man wei√ü also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.

```{r}
#| echo: false
#| label: fig-confounder
#| fig-asp: 0.8
#| fig-cap: "F√ºgt man in ein Modell eine Variable hinzu, k√∂nnen sich die Koeffizienten massiv √§ndern. In beiden Diagrammen wurden die gleichen Daten verwendet. (a): starker positiver Zusammenhang, (b) kein Zusammenhang in beiden Gruppen"
#| layout: [[45,-10, 45], [100]]
#| out-width: 100%
#| fig-subcap: 
#|   - "Modell: `y ~ x`, starker positiver Zusammenhang"
#|   - "Modell: `y ~ x + g`, kein Zusammenhang in beiden Gruppe"

n <- 100

set.seed(42)

d_sim <-
  tibble(
    x = rnorm(n, 0, 0.5),
    y = rnorm(n, 0, 0.5),
    group = "A"
  ) %>%
  bind_rows(
    tibble(
      x = rnorm(n, 1, 0.5),
      y = rnorm(n, 1, 0.5),
      group = "B")
  )

p_super_korr <- 
d_sim %>%
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = modelcol) +
  labs(title = "Oh yeah,",
       subtitle = "super Korrelation!") +
  theme_minimal() +
  theme(plot.title = element_text(size = 12)) +
  theme_large_text()

p_super_korr



d_sim %>%
  ggplot(aes(x = x, y = y, color = group, shape = group)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Oh nein",
       subtitle = "keine Korrelation!") +
  theme(legend.position = "bottom") +
  theme_minimal() +
  scale_color_okabeito() +
  theme(
    legend.position = c(0.97, 0.05),  # Adjust these values to position the legend
    legend.justification = c(1, 0)) +
  theme(plot.title = element_text(size = 12)) +
  theme_large_text()
```


Man k√∂nnte h√∂chstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur *deskriptiv* interpretiert,
z.$\,$B. "Dort wo es viele St√∂rche gibt, gibt es auch viele Babys" [@matthews2000].^[Das St√∂rche-Babys-Beispiel passt auch zu @fig-confounder.]
Leider ist unser Gehirn auf kausale Zusammenh√§nge gepr√§gt: 
Es f√§llt uns schwer, Zusammenh√§nge nicht kausal zu interpretieren.
Daher werden deskriptive Befunde immer wieder unzul√§ssig kausal interpretiert -- von Laien und Wissenschaftlern ebenfalls.



## Was war noch mal das Erfolgsgeheimnis?





Wenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. @fig-dranbleiben. 


:::{#fig-dranbleiben layout-ncol=2}

![Sie gestern](img/meme-stat1.jpg){#fig-gestern}

![Sie morgen](img/meme-stat2.jpg){#fig-morgen}

Statistik, Sie und Party: Gestern und (vielleicht) morgen. 
Wenn Sie dran bleiben, wird die Statistik Ihre beste Freundin [@imgflip2024].

:::


::: {.content-visible when-format="html" unless-format="epub"}

## Fallstudien

Die folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) 
beispielhalft zwei ausf√ºhrlichere Entwicklungen eines Prognosemodells.

Nutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.

### New Yorker Flugversp√§tungen 2023



{{< video https://youtu.be/4hM6Z-yrduw >}}

[Source](https://aistudios.com/share/64eef3e7d6644f00142d7285)



[Vorhersage von Flugversp√§tungen](https://sebastiansauer.github.io/Datenwerk/posts/flights-delay-simplified//)


### Filmerl√∂se


[Vorhersagen von Filmerl√∂sen](https://data-se.netlify.app/2020/11/13/fallstudie-zur-regressionsanalyse-ggplot2movies/)

## Vertiefung


[Allison Horst](https://allisonhorst.com/linear-regression-dragons) erkl√§rt die lineare Regression mit Hilfe von Drachen. 
[üêâ]{.content-visible when-format="html"} Sehenswert.


:::

## Aufgaben

Die Webseite [datenwerk.netlify.app](https://datenwerk.netlify.app) stellt eine Reihe von einschl√§gigen √úbungsaufgaben bereit. 
Sie k√∂nnen die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:


- [interpret-koeff-lm](https://sebastiansauer.github.io/Datenwerk/posts/interpret-koeff-lm/interpret-koeff-lm.html) 
- [Aussagen-einfache-Regr](https://sebastiansauer.github.io/Datenwerk/posts/aussagen-einfache-regr/aussagen-einfache-regr)
- [interpret-koeff](https://sebastiansauer.github.io/Datenwerk/posts/interpret-koeff/interpret-koeff.html)
- [regression1b](https://sebastiansauer.github.io/Datenwerk/posts/regression1b/regression1b.html)
- [mtcars-regr01](https://sebastiansauer.github.io/Datenwerk/posts/mtcars-regr01/mtcars-regr01.html)
- [regression1a](https://sebastiansauer.github.io/Datenwerk/posts/regression1a/regression1a.html)
- [lm1](https://sebastiansauer.github.io/Datenwerk/posts/lm1/lm1.html)
- [Regression5](https://sebastiansauer.github.io/Datenwerk/posts/regression5/regression5)
- [Regression6](https://sebastiansauer.github.io/Datenwerk/posts/regression6/regression6)
- [lm-mario1](https://sebastiansauer.github.io/Datenwerk/posts/lm-mario1/lm-mario1.html)
- [lm-mario2](https://sebastiansauer.github.io/Datenwerk/posts/lm-mario2/lm-mario2.html)
- [lm-mario3](https://sebastiansauer.github.io/Datenwerk/posts/lm-mario3/lm-mario3.html)
- [ausreisser1](https://sebastiansauer.github.io/Datenwerk/posts/ausreisser1/ausreisser1.html)
- [mario-compare-models](https://sebastiansauer.github.io/Datenwerk/posts/mario-compare-models/)

## Literaturhinweise

Ein empfehlenswertes Buch f√ºr Regressionsanalyse ist das Buch von Andrew Gelman zum Thema "Regression und andere Geschichten" [@gelman_regression_2021].
Sein Buch ist f√ºr Sozialwissenschaftler geschrieben, 
also nicht f√ºr typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel.
Eine Alternative bietet @sauer_moderne_2019.




