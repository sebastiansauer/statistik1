[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lernhilfen",
    "section": "",
    "text": "1 Hinweise\nGuter Fit"
  },
  {
    "objectID": "index.html#es-geht-um-ihren-lernerfolg",
    "href": "index.html#es-geht-um-ihren-lernerfolg",
    "title": "Lernhilfen",
    "section": "\n1.1 Es geht um Ihren Lernerfolg",
    "text": "1.1 Es geht um Ihren Lernerfolg\nMeister Yoda rät: Lesen Sie die Hinweise (Abbildung 1.1).\n\n\nAbbildung 1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\nQuelle: Imgflip Memengenerator\n\n1.1.1 Lernziele\n\nDie Studentis sind mit wesentlichen Methoden der explorativen Datenanalyse vertraut und können diese selbständig anwenden.\nDie Studentis können gängige Forschungsfragen in lineare Modelle übersetzen, diese auf echte Datensätze anwenden und die Ergebnisse interpretieren.\n\nKurz gesagt: Das ist ein Grundkurs in Daten zähmen.\n\n\nDaten zähmen\n\nBildquelle: Allison Horst, CC-BY\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nWas lerne ich hier?\nSie lernen die Grundlagen der Datenanalyse mit einem Schwerpunkt auf Vorhersage. Anders gesagt: Sie lernen wie man aus Daten Vorhersagen ableitet. Zum Beispiel: Kommt ein Student zu Ihnen und sagt “Ich habe 42 Stunden für die Klausur gelernt, welche Note kann ich in der Klausur erwarten?”. Darauf Ihre Antwort: “Auf Basis meiner Daten und meines Modells müsstest du eine 2.7 schreiben!”.1. Außerdem lernen Sie, wie man die Güte einer Vorhersage auf Stichhaltigkeit prüft. Denn Vorhersagen kann man ja in jeder Eckkneipe oder beim Wahrsager bekommen. Wir wollen aber belastbare Vorhersagen und zumindest wissen, wie gut die Vorhersagen (von jemanden) bisher waren.\nWarum ist das wichtig?\nWir wollen nicht auf Leuten vertrauen, die behaupten, sie wüssten, was für uns richtig und gut ist. Wir wollen selber die Fakten prüfen können.\nWozu brauche ich das im Job?\nDatenanalyse spielt bereits heute in vielen Berufen eine Rolle. Tendenz stark zunehmend.\nWozu brauche ich das im weiterem Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es üblich, statistische Ergebnisse hinsichtlich quantitativ zu analysieren.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas Forum (2020) berichtet zu den “Top 20 job roles in increasing and decreasing demand across industries” (S. 30, Abb. 22):\n\nData Analysts und Scientists\nAI and Machine Learning Specialists\nBig Data Specialists\n\n1.1.3 Motivieren Sie mich!\nAnsprache zur Motivation\n\n1.1.4 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie Folgendes mitbringen:\n\nBereitschaft, Neues zu lernen\nBereitschaft, nicht gleich aufzugeben\nKenntnis grundlegender Methoden wissenschaftlichen Arbeitens\n\nWas Sie nicht brauchen, sind besondere Mathe-Vorkenntnisse.\n\n1.1.5 Überblick\nAbb. Abbildung 1.2 gibt einen Überblick über den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Modellieren]\n      direction TB\n      M1[Verbildlichen] --&gt; Vis[Punktmodelle]\n      Vis --&gt; U[Modellguete]\n      U --&gt; G[Geradenmodelle]\n    end\n    subgraph N[Nachbereiten]\n      direction TB\n      D[Diskutieren]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\nAbbildung 1.2: Überblick über den Inhalt und Verlauf des Buches\n\n\n\nDas Diagramm zeigt den Ablauf einer typischen Datenanalyse. Natürlich kann man sich auch andere sinnvolle Darstellungen dieses Ablaufs vorstellen.\n\n1.1.6 Modulzeitplan\n\n\n\n\n\n\n\n\n\n\n\n\n\nNr\n      Thema\n      Datum\n      Kommentar\n    \n\n\n1\nRahmen\n13.3. - 19.3.\nLehrbeginn ist am Mi., 15.3.23\n\n\n2\nDaten einlesen\n20.3. - 26.3.\nNA\n\n\n3\nDaten umformen\n27.3. - 2.4.\nNA\n\n\n4\nDaten verbildlichen\n3.4. - 9.4\nKarwoche (kein Unterricht am Do. und Fr.)\n\n\n5\nDaten verbildlichen\n10.4. - 16.4.\nOsterwoche (kein Unterricht am Mo. und Di.)\n\n\n6\nPunktmodelle 1\n17.4. - 23.4.\nNA\n\n\n7\nModellgüte\n24.4. - 30.4.\nNA\n\n\n8\nFallstudien\n1.5. - 7.5.\nMaifeiertag (kein Unterricht am Mo.)\n\n\n9\nPunktmodelle 2\n8.5. - 14.5.\nNA\n\n\n10\nGeradenmodelle 1\n15.5. - 21.5.\nNA\n\n\n11\n-\n22.5. - 28.5.\nBlockwocke - kein regulärer Unterricht\n\n\n12\nGeradenmodelle 1\n29.6. - 4.6.\nPfingstwoche (kein Unterricht am Mo. und Di.)\n\n\n13\nAufholwoche\n5.6. - 11.6.\nFronleichnam (kein Unterricht am Do. und Fr.)\n\n\n14\nGeradenmodelle 2\n12.6. - 18.6.\nNA\n\n\n15\nGeradenmodelle 2\n19.6. - 25.6.\nNA\n\n\n16\nAbschluss\n26.6. - 2.7.\nLetzter Lehrtag ist Fr., 30.6.\n\n\n\n\n\n\n\n1.1.7 PDF-Version\nSie können die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen."
  },
  {
    "objectID": "index.html#lernhilfen",
    "href": "index.html#lernhilfen",
    "title": "Lernhilfen",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\n\n1.2.1 PDF-Version\nUm eine PDF-Version eines Kapitels zu erhalten, können Sie im Browser die Druckfunktion nutzen (Strg-P). Wählen Sie dort “PDF” als Ziel.\n\n1.2.2 Videos\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buchs. Besonders diese Playlist passt zu den Inhalten dieses Buchs.\n\n1.2.3 Software allgemein\nInstallieren Sie R und seine Freunde.\nInstallieren Sie bitte auch die folgende R-Pakete2:\n\ntidyverse\neasystats\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\nRStudio-Cloud-Project\n\n\n\nWenn Ihnen die Lehrkraft ein RStudio-Cloud-Projekt zur Verfügung stellt, nutzen Sie es. Dort sind alle R-Pakete, Datensätze und Syntax-Vorlagen schon bereit gestellt. Sie sparen sich also eine Menge Installationsarbeit.\\(\\square\\)\n\n\n\n\n\n\n\n\nBei Installationsproblemen\n\n\n\n\nGibt R eine Warning aus, ist das zumeist kein Problem und kann ignoriert werden.\nStarten Sie R neu, bevor Sie R-Pakete installieren.\nWenn Sie Probleme mit der Installation auf Ihrem Computer haben, können Sie (übergangsweise oder dauerhaft) die Online-Version von RStudio, RStudio Cloud verwenden (in gewissem Umfang kostenlos).\\(\\square\\)\n\n\n\n\n\n1.2.4 Software: Bayes\nWenn in diesem Modul Inferenzstatistik nötig ist, benötigen Sie Software für Bayes-Inferenz.\nFolgendes R-Paket ist für die Bayes-Inferenz nötig:\n\nrstanarm\n\n\n1.2.5 Online-Unterstützung\nDieser Kurs kann in Präsenz und Online angeboten werden. Wenn Sie die Wahl haben, empfehle ich die Teilnahme in Präsenz, da der Lernerfolg höher ist. Online ist es meist schwieriger, sich zu konzentrieren. Aber auch online ist es möglich, den Stoff gut zu lernen, s. Abbildung 2.1.\n\n\nAbbildung 1.3: We believe in you! Image Credit: Allison Horst\n\nBitte beachten Sie, dass bei einer Teilnahme in Präsenz eine aktive Mitarbeit erwartet wird. Hingegen ist bei einer Online-Teilnahme keine/kaum aktive Mitarbeit möglich.\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\n\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\nNutzen Sie das vom Dozenten bereitgestelle Forum, um Fragen zu stellen und Fragen zu beantworten.\n\n1.2.6 Fundorte für Datensätze\nHier finden Sie Datensätze, die sich eignen, um die Analyse von Daten zu lernen:\n\nVincent Arel-Bundocks Datenseite\nDie Datenseite der University of California in Irvine (UCI)\n\n1.2.7 Aufgabensammlung\nDie Webseite Datenwerk beherbergt eine Sammlung an Übungsaufgaben rund um das Thema Datenanalyse. es gibt eine Suchfunktion (wenn Sie den Namen der Aufgabe wissen) und eine Tag-Liste, wenn Sie Aufgaben nach Themengebiet durchsehen wollen.\n\n1.2.8 Tipps zum Lernerfolg\n\n\n\n\n\n\nHinweis\n\n\n\nStetige Mitarbeit - auch und gerade außerhalb des Unterrichts - ist der Schlüssel zum Prüfungserfolg. Vermeiden Sie, das Lernen aufzuschieben. Bleiben Sie dran!\\(\\square\\)\n\n\n\n\nLerngruppe: Treten Sie einer Lerngruppe bei.\n\nTutorium: Besuchen Sie ein Tutorium, falls eines angeboten wird.\n\nVor- und Nachbereitung: Bereiten Sie den Unterricht vor und nach.\n\nSelbsttest: Testen Sie sich mit Flashcards (Karteikarten mit Vor- und Rückseite). Wenn Sie alle Aufgaben dieses Kurses aus dem FF beherrschen, sollte die Prüfung kein Problem sein.\n\nÜbungen: Bearbeiten Sie alle Übungsaufgaben gewissenhaft.\nPortal Datenwerk: Gehen Sie die Aufgaben auf dem Portal Datenwerk durch (soweit relevant).\n\nFallstudien: Schauen Sie sich meine Fallstudiensammlungen an: https://sebastiansauer-academic.netlify.app/courseware/casestudies/\n\nLehrkraft ansprechen: Sprechen Sie die Lehrkraft an, wenn Sie Fragen haben. Haben Sie keine Scheu! Bitte lesen Sie aber vorab die Hinweise, um Redundanz zu vermeiden.\n\nDabei bleiben: Vermeiden Sie “Bullimie-Lernen” (lange nix, dann alles auf einmal), sondern bevorzugen Sie “Lern-Snacks” (immer wieder ein bisschen)\n\n1.2.9 Selbstlernkontrolle\nFür jedes Kapitel sind (am Kapitelende) Aufgaben eingestellt, jeweils mit Lösung. Ein Teil dieser Aufgaben hat eine kurze, eindeutige Lösung (z.B. “42” oder “Antwort C”); ein (kleiner) Teil der Aufgaben verlangen komplexere Antworten (z.B. “Welche Arten von Prioris gibt es bei stan_glm()?). Nutzen Sie die Fragen mit eindeutiger, kurzer Lösung um sich selber zu prüfen. Nutzen Sie die Fragen mit komplexerer, längerer Lösung, um ein Themengebiet tiefer zu erarbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nFortwährendes Feedback zu Ihrem Lernfortschritt ist wichtig, damit Sie Ihre Lernbemühungen steuern können. Bearbeiten Sie daher die bereitgestellten Arbeiten ernsthaft.\\(\\square\\)\n\n\n\n1.2.10 Lernen lernen\nHier sind einige Quellen (Literatur), die Ihnen helfen sollen, das Lernen (noch besser) zu lernen:\n\nEssentielle Tipps für Bachelor-Studierende der Psychologie\nKonzentriert arbeiten: Regeln für eine Welt voller Ablenkungen\nWie man ein Buch liest\nErsti-Hilfe: 112 Tipps für Studienanfänger - erfolgreich studieren ab der ersten Vorlesung\nVon der Kürze des Lebens\nBlog “Studienscheiss”"
  },
  {
    "objectID": "index.html#didaktik",
    "href": "index.html#didaktik",
    "title": "Lernhilfen",
    "section": "\n1.3 Didaktik",
    "text": "1.3 Didaktik\n\n1.3.1 Grundlagen\n\nAlle Lehrmaterialien stelle ich vor dem Unterricht online bereit.\nAlles prüfungsrelevante Material ist verschriftlicht und die Prüfungsmodalitäten sind frühzeitig (schriftlich) bekannt gemacht.\n\nEigenstudierbarkeit: Das Modul ist auch ohne Besuchen des Unterrichts studierbar.\nWenn möglich, wird der Präsenzunterricht durch Live-Streaming ergänzt.\nFür den Stoff existiert eine Gliederung und Lernziele, so dass ein roter Faden ersichtlich ist.\nFür jede Unterrichtseinheit ist ein Stundenthema vorgegeben.\nEs werden für (möglichst) alle Unterrichtseinheiten Aufgaben bereitgestellt, so dass Lernende üben können und über den eigenen Fortschritt im Bilde sind.\nPraxisbezug wird sichergestellt, z.B. durch Fallstudien.\n\nInfos an die Studierenden eines Moduls werden durch ein Nachrichtensystem zugestellt.\nDer Unterricht ist von einer dialogischen Haltung geprägt, nicht von Frontaltunerricht.\n\n1.3.2 Lehrkonzept\nIn der “Vorlesung” wird im Schwerpunkt nicht ein Folienskript “vorgelesen”. Solcher Inhalt steht oft vorab als Video zur Verfügung (s. Links im Themenüberblick). Stattdessen steht in der “Vorlesung” die Durcharbeiten und Vertiefen des Stoffes im Vordergrund, nicht aber das Vortragen des Stoffes. Warum wird die Literatur oder das Folienskript nicht im Unterricht vorgetragen? Zum einen können Sie das alleine besser (in eigener Geschwindigkeit, mit Pausen nach Gusto, zu beliebiger Zeit und beliebigem Ort, so oft wiederholt wie Sie mögen). Zum anderen ist der Lerngewinn beim passiven Zuhören gering. Das Durchdenken, Durcharbeiten, “Durchfragen” des Stoffes ist es, was Ihnen den meisten Gewinn beschwert. Entsprechend liegt auf dem aktiven, gemeinsamen Arbeiten der Schwerpunkt. Das heißt nicht, dass es nie Vorträge vom Dozenten im Unterricht gäbe; manchmal schon. Aber aus genannten Gründen liegt der Fokus des Unterrichts im aktivierenden Arbeiten. Natürlich können im Unterricht jederzeit die Fragen der Studentis zum Stoff besprochen werden. Seien Sie ausdrücklich ermuntert, Ihre Fragen im Unterricht zu formulieren, vorzugsweise im direkten Gespräch, aber alternativ anonym (wie Frag-Jetzt). In der Übung liegt der Schwerpunkt zumeist auf dem Bearbeiten von Aufgaben.\n\n1.3.3 Lerntipps\nDamit Sie vom Unterricht maximal profitieren, ist es essenziell, dass Sie aktiv mitarbeiten. Ein “Nur-Zuhören” nimmt Ihnen einen Gutteil des Nutzens des Unterrichts. Sie lernen nur zum kleinen Teil vom Zuhören; der größte Teil des Lernerfolgs kommt vom Selber-Erarbeiten! Bitte stellen Sie Ihre Kamera (Webcam) an, wenn Sie Kommilitonis oder den Dozenten ansprechen. Das ist der Güte der Kommunikation zuträglich. Bereiten Sie den Stoff vor und arbeiten Sie ihn gewissenhaft nach. Das gemeinsame Arbeiten in einer (virtuellen) Lerngruppe ist sehr nützlich. Tauschen Sie sich im Diskussionsforum auf unserer Modulseite aus; gehen Sie in den Diskurs mit den Kommiliton/innen. Falls Sie (im Internet) nützliches Material gefunden haben, können Sie es auch in das Forum einstellen. Nutzen Sie das Diskussionsforum auch, um den Dozenten Fragen zu stellen. Meine Erfahrung zeigt mir, dass der Lernerfolg zwar auch von der Lehrperson abhängt, aber entscheidend ist der Wille eines/r Studierenden/r, selbst aktiv zu lernen. Ich glaube, dass Sie gut mit Material ausgestattet sind, um selbständig und mit Erfolg zu lernen. Anbieter wie Google stellen (teilweise) kostenfreie Angebote zum kollaborativen Arbeiten zur Verfügung (Google Docs). Behalten Sie hier den Datenschutz im Blick.\n\n1.3.4 “Einstreuer”\nIn jedem Kapitel, gibt es eine Reihe von Lehrmaterialien, sozusagen orthogonal zum Inhalt, die das Verstehen und die Umsetzung anreichernd unterstützen, das sind:\n\nPraxisbezüge\nBeispiele\nDefinitionen\nHinweise\nAchtung, Fehlerquelle\nBesonders Wichtiges\nLiteratur\nAufgaben\nLernziele\nSoftwarehinweise\nÜberblick im Lernpfad\nExkurse\nBlick in die Forschung\n\n1.3.5 “Buch 2.0”\nModernes HTML bietet eine Reihe von technischen Vorteilen, dazu gehört, dass verschiedene Medien eingebettet werden können. In diesem Buch werden folgende verwendet:\n\nText, Bilder, Tabellen - voll referenziert\nR-Syntax und Ausgabe\nAnimationen\nVideos\nGleichungen und R-Syntax-Listings - voll referenziert\nCopy-Paste-Funktion (für R-Syntax)\nCode-Fold, so dass die R-Syntax und Exkurse nur nach Aufklappen sichtbar sind (und ansonsten nicht stören)\n\n1.3.6 Barrierefrei\nAuf Lehrinhalte wird oft zugegriffen, zumindest hofft das der Autor. Gehen wir davon aus, dass ein Kurs 15 Wochen dauert, und pro Unterrichtsstunde UE Material “im Wert von 50 Folien” angesehen werden, so kommt man auf 50 Klicks oder Kontakte, mal 4 UE pro Woche ergibt 3000 Kontakte mit Material pro Studi. Bei so vielen Kontakten bekommt das Wort barrierefrei eine hohe Bedeutung.\nAus diesem Grund steht das Buch steht frei im Netz, genauso die Aufgaben und die Lösungen. Damit ist ein einfacher Zugriff möglich. Außerdem gibt es eine hohe Anzahl an URLs: Nicht nur pro Seite, sondern auch pro Abschnitt und für alle besonderen Objekte wie Tabellen und Diagramme.\n\n1.3.7 Kompetenzorientiert\nEs gibt viele Übungsaufgaben, anhand derer die Studentis ihren Lernfortschritt überprüfen können. Diese Aufgaben haben zumeist eine klare, kurze richtige Antwort (oft im MC-Format), so dass einfach eine Punktzahl ausgegeben kann für ein maximal klares Feedback an die Studentis. Außerdem gibt es aber auch Fallstudien, für komplexere und reichhaltigeres Einüben der Kompetenzen. Schließlich ist die Prüfungsform komplett kompetenzorientiert gehalten und gleichzeitig maximal objektiv durch Berechnen der Vorhersagegüte.\n\n1.3.8 Fokus auf Modellierung\nModelle stehen, auch in modernen und fortgeschrittenen Anwendungen, im Mittelpunkt der Statistik als (angewandte) Wissenschaft. Gleichzeitig sind Sie einsteigerfreundlich, denn jeder Mensch kennt Modelle aus dem alltäglichen Leben. Darüber hinaus lassen sich Modelle perfekt verbinden mit zentraler statistischer Methodik, namentlich dem Allgemeinen (Generalisierten) Linearen Modell (ALM bzw GLM). Aus diesem Grund wird das ALM als zentrale methodische Blaupause verwendet. Anstelle von einer Vielzahl statistischer Testverfahren, die letztlich aber fast immer Spezialfälle des ALM darstellen, wird hier zu zugunsten der Einfachheit, konzeptioneller Klarheit (und wissenschaftlicher Ästhetik) alles Modellieren auf dem ALM aufgebaut.\n\n1.3.9 Praxisbezug\nIn allen Kapiteln werden Themen aus der (künftigen) Berufswelt der Teilnehmis herangezogen. Ganz zu Beginn eines neuen Themas wird davon abweichend immer wieder von extrem einfachen (aber auch lebensweltlich relevanten) Beispielen Gebraucht gemacht, zu Gunsten eines einfachen Einstiegs in neue Materie. Auf mathematische Herleitung wurde aus dem gleichen Grund weitgehend verzichtet.\n\n1.3.10 Anschaulichkeit\nEs wurde versucht, möglichst viele Sachverhalte schematisch in Diagrammen zu illustieren. Damit ist bei weitem nicht nur gemeint, statische Diagramme aufzuzeichnen. Vielmehr ist versucht worden, zentrale theoretische Konzepte in einfachen Diagrammen widerzuspiegeln. Dieser eher informelle Wege nimmt zwar Einbußen an Präzision und inhaltlicher Tiefe in Kauf, öffnet aber gerade für in symbolischer Verarbeitung schwächeren Studentis einen Zugang. Darüber hinaus haben Diagramme bzw. Schemata den didaktischen Vorteil, dass sie sich hervorragend eignen für Unterricht im Hörsaal oder Seminarraum: Man betrachtet zusammen ein Bild und diskutiert darüber, das Konzept ständig vor Augen.\n\n1.3.11 Bildreichtum\nDieses Buch verwendet viele Bilder. Das hat vor allem den Grund, das Lehren zu erleichtern. Es ist dröge - beim Zuhören und beim Lehren - sich durch Textwüsten und Stichpunkt-Wälder zu kämpfen. Viel angenehmer ist es (nach meiner Erfahrung), wenn die Lehrperson anhand eines guten Diagramms den wesentlichen Punkt erläutert.\n\n1.3.12 Literatur\nPro Thema wird Literatur ausgewiesen, die den Stoff ausführlicher erläutert oder auf vertiefende Aspekte eingeht (Aspekte, die über den Stoff und die Lernziele hinausgehen). Quellen der Inhalte sind pro Kapitel im Literaturverzeichnis aufgeführt.\n\n1.3.13 Für Autodidakten geeignet\nFolien sind zu knapp, um sie ohne Erläuterung zu verstehen. Wären Sie ausführlich, würde man sie “Buch” nennen. Dieses Buch versteht sich als eine Art “Prosa-Skript”, also ausformuliertes Skript zur Begleitung des Unterrichts. Nicht zur zur Begleitung: Dieses Skript ist zwar “dünner” als ein Buch, aber versucht, die wesentlichen Inhalte abzudecken. Außerdem sollen nicht nur Inhalte abdeckt sein, sondern auch die Kompetenz entwickelt werden, etwa durch Aufgaben.\n\n1.3.14 Viel R (?)\nDieses Buch enthält “mittel” viel R. Auf fortgeschrittene R-Techniken wurde aber komplett verzichtet. Dem einen oder der anderen Anfänger:in mag es dennoch “viel Code” erscheinen. Es wäre ja auch möglich gewesen, auf R zu verzichten und stattdessen eine “Klick-Software” zu verwenden. JASP ist zum Beispiel eine tolle Software aus dieser Kategorie. Ich glaube aber, der Verzicht auf eine Skriptsprache (R) wäre ein schlechter Dienst an den Studentis. Mit Blick auf eine “High-Tech-Zukunft” sollte man zumindest mit etwas Computer-Code vertraut sein. Auf Computercode zu verzichten erschiene mir daher fahrlässig für die “Zukunftsfestigkeit” der Ausbildung.\n\n\nDas sind Sie nach der Lektüre dieses Buchs"
  },
  {
    "objectID": "index.html#organisatorische-hinweise",
    "href": "index.html#organisatorische-hinweise",
    "title": "Lernhilfen",
    "section": "\n1.4 Organisatorische Hinweise",
    "text": "1.4 Organisatorische Hinweise\n\n\n1.4.1 Sicherheitsunterweisung\n\nDer Dozent weist auf Fluchtwege und auf die Sammelstelle hin (abhängig vom Seminarraum).\nFlucht- und Rettungspläne hängen im Gebäude aus; bitte betrachten Sie sie sorgfältig. Prägen Sie sich die Rettungswege, den Ort der Sammelstelle sowie von Feuerlöschern und Brandmeldeeinrichtungen gut ein.\nBei Alarm: Ruhe bewahren. Der Dozent weist an, den Raum sofort zu verlassen und geordnet über den kürzesten Weg zur Sammelstelle zu gehen. Tun Sie das.\nPrüfen Sie, ob niemand zurückgelassen ist (z. B. auf der Toilette).\nFluchtwege (z. B. Fluren und Treppen) dürfen nicht versperrt sein.\nNotausgänge müssen ausgeschildert und frei zugänglich sein.\nAufzüge dürfen im Brandfall nicht verwendet werden. Lebensgefahr!\nIm Brandfall sind Fenster und Türen zu schließen (aber nicht zu verriegeln!).\nHilflose Personen sind mitzunehmen.\nBrände sind zu bekämpfen, aber die sichere Evakuierung hat Vorrang.\nBei Bränden ist sofort die Feuerwehr zu alarmieren.\nBei einem Hupton ist das Gebäude sofort zu verlassen und die Sammelstelle aufzusuchen. Brandschutztüren sind stets geschlossen zu halten.\nPrägen Sie sich die Position von Feuerlöschern und Erste-Hilfe-Material gut ein.\n\n1.4.2 Organisatorisches\n\nBitte laden Sie sich rechtzeitig die Materialien herunter.\nBeachten Sie die Vorbereitungshinweise zur ersten Unterrichtsstunde und für die einzelnen Termine.\nEin Foliensatz kann kein Lehrbuch ersetzen; falls Sie bei einem Termin gefehlt haben oder Ihre Aufzeichnung lückenhaft ist, lesen Sie bitte in der Literatur nach oder bitten Sie eine/n Kommiliton/in um Hilfe.\nBeachten Sie die Hinweise der Hochschule (s. Moodle) wie die Orientierungshilfe, die Klausur- und Studiengangsordnungen. Dort finden Sie verbindliche Hinweise zu vielen organisatorischen Fragen.\nBitte prüfen Sie jetzt schon und in regelmäßigen Abständen die Modulseite auf neue Materialien.\nNachdem eine Unterrichtseinheit abgeschlossen ist, ändert der Dozent grundsätzlich nichts mehr an den Materialien (in Ausnahmefällen wie etwa der Korrektur eines Fehler informiert der Dozent schriftlich).\nEs können sich Aktualisierungen des Unterrichtsmaterials ergeben. Bitte prüfen Sie regelmäßig, ob neues Material eingestellt ist. Nachdem der Unterricht stattgefunden hat, wird das Material aber nicht mehr geändert, so dass Sie Sicherheit für das Lernen haben.\n\n1.4.3 Präsenzunterricht\n\nBeachten Sie aktuell geltenden Hygienevorschriften.\nBitte meiden Sie datenhungrige Applikationen wie das Streamen von Filmen – Sie behindern den Unterricht und verärgern damit andere Studierende (in diesem oder anderen Kursen).\nBitte bringen Sie einen Computer (mit Internetanschluss) in alle Präsenztermine mit. Bringen Sie ggf. Ersatzbatterien und/oder Verlängerungskabel mit - leider sind nicht überall ausreichend Steckdosen vorhanden.\n\n1.4.4 Rechtliche Hinweise\n\nDieser Kurs ist lizensiert unter der MIT Lizenz. Das ist eine permissive Lizenz, die erlaubt, dass Sie diesen Kurs frei verwenden können. Sie haben (nur) die Verpflichtung, zu zitieren und auf die Lizenzart hinzuweisen.\nMitarbeit oder Verbesserungsvorschläge: am besten als Github Issue auf der Github-Seite dieses Projekts einstellen.\nFür die Inhalte von Links kann keine Haftung übernommen werden.\nAus Datenschutzgründen dürfen Teilnehmis den Unterricht (Video, Ton, sonstige) nicht aufnehmen.\n\n1.4.5 Datenschutz\n\nEinige Teile des Unterrichts werden u.U. aufgenommen.\nDie Aufnahme erfolgt nur nach vorheriger Information durch den Dozenten.\nBei den Bild-Aufnahmen wird nur der Bildschirm des Dozenten aufgenommen; außerdem wird der Ton aufgenommen.\nBitte verzichten Sie daher während der Aufnahme auf Zoom-Reaktionen wie Hand heben, da diese u.U. mit Ihrem Namen auf dem Bildschirm des Dozenten und damit auf der Aufnahme zu sehen sind.\nWährend einer Aufnahme dürfen aus Datenschutzgründen keine Wortbeiträge zu hören sein, die Personen identifizieren.\nBitte verzichten Sie während der Aufnahme daher auf Wortbeiträge. - Der Dozent informiert umgehend, wenn er die Aufnahme beendet.\nDie Aufnahmen werden im Internet (z.B. YouTube) frei veröffentlicht. Solche offenen Beiträge im Internet können u.U. in Zukunft nicht kontrolliert werden, insbesondere können sie unkontrolliert verbreitet und kommentiert werden.\nDer Dozent hat u.U. keinen Einfluss auf Verbreitung, Kommentare oder sonstige Weiterverwendung.\nAlle Rechte an den Aufnahmen liegen beim Dozenten.\nAufnahmen des Unterrichts durch die Studentis sind nicht erlaubt.\n\n1.4.6 IT\n\n1.4.6.1 IT allgemein\n\nSie benötigen einen Computer für diesen Kurs. Ein Laptop ist ideal (ein günstiges Modell ist vollkommen ausreichend); ein Tablett ist nicht ideal, reicht aber zur Not, wenn Sie eine Tastatur für das Gerät haben.\nSorgen Sie dafür, dass Sie in jeder Stunde über eine gute Internetverbindung verfügen.\nBitte stellen Sie sicher, dass Sie Zugriff auf Moodle, Zoom und weitere Dienste haben, die wir im Unterricht nutzen (Passwörter dabei haben etc.).\nKontaktieren Sie die IT-Abteilung bei technischen Probleme.\nFür Präsenztermine: Bitte bringen Sie folgende IT-Geräte in jede Stunde mit: Laptop mit Stromkabel, Smartphone oder Tablett, Kopfhörer inkl. Mikrofon.\nFür Präsenztermine: Ein langer Uni-Tag zehrt an der Batterie; nicht nur an Ihrer, sondern auch in Ihrem Laptop und Smartphone. Ggf. kann eine Zusatzbatterie (Akku-Pack) hilfreich sein. Bei schlechter WLAN-Verbindung kann ein Hotspot über das Handy eine Lösung sein.\nBitte lesen Sie auch die Hinweise zur Software, die wir in diesem Modul benötigen.\n\n1.4.6.2 Software: R und Friends\n\nStellen Sie sicher, dass Sie die jeweils aktuelle Version für die in diesem Kurs verwendete Software verwenden (z.B. bei Zoom gibt es viele Aktualisierungen).\nUpdaten Sie ggf. R, RStudio und Ihre R-Pakete.\n\nBereiten Sie bitte R und seine Freunden vor vor der ersten Unterrichtsstunde. Sie können entweder R auf Ihrem Computer installieren oder den Cloud-Dienst RStudio Cloud nutzen.\nBitte beachten Sie die Installationshinweise für Software und stellen Sie sicher, dass die Software vor Beginn des ersten Termins einsatzbereit ist.\n\n1.4.7 Ich brauche Hilfe. Was soll ich tun?\n\nVersuchen Sie erst selber, das Problem zu lösen. Manchmal hilft etwas Abstand (Pause, drüber schlafen), um ein Problem klarer zu sehen (oder es als nicht mehr so wichtig zu sehen).\nFragen Sie Kommilitonis.\nRecherchen Sie (online) nach einer Lösung.\nPosten Sie das Problem im Forum oder einem Online-Forum. Wichtig: Stellen Sie Ihrem Post ein Erbie bei.\nBesuchen Sie die Sprechstunde des Dozenten.\nSchreiben Sie möglichst keine Email, sondern posten Sie Ihre Frage im Forum o.Ä., da die meisten Fragen für Ihre Kommilitonis auch nützlich sein können (eine Ausnahme sind natürlich individuelle, persönliche Angelegenheiten, die nicht den Stoff betreffen).\n\n1.4.8 Videokonferenzen\n\n1.4.8.1 Algemein\n\nIhr Dozent informiert Sie, ob Videokonferenzen in diesem Modul angeboten werden.\nFür Videokonferenzen/Webinare in diesem Modul wird die Software Zoom verwendet. Zur Einwahl benötigen Sie eine Zoom-Meeting-ID bzw. die dazu gehörige URL (Link); außerdem benötigen Sie ggf. ein zugehöriges Passwort. Diese Informationen werden Ihnen vom Dozenten zugestellt-.\nFür die Teilnahme an der Videokonferenz können Sie einen internetfähigen Rechner oder Tablet/Smartphone verwenden. Alternativ können Sie den Zoom-Client auf Ihrem Computer installieren (die Installation auf dem Rechner ist zu empfehlen).\nEin paar Minuten vor Unterrichtsbeginn da sein, hilft beim Ankommen und um etwaige technische Probleme auszuräumen.\n-Wenn jede(r) Hintergrundgeräusche vermeidet (auch die Tastatur kann ziemlich laute Geräusche verursachen), verstehen wir uns alle gut.\nDas Mikro auszuschalten, wenn man gerade nichts sagen möchte, gibt Freiheit, doch nicht ganz leise zu sein, ohne die anderen zu stören. - Ein Headset ist hilfreich, um Rückkopplungsgeräusche (Echo) zu vermeiden.\nEine einigermaßen schnelle Internetverbindung ist nötig.\nIch empfehle, eine Webcam anzuschließen (bzw. freigeben), so dass wir uns sehen können. Das ist der Qualität des Unterrichts zuträglich.\nHilfe zu Zoom findet sich hier: https://support.zoom.us/hc/de.\nZu bestimmten Seiten kann der Dienst (Zoom) überlastet sein, so dass das Webinar nur eingeschränkt oder nicht möglich ist. In diesem Fall erstellt der Dozent ein Video und stellt es im Nachgang über Moodle zur Verfügung.\nDie Datenschutzhinweise von Zoom finden Sie hier.\n\nPrüfen Sie regelmäßig, ob Ihr Zoom-Client aktuell ist (sonst updaten).\nAus Gründen der Sicherheit der Teilnehmis kann der Dozent anonyme Teilnahme an Videokonferenzen untersagen.\nDer Chat sollte nur für Themen des Unterrichts verwendet werden (nicht für private Themen).\nAus Sicherheitsgründen kann eine Zoom-Konferenz auf Ihre “offizielle” E-Mail-Adresse (der Hochschule) begrenzt sein. Mit einer anderen, potenziell anonymen E-Mail-Adresse, können Sie also u.U. nicht teilnehmen.\n\n1.4.8.2 Streaming\nIn einigen Kursen wird Präsenzunterricht plus Streaming angeboten. In diesem Fall gelten folgende Hinweise:\n\nMelden Sie sich zu Beginn der Stunde, wenn Sie merken, dass der Ton schwer zu verstehen ist (z.B. über das Mikro).\nWenn die Teilnehmerzahl am Kurs geringer ist als die Raumkapazität (z.B. weniger als 80 Teilnehmis), so haben Sie stets freie Wahl, ob Sie in Präsenz beiwohnen oder den Unterricht online verfolgen.\nÜbersteigt die Teilnehmerzahl am Kurs die Raumkapazität bis zum Doppelten (z.B. 160 Teilnehmis bei 80 Plätzen), so findet der Präsenzunterricht zweizügig statt. In der 1. Woche können alle Studentis des Zugs A zum Präsenunterricht kommen; in Woche 2 können alle Studentis des Zugs B zum Präsenzunterricht kommen. Wer nicht für Präsenz eingeteilt ist, kann dem Unterricht online folgen. Auch wer in Präsenz eingeteilt ist, kann dem Unterricht jederzeit online folgen. Auch wer nicht für Präsenz eingeteilt ist, kann zum Präsenzunterricht kommen, FALLS es freie Plätze gibt: Kommen Sie einfach zum Hörsaal, wenn es freie Plätze gibt, sind Sie herzlich willkommen (es gilt: first come, first serve).\nSie müssen sich nicht anmelden für Präsenz oder Online.\nFalls die Teilnehmerzahl größer ist als das Doppelte oder es Probleme mit dem Prozedere gibt, erfolgt eine neue Planung.\nIhr Dozent informiert Sie zu den Details, sobald die Teilnehmerzahl (grob) feststeht.\nAlle Angaben sind vorbehaltlich neuer Corona-Entwicklungen bzw. der Vorgaben der Hochschulleitung dazu.\n\n1.4.9 Umgangsformen\n\nFreundlicher Umgang miteinander ist selbstverständlich.\nSelbstverständlich sind auch die grundlegenden Formen der höflichen Miteinanders (Begrüßung, Ansprache mit Namen, bitte/danke sagen, Pünktlichkeit, Verbindlichkeit, …).\nBei Nichtwissen oder einem inhaltlichen Fehler wird niemand bloßgestellt oder lächerlich gemacht.\nUm eine Wortmeldung in einer Videokonferenz anzuzeigen, bietet sich die Funktion des Handhebens an.\nIn Breakout-Sessions (in Zoom) sollte aktiv mitgearbeitet werden, wer das nicht möchte, betritt den Breakout-Room nicht.\nSpricht man eine Person in einer Videokonferenz an, sollte die Kamera angeschaltet sein.\n\n1.4.10 Wenn der Unterricht ausfällt\n\nIm Krankheitsfall werden Sie möglichst frühzeitig informiert (via Moodle); das kann bedeuten, dass Sie am Morgen eine Nachricht bekommen, dass der Unterricht des jeweiligen Tages ausfällt.\nLeider muss der Unterricht in einigen Fällen aufgrund anderer Dienstverpflichtungen des Dozenten entfallen; ein Beispiel sind Berufungskomissionen (Auswahlgespräche für neu einzustellende Professor:innen).\nAufgrund gesetzlicher Feiertage sowie hochschulweit geltenden lehrfreien Tagen fallen jedes Semester einige Tage für den Unterricht aus. Bitte informieren Sie sich auf der zentralen Hochschulseite dazu.\nFalls der Unterricht ausfällt, heißt das nicht, dass der für die jeweilige Woche geplante Stoff obsolet ist. Viel mehr ist Ihre Pflicht, den Stoff selbständig zu erarbeiten. Natürlich können Sie bei Fragen jederzeit Ihren Dozenten kontaktieren.\n\n1.4.11 Salvatorische Klausel\n\nDiese Hinweise hier gelten nur insofern Ihre Dozentis Ihnen nicht andere Hinweise geben :-)"
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Lernhilfen",
    "section": "\n1.5 Technische Details",
    "text": "1.5 Technische Details\n\n## ─ Session info ───────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.1.2 (2021-11-01)\n##  os       Ubuntu 22.04.2 LTS\n##  system   x86_64, linux-gnu\n##  ui       X11\n##  language (EN)\n##  collate  de_DE.UTF-8\n##  ctype    de_DE.UTF-8\n##  tz       Europe/Berlin\n##  date     2023-08-03\n##  pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────\n##  package     * version date (UTC) lib source\n##  cellranger    1.1.0   2016-07-27 [1] CRAN (R 4.1.2)\n##  cli           3.6.1   2023-03-23 [1] CRAN (R 4.1.2)\n##  digest        0.6.33  2023-07-07 [1] CRAN (R 4.1.2)\n##  dplyr         1.1.2   2023-04-20 [1] CRAN (R 4.1.2)\n##  evaluate      0.21    2023-05-05 [1] CRAN (R 4.1.2)\n##  fansi         1.0.4   2023-01-22 [1] CRAN (R 4.1.2)\n##  fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.1.2)\n##  generics      0.1.3   2022-07-05 [1] CRAN (R 4.1.2)\n##  glue          1.6.2   2022-02-24 [1] CRAN (R 4.1.2)\n##  gt            0.9.0   2023-03-31 [1] CRAN (R 4.1.2)\n##  htmltools     0.5.5   2023-03-23 [1] CRAN (R 4.1.2)\n##  htmlwidgets   1.6.2   2023-03-17 [1] CRAN (R 4.1.2)\n##  jsonlite      1.8.7   2023-06-29 [1] CRAN (R 4.1.2)\n##  knitr       * 1.43    2023-05-25 [1] CRAN (R 4.1.2)\n##  lifecycle     1.0.3   2022-10-07 [1] CRAN (R 4.1.2)\n##  magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.1.2)\n##  pillar        1.9.0   2023-03-22 [1] CRAN (R 4.1.2)\n##  pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.1.2)\n##  R6            2.5.1   2021-08-19 [1] CRAN (R 4.1.2)\n##  readxl        1.4.3   2023-07-06 [1] CRAN (R 4.1.2)\n##  rlang         1.1.1   2023-04-28 [1] CRAN (R 4.1.2)\n##  rmarkdown     2.23    2023-07-01 [1] CRAN (R 4.1.2)\n##  rstudioapi    0.15.0  2023-07-07 [1] CRAN (R 4.1.2)\n##  sass          0.4.7   2023-07-15 [1] CRAN (R 4.1.2)\n##  sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.1.2)\n##  tibble        3.2.1   2023-03-20 [1] CRAN (R 4.1.2)\n##  tidyselect    1.2.0   2022-10-10 [1] CRAN (R 4.1.2)\n##  utf8          1.2.3   2023-01-31 [1] CRAN (R 4.1.2)\n##  vctrs         0.6.3   2023-06-14 [1] CRAN (R 4.1.2)\n##  withr         2.5.0   2022-03-03 [1] CRAN (R 4.1.2)\n##  xfun          0.39    2023-04-20 [1] CRAN (R 4.1.2)\n##  xml2          1.3.5   2023-07-06 [1] CRAN (R 4.1.2)\n##  yaml          2.3.7   2023-01-23 [1] CRAN (R 4.1.2)\n## \n##  [1] /home/sebastian/R/x86_64-pc-linux-gnu-library/4.1\n##  [2] /usr/local/lib/R/site-library\n##  [3] /usr/lib/R/site-library\n##  [4] /usr/lib/R/library\n## \n## ──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "index.html#literatur-1",
    "href": "index.html#literatur-1",
    "title": "Lernhilfen",
    "section": "\n1.6 Literatur",
    "text": "1.6 Literatur\n\n\n\n\nForum, World Economic. 2020. „The Future of Jobs Report 2020“. CH-1223 Cologny/Geneva Switzerland: World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Lernhilfen",
    "section": "",
    "text": "Darauf dis Studenti: “Hpmf.”↩︎\nfalls Sie die Pakete schon installiert haben, können Sie in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "pruefung.html#prüfungleistung",
    "href": "pruefung.html#prüfungleistung",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.1 Prüfungleistung",
    "text": "2.1 Prüfungleistung\nDie Prüfungsleistung besteht aus einer Hauptleistung (keine Bonusleistung).\n\n2.1.1 Hauptleistung\nDie Prüfungsleistung besteht aus einer Projektarbeit im Form eines Prognosewettbewerbs."
  },
  {
    "objectID": "pruefung.html#zum-prognosewettbewerb",
    "href": "pruefung.html#zum-prognosewettbewerb",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.2 Zum Prognosewettbewerb",
    "text": "2.2 Zum Prognosewettbewerb\n\nGegenstand dieser Prüfungsform ist eine Projektarbeit in Form eines Prognosewettbewerbs.\n\n2.2.1 tl;dr: Zusammenfassung\nVorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. Wenn Sie den DAX-Stand von morgen genau vorhersagen können, rufen Sie mich bitte sofort an. Genau das ist Ihre Aufgabe in dieser Prüfungsleistung: Sie sollen Werte vorhersagen.\nEtwas konkreter: Stellen Sie sich ein paar Studentis vor. Von allen wissen Sie, wie lange die Person für die Statistikklausur gelernt hat. Außerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. Und Sie wissen die Note jeder Person in der Statistikklausur. Auf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die Prüfung in Statistik schreiben muss will: “Sag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?”. Mit Hilfe Ihrer Analyse können Sie diese Frage (und andere) beantworten. Natürlich könnten Sie es sich leicht machen und antworten: “Mei, der Notendurchschnitt war beim letzten Mal 2.7. Also ist 2.7 kein ganz doofer Tipp für deine Note.” Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, wenn man es geschickt anstellt. Da hilft Ihnen die Statistik (doch, wirklich).\nKurz gesagt gehen Sie so vor: Importieren Sie die Daten in R, starten Sie die nötigen R-Pakete und schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. Dann nehmen Sie die vielversprechendsten Prädiktoren in ein Regressionsmodell und schauen sich an, wie gut die Vorhersage ist. Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. Je genauer Ihre Vorhersage, desto besser ist Ihr Prüfungsergebnis.\n\n\n2.2.2 Vorhersage\nNeben der erklärenden, rückwärtsgerichteten Modellierung spielt insbesondere in der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle: Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. für neue Kunden auf Basis von soziodemographischen Daten den Kundenwert – möglichst genau – zu prognostizieren. Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden, d.h. inklusive des für diese Kunden bekannten Kundenwertes.\nIhnen werden zwei Teildatenmengen zur Verfügung gestellt: Zum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet.\n\nBei den Trainingsdaten (Train-Sample) liegen sowohl die erklärenden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor. Auf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) geschätzt. Es ist also die Variable \\(y\\) vorherzusagen.\nDieses geschätzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(x_0\\), für die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({x}_0)\\) berechnet. Der unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.\n\nLiegt zu einem noch späteren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, so kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden, d.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden.\nIn der praktischen Anwendung können zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben):\n\ndie Trainingsphase, d.h., die Phase für die sowohl erklärende (\\(x\\)) als auch die erklärte Variable (\\(y\\)) bekannt sind. Hier wird das Modell geschätzt (gelernt): \\(\\hat{f}(x)\\). Dafür wird der Trainingsdatensatz genutzt.\nIn der folgenden Anwendungsphase sind nur die erklärenden Variablen (\\(x_0\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.\nEvt. gibt es später noch die Evaluierungsphase, für die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, so dass die Vorhersagegüte des Modells überprüft werden kann.\n\nIm Computer kann man dieses Anwendungsszenario simulieren: man teilt die Datenmenge zufällig in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((x,y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((x_0)\\)) auf: Die Modellierung erfolgt auf den Trainingsdaten. Das Modell wird angewendet auf die Testdaten (Anwendungsdaten). Da man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden.\n\n\n2.2.3 Hauptziel: Genaue Prognose\nIhre Aufgabe ist: Spielen Sie den Data-Scientist! Konstruieren Sie ein Modell auf Basis der Trainingsdaten \\((x,y\\)) und sagen Sie für die Testdaten (\\(x_0\\)) die Zielvariable möglichst genau voraus (\\(\\hat{y}_0\\)).\nIhr(e) Dozent*in kennt den Wert der Zielvariable (\\(y_0\\)). Sie nicht.\nVon zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser, das weniger Vorhersagefehler aufweist (im Test-Datensatz), also genauer vorhersagt. Kurz gesagt: Genauer ist besser.\n\n\n\n\n\n2.2.4 Prüfungsmaterial\nEs werden Ihnen im Rahmen der Prüfung drei (Text-)Dateien bereitgestellt:\n\nTrainings-Datensatz\nTest-Datensatz\nData Dictionary\n\nBeachten Sie, dass der Zugriff zum Prüfungsmaterial eingeschränkt sein kann (z.B. nur während der Prüfungszeit, nur nach Bestätigung der Kenntnis der Prüfungsbedingungen, nur für angemeldete Studentis).\nWelche Variable vorherzusagen ist (die AV), steht im Data Dictionary.\nDie Materialien (oder Hinweise zum Bezugsort) finden Sie im entsprechenden Moodlekurs.\n\n\n2.2.5 Einzureichende Dateien\n\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, qmd-, Rmd-Notebook oder Rmd-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.qmd.\n\n\n\n2.2.6 Zum Aufbau Ihrer Prognosedatei im CSV-Format\n\nDie CSV-Datei muss aus genau zwei Spalten mit exakt folgenden Spaltennamen bestehen:\n\n\nid: Den ID-Wert jedes vorhergesagten Wertes\npred: Der vorhergesagte Wert.\n\n\nSofern nicht anderweitig definiert, entspricht die ID einer Beobachtung ihrer Zeilennummer (in der Reihenfolge, wie sie in der vom Prüfer ausgegebenen Datei vorliegt). Die erste Beobachtung (im Test-Sample) bekommt die ID 1, die zweite Beobachtung die ID 2, etc. Die ID ist als Zahl (reell oder ganzzahlig) zu formatieren.\nDie CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).\nDie eingereichte CSV-Datei muss genau die Anzahl an Zeilen aufweisen, die der Zeilenlänge im Test-Datensatz entspricht.\nPrüfen Sie, dass Ihre CSV-Datei sich problemlos lesen lässt. Falls keine (funktionstüchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Prüfung nicht bestanden. Tipp: Öffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vernünftig aussieht. Achtung: Öffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, der CSV-Dateien verfälschen kann auch ohne dass man die Datei speichert.\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, Rmd-, qmd- oder Rmd-Notebook-Datei)\n\nReichen Sie keine weiteren Dateien ein.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichten Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd.\nUmlaute in ihren Dateinamen sind durch ASCII-Zeichen zu ersetzen (also Süß wird Suess etc.).\n\n\n\n2.2.7 Gliederung Ihrer Analyse\nIhr Analysedokument stellt alle Ihre Schritte vor, die Sie im Rahmen der Bearbeitung der Prüfungsaufgabe unternommen haben, zumindest was die Analyse der Daten betrifft.\nDas Dokument mischt drei Textarten: R-Syntax, R-Ausgaben sowie Prosa (d.h. Ihre Erklärung zu Ihrer Analyse). Alle drei Aspekte sind gleichermaßen wichtig für diese Analyse.\nWenn Sie das Dokument als R-Markdown-Datei (qmd- oder Rmd-Datei) anlegen, müssen Sie R-Code in einem “R-Chunk” auszeichnen. Prosa wird in Rmd-Datei als Standard gesehen, sie brauchen ihn nicht extra auszuzeichnen (für R-Notebook-Dateien gilt das Gleiche). In R-Skript-Dateien ist es umgekehrt: Sie müssen R-Code nicht extra auszeichnen, da in R-Skripten R als “Standard-Text” gesehen wird. Hingegen müssen Sie Prosa als Kommentar einfügen. Es bleibt Ihnen überlassen, für welche Variante (R-, Rmd- oder R-Notebook) Sie sich entscheiden. Keine Option wird als besser oder schlechter gewertet (vermutlich ist Rmd für Sie am einfachsten).\nSie können Ihr Analysedokument z.B. so gliedern:\n\nForschungsfrage und Hintergrund (Beschreiben Sie kurz, worum es geht)\nVorbereitung (Pakete laden, Daten importieren, etc.)\nExplorative Datenanalyse (Untersuchen Sie den Datensatz nach Auffälligkeiten, die Sie dann beim Modellieren nutzen)\nModelle (z.B. via lm(av ~ uv))\nVorhersagen (Vorhersage der Test-Daten anhand des besten Vorhersagemodells und Einreichen)\n\nDie Gliederung ist kein Muss; andere Gliederung sind auch möglich. Entscheidend ist die fachliche Angemessenheit.\n\n2.2.7.1 Abschnitt Forschungsfrage und Hintergrund\nIn diesem Abschnitt passiert noch keine Statistik bzw. keine Analyse. Stattdessen stellen Sie in “normaler Sprache”, also ohne intensiven Gebrauch vom (statistischem) Fachvokabular dar, was Ziel und was Hintergrund der Analyse ist. Sie können als Ziel bzw. Hintergrund den formalen Aspekt der Prüfung anführen, wichtiger sind aber inhaltliche bzw. fachliche Überlegungen: Worum geht es in der Analyse? Warum ist die Frage wichtig? Was wird untersucht? Anhand welcher Methodik wird die Frage untersucht?\nEine viertel bis halbe Seite sollte für diesen Abschnitt reichen.\n\n\n2.2.7.2 Vorbereitung\nIn diesem Abschnitt Ihres Analysedokuments führen Sie die technische Vorbereitung durch. Das betrifft vor allem das Importieren der Daten und das Starten aller R-Pakete, die in der Analyse verwendet werden.\nZum Importieren der Daten gehen Sie bitte so vor: Legen Sie für diese Analyse ein Projekt in Rstudio an. Speichern Sie in diesem Ordner (auf der Wurzelebene, nicht in Unterverzeichnissen) die zu analyiserenden Daten. Ändern Sie nicht den Dateinamen der Daten. Importieren Sie die Daten z.B. auf folgende Weise: d_train &lt;- read_csv(\"d_train.csv) bzw. d_test &lt;- read_csv(\"d_test.csv\"). Auf diese Weise ist die Reproduzierbarkeit Ihrer Analyse sichergestellt.\n\n\n2.2.7.3 Explorative Datenanalyse\nDie explorative Datenanalyse (EDA) meint sowohl die deskriptive Statistik als auch die Datenvisualisierung. Typische Schritte sind: das Bearbeiten (oder Entfernen) von Extremwerten und fehlenden Werten, die Untersuchung von Verteilungsformen oder das Suchen nach Mustern (Korrelationen, Gruppenunterschieden). Ein nützliches Ergebnis ist z.B. zu erkennen, welche Variablen sich als Prädiktoren eignen (für den nächsten Abschnitt der Modellierung). Ziel ist, dass Sie den folgenden Schritt vorbereiten, also Schritte unternehmen, damit Sie die AV möglichst gut vorhersagen können.\n\n\n2.2.7.4 Modellierung\nIn diesem Schritt berechnen Sie Prognosemodelle. Das sind oft lineare Modelle, also etwa lm(av ~ uv). Es empfiehlt sich, mehrere Modelle zu berechnen und zu schauen, welches dieser Kandidaten am besten ist. Die Güte eines Prognosemodells bemisst sich letztlich nur an der Präzision der Vorhersage neuer Daten, also des Test-Datensatzes. Wie gut Ihre Vorhersagen also wirklich sind, erfahren Sie erst mit der Notenbekanntgabe. Allerdings können Sie die Trainingsdaten nutzen, um die Güte Ihrer Modelle abzuschätzen.\n\n\n2.2.7.5 Vorhersagen\nSchließlich entscheiden Sie sich für einen Modellkandidaten. Diesen Modellkandidaten nehmen Sie her, um die (Ihnen unbekannten) Werte der AV (Zielvariablen) vorherzusagen. Diese Vorhersagen - zusammen mit der ID für jede Vorhersagen - speichern Sie als (reguläre) CSV-Datei ab und reichen Sie als Ihre Prüfungsleistung ein, zusammen mit Ihrer Analysedatei.\n\n\n\n2.2.8 Tipps\n\n2.2.8.1 Tipps für eine gute Prognose\n\nSchauen Sie in die Literatur.\nEvtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausreißern) helfen.\nÜberlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierfür gibt es Algorithmen und R-Funktionen.\nVermeiden Sie Über-Anpassung (Overfitting).\nVermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgefüllt.\nArbeiten Sie die bereitgestellten Fallstudien durch. Wenn Sie mehr tun möchten, finden Sie im Internet eine Fülle von weiteren Fallstudien.\n\n\n\n2.2.8.2 Tipps zur Datenverarbeitung\n\nEin “deutsches” Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets können dies allerdings.\n\n\n\n2.2.8.3 Tipps zum Aufbau des Analyseskripts\n\nZu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.\n\n\n\n\n\n2.2.9 Bewertung\n\n2.2.9.1 Kriterien\n\nEs gibt drei Bewertungskriterien:\n\nFormalia: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Übersichtlichkeit der Analyse.\nMethode: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.\nInhalt: Vorhersagegüte.\n\nDas zentrale Bewertungskriterium ist Inhalt; die übrigen beiden Kriterien fließen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein.\nDie Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.\nEs werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.\nEs werden keine Hinweise vergeben, stattdessen gibt es einen Überblick an typischen Fehlern.\nEs wird i.d.R. keine Musterlösung veröffentlicht, um nachfolgende Kohorten nicht zu bevorteilen bzw. die aktuelle Kohorte nicht zu benachteiligen.\n\n\n\n2.2.9.2 Kennzahl der Modellgüte\nDie Güte der Vorhersage wird anhand des RMSE bemessen.\n\n\n\n\n2.2.9.3 Notenstufen\nZur Vorhersagegüte: Die Vorhersagegüte eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\).\nIhre Bewertung erfolgt entsprechend Ihrer Vorhersagegüte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als \\(2,0\\)!\n\n\n2.2.9.4 Bewertungsprozess\nDer Gutachter legt im Nachgang der Prüfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellgüte offen. Außerdem werden die vorherzusagenden Daten veröffentlicht sowie die Grenzwerte für jede Notenstufe. Auf dieser Basis ist es allen Teilnehmis möglich, die Korrektheit Ihrer Note zu überprüfen.\n\n\n\n2.2.10 Freie Wahl in der Methodik\nSie haben freie Wahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie können aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen. (Die freie Wahl gilt nicht für die Formalia und Randbedingungen; auch nicht für die zu verwendende Software und Programmiersprachen.)\nEine Einführung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling with R.2. Die Bücher beinhalten jeweils Beispiele und Anwendung mit R.\nAuch ist es Ihnen überlassen, welche Variablen Sie zur Modellierung heranziehen – und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausreißer bereinigen o.Ä.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchführen, auch auf den Testdaten (Anwendungsdaten) durchzuführen.\nHinweise zur Modellwahl usw. gibt es auch in erwähnter Literatur, aber auch in vielen Büchern zum Thema Data-Science.\nAlles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent sein.\nIm Übrigen lautet die Aufgabe: Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine schöne Antwort, trifft die Wirklichkeit aber leider nicht immer. Eine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangsläufig eine gute Vorhersage (Test-Set).\n\n\n2.2.11 Formalia\n\nEs sind nur Einzelarbeiten zulässig.\nIn der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in bereitgestellten Datensatz genutzt werden.\nAlle Analyseschritte bzw. alle Veränderungen an den Daten müssen im (eingereichten) Analyseskript nachvollziehbar aufgeführt sein. Das Analyseskript ist als R-Skript, qmd-Datei, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie können die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).\nDas Analyseskript muss grundsätzlich funktionstüchtig für den Prüfer sein: Alle Befehle müssen ohne Fehlermeldung durchlaufen. Ausnahmen: a) Installation fehlender Pakete, b) Daten sollen aus der Wurzelebene des Projektordners importiert werden..\nEs dürfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzulässig.\nNichtbeachtung der für dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug führen.\nDer Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.\nEs muss keine Literatur zitiert werden.\nEin ausgedrucktes Exemplar muss nicht abgegeben werden.\nWährend der Prüfungsphase werden keine inhaltlichen Fragen (“wie macht man nochmal eine Log-Transformation?”) und keine technischen Fragen (“wie installiert man nochmal ein R-Paket?”) beantwortet.\n\n\n\n2.2.12 Ich brauche Hilfe!\n\n2.2.12.1 Wo finde ich Beispiele und Vorlagen?\nIm Rahmen des Unterrichts wurden mehrere Fallstudien erarbeitet bzw. bereitgestellt, diese dienen Ihnen als ideale Vorlage.\nEine Beispiel-Modellierung finden Sie in der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd. Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen können, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt.\nIm Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen können.\n\n\n2.2.12.2 Probeprüfung für den Prognosewettbewerb\nJa, hier. In diesem Ordner liegen die Dokumente, die Sie für die echte Prüfung auch bekommen:\n\nTrain-Datensatz\nTest-Datensatz\nHinweise zur vorherzusagenden Variablen\n\n\n\n2.2.12.3 Materialsammlung\nIn diesem Ordner finden Sie eine Materialsammlung zum Prognosewettbewerb.\n\n\n2.2.12.4 Videos\nDiese Playlist beinhaltet Videos, die die Rahmenbedingungen der Prüfungsleistung vorstellt.\n\n\n\n2.2.13 Plagiatskontrolle\nDie eingereichten Arbeiten können automatisiert auf Plagiate überprüft werden. Gibt es substanzielle Überschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungenügend bewertet oder es folgt eine Abwertung der Note."
  },
  {
    "objectID": "pruefung.html#wie-kann-ich-mich-auf-die-prüfung-vorbereiten",
    "href": "pruefung.html#wie-kann-ich-mich-auf-die-prüfung-vorbereiten",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.3 Wie kann ich mich auf die Prüfung vorbereiten?",
    "text": "2.3 Wie kann ich mich auf die Prüfung vorbereiten?\n\n2.3.1 PDF-Version\nUm eine PDF-Version eines Kapitels zu erhalten, können Sie im Browser die Druckfunktion nutzen (Strg-P). Wählen Sie dort “PDF” als Ziel.\n\n\n2.3.2 Videos\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buchs. Besonders diese Playlist passt zu den Inhalten dieses Buchs.\n\n\n2.3.3 Software allgemein\nInstallieren Sie R und seine Freunde.\nInstallieren Sie bitte auch die folgende R-Pakete3:\n\ntidyverse\neasystats\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n\n\n\nRStudio-Cloud-Project\n\n\n\nWenn Ihnen die Lehrkraft ein RStudio-Cloud-Projekt zur Verfügung stellt, nutzen Sie es. Dort sind alle R-Pakete, Datensätze und Syntax-Vorlagen schon bereit gestellt. Sie sparen sich also eine Menge Installationsarbeit.\\(\\square\\)\n\n\n\n\n\n\n\n\nBei Installationsproblemen\n\n\n\n\nGibt R eine Warning aus, ist das zumeist kein Problem und kann ignoriert werden.\nStarten Sie R neu, bevor Sie R-Pakete installieren.\nWenn Sie Probleme mit der Installation auf Ihrem Computer haben, können Sie (übergangsweise oder dauerhaft) die Online-Version von RStudio, RStudio Cloud verwenden (in gewissem Umfang kostenlos).\\(\\square\\)\n\n\n\n\n\n2.3.4 Software: Bayes\nWenn in diesem Modul Inferenzstatistik nötig ist, benötigen Sie Software für Bayes-Inferenz.\nFolgendes R-Paket ist für die Bayes-Inferenz nötig:\n\nrstanarm\n\n\n\n\n\n2.3.5 Online-Unterstützung\nDieser Kurs kann in Präsenz und Online angeboten werden. Wenn Sie die Wahl haben, empfehle ich die Teilnahme in Präsenz, da der Lernerfolg höher ist. Online ist es meist schwieriger, sich zu konzentrieren. Aber auch online ist es möglich, den Stoff gut zu lernen, s. Abbildung 2.1.\n\n\n\nAbbildung 2.1: We believe in you! Image Credit: Allison Horst\n\n\nBitte beachten Sie, dass bei einer Teilnahme in Präsenz eine aktive Mitarbeit erwartet wird. Hingegen ist bei einer Online-Teilnahme keine/kaum aktive Mitarbeit möglich.\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\nNutzen Sie das vom Dozenten bereitgestelle Forum, um Fragen zu stellen und Fragen zu beantworten.\n\n\n\n2.3.6 Fundorte für Datensätze\nHier finden Sie Datensätze, die sich eignen, um die Analyse von Daten zu lernen:\n\nVincent Arel-Bundocks Datenseite\nDie Datenseite der University of California in Irvine (UCI)\n\n\n\n2.3.7 Aufgabensammlung\nDie Webseite Datenwerk beherbergt eine Sammlung an Übungsaufgaben rund um das Thema Datenanalyse. es gibt eine Suchfunktion (wenn Sie den Namen der Aufgabe wissen) und eine Tag-Liste, wenn Sie Aufgaben nach Themengebiet durchsehen wollen.\n\n\n2.3.8 Tipps zum Lernerfolg\n\n\n\n\n\n\nHinweis\n\n\n\nStetige Mitarbeit - auch und gerade außerhalb des Unterrichts - ist der Schlüssel zum Prüfungserfolg. Vermeiden Sie, das Lernen aufzuschieben. Bleiben Sie dran!\\(\\square\\)\n\n\n\nLerngruppe: Treten Sie einer Lerngruppe bei.\nTutorium: Besuchen Sie ein Tutorium, falls eines angeboten wird.\nVor- und Nachbereitung: Bereiten Sie den Unterricht vor und nach.\nSelbsttest: Testen Sie sich mit Flashcards (Karteikarten mit Vor- und Rückseite). Wenn Sie alle Aufgaben dieses Kurses aus dem FF beherrschen, sollte die Prüfung kein Problem sein.\nÜbungen: Bearbeiten Sie alle Übungsaufgaben gewissenhaft.\nPortal Datenwerk: Gehen Sie die Aufgaben auf dem Portal Datenwerk durch (soweit relevant).\nFallstudien: Schauen Sie sich meine Fallstudiensammlungen an: https://sebastiansauer-academic.netlify.app/courseware/casestudies/\nLehrkraft ansprechen: Sprechen Sie die Lehrkraft an, wenn Sie Fragen haben. Haben Sie keine Scheu! Bitte lesen Sie aber vorab die Hinweise, um Redundanz zu vermeiden.\nDabei bleiben: Vermeiden Sie “Bullimie-Lernen” (lange nix, dann alles auf einmal), sondern bevorzugen Sie “Lern-Snacks” (immer wieder ein bisschen)\n\n\n\n2.3.9 Selbstlernkontrolle\nFür jedes Kapitel sind (am Kapitelende) Aufgaben eingestellt, jeweils mit Lösung. Ein Teil dieser Aufgaben hat eine kurze, eindeutige Lösung (z.B. “42” oder “Antwort C”); ein (kleiner) Teil der Aufgaben verlangen komplexere Antworten (z.B. “Welche Arten von Prioris gibt es bei stan_glm()?). Nutzen Sie die Fragen mit eindeutiger, kurzer Lösung um sich selber zu prüfen. Nutzen Sie die Fragen mit komplexerer, längerer Lösung, um ein Themengebiet tiefer zu erarbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nFortwährendes Feedback zu Ihrem Lernfortschritt ist wichtig, damit Sie Ihre Lernbemühungen steuern können. Bearbeiten Sie daher die bereitgestellten Arbeiten ernsthaft.\\(\\square\\)\n\n\n\n\n2.3.10 Lernen lernen\nHier sind einige Quellen (Literatur), die Ihnen helfen sollen, das Lernen (noch besser) zu lernen:\n\nEssentielle Tipps für Bachelor-Studierende der Psychologie\nKonzentriert arbeiten: Regeln für eine Welt voller Ablenkungen\nWie man ein Buch liest\nErsti-Hilfe: 112 Tipps für Studienanfänger - erfolgreich studieren ab der ersten Vorlesung\nVon der Kürze des Lebens\nBlog “Studienscheiss”"
  },
  {
    "objectID": "pruefung.html#lieblingsfehler",
    "href": "pruefung.html#lieblingsfehler",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.4 Lieblingsfehler",
    "text": "2.4 Lieblingsfehler\n\nEs wird nicht die richtige Variable AV (y) modelliert.\n\nAchten Sie auf eine korrekt spezifizierte Regressionsformel, etwa: y ~ x1 + x2.\n\nEs werden leichtfertig alle Fälle (Zeilen) mit fehlenden Werten entfernt.\n\nDas kann im Extremfall dazu führen, dass der Datensatz sehr klein wird, etwa von 1000 auf 50 Beobachtungen. Achten Sie darauf, wie viele Fälle übrig bleiben. Im Notfall trennen Sie sich von Variablen, die fast nur aus fehlenden Werten bestehen (entfernen Sie solche “Schweizer Käse” aus dem Datensatz).\n\nDie AV (y) erscheint auf beiden Seiten der Regressionsformel: y ~ x1 + y.\n\nDie AV darf nur auf der linken Seite der Regressionsformel erscheinen.\n\nNominale Variablen werden in numerische umgewandelt.\n\nSagen wir, in einer Analyse gibt es die (nominale) Variable Bundesland, mit den bekannten 16 Werten, Bayern, Baden-Württemberg, … Wandelt man diese Nomen in Zahlen um, so würde zwei Mal Bayern das gleiche wie Baden-Württemberg ergeben. Kein Schluss mit dem die Bürger jener Länder einfach zustimmen würden!\n\nDer Quellcode ist nicht reproduzierbar: Der Prüfer versucht Ihre Analyse nachzuvollziehen, scheitert aber, weil er Ihre Syntax nicht zum Laufen bekommt oder es nicht (vollständig) dokumentiert ist, was Sie gemacht haben.\n\nAchten Sie darauf, dass Ihr Code lauffähig ist, auch auf einem anderen Computer. Das bedeutet idealerweise, dass Sie keine Pfade (für Daten) verwenden, die auf Ihren Computer zeigen, da darauf ja außer Ihnen niemand Zugriff hat.\n\nEs wird keine explorative Analyse durchgeführt, und auch keine sonstigen Methoden, um herauszufinden, welche Variablen prädiktiv sind. Stattdessen werden auf Geratewohl Modelle ausprobiert.\n\nVerwenden Sie die z.B. Methoden der explorativen Datenanalyse, um herauszufinden, welche Variable z.B. viele fehlende Werte aufweisen, oder keine Streuung aufweisen oder hoch mit der AV korreliert sind.\n\nEs wird ein Prognosemodell gerechnet, ohne zu prüfen, ob die verwendeten Prädiktoren viele fehlende Werte aufweisen.\n\nAls Extrembeispiel: Sagen wird, nur 10 Zeilen im Datensatz weisen keine fehlenden Werte in den Prädiktoren Ihres Modells auf. Eine Regression wird nur diese Zeilen verwenden, also nur Zeilen mit kompletten Werte (keine fehlenden Werte). Ist es zu erwarten, dass so eine kleine Stichprobe (n=10) eine präzise Vorhersage machen wird (noch dazu, wenn es viele Prädiktoren gibt)? Leider nein! Prüfen Sie also vorab, wie viele Zeilen übrig bleiben, wenn man ein Modell mit Ihren Prädiktoren rechnet. Ohne diese Prüfung wird Ihr Modell u.U. sehr unzuverlässig sein. Auch wenn es Ihre 10 Zeilen gut beschreibt, ist es sehr fraglich, ob so eine kleine Stichprobe neue Daten gut erklären wird.\n\nEs werden kollineare (hochkorrelierte) Prädiktoren aufgenommen.\n\nNimmt man zwei (fast) identische Prädiktoren in eine Regression auf, so kann das das Modell “durcheinander bringen”. Besser ist es, auf eine der beiden Variablen zu verzichten.\n\nDie Vorhersagen werden* nicht mit der (richtigen) ID* versehen.\n\nStellen Sie sich vor, Sie sollen Noten schon Studentis vorhersagen. Jemand sagt vorher: “Schorsch wird eine 1 haben!”. Schorsch hat tatsächlich eine 1. Toll! Jemand anderes sagt vorher: “Jemand wird eine 1 haben!”. Tja. Schon richtig. Aber wer? Diese Vorhersage ist leider nicht wenig nütze, ihr fehlt eine ID, in dem Fall wäre die richtige (oder eine rictige) ID “Schorsch”. Achten Sie darauf, für jeden Wert von pred eine id anzugeben, sonst kann die Richtigkeit Ihrer Vorhersagen nicht überprüft werden bzw. es wird kein Treffer gefunden für Ihre Vorhersagen.\n\nDen “Sanity-Check” vergessen.\n\nStellen Sie sich vor, Sie sollen Noten von Studentis vorhersagen (Note 1 bis Note 5). Bei den Vorhersagen einer Kommilitonin lesen Sie als Vorhersagen einen Wert von minus 42 Billionen (Es könnten 420 Billionen gewesen sein, bei so vielen Nullern kommt man schon mal durcheinander). Was ist von dieser Vorhersage zu halten? Ein Blick zur richtigen Zeit in die Vorhersagen hätte hier vor einer verkehrten Vorhersage geschützt.\n\nDie einzureichenden Dateien falsch benennen.\n\n\nSoll man eine Datei “cool.csv” einreichen, aber man nennt die Datei stattdessen “cool_csv”, dann wird ein einfach gestricktes Computerprogramm Probleme haben, den Namen zu erkennen. Achtung vor Rechtschreibfehlern in entscheidenden Situationen, so ähnlich wie beim Eingeben einer PIN oder eines Passworts. An manchen Stellen lohnt sich ein Doppel-Check und Vorsicht. Man sollte auch keine Zip-Datei hochladen, wenn das vorab als ausgeschlossen deklariert wurde.\n\n\nRechtschreibfehler Manchmal muss man genau hinschauen, und leicht vertippt man sich: So heißt der Datensatz vielleicht tips und die Spalte, um die es Ihnen geht tip (oder war es umgekehrt?). Oder die Spalte heißt bill_length aber Sie schreiben bill_lenght.\nDatensatz nicht richtig importiert Ob ein Datensatz richtig importiert ist, erkennen Sie daran, ob er im Reiter “Environment” angezeigt wird. Außerdem können Sie dort den Datensatz anklicken, um zu einer Tabellenansicht des Datensatzes zu gelangen. Dort können Sie erkennen, ob z.B. die Anzahl der Spalten korrekt ist (und nicht etwa nur eine) oder z.B. ob die Spaltennamen korrekt sind.\ndata(datensatz) ohne vorher das zugehörige R-Paket gestartet zu haben: Mit data(datensatz) können Sie den Datensatz datensatz nur dann verfügbar machen, wenn das Paket, in dem datensatz “wohnt”, mit library(paketname) gestartet worden ist. So “wohnt” z.B. penguins im Datensatz palmerpenguins. Hier finden Sie eine Übung (und weitere Erklärung) zum Importieren von Daten in R am Beispiel des Datensatzes penguins.\nVerwenden einer Funktion, ohne das zugehörige R-Paket vorab gestartet zu haben.\nDas Laden zu vieler R-Pakete, die gar nicht benötigt werden, mit dem Ergebnis, dass es mehrere Funktionen des gleichen Namens gibt (z.B. filter()). Das führt dann zu Verwirrung, da dann z.B. nicht die Funktion filter aus tidyverse (dplyr) verwendet wird, wie Sie annehmen, sondern eine Funktion gleichen Namens aus einem anderen Paket, das Sie auch gestartet haben. Tipp: Starten Sie nur die Pakete, die Sie für die Aufgabe benötigen. Zumeist sind das immer die gleichen wenigen Pakete."
  },
  {
    "objectID": "pruefung.html#allgemeine-prüfungsheinweise",
    "href": "pruefung.html#allgemeine-prüfungsheinweise",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.5 Allgemeine Prüfungsheinweise",
    "text": "2.5 Allgemeine Prüfungsheinweise\n\n\n2.5.1 Grundsätzliches\nDie folgenden Hinweise gelten grundsätzlich, d.h. soweit nicht anders in der jeweiligen Prüfung bzw. der jeweiligen Aufgabe angegeben.\nNichtbeachten von Prüfungshinweisen kann zu Punkteabzug oder Nichtbestehen führen.\n\n\n2.5.2 Wiederholungsprüfungen\n\nWenn Sie bei einer Prüfung durchgefallen sein sollten, so haben Sie grundsätzlich die Möglichkeit, die Prüfung zu wiederholen.\nDenken Sie daran, sich rechtzeitig für Prüfungsleistungen anzumelden; beachten Sie die Fristen. Beim Zweit- bzw. Drittversuch gelten besondere Regeln und Fristen. Informieren Sie sich umfassend.\nDie Termine für die Wiederholungsprüfungen werden stets zusammen/zeitgleich mit denen der regulären Prüfungen bekannt gegeben.\nRelevanter Stoff und formale Bedingungen (wie Prüfungsform) sind grundsätzlich identisch zur letzten abgehaltenen Prüfung des Moduls (d.h. sofern nicht anders angegeben). Daher sind Wiederholungsprüfungen vom Anspruch vergleichbar wie die reguläre Klausur. Die Prüfungen sollen möglichst gleich vom Anspruch sein, um Fairness zu gewährleisten.\nBeachten Sie immer die Hinweise, die für die Wiederholungsprüfung angegeben sind. Im Einzelfall keine eine Wiederholungsprüfung von der vorherigen Prüfung stärker abweichen. Es gelten immer die Regeln, die dis Dozenti bei der jeweiligen Wiederholungsprüfung veröffentlicht hat.\nWird ein Modul im laufenden Semester angeboten, so gibt es keine Wiederholungsprüfung. Stattdessen können Sie ggf. an der regulären Klausur des Moduls teilnehmen. Es gilt der aktuelle Stoff bzw. die aktuellen formalen Bedingungen. Es ist möglich, dass der Stoff sich dann substanziell ändert; meist halten sich die Änderungen (im Stoff) aber in Rahmen.\nWird ein Modul im laufenden Semester nicht angeboten, gibt es eine Wiederholungsprüfung.\nSprechen Sie die Moduldozentis an für Details zur Prüfung (bzw. lesen Sie vorab auf jeweiligen Modulseite in Moodle nach).\nManchmal fragen Studentis nach einer Empfehlung, ob es besser ist, eine Prüfung zu verschieben, wenn man sich nicht ausreichend vorbereiten konnte. Es ist schwer, eine Empfehlung pauschal abzugeben; es kommt auf den Einzelfall an. Grundsätzlich rate ich aber dazu, Prüfungen nicht zu verschieben: Schließlich könnte in einem folgenden Semester wieder ein unvorhergesehenes Problem auftreten.\nBei Fragen zum Prüfungsrecht sprechen Sie bitte die Studienberatung an.\nHandelt es sich bei der Prüfung um eine Projektarbeit (oder vergleichbare Leistung), so ist als Wiederholungsprüfung ein neues Thema zu bearbeiten. Das “alte” (nicht eingereichte) Thema darf nicht weitergeführt werden, da sonst die Bearbeitungszeit unzulässigerweise zu lange wäre (z.B. ein Jahr).\n\n\n\n2.5.3 Prüfungsrelevanter Stoff\nPrüfungsrelevanter Stoff ist alles, was im Unterricht behandelt wurde, sofern es nicht explizit (und schriftlich) als “nicht prüfungsrelevant” gekennzeichnet ist. Insbesondere ist der komplette Inhalt des Skripts und sonstiger vom Dozenten eingestellter Unterlagen prüfungsrelevant (sofern nicht in Teilen anderweitig gekennzeichnet). Dazu zählen auch Hinweise auf zu lesende Literatur, aber nicht sonstige Literatur im Literaturverzeichnis.\n\n\n2.5.4 Teilnahmebedingungen\n\nEine Prüfungsleistung darf nur eingereicht werden, wenn Sie (erfolgreich) zur Prüfung angemeldet sind. Eine abgegebene/hochgeladene Arbeit, die nicht erfolgreich angemeldet ist, gilt nicht als erfolgreich eingereicht.\nDie Prüfung ist selbständig, also alleine nur durch Sie (Prüfling), ohne Hilfe Dritter, zu absolvieren.\nDie Bearbeitungszeiten der Prüfung sind einzuhalten.\nEs dürfen nur die explizit als zulässig gekennzeichneten Hilfsmittel verwendet werden.\nDie zulässigen Hilfsmittel sind: Notizpapier, Stifte, Taschenrechner, Vorlesungsfolien, Skripte, eigene Notizen, Bücher sowie Quellen aus dem Internet.\nDie Übernahme von Inhalten Dritter muss also solche gekennzeichnet (zitiert) werden.\nEine wörtliche Übernahme (“copy-paste”) von Inhalten Dritter (etwa aus einer Quelle aus dem Internet) ist unzulässig.\nBei technischen Problemen ist sofort der Prüfer bzw. die Prüferin zu verständigen und das technische Problem zu dokumentieren. Aus der Dokumentation muss der Fehler erkenntlich sein.\nEs ist untersagt, die Prüfung bzw. Teile daraus (z.B. Prüfungsfragen) zu speichern oder weiterzugeben.\nIm Übrigen gelten die allgemeinen Prüfungsregeln.\nEs darf nicht mit anderen Personen, insbesondere nicht Prüflingen, kommuniziert werden während der Prüfung. Dies gilt auch für den Fall von (vermeintlichen) technischen Problemen. Kontaktieren Sie den Prüfer, wenn Sie meinen, es liege ein technisches Problem vor.\n\n\n\n2.5.5 Organisatorische Hinweise\n\n2.5.5.1 Allgemeines\n\nEtwaige weitere Stoffeingrenzungen werden schriftlich bekannt gemacht (auf der Modulseite). Besondere Schwerpunkte gibt es nicht.\nSoweit bestimmte Inhalte nicht explizit ausgeschlossen sind, sind alle Inhalte, die im Rahmen des Moduls bearbeitet wurden, prüfungsrelevant.\nIm Übrigen gelten die Hinweise der offiziellen Regularien wie SPO, auf dem Modulsteckbrief und der APO. Bitte kontaktieren Sie die Studienberatung für formale oder rechtliche Fragen.\nWährend der Prüfung werden nur Fragen beantwortet, die für die Bearbeitung zwingend nötig sind (etwa bei technischen Problemen).\nKeine Vorab-Korrektur: Es werden keine Fragen der Art “Ist diese Aufgabe klar formuliert?” beantwortet während der Prüfung. Sollten Sie der Meinung sein, eine Frage ist unklar formuliert oder fehlerhaft, so notieren Sie dies bitte (z.B. im Kommentarfeld der Prüfung=. Der Prüfer untersucht im Nachgang die Angelegenheit. Stellt sich eine Frage als fehlerhaft oder unklar formuliert heraus, so wird sie von der Beurteilung herausgenommen.\nEine Teilnahme an der Prüfung ist nur möglich, wenn Sie den Teilnahmebedingungen der Prüfung zustimmen. Nehmen Sie an der Prüfung teil, so heißt das, dass Sie die Teilnahmebedingungen akzeptiert haben. Falls Sie Fragen oder Hinweise haben, können Sie sich jederzeit an die Prüfperson wenden.\nDie Aufgabenstellung der Prüfung wird ggf. nur während des Prüfungszeitraumes angezeigt.\nBeachten Sie eine etwaige Gruppeneinteilung (zu welcher Gruppe Sie zugeteilt sind).\nBeachten Sie die exakte Prüfungsuhrzeit (Beginn, Ende).\nPrüfungszeitraum, Aufgabenstellung und sonstige Materialien können variieren zwischen den Prüflingen etwa aufgrund von Gruppeneinteilungen oder Nachteilsausgleich.\nDie zusätzliche Bearbeitungszeit bei Studentis mit Nachteilsausgleich ist in der Aufgabenstellung bzw. der Prüfung in Moodle hinterlegt. Die Zeit wird automatisch um den jeweiligen Faktor bzw. Wert erhöht.\n\n\n\n2.5.5.2 Technische Probleme während der Prüfung\nIm Falle eines technischen Problems auf Seiten der Prüfungsinfrastruktur ist sofort der Prüfer zu informieren. Ein Beispiel für so ein Problem wäre etwa der Ausfall von Moodle. Der technische Fehler ist zu dokumentieren (z.B. Screenshot) und die Dokumentation ist einzureichen. Bitte beachten Sie, dass der Prüfer bzw. die Hochschule keine Gewähr übernimmt für Probleme mit Ihrer eigenen Ausstattung.\n\n\n2.5.5.3 Zeitrahmen der Prüfung\nDie Prüfung beginnt und endet zu einem festen Zeitpunkt. Sie sind selber verantwortlich, die Prüfung zur korrekten Zeit zu beginnen und zu beenden (einzureichen). Verspätete Abgaben werden u.U. als nicht bestanden gewertet. Die Dauer der Prüfung wird Ihnen von Ihrer Prüferin bzw. Ihrem Prüfer bekannt gegeben.\n\n\n\n2.5.6 Anspruch\nIn die Notengebung fließt folgende Konzeption zum Anspruch an die Prüfungsarbeit ein:\n\nSehr gute Leistung: Der Stoff aus dem Unterricht wird in sehr breitem Umfang und sehr hoher Tiefe in höchstem Maße korrekt angewandt. Die Stärken und Schwächen des gewählten Vorgehens werden ausgiebig und korrekt reflektiert.\nAusreichende Leistung: Wesentliche Teile des Stoffes aus dem Unterricht werden in einiger Breite wenn auch mit geringer Tiefe überwiegend korrekt angewandt. Eine Reflektion des Vorgehens ist in Ansätzen zu erkennen.\n\nEs wird kein unbehandelter Stoff vorausgesetzt für (sehr gutes) Absolvieren der Prüfung. Als “behandelter” Stoff gelten alle Inhalte, die als prüfungsrelevant gekennzeichnet sind.\n\n\n2.5.7 Plagiatskontrolle\nIhre Prüfungsarbeiten können auf Plagiate hin untersucht werden, auch unter Einsat von maschinellen Methoden oder KI-basierten Methoden (z.B. mit dieser Methode). Dabei können die Daten auch an Drittanbieter (z.B. Anbieter von Software zur Plagiatserkennung).\nBitte beachten: Angenommen in den Projektarbeiten von Studenti A und B werden (substanzielle) Überlappungen gefunden. In dem Fall ist davon auszugehen, dass beide Studentis getäuscht haben: eine/r hat abgeschrieben, der/die andere hat die eigene Arbeit dafür bereitgestellt. Daher wird in diesem Fall u.U. bei beiden Studentis der Plagiatsfall festgestellt und geahndet (z.B. mit “nicht bestanden” bewertet). Die genauen Konsequenzen legt die Prüfungskommission im Einzelfall fest.\nLassen Sie es auf keinen Fall soweit kommen: Schreiben Sie nicht ab und lassen Sie niemanden von Ihrer Arbeit abschreiben.\nEine faire Prüfung heißt: Gleiche Chancen für alle, und gute Leistung wird belohnt, Täuschung nicht.\n\n\n2.5.8 Widerspruch einlegen\nFalls Sie der Meinung sind, dis Gutachti hätte Ihre Arbeit nicht korrekt beurteilt, haben Sie folgende Möglichkeiten zum Widerspruch. Bitte halten Sie folgende Reihenfolge ein:\n\nPrüfungseinsicht: Schauen Sie sich die Aufgabe und Bewertung genau an.\nGespräch mit Gutachter: Sprechen Sie mit Isis Gutachti, vielleicht kann man in einem Gespräch etwaige Missverständnisse klären.\nWiderspruch einlegen: Sie können formlos beim Studierendenservice Widerspruch einlegen (bis 4 Wochen nach Notenbekanntgabe). Ihr Widerspruch wird dann in der Fakultät geprüft. Studierendenservice lässt sich die Unterlagen des Prüfers geben und leitet den Widerspruch und die Prüfung an den Prüfungsausschuss weiter. Dieser entscheidet über die Note. Nur im Zweifelsfall kommt hier noch der Zweitprüfer ins Spiel.\nDer Rechtsweg steht Ihnen offen.\n\nFolgenden Kritikpunkte von Studentis führen i.d.R. nicht zu einer Änderung der Note:\n\n“Das ist zu streng benotet.”\n“Da war kein konstruktives Feedback dabei.”\n“Der Gutachter hat nicht geschrieben, wie man den Satz/das Argument/die Seminararbeit besser formuliert hätte.”\n“Die Note passt nicht zu den Hinweisen der Gutachterin.”\n“Die Gutachterin konnte mir die Note nicht verständlich machen.”\n“Eine andere Studentin hat das aber so ähnlich geschrieben wie ich, und ihre Arbeit wurde besser benotet” - die Vergleichbarkeit von Seminararbeiten ist komplex, die Gesamtnote setzt sich aus vielen Aspekten zusammen, so dass man anhand eines einzelnen Aspekts nicht die Vergleichbarkeit der Noten beurteilen kann.\n“Die Aufgaben waren zu schwierig.”\n“Ich bin mit der Note nicht zufrieden. Ich hätte mir was Besseres erhofft.”\n“Ich habe nichts aus dem Gutachten gelernt.”\n“Da war kaum Negatives im Gutachten.”\n\nFolgenden Kritikpunkte von Studentis haben Aussicht auf eine Änderung der Note:\n\nDer Gutachter hat sich verzählt (oder Punkte übersehen): Sie haben tatsächlich 43 Punkte, aber er hat nur 42 Punkte gezählt.\nDie Gutachterin hat einen Teil der Prüfungsleistung übersehen (vielleicht war ein Teil des Textes in einem Anhang, der in einer separaten Datei beigefügt war, die die Gutachterin nicht gesehen hat).\nDie Aufgabenstellung war falsch (“Was ist der Logarithmus von -1?”).\nDie Aufgabenstellung war missverständlich (“Erläutern Sie den Hintergrund: ‘Islamistische Selbstmordattentäter wollen als Mehrtürer sterben.’”)\n\n\n\n2.5.9 Tipps\n\nLegen Sie regelmäßig Sicherheitskopien Ihrer Projektarbeit an (ggf. auf einem anderen Datenträger).\nAchten Sie darauf, dass Sie nicht mit den Versionen durcheinander kommen, in welcher Datei der aktuelle Stand Ihrer Projektarbeit liegt.\nLesen Sie die Hinweise sorgfältig durch.\nTeilen Sie sich die Zeit entsprechend ein."
  },
  {
    "objectID": "pruefung.html#fazit",
    "href": "pruefung.html#fazit",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "2.6 Fazit",
    "text": "2.6 Fazit\n🍀🍀🍀VIEL ERFOLG!🍀🍀🍀"
  },
  {
    "objectID": "pruefung.html#footnotes",
    "href": "pruefung.html#footnotes",
    "title": "Beispiele für Fehler im Prognosewettbewerb",
    "section": "",
    "text": "https://link.springer.com/book/10.1007/978-3-658-21587-3↩︎\nhttps://www.tmwr.org/↩︎\nfalls Sie die Pakete schon installiert haben, können Sie in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "010-rahmen.html#lernsteuerung",
    "href": "010-rahmen.html#lernsteuerung",
    "title": "\n3  Rahmen\n",
    "section": "\n3.1 Lernsteuerung",
    "text": "3.1 Lernsteuerung\n\n3.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\nAbbildung 3.1 zeigt, dass unser Vorgehen in diesem Buch einem Fließband gleicht: Schritt für Schritt, in der richtigen Reihenfolge, vom Anfang bis Ende, erarbeiten wir unser “Datenprodukt”.\n\n\nAbbildung 3.1: Datenanalyse als eine Abfolge am Fließband\n\n\nQuelle\n\n\n3.1.2 Lernziele\n\nSie können eine Definition von Statistik wiedergeben.\nSie können eine Definition von Daten wiedergeben.\nSie können den Begriff Tidy-Daten erläutern.\nSie können Beispiele für verschiedene Skalenniveaus nennen."
  },
  {
    "objectID": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "href": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "title": "\n3  Rahmen\n",
    "section": "\n3.2 Was ist Statistik und wozu ist sie gut?",
    "text": "3.2 Was ist Statistik und wozu ist sie gut?\nEs gibt mehrere Definition von Statistik; hier ist eine.\n\nDefinition 3.1 (Statistik) Statistik fasst Daten zusammen, um wesentliche Informationen den Daten zu entnehmen und beschreibt die Ungewissheit unserer Schlüsse Kaplan (2009), Poldrack (2023).\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Buch werden die Begriffe Statistik, Datenanalyse und Data Science synonym verwendet.\\(\\square\\)\n\n\nHm. Vielleicht fragen wir mal ChatGPT, was es unter Statistik versteht:\n\n👨 Was ist Statistik? Bitte definiere verständlich.\n\n\n🤖 Statistik ist eine Wissenschaft, die sich mit der Sammlung, Analyse, Interpretation, Präsentation und Übertragung von Daten beschäftigt. Ziel ist es, Muster und Trends in den Daten zu erkennen und verlässliche Schlussfolgerungen über eine größere Gruppe (z.B. Bevölkerung) auf der Basis einer Stichprobe (Teilmenge) zu treffen. Die Statistik hilft uns bei der Beantwortung von Fragen, indem sie uns dabei hilft, die Unsicherheit in den Daten zu messen und zu verstehen1.\n\nGute Antwort, oder?\n\nÜbungsaufgabe 3.1 (Nutzen von Statistik) 🏋️‍♀️ Fragen Sie ChatGPT, was der Nutzen von Statistik ist. Diskutieren Sie die Antwort.\n\n\n\n\n\n\n\n\nEin zentrales Vorgehen bei statistischen Analysen ist es, die Unterschiedlichkeit der Dinge zu beschreiben, präziser gesagt: die Variation zu quantifizieren. Betrachten wir dazu das Beispiel in s. Abbildung 3.2.\n\n\n\n\nAbbildung 3.2: Wenig Variation in der Körpergröße bei den Basketballern. Alles lange Kerle. Viel Variation bei den Schachspielern: Manche sind klein, ander groß.\n\n\n\nBei den Basketballern gibt es wenig Variation in der Körpergröße - alle sind groß, ähnlich groß. Bei den Schachspielenr gibt es (im Verhältnis) viel Variation: Einige Personen sind groß, andere klein.\nDie Variation (auch “Variabilität” genannt) kann man auch gut so darstellen wie in s. Abbildung 3.3 gezeigt.\n\n\n\n\nAbbildung 3.3: Die Abweichungen der einzelnen Personen von der mittleren Körpergröße ihres Teams\n\n\n\nEine Abweichung (auch Residium) genannt, zeigt die Differenz von Mittelwert und dem Wert der Körpergröße bei der jeweiligen Person. Wenn wir allgemein von einer Person \\(i\\) sprechen, die Körpergröße mit \\(x\\) bezeichnen und den Mittelwert der Körpergröße als \\(\\bar{x}\\) (“x quer”), dann können wir knapp und präzise das Residuum \\(r\\) so definieren: \\(r_i = x_i - \\bar{x}\\)."
  },
  {
    "objectID": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "href": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "title": "\n3  Rahmen\n",
    "section": "\n3.3 Was ist das Ziel Ihrer Analyse?",
    "text": "3.3 Was ist das Ziel Ihrer Analyse?\n\n3.3.1 Arten von Zielen\n\n\n\n\ngraph TD\n  subgraph Ziele\n    A[beschreiben]\n    B[vorhersagen]\n    C[erklären]\n  end\n\n\nAbbildung 3.4: Zielarten einer Datenanalyse\n\n\n\nBeispiele für die einzelnen Zielarten der Datenanalyse:\n\n\nBeschreiben: “Wie groß ist der Gender-Paygap in der Branche X im Zeitraum Y?”\n\nVorhersagen: Wenn ich 100 Stunden auf die Statistikklausur lernen, welche Note kann ich dann erwarten?\n\nErklären: Wie viel bringt mir das Lernen auf die Statistikklausur?\n\n3.3.2 Forschungsfrage\nEine Forschungsfrage ist die Leitfrage Ihrer Analyse. Sie definiert, was Sie herausfinden wollen. Häufig sind Forschungsfragen so aufgebaut:\n\nHat X einen Einfluss auf Y?\n\nEine Forschungsfrage weist häufig folgende Struktur auf, s. Abbildung 3.5.\n\n\n\n\ngraph LR\n    Input --&gt; X[hier passiert irgendwas]\n    subgraph \"Schwarze Kiste\"\n      X\n    end\n    X --&gt; Output\n\n\nAbbildung 3.5: Struktur eine Forschungsfrage\n\n\n\n\nBeispiel 3.1 (Forschungsfrage 1)  \n\nHat Lernen einen Einfluss auf den Prüfungserfolg? Verringert Joggen die Menge des Hüftgolds? Um welchen Betrag erhöht sich der Umsatz, wenn wir 1000€ mehr Werbung ausgeben?\\(\\square\\)\n\n\n\nBeispiel 3.2 (Forschungsfrage 2) Nach dem Studium haben Sie bei einem großen Online-Auktionshaus angeheuert. Da Sie angaben, sich im Studium intensiv etwas mit Statistik beschäftigt zu haben, hat man Sie in die F&E-Abteilung2 gesteckt. Heute ist es Ihre Aufgabe, Auktionen zur Spielekonsole Wii zu untersuchen, genauer gesagt, geht es um das Spiel Mariokart. Ihre Forschungsfrage lautet:\n\nWelche Produktmerkmale stehen mit einem hohen Verkaufserlös in Zusammenhang?\\(\\square\\)\n\n\n\nBeispiel 3.3 (Aus der Forschung: Smartphone-Brain-Drain) Ward u. a. (2017) untersuchten die Forschungsfrage, ob die bloße Gegenwart eines Handies (z.B. wenn es vor Ihnen auf dem Tisch dazu führt, dass man abgelenkt wird und daher schlechtere kognitive Leistungen zeigt.\nLeider schreiben die Autoren Ihre Hypothese nicht glasklar, aber implizit ist obige Hypothese herauszulesen:\n\nFirst, smartphones may redirect the orientation of conscious attention away from the focal task and toward thoughts or behaviors associated with one’s phone. Prior research provides ample evidence that … that this digital distraction adversely affects both performance … and enjoyment.\n\nSpäter formulieren Sie Ihre Hypothese noch genauer:\n\nIn two experiments, we test the hypothesis that the mere presence of one’s own smartphone reduces available cognitive capacity.\n\nDie Ergebnisse unterstützen Ihre Hypothese, s. Abbildung 3.6. Im Diagramm ist ersichtlich, dass die kognitive Leistung (Y-Achse) sowohl in der Kapazität des Arbeitsgedächtnisses (links) als auch in der fluiden Intelligenz (rechts) am geringsten ist, wenn das Handy auf dem Schreibtisch (Desk) liegt. Am besten ist die kognitive Leistung, wenn das Handy nicht im Raum ist.\\(\\square\\)\n\n\nAbbildung 3.6: Handy in Sichtweite verringert die kognitiven Ressourcen\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEs ist ein häufiger Fehler, in der Forschungsfrage zu formulieren “X führt zu Y”, aber in der Analyse keine Methode zu verwenden, die geeignet ist, kausale Zusammenhänge aufzudecken. Es reicht nicht, dass man z.B. einen (negativen) Zusammenhang zwischen der Häufigkeit von Smartphone-Nutzung und Konzentrationsfähigkeit findet (Schwaiger und Tahir 2022), um zu sagen: “Daddeln macht dumm!”. Es könnte ja z.B. auch umgekehrt sein. Platt gesagt: “Dummheit führt zu Daddeln”. Weitere Erklärungen sind möglich. Vorsicht also mit (vor)schnellen Aussagen zu kausalen Abhängigkeiten."
  },
  {
    "objectID": "010-rahmen.html#was-sind-daten",
    "href": "010-rahmen.html#was-sind-daten",
    "title": "\n3  Rahmen\n",
    "section": "\n3.4 Was sind Daten?",
    "text": "3.4 Was sind Daten?\n\nDefinition 3.2 (Hallo, Daten) Daten kann man als eine geordnete Folge von Zeichen definieren.\\(\\square\\)\n\nDaten kommen häufig in Tabellenform vor; so sind sie am besten zu untersuchen, s. Tabelle 3.1.\n\n\n\n\n Tabelle 3.1:  So sehen Daten aus. \n  \n\n\n\n\nDie erste Spalte id ist nur eine laufende Nummer. Sie dient dazu, die einzelnen Beobachtungen (hier Studentis) identifizieren zu können und birgt ansonsten keine Information. Beispiele für ID-Variablen sind z.B. Matrikulationsnummer, Personalausweisnummern oder Bestellnumern.\n\n3.4.1 Je mehr, desto besser (?)\nWas Daten betrifft, könnte man behaupten: “Viel hilft viel” oder “Je mehr, desto besser”. Natürlich unter sonst gleichen Umständen3. Viel Datenmüll ist natürlich nicht besser als ein paar knappe, wasserdichte Fakten!\n\nBeispiel 3.4 Um Ihre eigene Lehraktivität zu organisieren, wollen Sie sich ein Bild machen, wie viel Ihre Nebensitzer im Hörsaal so lernen. Sie blicken nach links und fragen “wie viel lernst du so?”. Sie blicken nach recht und wiederholen die Frage gerichtet an den rechtsnebensitzenden Kommilitonen. Dann addieren Sie die zwei Zahlen (unter der Annahme, dass Sie zwei Zahlen bekommen haben), und teilen durch zwei, um den Mittelwert zu erhalten.\nEin kritischer Geist könnte anmerken, dass Sie besser die Untersuchung nicht gemacht hätten (auch wenn Sie, vielleicht ohne zu wollen, eine statistische Untersuchung angestellt haben). Denn bei so wenig befragten Personen ist die Ungenauigkeit Ihrer Schätzung der typischen Lernzeit bei Studentis einfach zu hoch.\\(\\square\\)\n\nAbbildung 3.7 veranschaulicht, dass man einen Mittelwert genauer schätzen kann, wenn man auf eine größere Stichprobe zurückgreift.\n\n\nAbbildung 3.7: Schätzgenauigkeit als Funktion der Stichprobengröße\n\nBildquelle: Karsten Lübke\n\nBeispiel 3.5 (Daten zur Forschungsfrage 2) Hier ist ein Auszug der Daten zur Tabelle mariokart, s. Tabelle 4.1.\n\n\n\n\n Tabelle 3.2:  Auszug aus der Tabelle mariokart \n  \n\n\n\n\nEine Erklärung aller Variablen findet sich hier. Eine Erklärung, was die Namen einer Datentabelle bedeuten, nennt man Code Book or Data Dictionary.\\(\\square\\)\n\n\n\n\n\n\n\nWie man mit Statistik lügt: Das File-Drawer-Problem\n\n\n\nSie haben ein tolles Experiment durchgeführt, viel Arbeit, viel Stress, endlich geschafft, puh. Von den 20 Variablen (als AV, s. Kapitel 3.5), die Sie untersucht haben, zeigt nur 1 einen interessanten Effekt, leider. 1 von 20, das hört sich nicht so toll an. Wäre es da nicht “elegant”, die 19 Variablen ohne schönen Effekt einfach in der Schublade liegen zu lassen bis zum Sankt-Nimmerleins-Tag? Dann könnten Sie stattdessen als Ergebnis nur die eine Variable mit schönen Ergebnis präsentieren, ganz ohne widersprechende Befunde.\nDieser Versuchung nicht zu erliegen, kann schwer sein. Es ist aber gefährlich, missliebige Ergebnisse zu verschweigen: Die anderen Menschen bekommen dann ein falsches Bild der Ergebnislage; man spricht von Publikationsbias. Wer Ergebnisse verschweig, verzerrt die insgesamte Befundlage.\n\n\n\n3.4.2 Was ist eine Variable?\n\nDefinition 3.3 (Variable) Eine Variable ist ein Platzhalter, der für ein Merkmal steht, das verschiedene Werte annehmen kann.\\(\\square\\)\n\nMan kann sich eine Variable wie einen Behälter vorstellen, auf dem mit einem Stift geschrieben steht, was für eine Art Inhalt darin ist, s. Abbildung 3.8.\n\n\nAbbildung 3.8: Wir definieren eine Variable “temp” mit dem Inhalt “9”\n\n\n3.4.3 Beobachtungseinheit\n\nDefinition 3.4 (Beobachtungseinheit) Beobachtungseinheiten sind die Dinge, die wir untersuchen (beobachten). Beobachtungseinheiten sind die Träger von Variablen.\\(\\square\\)\n\nIn Tabelle 3.1 gibt es drei Variablen: id, Name und Note. Es gibt auch drei Beobachtungseinheiten: Anna, Berta und Carla.\n\n3.4.4 Wert\n\nDefinition 3.5 Ein Wert ist der Inhalt einer Variablen.\\(\\square\\)\n\nIn Abbildung 3.8 ist der Wert von temp 9.\nIn Tabelle 3.1 hat die Variable name drei Elemente: Anna, Berta, Carla. Der Wert des 2. Elements ist Berta.\nAls Ausprägungen bezeichnet man die verschiedenen Werte einer Variablen.\n\nBeispiel 3.6 In einer Studie wurden zehn Probanden untersucht. Die Variable geschlecht dokumentiert die Geschlechter der Personen:\n\ngeschlecht &lt;- c(\"Mann\", \"Frau\", \"Frau\", \"Frau\", \"Mann\",\n                \"Frau\", \"Mann\", \"Mann\", \"divers\", \"Frau\")\ngeschlecht\n##  [1] \"Mann\"   \"Frau\"   \"Frau\"   \"Frau\"   \"Mann\"   \"Frau\"   \"Mann\"   \"Mann\"  \n##  [9] \"divers\" \"Frau\"\n\nIn dieser Variable (die aus 10 Werten besteht) finden sich drei Ausprägungen: divers, Frau, Mann.\\(\\square\\)\n\n\n\n\n\n\n\nTipp\n\n\n\nGerade haben Sie etwas Computer-Syntax gesehen, genauer gesagt, Befehle aus der Programmiersprache R. Bisher haben wir diese Befehle nicht kennengelernt. Sie verstehen Sie vermutlich (nicht ganz). Ignorieren Sie diese Befehle einfach erstmal.\n\n\n\n3.4.5 Tidy-Data\n\nDefinition 3.6 Unter Tidy-Data (tidy data, “Normalform”) versteht man eine Tabelle, in der jede Zeile eine Beobachtungseinheit darstellt, jede Spalte eine Variable und jede Zelle der Tabelle einen Wert, s. Abbildung 3.9 (a). (Zusätzlich ist noch eine “Kopfzeile” erlaubt, in der die Namen der Variablen stehen.)\\(\\square\\)\n\nTabelle 3.1 ist ein Beispiel für Tidy-Data. Abbildung 3.9 (a) zeigt ein Sinnbild für Tidy-Data (Wickham und Grolemund 2018). Und Abbildung 3.9 (b) erläutert das Tidy-Prinzip genauer.\n\n\n\n\n\n(a) Tidy-Data-Sinnbild. Image Credit: Hadley Wickham\n\n\n\n\n\n(b) Was ist Tidy-Data?. Image Credit: Allision Horst\n\n\n\nAbbildung 3.9: Stay Tidy!\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nFür eine statistische Analyse ist es fast immer nötig, dass die Daten im Tidy-Format vorliegen.\n\n\nDer Vorteil des Tidy-Formats ist es, dass man weiß, wie die Daten aufgebaut sind. Außerdem können Statistikprogramme oft mit dieser Form am besten umgehen, s. fig-tidy3.\n\n\nAbbildung 3.10: Immer schön Ordnung halten… Image credit: Allision Horst\n\n\nQuelle\n\nDas Tidy-Format wird auch als “langes” Format bezeichnet.\nAbbildung 3.11 zeigt einen Datensatz in der “langen” Form, also tidy, und den gleichen Datensatz, umformatiert in der “breiten” Form, nicht-tidy.\n\n\nAbbildung 3.11: Links: Eine Tabelle mit Format “wide” - nicht “tidy”. Rechts: Das “Langformat” ist tidy.\n\n\n\n\n\n\n\nTipp\n\n\n\nIn fast allen Organisationen werden Exceltabellen zur Datenverarbeitung verwendet. Dabei wiederholen sich immer wieder die gleichen Fehler bzw. suboptimalen Vorgehensweise zum Aufbau einer Exceltabelle.\nDieser Artikel von Broman und Woo (2018) zeigt anhand einiger praktischer Tipps, wie man Exceltabellen so aufbaut, dass Fehler minimiert werden."
  },
  {
    "objectID": "010-rahmen.html#sec-arten-variablen",
    "href": "010-rahmen.html#sec-arten-variablen",
    "title": "\n3  Rahmen\n",
    "section": "\n3.5 Arten von Variablen",
    "text": "3.5 Arten von Variablen\n\n3.5.1 Nach Position in der Forschungsfrage\nAngenommen, Ihre Forschungsfrage lautet:\n\nHat Lernen einen Einfluss auf den Prüfungserfolg?\n\nIn dem Fall gilt:\n\n\nLernen ist die Inputvariable/X-Variable/Ursache/UV\n\nPrüfungserfolg ist die Outputvariable/Y-Variable/Wirkung/AV\n\nAbbildung 3.12 stellt diese beiden “Positionen” einer Variable dar. Die erste Position ist vor dem Pfeil. Die zweite Position ist nach dem Pfeil.\n\n\n\n\ngraph LR\n    Input --&gt; Output\n    X --&gt; Y\n    P[Prädiktor] --&gt; K[Kriterium]\n    Ursache --&gt; Wirkung\n    UV[unabhängige Variable] --&gt; AV[abhängige Variable]\n\n\nAbbildung 3.12: Synonyme Bezeichnungen für Input- und Output-Variablen einer Forschungsfrage\n\n\n\n\n3.5.2 Nach dem Skalenniveau\nAbbildung 3.13 gibt einen Überblick über typisch verwendete Skalenniveaus.\n\n\n\n\ngraph TD\n    Variablen --&gt; qualitativ\n    Variablen --&gt; quantitativ\n    qualitativ --&gt; nominal\n    qualitativ --&gt; ordinal\n    quantitativ --&gt; Intervallniveau\n    quantitativ --&gt; Verhältnisniveau\n\n\nAbbildung 3.13: Skalenniveaus\n\n\n\n\n3.5.3 Beispiele für Skalenniveaus\nBeispiele zu den Skalenniveaus sind in Tabelle 3.3 aufgeführt.\n\n\n\n\n Tabelle 3.3:  Beispiele für Skalenniveaus \n  \n\n\n\n\n\\(\\square\\)\nJe nach dem, über welches Skalenniveau eine Variable verfügt, sind verschiedenen Rechenoperationen erlaubt, s. Tabelle 3.4.\n\n\n\n\n Tabelle 3.4:  Erlaubte Rechenoperationen nach Skalenniveau \n  \n\n\n\n\nWas soll das bedeuten, “Rechenoperationen”?\nSchauen wir uns für jedes Skalenniveau ein “Rechenbeispiel” an.\nNominalskala: Die Variable Geschlecht ist nominalskaliert. Das bedeutet, dass ihre Ausprägungen Frau und Mann z.B. nicht (sinnvoll) addiert oder sonswie “verrechnet” werden können. Man könnte, z.B. um das Eintippen zu erleichtern, Frauen mit 1 kodieren und Männer mit 2. Damit darf man aber nicht rechnen! Es macht keinen Sinn zu sagen: “Ich habe eine Frau und einen Mann in meiner Tabelle, das ist im Schnitt ein diverses Geschlecht, weil der Mittelwert von 1 und 2 ist 1,5!”\nDie einzige “Rechenoperation”, die man auf der Nominalskala machen darf, ist die Prüfung auf Gleichheit: Mann kann feststellen, ob ein Objekt gleich zu einem anderen ist oder unterschiedlich. Also ob zwei Personen das gleiche Geschlecht haben oder von unterschiedlichem Geschlecht sind. Etwas formaler ausgedrückt:\n\n👩 \\(\\ne\\) 👨\n👩 \\(=\\) 👩\n👨 \\(=\\) 👨\n\nOrdinalskala: Diese Skala entspricht einer Rangordnung. Eine Rangordnung ist etwa die geordnete Abfolge Ihres Leibgerichte4. Etwas formaler ausgedrückt:\n\n🍕 \\(\\succ\\) 🍝 \\(\\succ\\) 🥩\n\nDas komische Zeichen \\(\\succ\\) soll heißen: “Ist auf meiner Liste von Leibgerichten weiter oben, mag ich lieber”. Man kann aber nicht sagen, “Ich mag aber Pizza um 42% mehr als die Spagetthi und die wieder um 73% mehr als ein Schnitzel!”. Zumindest kann man das nicht ohne weitere Informationen und Annahmen. Es gibt also Dinge auf der Welt, die man leicht in eine Rangordnung bringen kann, aber die man nur schwer in der Größe der Unterschiede bemessen kann. Das ist die Ordinalskala, s. Abbildung 3.14.\n\n\n\n\nAbbildung 3.14: Die Ordinalskala: Je weiter rechts auf der X-Achse, desto höher lieber esse ich das Gericht.\n\n\n\nIntervallskala: Das ist vielleicht eine Überraschung für Sie: Wenn es heute 10°C hat und morgen 5°C – dann ist es heute nicht doppelt so warm wie morgen. Ja, 10 ist das Doppelte von 5. Aber 10° Celcius ist nicht doppelt so warm wie 20° Celcius. Wenn Sie das verwundert: Das ist normal, so geht es den meisten, wenn sie das zum ersten Mal hören. Der Grund, dass es nicht erlaubt ist, Verhältnisse (wie doppelt/halb so viel etc.) auf der Celcius-Skala zu bilden, ist, dass der Nullpunkt der Skala, 0° C, kein echter, physikalischer Nullpunkt ist. Bei 0° C liegt eben nicht Null Wärmeenergie vor. Stattdessen wurde eine Wärmenergiemenge gewählt, die für uns Menschen ganz praktisch, da augenfällig ist: der Gefrierpunkt von Wasser. Was bei der Intervallskala erlaubt ist, ist das Addieren (und Subtrahieren): heute 10°C, morgen 5°C, das ist ein Unterschied von 5°C. Oder: Im Schnitt waren es 7,5°C, das ist genau in der Mitte von 5 und 10°C. Abbildung 3.15 versinnbildlicht die Intervallskala.\n\n\n\n\nAbbildung 3.15: Ein Metermaß steckt im Wasser. Auf dem Metermaß können wir die aufgedruckten Zahlen ablesen. Aber wir wissen nicht, ob der Metermaß auf dem Boden steht. Wir wissen demnach nicht, ob der vom Metermaß angegebene Nullpunkt der wahre Nullpunkt (Meeresboden) ist.\n\n\n\nVerhältnisskala: Eine Verhältnisskala ist das, was man sich gemeinhin unter einer metrische Variable vorstellt: Man kann “normal” rechnen, alle Rechenoperationen sind erlaubt. Zuzüglich zu denen, die auch in anderen, “niedrigeren” Skalenniveaus erlaubt sind, ist das das Bilden von Verhältnissen - Multiplizieren, s. Abbildung 3.16.\n\n\n\n\nAbbildung 3.16: Puh! Der rote Flitzer ist 10 Mal so teuer wie die blaue Möhre. Kohlen zusammenkratzen.”\n\n\n\nIn diesem Video gibt es noch ausführlichere Erklärung zum Thema Skalenniveaus.\n\nAußerdem können quantitative Variablen untergliedert werden in:\n\n\nstetige Variablen, das sind Variablen, bei denen man zwischen zwei Ausprägungen immer noch eine weitere quetschen kann. So gibt es eine Wert für die Köpergröße zwischen 1.60m und 1.61. Und einen Wert zwischen 1.601m und 1.602m, etc.\ndiskrete Variablen, das sind metrische Variablen, die nur bestimmte Ausprägungen haben, häufig sind das die natürlichen Zahlen: \\(1,2,...\\). Ein Beispiel wäre die Anzahl der Kinder in einer Familie.\n\n\n\n\n\n\n\nTipp\n\n\n\nFragen nach Skalenniveaus gehören zu den Lieblingsprüfungsfragen in diesem Themenbereich. Sie sind gut beraten, sich gerade mit dieser Frage intensiver zu beschäftigen. Auch in thematisch angrenzenden Fächern wird immer wieder die Frage nach dem Skalennvieau aufgeworfen. Das zeigt natürlich auch die hohe Relevanz des Themas."
  },
  {
    "objectID": "010-rahmen.html#modelle",
    "href": "010-rahmen.html#modelle",
    "title": "\n3  Rahmen\n",
    "section": "\n3.6 Modelle",
    "text": "3.6 Modelle\nWoran denken Sie beim Wort “Modell”? Vielleicht an Spielzeugautos, s. Abbildung 3.17.\n\n\nAbbildung 3.17: Matchbox-Autos sind Modelle für Autos\n\n\nDefinition 3.7 (Modelle) Modelle sind ein vereinfachtes Abbild der Realität eine Repräsentation (Kaplan 2009).\\(\\square\\)\n\n\nBeispiel 3.7 (Beispiele für Modelle) Puppen sind Modelle für Babies, Landkarten für Landstriche und das Atommodell von Nils Bohr ist ein Modell für Atome.\\(\\square\\)\n\nAuch in der Statistik nutzen wir Modelle. Helfen Sie Prof. Weiss-Ois: Er blickt nicht durch. Gerne würde er wissen, wie viele Stunden seine Studentis auf die Prüfung lernen. Aber mit so vielen Zahlen kann er nicht umgehen … Geben Sie ihm ein Modell: Sagen Sie ihm, wie lang die Studis typischerweise lernen (sagen Sie ihm ein einfach den Mittelwert der Lernzeiten).\n\n\n\n3.6.1 Vorher\n12, 8, 10, 11, 10, 9, 13, 9, 14, 9, 12, 14, 7, 9, 9, 11, 9, 4, 5, 12, 9, 6, 9, 12, 13, 9, 9, 6, 10, 8\n\n\nOh jeh, so viele Zahlen! Ich check nix! Wie viel lernen denn jetzt meine Studis?!\n\n\n\n\n\n\n3.6.2 Nachher\n\n9.6\n\n\n\n\nYeah, jetzt weiß ich, wie viel die Studis so typischerweise lernen. Viel zu wenig natürlich!\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\nDer Nutzen von Modellen ist, dass sie komplexe Sachverhalte vereinfachen und damit oft überhaupt erst dem Verständnis oder einer Untersuchung zugänglich machen: Modelle ermöglichen Verständnis. In der Datenanalyse bzw. Statistik5 fassen Sie oft viele Daten prägnant zusammen, z.B. zu einer einzelnen Kennzahl. Das Verrückte an Modellen ist, dass man Informationen wegwirft, um eine (andere, hoffentlich nützlichere) Information zu bekommen (Stigler 2016). Weniger ist mehr?!"
  },
  {
    "objectID": "010-rahmen.html#nomenklatur",
    "href": "010-rahmen.html#nomenklatur",
    "title": "\n3  Rahmen\n",
    "section": "\n3.7 Nomenklatur",
    "text": "3.7 Nomenklatur\nIn diesem Buch werden ein paar (wenige) griechische Buchstaben verwendet, die in der Statistik üblich sind.\nHäufig werden griechische Buchstaben verwendet, um eine Grundgesamtheit (Population) zu beschreiben (die meistens unbekannt ist). Lateinische (“normale”) Buchstaben werden demgegenüber verwendet, um eine Stichprobe (Datensatz, vorliegende Daten) zu beschreiben.\nTabelle 3.5 stellt diese Buchstaben zusammen mit ihrer Aussprache und Bedeutung vor.\n\n\nTabelle 3.5: Griechische Buchstaben, die in diesem Buch verwendet werden.\n\nZeichen\nAussprache\nBuchstabe\nBedeutung in der Statistik\n\n\n\n\\(\\beta\\)\nbeta\nb\nRegressionskoeffizent\n\n\n\\(\\mu\\)\nmü\nm\nMittelwert\n\n\n\\(\\sigma\\)\nsigma\ns\nStreuung\n\n\n\\(\\Sigma\\)\nSigma\nS\nSummenzeichen\n\n\n\\(\\rho\\)\nrho\nr\nKorrelation (nach Pearson)\n\n\n\n\nMehr griechische Buchstaben finden sich hier."
  },
  {
    "objectID": "010-rahmen.html#praxisbezug",
    "href": "010-rahmen.html#praxisbezug",
    "title": "\n3  Rahmen\n",
    "section": "\n3.8 Praxisbezug",
    "text": "3.8 Praxisbezug\nWir leben im Datenzeitalter; Daten durchdringen alle Bereiche des beruflichen, gesellschaftlichen und privaten Lebens. Die Datenanalyse hat sich in den letzten Jahren massiv verändert, s. Abbildung 3.18.\n\n\nAbbildung 3.18: Forschung früher und heute\n\nDiese Entwicklung ist durchaus auch kritisch zu betrachten. Mit der wachsenden Bedeutung von Daten wächst in gleichem Maße die Bedeutung von Datenanalyse. Denn Daten ohne Sinn sind nutzlos. Aus diesem Grund kann man sagen, dass Datenanalyse (und damit auch Statistik als eine spezielle Art von Datenanalyse) zu stark nachgefragten Jobs gehören.\nLaut dem Entgeltatlas der Bundesagentur für Arbeit liegt ein typisches Gehalt von Data Scientisten bei knapp 6000 € pro Monat (in der Altersgruppe von 25 bis 54)6. Laut dem Gehaltsreporter liegt das Einstiegsgehalt dieser Berufsgruppe bei knapp 50.000€ pro Jahr."
  },
  {
    "objectID": "010-rahmen.html#fazit",
    "href": "010-rahmen.html#fazit",
    "title": "\n3  Rahmen\n",
    "section": "\n3.9 Fazit",
    "text": "3.9 Fazit\nDie Aufgabe von Statistik ist es, durch Zusammenfassen von Daten Modelle zu bilden, die es uns einfacher machen, schwierige Sachverhalte zu verstehen. Zentral ist dabei, die Analyse von Variabilität der Daten. Daten kommen in verschiedenen Varianten vor, typischerweise in Tabellenform, möglichst im Tidy-Format."
  },
  {
    "objectID": "010-rahmen.html#aufgaben",
    "href": "010-rahmen.html#aufgaben",
    "title": "\n3  Rahmen\n",
    "section": "\n3.10 Aufgaben",
    "text": "3.10 Aufgaben\n\nvariation01\nDef-Statistik01\ntidy1\nSkalenniveau1a\nZiele-Statistik\nvariation02\nSkalenniveau1b\ntidydata1"
  },
  {
    "objectID": "010-rahmen.html#vertiefung",
    "href": "010-rahmen.html#vertiefung",
    "title": "\n3  Rahmen\n",
    "section": "\n3.11 Vertiefung",
    "text": "3.11 Vertiefung\nFassen Sie den Artikel von Broman und Woo (2018) zusammen.\nInspiration von einer Praktikerin der Datenanalyse: Caitlin Hudon verrät in diesem Video, welche Fehler Sie sie in in den acht Jahren ihrer Berufserfahrung gemacht hat und was sie daraus gelernt hat."
  },
  {
    "objectID": "010-rahmen.html#literatur",
    "href": "010-rahmen.html#literatur",
    "title": "\n3  Rahmen\n",
    "section": "\n3.12 Literatur",
    "text": "3.12 Literatur\n\n\n\n\nBroman, Karl W., und Kara H. Woo. 2018. „Data Organization in Spreadsheets“. The American Statistician 72 (1): 2–10. https://doi.org/10.1080/00031305.2017.1375989.\n\n\nKaplan, Daniel T. 2009. Statistical modeling: a fresh approach. Scotts Valley, Calif.: CreateSpace. https://dtkaplan.github.io/SM2-bookdown/.\n\n\nPoldrack, Russell A. 2023. Statistical thinking: analyzing data in an uncertain world. Princeton: Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/.\n\n\nSchwaiger, Elizabeth, und Rameen Tahir. 2022. „The impact of nomophobia and smartphone presence on fluid intelligence and attention“. Cyberpsychology: Journal of Psychosocial Research on Cyberspace 16 (1). https://doi.org/10.5817/CP2022-1-5.\n\n\nStigler, Stephen M. 2016. The seven pillars of statistical wisdom. Cambridge, Massachusetts: Harvard University Press.\n\n\nWard, Adrian F., Kristen Duke, Ayelet Gneezy, und Maarten W. Bos. 2017. „Brain Drain: The Mere Presence of One’s Own Smartphone Reduces Available Cognitive Capacity“. Journal of the Association for Consumer Research 2 (2): 140–54. https://doi.org/10.1086/691462.\n\n\nWickham, Hadley, und Garrett Grolemund. 2018. R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren. Übersetzt von Frank Langenau. 1. Auflage. Heidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "010-rahmen.html#footnotes",
    "href": "010-rahmen.html#footnotes",
    "title": "\n3  Rahmen\n",
    "section": "",
    "text": "Release 2023-Jan↩︎\nForschung und Entwicklung↩︎\nCeteris paribus, auf Latein, hört sich gleich viel schlauer an↩︎\n1. Pizza, 2. Spagetthi, 3. Schnitzel↩︎\ndie beiden Begriffe werden hier weitgehend synonym gebraucht↩︎\nAbrufdatum: 1.2.23↩︎"
  },
  {
    "objectID": "020-R.html#lernsteuerung",
    "href": "020-R.html#lernsteuerung",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n4.1.2 Lernziele\n\nSie können R und RStudio starten.\nSie können R-Pakete installieren und starten\nSie können Variablen in R zuweisen und auslesen.\nSie können Daten in R importieren.\nSie können den Begriff Reproduzierbarkeit definieren.\n\n4.1.3 Überblick\nAbbildung 1.2 zeigt Ihnen, wo auf unserer Reise durch die Datenanalyse sich dieses Kapitels verorten lässt.\nAbbildung 4.1 zeigt den typischen Lernverlauf in Zusammenhang mit Datenanalyse (und R) an: Es gibt Höhen und Tiefen. Die wechseln sich ab. Das ist ganz normal!\n\n\nAbbildung 4.1: Life is a roller-coaster. You just have to ride it. Image credit: Allison Horst\n\n\nQuelle\n\n\n4.1.4 Benötigte R-Pakete\n\nlibrary(easystats)\n\n\n4.1.5 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n4.1.6 Begleitvideos\nSchauen Sie sich mal in dieser Playlist um, dort finden Sie einige Videos zum Thema R."
  },
  {
    "objectID": "020-R.html#errrstkontakt",
    "href": "020-R.html#errrstkontakt",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.2 Errrstkontakt",
    "text": "4.2 Errrstkontakt\n\n4.2.1 Warum R?\nGründe, die für den Einsatz von R sprechen:\n\n🆓 R ist kostenlos, andere Softwarepakete für Datenanalyse sind teuer. 💸\n📖 R und R-Befehle sind quelloffen, d.h. man kann sich die zugrundeliegenden Computerbefehle anschauen. Jeder kann prüfen, ob es vernünftig arbeitet. Jeder kann beitragen.\n🆕 R hat die neuesten Methoden.\n🫂R hat eine große Community.\n🪡 R ist maßgeschneidert für Datenanalyse.\n\nAllerdings gibt es auch abweichende Meinungen, s. Abbildung 4.2.\n\n\nAbbildung 4.2: Nicht jeder ist R-Freund\n\n\n4.2.2 R und Reproduziebarkeit\n\nDefinition 4.1 (Reproduzierbarkeit) Ein (wissenschaftlicher) Befunde ist reproduzierbar, wenn andere Analystis mit dem gleichen experimentellen Setup zum gleichen Ergebnis (wie in der ursprünglichen Analyse) kommen (Plesser 2018). \\(\\square\\)\n\n\nDefinition 4.1 ist, etwas überspitzt, in Abbildung 4.3 wiedergegeben.\n\n\n\n\nAbbildung 4.3: Daten + Syntax + genaue Beschreibung der Messungen = reproduzierbar\n\n\n\n\nBeispiel 4.1 (Aus der Forschung: Reproduzierbarkeit in der Psychologie)  \n\n🧑‍🎓 Wie ist es um unsere Wissenschaft, Psychologie, bestellt? Haben die Befunde Hand und Fuß?\n\nObels u. a. (2020) haben die Reproduzierbarkeit in psychologischen Studien untersucht. Sie berichten folgendes Ergebnis\n\nWe examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. \\(\\square\\)"
  },
  {
    "objectID": "020-R.html#architektur-von-r",
    "href": "020-R.html#architektur-von-r",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.3 Architektur von R",
    "text": "4.3 Architektur von R\n\n4.3.1 R & RStudio\n\n\n\n\n\n💖\n\n\n\n\n\nIsmay und Kim (2020) zeigen eine schöne Analogie, was der Unterschied von R und RStudio ist, s. Abbildung 4.4.1\n\n\n\n\nAbbildung 4.4: R vs. RStudio: R macht die Arbeit, RStudio ist für Komfort und Übersicht\n\n\n\nWir verwenden beide Programme. Aber wir öffnen nur RStudio. RStudio findet selbständig R und öffnet diese “heimlich”. Öffnen Sie nicht noch extra R (sonst wäre R zweifach geöffnet).\nHier sehen Sie einen Screenshot von der Oberfläche von RStudio, s. Abbildung 4.5.\n\n\nAbbildung 4.5: So sieht RStudio aus\n\n\n4.3.2 Posit Cloud\nPosit Cloud2 ist ein Webdienst von Posit/RStudio (zum Teil kostenlos). Man kann damit online mit R arbeiten. Die Oberfläche ist praktisch identisch zur Desktop-Version, s. Abbildung 4.6. Ein Vorteil ist, dass man als Nutzer nichts installieren muss und dass es auch auf Tablets läuft (im Gegensatz zur Desktop-Version von R). Ein Nachteil ist, dass es etwas langsamer ist und nur für ein gewisses Zeitvolumen kostenlos.\n\n\nAbbildung 4.6: So sieht RStudio Cloud aus. Genau wie RStudio Desktop\n\n\n\n\n\n\n\nHinweis\n\n\n\nWenn Ihr Dozent Ihnen einen Projektordner bzw. einen Link dazu bereitstellt, ist das komfortabel, da der Dozent dann schon Pakete installieren, Daten bereitstellen und andere Nettigkeit vorbereiten kann für Sie. Allerdings müssen Sie den Projektordner in Ihrem Konto abspeichern, wenn Sie etwas speichern möchten, da Sie vermutlich keine Schreibrechte im Projektordner Ihres Dozenten haben. Klicken Sie dazu auf “Save a permanent copy”, s. Abbildung 4.7.\\(\\square\\)\n\n\n\n\nAbbildung 4.7: Einen Projektordner im eigenen Konto abspeichern, um Schreibrechte zu haben\n\nSie können auch von der Cloud exportieren, also Ihre Syntaxdatei herunterladen. Klicken Sie dazu im Reiter “Files” auf More &gt; Export ....\n\n4.3.3 Installation\nLesen Sie hier die Installation von R und seiner Freunde nach.\n\n4.3.4 R-Pakete\nTypisch für R ist sein modularer Aufbau: Man kann eine große Zahl an Erweiterungen (“Pakete”) installieren, alle kostenlos.\nIn R Paketen “wohnen” Funktionen, also Dinge, die R kann, “Skills” sozusagen - wenn das Paket verfügbar (gestartet) ist.\nMan kann sich daher ein R-Paket vorstellen wie ein Buch: Wenn R es gelesen hat, dann kennt es die Inhalte. Diese Inhalte könnten irgendwelche Formeln, also Berechnungen sein. Es könnte aber die “Bauanleitung” für ein schönes Diagramm sein.\nIst ein spezielles R-Paket auf Ihrem Computer vorhanden, so können Sie diese Funktionalität nutzen.\nDie Zahl an diesen “Paketen” ist groß; zur Verdeutlichung s. Abbildung 4.8.\n\n\nAbbildung 4.8: Containershiff, Corey Seeman, CC-BY-NC 20, Flickr.com\n\nErweiterungen kennt man von vielen Programmen, sie werden auch Add-Ons, Plug-Ins oder sonstwie genannt.\nMan siehe zur Verdeutlichung Erweiterungen beim Broswer Chrome, Abbildung 4.9.\n\n\nAbbildung 4.9: Erweiterungen beim Browser Chrome\n\nDie Anzahl der R-Pakete ist groß; allein auf dem “offiziellen Web-Store” (nennt sich “CRAN”) von R gibt es ca. 20,000 Pakete (Abbildung 4.10); Stand: 2022; Quelle).\n\n\nAbbildung 4.10: Die Anzahl der R-Pakete ist expoenziell gewachsen\n\n\n4.3.4.1 Pakete installieren\nWie jede Software muss man Pakete (Erweiterungen für R) erst einmal installieren, bevor man sie verwenden kann. Ja, einmal installieren reicht.\nDas geht komfortabel, wenn man beim Reiter Packages auf Install klickt (s. Abbildung 4.11) und dann den Namen des zu installierenden Pakets eingibt.\n\n\n\n\n\n(a) Klicken Sie auf “Install” im Reiter “Packages”, um R-Pakete zu installieren\n\n\n\n\n\n(b) So kann man R-Pakete installieren in RStudio\n\n\n\nAbbildung 4.11: So installiert man Pakete in R.\n\n\nDann öffnet sich ein Menü, wo man die Namen der gewünschten R-Pakete eingeben kann (s. Abbildung Abbildung 4.12).\n\n\nAbbildung 4.12: Hier den oder die Namen der gewünschten R-Pakete eingeben\n\n\n🧑‍🎓Welche R-Pakete sind denn schon installiert?\n\nIm Reiter Packages können Sie nachschauen, welche Pakete auf Ihrem Computer schon installiert sind. Diese Pakete brauchen Sie logischerweise dann nicht noch mal installieren.\n\n🧑‍🎓Ja, aber welche R-Pakete “soll” ich denn installieren, welche brauch ich denn?\n\nIm Moment sollten Sie die folgenden Pakete installiert haben:\n\ntidyverse\neasystats\n\nWenn Sie die noch nicht installiert haben sollten, dann können Sie das jetzt ja nachholen.3\n\n\n\n\n\n\nHinweis\n\n\n\nIhre R-Pakete sollten aktuell sein. Klicken Sie beim Reiter Packages auf “Update”, um Ihre R-Pakete zu aktualisieren. Arnold Schwarzenegger rät, Ihre R-Pakete aktuell zu halten, s. Abbildung 4.13.\n\n\n\n\nAbbildung 4.13: R-Pakete sollten stets aktuell sein, so Arnold Schwarzenegger\n\n\nmade at https://imgflip.com/memegenerator\n\n\n\n\n\n\n\nVorsicht\n\n\n\nBevor Sie ein R-Paket (oder überhaupt irgendwelche Software) installieren/updaten, sollten Sie das R-Paket schließen/beenden. Sonst schrauben Sie an einem elektrischen Gerät herum, das noch unter Strom steht (nicht gut). Die einfachste Art, alle Pakete zu beenden ist, Session &gt; Restart R zu klicken (in RStudio).\\(\\square\\)\n\n\n\n4.3.4.2 Pakete updaten\nKlicken Sie im Reiter Packages (in RStudio) und dort auf den Button Update.4\nDenken Sie daran, dass Sie das Paket, das Sie updaten/installieren, nicht laufen darf.\n\n4.3.4.3 Pakete starten\nWenn Sie ein Softwareprogramm - nichts anderes sind R-Pakete - installiert haben, müssen Sie es noch starten.\nMerke: Ein bestimmtes Paket muss man nur einmalig installieren. Aber man muss es jedes Mal neu starten, wenn man R (bzw. RStudio) startet.\nSie erkennen leicht, ob ein Paket gestartet ist, wenn Sie ein Häkchen vor dem Namen des Pakets in der Paketliste (Reiter Packages) sehen, s. Abbildung Abbildung 4.11 (a).\nDieses Video verdeutlicht den Unterschied zwischen Installation und Starten eines R-Pakets.\n\n4.3.5 Projekte in R\nEin Projekt in RStudio (s. Abbildung 4.14) ist letztlich ein Ordner, der als “Basis” für eine Reihe von Dateien verwendet wird. Sagen wir, das Projekt heißt cool_stuff. RStudio legt uns diesen Ordner an einem von uns gewählten Platz auf unserem Computer an. Das ist ganz praktisch, weil man dann sagen kann “Hey R, nimmt die Datei ‘daten.csv’”, ohne einen Pfad anzugeben. Vorausgesetzt, die Datei liegt auch im Projektordner (cool_stuff).\nProjekte kann anlegen mit Klick auf das Icon, das einen Quader mit dem Buchstaben R darin anzeigt (s. Abbildung 4.14 (a)). RStudio-Projekte machen Ihr Leben leichter (s. Abbildung 4.14).\n\n\n\n\n\n(a) RStudio-Projekte, Beispiele\n\n\n\n\n\n(b) RStudio-Projekte sind viel sicherer als das Arbeitsverzeichnis von Hand zu wählen oder mit Pfaden herumzubasteln. Image credit: Allision Horst\n\n\n\nAbbildung 4.14: Nutzen Sie RStudio-Projekte, das macht Ihr Leben leichter.\n\n\n\n4.3.6 Skriptdateien\nDie R-Befehle (“Syntax”) schreiben Sie am besten in eine speziell dafür vorgesehene Textdatei in RStudio. Eine Sammlung von (R-)Computer-Befehlen nennt man auch ein Skript, daher spricht man auch von einer Skriptdatei. Um eine neue R-Skriptdatei zu öffnen, klicken Sie auf das Icon, das ein weißes Blatt mit einem grünen Pluszeichen zeigt, s. Abbildung 4.15.\n\n\nAbbildung 4.15: So erstellen Sie eine neue Skriptdatei\n\nVergessen Sie nicht zu speichern, wenn Sie ein tolles Skript geschrieben haben. Dafür gibt es mehrere Möglichkeiten:\n\nStrg+S\nMenü: File &gt; Save\nKlick auf das Icon mit der Diskette, s. Abbildung 4.15.\n\nEine Skriptdatei können Sie in typischer Manier öffnen:\n\nStrg+O\nKlick auf das Icon mit der Akte und dem grünen Pfeil (vgl. Abbildung 4.15)\nMenü: File &gt; Open File..."
  },
  {
    "objectID": "020-R.html#grundlagen-von-r",
    "href": "020-R.html#grundlagen-von-r",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.4 Grundlagen von R",
    "text": "4.4 Grundlagen von R\n\n\n\n\n\n\nHinweis\n\n\n\nR ist penibel: So sind name und Name zwei verschiedene Variablen für R. Groß- und Kleinschreibung wird von R genau beachtet! Hingegen ist es R egal, ob Sie zur besseren Übersichtlichkeit Leerzeichen in Ihre Syntax tippen. Ausnahme sind spezielle Operatoren wie &lt;- oder &lt;=.\nEine gute Nachricht: Wenn R etwas von WARNING (bzw. Warnung) sagt, können Sie das zumeist ignorieren. Eine Warnung ist kein Fehler (ERROR) und meistens nicht gravierend oder nicht dringend. Im Zweifel ist Googeln eine gute Idee. Nur wenn R von Error spricht, ist es auch ein Fehler.\\(\\square\\)\n\n\n\n4.4.1 Variablen\nIn jeder Programmiersprache kann man Variablen definieren, so auch in R:\n\nrichtige_antwort = 42\nfalsche_antwort = 43\ntyp = \"Antwort\"\nist_korrekt = TRUE\n\nAlternativ zum Gleichheitszeichen = können Sie auch (synonym) den Zuweisungspfeil &lt;- verwenden. Beides führt zum gleichen Ergebnis. Allerdings ist der Zuweisungspfeil präziser, und sollte daher bevorzugt werden.\nDer Zuweisungspfeil &lt;- bzw. das Gleichheitszeichen = definiert eine neue Variable (oder überschreibt den Inhalt, wenn die Variable schon existiert).\n\nrichtige_antwort &lt;- 42\nfalsche_antwort &lt;- 43\ntyp &lt;- \"Antwort\"\nist_korrekt &lt;- TRUE\n\nDieses Video und dieses Video geben eine Einführung in das Definieren von Variablen in R.\nSie können sich eine Variable wie einen Becher oder Behälter vorstellen, der bestimmte Werte enthält. Auf dem Becher steht (mit Edding geschrieben) der Name des Bechers. Natürlich können Sie die Werte aus dem Becher entfernen und sie durch neue ersetzen (vgl. Abbildung 4.16).\n\n\nAbbildung 4.16: Variablen zuweisen\n\nR kann übrigens auch rechnen:\n\ndie_summe &lt;- falsche_antwort + richtige_antwort\n\nAber was ist jetzt der Wert, der “Inhalt” der Variable die_summe?\nUm den Wert, d.h. den Inhalt einer Variablen in R auszulesen, geben wir einfach den Namen des Objekts ein:\n\ndie_summe\n## [1] 85\n\nWas passiert wohl, wenn wir die_summe jetzt wie folgt definieren?\n\ndie_summe &lt;- falsche_antwort + richtige_antwort + 1\n\nWer hätt’s geahnt:\n\ndie_summe\n## [1] 86\n\nVariablen können auch “leer” sein:\n\nalter &lt;- NA\nalter\n## [1] NA\n\nNA steht für not available, nicht verfügbar und macht deutlich, dass hier ein Wert fehlt.\n\n🧑‍🎓 Wozu brauche ich bitte fehlende Werte?!\n\nFehlende Werte sind ein häufiges Problem in der Praxis. Vielleicht hat sich die befragte Person geweigert, ihr Alter anzugeben5. Oder als Sie die Daten in Ihren Computer eingeben wollten, ist Ihre Katze über die Tastatur gelaufen und alles war futsch…\n\n4.4.2 Funktionen - “Befehle”\n\n4.4.2.1 Vektoren erstellen\nDas, was R kann, ist in “Funktionen” hinterlegt. Ein Beispiel für eine solche Funktion könnte sein: “Berechne den Mittelwert” (schauen wir uns gleich an).\nEin weiteres Beispiel für eine Funktion ist: “Erstelle eine Liste (Vektor) von Werten”.\nDas geht so:\n\nAntworten &lt;- c(42, 43)\n\nDer Befehl c (c wie combine) fügt mehrere Werte zusammen zu einer “Liste” (einem Vektor).6\n\nDefinition 4.2 Als Vektor bezeichnen wir eine geordnete Folge von Werten. In R kann man sie mit dem Befehl c() erstellen. Die Werte eines Vektors bezeichnet man auch als Elemente.\\(\\square\\)\n\nMit dem Zuweisungspfeil geben wir diesem Vektor einen Namen, hier Antworten. Dieser Vektor besteht aus zwei Werten, zuerst 42, dann kommt 43.\n\nBeispiel 4.2 (Beispiele für Vektoren) Vektoren können (praktisch) beliebig lang sein, z.B. drei Elemente.\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 3)  # x und y sind ungleich!\nnamen &lt;- c(\"Anni\", \"Bert\", \"Charli\") # Text-Vektor\n\n\nZwei wichtige Typen von Vektoren sind numerische Vektoren (reelle Zahlen; in R auch als numeric oder double bezeichnet) und Texvektoren, in R auch als String oder character bezeichnet.\n\n4.4.3 Unsere erste statistische Funktion\nJetzt wird’s ernst. Jetzt kommt die Statistik. Berechnen wir also unsere erste statistische Funktion: Den Mittelwert. Puh.\n\nmean(Antworten)\n## [1] 42.5\n\nSie hätten Antworten auch durch c(42, 43) ersetzen können, so haben Sie ja schließlich die Variable gerade definiert.\nR arbeitet so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: mean(Antworten)\n  ⬇️ \nSchritt 1: mean(c(42, 43))\n  ⬇️ \nSchritt 2: 42.5\n\n4.4.3.1 Schema einer Funktion\nAbbildung 4.17 stellt eine Funktion schematisch dar.\n\n\nAbbildung 4.17: Schema einer Funktion\n\nEine Funktion hat einen oder mehrere Inputs, das sind Daten oder Verarbeitungshinweise, die man in die Funktion fun eingibt, bevor sie loslegt. Eine Funktion hat immer (genau) eine Ausgabe (Output), in der das Ergebnis einer Funktion ausgegeben wird.\n\nDefinition 4.3 (Argumente einer Funktion) Die “Trichter” einer (R-)Funktion, in denen man die Eingaben “einfüllt”, nennt man auch Argumente.\\(\\square\\)\n\nSo hat die Funktion mean() z.B. folgende Argumente:\nmean(x, trim = 0, na.rm = FALSE, ...)\n\n\nx: das ist der Vektor, für den der Mittelwert berechnet werden soll\n\ntrim = 0: Sollen die extremsten Werte von x lieber “abgeschnitten” werden, also nicht in die Berechnung des Mittelwerts einfließen?\n\nna.rm = FALSE: Wie soll mit fehlenden Werten NA umgegangen werden? Im Standard liefert mean7 NA zurück. R schwenkt sozusagen die rote Fahne, um zu signalisieren, Achtung, Mensch, hier ist irgendwas nicht in Ordnung. Setzt man aber na.rm = TRUE, dann entfernt (remove, rm) R die fehlenden Werte und berechnet den Mittelwert.\n\n... heißt “sonstiges Zeugs, das manchmal eine Rolle spielen könnte”; darum kümmern wir uns nicht.\n\nEinige Argumente haben einen Standardwert bzw. eine Voreinstellung (default). So wird bei der Funktion mean im Standard nicht getrimmt (trim = 0) und fehlende Werte werden nicht entfernt (na.rm = FALSE).\n\n\n\n\n\n\nHinweis\n\n\n\nWenn ein R-Befehl ein Argument mit Voreinstellung hat, brauchen Sie dieses Argument nicht zu befüllen. In dem Fall wird auf den Wert der Voreinstellung zurückgegriffen. Argumente ohne Voreinstellung - wie x bei mean() - müssen Sie aber auf jeden Fall mit einem Wert befüllen.\\(\\square\\)\n\n\nSagen wir, wir haben einen fehlenden Wert in unseren Daten:\n\nAntworten &lt;- c(42, 43, NA)\nAntworten\n## [1] 42 43 NA\n\nWenn wir jetzt den Mittelwert berechnen wollen, quittiert R das mit einem schnöden NA:\n\nmean(Antworten)\n## [1] NA\n\nR meint es gut mit Ihnen8. Stellen Sie sich vor, dass R Sie auf dieses Problem aufmerksam machen möchte:\n\n🤖 Achtung, lieber Herr und Gebieter, du hast nicht mehr alle Latten am Zaun, will sagen, alle Daten im Vektor!\n\n(Danke, R.)\nMöchten Sie aber lieber R dieses Verhalten austreiben, so befüllen Sie das Argument na.rm mit dem Wert TRUE.\n\nmean(Antworten, na.rm = TRUE)\n## [1] 42.5\n\nBei jedem R-Befehl haben die Argumente eine bestimmte Reihenfolge, etwa bei mean(): mean(x, trim = 0, na.rm = FALSE, ...).\n(Nur) wenn man die Argumente in ihrer vorgegebenen Reihenfolge anspricht, muss man nicht den Namen des Arguments anführen:\n✅ mean(Antworten, 0, FALSE)\nHält man sic aber nicht an die vorgebene Reihenfolge, so weiß R nicht, was zu tun ist und flüchtet sich in eine Fehlermeldung:\n\nmean(Antworten, FALSE, 0)  # FALSCH, DON'T DO IT 🙅‍♀️\n## Error in mean.default(Antworten, FALSE, 0): 'trim' must be numeric of length one\n\nWenn man die Namen der Argumente anspricht, ist die Reihenfolge egal:\n\nmean(na.rm = FALSE, x = Antworten)\nmean(trim = 0, x = Antworten, na.rm = TRUE)\n\nÜbrigens: Leerzeichen sind R fast immer egal. Aus Gründen der Übersichtlichkeit sollte man aber Leerzeichen verwenden. In diesen Fällen sind Leerzeichen nicht erlaubt:\n\n&lt;-\n\n&lt;= etc.\nVariablennamen\n\n4.4.4 Vektorielles Rechnen\nDas Rechnen mit Vektoren in R bezeichnen wir als vektorielles Rechnen. Das ist ein praktische Angelegenheit, man kann z.B. folgende Dinge einfach in R ausrechnen.\nGegeben x als Vektor (1, 2, 3) können wir die Differenz (Abweichung) jedes Elements von x zum Mittelwert von x komfortabel so ausrechnen:\n\nx - mean(x)\n## [1] -1  0  1\n\nEtwas fancier ausgedrückt: Wir haben die Funktion mit Namen “Differenz” (“Minus-Rechnen”) auf jedes Element von x angewandt. Im Einzelnen haben wir also folgenden drei Differenzen ausgerechnet:\n\n1 - 2\n2 - 2\n3 - 2\n\n\n\n\n\nAbbildung 4.18: Schema des vektoriellen Rechnens: Eine Funktion wird auf jedes Elemnt eines Vektors angewandt\n\n\n\n\n4.4.5 Häufige Fragen\n\n\nWo finde ich Hilfe zu einer bestimmten Funktion, z.B. fun()? Geben Sie dazu folgenden R-Befehl ein: help(fun).\n\nIn welchem Paket wohnt meine R-Funktion? Suchen Sie nach der Funktion auf dieser Seite.\n\nIch weiß nicht, wie der R-Befehl funktioniert? Vermutlich haben andere Ihr Problem auch, und meistens hat irgendwer das Problem schon gelöst. Am besten suchen Sie mal auf Stackoverflow.\n\nIch muss mal grundlegend verstehen, wozu ein bestimmten R-Paket gut ist. Was tun? Lesen Sie die Dokumenation (“Vignette”) eines R-Pakets durch. Für das Paket dplyr bekommen Sie so einen Überblick über die verfügbaren Vignetten diese Pakets: vignette(package = \"dplyr\"). Dann suchen Sie sich aus der angezeigten Liste eine Vignette raus; mit vignette(\"rowwise\") können Sie sich dann die gewünschte Vignette (z.B. rowwise) anzeigen lassen.\n\nOh nein, ich seh rot, das heißt, R zeigt mir irgendwas in roter Schrift an. Ist jetzt was kaputt? Keine Sorge, R ist in seiner Ausgabe nicht sparsam mit roter Frabe. Solange es nicht als Fehlermeldung (ERROR) erscheint, ist es meist kein Problem.\n\n4.4.6 Hilfe?! Erbie!\nR will nicht, so wie Sie wollen? Sie haben das Gefühl, R verweigert störrisch den Dienst, vermutlich rein aus Boshaftigkeit, rein um Sie zu ärgern?\nAusführliches Googeln und ChatGPT befragen hat keine Lösung gebracht?\nKurz, Sie brauchen Hilfe von einem kundigen Menschen?9\nHier finden Sie eine Anleitung, wie man seinen Hilfeschrei so formuliert (ruft), dass er nicht nur gehört, sondern auch verstanden wird und einen anderen Menschen veranlasst und ermöglicht Ihnen zu helfen.\nAlso: Sie müssen Ihr Problem nachvollziehbar aber möglichst prägnant formulieren. Das nennt man auch ein ERBie, ein einfaches, reproduzierbare Beispiel Ihres Problems mit (R-)Syntax:\n\neinfach: die einfachste Syntax, die Ihr Problem bzw. die Fehlermeldung produziert. Es bietet sich an, einen einfachen, allgemein bekannten Datensatz zu verwenden, etwa mtcars\n\nreproduzierbar: Code (z.B. als Textdatei oder in einem Post), der die Fehlermeldung entstehen lässt\n\n\nBeispiel 4.3 (Beispiel für ein Erbie) Problem: Ich verstehe nicht, warum eine Fehlermeldung kommt Ziel: Ich möchte die Automatikautos filtern (am = 0) Was ich schon versucht habe: Ich habe folgende Posts gelesen …, aber ohne Erfolg Erbie:\n\ndata(mtcars)\nlibrary(dplyr)  # nicht \"tidyverse\", denn \"dplyr\" reicht\n\nmtcars %&gt;% \n  filter(am = 0)  # den kürzesten Code, der Ihren Fehler entstehen lässt!\n## Error in `filter()`:\n## ! We detected a named input.\n## ℹ This usually means that you've used `=` instead of `==`.\n## ℹ Did you mean `am == 0`?\n\nsessionInfo()  # gibt Infos zur R-Version etc. aus\n## R version 4.2.1 (2022-06-23)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Big Sur ... 10.16\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] see_0.8.0          report_0.5.7       parameters_0.21.1  performance_0.10.4\n##  [5] modelbased_0.8.6   insight_0.19.2     effectsize_0.8.3   datawizard_0.8.0  \n##  [9] correlation_0.8.4  bayestestR_0.13.1  easystats_0.6.0    lubridate_1.9.2   \n## [13] forcats_1.0.0      stringr_1.5.0      dplyr_1.1.2        purrr_1.0.1       \n## [17] readr_2.1.4        tidyr_1.3.0        tibble_3.2.1       ggplot2_3.4.2     \n## [21] tidyverse_2.0.0    knitr_1.43        \n## \n## loaded via a namespace (and not attached):\n##  [1] mvtnorm_1.2-2      lattice_0.21-8     zoo_1.8-12         digest_0.6.32     \n##  [5] utf8_1.2.3         R6_2.5.1           evaluate_0.21      coda_0.19-4       \n##  [9] pillar_1.9.0       rlang_1.1.1        multcomp_1.4-25    rstudioapi_0.14   \n## [13] Matrix_1.5-4.1     rmarkdown_2.23     splines_4.2.1      htmlwidgets_1.6.2 \n## [17] munsell_0.5.0      compiler_4.2.1     xfun_0.39          pkgconfig_2.0.3   \n## [21] htmltools_0.5.5    tidyselect_1.2.0   codetools_0.2-19   fansi_1.0.4       \n## [25] tzdb_0.3.0         withr_2.5.0        MASS_7.3-60        grid_4.2.1        \n## [29] jsonlite_1.8.7     xtable_1.8-4       gtable_0.3.3       lifecycle_1.0.3   \n## [33] magrittr_2.0.3     scales_1.2.1       estimability_1.4.1 cli_3.6.1         \n## [37] stringi_1.7.12     generics_0.1.3     vctrs_0.6.3        sandwich_3.0-2    \n## [41] TH.data_1.1-2      tools_4.2.1        glue_1.6.2         hms_1.1.3         \n## [45] emmeans_1.8.6      fastmap_1.1.1      survival_3.5-5     yaml_2.3.7        \n## [49] timechange_0.2.0   colorspace_2.1-0\n\nMit dem Paket reprex kann man sich R-Syntax schön formuliert ausgeben lassen. Das ist perfekt, um den Code dann in einem Forum (oder Mail) einzustellen. Dafür müssen Sie nur den Code auswählen, Strg-C drücken und dann reprex::reprex ausführen. Mit Strg-V können Sie die schön formatierte Syntax (sowie die Ausgabe, auch schön formatiert) dann irgendwohin pasten.\n\n\n\n\nvia GIFER\n\n\n\n\n\n\n\nTipp\n\n\n\nPosten Sie Ihr Erbie bei https://gist.github.com/ als “public gist”. Hier ist ein Beispiel.\\(\\square\\)"
  },
  {
    "objectID": "020-R.html#daten-importieren",
    "href": "020-R.html#daten-importieren",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.5 Daten importieren",
    "text": "4.5 Daten importieren\n\n4.5.1 Wo sind meine Daten?\nDamit Sie eine Datendatei importieren können, müssen Sie wissen, wo die Datei ist.\nSchauen wir uns zwei Möglichkeiten an, wo eine Datei liegen könnte.\n\nIrgendwo im Internet, z.B. hier\n\nIrgendwo auf Ihrem Computer, z.B. in Ihrem Projektordner\n\nIn beiden Fällen wird der “Aufenthaltsort” der Datei durch den Pfad (in welcher Ordnerhierarchie?) und den Namen definiert.\n\n\n\n\n\n\nHinweis\n\n\n\nWir werden in diesem Kurs häufiger mit dem Daten mariokart arbeiten; Sie finden ihn hier.10\n\n\n\n4.5.2 Gebräuchliche Datenformate\nDaten werden in verschiedenen Formaten im Computer abgespeichert; Tabellen häufig als\n\nExcel-Datei\nCSV-Datei\n\nIn der Datenanalyse ist das gebräuchlichste Format für Daten in Tabellenform die CSV-Datei. Das hat den Grund, weil dieses Format technisch schön einfach ist. Für uns Endverbraucher tut das nichts groß zur Sache, die CSV-Datei beherbergt einfach eine brave Tabelle in einer Textdatei, sonst nichts.\n🏋️‍♀️ Öffnen Sie mal eine CSV-Datei mit einem Texteditor (nicht mit Word und auch nicht mit Excel). Schauen Sie sich gut an, was Sie dort sehen und erklären Sie die Datenstruktur.\n\n4.5.3 Einlesen aus einem R-Paket\nIhr Datensatz schon in einem R-Paket gespeichert, können Sie ihn aus diesem R-Paket starten. Das ist die bequemste Option. Zum Beispiel “wohnt” der Datensatz mariokart im R-Paket openintro; hallo Mario (s. Abbildung 4.19)!\n\n\nAbbildung 4.19: Hallo, Mario\n\n\n\n\n\n\n\nTipp\n\n\n\nEin häufiger Fehler ist, dass man vergisst, dass man zuerst ein R-Paket installieren muss, bevor man es nutzen kann. Auf der anderen Seite muss man ein R-Paket (wie andere Software auch) nur ein Mal installieren - das Paket muss man ein Paket nach jedem Neustart von RStuio mit library() starten.\n\n\n\ndata(\"mariokart\", package = \"openintro\")\n\n\n4.5.4 Einlesen von einer Webseite\nHier ist eine Möglihckeit, Daten (in Form einer Tabelle) von einer Webseite (URL) in R zu importieren:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nHier ist eine weitere Möglichkeit:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nd &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nDer Unterschied ist, dass data_read viele Formate von Daten (Excel, CSV, SPSS, …) verkraftet, wohingeben read.csv nur Standard-CSV einlesen kann.\nSchauen wir uns die letzte R-Syntax en Detail an:\nHey R,\nhol das \"Buch\" easystats aus der Bücherei und lies es\ndefiniere als \"d\" die Tabelle,\ndie du unter der angegebenen URL findest.\nEs ist egal, welchen Namen Sie der Tabelle geben. Ich nehme oft d, d die Daten. Außerdem ist d kurz, muss man nicht so viel tippen.\nWerfen wir einen Blick in die Tabelle (engl. to glimpse):\n\nglimpse(d)\n## Rows: 143\n## Columns: 12\n## $ id          &lt;dbl&gt; 150377422259, 260483376854, 320432342985, 280405224677, 17…\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7…\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, …\n## $ cond        &lt;fct&gt; new, used, new, new, new, new, used, new, used, used, new,…\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9…\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00…\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47…\n## $ ship_sp     &lt;fct&gt; standard, firstClass, firstClass, standard, media, standar…\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,…\n## $ stock_photo &lt;fct&gt; yes, yes, no, yes, yes, yes, yes, yes, yes, no, yes, yes, …\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2…\n## $ title       &lt;fct&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW …\n\nHier findet sich eine Erklärung des Datensatzes.\n\n\nDownload einer Datendatei (CSV-Format) von einer Webseite\n\n\n4.5.5 Importieren von Ihrem Computer\nStellen Sie zuerst sicher, dass sich die Datendatei in Ihrem RStudio-Projektordner befindet. Dann können Sie die Datei einfach so importieren:\n\nd &lt;- data_read(\"mariokart.csv\")\n\nDieses Video erklärt die Schritte des Importierens einer Datendatei von Ihrem Computer.\n\n\n\n\n\n\nHinweis\n\n\n\nEs gibt verschiedene Formate, in denen (Tabellen-)Dateien in einem Computer abgespeichert werden. Die gebräuchlichsten sind CSV und Excel. Praktischerweise kann der R-Befehl data_read() viele verschiedene Formate automatisch einlesen, so dass wir uns nicht weiter um das Format kümmern brauchen. Der Vorteil von read.csv ist, dass Sie kein Extra-Paket installiert bzw. gestartet haben müssen.\n\n\n\n4.5.6 Dataframes\nEine in R importierte Tabelle heißt Dataframe.11\n\nDefinition 4.4 (Dataframe) Ein Dataframe (data frame; auch “Tibble” genannt12) ist ein Datenojbekt in R zur Darstellung von Tabellen. Dataframes bestehen aus einer oder mehreren Spalten. Spalten haben einen Namen, sozusagen einen “Spaltenkopf”. Alle Spalten müssen die gleiche Länge haben; anschaulich gesprochen ist eine Tabelle (in R) rechteckig. Jede Spalte einzeln betrachtet kann als Vektor aufgefasst werden.$square$\n\nTabelle 4.1 ist die Tabelle mit den Mariokart-Daten; etwas präziser gesprochen ein Dataframe mit Namen mariokart. Übrigens ist Tabelle 4.1 in Normalform (Tidy-Format), vgl. Definition 3.6.\n\n\n\n\n\n\nHinweis\n\n\n\nGeben Sie den Namen eines Dataframes ein, um sich den Inhalt anzeigen zu lassen. Mit dem Befehl View(mariokart) wird eine Excel ähnlich Tabellenansicht in RStudio geöffnet. Beachten Sie, dass Sie die Daten auf diese Weise nur anschauen, nicht ändern können.$square$\n\n\n\nmariokart\n\n\n\n Tabelle 4.1:  Der Dataframe ‘mariokart’"
  },
  {
    "objectID": "020-R.html#sec-logic",
    "href": "020-R.html#sec-logic",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.6 Logikprüfung",
    "text": "4.6 Logikprüfung\n\n🧑‍🎓 Wer will schon wieder wen prüfen?!\n\nIn diesem Abschnitt schauen wir uns Logikprüfungen an: Wir lassen R prüfen, ob eine Variable einen bestimmten Wert hat oder größer/kleiner als ein Referenzwert ist.\nDefinieren wir zuerst eine Variable, x.\n\nx &lt;- 42\n\nDann fragen wir R, ob diese Variable den Wert 42 hat.\n\nx == 42\n## [1] TRUE\n\n\n🤖 Hallo, Mensch. Ja, diese Variable hat den Wert 42.\n\n(Danke, R.)\nMöchte man mit R prüfen, ob eine Variable x einen bestimmten Wert (“Inhalt”) hat, so schreibt man:\nx == Wert.\n\n\n\n\n\n\nWichtig\n\n\n\nMan beachte das doppelte Gleichheitszeichen! Zur Prüfung auf Gleichheit muss man das doppelte Gleichheitszeichen verwenden.\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEin beliebter Fehler ist es, bei der Prüfung auf Gleichheit, nur ein Gleichheitszeichen zu verwenden, z.B. so: x = 73. Mit einem Gleichheitszeichen prüft man aber nicht auf Gleichheit, sondern man definiert die Variable, s. Kapitel 4.4.1.$¿square$\n\n\nPrüfungen mit dem logischen UND bzw. ODER sind in Kapitel 4.6 erläutert.\nTabelle 4.2 gibt einen Überblick über wichtige Logikprüfungen in R.\n\n\n\n\n Tabelle 4.2:  Logische Prüfungen in R"
  },
  {
    "objectID": "020-R.html#praxisbezug",
    "href": "020-R.html#praxisbezug",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.7 Praxisbezug",
    "text": "4.7 Praxisbezug\n\n🧑‍🎓Wird R in der Praxis wirklich genutzt? Oder ist R nur der Traum von (vielleicht verwirrten) Profs im Elfenbeinturm?\n\nSchauen wir uns dazu die Suchanfragen bei stackoverflow.com an, dem größten FAQ-Forum für Software-Entwicklung. Wir vergleichen Suchanfragen mit dem Tag [r] zu Suchanfragen mit dem Tag [spss]13. Die Ergebnisse sind in Abbildung Abbildung 4.20 dargestellt.\n\n\n\n\nAbbildung 4.20: Suchanfragen nach R bzw SPSS, Stand 2022-02-24\n\n\n\nDas ist grob gerechnet ein Faktor von 200 (der Unterschied von R zu SPSS). Dieses Ergebnis lässt darauf schließen, dass R in der Praxis viel mehr als Excel gebraucht wird.\n\n🧑‍🎓 Aber ist R wirklich ein Werkzeug, das mir im Job hilft?\n\nViele Firmen weltweit nutzen R zur Datenanalyse, wie diese Liste zeigt.\n\n👨‍🏫 R ist der Place-to-be für die Datenanalyse.\n\n\n🧑‍🎓 Aber ist Datenanalyse wirklich etwas, womit ich in Zukunft einen guten Job bekomme?\n\nBerufe mit Bezug zu Daten, Datenanalyse oder, allgemeiner, Künstlicher Intelligenz (artificial intelligence) gehören zu den am meisten wachsenden Berufen:\n\nArtificial intelligence (AI) continues to make a strong showing on our Emerging Jobs lists, which is no surprise. Many jobs that have risen up as a result of AI in ﬁelds like cybersecurity and data science and because it’s is so pervasive many roles may demand more knowledge of AI than you may think. For example, real estate and business development roles. Quelle: LinkedIn"
  },
  {
    "objectID": "020-R.html#aufgaben",
    "href": "020-R.html#aufgaben",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.8 Aufgaben",
    "text": "4.8 Aufgaben\n\nTyp-Fehler-R-01\nTyp-Fehler-R-02\nTyp-Fehler-R-03\nTyp-Fehler-R-04\nTyp-Fehler-R-06a\nTyp-Fehler-R-07\nTyp-Fehler-R-08-name-clash\nLogikpruefung1\nLogikpruefung2\nthere-is-no-package\nWertberechnen2\nWertzuweisen_mc\nargumente\nimport-mtcars\nWertzuweisen\nWertpruefen\nwrangle1\nrepro1-sessioninfo"
  },
  {
    "objectID": "020-R.html#vertiefung",
    "href": "020-R.html#vertiefung",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.9 Vertiefung",
    "text": "4.9 Vertiefung\nIn R gibt es oft viele Möglichkeiten, ein Ziel zu erreichen. Zum Beispiel haben wir hier den Befehl data_read() verwendet, um Daten zu importieren. Andere, gebräuchliche Befehle, die CSV-Dateien importieren, heißen read.csv() (aus dem Standard-R, kein Extra-Paket nötig) und read_csv() (aus dem Meta-Paket tidyverse). data_read() (aus dem Meta-Paket easystats) ist praktisch, da es viele verschiedenen Datenformate lesen kann und selbständig erkennt, um welches Datenformat (CSV, XLSX,…) es sich handelt.\n\n\n\n\n\n\nTipp\n\n\n\nSie können bei LinkedIn ein Zertifikat bekommen, das Ihre R-Kenntnisse dokumentiert. Praktischerweise wird das Zertifikat gleich Ihrem Profil zugeordnet.\\(\\square\\)\n\n\n\nÜbungsaufgabe 4.1 (Statistik-Meme) Suchen Sie ein schönes Meme zum Thema Statistik, Datenanalyse und Data Science. Hier ist ein Startpunkt.\\(\\square\\)\n\nDas Kombinieren von Funktionen kann kompliziert werden:\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x)-x)) \n## [1] 2\n\nDie Funktion abs(x) gibt den (Absolut-)Betrag von x zurück (entfernt das Vorzeichen, mit anderen Worten)."
  },
  {
    "objectID": "020-R.html#literaturhinweise",
    "href": "020-R.html#literaturhinweise",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.10 Literaturhinweise",
    "text": "4.10 Literaturhinweise\n“Warum R? Warum, R?” heißt ein Kapitel in Sauer (2019), das einiges zum Pro und Contra von R ausführt. In Kapitel 3 in der gleichen Quelle finden sich viele Hinweise, wie man R startet; In Kapitel 4 werden Grundlagen von “Errisch” erläutert; Kapitel 5 führt in Datenstrukturen von R ein (schon etwas anspruchsvoller). Alternativ bietet Kapitel 1 von Ismay und Kim (2020) einen guten Überblick."
  },
  {
    "objectID": "020-R.html#literatur",
    "href": "020-R.html#literatur",
    "title": "\n4  Daten einlesen\n",
    "section": "\n4.11 Literatur",
    "text": "4.11 Literatur\n\n\n\n\nIsmay, Chester, und Albert Young-Sun Kim. 2020. Statistical inference via data science: a ModernDive into R and the Tidyverse. Chapman & Hall/CRC the R Series. Boca Raton: CRC Press / Taylor & Francis Group. https://moderndive.com/.\n\n\nObels, Pepijn, Daniël Lakens, Nicholas A. Coles, Jaroslav Gottfried, und Seth A. Green. 2020. „Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology“. Advances in Methods and Practices in Psychological Science 3 (2): 229–37. https://doi.org/10.1177/2515245920918872.\n\n\nPlesser, Hans E. 2018. „Reproducibility vs. Replicability: A Brief History of a Confused Terminology“. Frontiers in Neuroinformatics 11 (Januar): 76. https://doi.org/10.3389/fninf.2017.00076.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866."
  },
  {
    "objectID": "020-R.html#footnotes",
    "href": "020-R.html#footnotes",
    "title": "\n4  Daten einlesen\n",
    "section": "",
    "text": "Streng genommen ist RStudio für die Datenanalyse irrelevant, aber RStudio ist praktisch, Sie werden es nicht missen wollen.↩︎\nfrüher hieß der Dienst “RStudio Cloud”↩︎\nÜbrigens sind tidyverse und easystats Pakete, die nur dafür da sind, mehrere Pakete zu installieren. So gehören z.B. zu tidyverse die Pakete ggplot (Daten verbildlichen) und dplyr (Datenjudo). Damit wir nicht alle Pakete einzeln installieren und starten müssen, bietet uns das Paket tidyverse den Komforat, alle die Pakete dieser “Sammlung” auf einmal zu starten. Praktisch.↩︎\nWenn die Anzahl der zu aktualisierenden Pakete groß ist, dann besser nicht alle auswählen, sondern nur ein paar. Dann die nächsten paar Pakete usw.↩︎\nDatenschutz!↩︎\nStreng genommen sollte man nicht von einer Liste sprechen, da es in R noch einen anderen Objekttyp gibt, der list heißt, und eine verallgemeinerte Form eines Vektors ist.↩︎\nund viele andere arithmetische Funktionen in R↩︎\n&gt; 🤖 Naja, manchmal.↩︎\n&gt;https://www.youtube.com/watch?v=2Q_ZzBGPdqE&gt;↩︎\nAuf dieser Webseite finden Sie eine große Zahl an Datensätzen. Nur für den Fall, dass Ihnen langweilig ist.↩︎\nEtwas vereinfach ausgedrückt.↩︎\nvon “tbl” wie Table↩︎\nDurchgeführt am 2022-02-24, 17:21 CET↩︎"
  },
  {
    "objectID": "030-aufbereiten.html#lernsteuerung",
    "href": "030-aufbereiten.html#lernsteuerung",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n5.1.2 Lernziele\n\nSie können folgende Verben des Datenjudo anwenden: arrange, filter, select, summarise, group_by, mutate\n\nSie können Daten in R importieren\nSie können R-Befehle mit der “Pfeife” verketten\n\n5.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n5.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n5.1.5 Frag den Bot\n\n👨‍🏫 Erkläre einem Fünfjährigen, warum Statistik nützlich ist.\n\n\n🤖 Okay, hör zu. Stell dir vor, du hast viele Spielzeugautos und du willst herausfinden, welches Auto am meisten bespielt wird. Du kannst jeden Tag zählen, wie oft du jedes Auto benutzt hast. Aber das wäre sehr mühsam und könnte schnell durcheinander gebracht werden. Stattdessen kannst du mit Statistik eine einfachere Methode finden. Du kannst zum Beispiel eine Liste machen und jedes Auto mit einer bestimmten Farbe markieren. Dann kannst du jeden Tag einfach zählen, wie oft du jede Farbe verwendet hast. Am Ende kannst du herausfinden, welches Auto am meisten bespielt wurde, indem du siehst, welche Farbe am meisten verwendet wurde. Das ist ein Beispiel dafür, wie Statistik uns dabei helfen kann, Muster in großen Datensätzen zu finden und Entscheidungen zu treffen, ohne alles einzeln zu zählen.\n\nQuelle: ChatGTP, 2023-02-09"
  },
  {
    "objectID": "030-aufbereiten.html#datenjudo",
    "href": "030-aufbereiten.html#datenjudo",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.2 Datenjudo",
    "text": "5.2 Datenjudo\n\n5.2.1 Die Wahrheit über Data Science\nDenkt man an Data Science, stellt man sich coole Leute vor (in San Francisco oder Berlin), die an abgefahrenen Berechnungen mit hoch komplexen statistischen Modellen für gigantische Datenmengen basteln. Tatsächlich besteht ein großer Teil der Arbeit aus dem Aufbereiten von Daten.\n\n5.2.2 Praxisbezug: Aus dem Alltag des Data Scientisten\nLaut dem Harvard Business Review allerdings, verbringen diese Leute “80%” ihrer Zeit mit dem Aufbereiten von Daten (Bowne-Anderson 2018). Ja: mit uncoolen Tätigkeiten wie Tippfehler aus Datensätzen entfernen oder die Daten überhaupt nutzbar und verständlich zu machen.\nDas zeigt zumindest, dass das Aufbereiten von Daten a) wichtig ist und b) dass man allein damit schon weit kommt. Eine gute Nachricht ist (vielleicht), dass das Aufbereiten von Daten keine aufwändige Mathematik verlangt, stattdessen muss man ein paar Handgriffe und Kniffe kennen. Daher passt der Begriff Datenjudo vielleicht ganz gut. Kümmern wir uns also um das Aufbereiten bzw. Umformen von Daten, um das Datenjudo.\\(\\square\\)\n\nBeispiel 5.1 Beispiele für typische Tätigkeiten des Datenjudos sind:\n\nZeilen filtern (z. B. nur Studentis des Studiengangs X)\nZeilen sortieren (z. B. Studenten mit guten Noten in den oberen Zeilen)\nSpalten wählen (z. B. 100 weitere Produkte ausblenden)\nSpalten in eine Zahl zusammenfassen (z. B. Notenschnitt der 1. Klausur)\nTabelle gruppieren (z. B. Analyse getrennt nach Standorten)\nWerte aus einer Spalte verändern oder neue Spalte bilden (z. B. Punkte in Prozent-Richtige umrechnen).\n… \\(\\square\\)\n\n\n\n\n5.2.3 Mach’s einfach\nEs gibt einen (einfachen) Trick, wie man umfangreiche Datenaufbereitung elegant geregelt kriegt, klingt fast zu schön, um wahr zu sein (s. Abbildung 5.1).\n\n\nAbbildung 5.1: Mach’s einfach. Made at imgflip.com, Meme Generator\n\nDer Trick besteht darin, komplexe Operationen in mehrere einfache Teilschritte zu zergliedern1. Man könnte vom “Lego-Prinzip” sprechen, s. Abbildung 5.2. Im linken Teil von Abbildung 5.2 sieht man ein (recht) komplexes Gebilde. Zerlegt man es aber in seine Einzelteile, so sind es deutlich einfachere geometrische Objekte wie Dreiecke oder Quadrate (rechter Teil des Diagramms).\n\n\nAbbildung 5.2: Das Lego-Prinzip\n\nDamit Sie es selber einfach machen können, müssen Sie selber Hand anlegen. Importieren Sie daher den Datensatz mariokart, z.B. so:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nglimpse(mariokart)\n## Rows: 143\n## Columns: 13\n## $ V1          &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n## $ id          &lt;int64&gt; 150377422259, 260483376854, 320432342985, 280405224677, …\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1, 7…\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, 6, …\n## $ cond        &lt;chr&gt; \"new\", \"used\", \"new\", \"new\", \"new\", \"new\", \"used\", \"new\", …\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 19.9…\n## $ ship_pr     &lt;dbl&gt; 4.00, 3.99, 3.50, 0.00, 0.00, 4.00, 0.00, 2.99, 4.00, 4.00…\n## $ total_pr    &lt;dbl&gt; 51.55, 37.04, 45.50, 44.00, 71.00, 45.00, 37.02, 53.99, 47…\n## $ ship_sp     &lt;chr&gt; \"standard\", \"firstClass\", \"firstClass\", \"standard\", \"media…\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 4858,…\n## $ stock_photo &lt;chr&gt; \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"ye…\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2…\n## $ title       &lt;chr&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW …\n\n\nBeispiel 5.2 Sie arbeiten immer noch bei dem großen Online-Auktionshaus. Mittlerweile haben Sie sich den Ruf des “Datenguru” erworben. Vielleicht weil Sie behauptet haben, Data Science sei zu 80% Datenjudo, das hat irgendwie Eindruck geschindet… Naja, jedenfalls müssen Sie jetzt mal zeigen, dass Sie nicht nur schlaue Sprüche draufhaben, sondern auch die Daten ordentlich abbürsten können. Sie analysieren dafür im Folgenden den Datensatz mariokart. Na, dann los.\\(\\square\\)"
  },
  {
    "objectID": "030-aufbereiten.html#die-verben-des-datenjudos",
    "href": "030-aufbereiten.html#die-verben-des-datenjudos",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.3 Die Verben des Datenjudos",
    "text": "5.3 Die Verben des Datenjudos\nIm R-Paket dplyr, das wiederum Teil des R-Pakets tidyverse ist, gibt es eine Reihe von R-Befehlen, die das Datenjudo in eine Handvoll einfacher Verben runterbrechen.2 Die wichtigsten Verben des Datenjudos schauen wir uns im Folgenden an.\nWir betrachten dazu im Folgenden einen einfachen (Spielzeug-)Datensatz, an dem wir zunächst die Verben des Datenjudos vorstellen, s. Tabelle 5.1.\n\n\n\n\n Tabelle 5.1:  Ein einfacher Datensatz von schlichtem Gemüt \n  \n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Verben des Datenjudos wohnen im Paket {dyplr}, welches gestartet wird, wenn Sie library(tidyverse) eingeben. Vergessen Sie, tidyverse zu starten, dann funktionieren diese Befehle nicht.\\(\\square\\)\n\n\n\n5.3.1 Tabelle sortieren: arrange\n\nSortieren der Zeilen ist eine einfache, aber häufige Tätigkeit des Datenjudos, s. Abbildung 5.3.\n\n\n\n\nAbbildung 5.3: Sinnbild für das Sortieren einer Tabelle mit arrange()\n\n\n\n\nBeispiel 5.3 (Was sind die höchsten Preise?) Sie wollen mal locker anfangen. Was sind denn eigentlich die höchsten Preise, für die das Spiel Mariokart über den Online-Ladentisch geht. Die entsprechende Spalte heißt offenbar total_pr. In Excel kann die Spalte, nach der man die Tabelle sortieren möchte, einfach anklicken. Ob das in R auch so einfach geht?\n\nmariokart_neu &lt;- arrange(mariokart, total_pr)\nmariokart_neu\n\n\n\n  \n\n\n\nÜbersetzen wir die R-Syntax ins Deutsche:\nHey R,\narrangiere (sortiere) `mariokart` nach der Spalte `total_pr`\nGar nicht so schwer.\\(\\square\\)\n\nÜbrigens wird in arrange() per Voreinstellung aufsteigend sortiert. Setzt man ein Minus vor der zu sortierenden Spalte, wird umgekehrt, also absteigend sortiert:\n\nmario_sortiert &lt;- arrange(mariokart, -total_pr)\n\n\n5.3.2 Zeilen filtern: filter\n\nZeilen filtern bedeutet, dass man nur bestimmte Zeilen (Beobachtungen) behalten möchte, die restlichen Zeilen brauchen wir nicht, weg mit ihnen. Wir haben also ein Filterkriterium im Kopf, anhand dessen wir die Tabelle filern, s. Abbildung 5.4.\n\n\n\n\nAbbildung 5.4: Sinnbild für das Filtern einer Tabelle mit filter()\n\n\n\n\nBeispiel 5.4 (Ob ein Foto für den Verkaufspreis nützlich ist?) Als nächstes kommt Ihnen die Idee, mal zu schauen, ob Auktionen mit Photo der Ware einen höheren Verkaufspreis erzielen als Auktionen ohne Photo.\n\nmariokart_neu &lt;- filter(mariokart, stock_photo == \"yes\")\nmariokart_neu\n\n\n\n  \n\n\n\nSie filtern also die Tabelle so, dass nur diese Auktionen im Datensatz verbleiben, welche ein Photo haben, mit anderen Worten, Auktionen (Beobachtungen) bei denen gilt: stock_photo == TRUE.\\(\\square\\)\n\n\nBeispiel 5.5 (Komplexeres Filtern) Angestachelt von Ihren Erfolgen möchten Sie jetzt komplexere Hypothesen prüfen: Ob wohl Auktionen von neuen Spielen und zwar mit Photo einen höheren Preis erzielen als die übrigen Auktionen?\nAnders gesagt haben Sie zwei Filterkriterien im Blick: Neuheit cond und Photo stock_photo. Nur diejenigen Auktionen, die sowohl Neuheit als auch Photo erfüllen, möchten Sie näher untersuchen.\n\nmario_filter1 &lt;- filter(mariokart, stock_photo == \"yes\" & cond == \"new\")\nmario_filter1\n\n\n\n  \n\n\n\nHm. Was ist mit den Auktionen, die entweder über ein Photo verfügen oder neu sind (oder beides)?\n\nmario_filter2 &lt;- filter(mariokart, stock_photo == \"yes\" | cond == \"new\")\nmario_filter2\n\n\n\n  \n\n\n\nHier könnte man noch viele interessante Hypothesen prüfen, denken Sie sich und tun das auch … \\(\\square\\)\n\n\n5.3.3 Spalten auswählen mit select\n\nEine Tabelle mit vielen Spalten kann schnell unübersichtlich werden. Da lohnt es sich, eine alte goldene Regel zu beachten: Mache die Dinge so einfach wie möglich, aber nicht einfacher. Wählen wir also nur die Spalten aus, die uns interessieren und entfernen wir die restlichen, s. Abbildung 5.5.\n\n\n\n\nAbbildung 5.5: Sinnbild für das Auswählen von Spalten mit select()\n\n\n\n\nBeispiel 5.6 (Fokus auf nur zwei Spalten) Ob wohl gebrauchte Spiele deutlich geringere Preise erzielen im Vergleich zu neuwertigen Spielen? Sie entschließen sich, mal ein Stündchen auf die relevanten Daten zu starren.\n\nmario_select1 &lt;- select(mariokart, cond, total_pr)\nmario_select1\n\n\n\n  \n\n\n\nAha (?)\\(\\square\\)\n\nDer Befehl select erwartet als Input eine Tabelle und gibt (als Output) eine Tabelle zurück - genau wie die meisten anderen Befehle des Datenjudos. Auch wenn Sie nur eine Spalte auswählen, bleibt es eine Tabelle, eben eine Tabelle mit nur einer Spalte.\nselect erlaubt Komfort; Sie können Spalten auf mehrere Arten auswählen, z.B.\n\nselect(mariokart, 1, 2)  # Spalte 1 und 2\nselect(mariokart, 2:5)  #  Spalten 2 *bis* 5 \nselect(mariokart, -1)  # Alle Spalte *bis auf* Spalte 1\n\nVertiefte Informationen zum Auswählen von Spalten mit select findet sich hier.\n\n5.3.4 Spalten zu einer Zahl zusammenfassen mit summarise\n\nSo eine lange Spalte mit Zahlen – mal ehrlich: wer blickt da schon durch? Viel besser wäre es doch, die Spalte total_pr zu einer Zahl zusammenzufassen, das ist doch viel handlicher. Kurz entschlossen fassen Sie die Spalte total_pr, den Verkaufspreis, zum Mittelwert zusammen, s. Abbildung 5.6.\n\n\n\n\nAbbildung 5.6: Spalten zu einer einzelnen Zahl zusammenfassen mit summaris()\n\n\n\n\nBeispiel 5.7 (Was ist der mittlere Verkaufspreis?)  \n\nmariokart_neu &lt;- summarise(mariokart, preis_mw = mean(total_pr))\nmariokart_neu\n\n\n\n  \n\n\n\nAha! Etwa 50$ erzielt so eine Auktion im Schnitt.\\(\\square\\)\n\nEin bisschen abstrakter gesprochen, fasst summarise also eine Spalte zu einer (einzelnen) Zahl zusammen, s. Gleichung 5.1.3\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\  \\\\  \\\\ \\\\ \\hline \\end{array} \\qquad \\rightarrow  \\qquad \\begin{array}{|c|} \\hline \\\\  \\hline \\end{array} \\tag{5.1}\\]\n\n5.3.5 Tabelle gruppieren\nEs ist ja gut und schön, zu wissen, was so ein Spiel im Schnitt kostet. Aber viel interessanter wäre es doch, denken Sie sich, zu wissen, ob die neuen Spiele im Schnitt mehr kosten als die alten? Ob R Ihnen so etwas ausrechnen kann?\n\n🤖 Ich tue fast alles für dich. 🧡\n\nAlso gut, R, dann gruppiere die Tabelle, s. Abbildung 5.7.\n\n\n\n\nAbbildung 5.7: Gruppieren von Datensätzen mit group_by()\n\n\n\nDurch das Gruppieren wird die Tabelle in “Teiltabellen” - entsprechend der Gruppen - aufgeteilt. Das sieht man der Tabelle aber nicht wirklich an. Aber alle nachfolgenden Berechnungen werden für jede Teiltabelle einzeln ausgeführt.\n\nBeispiel 5.8 (Mittlerer Preis pro Gruppe) Gruppieren alleine liefert Ihnen zwei (oder mehrere) Teiltabellen, etwa neue Spiele (Gruppe 1, new) vs. gebrauchte Spiele (Gruppe 2, used). Mit anderen Worten: Wir gruppieren anhand der Variable cond.\n\nmariokart_gruppiert &lt;- group_by(mariokart, cond)\n\nWenn Sie die neue Tabelle betrachte, sehen Sie wenig Aufregendes, nur einen Hinweis, dass die Tabelle gruppiert ist.\nJetzt können Sie an jeder Teiltabelle Ihre weiteren Berechnungen vornehmen, etwa die Berechnung des mittleren Verkaufspreises.\n\nsummarise(mariokart_gruppiert, preis_mw = mean(total_pr))\n\n\n\n  \n\n\n\nLangsam fühlen Sie sich als Datenchecker.. 🥷 🦹‍♀️. \\(\\square\\).\n\n\n5.3.6 Spalten verändern mit mutate\n\nImmer mal wieder möchte man Spalten verändern, bzw. deren Werte umrechnen, s. Abbildung 5.8.\n\n\n\n\nAbbildung 5.8: Spalten verändern/neu berechnen mit mutate()\n\n\n\n\nBeispiel 5.9 Der Hersteller des Computerspiels Mariokart kommt aus Japan; daher erscheint es Ihnen opportun für ein anstehendes Meeting mit dem Hersteller die Verkaufspreise von Dollar in japanische Yen umzurechnen. Nach etwas Googeln finden Sie einen Umrechnungskurs von 1:133.\n\nmariokart2 &lt;- mutate(mariokart, total_pr_yen = total_pr * 133)\nmariokart2 &lt;- select(mariokart2, total_pr_yen, total_pr)\nmariokart2\n\n\n\n  \n\n\n\nSicherlich werden Sie Ihre Gesprächspartner schwer beeindrucken.\\(\\square\\)\n\n\n5.3.7 Zeilen zählen mit count\n\nArbeitet man mit nominalskalierten Daten, ist (fast) alles, was man tun kann, das Zeilen zählen.4\nMan könnte z.B. fragen, wie viele neue und wie viele alte Spiele in der Tabelle (Dataframe) mariokart vorhanden sind.\n\nBeispiel 5.10 Nach der letzten Präsentation Ihrer Analyse hat Ihre Chefin gestöhnt: Oh nein, alles so kompliziert. Statistik! Himmel hilf! Kann man das niht einfacher machen? Anstelle von irgendwelchen komplizierten Berechnungen (Mittelwert?) möchten Sie beim nächsten Treffen nur zeigen, wie viele Computerspiele neu und wie viele gebraucht sind (in Ihrem Datensatz). Schlichte Häufigkeiten! Hoffentlich ist Ihre Chefin nicht wieder überfordert…\n\nmariocart_counted &lt;- count(mariokart, cond)\nmariocart_counted\n\n\n\n  \n\n\n\nAha! Es gibt mehr gebrauchte als neue Spiele.\\(\\square\\)\n\nJetzt könnte man noch den Anteil ergänzen: Welcher Anteil (der 143 Spiele in mariokart) ist neu, welcher gebraucht?\n\nmariocart_counted %&gt;% \n  mutate(Anteil = n / sum(n))\n\n\n\n  \n\n\n\n\n5.3.8 Fazit\ndie Befehle (“Verben”) des Tidyverse sind jeweils für einzelne, typische Aufgaben des Datenaufbereitens (“Datenjudo”) zuständig.\nTypischerweise erwarten diese Befehle eine Tabelle (▥) als Input und liefern eine Tabelle aus Output zurück, s. Abbildung 5.9.\n\n\n\n\nflowchart LR\n  A[\"▥\"] --&gt; B[tidyverse-Befehl] --&gt; C[\"▥\"] \n\n\nAbbildung 5.9: Tidyverse-Befehle erwarten normalerweise eine Tabelle (tibble) als Input und geben auch eine Tabelle zurück als Output"
  },
  {
    "objectID": "030-aufbereiten.html#die-pfeife",
    "href": "030-aufbereiten.html#die-pfeife",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.4 Die Pfeife",
    "text": "5.4 Die Pfeife\n🚬 👈 Das ist keine Pfeife, wie René Magritte 1929 in seinem berühmten Bild schrieb, s. Abbildung 5.11.\n\n\n\n\nAbbildung 5.10: Das ist keine Pfeife. Sondern ein Bild einer Pfeife\n\n\n\n\n\n%&gt;%\n\n\nSo sieht die Pfeife in R aus5.\n\n\n5.4.1 Russische Puppen\nComputerbefehle, und im Speziellen R-Befehle kann man “aufeinander” - oder vielmehr: ineinander - stapeln, so ähnlich wie eine russische Puppe (vgl. Kapitel 4.4.3).\nDefinieren wir zuerst einen Vektor x aus drei Zahlen:\n\nx &lt;- c(1, 2, 3)\n\nUnd dann kommt unser verschachtelter Befehl:\n\nsum(x - mean(x))\n## [1] 0\n\nWie schon erwähnt, arbeitet R so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: sum(x - mean(x))\n  ⬇️ \nSchritt 1: sum(x - 2)\n  ⬇️ \nSchritt 2: sum(-1, 0, 1)\n  ⬇️ \nSchritt 3: 0. Fertig. Puh.\nSoweit kann man noch einigermaßen folgen. Aber das Verschachteln kann man noch extremer machen, dann wird’s wild. Schauen Sie sich mal folgende (Pseudo-)Syntax an:6\n\nListing 5.1: Eine wild verschachtelte Sequenz von R-Befehlen\nfasse_zusammen(gruppiere(wähle_spalten(filter_zeilen(meine_daten))))\n\n\n5.4.2 Die Pfeife zur Rettung\nListing 5.1 ist schon harter Tobak, was für echte Fans. Wäre es nicht einfacher, man könnte Listing 5.1 wie folgt schreiben:\nNimm \"meine_daten\" *und dann*\n  filter gewünschte Zeilen *und dann*\n  wähle gewünschte Spalten *und dann*\n  teile in Subgruppen *und dann*\n  fasse sie zusammen.\n\n\n\n\n\n\nHinweis\n\n\n\nDer Befehl %&gt;% verknüpft Befehle, man nennt ihn “Pfeife” (pipe). Der Shortcut für diesen Befehl ist Strg-Shift-M. Die Pfeife %&gt;% “wohnt” im Paket tidyverse.7\n\n\nMittlerweile ist auch im Standard-R eine Pfeife eingebaut. die sieht so aus: |&gt;. Die eingebaute Pfeife funktioniert praktisch gleich zur anderen Pfeife %&gt;%, hat aber den Vorteil, dass Sie nicht tidyverse starten müssen. Da wir tidyverse aber sowieso praktisch immer starten werden, bringt es uns keinen Vorteil, die neuere Pfeife des Standard-R |&gt; zu verwenden.8\n\n\n\n\n\n\nflowchart TD\n  A[\"meine Daten 🗳\"] --filter_zeilen--&gt;B[\"▥\"] \n  B --wähle_spalten--&gt; C[\"▥\"]\n  C --gruppiere--&gt; D[\"▥\"]\n  D --fasse_zusammen--&gt; E[\"▥ Fertig. 🤩\"]\n\n\n\nAbbildung 5.11: Illustration für eine Pfeifensequenz\n\n\n\n\nUnd jetzt kommt’s: So eine Art von Befehls-Verkettung gibt es in R. Schauen Sie sich mal Listing 5.2 an:\n\nListing 5.2: Eine Pfeifen-Befehlssequenz (Pseudo-Syntax)\nmeine_daten %&gt;%\n  filter_gewünschte_zeilen() %&gt;%\n  wähle_gewünschte_spalten() %&gt;%\n  gruppiere() %&gt;%\n  fasse_zusammen() \n\nSo eine Pfeifen-Befehlsequenz ist ein wie ein Fließband, an dem es mehrere Arbeitsstationen gibt, s. Abbildung 5.11. Unser Datensatz wird am Fließband von Station zu Station weitergereicht und an jeder Stelle weiterverarbeitet.\n\n\n\n\n\n\n\nSo könnte Ihre “Pfeifen-Sequenz” aussehen:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")  # Daten einlesen nicht vergessen\n\nlibrary(tidyverse)  # Die Pfeife wohnt auch im Paket \"tidyverse\"\n\n# Hey R:\nmariokart %&gt;%   # nimm die Tabelle \"mariokart\" und dann...\n  filter(total_pr &lt; 100) %&gt;%  # filter nur die günstigen Spiele und dann...\n  select(cond, total_pr) %&gt;%  # wähle die zwei Spalten und dann ...\n  group_by(cond) %&gt;%  # gruppiere die Tabelle nach Zustand des Spiels und dann ...\n  summarise(total_pr_mean = mean(total_pr))  # fasse beide Gruppen nach dem mittleren Preis zusammen"
  },
  {
    "objectID": "030-aufbereiten.html#fallbeispiel",
    "href": "030-aufbereiten.html#fallbeispiel",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.5 Fallbeispiel",
    "text": "5.5 Fallbeispiel\n\n5.5.1 Forschungsfrage 1\n\n🧔‍♂️ Ich würde gerne wissen, was das teuerste Spiel ist, aber jeweils für neue und gebrauchte Spiele. Aber nur für Spiele, die mit Foto verkauft wurden!\n\n\nmariokart %&gt;% \n  filter(stock_photo == \"yes\") %&gt;% \n  group_by(cond) %&gt;% \n  summarise(total_pr_max = max(total_pr))\n\n\n\n  \n\n\n\nDie Funktion max liefert den größten Wert eines Vektors zurück:\n\nx &lt;- c(1, 2, 10)\nmax(x)\n## [1] 10\n\n\n5.5.2 Forschungsfrage 2\n\n🧔‍♂️ Ich würde gerne die mittlere Versandpauschale wissen, aber getrennt nach Anzahl der Lenkräder, die dem Spiel beigelegt sind. Und ich will nur Gruppen berücksichtigen, die aus mindestens 10 Spielen bestehen!\n\nWenn wir die Anzahl der Spiele zählen in Abhängigkeit der beigelegten Lenkräder (wheels), bekommen wir eine Tabelle mit zwei Spalten: wheels und n. n zählt, wie viele Spiele (Zeilen) in der jeweiligen Gruppe (“Teiltabelle”) von wheels sind.\n\nmariokart %&gt;%\n  count(wheels)\n\n\n\n  \n\n\n\nAus dieser Tabellet sehen wir, dass es 3 oder 4 Lenkräder nur selten (2 bzw. 1 Mal) beigelegt wurden und wir solche Spiele herausfiltern sollten bevor wir den Mittelwert der Versankosten ausrechnen:\n\nmariokart %&gt;%\n  filter(wheels &lt; 3) %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(mittlere_versandkosten = mean(ship_pr),\n            anzahl_spiele = n())\n\n\n\n  \n\n\n\nDie Funktion n() gibt die Anzahl der Zeilen pro Teiltabelle zurück.\n\n5.5.3 Forschungsfrage 3\n\n🧔‍♂️ Ich würde gerne den Verkaufspreis in Yen wissen, nicht in Euro. Dann rechne mal den mittleren Verkaufspreis aus und ziehe 10% ab, die wir als Provision unseren Verkäufern zahlen müssen.\n\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  mutate(total_pr_yen = total_pr * 133) %&gt;% \n  summarise(preis_yen_mw = mean(total_pr_yen),\n            preis_yen_mw_minus_10proz = preis_yen_mw - 0.1*preis_yen_mw)\n\n\n\n  \n\n\n\nWie man sieht kann man in summarise auch mehr als eine Berechnung einstellen. In diesem Fall haben wir zwei Berechnungen angestellt: Einmal den Mittelwert und einmal den Mittelwert minus 10% (des Mittelwerts)."
  },
  {
    "objectID": "030-aufbereiten.html#praxisbezug",
    "href": "030-aufbereiten.html#praxisbezug",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.6 Praxisbezug",
    "text": "5.6 Praxisbezug\nDie Covid19-Epidemie hatte weltweit massive Auswirkungen; auch psychologischer Art wie Vereinsamung, Angst oder Depression.\nEine Studie, die die psychologischen Auswirkungen von Mulukom u. a. (2020), die unter diesem Projekt bei der Open Science Foundation (OSF) angemeldet ist.\nDie Daten wurden mit R ausgewertet. Beispielhaft ist hier die R-Syntax zu sehen, die die Autoren zur Datenaufbereitung verwendet haben. Einen guten Teil dieser Syntax kennen Sie aus diesem Kapitel.\nDiese Studie ist, neben einigen vergleichbaren, ein schönes Beispiel, wie Forschung und Praxis ineinander greifen können: Angewandte Forschung als Beitrag zur Lösung eines akuten Problems, der Corona-Pandemie."
  },
  {
    "objectID": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "href": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.7 Wie man mit Statistik lügt",
    "text": "5.7 Wie man mit Statistik lügt\nEin (leider) immer mal wieder zu beobachtender “Trick”, um Daten zu frisieren ist, nur die Daten zu berichten, die einem in den Kram passen.\n\nBeispiel 5.11  \nEi Analysti 🧑‍🦰 möchte zeigen, dass der Verkaufspreis von Mariokart-Spielen “viel zu niedrig” ist. Es muss ein höherer Wert rauskommen, findet dis Analysti. Der mittlere Verkaufspreis (im Datensatz mariokart) liegt bei 50 Euro.\n\n‍🦰 Kann man den Wert nicht … “kreativ verbessern”? Ein paar Statistik-Tricks anwenden?\n\nUm dieses Ziel zu erreichen, teilt dis Analysti den Datensatz in Gruppen nach Anzahl der dem Spiel beigelegten Lenkräder (wheels). Dann berechnet er den Mittelwert pro Gruppe.\n\nmariokart_wheels &lt;- \nmariokart %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_mean = mean(total_pr),\n            count_n = n())  # n() gibt die Anzahl der Zeilen pro Gruppe an\n\nmariokart_wheels\n\n\n\n  \n\n\n\nSchließlich berechnet unser Analysti den ungewichteten Mittelwert über diese 5 Gruppen:\n\nmariokart_wheels %&gt;% \n  summarise(mean(pr_mean))\n\n\n\n  \n\n\n\nUnd das Ergebnis lautet: 56 Euro! Das ist doch schon etwas “besser” als 50 Euro.\nNatürlich ist es falsch und irreführend, hier einen ungewichteten Mittelwert zu berechnen. Der gewichtete Mittelwert würde wiederum zum korrekten Ergebnis, 50 Euro, führen.\\(\\square\\)"
  },
  {
    "objectID": "030-aufbereiten.html#fallstudie",
    "href": "030-aufbereiten.html#fallstudie",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.8 Fallstudie",
    "text": "5.8 Fallstudie\n\n\nAbbildung 5.12: Possierlich: Die Pinguine\n\nBearbeiten Sie die Fallstudie zu Pinguinen von Allison Horst. Sie können die Teile auslassen, die Themen beinhalten, die nicht in diesem Kapitel vorgestellt wurden."
  },
  {
    "objectID": "030-aufbereiten.html#aufgaben",
    "href": "030-aufbereiten.html#aufgaben",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.9 Aufgaben",
    "text": "5.9 Aufgaben\n\nwrangle3\nwrangle4\nwrangle5\nwrangle7\nwrangle9\nwrangle10\ntidydata1\naffairs-dplyr\ndplyr-uebersetzen\nhaeufigkeit01\nmariokart-mean1\nmariokart-mean2\nmariokart-mean3\nmariokart-mean4\nmariokart-max1\nmariokart-max2\nfilter01\naffairs-dplyr\nsummarise01\nsummarise02\nmutate01"
  },
  {
    "objectID": "030-aufbereiten.html#vertiefung",
    "href": "030-aufbereiten.html#vertiefung",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.10 Vertiefung",
    "text": "5.10 Vertiefung\n\n\n\n\n\n\nHinweis\n\n\n\nIn weiterführendem Material werden Sie immer wieder auf Inhalte treffen, die Sie noch nicht kennen, die etwa noch nicht im Unterricht behandelt wurden. Seien Sie unbesorgt: In der Regel können Sie diese Inhalte einfach auslassen, ohne den Anschluss zu verlieren. Einfach ignorieren. 😄\n\n\nHäufig ist es nützlich, die Werte einer Variablen umzukodieren, z.B. “weiblich” in “w” oder in 0. Eine gute Möglichkeit, dies in R umzusetzen, bietet der Befehl case_when(); der Befehl wohnt im Tidyverse. Hier - und an vielen weiteren Stellen im Internet - finden Sie ein Tutorium.\nWer sich tiefer in das Datenjudo mit dem Tidyverse einarbeiten möchte, dem sei z.B. dieser Kurs empfohlen.\nEin gutes und frei verfügbares Buch ist das von Wickham und Grolemund (2018); Kap. 5 behandelt (etwas ausführlicher) die Themen dieses Kapitels.\nDiese Fallstudie hat die Analyse von Flugverspätungen zum Thema.\n\n\nhttps://osf.io/z39us/\n\n\nThe COVIDiSTRESS global survey is an international collaborative undertaking for data gathering on human experiences, behavior and attitudes during the COVID-19 pandemic. In particular, the survey focuses on psychological stress, compliance with behavioral guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures, but multiple further items and scales are included for descriptive statistics, further analysis and comparative mapping between participating countries. Round one data collection was concluded May 30. 2020. To gather comparable data swiftly from across the globe, when the Coronavirus started making a critical impact on societies and individuals, the collaboration and survey was constructed as an urgent collaborative process. Individual contributors and groups in the COVIDiSTRESS network (see below) conducted translations to each language and shared online links by their own best means in each country.\n\nDie Daten stehen zur freien Verfügung. Sie können diese echten Daten eigenständig analysieren. Diese Datei beinhaltet die finalen, aufbereiteten Daten. Achtung: Die Datei ist recht groß, ca. 90 MB."
  },
  {
    "objectID": "030-aufbereiten.html#exkurs",
    "href": "030-aufbereiten.html#exkurs",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.11 Exkurs",
    "text": "5.11 Exkurs\nDall-E 2 ist eine KI, die “realistissche Bilder und Kust aus einer Beschreibung in natürlicher Sprache” erstellt.\n\n👨‍🏫 a mixture between robot und professor, oil painting\n\n\n🤖 … s. Abbildung 5.13\n\n\n\nAbbildung 5.13: Bild erzeugt von künstlicher Intelligenz, Quelle: DALL-E 2, 2023-02-09\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Nutzen künstlicher Intelligenz für die Datenanalyse ist natürlich breiter: Wenn Sie sich z.B. über die Syntax eines bestimmten Befehls (oder allgemeiner: Vorhabens) nicht sicher sind, fragen Sie sich doch mal einen Bot wie ChatGPT."
  },
  {
    "objectID": "030-aufbereiten.html#literatur",
    "href": "030-aufbereiten.html#literatur",
    "title": "\n5  Daten umformen\n",
    "section": "\n5.12 Literatur",
    "text": "5.12 Literatur\nSauer (2019), Kap. 7 gibt eine Einführung in die Datenaufbereitung (mit Hilfe von R), ähnlich zu den Inhalten dieses Kapitels.\n\n\n\n\nBowne-Anderson, Hugo. 2018. „What Data Scientists Really Do, According to 35 Data Scientists“. Harvard Business Review, August. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists.\n\n\nMulukom, Valerie van, Barbara Muzzulini, Bastiaan Rutjens, Caspar J. van Lissa, und Miguel Farias. 2020. „Psychological Impact of COVID-19 Pandemic“, März. https://doi.org/10.17605/OSF.IO/TSJNB.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nWickham, Hadley, und Garrett Grolemund. 2018. R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren. Übersetzt von Frank Langenau. 1. Auflage. Heidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "030-aufbereiten.html#footnotes",
    "href": "030-aufbereiten.html#footnotes",
    "title": "\n5  Daten umformen\n",
    "section": "",
    "text": "Genau darin besteht das Wesen einer Analyse: die Zerlegung eines Objekts in seine Bestandteile.↩︎\nFalls Sie das R-Paket tidyverse noch nicht installiert haben sollten, wäre jetzt ein guter Zeitpunkt dafür.↩︎\nEine Alternative, um eine Spalte zu einer Zahl zusammenzufassen, bietet der “Dollar-Operator” ($): mean(mariokart$total_pr). Der Dollar-Operator trennt hier die Tabelle von der Spalte: tibble$spalte. Im Gegensatz zu den Verben des Tidyverse (die immer einer Tabelle zurückliefern), liefert der Dollar-Operator einen Vektor (Spalte) zurück. (Diese wird von mean dann zu einer einzelnen Zahl zusammengefasst.)↩︎\nJa, das ist traurig.↩︎\nJaja, das ist keine Pfeife, sondern ein Symbol einer Pfeife…↩︎\nEin beliebter Fehler ist es übrigens, nicht die richtige Zahl an schließenden Klammern hinzuschreiben, z.B. fasse_zusammen(gruppiere(wähle_spalten(filter_zeilen(meine_daten)))) FALSCHE ZAHL AN KLAMMERN.↩︎\nGenauer gesagt im Paket magrittr, welches aber under the hood von tidyverse geladen wird. Also nichts, um dass Sie sich kümmern müssten.↩︎\nUnter Tools &gt; Global Options… können Sie einstellen, dass der Shortcut Strg-Shit-M die eingebaute Pfeife verwendet.↩︎"
  },
  {
    "objectID": "040-verbildlichen.html#lernsteuerung",
    "href": "040-verbildlichen.html#lernsteuerung",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n6.1.2 Lernziele\n\nSie können erläutern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arte von Datendiagrammen.\nSie können typische Datendiagramme mit R visualisieren.\nSie können zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n6.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\n\n\n6.1.4 Wozu das alles?\n\n\n\n. Quelle: GIPHY\n\n\n🥷 Wir müssen die Galaxis verteidigen, Kermit\n\n\n🐸 Schlock"
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "6.2 Ein Dino sagt mehr als 1000 Worte\nEs heißt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte, s. Abbildung 6.1.\n\n\nAbbildung 6.1: Dinosaurier und Kreis: Gleiche statistischen Kennwerte\n\n\nQuelle\n\nIn Abbildung 6.1 sieht man zwei verschiedene “Bilder”, also Datensätze: einmal einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschiedene sind, sind die zentralen statistischen Kennwerte (praktisch) identisch.\nIn die gleiche Bresche schlägt “Anscombes Quartett”, s. Abbildung 6.2: Es zeigt 4 Datensätze, in denen die zentralen Statistiken fast identisch sind, also Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthüllt, was der Statistik (als Kennzahl) verhüllt bleibt.\n\n\nAbbildung 6.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier Datensätzen\n\n\nQuelle\n\nUnter visueller Cortex ist sehr leistungsfähig. Wir können ohne Mühe eine große Anzahl an Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen.\n\n\n\n\n\n\nTipp\n\n\n\nNutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mächtig.\n\n\n\n6.2.1 Datendiagramm\nEin Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\nBeispiel 6.1 (Aus der Forschung: Ein aufwändiges (und ansprechendes) Datendiagramm) Hier finden Sie ein Beispiel für ein Datendiagramm, das mit R erzeugt wurde (Scherer u. a. 2019).\n\n\n6.2.2 Ein Bild hat nicht so viele Dimensionen\nAbbildung 6.3 zeigt ein Bild mit mehreren Variablen. Wie man (nicht) sieht, wird es langsam unübersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen reinquetschen. Die “Dimensionalität” eines Diagramms hat ihre Grenzen, vielleicht bei 4-6 Variablen.\n\n\n\n\nAbbildung 6.3: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen\n\n\n\nMöchten wir den Zusammenhang von vielen Variablen, z.B. mehr als 5, verstehen, kommen wir mit Bildern nicht weiter. Dann brauchen wir andere Werkzeuge: statistics to the rescue.\n\n\n\n\n\n\nHinweis\n\n\n\nBei klaren Zusammenhängen und wenig Variablen braucht man keine (aufwändige) Statistik. Ein Bild (Datendiagramm) ist dann (oft) ausreichend. Man könnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. 4-6 Variablen nicht gleichzeitig umgehen kann.\n\n\n\nÜbungsaufgabe 6.1 Wie viele Variablen sind in Abbildung 6.3 dargestellt?1\n\nEine weitere Möglichkeit, mehr Variablen in einem Diagramm unterzubringen, ist die “Flatlands” zu verlassen, also von 2D auf 3D zu wechseln, s. hier.\n#s. ?fig-3d-germany.\nQuelle: Plotly\n\n\nxoj"
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.3 Nomenklatur von Datendiagrammen",
    "text": "6.3 Nomenklatur von Datendiagrammen\nTabelle 6.1 zeigt eine - sehr kurze Nomenklatur - an Datendigrammen.2\n\n\n\n\nTabelle 6.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefülltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefülltes Balkendiagramm\nBoxplot\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nWir arbeiten hier mit dem Datensatz mariokart. Hilfe bzw. ein Data-Dictionary (Codebook) finden Sie hier."
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.4 Verteilungen verbildlichen",
    "text": "6.4 Verteilungen verbildlichen\n\n6.4.1 Verteilung: nominale Variable\n\nDefinition 6.1 (Verteilung) Eine (Häufigkeits-)Verteilung einer Variablen \\(X\\) schlüsselt auf, wie häufig jede Ausprägung von \\(X\\) ist.\\(\\square\\)\n\n\nBeispiel 6.2 Tabelle 6.2 zeigt die Häufigkeitsverteilung von cond aus dem Datensatz mariokart. Die Variable hat 5 Ausprägungen; z.b. kommt die Ausprägung new 59 mal vor.\\(\\square\\)\n\n\n\n\n\n Tabelle 6.2:  Häufigkeitsverteilung von cond aus dem Datensatz\nmariokart \n  \n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. Abbildung 6.4. Wie man sieht, besteht so ein Diagramm als Balken, daher heißt es Balkendiagramm. Man kann so ein Diagramm um 90° drehen, keine Ausrichtung ist unbedingt besser als die andere.\n\nDefinition 6.2 (Balkendiagramm) Ein Balkendiagramm eignet sich, um Häufigkeiten darzustellen\n\n\n\n\n\nAbbildung 6.4: Häufigkeitsverteilung der Variable cond\n\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. Abbildung 6.5.\nZuerst importieren wir die Daten, s. Listing 6.1.\n\nListing 6.1: Mariokart-Daten importieren von einer Webseite\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nAußerdem nicht vergessen, das Paket DataExplorer zu starten, s. Listing 6.2.3 In diesem Paket “wohnen” die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden.\n\nListing 6.2: Wir starten das R-Paket DataExplorer\nlibrary(DataExplorer)\n\n\nListing 6.3: Syntax zur Erstellung eines Histogramms\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\nListing 6.4: Syntax zur Erstellung eines Balkendiagramms\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\nDie Syntax ist in Listing 6.4 abgedruckt. Übersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz mariokart *und dann*\n  wähle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm.\n\nÜbungsaufgabe 6.2 (Spalten wählen für das Balkendiagramm) Hätten wir andere Spalten ausgewählt, so würde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie können auch mehrere Variablen auf einmal auswählen. Probieren Sie das doch mal aus!\n\n\n\n\n\nAbbildung 6.5: Balkendiagramm mit dem R-Paket DataExplorer\n\n\n\n\n\n6.4.2 Verteilung: quantitative Variable\n\n6.4.2.1 Histogramm\nBei einer quantitativen Variablen mit vielen Ausprägungen wäre ein Balkendiagramm nicht so aussagekräftig, s. Abbildung 6.6. Es gibt einfach zu viele Ausprägungen.\n\n\n\n\nAbbildung 6.6: Balkendiagramm für total_pr\n\n\n\nDie Lösung: Wir reduzieren die Anzahl der Ausprägungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger Ausprägungen zu bekommen, können wir einfach Gruppen definieren, z.B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 2: 11-15 Dollar …\n\nIn Abbildung 6.7 sind z.B. die Ausprägungen des Verkaufspreis (total_pr) in in Gruppen der Breite von 5 Dollar aufgeteilt worden. Zusätzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\nAbbildung 6.7: Balkendiagramm für total_pr\n\n\n\n\nDefinition 6.3 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der Häufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt sind. Die Höhe der Balken zeigt die Häufigkeit der Daten in dieser Gruppe/in diesem Balken4.\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten nicht sehr viele und nicht sehr wenig sein, s. Abbildung 6.8 links bzw. Abbildung 6.8, rechts.\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\nAbbildung 6.8: Nicht zu wenig und nicht zu viele Balken im Balkendiagramm\n\n\nZur Erstellung eines Histogramms können Sie die Syntax Listing 6.5 nützen, vgl. Abbildung 6.9, links.\n\nListing 6.5: Syntax zur Erstellung eines Histogramms\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\nAbbildung 6.9: Eine stetige Verteilung verbildlichen\n\n\n\n6.4.2.2 Dichtediagramm\nAbbildung 6.10 fügt zu Abbildung 6.7 ein Dichtediagramm hinzu (rote Linie). Ein Dichtediagramm ähnelt einem “glattgeschmirgeltem” Histogramm.\n\nDefinition 6.4 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglättet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden.5\n\n\n\n\n\nAbbildung 6.10: Balkendiagramm für total_pr\n\n\n\n\nÜbungsaufgabe 6.3 Erstellen Sie das Diagramm Abbildung 6.9, rechtes Teildiagramm!6\\(\\square\\)\n\n\n6.4.2.3 Eigenschaften von Verteilungen\nVerteilungen unterscheiden sich z.B. einerseits in ihrem “typischen” oder “mittleren” Wert7 und anderseits in ihrer Streuung8\n(Diagramme von) Verteilungen können symmetrisch oder schief (nicht symmetrisch) sein, s. Abbildung 6.11.\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n(b) Schief\n\n\n\nAbbildung 6.11: Symmetrische vs. schiefe Verteilung, verbildlicht\n\n\nAbbildung 6.12 zeigt verschiedene Formen von Verteilungen.\n\n\n\n\nAbbildung 6.12: Verschiedene Verteilungsformen\n\n\n\nQuelle: ifes/FOM Hochschule\n\n6.4.3 Normalverteilung\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer quantitativen Variablen. Aber sie ist besonders wichtig, und daher hier herausgestellt.\nEine Normalverteilung sehen Sie in Abbildung 6.11, links. Sie hat u.a. folgende Eigenschaften:\n\nsymmetrisch\nglockenförmig\nstetig\neingipflig (unimodal)\nMittelwert, Median und Modus sind identisch\n\n\nBeispiel 6.3 Beispiele für normalverteilte Variablen sind Körpergröße von Männern oder Frauen, IQ-Werte, Prüfungsergebnisse, Messfehler, Lebensdauer von Glühbirnen, Gewichte von Brotlaiben, Milchproduktion von Kühen, Brustumfang schottischer Soldaten (Lyon 2014).\\(\\square\\)\n\nDie Normalverteilung ist von hoher Bedeutung, da diese Verteilung unter (recht häufigen) Bedingungen zwangsläufig ergeben muss. Wenn sich eine Variable als Summe mehrerer, unabhängiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable normalverteilt. Dieses Phänomen kann man gut anhand des Galton-Bretts veranschaulichen.\n\nEine Normalverteilung lässt sich exakt beschreiben anhand zweier Parameter: ihres zentralen Werts (Mittelwerts), \\(\\mu\\) und ihrer Streuung (Standardabweichung), \\(\\sigma\\).\nKennt man diese beiden Parameter, so kann man einfach angeben, welcher Anteil der Fläche sich in einem bestimmten Bereich befindet, s. Abbildung 6.13.\nDavon leitet sich die “68-95-99-Prozentregel” ab:\n\n\n\\(68\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{,}7\\,\\%\\) der Werte im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\nAbbildung 6.13: Die Flächeninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in Abhängigkeit der SD-Einheiten\n\nBy Ainali - Own work, CC BY-SA 3.0"
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.5 Zusammenhänge verbildlichen",
    "text": "6.5 Zusammenhänge verbildlichen\n\n6.5.1 Zusammenhang: nominale Variablen\n\nBeispiel 6.4 (Beispiele für Zusammenhänge bei nominalen Variablen)  \n\nHängt Berufserfolg (Führungskraft ja/nein) mit dem Geschlecht zusammen?\nHängt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen Automarke und politische Präferenz einer Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primär bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. Abbildung 6.14.\n\n\n\n\n\n(a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten\n\n\n\n\n\n(b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\nAbbildung 6.14: Zusammenhang zwischen nominalskalierten Variablen verbildlichen\n\n\nTatsächlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (Abbildung 6.14, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei. Bei gebrauchten Spiel immerhin bei gut der Hälfte der Fälle.\nAnders sieht es aus für die Frage, ob ein (oder mehrere) Lenkräder dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach “Foto des Produkts dabei” betraf (Abbildung 6.14, rechts), der Anteil betrug jeweils ca. 70%.\nAnders gesagt: Unterscheiden sich die “Füllhöhe” in den Diagrammen, so gibt es einen Unterschied hinsichtlich “Foto ist dabei” zwischen den beiden Gruppen (linker vs. rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs. gebrauchte Spiele), so spielt z.B. die Variable “Foto dabei” offenbar eine Rolle. Dann hängen Neuwertigkeit und “Foto dabei” also zusammen!\nSo können Sie sich in R ein gefülltes Balkendiagramm ausgeben lassen, s. Abbildung 6.15.\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")\n\n\n\nAbbildung 6.15: Ein gefülltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nGefüllte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei Ausprägungen aufweisen, sonst sind die Zusammenhänge nicht mehr so gut zu erkennen.\\(\\square\\)\n\n\n\n6.5.2 Zusammenhang: metrisch\nDen (etwaigen) Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). Abbildung 6.16 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine Ellipse ergänzt, um die Art des Zusammenangs besser zu verdeutlichen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je höher der Startpreis, desto höher der Abschlusspreis, zumindest tendenziell. Außerdem ist eine “Trendgerade” (Regressionsgerade) in blau eingezeichnet. Diese Gerade liegt “mittig” in den Daten (wir definieren dies später genauer). Diese Trendgerade gibt Aufschluss über “typische” Werte: Welcher Y-Wert ist “typisch” für einen bestimmten X-Wert?\nAbbildung 6.16 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis.\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n\n(b) negativer, eher schwacher Zusammenhang\n\n\n\nAbbildung 6.16: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\nAbbildung 6.17 bietet einen Überblick über verschiedene Beispiele von Richtung und Stärke von Zusammenhängen.\n\n\n\n\nAbbildung 6.17: Überblick über verschiedene Beispiele von Streudiagrammen\n\n\n\n\nQuelle: Aufbauend auf FOM/ifes, Norman Markgraf\n\nIn Abbildung 6.17 ist für jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und Stärke des Zusammenhangs (mehr dazu in Kap. Kapitel 9). Ein positives Vorzeichen steht für einen positiven Zusammenhang, ein negatives Vorzeichen für einen negativen Zusammenhang. Der (Absolut-)Wert gibt die Stärke des linearen Zusammenhangs an (Cohen 1992):\n\n±0: Kein Zusammenhang\n±0.1: schwacher Zusammenhang\n±0.3: mittlerer Zusammenhang\n±0.5: starker Zusammenhang\n±1: perfekter Zusammenhang\n\nAbbildung 6.18 hat die gleiche Aussage, ist aber plakativer, indem Stärke (schwach, stark) und Richtung (positiv, negativ) gegenübergestellt sind.\n\n\n\n\nAbbildung 6.18: Überblick über starke vs. schwache bzw. positive vs. negative Zusammenhänge\n\n\n\nMan sieht in Abbildung 6.17 und Abbildung 6.18, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade 9 (blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke Zusammenhänge mit einer schmaler Ellipse einhergehen und schwache Zusammenhänge mit einer breiten Ellipse einhergehen.\n\nDefinition 6.5 (Richtig und Stärke eines Zusammenhang) Gleichsinnige (positive) Zusammenhänge erkennt man an aufsteigenden Trendgeraden; gegensinnigen (negative) Zusammenhänge an absteigenden Trendgeraden:\n\n➕ : ⬆️\n➖ : ⬇️\n\nStarke Zusammenhänge erkennt man an schmalen Ellipsen (“Baguette”); schwache Zusammenhänge an breiten Ellipsen (“Torte”):\n\nschwach: 🥮\nstark: 🥖\n\n\\(\\square\\)\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEin Zusammenhang der Art “je mehr X, desto mehr Y” ist linear. Lineare Zusammenhänge erkennt man im Diagramm an einer Geraden bzw. inwieweit sich die Punkte an einer Geraden “anschmiegen”. Natürlich könnte man auch nicht-lineare Zusammenhänge untersuchen, aber der Einfachheit halber begnügen wir uns mit linearen.\\(\\square\\)\n\n\n\nBeispiel 6.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und machmal gehört Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhängen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. Starten Sie dieses Paket, s. Listing 6.2. Außerdem müssen wir noch die Daten importieren, falls noch nicht getan, s. Listing 6.1.\nSo, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf metrische Variablen konzentrieren wollen, wählen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewählten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primär interessiert. Das Ergebnis sieht man in Abbildung 6.19.\n\nmariokart %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\nAbbildung 6.19: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\nAha… Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafür sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur Verkäufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100). Das Ergebnis ist in Abbildung 6.20 zu sehen.\n\nmariokart2 &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\nmariokart2 %&gt;% \n  select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\nAbbildung 6.20: Der Zusammenhang metrischer Variablen mit Abschlusspreis\n\n\n\nOhne Extremwerte schält sich ein deutlicheres Bild (Abbildung 6.20) hervor: Startpreis (start_pr) und Anzahl der Räder (wheels) scheinen am stärksten mit dem Abschlusspreis zusammenzuhängen.\nDas Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle übrigen Variablen kommen jeweils einmal als X-Variable vor.\\(\\square\\)"
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.6 Unterschiede verbildlichen",
    "text": "6.6 Unterschiede verbildlichen\n\n6.6.1 Unterschied: nominale Variablen\nGute Nachrichten: Für nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von Zusammenhängen als auch von Unterschieden an. Genau genommen zeigt ja Abbildung 6.14 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Photos beiliegen. Und wie man in Abbildung 6.14 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen höher als bei gebrauchten Spielen.10\n\n6.6.2 Unterschied: quantitative Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich unterscheiden. Genauer gesagt untersucht man z.B. oft, ob sich die Mittelwerte der beiden Gruppen zwischen der Zielvariablen deutlich unterscheiden. Das hört sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. Abbildung 6.21.\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\nAbbildung 6.21: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 6.21 zeigt das Histogramm von total_pr, getrennt für neue und gebrauchte Spiele, vgl. Abbildung 6.9. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsfrom, den Boxplot.11\n\n\n\n\n\n(a) Y: Abschlusspreis, X: Zustand\n\n\n\n\n\n(b) Y: Abschlusspreis, X: Photo dabei?\n\n\n\nAbbildung 6.22: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 6.22 zeigt den Unterschied in den Verteilungen von total_pr, einmal für die neuen Computerspiele (cond == new) und einmal für gebrauchte Spiele (cond == used).\nWas ein “deutlicher”12 Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\nDefinition 6.6 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms.13 Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar.\\(\\square\\)\n\nIn Abbildung 6.23 sieht man die “Übersetzung” von Histogramm (oben) zu einem Boxplot (unten).\n\n\n\n\nAbbildung 6.23: Übersetzung eines Histogramms zu einem Boxplot\n\n\n\nSchauen wir uns die “Anatomie” des Boxplots näher an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung\nDie Enden der Box zeigen das 1. Quartil bzw. das 3. Quartil. Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto größer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR), da er die Strecke zwischen den Quartilen bemisst.\nDie “Antennen” des Boxplots zeigen die Streuung in den kleinsten 25% der Werte (linke Antenne) bzw. die Streuung der größten 25% der Werte (rechte Antennen). Je länger die Antenne, desto größer die Streuung.\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, außerhalb der Antennen gezeigt werden. Daher ist die Antennenlänge auf die 1,5-fache Länge der Box beschränkt. Werte die außerhalb dieses Bereichs liegen (also mehr als das 1,5-fache der Boxlänge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (schief). Gleiches gilt für die Antennenlängen: Sind die Antennen gleich lang, so ist der äußere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 6.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der Lenkräder untersucht. Jetzt möchten Sie eine sehr ähnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten Lenkräder? Flink erstellen Sie dazu folgendes Diagramm, Abbildung 6.24, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl Lenkräder (by = \"wheels).\nAber ganz glücklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wäre eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen würde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von Abbildung 6.24) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert.14 Aber wir möchten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir möchten wheels als nominale Variable definieren. Das kann man mit dem Befehle factor(wheels) erreichen (verpackt in mutate), s. Abbildung 6.24, rechts.\n\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\nmariokart2 %&gt;% \n  select(total_pr, wheels) %&gt;% \n  mutate(wheels = factor(wheels)) %&gt;% \n  plot_boxplot(by = \"wheels\")\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\nAbbildung 6.24: Abschlusspreis nach Anzahl von beigelegten Lenkrädern\n\n\n\nSie schlißen aus dem Bild, dass Lenkräder und Preis (positiv) zusammenhängen. Allerdings scheint es wenig Daten für wheels == 4 zu geben. Das prüfen Sie nach:\n\nmariokart2 %&gt;% \n  count(wheels)\n\n\n\n  \n\n\n\nTatsächlich gibt es (in mariokart2) auch für 3 Lenkräder schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten.\\(\\square\\)"
  },
  {
    "objectID": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.7 So lügt man mit Statistik",
    "text": "6.7 So lügt man mit Statistik\nDiagramme werden häufig eingesetzt, um die Wahrheit “aufzuhübschen”.\n\n6.7.1 Achsen manipulieren\nAchsen zu stauchen ist ein einfacher Trick, s. Abbildung 6.25.\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\nAbbildung 6.25: Stauchen der Y-Achse, um mit Statistik zu lügen\n\n\nNatürlich kann man auch durch “Abschneiden” der Y-Achse einen eindrucksvollen Effekt erzielen, s. Abbildung 6.26.\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\nAbbildung 6.26: Abschneiden der Y-Achse, um mit Statistik zu lügen\n\n\n\n6.7.2 Scheinkorrelation\nMesserli (2012) berichtet von einem Zusammenhang von Schokoloadenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: Länder), s. Abbildung 6.27. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?)\n\n\nAbbildung 6.27: Schokolodenkonsum und Nobelpreise\n\nLeider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhängen, heißt das nicht, dass die Variable die Ursache und die andere die Wirkung sein muss. So könnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In höher entwickelten Ländern wird mehr Schokoloade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu Ländern mit geringerem Entwicklungsstand."
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.8 Praxisbezug",
    "text": "6.8 Praxisbezug\nEin, wie ich finde schlagendes Beispiel zur Stärke von Datendiagrammen ist Abbildung 6.28. Das Diagramm zeigt die Häufigkeit von Masern, vor und nach der Einführung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf Panhuis u. a. (2013) zurück. Das Diagramm und weitere finden sich in ähnlicher Form imn Wall Street Journal.\n\n\nAbbildung 6.28: Häufigkeit von Masern und Impfung in den USA, Lizenz: MIT\n\nQuellcode Datenquelle\nIn der “freien Wildbahn” findet man häufig sog. “Tortendiagramme”. Zwar sind sie beliebt, doch ist von ihrer Verwendung abzuraten; vgl. auch hier."
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.9 Vertiefung",
    "text": "6.9 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\nEinen Überblick über verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur findet sich bei data-to-vis.\n\n6.9.1 Animation\nEine weitere nützliche Art von Visualisierung sind Karten und Animationen. So zeigt z.B. Abbildung 6.29 die Veränderung der Lebenserwartung (in Jahren) über die letzten Dekaden.\n\n\nAbbildung 6.29: Animation zur Veränderung der Lebenserwartung\n\nDer Quellcode der Animation ist hier zu finden.\nIn einigen Situation können Animationen zweckdienlich sein. Außerdem sind sie mitunter nett anzuschauen, s. Abbildung 6.30.\n\n\nAbbildung 6.30: Veränderung des Zusammenhangs von Lebenswertung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\nNatürlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animationen ziemlich atemberaubend.\n\n6.9.2 Schicke Diagramme\nEin Teil der Diagramm dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen, so lautet die etwa die Syntax von Abbildung 6.22 wie folgt.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMöchte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median heraustellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.B.) mit ggpubr, s. Abbildung 6.31.\n\nggviolin(mariokart2, x = \"cond\", y = \"total_pr\",\n         add = \"mean_sd\") \n\n\n\nAbbildung 6.31: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\nEin “Violinenplot” hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die “Violine”, desto mehr Beobachtungen gibt es an dieser Stelle. Weitere Varianten zum Violinenplot mit ggpubr finden sich hier.\nSowohl ggpubr als auch DataExplorer (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham 2009). Eine neue, gute Einführung in Datenvisualisierung findet sich bei Wilke (2019). Beide Bücher sind kostenfrei online lesbar.\nÜbrigens sind Modelle - und Diagramme sind Modelle - immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen. Dieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.\nEin weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heißt ggstatsplot.\nAbbildung 6.32 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart2,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrückt statistische Kennzahlen\n)\n\n\n\nAbbildung 6.32: Ein Histogramm mit ggstatsplot\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. Möchte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE.15.\n\n🧑‍🎓 Ich würde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\n👨‍🏫 Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.\n\n\n6.9.3 Farbwahl\nEinige Überlegungen zur Farbwahl findet sich in diesem Post; ausführlichere Erläuterung bietet Wilke (2019), s. Kap. 4.\nSo ist die Farbpalette von (okabeito?) empfehlenswert, da sie auch bei Schwarz-Weiß-Druck und bei Sehschwächen die Farben noch recht gut unterscheiden lässt.\n\nlibrary(ggokabeito)  # installieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\") +\n  scale_fill_okabe_ito()"
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.10 Aufgaben",
    "text": "6.10 Aufgaben\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2"
  },
  {
    "objectID": "040-verbildlichen.html#literatur",
    "href": "040-verbildlichen.html#literatur",
    "title": "\n6  Daten verbildlichen\n",
    "section": "\n6.11 Literatur",
    "text": "6.11 Literatur\n\n\n\n\nCohen, J. 1992. „A power primer“. Psychological Bulletin 112 (1): 155–59.\n\n\nLyon, Aidan. 2014. „Why Are Normal Distributions Normal?“ The British Journal for the Philosophy of Science 65 (3): 621–49. https://doi.org/10.1093/bjps/axs046.\n\n\nMesserli, Franz H. 2012. „Chocolate Consumption, Cognitive Function, and Nobel Laureates“. New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064.\n\n\nPanhuis, Willem G. van, John Grefenstette, Su Yon Jung, Nian Shong Chok, Anne Cross, Heather Eng, Bruce Y. Lee, u. a. 2013. „Contagious Diseases in the United States from 1888 to the Present“. New England Journal of Medicine 369 (22): 2152–58. https://doi.org/10.1056/NEJMms1215400.\n\n\nScherer, Cédric, Viktoriia Radchuk, Christoph Staubach, Sophie Müller, Niels Blaum, Hans‐Hermann Thulke, und Stephanie Kramer‐Schadt. 2019. „Seasonal Host Life‐history Processes Fuel Disease Dynamics at Different Spatial Scales“. Herausgegeben von Ann Tate. Journal of Animal Ecology 88 (11): 1812–24. https://doi.org/10.1111/1365-2656.13070.\n\n\nWickham, Hadley. 2009. Ggplot2: Elegant Graphics for Data Analysis. Use R! New York: Springer. https://doi.org/10.1007/978-0-387-98141-3.\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. Sebastopol, CA: O’Reilly Media. https://clauswilke.com/dataviz/."
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n6  Daten verbildlichen\n",
    "section": "",
    "text": "5↩︎\nWeitere Nomenklaturen sind möglich, aber wir halten hier die Sache einfach.↩︎\nNatürlich müssen Sie das Paket einmalig installiert haben, bevor Sie es starten können.↩︎\nbei konstanter Balkenbreite↩︎\nMit Dichte ist die Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.↩︎\nGrob gesagt: mariokart %&gt;% plot_density().↩︎\nvgl. Kapitel 7.5↩︎\nvgl. ↩︎\nsynonym: Regressionsgerade↩︎\nAber Freunde lassen Freunde keine Tortendiagramme verwenden.↩︎\nÜbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen.↩︎\n“substanzieller”, “bedeutsamer”, “relevanter” oder “(inhaltlich) signifikanter”↩︎\nOb der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack überlassen.↩︎\nVielleicht so, dass in jeder Gruppe gleich viele Wert sind?↩︎\nWeitere Hinweise finden sich auf der Hilfeseite der Funktion↩︎"
  },
  {
    "objectID": "050-zusammenfassen.html#lernsteuerung",
    "href": "050-zusammenfassen.html#lernsteuerung",
    "title": "7  Punktmodelle 1",
    "section": "\n7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n7.1.2 Lernziele\n\nSie können gängige Arten von Lagemaße definieren.\nSie können erläutern, inwiefern man ein Lagemaß als ein Modell hernehmen kann.\nSie können Lagemaße mit R berechnen.\n\n7.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n7.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "7  Punktmodelle 1",
    "section": "\n7.2 Mittelwert als Modell",
    "text": "7.2 Mittelwert als Modell\nDer klassische Mittelwert (arithmetisches Mittel) ist ein prototypisches Beispiel für ein Modell in der Statistik.\n\nÜbungsaufgabe 7.1 Welche Vorstellung haben Sie, wenn Sie hören, dass der “typische deutsche Mann” 1,80m groß ist (Roser, Appel, und Ritchie 2013)?\n\nDie Hälfte der Männer ist größer als 1,80m, die andere Hälfte kleiner.\nDas arithmetische Mittel der Männer beträgt 1,80m.\nDie meisten Männer sind 1,80m groß.\nEtwas anderes.\nKeine Ahnung!\\(\\square\\)\n\n\n\n\nÜbungsaufgabe 7.2 Laut dieser Quelle beträgt der Wert der mittleren Größe deutscher Frauen etwa 1,66m, also 14cm weniger als bei Männern. Ist das viel?\n\nja\nnein\nkommt drauf an\nweiß nicht\\(\\square\\)\n\n\n\n\nBeispiel 7.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (\\(\\varnothing\\)) beträgt: 2.\n\n\n🧑‍🎓 Zu easy!\n\n\n👨‍🏫 Schon gut! Chill mal. Wird gleich interessanter.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig. 😄\n\nEtwas abstrakter kann man Beispiel 7.1 in folgendem Schaubild darstellen, s. Gleichung 7.1.\n\\[\n\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} = 3 \\cdot \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}\n\\tag{7.1}\\]\nDer Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) für die “typische Note” im Statistikkurs, s. Gleichung 7.2.\n\\[\\begin{array}{|c|} \\hline \\\\ \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\square \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array} \\qquad \\leftrightarrow  \\qquad \\underbrace{\\begin{array}{|c|} \\hline \\\\ \\square \\\\ \\square \\\\ \\hline \\end{array}}_{\\text{\"typischer Vertreter\"}} \\tag{7.2}\\]\n\n\n\n\n\n\nWichtig\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er eine Datenreihe zu einen “typischen Vertreter” zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller Merkmalsträger in gleichem Maße einfließen. Er gibt uns eine (mögliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen.\n\n\nEine nützliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. Abbildung 7.1.\n\n\nAbbildung 7.1: Mittelwert als ausbalancierte Wippe\n\n\nQuelle: Von Maphry - Eigenes Werk, CC BY-SA 4.0\n\nIn “Mathe-Sprech” bezeichnet man den Mittelwert häufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. Gleichung 7.3.\n\\[\\bar {x} =\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{7.3}\\]\n\nDefinition 7.1 (Mittelwert) Der Mittelwert von \\(X\\), präziser: das arithmetische Mittel, ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n\\).$\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. Abbildung 7.2 sehen wir die Noten von (dieses Mal) vier Studentis. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert. Bezeichnen wir die Abweichung - auch als “Fehler”, “Rest” oder “Residuum” bezeichnet - der \\(i\\)-ten Person mit \\(e_i\\) (e wie “Fehler) und die \\(i\\)-te Note mit \\(x_i\\), so können wir festhalten:\n\\[x_i = \\bar{x} + e_i\\]\nEinfacher ausgedrückt:\n\\[\\text{Daten} = \\text{Modell} + \\text{Rest}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe.\nUm Modelle darzustellen, wird in der Datenanalyse häufig folgende Art von Modellgleichung verwendet:\n\\[\\hat{y} \\sim m\\]\nLies: “Der Modellwert \\(\\hat{y}\\) ist eine Funktion des Modells (m)”. Der Kringel “~”1 soll also hier heißen “… ist eine Funktion von …”.\nMit \\(\\hat{y}\\) sind die vorhergesagten bzw. die zu erklärende Variable2 gemeint.\nDas “Dach” über dem \\(y\\) bedeutet “vorhergesager Y-Wert” oder “Y-Wert laut dem Modell”.\nDer tatsächliche, beobachtete Wert \\(y\\) setzt sich zusammen aus dem Modellwert (m) plus einem Fehler (e wie error):\n\\[y = m + e\\]\nAnstelle von \\(m\\) schreibt ma nauch \\(\\hat{y}\\) (“y-Dach”). bedeutet der “vorhergesagte y-Wert laut einem Modell”.\nIn diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir schreiben können:\n\\[y = \\bar{x} + e\\]\nDie Zielvariable \\(Y\\) wird also durch ihren eigenen Mittelwert erklärt, außer gehen wir von einem Fehler \\(e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In späteren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklären. Würden wir z.B. sagen wollen, dass wir \\(Y\\) als Funktion einer Variable \\(X\\) erklären, so würden wir schreiben:\n\\[\\bar{y} \\sim x\\] Da wir im Moment aber keine andere Variablen bemühen, um \\(Y\\) zu erklären schreibt man auch:\n\\[\\bar{y} \\sim 1\\]\nDiese Schreibweise sieht verwirrend aus. Die \\(1\\) soll aber einfach zeigen, dass wir keine andere Variable zur Erklärung von \\(Y\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\).\n\nBeispiel 7.2 (Noten, Mittelwert und Abweichung) Vier Studentis Anna, Berta, Carl, Dani haben ihre Statistik-Klausur zurückbekommen. Die Noten sehen Sie in Abbildung 7.2. Außerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen der einzelnen Noten vom Mittelwert eingezeichnet.\\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken3 in Abbildung 7.2 einmal genauer an.\n\n\n\n\nAbbildung 7.2: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\nJetzt stellen Sie sich vor, Sie würden die vom Mittelwert nach oben ragenden Balkenlängen aneinanderlegen. Sehen Sie das vor Ihrem geistigen Auge? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen aneinander, aneinander. Wer viel Phantasie hat, erkennt (sieht) jetzt, dass die Gesamtlänge der “Balken nach oben” identisch ist zur Gesamtlänge der nach “unten ragenden Balken”, vgl. Abbildung 7.1.\nPräziser ausgedrückt und ohne Ihre Phantasie zu strapazieren (Gleichung 7.4):\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{7.4}\\]\n\n\n\n\n\n\nHinweis\n\n\n\nDie Summe der Abweichungen vom Mittelwert ist Null.\n\n\n\nÜbungsaufgabe 7.3 Was schätzen Sie, wie hoch das mittlere Vermögen des Haushalte in Deutschland in etwa ist?4)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\\(\\square\\)\n\n\n\n\nBeispiel 7.3 (Der reichste Mensch der Welt in Ihrem Hörsaal) Kommt der wertvollste Fußballspieler der Welt in Ihren Hörsaal, sagen wir, es ist Kylian Mbappé5. Das Jahreseinkommen mit einem Jahreseinkommen von ca. 120 Millionen Euro6.\n\n🦹‍♂️ Hey Leute, wie geht’s denn so! Wie viel Kohle verdient ihr eigentlich so?\n\n\n🧑‍🎓 Äh, wir studieren und verdienen fast nix!\n\nDie 100 Studis im Hörsaal schauen verdattert aus der Wäsche: Was ist das für eine komische Frage!? Aber zumindest verteilt der Fußballspieler Autogramme.\n\n\nÜbungsaufgabe 7.4 (Mittleres Einkommen im Hörsaal, mit Kylian Mbappé) Schätzen Sie - im Kopf - das mittlere Vermögen im Hörsaal, gehen Sie davon aus, dass alle der 100 Studentis jeweils 1000 Euro im Jahr verdienen.\n\nIn R kann man das mittlere Einkommen (präziser: das arithmetische Mittel des Einkommenss) wie folgt berechnen.7\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # rep wie \"repeat\": wiederhole 1000 USD 100 Mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000E, 1 Mbappé mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nuller hinter der führenden Eins, das ist 1000 mal 1000. Anders gesagt: 1 Million = \\(10^6 = 10^3 * 10^3\\). In Taschenrechner oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als “1 Mal 10 mit 6 im Exponenten”.\n\n\nDer Mittelwert im Hörsaal beträgt also 1,189,109 Euro. Ist das ein gutes Modell für das “typische” Vermögen im Hörsaal?\n\n7.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. Abbildung 7.3, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 7.2 (Lineares Modell) Ein lineares Modell verwendet eine Gerade als Modell von Daten.\\(\\square\\)\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\nAbbildung 7.3: Der mittlere Preis von Mariokart-Spielen als Gerade eingezeichnet\n\n\nEin lineares Modell kann man in R so berechnen:\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear modell\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl gibt als Koeffizient einen Wert zurück und zwar den Mittelwert von einkommen, s. oben. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet, das wird verständlich, wenn man z.B. in Abbildung 7.3 sieht, dass die Gerade genau an diesem Punkt die Y-Achse schneidet.\nDie Syntax des Befehls lm() sieht etwas merkwürdig aus. Ignorieren Sie das fürs Erste, wir besprechen das später (Kapitel 10) ausführlich."
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "7  Punktmodelle 1",
    "section": "\n7.3 Median als Modell",
    "text": "7.3 Median als Modell\n\n🧑‍🎓 Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert für die Menschen im Hörsaal. Weder für den Mbappé, noch für uns Studis!\n\n\n👨‍🏫 Ja, da habt ihr Recht.\n\n\n⚽ Die Welt ist schon ungerecht!\n\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. Abbildung 7.4) ist der Mittelwert (sehr) wenig aussagekräftig, da er nicht mehr “typische” Werte für die Merkmalsträger beschreibt.\n\n\nAbbildung 7.4 stellt die Verteilung einer mit normal skalierter Achse und einmal mit logarithmischer X-Achse. Die logarithmische X-Achse stellt den Unterschied von Mittelwert und Median deutlicher heraus als die “normale” (additive) Achse.\n\n\n\n\n\n(a) X-Achse in additiver Form\n\n\n\n\n\n\n\n(b) X-Achse in multiplikativer Form (logarithmische Darstellung)\n\n\n\nAbbildung 7.4: Die Einkommensverteilung im Hörsaal\n\n\nDer Mittelwert ist Hörsaal ist nicht typisch für die Menschen im Hörsaal: Weder für Mbappé, noch für die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Mittelwert ist empfänglich für Extremwerte: Gibt es einen extremen Wert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wieder und weniger die Mehrheit der gemäßigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenüber Extremwerten).\n\n\n\nBeispiel 7.4 (Das Median-Einkommen einiger Studentinnen) Fünf Studentinnen tauschen sich über ihr Einkommen aus, s. Abbildung 7.5, links. Es handelt sich um eine schiefe Verteilung.\n\n\n\n\n\n(a) ID auf der X-Achse, Einkommen auf der Y-Achse\n\n\n\n\n\n\n\n(b) Einkommen auf der X-Achse, Häufigkeit auf der Y-Achse\n\n\n\nAbbildung 7.5: Das Median-Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\nWir könnten jetzt behaupten, dass Carla das typische Einkommen (für diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen.\n\\(\\square\\)\n\n\nDefinition 7.3 (Median) Merkmalsausprägung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt.\n\nDer Median ist robust (gegenüber) Extremwerten: Fügt man Extremwerte zu einer Verteilung hinzu, ändert sich der Median zumeist (deutlich) weniger als der Mittelwert.\nAbbildung 7.6 stellt den Median schematisch dar.\n\n\n\n\n\n1,60m\n\n\n\n\n\n1,72m\n\n\n\n\n\n1,79m: Median!\n\n\n\n\n\n1,94\n\n\n\n\n\n2,12m\n\n\n\nAbbildung 7.6: Der Median als der Wert des “mittleren” Objekts, wenn die Objekte aufsteigend sortiert sind.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 7.5 Bei der Messreihe 1, 2, 3, 4, 5, 6, 8, 9 beträgt der Median 4.5.\\(\\square\\)\n\n\nÜbungsaufgabe 7.5 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhöht sich um das Hundertfache. Wie verändert sich der Median?8\\(\\square\\)\n\nDer Median ist robust, er verändert sich nicht oder kaum, wenn Extremwerte vorliegen.\n\nÜbungsaufgabe 7.6 (Wer ist mehr “mittel”? Median oder Mittelwert?)  \n\n🧑‍🎓 Das arithmetische Mittel sollte Mittelwert heißen, weil es die Mitte von zwei Messwerten widerspiegelt, also z.B. von 1 und 10 ist die Mitte 5,5 - also genau beim Mittelwert!\n\n\n👩‍🎓 Moment! Der Median zeigt den mittleren Messert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der Größe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion!\\(\\square\\)\n\n\nBeispiel 7.6 (Ein “mittlerer” Preis für Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median für das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist höher als der Median.\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n\n  \n\n\n\nWie man sieht, ist der Mittelwert größer als der Median, s. Abbildung 7.7\n\n\n\n\nAbbildung 7.7: Das Start-Gebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert größer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell für den “typischen Wert” vorzuziehen.\n\n\n\nÜbungsaufgabe 7.7 Was schätzen Sie, wie hoch das mediane Vermögen des Haushalte in Deutschland in etwa ist?9)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n250.000 Euro\\(\\square\\)\n\n\n\n\nÜbungsaufgabe 7.8 Was schätzen Sie, wie groß der Unterschied zwischen medianem und mittlerem (arithm. Mittel) des Jahreseinkommen deutscher Haushalte ungefähr ist?10)\n\n1.000 Euro\n2.000 Euro\n3.000 Euro\n4.000 Euro\n5.000 Euro\\(\\square\\)"
  },
  {
    "objectID": "050-zusammenfassen.html#quartile",
    "href": "050-zusammenfassen.html#quartile",
    "title": "7  Punktmodelle 1",
    "section": "\n7.4 Quartile",
    "text": "7.4 Quartile\nDer Median teilt eine Verteilung in eine untere und ein obere Hälfte. Er markiert sozusagen eine “50-Prozent-Marke” (der aufsteigend sortierten Beobachtungen). Betrachten wir einmal nur alle Spiele, die für weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. Abbildung 7.8. 50% aller Spiele wurden für weniger als ca. 46 Euro verkauft; 50% aller Spiele für mehr als 46 Euro.\nJetzt könnten wir nur die günstigere Hälfte betrachten und wieder nach dem Median fragen. Dieser “Median der günstigeren Hälfte” grenzt damit das insgesamt günstigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro.\n\nDefinition 7.4 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25%). Den Median nennt man das zweite Quartil (Q2, 50%). Entsprechend heißt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75%).\\(\\square\\)\n\n\nBeispiel 7.7 (Quartile des Verkaufsgebot) Abbildung 7.8 zeigt die Quartile für das Verkaufsgebot.\\(\\square\\)\n\nJetzt könnte man sagen, hey, warum nur in 25%-Stücke die Verteilung aufteilen? Warum nicht in 10%-Schritten? Oder in 1%-Schritten oder in sonstigen Schnitten? Wo die Quartile in 25%-Schritten aufteilen, teilt in Quantil in \\(p\\)-Prozent-Schritten auf.\n\nDefinition 7.5 (Quantile) Ein p-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht überschritten wird.\\(\\square\\)\n\n\n\n\n\nAbbildung 7.8: Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)\n\n\n\nQuantile kann man in R so berechnen:\n\nmario_quantile &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(q25 = quantile(total_pr, .25),\n            q50 = quantile(total_pr, .50),\n            q75 = quantile(total_pr, .75))"
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "7  Punktmodelle 1",
    "section": "\n7.5 Lagemaße",
    "text": "7.5 Lagemaße\n\n🧑‍🎓 Was ist der Oberbegriff für Median, Mittelwert und so weiter?\n\n\n👩‍🏫 Gute Frage! Wie würden Sie ihn nennen?\n\n\nDefinition 7.6 (Lagemaß) Ein Lagemaß oder Maß der zentralen Tendenz gibt einen Vorschlag, welchen Wert wir als typisch, normal, zu erwarten, repräsentativ oder mittel ansehen sollten.\\(\\square\\)\n\nTypische Lagemaße:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuartile\nQuantile\nMinimum (kleinester Wert)\nMaximum (größter Wert)\nModus (häufigster Wert)\n\n\nmariokart_lagemaße_total_pr &lt;-\n  mariokart %&gt;% \n  summarise(mw = mean(total_pr),\n            md = median(total_pr),\n            q1 = quantile(total_pr, .25),\n            q2 = quantile(total_pr, .5),\n            q3 = quantile(total_pr, .75),\n            min = min(total_pr),\n            max = max(total_pr))\nmariokart_lagemaße_total_pr\n\n\n\n  \n\n\n\n\n7.5.1 Gruppierte Lagemaße\nHäufig möchte man Statistiken wie Lagemaße für mehrere Teilgruppen - z.B. Mittlere Körpergröße von Frauen vs. Mittlere Körpergröße von Männer - berechnen und dann vergleichen. Die dahinter stehende Forschungsfrage könnte lauten:\n\nUnterscheidet sich die mittlere Körpergröße von Frauen und Männern?\n\nOder vielleicht:\n\nHat das Geschlecht einen Einfluss auf die Körpergröße?\n\nAnders ausgedrückt:\n\nKörpergröße \\(y\\) ist eine Funktion des Geschlechts \\(G\\).\n\nDie Modellformel könnte also lauten:\n\\[y \\sim G\\]\nGruppierte Lagemaße lassen sich in R z.B. so berechnen:\n\nmariokart_lagemaße_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\nmariokart_lagemaße_gruppiert\n\n\n\n  \n\n\n\nAbbildung 7.3 zeigt ein Beispiel für ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, “globalen” Mittelwert).\n\nDefinition 7.7 (Punktmodell) Ein Modell, welches für alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heißt ein Punktmodell. Anders gesagt fasst ein Punktmodell eine Wertereihe (häufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem “Punkt” in diesem Sinne, s. Gleichung 7.5.\\(\\square\\)\n\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{7.5}\\]\nMittelwert, Median und Quartile sind Beispiele für Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein “Bild” der Daten, machen Sie uns verständlich - sie sind uns ein Modell."
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "title": "7  Punktmodelle 1",
    "section": "\n7.6 Wie man mit Statistik lügt",
    "text": "7.6 Wie man mit Statistik lügt\nMit Statistik kann man vortrefflich lügen, heißt es. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lässt: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzuführen. Viele Wege führen nach Rom.\nUm Manipulationsversuche abzuwehren oder einfache Fehler und Unschärfen ohne böse Abwehr aufzudecken, gibt es ein probates Gegenmittel: Transparenz.\n\nStellen Sie hohe Anforderung an die Transparenz einer statistischen Analyse. Nur durch Nachprüfbarkeit können Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation überzeugen.\n\nHier ist eine (nicht abschließende!) Checkliste, was Sie nachprüfen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts u. a. (2016):"
  },
  {
    "objectID": "050-zusammenfassen.html#fazit",
    "href": "050-zusammenfassen.html#fazit",
    "title": "7  Punktmodelle 1",
    "section": "\n7.7 Fazit",
    "text": "7.7 Fazit\n\nBeispiel 7.8 (Survival-Tipp) Eine Studentin aus dem dem Bachelorstudiengang “Angewandte Medien- und Wirtschaftspsychologie” mit Schwerpunkt Data Science berichtet ihre “Survival-Tipps” für Statistik.\n\nWenn man mal nicht weiterkommt hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nSich während des Semesters neue Begriffe und ihre Erklärung zusammenschreiben.\nMit KommilitonInnen austauschen oder in höheren Semestern nach Tipps fragen.\\(\\square\\)\n\n\n\n\n👩‍🎓 Irgendwie kann ich mir R-Code so schlecht merken.\n\n\n👩‍🏫 Frag doch mal ChatGPT, da bekommt man auch R-Code ausgegegeben."
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "7  Punktmodelle 1",
    "section": "\n7.8 Aufgaben",
    "text": "7.8 Aufgaben\nEin Teil der Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber später kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekannte Stoff.\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nnasa02\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu z.B. dem Tag EDA an."
  },
  {
    "objectID": "050-zusammenfassen.html#literatur",
    "href": "050-zusammenfassen.html#literatur",
    "title": "7  Punktmodelle 1",
    "section": "\n7.9 Literatur",
    "text": "7.9 Literatur\n\n\n\n\nRoser, Max, Cameron Appel, und Hannah Ritchie. 2013. „Human height“. Our World in Data. https://ourworldindata.org/human-height.\n\n\nSimmons, Joseph P., Leif D. Nelson, und Uri Simonsohn. 2011. „False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant“. Psychological Science 22 (11): 1359–66. https://doi.org/10.1177/0956797611417632.\n\n\nWicherts, Jelte M., Coosje L. S. Veldkamp, Hilde E. M. Augusteijn, Marjan Bakker, Robbie C. M. van Aert, und Marcel A. L. M. van Assen. 2016. „Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking“. Frontiers in Psychology 7 (November): 1832. https://doi.org/10.3389/fpsyg.2016.01832."
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "7  Punktmodelle 1",
    "section": "",
    "text": "die sog. “Tilde”↩︎\nAV, Output-Variable, Zielvariable↩︎\nResiduen, Fehler; häufig mit \\(e\\) wie error bezeichnet↩︎\nQuelle: WSI, Abruf 2023-04-19↩︎\nQuelle: https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop, 2023-03-19↩︎\nQuelle: https://www.einkommenmagazin.de/kylian-mbappe-einkommen/, 2023-03-19↩︎\nDie Details der Syntax, z.B. der Befehl rep() sind von geringer Bedeutung.↩︎\nEr bleibt gleich, verändert sich also nicht.↩︎\nQuelle: WSI, Abruf 2023-04-19↩︎\nQuelle: Wikipedia, Abruf 2023-04-19, der Unterschied beträgt knapp 3000 Euro laut der Quelle↩︎"
  },
  {
    "objectID": "060-modellguete.html#lernsteuerung",
    "href": "060-modellguete.html#lernsteuerung",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n8.1.2 Lernziele\n\nSie kennen gängige Maße der Streuung einer Stichprobe und können diese definieren und mit Beispielen erläutern.\nSie können gängige Maße der Streuung einer Stichprobe mit R berechnen.\nSie können die Bedeutung von Streuung für die Güte eines Modells erläutern.\n\n8.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n8.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "060-modellguete.html#sec-weiss-ois",
    "href": "060-modellguete.html#sec-weiss-ois",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.2 Prof. Weiss-Ois hat eine Idee",
    "text": "8.2 Prof. Weiss-Ois hat eine Idee\n\n\n\n8.2.1 Was er sagt\n\n\n“Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1kg reduziert!”\n\n\n\n\n\n\n8.2.2 Was er NICHT sagt\n\n\n“Allerdings streuten die Werte der Gewichtsveränderung um 10kg um den Mittelwert herum.”\n\n\n\n\nIcon unter Flaticon licence, Autor: iconixar\n\nWürden Sie die Pille von Prof. Weiss-Ois nehmen?\n\nja\nnein\nNur wenn ich 100 Euro bekomme\nOkay, für 1000 Euro$\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information.\\(\\square\\)"
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.3 Woran erkennt man ein gutes Modell?",
    "text": "8.3 Woran erkennt man ein gutes Modell?\nAbbildung 8.1 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts).\n\n\n\n\nAbbildung 8.1: Ein Modell mit wenig Streuung vs. ein Modell mit viel Streuung\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsächlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groß.\n\n\n\nBeispiel 8.1 (Daten zur Schlankheitskur von Prof. Weiss-Ois) In Abbildung 8.1 sind die Daten zu der Gewichtsveränderung nach Einnahme von “Schlankheitspillen” zweier verschiedener Präparate. Wie man sieht unterscheidet sich die typische (vorhergersagte) Gewichtsveränderung zwischen den beiden Präparaten kaum. Die Streuung allerdings schon. Links sieht man die Gewichtsveränderungen nach Einnahme des Präparats “Dickableibtin extra mild” (c) und rechts das Präparat von Prof. Weiss-Ois “Pfundafliptan Forte”. Welches Präparat würden Sie lieber einnehmen?\\(\\square\\)\n\n\n\n\n\n\n\nWichtig\n\n\n\nWir wollen ein präzises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklären, also wenig vom tatsächlichen Wert abweichen. Jedes Modell sollte Informationen über die Präzision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellgüte, d.h. der Präzision der Schätzung des Modellwerts, ist wenig nütze.\\(\\square\\)\n\n\n\n👩‍🎓 Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\n👩‍🏫 Die Frage ist, was wir mit “verbessern” meinen?\n\n\n👩‍🎓 Naja, kürzere Fehlerbalken, ist doch klar!\n\nDa die Anzahl der Lenkräder mit dem Verkaufsgebot zusammenhängt, könnte es vielleicht sein, dass wir die Lenkräder-Anzahl da irgendwie nutzen könnten. Das sollten wir ausprobieren.\nAbbildung 8.2 zeigt, dass die Fehlerbalken kürzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 Lenkrädern vs. mit 0 Lenkrädern) sind die Fehlerbalken jeweils im Durchschnitt kürzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildaigramm).1\n\n\n\n\n\n(a) Fehlerbalken im einfachen Modell: Ein Mittelwert\n\n\n\n\n\n(b) Fehlerbalken im komplexen Modell: Zwei Mittelwerte\n\n\n\nAbbildung 8.2: Fehlerbalken in einem einfachen und komplexeren Modell\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells.\\(\\square\\)"
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.4 Streuungsmaße",
    "text": "8.4 Streuungsmaße\n\n8.4.1 Der mittlere Abweichungsbalken\n\n🧑‍🎓 Wir müssen jetzt mal präziser werden! Wie können wir die Streuung berechnen?\n\n\n👨‍🏫 Gute Frage! Am einfachsten ist es, wenn wir die mittlere Länge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir wir den “mittleren Abweichungsbalken”, den wir mit \\(\\varnothing e\\) bezeichnen könnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als Mittlere Absolutabweichung (MAA). Er ist so definiert:\n\\({\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}.}\\)\n\nDefinition 8.1 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte.2\\(\\square\\)\n\n\nBeispiel 8.2 Abbildung 8.3 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE für das Beispiel von Abbildung 8.3 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5\\)\n\n\n\n\n\nAbbildung 8.3: Abweichungsbalken und der MAE\n\n\n\nNatürlich können wir R auch die Rechenarbeit überlassen.\n\n🤖 Loving it!!\n\nSchauen Sie: Den Mittelwert (s. Abbildung 8.3) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? Schließlich erklären wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse ist).\nIn R gibt es einen Befehl für ein lineares Modell, er heißt lm.\nDie Syntax von lm() lautet:\nlm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur Erklärung von Y. Aber verwende keine andere Variable zur Erklärung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm1 &lt;- lm(y ~ 1, data = d)\n\nDen MAE können wir uns jetzt so ausgeben lassen:\n\nmae(lm1)\n## [1] 1.5\n\n\n8.4.2 Der Interquartilsabstand\nDer Interquartilsabstand (engl. inter quartile range, IQR) ist ein Streuungsmaß, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.B. der MAA oder die Varianz und die Standardabweichung.\n:::{#def-iqr} ### Interquartilsabstand Der Interquartilsabstand (IRR) ist definiert als der die Differenz vom 3. Quartil und 1. Quartil.\\(\\square\\)\n\nBeispiel 8.3 (IQR im Hörsaal) In einem Statistikkurs betragen die Quartile der Körpergröße: Q1: 1.65m, Q2 (Median): 1,70m, Q3: 1.75m. Der IQR beträgt dann: \\(IQR = Q3-Q1 = 1.75m - 1.65m = 0.10m\\), d.h. 10 cm.\\(\\square\\)\n\n\n8.4.3 Der mittlere Quadratfehler\nSagen wir, wir möchten die Körpergröße erwachsener (deutscher) Männer modellieren. Einfach gesagt: Wir möchten wissen, wie groß typischerweise ein deutscher Mann ist. Wir verwenden den Mittelwert, um diese Frage zu beantworten. Aus der Literatur erfahren wir, dass die mittlere Körpergröße belgischer Männer bei 179 cm liegt und normalverteilt ist (Garcia und Quintana-Domeque 2007).3\nSind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert, “verschiebt man den Berg” ja nur zur Seite, ohne seine Form zu verändern, s. Abbildung 8.4.\n\n\n\n\nAbbildung 8.4: Die Abweichungen zum Mittelwert einer normalverteilten Variable sind selber normalverteilt\n\n\n\nHat man normalverteilte Residuen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma\\), \\(s\\)) eine komfortable Maßeinheit der Streuung, denn damit lässt sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\n\n\n\n\n\n\nHinweis\n\n\n\nNormalverteilte Residuen lassen sich gut mit der Standardabweichung beschreiben.\\(\\square\\)\n\n\n\n🧑‍🎓 Aber wie berechnet man jetzt diese Standardabweichung?\n\n\n👨‍🏫 Moment, noch ein kurzer Exkurs zur Varianz …\n\n\n🧑‍🎓 (seufzt)\n\n\n8.4.4 Varianz\nUm die Standardabweichung zu berechnen, berechnet man zunächst die Varianz, \\(s^2\\) abgekürzt. Hier ist ein “Kochrezept”4 zur Berechnung der Varianz:\n\nFür alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\)\n\nQuadriere diese Werte\nSummiere dann auf\nTeile durch die Anzahl \\(N\\) der Werte\n\nAls Formel ausgedrückt, lautet die Definition der Varianz5 einer Stichprobe:\n\\[{\\displaystyle s^{2}={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(x_{i}-{\\bar {y}}\\right)^{2}.}\\]\n\nDefinition 8.2 (Varianz) Die Varianz (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadradrierten Abweichungen (vom Mittelwert).\\(\\square\\)\n\nDie Varianz steht im engen Verhältnis zur Kovarianz, s. Kapitel 9.3.\nDie Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells. Im Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells.\n\\[{\\displaystyle MSE={\\frac {1}{N}}\\sum _{i=1}^{N}\\left(x_{i}-{\\hat {y}}\\right)^{2}.}\\]\n\n\nAbbildung 8.7 illustriert die Varianz:\n\nMan gehe von der Häufigkeitverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan bilde Quadrate für jeden Datenpunkt mit der Kantenlänge, die dem Abstand des Punktes zum Mittelwert entspricht.\nDie Quadrate quetscht man jetzt wo nötig in rechteckige Formen (ohne dass sich die Fläche ändern darf) und verschiebt sie, bis sich alle Formen zu einem Rechteck mit Seitenlänge \\(n\\) und \\(\\sigma^2\\) anordnen.\n\n\n\n\nAbbildung 8.5: Illustration zur Varianz als “mittlerer Quadratfehler”\n\nBy Cmglee - Own work, CC BY-SA 3.0\n\n\nAbbildung 8.6 visualisiert die Varianz für Beispiel 8.2.6\n\n\n\n\nAbbildung 8.6: Quadrierte Fehlerbalken\n\n\n\nBildquelle: FOM-ifes\n\nBeispiel 8.4 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. Natürlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann.\nZunächst betrachten Sie die Streuung in den Verkaufspreisen:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nmariokart &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nm &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  m %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\nm_summ\n\n\n\n  \n\n\n\nStatistiken sind ja schön … aber Bilder sind auch gut, s. Abbildung 8.7.\n\nmariokart %&gt;% \n  mariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_density()\n\n\n\n\n\n\n(a) Dichtediagramm mit MW±SD in roter Farbe\n\n\n\n\n\n(b) Violindiagramm mit MW±SD in roter Farbe\n\n\n\nAbbildung 8.7: Die Verteilung des Verkaufspreises von Mariokart-Spielen\n\n\n\\(\\square\\)\n\nWer sich die Berechnung von Hand für pr_maa sparen möchte, kann die Funktion MeanAD aus dem Paket DescTools nutzen.\n\n8.4.5 Die Standardabweichung\nKennt man die Varianz, so lässt sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen.\n\nDefinition 8.3 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz.\n\\[s := \\sqrt{s^2}\\]\n\\(\\square\\)\n\nDurch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche Größenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groß werden kann).\nAus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(rmse = \\sqrt{mse}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE.\\(\\square\\)\n\n\n\nBeispiel 8.5 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n\n  \n\n\n\nAh! Das war einfach. Wird auch langsam Zeit für Feierabend.\\(\\square\\)\n\n\nBeispiel 8.6 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So auch heute. Bevor Sie nach Hause gehen, möchten Sie noch eine Sache anschauen. In einer früheren Analyse (s. Abbildung 8.2) fanden Sie heraus, dass die Fehlerbalken kürzer werden, wenn man ein geschickteres und komplexeres Modell findet.\nDas wollen Sie natürlich prüfen. Sie überlegen: “Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufpreis sein soll.”\nDas spezifizieren Sie so:\n\nlm1 &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm1)\n## [1] 10.01811\n\nIm nächsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufpreis eine Funktion der Anzahl der Lenkräder ist (ähnlich wie in Abbildung 8.2):\n\nlm2 &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm2)\n## [1] 7.375873\n\nAh! Sehr schön, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach hause!\\(\\square\\)"
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.5 Streuung als Modellfehler",
    "text": "8.5 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufpreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellgüte auffassen.\nDefinieren wir zunächst als Punktmodell auf Errisch:\n\nlm_mario1 &lt;- lm(total_pr ~ 1, data = m)\n\nZur Erinnerung: Wir modellieren total_pr ohne Prädiktoren, sondern als Punktmodell, und zwar schätzen wir den Mittelwert mit den Daten m.\nDas (Meta-)Paket easystats bietet komfortable Befehle, um die Modellgüte zu berechnen:\n\nmae(lm_mario1)  # Mean absolute error\n## [1] 7.199762\nmse(lm_mario1)  # Mean squared error\n## [1] 82.46957\nrmse(lm_mario1)  # Root mean squared error\n## [1] 9.081276"
  },
  {
    "objectID": "060-modellguete.html#fazit",
    "href": "060-modellguete.html#fazit",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.6 Fazit",
    "text": "8.6 Fazit\nDer „gesunde Menschenverstand“ würde spontan den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Das ist vernünftig, denn die MAA ist anschaulicher und damit nützlicher als die Varianz und die SD.\nWarum sollte man überhaupt ein unanschauliches Maß wie die Varianz verwenden? Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt.\nGründe, warum Sie die Varianz (bzw. SD) kennen und nutzen sollten, sind:7\n\nDie SD ist sehr nützlich zur Beschreibung der Normalverteilung\nDie Varianz wird häufig verwendet bzw. in Forschungsarbeiten berichtet, also müssen Sie die Varianz kennen.\n\nLiegen Exremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenüber Mittelwert basierten Streuungsmaßen (MAA, Varianz, SD)."
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.7 Aufgaben",
    "text": "8.7 Aufgaben\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag variability an."
  },
  {
    "objectID": "060-modellguete.html#literatur",
    "href": "060-modellguete.html#literatur",
    "title": "\n8  Modellgüte\n",
    "section": "\n8.8 Literatur",
    "text": "8.8 Literatur\n\n\n\n\nGarcia, Jaume, und Climent Quintana-Domeque. 2007. „The evolution of adult height in Europe: a brief note“. Econ Hum Biol 5 (2): 340–49. https://doi.org/10.1016/j.ehb.2007.02.002."
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n8  Modellgüte\n",
    "section": "",
    "text": "Aus Gründen der Übersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berücksichtigt und nur Spiele mit 0 oder mit 2 Lenkrädern.↩︎\nWenn man solche Sätze liest, fühlt sich die Formel fast einfacher an.↩︎\nDas sind Daten für Belgien; Daten zur Standardabweichung für Deutschland habe ich nicht gefunden.↩︎\nAlgorithmus↩︎\nsog. unkorrigierte Stichprobenvarianz↩︎\nDie Abweichungsquadrate wirken optischt nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine…↩︎\nIch wollte noch hinzufügen, dass die Varianz eng verknüpft mit der linearen Algebra, aber ich war nicht sicher, ob das Argument allgemein überzeugen würde.↩︎"
  },
  {
    "objectID": "070-zusammenhaenge.html#lernsteuerung",
    "href": "070-zusammenhaenge.html#lernsteuerung",
    "title": "9  Punktmodelle 2",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Standort im Lernpfad\nAbbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n9.1.2 Lernziele\n\nSie können die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenhäng erläutern.\nSie können die Stärke einer Korrelation einschätzen.\n\n9.1.3 Benötigte R-Pakete\nIn diesem Kapitel benötigen Sie folgende R-Pakete.\n\n9.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "9  Punktmodelle 2",
    "section": "\n9.2 Zusammenfassen zum Zusammenhang",
    "text": "9.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 7 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl1, zu einem “Punkt” sozusagen, zusammengefasst werden kann.\nIn diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. Gleichung 9.1.\n\\[\\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} + \\begin{array}{|c|} \\hline \\\\ \\hline \\\\\\\\\\\\ \\hline \\end{array} \\qquad \\rightarrow \\qquad \\begin{array}{|c|} \\hline \\\\ \\hline  \\hline \\end{array} \\tag{9.1}\\]\nWo wir in Kapitel 7 eine Variable mit Hilfe eines Lagemaßes beschrieben/dargestellt/zusammengefasst/modelliert haben, tun wir hier das Gleich für zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen von einander abhängen bzw. miteinander (irgendwie) zusammenhängen. Wir begrenzen auf metrische Variablen.\nDie Verbildlichung2 zweier metrischer Variablen haben wir bereits in Kapitel 6.5.2 kennengelernt. Zur Verdeutlichung, wie ein Zusammenhang zweier metrischer Variablen aussehen kann, helfe noch einmal Abbildung 9.1.\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung)\n\n\n\n\n\n(b) ‘Verwackeltes’ Streudiagramm, um die einzelnen Punkte besser zu erkennen\n\n\n\nAbbildung 9.1: Visualisierung des Zusammenhangs von wheels und total_pr"
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "9  Punktmodelle 2",
    "section": "\n9.3 Abweichungsrechtecke",
    "text": "9.3 Abweichungsrechtecke\n\n9.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 9.1 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurückbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhängen.3 Gar nicht so schlecht ausgefallen, s. Tabelle 9.1.\\(\\square\\)\n\n\n\n\n\nTabelle 9.1: Statistiknoten und Lernzeit\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\nZeichner wir uns die Daten als Streudiagramm, s. Abbildung 9.2. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 9.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso für \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\). Die Fläche des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\).\\(\\square\\)\n\n\n\n\n\nAbbildung 9.2: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus Abbildung 9.2. Nennen wir das resultierende Rechteck das “Summenrechteck”. Ja, ich weiß, ich strapaziere mal wieder Ihre Phantasie4. Jetzt kommt’s: Je größer die Fläche des Summenrechtecks, desto stärker der (lineare) Zusammenhang.\nBeachten Sie, dass die Flächen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nach dem, in welchem der vier Quadranten sie stehen. Die Füllfarben der Rechtecke verdeutlichen dies, s. Abbildung 9.2.\nDas Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist.\nSo zeigt Abbildung 9.3 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Diagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (rot) überwiegt; im rechten Diagramm ist es umgekehrt (blau, negativ überwiegt).\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten 1 und 3) überweigen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überweigen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n(b) Positive Vorzeichen (Quadranten 1 und 3) überweigen, was in einer positiven Kovarianz resultiert - Negative Vorzeichen (Quadranten 2 und 4) überweigen, was in einer negativen Kovarianz resultiert\n\n\n\nAbbildung 9.3: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die Flächen der Abweichungsrechtecke addiert.\n\n\nWir können das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das ändert nichts an der Aussage, aber der Mittelwert hat gegenüber der Summe den Vorteil, dass er unabhängig ist in seiner Aussage von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck.\nEin Maß für den Zusammenhang von Lernzeit und Klausurpunkte ist also die Größe des mittleren Abweichungsrechtecks.\n\n9.3.2 Kovarianz\n\nDefinition 9.2 (Kovarianz) Die Kovarianz ist definiert als die Fläche des mittleren Abweichungsrechtecks. Sie ist ein Maß für die Stärke und Richtung des linearen Zusammenhangs zweier metrischer Variablen.\\(\\square\\)\n\n\n👩‍🎓 Zu viele Bilder! Ich brauch Zahlen.\n\n\n👩‍🏫 Kommen schon!\n\nTabelle 9.2 zeigt die Werte für die X- und Y-Abweichung und die resultierenden Flächen der Abweichungsrechtecke. Wenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv.\n\n\n\n\nTabelle 9.2: Werte der Abweichungsrechtecke\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\nx_pos\ny_pos\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51.25\n17\n20.75\nTRUE\nTRUE\n1\n352.75\n\n\n2\n44\n40\n53\n51.25\n-13\n-7.25\nFALSE\nFALSE\n1\n94.25\n\n\n3\n39\n35\n53\n51.25\n-18\n-12.25\nFALSE\nFALSE\n1\n220.50\n\n\n4\n50\n67\n53\n51.25\n14\n-1.25\nTRUE\nFALSE\n-1\n-17.50\n\n\n\n\n\n\nBerechnen wir als nächstes das mittlere Abweichungsrechteck, die Kovarianz:\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet (?eq-cov4):\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i\\]{#eq-cov4}.\nIn Worten:\n\nRechne für jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\)\n\nRechne für jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\)\n\nMultipliziere für alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu berechnen\nAddiere die Flächen der Abweichungsrechtecke\nTeile durch die Anzahl der Beobachtungen \\(n\\)\n\n\n\nBeispiel 9.2 (Variablen mit positiver Kovarianz)  \n\nGröße und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf\\(\\square\\)\n\n\n\n\nBeispiel 9.3 (Variablen mit negativer Kovarianz)  \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und Depressivität\\(\\square\\)\n\n\n\nDrei Extrembeispiele für Kovarianz-Werte sind in Abbildung 9.4 dargestellt.\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n(c) negativer Zusammenhang\n\n\n\nAbbildung 9.4: Verschiedene Werte der Kovarianz\n\n\nBei einer Kovarianz von 0 ist die Fläche der Abweichungsrechtecke5, wenn man sie pro Quadrant aufsummiert, etwa gleich groß, s. Abbildung 9.5. Addiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen: rot = positiv; blau = negativ), so beträgt die Summe in etwa (oder genau) Null.\nDamit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null:\n\\[\\begin{align}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\varnothing \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov} &= 0\n\\end{align}\\]\n\n\n\n\n\n(a) 4 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\n\n\n(b) 200 Abweichungsrechtecke, deren Fläche sich zu 0 addiert\n\n\n\nAbbildung 9.5: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus\n\n\n\n9.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhängig ist von der Skalierung. So steigt die Kovarianz z.B. um den Faktor 100, wenn man eine Variable (z.B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wünschenswert, denn der Zusammenhang zwischen z.B. Einkommen und Lebenszufriedenheit ist unabhängig davon, ob man Einkommen in Euro, Cent oder Dollar misst. Außerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt.\nInsgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet."
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "9  Punktmodelle 2",
    "section": "\n9.4 Korrelation",
    "text": "9.4 Korrelation\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson löst das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nämlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so führt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) so definieren:\n\nDefinition 9.3 (Korrelationskoeffizient r) Der Korrelationskoeffizient \\(r\\) ist definiert als das mittlere Produkt der z-Wert-Paare: \\(r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z^x_i z^y_i\\).\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nAus dem Korrelationskoeffizienten können Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusamamenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert des Korrelationskoeffizienten gibt die Stärke des linearen Zusammenhangs an. Je näher der Wert bei 1 liegt desto stärker der Zusammenhang.\n\n\n\n\\(r = 0\\): kein linearer Zusammenhang\n\n\\(r = 1\\): perfekter linearer Zusammenhang\\(\\square\\)\n\n\n\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt Abbildung 9.6.\n\n\nAbbildung 9.6: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden. Quelle: Wikipedia, By DenisBoigelot, original uploader was Imagecreator, CC0, https://commons.wikimedia.org/w/index.php?curid=15165296 CC0\n\n\nÜbungsaufgabe 9.1 (Korrelationsspiel) Spielen Sie das Korrelationsspiel: Sie Sehen ein Streudiagramm und müssen den richtigen Korrelationskoeffizienten eingeben.\\(\\square\\)\n\n\nÜbungsaufgabe 9.2 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr Gefühl für die Stärke des Korrelationskoeffizienten zu entwickeln.\\(\\square\\)\n\n\n9.4.1 Korrelation ≠ Kausation\nEine Studie fand eine starke Korrelation, zwischen der (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli 2012), s. Abbildung 9.7.\n\n\nAbbildung 9.7: Schoki futtern macht schlau?\n\n\n\n\n\n\n\nVorsicht\n\n\n\nKorrelation (bzw. Zusammenhang) ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n\n\n9.4.2 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 9.4 (Scheinkorrelation) Eine Urban Myth besagt: Die Anzahl der Störche pro Landkreis korreliert mit der Anzahl der Babies in diesem Landkreis.\n\nBald men at higher risk of severe case of Covid-19, research finds6\n\nMacht die Glatze krank? Männer mit Glatze bekommen häufiger Corona (Goren u. a. 2020).\\(\\square\\)"
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "9  Punktmodelle 2",
    "section": "\n9.5 Fallbeispiel",
    "text": "9.5 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhängen.\nFalls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, können Sie die Daten so (in mittlerweile gewohnter Manier) importieren:\n\nmariokart &lt;- read.csv(\"mariokart.csv\")\n\nFalls der Datensatz im Unterordner mit Namen “Mein_Unterordner” liegt, so würden Sie folgenden Pfad eingeben:\n\nmariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\")\n\nMan beachte, dass solche sog. relativen Pfade (relativ zu Ihrem Arbeitsverzeichnis, d.h. Ihr Projektverzeichnis in R-Studio) nicht mit einem Schrägstrich (Slash) beginnen.\nFalls Sie die Daten nicht auf Ihrem Computer haben, können Sie sie komfortable von z.B. der Webseite von Vincent Arel-Bundock herunterladen:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wählen die Variablen von mariokart, die Sie interessieren - natürlich nur die metrischen - und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\n\n\n\n\n\n\nNamensverwechslung (name clash)\n\n\n\nEs kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein, wie es mir oben in der Syntax passiert ist. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemäß sagt: “Hey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.” Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: “Hey R, nimm gefälligst select aus dem Paket dplyr, dort”wohnt” nämlich select. Auf Errisch spricht sich das so: dplyr::select(...).\\(\\square\\)\n\n\nEtwas schöner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. Tabelle 9.3.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  correlation() \n\n\n\n Tabelle 9.3:  Korrelationstabelle (tidy) im Datensatz mariokart \n  \n\n\n\n\nNeben einigen Statistiken, die wir einfach geflissentlich ausblenden (t und p) beinhaltet die Tabelle eine interessante Information: den Schätzbereich für die Korrelation, gekennzeichnet als 95% CI. Grob gesagt können wir diese Information so interpretieren: “Mit 95% Wahrscheinlichkeit liegt der echte Wert der Korrelation in folgendem Bereich.”7\nMöchte man nur einzelne Korrelationskoeffizienten ausrechnen, können wir die Idee des Zusammenfassens, s. Gleichung 9.1, nutzen:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels))\n\n\n\n  \n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nIm Falle von fehlenden Werte müssen Sie R aus seiner schüchternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor:\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n\n  \n\n\n\n\n\n\n🧑‍🎓 Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket {dataExplorer} bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. Abbildung 9.8.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\nAbbildung 9.8: Heatmap zu den Korrelationen im Datensatz mariokart."
  },
  {
    "objectID": "070-zusammenhaenge.html#vertiefung",
    "href": "070-zusammenhaenge.html#vertiefung",
    "title": "9  Punktmodelle 2",
    "section": "\n9.6 Vertiefung",
    "text": "9.6 Vertiefung\nTED-Vortrag zum Thema Scheinkorrelation.\nHier finden Sie weitere Beispiele für Scheinkorrelationen."
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "9  Punktmodelle 2",
    "section": "\n9.7 Aufgaben",
    "text": "9.7 Aufgaben\nSchauen Sie sich auch mal auf Datenwerk die Aufgaben zu dem Tag association an."
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "9  Punktmodelle 2",
    "section": "\n9.8 Fallstudien",
    "text": "9.8 Fallstudien\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Übungsaufgaben können theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer Lösung anhand von Konzepten bzw. R-Befehlen, die Sie kennen.\\(\\square\\)\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nBitte verstehen Sie die folgende Auswahl an Fallstudien als Auswahl. Es ist nicht nötig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Übung, dort, wo Sie es nötig haben.\\(\\square\\)\n\n\n\nEDA zu Flugverspätungen\nYACSDA: Topgear\nExplorative Datenanalyse zum Datensatz “OECD Wellbeing”\nDatensatz flights: Finde den Tag mit den meisten Abflügen\nTidyverse Case Study: Exploring the Billboard Charts"
  },
  {
    "objectID": "070-zusammenhaenge.html#literatur",
    "href": "070-zusammenhaenge.html#literatur",
    "title": "9  Punktmodelle 2",
    "section": "\n9.9 Literatur",
    "text": "9.9 Literatur\n\n\n\n\nGoren, Andy, Sergio Vaño-Galván, Carlos Gustavo Wambier, John McCoy, Alba Gomez-Zubiaur, Oscar M. Moreno-Arrones, Jerry Shapiro, u. a. 2020. „A Preliminary Observation: Male Pattern Hair Loss Among Hospitalized COVID-19 Patients in Spain – A Potential Clue to the Role of Androgens in COVID-19 Severity“. Journal of Cosmetic Dermatology 19 (7): 1545–47. https://doi.org/10.1111/jocd.13443.\n\n\nMesserli, Franz H. 2012. „Chocolate Consumption, Cognitive Function, and Nobel Laureates“. New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/NEJMon1211064."
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "9  Punktmodelle 2",
    "section": "",
    "text": "auch Skalar genannt↩︎\nVisualisierung↩︎\n&gt; 🧑‍🎓 Typisches Lehrerbeispiel!!↩︎\nhoffentlich nicht Ihre Geduld↩︎\nBei der Varianz waren es Quadrate, bei der Kovarianz sind es Rechtecke.↩︎\nhttps://www.telegraph.co.uk/global-health/science-and-disease/bald-men-higher-risk-severe-case-covid-19-research-finds/, Abruf 2023-03-24↩︎\nBayesianische Interpretation↩︎"
  },
  {
    "objectID": "080-regression1.html#lernsteuerung",
    "href": "080-regression1.html#lernsteuerung",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n10.1.2 Lernziele\n\nSie können ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie können die Bestandteile eines Geradenmodells aufzählen und erläutern.\nSie können die Güte eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie können Geradenmodelle sowie ihre Modellgüte in R berechnen.\n\n10.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n10.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.2 Vorhersagen",
    "text": "10.2 Vorhersagen\nVorhersagen sind eine nützlich Sache, unter (mindestens) folgenden Voraussetzungen:\n\nSie sind präzise\nWir kennen die Präzision\nJemand interessiert sich für die Vorhersage\n\nDie Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n10.2.1 Vorhersagen ohne Prädiktor\n\nBeispiel 10.1 Nach intensiver Beschäftigung mit Statistik sind Sie allgemein als Checker bekannt. Viele jüngere Studentis fragen Sie um Rat. eines Tages kommt ei Studenti, Toni, und fragt: “Welche Statistiknote kann ich in der Klausur erwarten?” Sie entgegnen: “Wie viel hast du denn gelernt?”. Die Antwort: “Sag ich nicht.”\nNach kurzem Überlegen geben sie den Notenschnitt der letzten Klausur als Prognose für dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).\nZuerst importieren Sie die Daten der letzten Klausur1:\n\nnoten2 &lt;- read.csv(\"daten/noten2.csv\")\n\nDann rechnen Sie den Mittelwert aus:\n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n\n  \n\n\n\nIhre Antwort lautet also: “Im Schnitt haben die Studis bei der letzten Klausur gut 50% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorherage machen, sorry!”\\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nOhne Kenntnis eines Prädiktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert für jede Beobachtung, s. Abbildung 10.1. Wir nutzen den Mittelwert als Punktmodell für den Klausurerfolg.\\(\\square\\)\n\n\n\n\n\n\nAbbildung 10.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n10.2.2 Nullmodell\nModelle ohne Prädiktor, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da es null Prädiktoren hat, nennt man es auch manchmal “Nullmodell”.\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##       71.08\n\nlm steht für “lineares Modell”, die 0 sagt, dass es keine Prädiktoren gibt. In dem Fall wird der Mittelwert als Gerade verwendet. Der zurückgemeldete Koeffizient (Intercept) ist hier der Modell des Punktmodells. Da es ein Punktmodell ist, sagt es für alle Beobachtungen (hier Studentis) den gleichen Wert vorher.\nDie Regressionsgleichung lautet demnach: y_pred = 71.08. In Worten: “Wir sagen von jede Beobachtung einen Wert von ca. 71 vorher”.\n\n10.2.3 Vorhersagen mit Prädiktor\n\nBeispiel 10.2 (Toni verrät die Lernzeit) Dis Studenti, Toni, entschließt sich dann doch noch, die Lernzeit zu verraten: “Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.” Jetzt müssen Sie erstmal nachdenken: “Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 gelernt hat?”\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. Abbildung 10.2, links.\n\nnoten2 &lt;- read.csv(noten2, \"daten/noten2.csv\")\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: “Bei 42 Stunden Lernzeit solltest du so 46 Punkte bekommen. Könnte mit dem Bestehen eng werden.” Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.\\(\\square\\)\n\nDer Trend (im Sinne eines linearen Zusammenhangs) von Lernzeiten und Klausurpunkte ist deutlich zu erkennen. Mit einem Lineal könnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. Abbildung 10.2.\n\n\n\n\n\n(a) Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)\n\n\n\n\n\n(b) Eine ‘Trendgerade’ (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet.\n\n\n\nAbbildung 10.2: Noten und Lernzeit: Rohdaten und Modell\n\n\nEine Gerade eignet sich, um einen linearen Trend zusammenzufassen."
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.3 Geradenmodelle",
    "text": "10.3 Geradenmodelle\n\n10.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell für die Daten, s. Abbildung 10.2, rechts. Anders gesagt: Wir modellieren die X-Y-Daten (bzw. ihren Zusammenhang) mit einem Geradenmodell.\nEin Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt für alle Beobachtungen den gleichen Wert vorher. Abbildung 10.1 und Abbildung 10.2 stellen ein Punktmodell einem Geradenmodell gegenüber.\nIn einem Geradenmodell wird nicht mehr (notwendig) für jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 10.1 Eine Gerade ist definiert durch zwei Koeffizienten: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). Häufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet: \\(f(x)=y=\\color{blue}[m]x + \\color{red}[t]\\). In der Statistik wird folgende Nomenklatur bevorzugt: \\(f(x)=\\hat{y} = \\color{red}{b_0} + \\color{blue}{b_1}x\\) oder \\(y = \\color{red}{\\beta_0} + \\color{blue}{\\beta_1}x\\) .2\nAbbildung 10.3 skizziert die Elemente einer Regression.\n\n\n\nAbbildung 10.3: Achsenabschnitt und Steigung einer Regressionsgeraden\n\nBasierend auf diesem Diagramm von Henri Menke\n\nBeispiel 10.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert. “Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurück!”\nDas sind gute Fragen. Den Y-Wert (Klausurpunkte) bei \\(X=0\\) gibt der Achsenabschnitt zurück. Schnell skizzieren Sie dazu ein Diagramm, s. Abbildung 10.4. Puh, die Antwort wird Toni nicht gefallen …\n\n\n\n\n\nAbbildung 10.4: Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\nAnstelle auf Abbildung 10.4 zu schauen, können Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n🧑‍🎓 Hey R, predicte mir mal auf Basis vom Modell “lm1” den Lernerfolg für Toni, wenn der x=0 Stunden lernt.\n\n\n🤖 Okay, ich predicte mit Modell “lm1” und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)\ntonis_lernzeit\n\n\n\n  \n\n\n\n\npredict(lm1, newdata = tonis_lernzeit)\n##        1 \n## 8.603032\n\n\n10.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall so spezifizieren, s. Gleichung 10.1:\n\\[\\hat{y} \\sim x \\tag{10.1}\\]\nLies: “Laut meinem Modell ist \\(\\hat{y}\\) irgendeine Funktion von \\(y\\)”. Wir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.\nGleichung 10.1 können Sie so ins Errische übersetzen:\n\nlm(y ~ x, data = meine_daten)\n\nlm steht für “lineares Modell”, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade3.\n\nBeispiel 10.4 (Zahlen für Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: “Jetzt hör mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir präzise Zahlen!”.\n\n\nlm1 &lt;- lm(y ~ x, data = noten2)\nlm1\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      8.6030       0.8794\n\nR gibt Ihnen die beiden Koeffizienten für die Gerade aus. Den Namen des Objekts können Sie frei aussuchen, z.B. mein_erstes_lm.\nDie Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x\nMit Kenntnis der beiden Koeffizienten kann man beliebige Y-Werte ausrechnen gegeben bestimmte X-Werte.\nHat jemand zum Beispiel 10 Stunden gelernt, würden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 10\ny_pred &lt;- 8.6 + 0.88*lernzeit\ny_pred\n## [1] 17.4\n\n\nBeispiel 10.5 (Vorhersage für Klausurerfolg, nächster Versuch) Sie versuchen, noch etwas Gutes für Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dürfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)\n\n\npredict(lm1, newdata = tonis_lernzeit2)\n##       1 \n## 72.7999\n\n:::\nDie Syntax von predict lautet:\npredict(name_des_objekts, newdata = tabelle_mit_prädiktorwerten)\n\n\n\n\n\n\nHinweis\n\n\n\nMit predict bekommt man eine Vorhersage; im Standard eine “Punkt-Vorhersage”, eine einzelne Zahl.\\(\\square\\)\n\n\n\n10.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagten Wert für eine (neue) Beobachtung, \\(\\hat{y_0}\\) und ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, \\(e_i\\)) oder Residuum: \\(e_i = y_i - \\hat{y}_i\\).\n\n\n\n\n\n(a) Residuen beim Geradenmodell (lm1)\n\n\n\n\n\n(b) Residuen beim Punktmodell (lm0)\n\n\n\nAbbildung 10.5: Vorhersagefehler als Abweichungsbalken\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?\nLassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben4:\n\nmae(lm0)\n## [1] 11.18385\nmae(lm1)\n## [1] 7.954085\n\nVergleichen wir MAE im Nullmodell mit MAE in lm1:\n\nverhaeltnis_fehler_gerade_zu_punkt_mae &lt;- mae(lm1) / mae(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mae\n## [1] 0.7112118\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm1 haben die mittlere (Absolut-)Länge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 10.2 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)).\\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngrößen wie MAE oder MSE.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreung), solange X mit Y korreliert ist.\\(\\square\\)\n\n\nNatürlich können wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen5.\n\nmse(lm0)\n## [1] 192.7863\nmse(lm1)\n## [1] 106.4519\n\n\nverhaeltnis_fehler_gerade_zu_punkt_mse &lt;- mse(lm1)/mse(lm0)\nverhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.5521755\n\n\n10.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?\nDie Regressionskoeffizienten6 b0 und b1 wählt man so, dass die Residuen minimal sind. Es gibt verschiedene Algorithmen, um dies zu berechnen7. Eine schöne Darstellung dazu findet sich bei Kaplan (2009).\n“Von Hand” können Sie die Optimierung von b0 und b1 in dieser App der FOM-Hochschule ausprobieren."
  },
  {
    "objectID": "080-regression1.html#r-quadrat",
    "href": "080-regression1.html#r-quadrat",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.4 R-Quadrat",
    "text": "10.4 R-Quadrat\n\n10.4.1 R-Quadrat als Verringerung der Fehlerstreuung\nAnders gesagt, wir haben uns um \\(1 - 0.55\\) verbessert:\n\n1 - verhaeltnis_fehler_gerade_zu_punkt_mse\n## [1] 0.4478245\n\n\nDefinition 10.3 (R-Quadrat) Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen von lm0 zum gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). R-Quadrat (\\(R^2\\)) eines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1- \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein Maß der Modellgüte: Je größer \\(R^2\\), desto besser die Vorhersage. Da es ein Anteilsmaß8 ist, liegt der Wertebereich zwischen 0 uns 1. Im Nullmodell liegt R-Quadrat per Definition bei 0. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nWir können R-Quadrat (\\(R^2\\)) uns von R z.B. so ausgeben lassen:\n\nr2(lm1)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\)9, s. Abbildung 10.6.\n\n\n\n\n\n(a) Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert\n\n\n\n\n\n(b) Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert\n\n\n\nAbbildung 10.6: Extremfälle von R-Quadrat: 0 und 1\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man für jedes \\(y\\) den Mittelwert, \\(\\bar{y}\\), vorhersagen würde.\n\n\n\n\n\n\nHinweis\n\n\n\nJe größer R-Quadrat, desto besser erklärt das Modell die Daten (desto besser der “Fit”, sagt man).\n\n\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der Größe der Residuen eines linearen Modells zu spielen."
  },
  {
    "objectID": "080-regression1.html#interpretation-eines-regressionsmodells",
    "href": "080-regression1.html#interpretation-eines-regressionsmodells",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.5 Interpretation eines Regressionsmodells",
    "text": "10.5 Interpretation eines Regressionsmodells\n\n10.5.1 Modellgüte\nDie Residuen (Vorhersagefehler) bestimmen die Modellgüte: Sind die Residuen im Schnitt groß, so ist die Modellgüte gering (schlecht), und umgekerht. Verschiedenen Koeffizienten stehen zur Verfügung: R-Quadrat, r10, MSE, RMSE, MAE, …\n\n10.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(b_0\\)) und Steigung (\\(b_1\\)) sind nur eingeschränkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abhängigkeiten nicht kennt. Nur aufgrund eines Zusammenhangs darf man keine kausalen Abhängigkeiten annehmen. Ohne eine guten Grund für eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der Modellgüte und den Vorhersagen begnügen. Was auch was wert ist.\n\n10.5.2.1 Achsenabschnitt (b0)\n“Im Modell lm1 liegt der Achsenabschnitt bei \\(y=8.6\\). Beobachtungen mit \\(x=0\\) können also diesen Y-Wert erwarten.” Leider ist es häufig so, dass Prädiktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nützt.\n\nBeispiel 10.6 (Regression Größe und Gewicht) Nutzt man Körpergröße umd das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von Körpergröße wenig nützlich, da es keine Menschen gibt der Größe 0.\\(\\square\\)\n\n\n10.5.2.2 Geradensteigung (b1)\n“Im Modell lm1 beträgt der Regressionskoeffizient b1 \\(0.88\\). Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von b1.”\n\n\n\n\n\n\nVorsicht\n\n\n\nHäufig liest man, der “Effekt des Prädiktors” auf die AV betrage z.B. \\(0.88\\). “Effekt” ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort “Effekt” mit Vorsicht genießen. Manche sprechen daher auch von einem “statistischen Effekt”.\\(\\square\\)."
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.6 Fallbeispiel Mariokart",
    "text": "10.6 Fallbeispiel Mariokart\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie möchten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs. Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz. Auf geht’s!\nDaten laden:11\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloßen Rumprobieren überlegen Sie und schauen dann in Abbildung 9.8 nach, welche Variable am stärksten korreliert mit total_pr, es resultiert lm3:\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\nparameters(lm3)\n\n\n\n\n\nTabelle 10.1: Modellparameter von lm3\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Euro, wie man in Tabelle 10.1 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut lm3 etwa 36 Euro finaler Verkaufspreis erwarten. Pro Euro an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.12.\nDie Regressionsgleichung von lm3 lautet demnach:\ntotal_pr_pred = 36.25 + 4.34*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36.25€ “Sockelbetrag” plus 4.34 mal die Versandkosten.\n\nMan kann sich die erwarteten Werte (“expectations”) des Verkaufspreises in Abhängigkeit vom Wert der UV (ship_pr) auch schätzen (“to estimate”) lassen, und zwar so13:\n\nestimate_expectation(lm3) %&gt;% head()  # nur die ersten paar vorhergesagten Werte\n\n\n\n  \n\n\n\nAh, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.\n\n🤖 Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert für total_pr für einen bestimmten Wert von ship_pr.\n\n\n🧑‍🎓 Kann ich auch predict benutzen? Ich würde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.\n\n\n🤖 Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen\n)\n\n\npredict(lm3, newdata = neue_daten)\n##        1        2 \n## 40.58276 53.59442\n\nAber nützlich wäre noch, das Modell (bzw. die Schätzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.B. so, s. Abbildung 11.11.\n\nestimate_expectation(lm3) %&gt;% plot()\n\n\n\nAbbildung 10.7: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\nestimate_expectation heißt sinngemäß “schätze den zu erwartenden Wert”. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie “gut” das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13.0632\n\nDas Modell erklärt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nmae(lm3)\n## [1] 13.0632\n\nIm nächsten Meeting erzählen Sie Ihrem Chef “Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!”. Hört sich gut an. Allerdings hätte ihr Chef es gerne genauer. Kann man da noch was machen?"
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.7 Fallstudie Immobilienpreise",
    "text": "10.7 Fallstudie Immobilienpreise\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie stellt die Prüfungsleistung “Prognosewettbewerb” einführend dar. Es empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten.\\(\\square\\)\n\n\n\n10.7.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei Kaggle ein.\nKaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet.\nIn dieser Fallstudie nehmen Sie teil an der Kaggle-Competition Ames House Prices.\n\nBeschreibung\nZiel/Aufgabe\nSpielregeln\n\n10.7.2 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\n10.7.3 Daten\nWenn Sie sich bei Kaggle einloggen möchten, können Sie die Daten von Kaggle herunterladen und zwar hier.\nIm Einzelnen müssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Code book, d.h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen\n\nSie können auch so auf die Daten zugreifen:\n\nd_train_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/train.csv\"\nd_test_path_online &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/ames-kaggle/test.csv\"\n\nd_train &lt;- read_csv(d_train_path_online)\nd_test &lt;- read_csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab.\nDas Code Book können Sie hier einsehen und herunterladen.\n\n10.7.4 Prognosedatei\nDie Prognosedatei soll prinzipiell so aussehen:\n\n\n\n\n  \n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist - für welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice ist Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt.\nAlles klar?\nLos geht’s!\n\n10.7.5 Daten importieren\nWir starten die üblichen R-Pakete und importieren die Daten (d):\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\nd_train_path &lt;- \"daten/ames-kaggle/train.csv\"\nd_test_path &lt;- \"daten/ames-kaggle/test.csv\"\nd_train &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\n\n\n\n\n\n\nHinweis\n\n\n\nIn diesem Beispiel gehen wir davon aus, dass die Dateien train.csv und test.csv in einem Unterordner namens daten/ames-kaggle liegen. Sie müssen sie dort abspeichern. Dieser Ornder muss ein Unterordner Ihres aktuellen R-Projekts sein.\\(\\square\\)\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn das Importieren von der Festplatte nicht klappt … Es ist hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.\\(\\square\\)\n\n\n\nd_train &lt;- read_csv(d_train_path_online)\nd_test &lt;- read_csv(d_test_path_online)\n\n\n10.7.6 Ein erster Blick in die Daten\nSchauen wir uns einmal die Verteilung der metrischen Variablen an, Tabelle 10.2.\n\ndescribe_distribution(d_train)\n\n\n\n Tabelle 10.2:  Verteilung der metrischen Variablen im ames-Datensatz \n  \n\n\n\n\n\n10.7.7 Ein erstes Vorhersagemodell\n\n10.7.7.1 Welche Variablen eignen sich zur Vorhersage?\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller Prädiktoren mit der abhängigen Variablen14 zu berechnen, s. Tabelle 10.3.\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; 3.\n\n\n\n\n\nTabelle 10.3: Korrelation der Prädiktoren (UV) mit der AV\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\n95% CI\nt\ndf\np\n\n\n\nOverallQual\nSalePrice\n0.79\n(0.77, 0.81)\n49.36\n1458\n&lt; .001***\n\n\nGrLivArea\nSalePrice\n0.71\n(0.68, 0.73)\n38.35\n1458\n&lt; .001***\n\n\nGarageCars\nSalePrice\n0.64\n(0.61, 0.67)\n31.84\n1458\n&lt; .001***\n\n\nGarageArea\nSalePrice\n0.62\n(0.59, 0.65)\n30.45\n1458\n&lt; .001***\n\n\nTotalBsmtSF\nSalePrice\n0.61\n(0.58, 0.64)\n29.67\n1458\n&lt; .001***\n\n\n1stFlrSF\nSalePrice\n0.61\n(0.57, 0.64)\n29.08\n1458\n&lt; .001***\n\n\nFullBath\nSalePrice\n0.56\n(0.52, 0.59)\n25.85\n1458\n&lt; .001***\n\n\nTotRmsAbvGrd\nSalePrice\n0.53\n(0.50, 0.57)\n24.10\n1458\n&lt; .001***\n\n\nYearBuilt\nSalePrice\n0.52\n(0.48, 0.56)\n23.42\n1458\n&lt; .001***\n\n\nYearRemodAdd\nSalePrice\n0.51\n(0.47, 0.54)\n22.47\n1458\n&lt; .001***\n\n\nGarageYrBlt\nSalePrice\n0.49\n(0.44, 0.53)\n20.66\n1377\n&lt; .001***\n\n\nMasVnrArea\nSalePrice\n0.48\n(0.44, 0.52)\n20.69\n1450\n&lt; .001***\n\n\nFireplaces\nSalePrice\n0.47\n(0.43, 0.51)\n20.16\n1458\n&lt; .001***\n\n\nBsmtFinSF1\nSalePrice\n0.39\n(0.34, 0.43)\n16.00\n1458\n&lt; .001***\n\n\nLotFrontage\nSalePrice\n0.35\n(0.30, 0.40)\n13.01\n1199\n&lt; .001***\n\n\nWoodDeckSF\nSalePrice\n0.32\n(0.28, 0.37)\n13.10\n1458\n&lt; .001***\n\n\n2ndFlrSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.87\n1458\n&lt; .001***\n\n\nOpenPorchSF\nSalePrice\n0.32\n(0.27, 0.36)\n12.71\n1458\n&lt; .001***\n\n\n\n\np-value adjustment method: Holm (1979) Observations: 1201-1460\n\n\nAha! Ein Menge Information.15\nDiese Variablen sind einigermaßen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage.\n\n10.7.7.2 Model 1\nBerechnen wir ein erstes Modell für diese Forschungsfrage, s. Tabelle 10.4.\n\nm1 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(m1)\n\n\n\n\n\nTabelle 10.4: Modellparameter von m1\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(1456)\np\n\n\n\n(Intercept)\n-98832.49\n4842.90\n(-1.08e+05, -89332.69)\n-20.41\n&lt; .001\n\n\nOverallQual\n27104.83\n1072.18\n(25001.64, 29208.01)\n25.28\n&lt; .001\n\n\nGrLivArea\n50.67\n2.55\n(45.67, 55.68)\n19.86\n&lt; .001\n\n\nGarageCars\n21298.96\n1807.06\n(17754.23, 24843.69)\n11.79\n&lt; .001\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells für die Daten von d_train?\n\nrmse(m1)\n## [1] 40566.42\n\nIm Schnitt liegen unsere Vorhersagen ca. 40 Tausend Dollar daneben. Ist das gut?\n\nr2(m1)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n\nOb das R-Quadrat “gut” oder “hoch” ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen.\n\n10.7.7.3 Nullmodell\nZum Vergleich berechnen wir das maximal einfache Modell: ohne Prädiktoren. Man nennt es das “Nullmodell”. In diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnomdells?\n\nrmse(m0)\n## [1] 79415.29\n\nDas R-Quadrat der Nullmodells ist per Definition Null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n10.7.8 Vorhersagen im Test-Datensatz\nWir haben jetzt unseren Champion, m1. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample präzise sein werden? Oder himmelweit daneben? Bitte, enttäusche uns nicht!\nHier sind die Vorhersagen:\n\nm1_pred &lt;- predict(m1, newdata = d_test)\nhead(m1_pred)\n##        1        2        3        4        5        6 \n## 103394.7 152441.4 161837.8 187675.8 225467.0 190260.2\n\n\n1\n\npredicte anhand der Regressionsgerade von m1 und zwar anhand der Daten aus d_test\n\n2\n\nzeige den “Kopf” der Vorhersagen (m1_pred), d.h. die ersten paar Vorhersagen\n\n\n\n\nDie Vohersagen fügen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = m1_pred)\n\n\n10.7.9 Einreichen!\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhesagen ein.\nFür die Prognosedatei (submission file) zum Einreichen brauchen wir nur die Spalten id und SalePrice:\n\nm1_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\nKaggle möchte keine fehlenden Werten in den Vorhersagen, also prüfen wir das mal:\n\nm1_subm %&gt;% \n  drop_na() %&gt;%\n  nrow()\n## [1] 1458\n\n\n1\n\nLass alle Zeilen mit NAs (fehlenden Werten in irgendeiner Spalte) fallen, filtere diese Zeilen also raus\n\n2\n\nzähle die Anzahl der Zeilen\n\n\n\n\nOh, das ist eine Zeile weniger! Wir haben also einen fehlenden Wert!\nFiltern wir die Spalte SalePrice mal nach “ist NA”:\n\nm1_subm %&gt;% # &lt;1)\n  filter(is.na(SalePrice))\n\n\n\n  \n\n\n\nÜbersetzen wir die Syntax auf Detusch:\n\nNimm zuerst die Tabelle m1_smb\n\nFilter dann so, dass du nur Zeilen hast, für die gilt, “hier ist ein NA in der Spalte SalePrice\n\n\nAh, da ist er, der fehlende Wert, in Zeile 2577! Hinfort!\nWir ersetzen die fehlenden Werte in SalePrice mit dem Mittelwert von SalePrice:\n\nm1_subm_nona &lt;-\n  m1_subm %&gt;%\n  mutate(SalePrice = replace_na(SalePrice, mean(SalePrice, na.rm = TRUE)))\n\nDie Syntax wieder auf Deutsch:\n\nDefiniere m1_subm_nona wie folgt\nNimm m1_subm und dann\nVerändere die Spalte SalePrice und zwar so, dass NAs ersetzt werden durch den Mittelwert von SalePrice\n\n\nUnd? Gib es jetzt noch fehlende Werte?\n\nm1_subm_nona %&gt;% \n  filter(is.na(SalePrice))\n\n\n\n  \n\n\n\nNein! Die Ergebnistabelle hat null Zeilen. “No NA” - Keine NAs, keine fehlenden Werte mehr.\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab.16.\n\nwrite_csv(m1_subm_nona, \"daten/ames-kaggle/m1-subm.csv\")\n\nUnd dann laden Sie diese Datei, m1_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn.\nDas Modell erzielte einen Score von 0.55521.\n\n10.7.10 Debrief\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele Ansätze, dieses Modell zu verbessern.\nHier sind einige Fragen, die Sie sich dazu stellen können:\n\nWelche Prädiktoren sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn ein Prädiktor schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche Prädiktoren quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n…\n\nViel Spielraum für Ihre Kreativität!"
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.8 Aufgaben",
    "text": "10.8 Aufgaben\nEine Aufgabe, die eine Einführung zum [Kaggle-Wettbewerb Ames House Prices]((https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview) bietet, finden Sie hier im Datenwerk.\nSuchen Sie beim Datenwerk nach diesen Aufgaben\n- Aussagen-einfache-Regr\n- interpret-koeff-lm\n- korr-als-regr\n- Linearitaet1a\n- lm1\n- mtcars-regr01\n- nichtlineare-regr1\n- penguins-regr02\n- regression1\n- regression1b\n- Regression3\n- Regression4\n- Regression5\n- Regression6\nSchauen Sie sich die Aufgaben beim Datenwerk an, vor allem die Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff; vielleicht können Sie einige Aufgaben nicht lösen. Ignorieren Sie einfach diese Aufgaben.\nBeachten Sie die Hinweise zu den Aufgaben."
  },
  {
    "objectID": "080-regression1.html#literatur",
    "href": "080-regression1.html#literatur",
    "title": "10  Geradenmodelle 1",
    "section": "\n10.9 Literatur",
    "text": "10.9 Literatur\n\n\n\n\nKaplan, Daniel T. 2009. Statistical modeling: a fresh approach. Scotts Valley, Calif.: CreateSpace. https://dtkaplan.github.io/SM2-bookdown/."
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "10  Geradenmodelle 1",
    "section": "",
    "text": "Diese Syntax wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls müssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.↩︎\nDie Nomenklatur mit \\(b_0, b_1\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, ...\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage über eine Population, nicht nur über eine Stichprobe, machen möchte.↩︎\nan anderer Stelle in diesem Buch unscharf als “Trendgerade” bezeichnet.↩︎\naus dem Paket easystats↩︎\nWer mag, kann den MSE auch von Hand berechnen: mean((noten2$y-mean(noten2$y))^2)↩︎\nhier synonym: Modellparameter↩︎\naber nicht in diesem Buch zu finden↩︎\nProzentzahl↩︎\nBei Modellen mit einem Prädiktor; gibt es mehrere Prädiktoren gilt die Beziehung nur wenn die Prädiktoren alle paarweise unabhängig sind.↩︎\nals Korrelation von tatsächlichem \\(y\\) und vorhergesaten $↩︎\nUnd die üblichen Pakete starten, nicht vergessen.↩︎\nDie Spalte 95 CI gibt einen Schätzbereich für den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um Schätzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schließlich nur eine Stichprobe der Größe \\(n=143\\).↩︎\nDie Funktion stammt aus easystats↩︎\ndie vorherzusagende Variable, auch Ziel- oder Outcome-Variable genannt↩︎\nWenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: Führen Sie die Syntax schrittweise aus. Zuerst d_train ausführen und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausführen, wieder die Ausgabe betrachten, usw.↩︎\nEs bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice↩︎"
  },
  {
    "objectID": "090-regression2.html#lernsteuerung",
    "href": "090-regression2.html#lernsteuerung",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Standort im Lernpfad\nAbb. Abbildung 1.2 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel.\n\n11.1.2 Lernziele\n\nSie können Regressionsmodelle für Forschungsfragen mit binärer, nominaler und metrischer UV erläutern und in R anwenden.\nSie können Interaktionseffekte in Regressionsmodellen erläutern und in R anwenden.\nSie können den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erläutern und in R anwenden.\nSie können Modelle nutzen, um Vorhersagen anhand neuer Daten zu erstellen.\n\n11.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(yardstick)  # für Modellgüte im Test-Sample\nlibrary(easystats)\n\n\n11.1.4 Benötigte Daten\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")"
  },
  {
    "objectID": "090-regression2.html#mighty-regression",
    "href": "090-regression2.html#mighty-regression",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.2 Mighty Regression",
    "text": "11.2 Mighty Regression\nLineare Modelle1 sind ein altes, aber mächtiges Werkzeug. Sie gehören immernoch zum Standard-Repertoire moderner Analysten.\n\nBeispiel 11.1 (Wie gut kann man Ihre Persönlchkeit auf Basis des Facebook-Profils vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Kosinski, Stillwell, und Graepel (2013), wie gut Persönlichkeitszüge durch Facebook-Daten (Likes etc.) vorhergesagt werden können. Die Autoren resümieren:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten über hohe Modellgüte (\\(r\\)) zwischen den tatsächlichen persönlichen Attributen und den vorhergesagten Werten Ihres Modells, s. Abbildung 11.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also ähnlich zu dem in diesem Kapitel vorgestellten Methoden.\\(\\square\\)\n\n\n\nAbbildung 11.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values"
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.3 Wetter in Deutschland",
    "text": "11.3 Wetter in Deutschland\n\nBeispiel 11.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach ewtas Abwechslung. Viel Geld verdienen und Ruhm und Anerkennung sind ja schon ganz nett, aber Ihnen viel ein, dass Sie ja zu Generation Z gehören, und daher den schnöden Mammon nicht so hoch schätzen sollten. Sie entschließen sich, Ihre hochgeschätzten Analyse-Skills für etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels.\nBeim Deutschen Wetterdienst, DWD haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen resultiert ein schöner Datensatz, den Sie jetzt analysieren wollen2:\n\nwetter_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/wetter-dwd/precip_temp_DWD.csv\"\nwetter &lt;- read.csv(wetter_path)\n\nEin Data-Dictionary für den Datensatz können Sie hier herunterladen.\n\n\n\n\n\n\nHinweis\n\n\n\nEin Data-Dictionary (Codebook) erklärt einen Datensatz. Oft bedeutet das, das für jede Spalte der Datentabelle erklärt wird, was die Spalte bedeutet.\\(\\square\\)\n\n\nIn Tabelle 11.1 und Abbildung 11.2 kann man sich die Daten en Detail anschauen (Temperatur und Niederschlag im Zeitverlauf).\n\n\n\nTemperatur (Grad Celcius) im Veraluf der Jahre\n\n\n\nNiederschlage (mm) im Veraluf der Jahre\n\nAbbildung 11.2: Veränderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland\n\n\n\n\n\n Tabelle 11.1:  Wetterdaten für Deutschland \n  \n\n\n\n\nHervorragend!\nAn die Arbeit 💪\n\n\n11.3.1 metrische UV\nSie stellen sich nun folgende Forschungsfrage:\n\n🧑‍🎓 Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in Tabelle 11.2 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\n\n Tabelle 11.2:  Modellparameter von lm_wetter1 \n  \n\n\n\n\nLaut Ihrem Modell wurde es pro Jahr um 0.01 Grad wärmer, pro Jahrzehnt also 0.1 und pro Jahrhundert 1 Grad.\n\n🧑‍🎓 Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\n👨‍🏫 Mit der Ruhe, das schauen Sie sich später an.\n\nDas Modell, bzw. die Schätzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. Abbildung 11.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. Abbildung 11.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))\n\nAuf dieser Basis erstellen wir ein neues lineares Modell, s. Tabelle 11.3.\n\nlm_wetter1a &lt;- lm(temp ~ year, data = wetter_summ)\nparameters(lm_wetter1a)\n\n\n\n\n\nTabelle 11.3: Modellparameter von lm_wetter1a\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(140)\np\n\n\n\n(Intercept)\n-14.14\n2.70\n(-19.48, -8.79)\n-5.23\n&lt; .001\n\n\nyear\n0.01\n1.38e-03\n(8.86e-03, 0.01)\n8.38\n&lt; .001\n\n\n\n\n\n\n\nplot(estimate_relation(lm_wetter1))\nplot(estimate_relation(lm_wetter1a))\n\n\n\n\n\n(a) Jeder Punkt ist ein Tag\n\n\n\n\n\n(b) Jeder Punkt ist ein Jahr (wetter_summ)\n\n\n\nAbbildung 11.3: Die Veränderung der mittleren Temperatur in Deutschland im Zeitverlauf (Datenquelle: DWD)\n\n\n\n\n🧑‍🎓 Moment mal, der Achsenabschnitt liegt bei -15 Grad! Was soll das bitte bedeuten?\n\n\n11.3.2 UV zentrieren\n\nDefinition 11.1 Der Achsenabschnitt (\\(\\beta_0\\); engl. Intercept) ist definiert als der Y-Wert an der Stelle X=0.\\(\\square\\)\n\nIn den Wetterdaten wäre Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extraplieren, ganz ohne dass wir dafür Daten haben, s. Abbildung 11.4.\n\n\nAbbildung 11.4: Du sollst nicht ein Modell weit außerhalb seines Datenbereichs extrapolieren\n\nSinnvoller ist es da, z.B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezöge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn für dieses Jahr haben wir Daten.\nHat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es üblich, z.B. den Mittelwert als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten.\nSo zentriert man eine Verteilung:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist übrigens 1951:\n\nwetter %&gt;% \n  summarise(mean(year))\n\n\n\n  \n\n\n\nDie Steigung (d.h. der Regressionskoeffizient für year_c) bleibt unverändert, nur der Achsenabschnitt ändert sich, s. Tabelle 11.4.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert)\n\n\n\n\n\nTabelle 11.4: Modellparameter von lm_wetter1_zentriert\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(28864)\np\n\n\n\n(Intercept)\n8.49\n0.04\n(8.42, 8.57)\n219.43\n&lt; .001\n\n\nyear c\n0.01\n9.47e-04\n(9.80e-03, 0.01)\n12.30\n&lt; .001\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5 Grad Celcius. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49 Grad plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\n\n\n\n\n\n\nReferenzwert entspricht Null\n\n\n\nDer Referenzwert bzw. die Referenzgruppe entspricht dem Wert x=0 im Regressionsmodell.\\(\\square\\)\n\n\nWie gut erklärt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystat}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklärt das Modell mit year_c3 aber nicht. Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.B. die Jahreszeit eine große Rolle für die Temperatur. Das haben wir nicht berücksichtigt.\n\n🧑‍🎓 Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##       1 \n## 9.65775\n\n\n🧑‍🎓 Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5° Celcius.4\n\n\n👨‍🏫 Wir brauchen ein besseres Modell! Zum Glück haben wir ambitionierte Nachwuchs-Wissenschaftler:innen.\n\nDie Veränderung der auf fünf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in Abbildung 11.5 dargestellt. Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)5; rechts eine feinere (Daten ab 1881)6.\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020\n\nAbbildung 11.5: \n\nBildquelle; Lizenz: GeoNutzV\n\n11.3.3 Binäre UV\n\nDefinition 11.2 (Binäre Variable) Eine binäre UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei Ausprägungen: 0 und 1.\\(\\square\\)\n\n\nBeispiel 11.3 (Binäre Variablen) Das sind zum Beispiel weiblich mit den Ausprägungen 0 (nein) und 1 (ja) oder before_1950 mit 1 für Jahre früher als 1950 und 0 ansonsten.\\(\\square\\)\n\n\nBeispiel 11.4 Hier interessiert Sie folgende Forschungsfrage:\n\n🧑‍🎓 Ob es in der zweiten Hälfte des 20. Jahrhunderts wohl wärmer warm, im Durchschnitt, als vorher?\\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite Hälfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Überlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 4.4.4) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nJa, so könnte das klappen! Diese Syntax übertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten für Gesamt-Deutschland\n\nScheint zu klappen!\nJetzt ein lineares Modell dazu\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\nDie Parameter des Modells lassen darauf schließen, dass es tatsächlich wärmer war nach 1950, und zwar im Schnitt offenbar ein gutes halbes Grad, s. Abbildung 11.6.\n\nplot(parameters(lm_wetter_bin_uv))\nplot(estimate_expectation(lm_wetter_bin_uv))\n\n\n\n\n\n(a) Der Schätzbereich für den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied\n\n\n\n\n\n(b) Wie man sieht, überlappen die Temperaturen dennoch beträchtlich; aufgrund des starken “Overplotting” ist dieses Diagramm nict ideal\n\n\n\nAbbildung 11.6: Modell temp ~ after_1950\n\n\n\nLeider zeigt ein Blick zum r2, dass die Vorhersagegüte des Modells zu wünschen übrig lässt7.\\(\\square\\)\n\n\n\n\n\n\nLineare Modelle verkraften nur metrische Variablen\n\n\n\nUm die Koeffizienten eines linearen Modells auszurechnen, benötigt man eine metrische X- und eine metrische Y-Variable. Hier haben wir aber keine richtige metrische X-Variable8, sondern eine logische Variable mit den Werten TRUE und FALSE.\\(\\square\\)\n\n\nUm die X-Variable in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R für uns ohne viel Ankündigung durchführt.\n\n\n\n\n\n\nHinweis\n\n\n\nHat ein nominaler Prädiktor zwei Stufen, so überführt9 lm() diese Variable in eine binäre Variable. Da eine binäre Variable metrisch ist, kann die Regression in gewohnter Weise durchgeführt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binäre Variable. Man beachte, dass der ursprüngliche Datensatz nicht geändert wird, nur während der Analyse von lm wird die Umwandlung der Variable 10 druchgeführt.\\(\\square\\)\n\n\n\n🤖 Eine 1 kannst du als “Ja! Richtig!” verstehen und eine0 als “Nein! Falsch!”\n\n\nafter_1950 wird in eine Indikatorvariable umgewandelt:\n\n\n\n\n\n  \n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n  \n\n\n\n\n\n\nBeispiel 11.5 (Beispiel: ‘Geschlecht’ in eine binäre Variable umwandeln.) Angeonmen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umgewandeln. Da “Frau” alphabetisch vor “Mann” kommt, nimmt R “Frau” als erste Stufe bzw. als Referenzgruppe. “Mann” ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann).\\(\\square\\)\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\nEin lineares Modell mit binärer UV ist nichts anderes die Differenz der Gruppenmittelwerte zu berechnen:\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n\n  \n\n\n\nDie Interpretation eines linearen Modells mit binärer UV veranschaulicht Abbildung 11.7: Der Achsenabschnitt (b0) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe.\n\n\n\n\nAbbildung 11.7: Sinnbild zur Interpretation eines linearen Modells mit binärer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\nFassen wir die Interpretation der Koeffizienten für das Modell mit binärer UV zusammen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der Regressionsgeraden (b1)\n\n11.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineare Modell11 mit einer mehrstufigen12 (nominalskalierten) UV.13\n\nBeispiel 11.6 Ob es wohl substanzielle14 Temperaturunterschiede zwischen den Bundesländern gibt?\n\nBefragen wir dazu ein lineares Modell, s. Tabelle 11.5.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\nparameters(lm_wetter_region)\n\n\n\n\n\nTabelle 11.5: Modellparameter für lm_wetter_region\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27152)\np\n\n\n\n(Intercept)\n8.25\n0.16\n(7.93, 8.56)\n51.62\n&lt; .001\n\n\nregion (Bayern)\n-0.63\n0.23\n(-1.07, -0.19)\n-2.79\n0.005\n\n\nregion (Brandenburg)\n0.57\n0.23\n(0.13, 1.02)\n2.53\n0.011\n\n\nregion (Brandenburg/Berlin)\n0.58\n0.23\n(0.14, 1.03)\n2.59\n0.010\n\n\nregion (Hessen)\n0.11\n0.23\n(-0.33, 0.56)\n0.51\n0.612\n\n\nregion (Mecklenburg-Vorpommern)\n0.08\n0.23\n(-0.37, 0.52)\n0.34\n0.732\n\n\nregion (Niedersachsen)\n0.52\n0.23\n(0.07, 0.96)\n2.29\n0.022\n\n\nregion (Niedersachsen/Hamburg/Bremen)\n0.52\n0.23\n(0.08, 0.96)\n2.31\n0.021\n\n\nregion (Nordrhein-Westfalen)\n0.80\n0.23\n(0.35, 1.24)\n3.53\n&lt; .001\n\n\nregion (Rheinland-Pfalz)\n0.46\n0.23\n(0.02, 0.90)\n2.03\n0.042\n\n\nregion (Saarland)\n0.71\n0.23\n(0.27, 1.16)\n3.16\n0.002\n\n\nregion (Sachsen)\n-0.04\n0.23\n(-0.48, 0.40)\n-0.18\n0.853\n\n\nregion (Sachsen-Anhalt)\n0.55\n0.23\n(0.11, 1.00)\n2.45\n0.014\n\n\nregion (Schleswig-Holstein)\n0.17\n0.23\n(-0.27, 0.62)\n0.76\n0.446\n\n\nregion (Thueringen)\n-0.48\n0.23\n(-0.92, -0.03)\n-2.11\n0.035\n\n\nregion (Thueringen/Sachsen-Anhalt)\n0.10\n0.23\n(-0.34, 0.54)\n0.43\n0.664\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariablen um. Genauer gesagt ist es immer eine Indikatorvariablen weniger als es Stufen in der nominalskalierten Variablen gibt.\n\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland (aus Gründen der Einfachheit hier nur mit 3 Bundesländern). Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt:\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWü\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\nAuch im Fall mehrerer Ausprägungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binären Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (b0)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 1. Regressionsgeraden (b1)\nMittelwert der 2. Gruppe: Achsenabschnitt (b0) + Steigung der 2. Regressionsgeraden (b2)\nusw.\n\nAm Anfang kann es nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts ausgewählt wurde) nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt.\n\n\n\n\n\n\nHinweis\n\n\n\nBei einer Variable vom Typ character wählt R den alphabetisch ersten Wert als Referenzgruppe für ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 11.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt. \\(\\square\\)\n\n\n\nBeispiel 11.7 (Achsenabschnitt in wetter_lm2) Da Baden-Württemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewählt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird.\\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. Abbildung 11.8.\n\n\n\n\nAbbildung 11.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben). Die Achsen wurden um 90° gedreht, damit man die Namen der Bundesländer besser lessen kann.\n\n\n\n\nBeispiel 11.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht außer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechnen!\n\n🤖 Endlich geht’s weiter! Ergebnisse in Tabelle 11.6! \\(\\square\\)\n\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\n\nTabelle 11.6: Modellparameter für lm_wetter-month”\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschied im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. Abbildung 11.9, links.15 Oh nein: R betrachtet month als numerische Variable! Aber “Monat” bzw. “Jahreszeit” sollte nominal sein.\n\n🤖 Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\nOkay, R, wir müssen month in eine nominale Zahl transformieren.\n\n🤖 Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heißt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 11.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren.\\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. Tabelle 11.7.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor)\n\n\n\n\n\nTabelle 11.7: Modellparameter von lm_wetter_month_factor\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27156)\np\n\n\n\n(Intercept)\n56.95\n0.64\n(55.68, 58.21)\n88.56\n&lt; .001\n\n\nmonth factor (2)\n-9.95\n0.91\n(-11.73, -8.17)\n-10.94\n&lt; .001\n\n\nmonth factor (3)\n-7.78\n0.91\n(-9.56, -6.00)\n-8.56\n&lt; .001\n\n\nmonth factor (4)\n-8.49\n0.91\n(-10.27, -6.71)\n-9.34\n&lt; .001\n\n\nmonth factor (5)\n4.74\n0.91\n(2.96, 6.53)\n5.22\n&lt; .001\n\n\nmonth factor (6)\n14.34\n0.91\n(12.56, 16.12)\n15.77\n&lt; .001\n\n\nmonth factor (7)\n24.36\n0.91\n(22.57, 26.14)\n26.74\n&lt; .001\n\n\nmonth factor (8)\n17.52\n0.91\n(15.74, 19.31)\n19.24\n&lt; .001\n\n\nmonth factor (9)\n1.93\n0.91\n(0.15, 3.72)\n2.12\n0.034\n\n\nmonth factor (10)\n2.29\n0.91\n(0.51, 4.08)\n2.52\n0.012\n\n\nmonth factor (11)\n0.89\n0.91\n(-0.89, 2.68)\n0.98\n0.327\n\n\nmonth factor (12)\n5.20\n0.91\n(3.42, 6.99)\n5.71\n&lt; .001\n\n\n\n\n\n\nSehr schön! Jetzt haben wir eine Referenzgruppe (Monat 1, d.h. Januar) und 11 Unterschiede zum Januar, s. Abbildung 11.9, rechts.\n\n\n\n\n\n(a) Modell lm_wetter_month, Monat fälschlich als metrische Variable\n\n\n\n\n\n(b) Modell lm_wetter_month_text, Monat korrekt als nominale Variable\n\n\n\nAbbildung 11.9: Niederschlagsunterschiede pro Monat (ein Punkt ist ein Jahr); aufgrund der vielen Datenpunkte ist das Diagramm wenig übersichtlich (Overplotting).\n\n\nMöchte man die Referenzgruppe eines Faktors ändern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geänderte Reihenfolge aus:\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n11.3.5 Binäre plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binären) UV plus einer metrischen UV.16\n\nBeispiel 11.12 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\n👨‍🏫 Ich muss mal kurz auf eine Sache hinweisen…\n\n\n\n\n\n\n\nFaktorvariable\n\n\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich für nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten Ausprägungen (“Faktorstufen”) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht.\nDas kann praktisch sein, denn dann ist immer klar, welche Ausprägungen in Ihrer Variable möglich sind.\\(\\square\\)\n\n\n\nBeispiel 11.10 (Beispiel für eine Faktorvariable)  \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\n\nBeispiel 11.11 (Filtern verändert die Faktorstufen nicht) Wenn Sie von der Faktorvariablen17 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.B. nur die ersten beiden Elemente übrig bleiben mit allein der Ausprägung \"f\", merkt sich R trotzdem, dass es zwei Faktorstufen gibt (\"f\" und \"m\").\nGenaus so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. Möchten Sie die herausgefilterten Faktorstufen “löschen”, so können Sie einfach die Faktorvariable neu berechnen (mit factor).\\(\\square\\)\n\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  mutate(month_factor = factor(month))  # Faktor (und damit die Faktorstufen) neu berechnen\n\nOkay. Wie spezifiziert man jetzt das lineare Modell?\\(\\square\\)\n\nHat man mehrere Prädiktoren, so trennt man sich mit einem Plus-Zeichen in der Regressionsformel:\ntemp ~ year_c + month.\nDie Veränderung der monatlichen Temperatur (10-Jahres-Mittel) ist in Abbildung 11.10 dargestellt (aber mit allen 12 Monaten, sieht schöner aus).\n\n\nAbbildung 11.10: Veränderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte)\n\n\n\n\n\n\n\nModellgleichung\n\n\n\nDas Pluszeichen hat in der Modellgleichung18 keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur “und noch folgende UV…”.\\(\\square\\)\n\n\nDie obige Modellgleichung liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, data = wetter_month_1_7)\n\nDie Modellparameter sind in Tabelle 11.8 zu sehen.\n\n\n\n\nTabelle 11.8: Modellparameter von lm_year_month\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4525)\np\n\n\n\n(Intercept)\n56.94\n0.68\n(55.60, 58.27)\n83.57\n&lt; .001\n\n\nyear c\n0.03\n0.01\n(5.59e-03, 0.05)\n2.43\n0.015\n\n\nmonth factor (7)\n24.37\n0.97\n(22.48, 26.27)\n25.25\n&lt; .001\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (b0, (Intercept)): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57 mm pro Quadratmeter.\nRegressionskoeffizient für Jahr (b1, year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.02 mm an (im Referenzmonat).\nRegressionskoeffizient für Monat (b2, month [7]) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25 mm über dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7.\nIm Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0.\n\n🧑‍🎓 Puh, kompliziert!\n\n\n👨‍🏫 Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. Beispiel 11.13.\n\n\nBeispiel 11.13 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag für Januar im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"1\"))\npredict(lm_year_month, newdata = neue_daten)\n##        1 \n## 58.92171\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nAlle Regressionskoeffizienten beziehen sich auf den Y-Wert unter der Annahme, dass alle übrigen Prädiktoren den Wert Null (bzw. Referenzwert) aufweisen.\\(\\square\\)\n\n\nVisualisieren wir uns die geschätzten Erwartungswert pro Prädiktorwert, s. Abbildung 11.11.\n\nplot(estimate_expectation((lm_year_month))) +\n  scale_color_okabeito() +\n  scale_fill_okabeito()\n\n\n\nAbbildung 11.11: Temperaturverlauf über die Jahre für zwei Monate. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von (okabeito?) ersetzt (s. Hinweise hier). Das ist nicht unbedingt nötig, aber robuster bei Schwarz-Weiß-Druck und bei Sehschwächen, vgl. Kapitel 6.9.3.\nDie erklärte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n11.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht würden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dürfen?\nNicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. Abbildung 11.12.\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\nplot(estimate_expectation(lm_year_month_interaktion)) +\n  scale_color_okabeito()\n\n\n\nAbbildung 11.12: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die Veränderung im Verlauf der Jahre ist unterschiedlich für die Monate (Janur vs. Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\nWie man in Abbildung 11.12 sieht, sind die beiden Regressionsgeraden nicht parallel.\n\n\n\n\n\n\nHinweis\n\n\n\nSind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor.\\(\\square\\)\n\n\n\nBeispiel 11.14 (Interaktionseffekt von Niederschlag und Monat) Wie ist die Veränderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich für die Monate: Im Juli nahm der Niederschlag ab, im Januar zu.\\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von “dem” (statistischen) Effekt eines Prädiktors (afu die Y-Variable) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.B. Monat) unterscheidet der Effekt.19\nBetrachten wir die Parameterwerte des Interaktionsmodells (parameters(lm_year_month_interaktion)), s. Tabelle 11.9.\n\n\n\n\nTabelle 11.9: Modellparameter von lm_year_month_interaktion\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(4524)\np\n\n\n\n(Intercept)\n56.91\n0.68\n(55.59, 58.24)\n84.21\n&lt; .001\n\n\nyear c\n0.13\n0.02\n(0.10, 0.16)\n7.80\n&lt; .001\n\n\nmonth factor (7)\n24.37\n0.96\n(22.50, 26.25)\n25.45\n&lt; .001\n\n\nyear c × month factor (7)\n-0.20\n0.02\n(-0.25, -0.16)\n-8.62\n&lt; .001\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die Zeile year c × month factor [7]. Sie gibt die Stärke des Interaktionseffekts an. Da die Null nicht im Schätzbereich (95 CI) liegt, ist der Interaktionseffekt offenbar nicht Null, also vorhanden (zumindest laut unserem Modell20. Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre ändert: Im Monat \"7\" ist der Effekt von year_c um 0.20 mm geringer: Die Regressionsgerade neigt sich mehr nach “unten” im Monat Juli, da der Koeffizient kleiner als Null ist.\nDie Regressionsgleichung lautet: precip_pred = 56.91 + 0.13*year_c + 24.37*month_factor_7 - 0.20*year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert für Y an unter der Annahme, dass alle Prädiktoren den Wert Null aufweisen. Die Regressionskoeffizienten geben die Zunahme in Y an, wenn der jeweilige Prädiktorwert um 1 steigt, die übrigen Prädiktoren aber den Wert 0 aufweisen.\\(\\square\\)\n\n\nDas R-Quadrat von lm_year_month_interaktion beträgt übrigens:\n\nr2(lm_year_month_interaktion)[[\"R2\"]]  # aus `{easystats}`\n##        R2 \n## 0.1385194"
  },
  {
    "objectID": "090-regression2.html#vorsicht-bei-der-interpretation-von-regressionskoeffizienten",
    "href": "090-regression2.html#vorsicht-bei-der-interpretation-von-regressionskoeffizienten",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.4 Vorsicht bei der Interpretation von Regressionskoeffizienten",
    "text": "11.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere nie Modellkoeffizienten ohne ein Kausalmodell.\\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lässt man besser die Finger von der Interpretation der Modellkoeffizienten und begnügt sich mit der Beschreibung der Modellgüte und mit Vorhersage21.\nWer das nicht glaubt, der betrachte Abbildung 11.13, links.22 Ei Forschi stellt das Modell m1: y ~ x auf und interpretiert dann b1: “Ist ja klar, X hat einen starken positiven Effekt auf Y!”.\nIn der nächsten Studie nimmt dis Forschi dann eine zweite Variable, group (z.B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. Abbildung 11.13, rechts!\nDieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt “echt”, also kausal, ist. Handelt es sich aber um “nicht echte”, also nicht-kausale Zusammenhänge, so können sich die Modellkoeffizienten dramatisch verändern (auch das Vorzeichen ändern23), wenn man das Modell verändert, also Variablen hinzufügt oder wegnimmt.\nWenn man die kausalen Abhängigkeiten nicht kennt, weiß man also nicht, ob die Zusammenhänge kausal oder nicht-kausal sind. Man weiß also nicht, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n(a) Modell: y ~ x, starker Zusammenhang; b1 ist stark positiv\n\n\n\n\n\n(b) Modell: y ~ x + g, in jeder der beiden Gruppen ist der Zusammenhang praktisch Null, b1 = 0\n\n\n\nAbbildung 11.13: Fügt man in ein Modell eine Variable hinzu, können sich die Koeffizienten massiv ändern. In beiden Diagrammen wurden die gleichen Daten verwendet.\n\n\nMan könnte höchstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.B. “Dort wo es viele Störche gibt, gibt es auch viele Babies”.24 Leider ist unser Gehirn auf kausale Zusammenhänge geprägt: Es fällt uns schwer, Zusammenhänge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulässig kausal interpretiert - von Laien und Wissenschaftlis auch."
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-variablen",
    "href": "090-regression2.html#modelle-mit-vielen-variablen",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.5 Modelle mit vielen Variablen",
    "text": "11.5 Modelle mit vielen Variablen\nGrundsätzlich kann man viele Prädiktoren in ein (lineares) Modell aufnehmen.\nBetrachten wir z.B. folgendes lineares Modell mit zwei UV.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\n\n\nWir könnten im Prinzip alle Variablen unserer Datentabelle als Prädiktoren in das Regressionsmodellaufnehmen. Die Frage ist nur: macht es Sinn?\nHier sind einige Richtlinien, die helfen, welche Prädiktoren (und wie viele) man in ein Modell aufnehmen sollte (Gelman, Hill, und Vehtari 2021, 199f):\n\nAlle Prädiktoren aufnehmen, von denen anzunehmen ist, dass Sie Ursachen für die Zielvariablen sind\nBei Prädiktoren mit starken Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen\nPrädiktoren mit kleinem Schätzbereich (95 CI) sollten eher im Modell belassen werden, da sie die Modellgüte verbessern"
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.6 Fallbeispiel zur Prognose",
    "text": "11.6 Fallbeispiel zur Prognose\n\nBeispiel 11.15 (Prognose des Verkaufspreis) Ganz können Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen möglichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld.\\(\\square\\)\n\n\n11.6.1 Modell “all-in”\nUm die Güte Ihrer Vorhersagen zu prüfen, teilt Ihr Chef den Datensatz in zwei zufällige Teile.\n\n🧔‍♂️ Ich teile den Datensatz mariokart zufällig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (“trainieren”) und ihre Güte zu prüfen. Den Teil nenne ich “Trainingssample”, hört sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die Güte deiner Vorhersagen.\n\nWenn die Daten auf Ihrer Festplatte liegen, z.B. im Unterordner daten, dann könne Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"daten/mariokart_train.csv\")\n\nAlternativ können Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Wiese Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die “All-in-Strategie”: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.979\n\nDer Punkt in total_pr ~ . heißt “alle Variablen in der Tabelle (außer total_pr)”.\n\n🧔‍♂️ Hey! Das ist ja fast perfekte Modellgüte!\n\n\n🦹‍♀️ Vorsicht: Wenn ein Angebot aussieht wie “too good to be true”, dann ist es meist auch too good to be true.\n\n\n\n\n\n\n\nOverfitting\n\n\n\nDer Grund für den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. Weiß man, welcher Titel zu welcher Auktion gehört, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nützen die Titel der Auktionen im Train-Sample nichts für andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stützen. Merke: Höchst idiografische Informationen wie Namen, Titel etc. sind nicht nützlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\\(\\square\\)\n\n\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in eval(predvars, data, env): object 'V1' not found\n\nOh nein! Was ist los!? Eine Fehlermeldung!\n\n\n\n\n\n\nVorsicht\n\n\n\nNominalskalierte Prädiktorvariablen mit vielen Ausprägungen, wie title sind problematisch. Kommt eine Ausprägung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. Häufig ist es sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting führen.\\(\\square\\)\n\n\n\n11.6.2 Modell “all-in”, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. Nächster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, V1, id))\n\nWir entfernen auch die Spalte V1 und id, da sie ebenfalls keine Informatione bergen.\n\nlm_allin_no_title &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist ja durchaus ordentlich. Schauen wir uns noch den rmse (die SD der Vorhersagefehler) an25:\n\n🤖 Gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title)\n## [1] 20.22998\n\n\n\n\n\n\n\nName Clash\n\n\n\nIm Paket yardstick gibt es eine Funktion namens rmse und im Paket performance, Teil des Meta-Pakets easystats ebenfalls. Da sind Probleme vorprogrammiert. Das ist so als würde die Lehrerin rufen: “Schorsch, komm her!”. Dabei gibt es zwei Schorsche in der Klasse: Den Müllers Schorsch und den Meiers Schorsch. Sonst kommen beide, was die Lehrerin nicht will. Die Lehrerin müsste also rufen: “Schorsch Müller (oder Meier), komm her!”. Genau dasselbe machen wir, wenn wir das R-Paket eines Befehls mitschreiben, sozusagen den “Nachnamen” des Befehls: paketname::funktion ist wie Müller::Schorsch. In unserem Fall also: performance::rmse Endlich weiß R wieder, was zu tun ist!\\(\\square\\)\n\n\nSie rennen zu Ihrem Chef, der jetzt die Güte Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\n🧔‍♂️ Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das “Test-Sample”.\n\nIhr Chef schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n\n  \n\n\n\n\n🧔‍♂️ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nHier sind Ihre Vorhersagen26:\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title, newdata = mariokart_test)\n\nHier sind Ihre ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##        1        2        3        4        5        6 \n## 28.62826 53.85885 53.28035 54.03619 41.75512 46.57713\n\nDies Vorhersagen fügen wir noch der Ordnung halber in die Tabelle mit den Test-Daten:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title, newdata = mariokart_test))\n\nOkay, was ist jetzt der mittlere Vorhersagefehler?\nUm die Vorhersagegüte im Test-Sample auszurechnen27, nutzen wir die Funktionen des R-Paketes yardstick28:\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n  \n\n\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n  \n\n\n\nIhr mittlerer Vorhersagefehler (MAE) liegt bei ca. 13 Euro.29\n\n🧔‍♂️ Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n  \n\n\n\n\n🧔‍♂️ Nicht berauschend, aber immerhin!\n\n\n\n\n\n\n\nModellgüte im Test-Sample meist geringer als im Train-Sample\n\n\n\nWie das Beispiel zeigt, ist die Modellgüte im Test-Sample (leider) oft geringer als im Train-Sample. Die Modellgüte im Train-Sample ist mitunter übermäßig optimistisch. Dieses Phänomen bezeichnet man als Overfitting.\\(\\square\\)\n\n\n\n\n\n\n\n\nTipp\n\n\n\nBevor man Vorhersagen eines Modells einreicht, bietet es sich, die Modellgüte in einem neuen Datensatz, als einem Test-Sample, zu überprüfen.\\(\\square\\)"
  },
  {
    "objectID": "090-regression2.html#vertiefung-train--und-test-sample",
    "href": "090-regression2.html#vertiefung-train--und-test-sample",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.7 Vertiefung: Train- und Test-Sample",
    "text": "11.7 Vertiefung: Train- und Test-Sample\nWenn Sie eine robuste Schätzung der Güte Ihres Modells erfahren möchten, bietet es sich an, die Vorhersagegenauigkeit Ihres Modells in einem neuen Datensatz, einem sog. Test-Sample, zu überprüfen.\nDie Aufteilung Ihres Datensatzes in ein Train- und ein Test-Sample können Sie z.B. so bewerkstelligen:\n\nlibrary(rsample)\nmariokart &lt;- read_csv(\"daten/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"daten\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split bestimmt für jede Zeile (Beobachtung) zufällig aus, ob diese Zeile in das Train- oder in das Test-Sample kommen soll. Im Standard werden 70% der Daten in das Train- und 30% in das Test-Sample eingeteilt; das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafür, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wäre nämlich blöd für Ihr Modell, wenn im Train-Sample z.B. nur die teuren, und im Test-Sample nur die günstigen Spiele landen würde. In so einem Fall würde sich Ihr Modell unnötig schwer tun.\nIm nächsten Schritt können Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsächlich aufteilen.30\n\nmariokart_train &lt;- training(meine_aufteilung)  # Train-Sample\nmariokart_test &lt;- testing(meine_aufteilung)  # Test-Sample\n\nIch persönliche nenne die Tabelle mit den Daten gerne d_train bzw. d_test, das ist kürzer zu tippen und einheitlich. Sie können aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, außerdem Kürze und aussagekräftige Namen."
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.8 Praxisbezug",
    "text": "11.8 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden “abwanderungsgefährdet” sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (“customer churn”). Es gibt eine ganze Reihe von Untersuchungen dazu, z.B. die von Lalwani u. a. (2022). Die Forschis versuchen anhand von Daten und u.a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von über 80% in Ihrem (besten) Vorhersagemodell."
  },
  {
    "objectID": "090-regression2.html#fazit",
    "href": "090-regression2.html#fazit",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.9 Fazit",
    "text": "11.9 Fazit\nIn diesem Kapitel haben Sie lineare Modelle gelernt, die über einfache Modelle der Art y ~ x hinausgehen. Dazu gehören multiple Modelle, das sind Modelle mit mehr als einer UV (Prädiktor) und auch Interaktionsmodelle. Außerdem haben Sie sich mit einem Datensatz von gesamtgesellschaftlichen Nutzen beschäftigt - sehr schön. Das Fallbeispiel zum Schluss war vielleicht erhellend insofern, als dass ein gutes Modell im Train-Sample nicht (notwendig) zu guten Vorhersagen im Test-Sample führt."
  },
  {
    "objectID": "090-regression2.html#dran-bleiben",
    "href": "090-regression2.html#dran-bleiben",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.10 Dran bleiben",
    "text": "11.10 Dran bleiben\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen.\n\n\n\n\n\n(a) So ging es Ihnen gestern\n\n\n\n\n\n(b) So wird es Ihnen morgen ergehen, wenn Sie dran bleiben\n\n\n\nAbbildung 11.14: Statistik, Sie und Party: Gestern und (vielleicht) morgen.\n\n\nQuelle: imgflip"
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.11 Fallstudien",
    "text": "11.11 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei Fallstudien:\n\nVorhersage von Flugverspätungen\nVorhersagen von Filmerlösen"
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.12 Aufgaben",
    "text": "11.12 Aufgaben\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1"
  },
  {
    "objectID": "090-regression2.html#literatur",
    "href": "090-regression2.html#literatur",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "\n11.13 Literatur",
    "text": "11.13 Literatur\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and other stories. Analytical methods for social research. Cambridge: Cambridge University Press.\n\n\nKosinski, Michal, David Stillwell, und Thore Graepel. 2013. „Private traits and attributes are predictable from digital records of human behavior“. Proceedings of the National Academy of Sciences 110 (15): 5802–5. https://doi.org/10.1073/pnas.1218772110.\n\n\nLalwani, Praveen, Manas Kumar Mishra, Jasroop Singh Chadha, und Pratyush Sethi. 2022. „Customer Churn Prediction System: A Machine Learning Approach“. Computing 104 (2): 271–94. https://doi.org/10.1007/s00607-021-00908-y."
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n11  Geradenmodelle 2\n",
    "section": "",
    "text": "synonym: Regressionsanalysen↩︎\nTemperatur: Grad Celcius, Niederschlag (precip) mm Niederschlag pro Quadratmeter↩︎\nyear und year_c sind gleich stark mit temp korreliert, daher wird sich die Modellgüte nicht unterscheiden.↩︎\nQuelle: Umweltbundesamt↩︎\nQuelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3)↩︎\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/↩︎\nr2(lm_wetter_bin_uv)↩︎\nUV↩︎\nsynonym: transformiert↩︎\nTransformation↩︎\nfür uns synonym: Regressionsmodell↩︎\ndrei oder mehr Stufen bzw. Ausprägungen↩︎\nSo ein Modell ist von den Ergebnissen her praktisch identisch zu einer einfachen Varianzanalyse.↩︎\nwie könnte man dieses Wort eigentlich definieren?↩︎\nplot(estimate_expectation(lm_wetter_month)↩︎\nSo ein Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ancova) bezeichnet werden.↩︎\nsynonym: nominalskalierte Variable↩︎\nsynonym: Regressionsformel↩︎\nEffekt ist hier immer statistisch, nie kausal gemeint.↩︎\nunser Modell könnte ja auch falsch sein.↩︎\nsynonym: Prognose↩︎\nQuelle↩︎\ndas nennt man dann Simpsons Paradox↩︎\nDas Störche-Babies-Beispiel passt auch zu Abbildung 11.13.↩︎\nder Befehl wohnt im Paket performance, Teil des Metapakets easystats↩︎\nengl. predictions; to predict: vorhersagen↩︎\nwir verwenden dazu die Funktionen mae und rsq↩︎\nwelches Sie vielleicht noch installieren müssen.↩︎\nWir haben hier yardstick::mae geschrieben und nicht nur mae, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens mae gibt. Name-Clash-Alarm! R könnte daher den anderen mae meinen als Sie, was garantiert zu Verwirrung führt. Entweder bei R oder bei Ihnen.↩︎\ninitial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgeführt.↩︎"
  }
]