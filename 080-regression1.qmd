# Geradenmodelle 1 {#sec-gerade1}



## Lernsteuerung




### Standort im Lernpfad

Abb. @fig-ueberblick zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen √úberblick √ºber das Thema dieses Kapitels im Kontext aller Kapitel.







### Lernziele


- Sie k√∂nnen ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.
- Sie k√∂nnen die Bestandteile eines Geradenmodells aufz√§hlen und erl√§utern.
- Sie k√∂nnen die G√ºte eines Geradenmodells anhand von Kennzahlen bestimmen.
- Sie k√∂nnen Geradenmodelle sowie ihre Modellg√ºte in R berechnen.


### Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(easystats)
```


### Ben√∂tigte Daten

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```



## Vorhersagen


Vorhersagen sind eine n√ºtzlich Sache, unter (mindestens) folgenden Voraussetzungen:

1. Sie sind pr√§zise
2. Wir kennen die Pr√§zision
3. Jemand interessiert sich f√ºr die Vorhersage


Die Methode des Vorhersagens, die wir hier betrachten, nennt man auch *lineare Regression*.


### Vorhersagen ohne Pr√§diktor

:::{#exm-noten-prognose}
Nach intensiver Besch√§ftigung mit Statistik sind Sie allgemein als Checker bekannt.
Viele j√ºngere Studentis fragen Sie um Rat.
eines Tages kommt ei Studenti, Toni, und fragt: "Welche Statistiknote kann ich in der Klausur erwarten?"
Sie entgegnen: "Wie viel hast du denn gelernt?".
Die Antwort: "Sag ich nicht."

Nach kurzem √úberlegen geben sie den Notenschnitt der letzten Klausur als Prognose f√ºr dis Studenti. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert aus).

Zuerst importieren Sie die Daten der letzten Klausur^[Diese Syntax wird bei Ihnen nur funktionieren, wenn auf *Ihrem Computer* dieser Ordner mit dieser Datei existiert. Andernfalls m√ºssen Sie die Daten erst herunterladen: https://raw.githubusercontent.com/sebastiansauer/statistik1/main/daten/noten.csv.]:

```{r}
#| echo: false
# set.seed(42)
# noten2 <-
#   tibble(
#     id = 1:100,
#     x = rnorm(100, mean = 73, sd = 10),
#     y = x + rnorm(100, 0, 10)
#   )
# write.csv(noten2, "daten/noten2.csv")
```


```{r}
noten2 <- read.csv("daten/noten2.csv")
```

Dann rechnen Sie den Mittelwert aus:

```{r}
noten2 %>% 
  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur
```

Ihre Antwort lautet also: "Im Schnitt haben die Studis bei der letzten Klausur gut 50% der Punkte erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.B. wieviel du gelernt hast, kann ich dir keine genauere Vorherage machen, sorry!"$\square$
:::

:::{.callout-note}
Ohne Kenntnis eines Pr√§diktors (UV) (wie z.B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert f√ºr jede Beobachtung, s. @fig-noten3.
Wir nutzen den Mittelwert als Punktmodell f√ºr den Klausurerfolg.$\square$
:::

```{r}
#| echo: false
#| fig-cap: "Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell"
#| label: fig-noten3
ggplot(noten2) +
  aes(id, y) +
  geom_point() +
  geom_hline(yintercept = mean(noten2$y), color = "blue") +
  annotate("label", x = -Inf, y = mean(noten2$y), 
           label = paste0("MW: ", round(mean(noten2$y))), hjust = "left") +
  theme_minimal()
```

:::{def-nullmodell}
### Nullmodell
Modelle ohne Pr√§diktor, Punktmodelle also, kann man so bezeichnen: `y ~ 1`. 
Da es null Pr√§diktoren hat, nennt man es auch manchmal "Nullmodell".
:::

Auf Errisch kann man dieses Nullmodell so spezifizieren:

```{r}
lm0 <- lm(y ~ 1, data = noten2)
lm0
```

`lm` steht f√ºr "lineares Modell", die `0` sagt, dass es keine Pr√§diktoren gibt.
In dem Fall wird der Mittelwert als Gerade verwendet.
Der zur√ºckgemeldete Koeffizient `(Intercept)` ist hier der Modell des Punktmodells.
Da es ein Punktmodell ist, sagt es f√ºr alle Beobachtungen (hier Studentis) den gleichen Wert vorher.

Die Regressionsgleichung lautet demnach: `y_pred = 71.08`.
In Worten: "Wir sagen von jede Beobachtung einen Wert von ca. 71 vorher".


### Vorhersagen mit Pr√§diktor




:::{#exm-noten3}
### Toni verr√§t die Lernzeit

Dis Studenti, Toni, entschlie√üt sich dann doch noch, die Lernzeit zu verraten:
"Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt."
Jetzt m√ºssen Sie erstmal nachdenken: "Wie viele Klausurpunkte sag ich vorher, wenn Toni 42 gelernt hat?"

Sie visualisieren sich zur Hilfe die vorliegenden Daten, s. @fig-noten4, links.


```{r}
#| eval: false
noten2 <- read.csv(noten2, "daten/noten2.csv")

library(DataExplorer)
noten2 %>% 
  plot_scatterplot(by = "y")  # Y-Variable muss angegeben werden
```


```{r}
#| echo: false
lm1 <- lm(y ~ x, data = noten2)
lm1_b0 <- coef(lm1)[1]
lm1_b2 <- coef(lm1)[2]

toni_punkte <- predict(lm1, newdata = data.frame(x=42))
```


Auf dieser Basis antworten Sie Toni: "Bei 42 Stunden Lernzeit solltest du so `r round(toni_punkte, 0)` Punkte bekommen. K√∂nnte mit dem Bestehen eng werden."
Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen.$\square$
:::


Der Trend (im Sinne eines linearen Zusammenhangs) von Lernzeiten und Klausurpunkte ist deutlich zu erkennen.
Mit einem Lineal k√∂nnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. @fig-noten4.


```{r}
#| label: fig-noten4
#| echo: false
#| fig-cap: "Noten und Lernzeit: Rohdaten und Modell"
#| layout-ncol: 2
#| fig-subcap: 
#|   - "Gemeinsame Verteilung (Zusammenhang) von Lernzeit (X) und Noten (Y)"
#|   - "Eine 'Trendgerade' (blau) im Datensatz noten2. Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem roten Punkt gekennzeichnet."

#noten2 <- read.csv(noten2, "daten/noten2.csv")



ggplot(noten2) +
  aes(x, y) +
  geom_point() +
  labs(x = "Lernzeit",
       y = "Klausurpunkte") +
  theme_minimal()

noten2 %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_vline(xintercept = mean(noten2$x), linetype = "dashed", color = "grey") +  
  geom_hline(yintercept = mean(noten2$y), linetype = "dashed", color = "grey") +   
  geom_abline(slope = coef(lm1)[2], intercept = coef(lm1)[1], color = "blue", size = 1.5) +
  theme_minimal() +
  annotate("label", x = mean(noten2$x), y = -Inf, 
           label = paste0("MW: ", round(mean(noten2$x))), vjust = "bottom") +
  annotate("label", y = mean(noten2$y), x = -Inf, 
           label = paste0("MW: ", round(mean(noten2$y))), hjust = "left")   +
  annotate("point", x = 42, y = toni_punkte, color = "red",
           alpha = .7, size = 4) +
  scale_x_continuous(breaks = c(40, 42, 60, 80, 100)) +
  labs(x = "Lernzeit",
       y = "Klausurpunkte")
```

Eine Gerade eignet sich, um einen linearen Trend zusammenzufassen.



## Geradenmodelle


### Achsenabschnitt und Steigung definieren eine Gerade

Wir verwenden eine Gerade als Modell f√ºr die Daten, s. @fig-noten4, rechts.
Anders gesagt: Wir modellieren die X-Y-Daten (bzw. ihren Zusammenhang) mit einem Geradenmodell.

Ein Geradenmodell ist eine Verallgemeinerung des Punktmodells:
Ein Punktmodell sagt f√ºr alle Beobachtungen den gleichen Wert vorher.
@fig-noten3 und @fig-noten4 stellen ein Punktmodell einem Geradenmodell gegen√ºber.

In einem Geradenmodell wird nicht mehr (notwendig) f√ºr jede Beobachtung die gleiche Vorhersage $\hat{y}$ gemacht (wie das bei einem Punktmodell der Fall ist).


:::{#def-gerade}
Eine Gerade ist definiert durch zwei *Koeffizienten*: Achsenabschnitt (engl. intercept), und Steigung (engl. slope).
H√§ufig wird (z.B. im Schulunterricht) der Achsenabschnitt mit $t$ und die Steigung mit $m$ bezeichnet: $f(x)=y=\color{blue}[m]x + \color{red}[t]$.
In der Statistik wird folgende Nomenklatur bevorzugt: $f(x)=\hat{y} = \color{red}{b_0} + \color{blue}{b_1}x$ oder $y = \color{red}{\beta_0} + \color{blue}{\beta_1}x$ .^[Die Nomenklatur mit $b_0, b_1$ hat den Vorteil, dass man das Modell einfach erweitern kann: $b_2, b_3, ...$. Anstelle von $b$ liest man auch oft $\beta$. Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage √ºber eine Population, nicht nur √ºber eine Stichprobe, machen m√∂chte.]


@fig-regrtex skizziert die Elemente einer Regression.
:::


![Achsenabschnitt und Steigung einer Regressionsgeraden](img/regr.png){#fig-regrtex width="70%"}


[Basierend auf diesem Diagramm von Henri Menke](https://texample.net/tikz/examples/linear-regression/)




:::{#exm-noten5}
### Toni will es genau wissen
Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert.
"Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zur√ºck!"

Das sind gute Fragen. Den Y-Wert (Klausurpunkte) bei $X=0$ gibt der Achsenabschnitt zur√ºck. Schnell skizzieren Sie dazu ein Diagramm, s. @fig-beta0.
Puh, die Antwort wird Toni nicht gefallen ...
:::

```{r}
#| echo: false
#| label: fig-beta0
#| fig-cap: "Der Achsenabschnitt: Wie viele Punkt kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)"


noten2 %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_vline(xintercept = mean(noten2$x), linetype = "dashed", color = "grey") +  
  geom_hline(yintercept = mean(noten2$y), linetype = "dashed", color = "grey") +   
  geom_abline(slope = coef(lm1)[2], intercept = coef(lm1)[1], color = "blue", size = 1.5) +
  theme_minimal() +
  scale_x_continuous(limits = c(0, 100)) +
  scale_y_continuous(limits = c(0, 100)) +
  annotate("point", x = 0, y = lm1_b0, color = "red", size = 7, alpha = .7)
```



Anstelle auf @fig-beta0 zu schauen, k√∂nnen Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:


>    üßë‚Äçüéì Hey R, predicte mir mal auf Basis vom Modell "lm1" den Lernerfolg f√ºr Toni, wenn der x=0 Stunden lernt.

>    ü§ñ Okay, ich predicte mit Modell "lm1" und nehme als neue Datentabelle Tonis Lernzeit (x=0)!

```{r}
tonis_lernzeit <- tibble(x = 0)
tonis_lernzeit
```


```{r}
predict(lm1, newdata = tonis_lernzeit)
```


### Spezifikation eines Geradenmodells


Ein Geradenmodell kann man im einfachsten Fall so spezifizieren, s. @eq-mod1:

$$\hat{y} \sim x$$ {#eq-mod1}


Lies: "Laut meinem Modell ist $\hat{y}$ irgendeine Funktion von $y$".
Wir werden als Funktion (erstmal) nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns (erstmal) vom Computer ausrechnen.


@eq-mod1 k√∂nnen Sie so ins Errische √ºbersetzen:


```{r}
#| eval: false
lm(y ~ x, data = meine_daten)
```

`lm` steht f√ºr "lineares Modell", also eine Gerade als Modell.
Die Gerade nennt man auch *Regressionsgerade*^[an anderer Stelle in diesem Buch unscharf als "Trendgerade" bezeichnet.].

:::{#exm-noten5}
### Zahlen f√ºr Toni
Toni ist nicht zufrieden mit Ihren Vorhersagen: "Jetzt h√∂r mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sag mir pr√§zise Zahlen!".
:::


```{r}
lm1 <- lm(y ~ x, data = noten2)
lm1
```

R gibt Ihnen die beiden Koeffizienten f√ºr die Gerade aus. 
Den Namen des Objekts k√∂nnen Sie frei aussuchen, z.B. `mein_erstes_lm`.

Die Regressionsgleichung lautet demnach:
`y_pred = 8.6 + 0.88*x`

Mit Kenntnis der beiden Koeffizienten kann man beliebige Y-Werte ausrechnen gegeben bestimmte X-Werte.

Hat jemand zum Beispiel 10 Stunden gelernt, w√ºrden wir folgendes Klausurergebnis vorhersagen:

```{r}
lernzeit <- 10
y_pred <- 8.6 + 0.88*lernzeit
y_pred
```


:::{#exm-noten6}
### Vorhersage f√ºr Klausurerfolg, n√§chster Versuch
Sie versuchen, noch etwas Gutes f√ºr Toni zu tun.
R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt.
Sie d√ºrfen es aber auch selber rechnen, wenn Ihnen das lieber ist.
:::


```{r}
tonis_lernzeit2 <- tibble(x = 73)
```


```{r}
predict(lm1, newdata = tonis_lernzeit2)
```
:::


Die Syntax von `predict` lautet:

```
predict(name_des_objekts, newdata = tabelle_mit_pr√§diktorwerten)
```

:::{.callout-note}
Mit `predict` bekommt man eine Vorhersage; im Standard eine "Punkt-Vorhersage", eine einzelne Zahl.$\square$
:::


### Vorhersagefehler

Die Differenz zwischen vorhergesagten Wert f√ºr eine (neue) Beobachtung, $\hat{y_0}$ und ihrem tats√§chlichen Wert nennt man Vorhersagefehler (error, $e_i$) oder *Residuum*: $e_i = y_i - \hat{y}_i$.



```{r}
#| echo: false
#| fig-cap: "Vorhersagefehler als Abweichungsbalken"
#| label: fig-resid
#| layout-ncol: 2
#| fig-subcap: 
#|   - Residuen beim Geradenmodell (lm1)
#|   - Residuen beim Punktmodell (lm0)

noten2 <-
  noten2 %>% 
  mutate(yhat = predict(lm1, newdata = noten2))

noten2 %>% 
  ggplot(aes(x, y)) +
  geom_point(color = "grey") +
  geom_abline(slope = coef(lm1)[2], intercept = coef(lm1)[1], color = "blue", size = 1.5) +
  theme_minimal() +
  geom_segment(aes(xend = x, yend = yhat))

noten2 %>% 
  ggplot(aes(x, y)) +
  geom_point(color = "grey") +
  geom_hline(yintercept = mean(noten2$y), color = "blue", size = 1.5) +
  theme_minimal() +
  geom_segment(aes(xend = x, yend = mean(noten2$y)))

```


Wie ist es mit den Vorhersagefehlern von beiden Modellen bestellt?

Lassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben^[aus dem Paket `easystats`]:

```{r}
mae(lm0)
mae(lm1)
```


Vergleichen wir MAE im  Nullmodell mit MAE in `lm1`: 

```{r}
verhaeltnis_fehler_gerade_zu_punkt_mae <- mae(lm1) / mae(lm0)
verhaeltnis_fehler_gerade_zu_punkt_mae
```



Ah! Das Geradenmodell ist viel besser:
Von `lm0` zu `lm1` haben die mittlere (Absolut-)L√§nge des Fehlerbalkens auf `r round(verhaeltnis_fehler_gerade_zu_punkt_mae, 2)*100` Prozent verbessert.
Nicht schlecht!


:::{#def-fehlerstreung}
### Fehlerstreuung
Als Fehlerstreuung bezeichnen wir die Gesamtheit der Abweichungen der beobachteten Werte ($y_i$) vom vorhergesagten Wert ($\hat{y}_i$).$\square$
:::

Zur Berechnung der Fehlerstreuung gibt es mehrere Kenngr√∂√üen wie MAE oder MSE.


:::{.callout-note}
Ein Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreung), solange X mit Y korreliert ist.$\square$
:::


Nat√ºrlich k√∂nnen wir - in Analogie zur Varianz - auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen^[Wer mag, kann den MSE auch von Hand berechnen: `mean((noten2$y-mean(noten2$y))^2)`].

```{r}
mse(lm0)
mse(lm1)
```


```{r}
verhaeltnis_fehler_gerade_zu_punkt_mse <- mse(lm1)/mse(lm0)
verhaeltnis_fehler_gerade_zu_punkt_mse
```


### Berechnung der Modellkoeffizienten

Aber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen?

Die Regressionskoeffizienten^[hier synonym: Modellparameter] b0 und b1 w√§hlt man so, dass die Residuen minimal sind.
Es gibt verschiedene Algorithmen, um dies zu berechnen^[aber nicht in diesem Buch zu finden].
Eine sch√∂ne Darstellung dazu findet sich bei @kaplan_statistical_2009.

"Von Hand" k√∂nnen Sie die Optimierung von b0 und b1 in [dieser App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/KleinsteQuadrate/) ausprobieren.




## R-Quadrat

### R-Quadrat als Verringerung der Fehlerstreuung

Anders gesagt, wir haben uns um $1 - `r round(verhaeltnis_fehler_gerade_zu_punkt_mse, 2)`$ verbessert:

```{r}
1 - verhaeltnis_fehler_gerade_zu_punkt_mse
```




:::{#def-r2}
### R-Quadrat
Die Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen  von `lm0` zum gerade untersuchten Modell nennt man  *R-Quadrat* ($R^2$).
R-Quadrat ($R^2$) eines Modells $m$ ist definiert als die Verringerung der Streuung, wenn man das Modell $m$ mit dem Nullmodell $m_0$ vergleicht: $R^2 =1-  \frac{\text{MSE}_{m}}{\text{MSE}_{m0}}$. R-Quadrat ist ein Ma√ü der *Modellg√ºte*: Je gr√∂√üer $R^2$, desto besser die Vorhersage. 
Da es ein Anteilsma√ü^[Prozentzahl] ist, liegt der Wertebereich zwischen 0 uns 1.
Im Nullmodell liegt R-Quadrat per Definition bei 0.
Im Fall von Modellen des Typs $y\sim x$ gilt: $R^2 = r_{xy}^2$.
$\square$
:::




Wir k√∂nnen R-Quadrat ($R^2$) uns von R z.B. so ausgeben lassen:

```{r}
r2(lm1)
```

Bei einer perfekten Korrelation ist $r=1$, daher ist dann auch $R^2 = 1$^[Bei Modellen mit einem Pr√§diktor; gibt es mehrere Pr√§diktoren gilt die Beziehung nur wenn die Pr√§diktoren alle paarweise unabh√§ngig sind.], 
s. @fig-r2-extreme.


```{r}
#| echo: false
#| fig-cap: "Extremf√§lle von R-Quadrat: 0 und 1"
#| fig-subcap:
#|   - "Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert"
#|   - "Perfekte Korrelation, r = 1 und R2 = 1. Prognose gleich beobachtetem Wert"
#| label: fig-r2-extreme
#| layout-ncol: 2
d0 <-
  tibble(x = rnorm(100),
         y = rnorm(100))

d0 %>% 
  ggplot(aes(x,y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)


d_r1 =
  tibble(x = 1:10,
         y = seq(10, 100, by = 10))

d_r1 %>% 
  ggplot(aes(x,y)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```

Bei einer perfekten Korrelation $R^2=1$ liegen die Punkte auf der Geraden.
Im gegenteiligen Extremfall von $R^2=0$ ist die Vorhersage genauso gut, wie wenn man f√ºr jedes $y$ den Mittelwert, $\bar{y}$, vorhersagen w√ºrde. 


:::{.callout-note}
Je gr√∂√üer R-Quadrat, desto besser erkl√§rt das Modell die Daten (desto besser der "Fit", sagt man).
:::

[Diese App der FOM-Hochschule](https://fomshinyapps.shinyapps.io/Variationszerlegung/) erlaubt es Ihnen mit der Gr√∂√üe der Residuen eines linearen Modells zu spielen.




<!-- ### Addition der Varianzen -->


<!-- Nennen wir die Varianz des Verkaufspreis $s^2_y$, die Verbesserung der Fehlerstreuung durch das *M*odell $s^2_m$ und die restliche Fehlerstreuung, den MSE, $s^2_e$. -->
<!-- Dann gilt: -->

<!-- $$s^2_y = s^2_m + s^2_e \\ -->
<!-- s^2_m = s^2_y - s^2_e$$ -->

<!-- ```{r} -->
<!-- s2_y = var(noten2$y) -->
<!-- s2_e = mse(lm1) -->
<!-- s2_m = s2_y - s2_e -->
<!-- s2_m -->
<!-- ``` -->

<!-- Die Varianzanteile addieren sich. Mit anderen Kennzahlen der Streuung (SD, MAE) funktioniert das nicht. -->


## Interpretation eines Regressionsmodells


### Modellg√ºte

Die Residuen (Vorhersagefehler) bestimmen die Modellg√ºte:
Sind die Residuen im Schnitt gro√ü, so ist die Modellg√ºte gering (schlecht), und umgekerht.
Verschiedenen Koeffizienten stehen zur Verf√ºgung: R-Quadrat, r^[als Korrelation von tats√§chlichem $y$ und vorhergesaten $\hat{y}], MSE, RMSE, MAE, ...


### Koeffizienten

Die Modellkoeffizienten, also Achsenabschnitt ($b_0$) und Steigung ($b_1$) sind nur eingeschr√§nkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abh√§ngigkeiten nicht kennt.
Nur aufgrund eines Zusammenhangs darf man keine kausalen Abh√§ngigkeiten annehmen.
Ohne eine guten Grund f√ºr eine Kausalbehauptung kann man kann nur *deskriptiv* argumentieren.
Oder sich mit der Modellg√ºte und den Vorhersagen begn√ºgen. Was auch was wert ist.

#### Achsenabschnitt (b0)

"Im Modell `lm1` liegt der Achsenabschnitt bei $y=`r round(coef(lm1)[1], 2)`$. Beobachtungen mit $x=0$ k√∂nnen also diesen Y-Wert erwarten."
Leider ist es h√§ufig so, dass Pr√§diktorwerte von 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig n√ºtzt.

:::{#exm-groesse}
### Regression Gr√∂√üe und Gewicht
Nutzt man K√∂rpergr√∂√üe umd das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von K√∂rpergr√∂√üe wenig n√ºtzlich, da es keine Menschen gibt der Gr√∂√üe 0.$\square$
:::


#### Geradensteigung (b1)

```{r}
#| echo: false
lm1_b1 <- coef(lm1)[2] %>% round(2)
```


"Im Modell `lm1` betr√§gt der Regressionskoeffizient `b1` $`r lm1_b1`$. Zwei Studenti, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich *laut Modell* um den Wert von b1."

:::{.callout-caution}
H√§ufig liest man, der "Effekt des Pr√§diktors" auf die AV betrage z.B. $`r lm1_b1`$. "Effekt" ist aber ein Wort, dass man kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort "Effekt" mit Vorsicht genie√üen. Manche sprechen daher auch von einem "statistischen Effekt".$\square$.
:::


## Fallbeispiel Mariokart

Als mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt.
Sie m√∂chten eine genaue Vorhersage von Verkaufspreisen erzielen.
Als Sie von diesem Plan berichteten, leuchteten die Augen Ihres Chefs.
Genaue Vorhersagen, das ist etwas von hoher betriebswirtschaftlicher Relevanz.
Auf geht's!

Daten laden:^[Und die √ºblichen Pakete starten, nicht vergessen.]

```{r}
mariokart <- read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv")
```


```{r}
lm2 <- lm(total_pr ~ start_pr, data = mariokart)
r2(lm2)
```


Oh nein! Unterirdisch schlecht. Anstelle von blo√üen Rumprobieren √ºberlegen Sie und schauen dann in @fig-mario-corr nach, welche Variable am st√§rksten korreliert mit `total_pr`,
es resultiert `lm3`: 

```{r}
#| results: hide
lm3 <- lm(total_pr ~ ship_pr, data = mariokart)
parameters(lm3)
```

```{r}
#| echo: false
#| label: tbl-lm3
#| tbl-cap: "Modellparameter von lm3"
parameters(lm3) %>% print_md()
```


Der Achsenabschnitt liegt bei ca. 36 Euro, wie man in @tbl-lm3 sieht: Ein Spiel, das mit Null Euro Preis startet, kann laut `lm3` etwa 36 Euro finaler Verkaufspreis erwarten.
*Pro Euro an Versandkosten* (`ship_pr`) steigt der zu erwartende finale Verkaufspreis um ca. 4 Euro.^[Die Spalte `95 CI` gibt einen Sch√§tzbereich f√ºr den jeweiligen Modellkoeffizienten an,
denn es handelt sich bei den Koeffizienten um Sch√§tzwerte;
der wahre Wert in der Population ist unbekannt. 
Wir kennen schlie√ülich nur eine Stichprobe der Gr√∂√üe $n=143$.].

Die Regressionsgleichung von `lm3` lautet demnach:

`total_pr_pred = 36.25 + 4.34*ship_pr`.

In Worten: 

>    Der vorhergesagte Gesamptreis eines Spiels liegt bei 36.25‚Ç¨ "Sockelbetrag" plus 4.34 mal die Versandkosten.


Man kann sich die erwarteten Werte ("expectations") des Verkaufspreises in Abh√§ngigkeit vom Wert der UV (`ship_pr`) auch sch√§tzen ("to estimate") lassen, und zwar so^[Die Funktion stammt aus easystats]: 

```{r}
estimate_expectation(lm3) %>% head()  # nur die ersten paar vorhergesagten Werte
```


Ah, bei 4 Euro Versandkosten ist laut dem Modell knapp 54 Euro Verkaufspreis zu erwarten, fassen Sie sich die Ausgabe zusammen.


>   ü§ñ Das sieht man in der Spalte `Predicted`, dort steht der vorhersagte Wert f√ºr `total_pr` f√ºr einen bestimmten Wert von `ship_pr`.


>    üßë‚Äçüéì Kann ich auch `predict` benutzen? Ich w√ºrde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Euro liegen.

>   ü§ñ Ja, klar!


```{r}
neue_daten <- tibble(
  ship_pr = c(1, 4)  # zwei Werte zum Vorhersagen
)
```


```{r}
predict(lm3, newdata = neue_daten)
```




Aber n√ºtzlich w√§re noch, das Modell (bzw. die Sch√§tzung der erwarteten Werte) als Diagramm zu bekommen.
Das erreicht man z.B. so, s. @fig-lm3.

```{r}
#| label: fig-lm3
#| fig-cap: Verbildlichung der erwarteteten Werte laut lm3
estimate_expectation(lm3) %>% plot()
```

`estimate_expectation` hei√üt sinngem√§√ü "sch√§tze den zu erwartenden Wert".
Kurz gesagt: Wir wollen eine Vorhersage von R.

Am wichtigsten ist Ihnen aber im Moment die Frage, wie "gut" das Modell ist, spricht wie lang oder kurz die Vorhersagefehler-Balken sind:

```{r}
mae(lm3)
```


```{r}
#| echo: false
lm3_r2 <- round(r2(lm3)$R2, 2)
```

Das Modell erkl√§rt einen Anteil von ca. `r lm3_r2` der Gesamtstreuung.


```{r}
mae(lm3)
```



Im n√§chsten Meeting erz√§hlen Sie Ihrem Chef "Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!".
H√∂rt sich gut an.
Allerdings h√§tte ihr Chef es gerne genauer. Kann man da noch was machen?




## Fallstudie Immobilienpreise



{{< include casestudy-ames.qmd >}}




<!-- ## Fazit -->
<!-- TODO  -->

## Aufgaben

Eine Aufgabe, die eine Einf√ºhrung zum [Kaggle-Wettbewerb Ames House Prices]((https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview) bietet, finden Sie [hier im Datenwerk](https://datenwerk.netlify.app/posts/ames-kaggle1/ames-kaggle1.html).

Suchen Sie beim [Datenwerk](https://datenwerk.netlify.app/) nach diesen Aufgaben

    - Aussagen-einfache-Regr
    - interpret-koeff-lm
    - korr-als-regr
    - Linearitaet1a
    - lm1
    - mtcars-regr01
    - nichtlineare-regr1
    - penguins-regr02
    - regression1
    - regression1b
    - Regression3
    - Regression4
    - Regression5
    - Regression6
    
    

Schauen Sie sich die Aufgaben beim [Datenwerk](https://datenwerk.netlify.app/) an, vor allem die Tags [regression](https://datenwerk.netlify.app/#category=regression) und [lm](https://datenwerk.netlify.app/#category=lm).

*Nicht alle Aufgaben* aus dieser Sammlung passen zum Stoff; vielleicht k√∂nnen Sie einige Aufgaben nicht l√∂sen.
Ignorieren Sie einfach diese Aufgaben.

Beachten Sie die [Hinweise zu den Aufgaben](https://datenwerk.netlify.app/hinweise).




## Literatur



