[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik1",
    "section": "",
    "text": "Vorwort\nWillkommen bei Statistik1!\nDieses Buch führt in die Grundlagen der Statistik ein mit einem Schwerpunkt auf Vorhersagen (Prognosen). Es ist ein angewandtes Buch für Anfänger. Anders gesagt: Sie lernen, Daten aufzubereiten und mit Hilfe einfacher Modelle Vorhersagen abzuleiten. Dieses Buch soll Freude an der Statistik bereiten und hat nur ein Thema: Vorhersagen mittels moderner statistischen Methoden. Alle Inhalte dieses Buch erklären einen Aspekt der statistischen Prognose-Modellierung. Viele Statistikbücher gibt es schon auf dieser Welt, braucht es da noch eines? Ja, es gibt viele Statistikbücher, aber (meines Wissens) in deutscher Sprache keines, das Freude beim Lernen vermittelt, sich auf statistische Prognose-Modellierung konzentriert und moderne Werkzeuge einsetzt. Diese Lücke soll dieses Buch schließen. Freude am Lernen, beim Angstgegner Statistik, wie soll das gehen? Viele Verständnisschwierigkeiten rühren daher, dass Lehrbücher kompliziert geschrieben sind. Solcher Didaktik liegt offenbar die Überlegung zugrunde, dass die Konzepte präzise und nuanciert erläutert sein müssten. Meiner Ansicht nach wird da das Ziel mit dem Weg verwechselt: Am Anfang darf eine Erklärung ruhig etwas grober sein. Überblicken die Leserinnen und Leser die Materie einigermaßen, können sie sich im nächsten Schritt mit den Details vertraut machen, was Präzision und Tiefe verlangt. Darüber hinaus verwendet dieses Buch eine lockere Sprache für einen entspannten Lesefluss. Für einigen Komfort beim Lesen wurde gesorgt: Lernziele, Definitionen, Beispiele, Übungen, Hinweise, Fehlerquellen, Tipps, Literatur, Querverweise, QR-Codes zu externen Medien und andere Hilfsmittel mehr werden im Buch verwendet; an Erklärbildern wurde nicht gespart.\n\n“Statistische Modelle” ist ein sperriger Begriff, aber er sagt nur, dass es darum geht, fachliche Fragen in statistisch greifbare Bausteine zu gießen. Ein Beispiel: Studentin Anna fragt sich, ob sie die Prüfung besteht, wenn Sie 42 Stunden büffelt? Student Bert meint, dass motivierte Studis am meisten vom Lernen profitieren. Studentin Carla ist hingegen überzeugt, dass Lernen nix bringt, sondern dass die Intelligenz allein für den Prüfungserfolg verantwortlich sei. Damit haben wir drei (noch eher unpräzise) Modelle. Die Statistik hat die Aufgabe, ein (wissenschaftliches) Modell in ein statistisches zu übersetzen, um möglichst präzise Antworten (für eine Forschungsfrage) zu liefern; dafür sind Zahlen hilfreich. Wenn Anna, Bert und Carla ihre Überlegungen fachlich schärfen, auf wissenschaftlichen Theorien aufbauen und dann in statistische Sprache übersetzen, können sie mit Antworten von der Statistik rechnen, manchmal sogar mit präzisen. Was nicht heißt, dass diese Antworten immer richtig oder nützlich sind. Tja, das Leben ist nicht leicht.\nMit Blick auf den Spagat zwischen Theorie und Anwendung irrt das Buch (bzw. sein Autor) zugunsten der Seite der Anwendung. Ich wollte lieber befähigen, praktische Probleme zu lösen, als tiefen theoretischen Einblick zu vermitteln. Meine Hoffnung ist, dass die Freude am Können beflügelt, sich im nächsten Schritt tiefer mit der Materie zu beschäftigen. Ist es nicht auch so im Alltag? Was Freude macht, wo sich Erfolge einstellen, dort vertiefen wir uns gerne weiter.\nDa sich das Buch auf ein Thema, Modellierung in der Statistik, konzentriert, bleiben andere Themen außen vor, vor allem Inferenzstatistik. Vielleicht freut sich die eine oder der andere, von diesem Thema verschont zu sein. Ich denke, dass Modellierung für die Forschung und für die Praxis ein zentraler Gedanke ist; für zwei große Themen erscheint mir dieses Buch zu eng.\nWenn Sie Fragen oder Feedback haben, bin ich für Ihre Hinweise dankbar. Stellen Sie sie gerne hier ein: https://github.com/sebastiansauer/statistik1/issues. Die Online-Version dieses Buches ist frei verfügbar und unter der CC-BY-NC-SA-4.0-Lizenz publiziert.\n\n\n\nCC BY NC SA 4.0\n\n\nEine gedruckte Version können Sie als Softcover oder Hardcover bei Amazon kaufen (ISBN Softcover: 979-8343798951; Hardcover: 979-8311581899).\nDieses Buch ist meinen Kindern Laurenz und Martha gewidmet. Und allen anderen Menschen, die noch viel lernen wollen. Die Fragen meiner Studierenden sind der Grund für vieles, was ich gelernt habe; dafür bin ich dankbar.\nIch wünsche Ihnen viel Freude und Erfolg beim Lernen!\nIhr\nSebastian Sauer",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "005-orga.html",
    "href": "005-orga.html",
    "title": "\n1  Organisatorisches\n",
    "section": "",
    "text": "1.1 Es geht um Ihren Lernerfolg\nMeister Yoda rät: Lesen Sie die folgenden Hinweise, s. Abbildung 1.1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#es-geht-um-ihren-lernerfolg",
    "href": "005-orga.html#es-geht-um-ihren-lernerfolg",
    "title": "\n1  Organisatorisches\n",
    "section": "",
    "text": "Abbildung 1.1: Lesen die Inhalte du musst (imgflip, 2024).\n\n\n\n1.1.1 Lernziele\n\nDie Studierenden sind mit wesentlichen Methoden der explorativen Datenanalyse vertraut und können diese selbständig anwenden.\nDie Studierenden können gängige Forschungsfragen in lineare Modelle übersetzen, diese auf echte Datensätze anwenden und die Ergebnisse interpretieren.\n\n1.1.2 Was lerne ich hier und wozu ist das gut?\nWas lerne ich hier?\nSie lernen das Handwerk der Datenanalyse mit einem Schwerpunkt auf Vorhersage (Prognose). Anders gesagt: Sie lernen, Daten aufzubereiten und aus Daten Vorhersagen abzuleiten. Zum Beispiel: Kommt ein Student zu Ihnen und sagt “Ich habe 42 Stunden für die Klausur gelernt, welche Note kann ich in der Klausur erwarten?”. Darauf Ihre Antwort: “Auf Basis meiner Daten und meines Modells müsstest du eine 2,7 schreiben!” Außerdem lernen Sie, wie man die Güte einer Vorhersage auf Stichhaltigkeit prüft. Denn Vorhersagen kann man ja in jeder Eckkneipe oder beim Wahrsager bekommen. Wir wollen aber belastbare Vorhersagen und wollen zumindest wissen, wie (un)sicher eine Vorhersage ist.\nWarum ist das wichtig?\nWir wollen nicht auf Leuten vertrauen, die behaupten, sie wüssten, was für uns gut ist. Wir wollen selber die Fakten beurteilen können.\nWozu brauche ich das im Job?\nDatenanalyse spielt bereits heute in vielen Berufen eine Rolle. Tendenz stark zunehmend.\nWozu brauche ich das im Studium?\nIn Forschungsarbeiten (wie in empirischen Forschungsprojekten, etwa in der Abschlussarbeit) ist es üblich, statistische Ergebnisse quantitativ zu analysieren.\nIst Statistik nicht sehr abstrakt?\nDer Schwerpunkt dieses Kurses liegt auf Anwenden und Tun; ähnlich dem Erlernen eines Handwerks. Theorien und Abstraktionen stehen in diesem Buch nur am Rand.\nGibt es auch gute Jobs, wenn man sich mit Daten auskennt?\nDas World Economic Forum (2020) berichtet zu den “Top 20 job roles in increasing and decreasing demand across industries” (S. 30, Abb. 22): “1. Data Analysts und Scientists, 2. AI and Machine Learning Specialists, 3. Big Data Specialists”.\n\n1.1.3 Was ist hier das Erfolgsgeheimnis?\nDas Lesen einer Schwimmfibel nutzt wenig, wenn Sie Freischwimmer werden wollen. Es hilft nichts: Rein in die Fluten! Wenn das Wasser nicht tief ist und man jederzeit im Trockenen Pause machen kann, steht Ihrem Fortschritt beim Lernen nichts im Weg. Ich gebe zu, der Vergleich ist nicht gerade subtil. Aber es ist so: Sie lernen durch Tun (Lovett & Greenhouse, 2000). Dieses Buch bietet dafür reichhaltige Gelegenheit. Nutzen Sie sie. Jedes Kapitel führt am Ende eine Reihe von Aufgaben auf, alle mit Lösungen. So können Sie Ihren Lernfortschritt testen. Dass Schwierigkeiten auftreten, wenn man etwas Neues lernt, ist normal. Das geht fast allen so. Ihren Lernerfolg kann nur eine Sache gefährden: Wenn Sie aufgeben. Bleiben Sie dran, und der Erfolg wird sich einstellen! Abbildung 1.2 zeigt Daten von \\(n=1646\\) Studierenden, die zeigen, dass regelmäßiges Üben und Dranbleiben mit Erfolg einhergeht (Sauer, 2017). Dran bleiben ist der Schlüssel zum Erfolg. Üben Sie regelmäßig. Geben Sie bei Schwierigkeiten nicht auf. \n\n\n\n\n\nAbbildung 1.2: Der Zusammenhang von Lernzeit (1: gering bis 5: hoch) von Klausurerfolg\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDran bleiben ist der Schlüssel zum Erfolg. Üben Sie regelmäßig. Geben Sie bei Schwierigkeiten nicht auf. 🏋️‍♂️🔁🔑✨ \\(\\square\\)\n\n\n\n\n\nHaben Sie Motivation nötig? Dann schauen Sie sich das Video mit einer Ansprache zur Motivation an.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.4 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie Folgendes mitbringen:\n\nBereitschaft, Neues zu lernen\nBereitschaft, bei Schwierigkeiten nicht gleich aufzugeben\nKenntnis grundlegender Methoden wissenschaftlichen Arbeitens\n\nWas Sie nicht brauchen, sind besondere Mathe- oder Statistik-Vorkenntnisse.\n\n1.1.5 Überblick über das Buch\nAbb. Abbildung 1.3 gibt einen Überblick über den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen, zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Grundlagen des Modellieren]\n      direction TB\n      M1[Punktmodelle] --&gt; Vis[Verbildlichen]\n      Vis --&gt; U[Ungewissheit]\n\n    end\n    subgraph N[Geradenmodelle]\n      direction TB\n      G1[Geradenmodelle 1] --&gt; G2[Geradenmodelle 2]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\nAbbildung 1.3: Überblick über den Inhalt und Verlauf des Buches\n\n\n\n\n\nDas Diagramm zeigt auch den Ablauf einer typischen Datenanalyse. Natürlich kann man sich auch andere sinnvolle Darstellungen dieses Ablaufs vorstellen.\n\n\n\n1.1.6 PDF-Version\nSie können die Druck-Funktion Ihres Broswers nutzen, um ein PDF-Dokument eines Kapitels dieses Buchs zu erstellen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#lernhilfen",
    "href": "005-orga.html#lernhilfen",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.2 Lernhilfen",
    "text": "1.2 Lernhilfen\nAuf der Webseite “Datenwerk” wird eine große Zahl an Aufgaben bereitgestellt.1\n\n\n\nAm Ende jedes Kapitels dieses Buchs finden Sie eine Auswahl an Aufgabennamen, die Sie im Datenwerk finden. Beachten Sie die Hinweise zu den Aufgaben.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAußerdem tauchen im Verlauf jedes Kapitels Übungsaufgaben an verschiedenen Stellen auf, so dass Sie den jeweiligen Stoff sofort üben und Ihr Verständnis prüfen können.   Das Buch verweist auf eine Reihe von Online-Materialien. So ist der gesamte R-Code für dieses Buch auf dem Github-Repo dieses Buches zu finden: https://github.com/sebastiansauer/statistik1.\n\n\n\nSchauen Sie sich mal den YouTube-Kanal sebastiansauerstatistics an und dann z.B. die Playlist “R”. Dort finden Sie Videos zum Thema dieses Buches.\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Gleichungen werden zum Teil Farben verwendet, diese haben folgende Bedeutung:\n\nY bzw. Abhängige Variable\nX bzw. Unabhängige Variable\ne bzw. Fehlerterm\nb0 bzw. Achsenabschnitt\nb1 bzw. Steigung (Regressionsgewicht)\nm bzw. y-Dach bzw. Modellwert\n\nIn Diagrammen werden auch Farben verwendet, die haben allerdings keine feste Bedeutung, sondern dienen der Übersichtlichkeit.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#software",
    "href": "005-orga.html#software",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.3 Software",
    "text": "1.3 Software\n\n1.3.1 R\nSie benötigen R, RStudio und einige R-Pakete für diesen Kurs. Dieses Buch enthält “mittel” viel R. Auf fortgeschrittene R-Techniken wurde aber komplett verzichtet. Dem einen Anfänger oder der anderen Anfängerin mag es dennoch als “viel Code” erscheinen. Es wäre ja auch möglich gewesen, auf R zu verzichten und stattdessen eine “Klick-Software” zu verwenden. JASP oder Jamovi sind Beispiele für tolle Software aus dieser Kategorie. Ich glaube aber, der Verzicht auf eine Skriptsprache (R) wäre ein schlechter Dienst an den Studentis. Mit Blick auf eine “High-Tech-Zukunft” sollte man zumindest mit etwas Computer-Code vertraut sein. Auf Computercode zu verzichten, erschiene mir daher fahrlässig für die “Zukunftsfestigkeit” der Ausbildung. Sie finden den R-Code für jedes Kapitel im Github-Repositorium dieses Buches.2\n\n\nDas sind Sie nach der Lektüre dieses Buchs (Horst, 2024)\n\n\n1.3.2 R-Pakete\nIn den meisten Kapiteln dieses Buches benötigen Sie die folgenden zwei R-Pakete: tidyverse und easystats.\n\nlibrary(tidyverse)\nlibrary(easystats)\n\nWeitere Hinweise zu R finden Sie in Kapitel 3.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#benötigte-daten",
    "href": "005-orga.html#benötigte-daten",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.4 Benötigte Daten",
    "text": "1.4 Benötigte Daten\nIn den meisten Kapiteln dieses Buches analysieren wir Daten; meist ist das der Datensatz mariokart, wo Auktionen zu diesem Computerspiel in einigen Merkmalen aufgeführt sind. Sie können den Datensatz auf folgende Art importieren, s. Listing 1.1. Keine Sorge, wenn Ihnen im Moment nicht klar ist, was Sie mit dem R-Code anfangen sollen. Sie lernen das Nötige in Kapitel 3.\n\n\n\nListing 1.1: Mariokart-Datensatz importieren\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\n\nmariokart &lt;- read.csv(mariokart_path)\n\n\n\n\nEin Data-Dictionary (Codebook) finden Sie in Anhang B.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#hinweise",
    "href": "005-orga.html#hinweise",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.5 Hinweise",
    "text": "1.5 Hinweise\n\nYouTube-Playlists zu Statistik\nLernhilfen\nDidaktik\nUnterrichtsorganisation\nDer Unterricht zu diesem Modul wird id.R. nur ein Mal pro Jahr angeboten (also nur jedes zweite Semester).\nEine Prüfung in diesem Modul ist in jedem Semester möglich.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#prüfung",
    "href": "005-orga.html#prüfung",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.6 Prüfung",
    "text": "1.6 Prüfung\nDie folgenden Hinweise sind dem Hinweisbuch des Autors entnommen. Lesen Sie auch die übrigen Hinweise dort.3\n\n1.6.1 Prüfungleistung\nDie Prüfungsleistung besteht aus einer Hauptleistung (keine Bonusleistung).\nDie Hauptleistung besteht aus einer Projektarbeit im Form eines Prognosewettbewerbs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.6.2 Zum Prognosewettbewerb\nIm Hinweisbuch finden Sie Hinweise zur Prüfung.4\n\n1.6.3 Prüfungsrelevanter Stoff\nBeachten Sie die Hinweise zum prüfungsrelevanten Stoff.5\n\n1.6.4 Wie kann ich mich auf die Prüfung vorbereiten?\nHier finden Sie Hinweise zur Prüfungsvorbereitung.6\n\n1.6.5 Allgemeine Prüfungshinweise\nDie folgenden Hinweise gelten grundsätzlich, d.\\(\\,\\)h. soweit nicht anders in der jeweiligen Prüfung bzw. der jeweiligen Aufgabe angegeben. Nichtbeachten von Prüfungshinweisen kann zu Punkteabzug oder Nichtbestehen führen. Lesen Sie sich diese Hinweise im eigenen Interesse sorgfältig durch. Die Kenntnis dieser Hinweise wird bei der Begutachtung vorausgesetzt.\nFür eine einfachere Kommunikation kontaktieren Sie mich per E-Mail bei Fragen, die nur Sie betreffen. Bei Fragen von allgemeinem Interesse (z.\\(\\,\\)B. “Bis wann müssen wir die Arbeit abgeben?”) nutzen Sie bitte (sofern verfügbar) das Kursforum, damit die Kommilitonen auch von dem Austausch profitieren.\nBeachten Sie die allgemeinen Prüfungshinweise.7\n\n1.6.6 Lieblingsfehler\nVermeiden Sie diese häufigen Fehler im Prognosewettbewerb.8\n\n1.6.7 Fazit\n🍀🍀🍀VIEL ERFOLG!🍀🍀🍀",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#sec-greek",
    "href": "005-orga.html#sec-greek",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.7 Griechische Buchstaben",
    "text": "1.7 Griechische Buchstaben\nIn diesem Buch werden ein paar (wenige) griechische Buchstaben verwendet, die in der Statistik üblich sind. Häufig werden griechische Buchstaben verwendet, um eine Grundgesamtheit (Population) zu beschreiben (die meistens unbekannt ist). Lateinische (“normale”) Buchstaben werden demgegenüber verwendet, um eine Stichprobe (Datensatz, vorliegende Daten) zu beschreiben. Tabelle 1.1 stellt diese Buchstaben zusammen mit ihrer Aussprache und Bedeutung vor.\n\n\nTabelle 1.1: Griechische Buchstaben, die in diesem Buch verwendet werden\n\n\n\nZeichen\nAussprache\nBuchstabe\nBedeutung in der Statistik\n\n\n\n\\(\\beta\\)\nbeta\nb\nRegressionskoeffizent\n\n\n\\(\\mu\\)\nmü\nm\nMittelwert\n\n\n\\(\\sigma\\)\nsigma\ns\nStreuung\n\n\n\\(\\Sigma\\)\nSigma\nS\nSummenzeichen\n\n\n\\(\\rho\\)\nrho\nr\nKorrelation (nach Pearson)\n\n\n\n\n\n\nMehr griechische Buchstaben finden sich z.\\(\\,\\)B. in Wikipedia.9",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#zitation",
    "href": "005-orga.html#zitation",
    "title": "\n1  Organisatorisches\n",
    "section": "\n1.8 Zitation",
    "text": "1.8 Zitation\nBitte zitieren Sie dieses Buch wie folgt:\n\nSauer, S. (2024). Statistik1. https://statistik1.netlify.app/\n\nHier sind die maschinenlesbaren Zitationsinfos (Bibtex-Format), die Sie in Ihre Literatursoftware importieren können:\n@book{sauer_statistik1,\n    title = {Statistik1},\n    rights = {CC-BY-NC},\n    url = {https://statistik1.netlify.app/},\n    author = {Sauer, Sebastian},\n    date = {2024},\n}\nHier ist die DOI:\n\n\nDOI\n\n\n\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024). Yoda Jealous Girl Friend Meme [Artwork]. https://imgflip.com\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive Theory to Statistics Instruction. The American Statistician, 54(3), 196–206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nSauer, S. (2017). Dataset ’Predictors of Performance in Stats Test’ [Data set]. Open Science Framework. https://doi.org/10.17605/OSF.IO/SJHUY\n\n\nWorld Economic Forum. (2020). The Future of Jobs Report 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "005-orga.html#footnotes",
    "href": "005-orga.html#footnotes",
    "title": "\n1  Organisatorisches\n",
    "section": "",
    "text": "https://sebastiansauer.github.io/Datenwerk/↩︎\nhttps://github.com/sebastiansauer/statistik1/tree/main/R-code-for-all-chapters↩︎\nhttps://hinweisbuch.netlify.app/↩︎\nhttps://hinweisbuch.netlify.app/080-hinweise-pruefung-prognosewettbewerb-frame↩︎\nhttps://hinweisbuch.netlify.app/010-hinweise-pruefung-allgemein-frame#pr%C3%BCfungsrelevanter-stoff↩︎\nhttps://hinweisbuch.netlify.app/150-hinweise-pruefungsvorbereitung-frame↩︎\nhttps://hinweisbuch.netlify.app/010-hinweise-pruefung-allgemein-frame↩︎\nhttps://hinweisbuch.netlify.app/170-beispiele-fehler-prognosewettbewerb-frame↩︎\nhttps://de.wikipedia.org/wiki/Griechisches_Alphabet↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organisatorisches</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html",
    "href": "010-rahmen.html",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "2.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nAbbildung 1.3 zeigt den Standort dieses Kapitels im Lernpfad und gibt damit einen Überblick über das Thema dieses Kapitels im Kontext aller Kapitel. Abbildung 2.1 zeigt, dass unser Vorgehen in diesem Buch einem Fließband gleicht: Schritt für Schritt, in der richtigen Reihenfolge, vom Anfang bis Ende, erarbeiten wir unser “Datenprodukt”.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#einstieg",
    "href": "010-rahmen.html#einstieg",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "Abbildung 2.1: Datenanalyse als eine Abfolge am Fließband (Horst, 2024)\n\n\n\n2.1.1 Lernziele\n\nSie können eine Definition von Statistik wiedergeben.\nSie können eine Definition von Daten wiedergeben.\nSie können den Begriff Tidy-Daten erläutern.\nSie können Beispiele für verschiedene Skalenniveaus nennen.\n\n2.1.2 Einstieg\n\nÜbungsaufgabe 2.1 (Hallo, Statistik) Gehen Sie in Kleingruppen zusammen (3-4 Personen). Stellen Sie sich anhand der Schlagworte einander vor:\n\n(wissenschaftliche) Interessen\nErwartung an diesen Kurs\nVorkenntnisse in Statistik (und in R)\n\nWenn Sie wollen: Fügen Sie einen Fun Fact hinzu. \\(\\square\\)\n\n\nÜbungsaufgabe 2.2 (Frag jetzt) Die Lehrkraft stellt Ihnen ein Forum zur Verfügung, auf dem Sie anonym Fragen an die Lehrkraft richten können (z.\\(\\,\\)B. auf frag.jetzt).\nStellen Sie dort Ihre Fragen ein; voten Sie die Fragen Ihrer Kommilitonis auf oder ab. Die Lehrkraft beantwortet dann die Fragen mit den meisten Upvotes. \\(\\square\\)\n\n\n2.1.3 Erfolgsgrezept\nDrei Faktoren beeinflussen Ihren Lernerfolg: 1) Ihre Lehrkraft, 2) Ihre Mitarbeit im Unterricht und 3) Ihr Eigenstudium zuhause (Vor- bzw. Nachbereitung des Unterrichts), s. Abbildung 2.2.\n\n\n\n\n\nflowchart TD\n  subgraph Lehrkraft\n    F[\"🔥\"]\n  end\n  subgraph A[Mitarbeit]\n    C[\"🪵\"]\n  end\n  subgraph E[Eigenstudium]\n    D[\"🌳\"] \n  end  \n\n\n\n\nAbbildung 2.2: Ihr Lernerfolg besteht aus drei Komponenten: Der Lehrkraft, Ihrer Mitarbeit im Unterricht und Ihrem Eigenstudium, also Ihrer Vor- bzw. Nachbereitung zuhause.\n\n\n\n\nEine gute Lehrkraft ist wie der Funke, der eine (Lern-)Flamme entzündet. Aber es braucht Brennmaterial, einen Holzscheit, das ist Ihre Konzentration im Unterricht. Ein Holzscheit allein reicht nicht aus; es braucht mehr Brennmaterial, um das Feuer am Leben zu erhalten: Ihr Eigenstudium, das stetige, selbständige Beschäftigen mit der Materie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "href": "010-rahmen.html#was-ist-statistik-und-wozu-ist-sie-gut",
    "title": "\n2  Rahmen\n",
    "section": "\n2.2 Was ist Statistik und wozu ist sie gut?",
    "text": "2.2 Was ist Statistik und wozu ist sie gut?\nDie Aufgabe von Statistik ist es, Modelle zu bilden durch Zusammenfassen von Daten. Modelle machen es uns einfacher, schwierige Sachverhalte zu verstehen. Zentral ist dabei die Analyse von Variabilität der Daten. Daten kommen in verschiedenen Varianten vor, typischerweise in Tabellenform, möglichst im sog. Tidy-Format.\nIn diesem Buch werden die Begriffe Statistik, Datenanalyse und Data Science synonym verwendet.\n\nÜbungsaufgabe 2.3 (Nutzen von Statistik) Fragen Sie einen Chatbot (wie ChatGPT), was der Nutzen von Statistik ist. Diskutieren Sie die Antwort. \\(\\square\\)\n\nDas versteht ChatGPT unter Statistik:\n\n🧑‍🎓 Was ist Statistik? Bitte definiere verständlich.\n\n\n🤖 Statistik ist eine Wissenschaft, die sich mit der Sammlung, Analyse, Interpretation, Präsentation und Übertragung von Daten beschäftigt. Ziel ist es, Muster und Trends in den Daten zu erkennen und verlässliche Schlussfolgerungen über eine größere Gruppe (z.\\(\\,\\)B. Bevölkerung) auf der Basis einer Stichprobe (Teilmenge) zu treffen. Die Statistik hilft uns bei der Beantwortung von Fragen, indem sie uns dabei hilft, die Unsicherheit in den Daten zu messen und zu verstehen1.\n\nGar nicht schlecht! Es gibt mehrere Definition von Statistik. Definition 2.1 zeigt eine.\n\nDefinition 2.1 (Statistik) Statistik fasst Werte zusammen, quantifiziert deren Unterschiedlichkeit und beschreibt die Ungewissheit unserer Schlüsse (Kaplan, 2009; Poldrack, 2023) . \\(\\square\\)\n\nBetrachten wir die drei Bestimmungsstücke einer Definition von Statistik genauer: 1. Daten zusammenfassen, 2. Unterschiedlichkeit quantifizieren und 3. Ungewissheit beschreiben.\n\n2.2.1 Daten zusammenfassen\nAbbildung 2.3 verdeutlicht das Prinzip des Zusammenfassens von Daten. Einfach ausgedrückt: Eine Menge von Zahlen wird zu einer einzelnen Zahl “zusammengedampft”. Eine einzelne Zahl ist wesentlich besser zu verstehen als eine große Menge von Zahlen. Bei vielen Zahlen würde man den Überblick verlieren.\n\n\n\n\n\n\n\n\n\n\n(a) Zusammengefasst zu einem Punkt\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Zusammengefasst zu einer Geraden\n\n\n\n\n\n\nAbbildung 2.3: Daten zusammenfassen. (a) Zusammenfassen einer Variable zu einem Punktwert, hier zum Mittelwert. (b) Zusammenfassen zweier Variablen zu einer Geraden.\n\n\n\n\n2.2.2 Unterschiedlichkeit quantifizieren\nEine allgegenwärtige Tatsache ist, dass die Dinge der Welt sich unterscheiden, etwa, dass Tiere einer Gattung sich in ihrer Größe unterscheiden. So sind nicht alle Menschen gleich groß, nicht alle Bücher gleich lang oder nicht alle Tage gleich warm. Daher ist eine zentrale Idee von statistischen Analysen, die Unterschiedlichkeit der Dinge zu beschreiben, präziser gesagt: die Variation zu quantifizieren. Betrachten wir dazu das Beispiel in Abbildung 2.4. Im Team der Basketballer gibt es (vergleichsweise) geringe Variation in der Körpergröße – alle sind groß, ähnlich groß. Im Team der Schachspieler gibt es (vergleichsweise) hohe Variation: Einige Personen sind groß, andere klein.\n\n\n\n\n\n\n\nAbbildung 2.4: Wenig Variation in der Körpergröße bei den Basketballern. Alles lange Kerle. Viel Variation bei den Schachspielern: Manche sind klein, andere groß. Die vertikalen, vom Mittelwert (MW) abgehenenden Balken zeigen die Abweichungen der jeweiligen Körpergröße zum Mittelwert. Hinweis: Die Y-Achse startet nicht bei Null.\n\n\n\n\n\nEine Abweichung (auch Residuum) genannt, zeigt die Differenz von Mittelwert und dem Wert der Körpergröße bei der jeweiligen Person. Nehmen wir an, wir sprechen allgemein von einer Person \\(i\\). Wir bezeichnen das Merkmal Körpergröße mit \\(X\\) und den Mittelwert der Körpergröße mit als \\(\\bar{x}\\) (“x quer”). Dann können wir das Residuum der \\(i\\)-ten Person mit \\(r_i\\) bezeichnen und entsprechend definieren.\n\nDefinition 2.2 (Residuum) Das Residuum des Merkmals \\(X\\) der \\(i\\)-ten Beobachtung ist definiert als die Differenz vom Wert \\(x_i\\) und einem Referenzwert, etwa dem Mittelwert (\\(\\bar{x}\\)), d.\\(\\,\\)h.: \\(r_i = x_i - \\bar{x}.\\square\\)\n\n\n2.2.3 Ungewissheit beschreiben\n\nBeispiel 2.1 Anna hat eine Statistik-Klausur geschrieben. Sie hat keine Ahnung, ob sie bestehen wird. Berta hingegen ist sich sehr sicher, dass sie bestanden hat. Die beiden Studentinnen unterscheiden sich also stark in der Ungewissheit hinsichtlich ihrer Einschätzung zum Klausurerfolg, s. Abbildung 2.5. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Was Anna denkt\n\n\n\n\n\n\n\n\n\n(b) Was Berta denkt\n\n\n\n\n\n\nAbbildung 2.5: Die Ungewissheit, die wir Ereignissen zuschreiben, kann variieren. Anna ist sich maximal unsicher, ob sie besteht. Berta ist sich ziemlich sicher, dass sie besteht.\n\n\n\nBeispiel 2.2 Sagen wir, Sie haben sich mit einem zwielichten Statistiker auf ein Glücksspiel eingelassen: Er wirft eine Münze 10 Mal; bei Kopf gewinnt er, bei Zahl Sie. Nun hat der Statistiker von den 10 Würfen 8 Mal gewonnen. Sie sind sich ziemlich sicher, dass dieser Typ Sie über den Tisch gezogen hat. Allerdings sind Sie nicht ganz sicher, und beweisen können Sie es leider auch nicht. Der zwielichte Statistiker ist sich ganz sicher: Er weiß, dass er Sie über den Tisch gezogen hat. Er weiß, dass seine Münze gezinkt ist. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "href": "010-rahmen.html#was-ist-das-ziel-ihrer-analyse",
    "title": "\n2  Rahmen\n",
    "section": "\n2.3 Was ist das Ziel Ihrer Analyse?",
    "text": "2.3 Was ist das Ziel Ihrer Analyse?\n\n2.3.1 Arten von Zielen\nStatistische Analysen können drei Arten von Zielen verfolgen, s. Abbildung 2.6.\n\n\n\n\n\ngraph TD\n  subgraph Ziele\n    A[beschreiben]\n    B[vorhersagen]\n    C[erklären]\n  end\n\n\n\n\nAbbildung 2.6: Zielarten einer Datenanalyse\n\n\n\n\n\nBeispiel 2.3  \n\n\nBeschreiben: Wie groß ist der Gender-Paygap in der Branche X im Zeitraum Y?\n\nVorhersagen: Wenn ich 100 Stunden auf die Statistikklausur lerne, welche Note kann ich dann erwarten?\n\nErklären: Wie viel bringt mir das Lernen auf die Statistikklausur? \\(\\square\\)\n\n\n\n\nÜbungsaufgabe 2.4 Benennen Sie Beispiele für die die drei Zielarten von Datenanalysen! \\(\\square\\)\n\n\n2.3.2 Forschungsfrage\nEine Forschungsfrage ist die Leitfrage Ihrer Analyse. Sie definiert, was Sie herausfinden wollen. Häufig fragen Forschungsfragen: “Hat X einen (kausalen) Einfluss auf Y?”\nEine Forschungsfrage weist häufig folgende Struktur auf, s. Abbildung 2.7.\n\n\n\n\n\ngraph LR\n    I[Input bzw. X] --&gt; O[Output bzw. Y]\n\n\n\n\nAbbildung 2.7: Struktur eine Forschungsfrage\n\n\n\n\n\nBeispiel 2.4 (Forschungsfragen)  \n\nHat Lernen (X) einen Einfluss auf den Prüfungserfolg (Y)?\n\n\nVerringert Joggen (X) die Menge des Hüftgolds (Y)?\n\n\nUm welchen Betrag erhöht sich der Umsatz (Y), wenn wir 1000 Euro mehr für Werbung ausgeben? (X)\n\n\nVerringert intensive Handynutzung (X) die Konzentrationsfähigkeit (Y)? \\(\\square\\)\n\n\n\nBeispiel 2.5 (Forschungsfrage: Produktmerkmale und Verkaufserlös) Nach dem Studium haben Sie bei einem großen Online-Auktionshaus angeheuert. Da Sie angaben, sich im Studium intensiv, naja, ein bisschen, mit Statistik beschäftigt zu haben, hat man Sie in die Abteilung für Forschung und Entwicklung (F&E) gesteckt. Heute ist es Ihre Aufgabe, Auktionen zur Spielekonsole Wii zu analysieren, genauer gesagt geht es um das Spiel Mariokart. Ihre Forschungsfrage lautet:\n\nWelche Produktmerkmale stehen mit einem hohen Verkaufserlös in Zusammenhang? \\(\\square\\)\n\n\n\n2.3.3 Aus der Forschung: Smartphone-Brain-Drain 📱🧠🚫\nWard et al. (2017) untersuchten die Forschungsfrage, ob die bloße Gegenwart eines Handys (z.\\(\\,\\)B. wenn es vor Ihnen auf dem Tisch liegt) dazu führt, dass man abgelenkt wird und daher schlechtere kognitive Leistungen zeigt.\nDie Autoren formulieren ihre Hypothese leider nicht explizit, aber sie lässt sich implizit aus dem Text herauslesen (S. 142):\n\nFirst, smartphones may redirect the orientation of conscious attention away from the focal task and toward thoughts or behaviors associated with one’s phone. Prior research provides ample evidence that … this digital distraction adversely affects both performance … and enjoyment.\n\nSpäter präzisieren sie ihre Hypothese (S. 143):\n\nIn two experiments, we test the hypothesis that the mere presence of one’s own smartphone reduces available cognitive capacity.\n\nDie Ergebnisse unterstützen ihre Hypothese, s. Abbildung 2.8. Die kognitive Leistung (Y-Achse) ist sowohl in der Kapazität des Arbeitsgedächtnisses als auch in der fluiden Intelligenz geringer, wenn das Handy auf dem Schreibtisch liegt, als wenn es nicht im Raum ist, so die Studie. Am besten ist die kognitive Leistung, wenn das Handy nicht im Raum ist. \\(\\square\\)\n\n\n\n\n\nAbbildung 2.8: Handy in Sichtweite verringert die kognitiven Ressourcen, Ward et al. (2017), S. 145\n\n\n\n\n\n\nÜbungsaufgabe 2.5 Fragen Sie einen Bot (z.\\(\\,\\)B. ChatGPT) zum Stand der Forschung hinsichtlich der Braindrain-Forschungsfrage. Diskutieren Sie die Antwort, auch in ihren Grenzen. \\(\\square\\)\n\n\n2.3.4 Der Prozess der Datenanalyse\nDatenanalyse ist eine Art des Problemlösens. Anders gesagt, man macht es nicht zum Spaß (jedenfalls nicht alle von uns), sondern um ein Ziel zu erreichen, also ein Problem zu lösen. Daher analysiert man nicht gleich zu Anfang wild drauf los. Zunächst 1) klärt man das Problem und das Ziel. Dann 2) plant man das Vorgehen, z.\\(\\,\\)B. welche Daten man erheben möchte. Als nächstes 3) erhebt man die Daten und bereitet sie auf. Schließlich kann man sie 4) endlich analysieren. Aber Daten sprechen nicht für sich, man muss sie 5) interpretieren und Schlüsse daraus ziehen. Dazu gehört auch, dass man die Schwächen der eigenen Analyse kritisch beleuchtet, vgl. Abbildung 2.9. Diesen Ablauf nennt man auch das PPDAC-Modell (MacKay & Oldford, 2000):\n\nP: Problem (Problem und Ziel und Sachgegenstand verstehen)\nP: Plan (Vorgehen planen)\nD: Data (Daten erheben und aufbereiten)\nA: Analysis (Daten analysieren)\nC: Conclusions (Schlussfolgerungen ziehen)\n\n\n\n\n\n\ngraph LR\n    Problem --&gt; Plan --&gt; Data --&gt; Analysis --&gt; Conclusions --&gt; Problem\n\n\n\n\nAbbildung 2.9: Datenanalyse als Prozess: Das PPDAC-Modell\n\n\n\n\nAus einer weniger abstrakten, eher praktischen Perspektive kann man von der Abfolge der “sieben Schritten der Datenanalyse” sprechen, s. Abbildung 2.10.\n\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Vorbereiten]\n      direction TB\n      E[Einlesen] --&gt; Um[Umformen]\n    end\n    subgraph M[Grundlagen des Modellieren]\n      direction TB\n      M1[Punktmodelle] --&gt; Vis[Verbildlichen]\n      Vis --&gt; U[Ungewissheit]\n\n    end\n    subgraph N[Modellieren]\n      direction TB\n      G1[Modelle] --&gt; G2[Ungewissheit]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\n\n\nAbbildung 2.10: Datenanalyse als Prozess: Die sieben Schritte der Datenanalyse",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#was-sind-daten",
    "href": "010-rahmen.html#was-sind-daten",
    "title": "\n2  Rahmen\n",
    "section": "\n2.4 Was sind Daten?",
    "text": "2.4 Was sind Daten?\n\nDefinition 2.3 (Daten) Daten sind eine geordnete Folge von Zeichen. \\(\\square\\)\n\nTabellen sind oft das geeignete Format für die Untersuchung von Daten. Tabelle 2.1 zeigt ein Beispiel für Daten. Die erste Spalte id ist nur eine laufende Nummer. Sie dient dazu, die einzelnen Beobachtungen (hier Studierenden) identifizieren zu können und birgt ansonsten keine Information. Beispiele für ID-Variablen sind Matrikelnummer, Personalausweisnummern oder Bestellnummern.\n\n\n\nTabelle 2.1: So sehen Daten in Form einer Tabelle aus.\n\n\n\n\nid\nname\nnote\n\n\n\n1\nAnna\n1.3\n\n\n2\nBerta\n2.3\n\n\n3\nCarla\n3.0\n\n\n\n\n\n\n\n\n\nBeispiel 2.6 (Daten zur Forschungsfrage 2) Hier ist ein Auszug der Daten zur Tabelle mariokart, s. Tabelle 2.2.\n\n\n\nTabelle 2.2: Auszug aus der Tabelle mariokart\n\n\n\n\nn_bids\nstart_pr\ntotal_pr\nwheels\n\n\n\n20\n0.99\n52\n1\n\n\n13\n0.99\n37\n1\n\n\n16\n0.99\n46\n1\n\n\n18\n0.99\n44\n1\n\n\n20\n0.01\n71\n2\n\n\n19\n0.99\n45\n0\n\n\n\n\n\n\n\n\nEine Erklärung (Data-Dictionary) aller Variablen des Datensatzes mariokart findet sich Auf openintro.org2 oder im Anhang, s. @#sec-data-dict. \\(\\square\\)\n\n\nDefinition 2.4 (Data-Dictionary) Eine Erklärung, was die Variablen (Spalten) einer Datentabelle bedeuten, nennt man Codebook or Data-Dictionary. \\(\\square\\)\n\nIn den Spalten einer Tabelle stehen Merkmale (Variablen) von den Dingen, die untersucht werden, z.\\(\\,\\)B. Patienten, Kunden oder Videospiele. Die untersuchten Dinge nennt man Beobachtungseinheiten. Die Beobachtungseinheiten stehen in den Zeilen einer Tabelle. Eine Variable kann man sich als einen Behälter vorstellen, auf dem mit einem Stift geschrieben steht, welcher Inhalt darin ist, s. Abbildung 2.11.\n\nDefinition 2.5 (Variable) Eine Variable ist ein Platzhalter für ein Merkmal, das verschiedene Ausprägungen annehmen kann. \\(\\square\\)\n\n\n\n\n\n\nAbbildung 2.11: Wir definieren eine Variable “temp” mit dem Inhalt “9”.\n\n\n\nDefinition 2.6 (Beobachtungseinheit) Beobachtungseinheiten sind die Dinge, die wir untersuchen (beobachten). Beobachtungseinheiten sind die Träger von Variablen. \\(\\square\\)\n\nTabelle 2.1 enthält drei Variablen (id, Name und Note) und Note) und drei Beobachtungseinheiten (Anna, Berta und Carla). Beobachtungseinheiten werden auch kurz als Beobachtungen bezeichnet.\n\nDefinition 2.7 (Wert) Ein Wert ist der Inhalt einer Variablen. \\(\\square\\)\n\nIn Abbildung 2.11 ist der Wert von temp 9. In Tabelle 2.1 nimmt die Variable name die Werte Anna, Berta und Carla an.\n\nDefinition 2.8 (Ausprägung) Als Ausprägungen bezeichnet man die verschiedenen Werte einer Variablen. \\(\\square\\)\n\n\nBeispiel 2.7 In einer Studie wurden zehn Probanden untersucht. Die Variable geschlecht dokumentiert die Geschlechter der Personen:\n\ngeschlecht &lt;- c(\"Mann\", \"Frau\", \"Frau\", \"Frau\", \"Mann\",\n                \"Frau\", \"Mann\", \"Mann\", \"divers\", \"Frau\")\ngeschlecht\n##  [1] \"Mann\"   \"Frau\"   \"Frau\"   \"Frau\"   \"Mann\"   \"Frau\"   \"Mann\"   \"Mann\"  \n##  [9] \"divers\" \"Frau\"\n\nDie Variable enthält drei Ausprägungen: divers, Frau, Mann. \\(\\square\\)\n\n\n\n\n\n\n\nTipp\n\n\n\nGerade haben Sie etwas Computer-Syntax gesehen, genauer gesagt, Befehle aus der Programmiersprache R. Bisher haben wir diese Befehle nicht kennengelernt. Sie verstehen Sie vermutlich (nicht ganz). Ignorieren Sie diese Befehle einfach erst einmal.\n\n\n\n2.4.1 Tidy Data\n\nDefinition 2.9 (Tidy Data) Unter Tidy Data (tidy data, “Normalform”) versteht man eine Tabelle, in der jede Zeile eine Beobachtungseinheit darstellt, jede Spalte eine Variable und jede Zelle der Tabelle einen Wert. (Zusätzlich ist noch eine “Kopfzeile” erlaubt, in der die Namen der Variablen stehen.) \\(\\square\\)\n\n\n\n\n\n\nAbbildung 2.12: Tidy-Data-Sinnbild (Wickham, 2023)\n\n\nTabelle 2.1 ist ein Beispiel für Tidy-Data. Abbildung 2.12 zeigt ein Sinnbild für Tidy-Data (Wickham & Grolemund, 2018). Für eine statistische Analyse ist es oft sinnvoll, dass die Daten im Tidy-Format vorliegen. Der Vorteil des Tidy-Formats ist es, dass man weiß, wie die Daten aufgebaut sind. Außerdem können Statistikprogramme oft mit dieser Form am besten umgehen, s. Abbildung 2.13.\n\n\n\n\n\nAbbildung 2.13: Immer schön Ordnung halten … (Horst, 2023)\n\n\n\nBeispiel 2.8 Ihre Firma produziert zwei Produkte: Hämmer und Nägel. Im Folgenden sind zwei Tabellen dargestellt, die die gleichen Informationen darstellen: den Umsatz Ihrer Firma für zwei Jahre. Einmal ist dazu eine Nicht-Tidy-Tabelle (Tabelle 2.3; Breitformat) und einmal eine Tidy-Tabelle (Tabelle 2.4; Langformat) verwendet. \\(\\square\\)\n\n\n\n\nTabelle 2.3: Beispiel für eine NICHT-Tidy-Tabelle (Breitformat)\n\n\n\n\nProdukt\nUmsatz_2021\nUmsatz_2022\nUmsatz_2023\n\n\n\nHämmer\n10\n11\n12\n\n\nNägel\n15\n10\n5\n\n\n\n\n\n\n\n\n\n\n\nTabelle 2.4: Beispiel für eine Tidy-Tabelle (Langformat)\n\n\n\n\nProdukt\nUmsatz_2021\nUmsatz_2022\nUmsatz_2023\n\n\n\nHämmer\n10\n11\n12\n\n\nNägel\n15\n10\n5\n\n\n\n\n\n\n\n\n\nÜbungsaufgabe 2.6 Suchen Sie ein Beispiel für eine Konfiguration einer Tabelle im Lang- vs. Breitformat. \\(\\square\\)\n\n\n🧑‍🎓 Wozu braucht man Tidy Data?\n\n\n👩‍🏫 In vielen Software-Programmen der Datenanalyse weißt man z.\\(\\,\\)B. der X- oder Y-Variable eine Spalte einer Tabelle zu. Möchte man etwa die Veränderung des Umsatzes im Verlauf der Jahre visualisieren oder analysieren, so braucht es die Spalten ‘Jahr’ und ‘Umsatz’, also ein Tidy-Format, Tabelle 2.3 bzw. Tabelle 2.4.\n\nAbbildung 2.14 stellt auf Basis einer “Tidy-Tabelle” (Tabelle 2.4) ein Diagramm dar. Ohne Tidy-Daten wäre dieses Diagramm nicht (so einfach) zu erstellen gewesen.\n\n\n\n\n\n\n\nAbbildung 2.14: Beispiel für eine Visualisierung auf Basis einer Tidy-Tabelle, vgl. Tabelle 2.4\n\n\n\n\n\n2.4.2 Je mehr, desto besser (?)\nWas Daten betrifft, könnte man behaupten: “Viel hilft viel” oder “Je mehr, desto besser”. Natürlich unter sonst gleichen Umständen.3 Viel Datenmüll ist natürlich nicht besser als ein paar knappe, wasserdichte Fakten!\n\nBeispiel 2.9 Um Ihre eigene Lehraktivität zu organisieren, wollen Sie sich ein Bild machen, wie viel Ihre Nebensitzerinner und Nebensitzer im Hörsaal so lernen. Sie blicken nach links und fragen “wie viel lernst du so?”. Sie blicken nach recht und wiederholen die Frage gerichtet an den Kommilitonen, der rechts neben Ihnen sitzt. Dann addieren Sie die zwei Zahlen (unter der Annahme, dass Sie zwei Zahlen bekommen haben), und teilen durch zwei, um den Mittelwert zu erhalten. \\(\\square\\)\n\nEin kritischer Geist könnte anmerken, dass Sie besser die Untersuchung nicht gemacht hätten (auch wenn Sie, vielleicht ohne zu wollen, eine statistische Untersuchung angestellt haben). Denn bei so wenig befragten Personen ist die Ungenauigkeit Ihrer Schätzung der typischen Lernzeit bei Studierenden einfach zu hoch. Abbildung 2.15 veranschaulicht, dass man einen Mittelwert genauer schätzen kann, wenn man auf eine größere Stichprobe zurückgreift. Das Teilbild links zeigt den Mittelwert einer Stichprobe mit \\(n=20\\) Beobachtungen. Das Teilbild rechts zeigt den Mittelwert einer Stichprobe mit \\(n=200\\) Beobachtungen (jeweils aus der gleichen Grundgesamtheit). Wie man sieht, ist im linken Teilbild die Streuung (Variation) höher als im rechten Teilbild.\n\n\n\n\n\nAbbildung 2.15: Schätzgenauigkeit als Funktion der Stichprobengröße: Die vertikale Linie zeigt den wahren Mittelwert. Kleinere Stichproben-Mittelwerte schanken (variieren) mehr um den Mittelwert herum als größere Stichproben.\n\n\nBildquelle: Karsten Lübke\n\n\n\n\n\n\nWichtig\n\n\n\nMehr Daten = genauere Ergebnisse (unter sonst gleichen Umständen)\n\n\n\nÜbungsaufgabe 2.7 (Live-Experiment zum Effekt der Stichprobengröße) In diesem Live-Experiment untersuchen wir den Effekt der Stichprobengröße auf die Streuung des Mittelwerts in der Stichprobe. Streuen die Ergebnisse mehr in kleinen Stichproben als in großen? Probieren wir es aus!\nIn diesem Experiment werfen Sie (in kleinen Gruppen) eine Münze (auf faire Art und Weise) und notieren das Ergebnis (Kopf oder Zahl). Uns interessiert dabei die Frage, ob die Ergebnisse bei kleinen Stichproben (\\(n=5\\) Münzwürfe) anders streuen als in großen Stichproben (\\(n=20\\) Münzwürfe).\n\n\n\nSie brauchen nur experimentierfreudige Partner (Kleingruppen mit 2-4 Personen), eine faire Münze und dann kann’s los gehen! Scannen Sie den QR-Code, um mit dem Experiment zu starten.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Daten aller Versuche können Sie hier einsehen.4 \\(\\square\\)\n\n\nBeispiel 2.10 (Dorfschulen machen die schlauesten Schüler?!) In einer Pressemitteilung sei zu lesen, dass die besten Schüler in den Dorfschulen zu finden seien. (Das ist eine fiktive Geschichte.) Mit etwas Recherche finden Sie heraus, dass diese Aussage auf belastbaren Daten beruht: Tatsächlich sind die Notendurchschnitte auf den kleinen Dorfschulen deutlich besser als in den großen Schulen in der Stadt. Also stimmt die Behauptung der Pressemitteilung? Die gute Landluft lässt das Hirn wachsen? Sie recherchieren noch etwas weiter in den Daten. Dann fällt Ihnen auf: Die schlechtesten Schüler kommen auch aus den Dorfschulen! Eine statistische Erklärung bietet sich an: In den Dorfschulen gibt es nur wenig Kinder und vergleichsweise‚ kleine Klassen – die Stichproben sind also klein. Bei kleinen Stichproben gibt es viel Variation um den Mittelwert herum, s. Abbildung 2.15, und zwar nach oben (guter Notenschnitt) und nach unten (schlechter Notenschnitt). \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#sec-arten-variablen",
    "href": "010-rahmen.html#sec-arten-variablen",
    "title": "\n2  Rahmen\n",
    "section": "\n2.5 Arten von Variablen",
    "text": "2.5 Arten von Variablen\n\n2.5.1 Nach Position in der Forschungsfrage\nAngenommen, Ihre Forschungsfrage lautet:\n\nHat Lernen einen Einfluss auf den Prüfungserfolg?\n\nIn dem Fall gilt: Lernen ist die Input-Variable, X-Variable, Ursache, unabhängig Variable (UV). Prüfungserfolg ist die Output-Variable, Y-Variable, Wirkung, abhängige Variable (AV). Abbildung 2.16 stellt diese beiden “Positionen” einer Variable dar. Die erste Position ist vor dem Pfeil (X). Die zweite Position ist nach dem Pfeil (Y).\n\n\n\n\n\ngraph LR\n    X[\"Lernen&lt;br&gt;(UV, X, Prädiktor)\"] --&gt; Y[\"gute Note&lt;br&gt;(AV, Y, Kriterium)\"]\n\n\n\n\nAbbildung 2.16: X und Y als synonyme Bezeichnungen für Input- und Output-Variablen einer Forschungsfrage\n\n\n\n\n\nÜbungsaufgabe 2.8 Überlegen Sie sich eine Forschungsfrage, die eine UV und eine AV enthält. Nennen Sie einer anderen Person diese Forschungsfrage und fragen Sie, was die UV und die AV ist. Bei richtiger Antwort belohnen Sie großzügig. \\(\\square\\)\n\n\n2.5.2 Nach dem Skalenniveau\n\nDefinition 2.10 (Skalenniveau) Der Begriff Skalenniveau wird verwendet, um die Art und Menge der Information, die in Variablen enthalten ist, zu benennen. Diese Klassifikation basiert auf den Eigenschaften der Daten und den mathematischen Operationen, die sinnvoll auf diese Daten angewendet werden können. \\(\\square\\)\n\nAbbildung 2.17 gibt einen Überblick über typisch verwendete Skalenniveaus.\n\n\n\n\n\ngraph TD\n    Variablen --&gt; qualitativ\n    Variablen --&gt; quantitativ\n    qualitativ --&gt; nominal\n    qualitativ --&gt; ordinal\n    quantitativ --&gt; Intervallniveau\n    quantitativ --&gt; Verhältnisniveau\n\n\n\n\nAbbildung 2.17: Skalenniveaus\n\n\n\n\n\nBeispiel 2.11 (Beispiele für Skalenniveaus) Beispiele zu den Skalenniveaus sind in Tabelle 2.5 aufgeführt. \\(\\square\\)\n\n\n\n\nTabelle 2.5: Beispiele für Skalenniveaus\n\n\n\n\nVariable\nSkalenniveau\n\n\n\nHaarfarbe\nNominalskala\n\n\nAugenfarbe\nNominalskala\n\n\nGeschlecht\nNominalskala\n\n\nAutomarke\nNominalskala\n\n\nPartei\nNominalskala\n\n\nLieblingsessen\nOrdinalskala\n\n\nMedaillen beim 100-Meter-Lauf\nOrdinalskala\n\n\nUniranking\nOrdinalskala\n\n\nIQ\nIntervallskala\n\n\nExtraversion\nIntervallskala\n\n\nTemperatur in Celsius\nIntervallskala\n\n\nTemperatur in Fahrenheit\nIntervallskala\n\n\nTemperatur in Kelvin\nVerhältnisskala\n\n\nKörpergröße\nVerhältnisskala\n\n\nGeschwindigkeit\nVerhältnisskala\n\n\nLänge\nVerhältnisskala\n\n\n\n\n\n\n\n\nJenachdem, über welches Skalenniveau eine Variable verfügt, sind verschiedenen Rechenoperationen erlaubt, s. Tabelle 2.6 . Zu diesen Rechenoperationen zählen: Das Testen auf Gleichheit (Symbol: \\(=\\)), das Ordnen der Größe nach (Symbol: \\(\\preceq\\)), das Addieren (und Subtrahieren; Symbol: \\(+\\)) und das Multiplizieren (und Dividieren; Symbol: \\(\\cdot\\)).\n\n\n\nTabelle 2.6: Erlaubte Rechenoperationen nach Skalenniveau\n\n\n\n\nSkalenniveau\nQuantitativ\n=\n≼\n+\n×\n\n\n\nNominalniveau\nnein\n✅\n❌\n❌\n❌\n\n\nOrdinalniveau\nnein\n✅\n✅\n❌\n❌\n\n\nIntervallniveau\nja\n✅\n✅\n✅\n❌\n\n\nVerhältnisniveau\nja\n✅\n✅\n✅\n✅\n\n\n\n\n\n\n\n\nWas soll das bedeuten, “Rechenoperationen”? Schauen wir uns für jedes Skalenniveau ein “Rechenbeispiel” an.\nNominalskala: Die Variable Geschlecht ist nominalskaliert. Das bedeutet, dass ihre Ausprägungen Frau und Mann z.\\(\\,\\)B. nicht (sinnvoll) addiert oder sonstwie “verrechnet” werden können. Man könnte, z.\\(\\,\\)B. um das Eintippen zu erleichtern, Frauen mit 1 kodieren und Männer mit 2. Damit darf man aber nicht rechnen! Nicht addieren, nicht multiplizieren, etc. Es macht keinen Sinn zu sagen: “Ich habe eine Frau und einen Mann in meiner Tabelle, das ist im Schnitt ein diverses Geschlecht, weil der Mittelwert von 1 und 2 ist 1,5!” Die einzige “Rechenoperation”, die man auf der Nominalskala machen darf, ist die Prüfung auf Gleichheit: Mann kann feststellen, ob ein Objekt gleich zu einem anderen ist oder unterschiedlich. Also ob zwei Personen das gleiche Geschlecht haben oder von unterschiedlichem Geschlecht sind. Anders ausgedrückt:\n\n👩 \\(\\ne\\) 👨\n👩 \\(=\\) 👩\n👨 \\(=\\) 👨\n\nOrdinalskala: Diese Skala stellt einer Rangordnung dar. Eine Rangordnung ist etwa die geordnete Abfolge Ihrer Leibgerichte (1. Pizza, 2. Spagetthi, 3. Schnitzel). Etwas “formaler” ausgedrückt, z.\\(\\,\\)B.:\n🍕 \\(\\succ\\) 🍝 \\(\\succ\\) 🥩\nDas komische Zeichen \\(\\succ\\) soll heißen: “Ist auf meiner Liste von Leibgerichten weiter oben, mag ich lieber”. Man kann aber nicht sagen, “Ich mag aber Pizza um 42\\(\\,\\)% mehr als die Spaghetti und die um 73\\(\\,\\)% mehr als ein Schnitzel!” Zumindest kann man das nicht ohne weitere Informationen und Annahmen. Es gibt also Dinge auf der Welt, die man leicht in eine Rangordnung bringen kann, aber die man nur schwer in der Größe der Unterschiede bemessen kann. Das ist die Ordinalskala. Die Ordinalskale erlaubt also, Objekte zu ordnen (hinsichtlich eines Merkmals). Die Abstände zwischen den Objekten können dabei nicht quantifiziert werden.\nIntervallskala: Das ist vielleicht eine Überraschung für Sie: Wenn die Temperatur heute bei 10\\(\\,\\)°C liegt und morgen 5\\(\\,\\)°C – dann ist es heute nicht doppelt so warm wie morgen. Ja, 10 ist das Doppelte von 5. Aber 10\\(\\,\\)°C ist nicht doppelt so warm wie 20\\(\\,\\)°C. Wenn Sie das verwundert: Das ist normal, so geht es vielen Leuten, wenn sie das zum ersten Mal hören. Der Grund, warum es nicht sinnvoll (“erlaubt”) ist, Verhältnisse (wie doppelt/halb so viel etc.) auf der Celsius-Skala zu bilden, ist, dass der Nullpunkt der Skala, 0\\(\\,\\)°C, kein echter, physikalischer Nullpunkt ist. Bei 0\\(\\,\\)°C liegt eben nicht Null Wärmeenergie vor. Stattdessen wurde mit 0\\(\\,\\)°C eine Wärmenergiemenge gewählt, die für uns Menschen praktisch, da augenfällig ist: der Gefrierpunkt von Wasser. Was bei der Intervallskala erlaubt ist, ist das Addieren (und Subtrahieren): heute 10\\(\\,\\)°C, morgen 5\\(\\,\\)°C, das ist ein Unterschied von 5\\(\\,\\)°C. Oder: Im Schnitt waren es 7,5\\(\\,\\)°C, das ist genau in der Mitte von 5 und 10\\(\\,\\)°C. Abbildung 2.18 versinnbildlicht die Intervallskala.\n\n\n\n\n\n\n\nAbbildung 2.18: Ein Metermaß steckt im trüben Wasser. Auf dem Metermaß können wir die aufgedruckten Zahlen ablesen. Aber wir wissen nicht, ob der Metermaß auf dem Boden steht. Wir wissen demnach nicht, ob der vom Metermaß angegebene Nullpunkt der wahre Nullpunkt (Meeresboden) ist.\n\n\n\n\nVerhältnisskala: Eine Verhältnisskala ist das, was man sich gemeinhin unter einer metrische Variable vorstellt: Man kann “normal” rechnen, alle Rechenoperationen sind erlaubt. Zuzüglich zu denen, die auch in anderen, “niedrigeren”, Skalenniveaus erlaubt sind, ist das das Bilden von Verhältnissen – Multiplizieren (und damit auch Dividieren).\nAußerdem können quantitative Variablen wie folgt untergliedert werden:\n\n\nstetige Variablen, das sind Variablen, bei denen man zwischen zwei Ausprägungen immer noch eine weitere quetschen kann. So gibt es einen Wert für die Köpergröße zwischen 1.60 m und 1.61 m. Und einen Wert zwischen 1.601 m und 1.602 m, etc.\n\ndiskrete Variablen, das sind metrische Variablen, die nur bestimmte Ausprägungen haben, häufig sind das die natürlichen Zahlen mit Null: \\(0, 1,2,...\\). Ein Beispiel wäre die Anzahl der Kinder in einer Familie.\n\nFragen nach Skalenniveaus gehören zu den Lieblingsprüfungsfragen in diesem Themenbereich. Sie sind gut beraten, sich gerade mit dieser Frage intensiver zu beschäftigen. Auch in thematisch angrenzenden Fächern wird immer wieder die Frage nach dem Skalenniveau aufgeworfen. Das belegt die hohe Relevanz des Themas.\n\nÜbungsaufgabe 2.9 Überlegen Sie sich für einige Variablen die Skalenniveaus und befragen Sie dann interessierte Mitmenschen dazu. \\(\\square\\)\n\n\n\n\nIn diesem Video gibt es noch ausführlichere Erklärung zum Thema Skalenniveaus.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#modelle",
    "href": "010-rahmen.html#modelle",
    "title": "\n2  Rahmen\n",
    "section": "\n2.6 Modelle",
    "text": "2.6 Modelle\nWoran denken Sie beim Wort “Modell”? Vielleicht an Behaims Globus oder an Spielzeugautos, s. Abbildung 2.19?\n\n\n\n\n\nAbbildung 2.19: Matchbox-Autos sind Modelle für Autos, (Spurzem, 2017)\n\n\n\nDefinition 2.11 (Modelle) Modelle sind ein vereinfachtes Abbild der Realität, eine Repräsentation (Kaplan, 2009). \\(\\square\\)\n\n\nBeispiel 2.12 (Beispiele für Modelle) Puppen sind Modelle für Babys, Landkarten für Landstriche und das Atommodell von Nils Bohr ist ein Modell für Atome. \\(\\square\\)\n\nAuch in der Statistik nutzen wir Modelle. Helfen Sie Prof. Weiss-Ois: Er blickt nicht durch, s. Beispiel 7.1. Gerne würde er wissen, wie viele Stunden seine Studierenden auf die Prüfung lernen. Aber mit so vielen Zahlen kann er nicht umgehen … Geben Sie ihm ein Modell: Sagen Sie ihm, wie lang die Studis typischerweise lernen – Sagen Sie ihm ein einfach den Mittelwert der Lernzeiten, das sind 9.6 Stunden.\n\nBeispiel 2.13 (Prof Weiss-Ois blickt nicht durch)  \n\n🧑‍🏫 Vorher: 12, 8, 10, 11, 10, 9, 13, 9, 14, 9, 12, 14, 7, 9, 9, 11, 9, 4, 5, 12, 9, 6, 9, 12, 13, 9, 9, 6, 10 … Oh je, so viele Zahlen! Ich check nix! Wie viel lernen denn jetzt meine Studis?!\n\n\n🧑‍🏫 Ah, 9.6 Stunden! Yeah, jetzt weiß ich, wie viel die Studis so typischerweise lernen. Viel zu wenig natürlich!\n\n\n\n\nProf. I. Ch. Weiss-Ois hat den Mittelwert verstanden … \\(\\square\\)\n\nDer Nutzen von Modellen ist, dass sie komplexe Sachverhalte vereinfachen und damit oft überhaupt erst dem Verständnis oder einer Untersuchung zugänglich machen: Modelle ermöglichen Verständnis. In der Datenanalyse bzw. Statistik (die beiden Begriffe werden hier weitgehend synonym gebraucht) fassen Modelle oft viele Daten prägnant zusammen, z.\\(\\,\\)B. zu einer einzelnen Kennzahl. Das Verrückte an Modellen ist, dass man Informationen wegwirft, um eine (andere, hoffentlich nützlichere) Information zu bekommen (Stigler, 2016). Weniger ist mehr?!",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#praxisbezug",
    "href": "010-rahmen.html#praxisbezug",
    "title": "\n2  Rahmen\n",
    "section": "\n2.7 Praxisbezug",
    "text": "2.7 Praxisbezug\nWir leben im Datenzeitalter; Daten durchdringen alle Bereiche des beruflichen, gesellschaftlichen und privaten Lebens. Die Datenanalyse hat sich in den letzten Jahren massiv verändert, da Datenmengen und -methoden einen regelrechten Boom erlebt haben. Diese Entwicklung ist durchaus auch kritisch zu betrachten; viele Menschen betrachten die Entwicklung im Datenzeitalter – Stichwort künstliche Intelligenz – mit Sorge. Egal ob man Daten als Segen oder Fluch betrachtet, in beiden Fällen ist es wichtig, mit Daten umgehen zu können. Mit der wachsenden Bedeutung von Daten wächst in gleichem Maße die Bedeutung von Datenanalyse. Denn Daten ohne Sinn sind nutzlos. Aus diesem Grund kann man sagen, dass Datenanalyse (und damit auch Statistik als eine spezielle Art von Datenanalyse) zu stark nachgefragten Jobs gehören.\nLaut dem Entgeltatlas der Bundesagentur für Arbeit liegt ein typisches Gehalt von Data Scientisten bei knapp 6000 Euro pro Monat (in der Altersgruppe von 25 bis 54)5. Laut dem Gehaltsreporter liegt das Einstiegsgehalt dieser Berufsgruppe bei knapp 50000 Euro pro Jahr.6",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#wie-man-mit-statistik-lügt",
    "href": "010-rahmen.html#wie-man-mit-statistik-lügt",
    "title": "\n2  Rahmen\n",
    "section": "\n2.8 Wie man mit Statistik lügt",
    "text": "2.8 Wie man mit Statistik lügt\nDas File-Drawer-Problem: Sie haben ein tolles Experiment durchgeführt, viel Arbeit, viel Stress, endlich geschafft, puh. Von den 20 Variablen (als AV, s. Kapitel 2.5), die Sie untersucht haben, zeigt nur 1 einen interessanten Effekt, leider. 1 von 20, das hört sich nicht so toll an. Wäre es da nicht “elegant”, die 19 Variablen ohne schönen Effekt einfach in der Schublade liegen zu lassen bis zum Sankt-Nimmerleins-Tag? Dann könnten Sie stattdessen als Ergebnis nur die eine Variable mit schönen Ergebnis präsentieren, ganz ohne widersprechende Befunde.\nDieser Versuchung zu widerstehen, kann schwer sein. Es ist aber gefährlich, missliebige Ergebnisse zu verschweigen: Die anderen Menschen bekommen dann ein falsches Bild der Ergebnislage; man spricht von Publikationsbias (Marks-Anglin, Arielle and Chen, Yong, 2020). Wer Ergebnisse verschweigt, verzerrt die gesamte Befundlage (Rothstein, 2014) – ein Fall von wissenschaftlichem Fehlverhalten.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#aufgaben",
    "href": "010-rahmen.html#aufgaben",
    "title": "\n2  Rahmen\n",
    "section": "\n2.9 Aufgaben",
    "text": "2.9 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nvariation01\nDef-Statistik01\ntidy1\nSkalenniveau1a\nZiele-Statistik\nvariation02\nSkalenniveau1b\ntidydata1",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#vertiefung",
    "href": "010-rahmen.html#vertiefung",
    "title": "\n2  Rahmen\n",
    "section": "\n2.10 Vertiefung",
    "text": "2.10 Vertiefung\n\n2.10.1 Excel für Könner\nIn vielen Organisationen werden Exceltabellen für bestimmte Zwecke der Datenverarbeitung verwendet. Excel und ähnliche Programme haben bestimmte Stärken und Vorteile, aber auch gewisse Nachteile und Schwächen; das liegt daran, dass Excel für bestimmte Aufgaben besser und für andere weniger gut geeignet ist. Wenn man mit Excel arbeitet, wiederholen sich erfahrungsgemäß immer wieder die gleichen Fehler bzw. kommt es wiederholt zu einer suboptimalen Vorgehensweise zum Aufbau einer Exceltabelle. Der Artikel von Broman & Woo (2018) zeigt anhand einiger praktischer Tipps, wie man Exceltabellen so aufbaut, dass Fehler minimiert werden.\n\nÜbungsaufgabe 2.10 (Fassen Sie den Artikel von Broman & Woo (2018) zusammen) Die Lehrkraft teilt Sie dazu in Gruppen ein und weist jeder Gruppe einen Abschnitt des Artikels zu. Fassen Sie das Wesentliche (und nur das Wesentliche) zum Artikel an einem geeigneten Ort zusammen (z.\\(\\,\\)B. auf einem Online-Whiteboard). \\(\\square\\)\n\n\n2.10.2 Sind Sie süchtig nach Ihrem Handy?\n\n\n\nSind Sie süchtig nach Ihrem Handy? Lassen Sie uns eine kleine Studie dazu (ggf. live im Hörsaal) durchführen. Füllen Sie diese Umfrage zum Thema Smartphonse-Sucht aus (anonym und kein Muss).\n\n\n\n\n\n\n\n\n\n\n\n\n\nKernstück der Umfrage ist die Smartphone-Sucht-Skala (Kwon et al., 2013). Eine Studie fand, dass ca. ein Siebtel der Studierenden süchtig nach ihrem Smartphone ist (Haug et al., 2015); demnach könnte dem Thema eine hohe Bedeutsamkeit zukommen.\n\n2.10.3 Datenprofi plaudert aus dem Nähkästchen\nInspiration von einer Praktikerin der Datenanalyse: Caitlin Hudon verrät in diesem Video, welche Fehler Sie sie in in den acht Jahren ihrer Berufserfahrung gemacht hat und was sie daraus gelernt hat.7",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#literaturhinweise",
    "href": "010-rahmen.html#literaturhinweise",
    "title": "\n2  Rahmen\n",
    "section": "\n2.11 Literaturhinweise",
    "text": "2.11 Literaturhinweise\nEinen Einblick in die Fundamente statistischer Analyse bietet Stigler (2016). Çetinkaya-Runde & Hardin (2021) stellen grundlegende Konzepte der Analyse von Daten im Kapitel 1, “Hello data”, vor. Downey (2023) illustriert statistische Überraschungsmoment auf unterhaltsame, und vor allem: sofataugliche Art.\n\n\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization in Spreadsheets. The American Statistician, 72(1), 2–10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., & Schaub, M. P. (2015). Smartphone Use and Smartphone Addiction among Young People in Switzerland. Journal of Behavioral Addictions, 4(4), 299–307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHorst, A. (2023). Tidy Data [Artwork]. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The Smartphone Addiction Scale: Development and Validation of a Short Version for Adolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific Method, Statistical Method and the Speed of Light. Statistical Science, 15(3), 254–278. https://doi.org/10.1214/ss/1009212817\n\n\nMarks-Anglin, Arielle and Chen, Yong. (2020). A Historical Review of Publication Bias. Research Synthesis Methods, 11(6), 725–742. https://doi.org/10.1002/jrsm.1452\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley StatsRef: Statistics Reference Online. John Wiley. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSpurzem, L. (2017). VW 1303 von Wiking in 1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG\n\n\nStigler, S. M. (2016). The Seven Pillars of Statistical Wisdom. Harvard University Press.\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain Drain: The Mere Presence of One’s Own Smartphone Reduces Available Cognitive Capacity. Journal of the Association for Consumer Research, 2(2), 140–154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild [Artwork]. https://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., & Grolemund, G. (2018). R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren (F. Langenau, Übers.). O’Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "010-rahmen.html#footnotes",
    "href": "010-rahmen.html#footnotes",
    "title": "\n2  Rahmen\n",
    "section": "",
    "text": "Release 2023-Jan↩︎\nhttps://www.openintro.org/data/index.php?data=mariokart↩︎\nCeteris paribus auf Latein, hört sich gleich viel schlauer an.↩︎\nhttps://tinyurl.com/3w8ke2n2↩︎\nAbrufdatum: 1.2.23; https://web.arbeitsagentur.de/entgeltatlas/beruf/129987↩︎\nhttps://gehaltsreporter.de/gehaelter-von-a-bis-z/it/data-scientist/↩︎\nhttps://youtu.be/O5lP6XcopdQ?si=7UsS6xbeYjnorGhx↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rahmen</span>"
    ]
  },
  {
    "objectID": "020-R.html",
    "href": "020-R.html",
    "title": "3  Daten einlesen",
    "section": "",
    "text": "3.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#einstieg",
    "href": "020-R.html#einstieg",
    "title": "3  Daten einlesen",
    "section": "",
    "text": "3.1.1 Lernziele\n\nSie können R und RStudio starten.\nSie können R-Pakete installieren und starten.\nSie können Variablen in R zuweisen und auslesen.\nSie können Daten in R importieren.\nSie können den Begriff Reproduzierbarkeit definieren.\n\n3.1.2 Überblick\nAbbildung 3.1 veranschaulicht den typischen Lernverlauf in der Datenanalyse (und mit R): Höhen und Tiefen sind normal.\n\n\n\n\n\nAbbildung 3.1: Life is a roller-coaster. You just have to ride it (Horst, 2024).\n\n\n\n3.1.3 Ab diesem Kapitel benötigen Sie R\nBitte stellen Sie sicher, dass Sie R (R Core Team, 2024) für dieses Kapitel einsatzbereit haben. Weiter unten in diesem Kapitel finden Sie Installationshinweise (Kapitel 3.3). Falls Sie dieses Kapitel zum ersten Mal bzw. sich noch nicht mit R auskennen, werden Sie vielleicht einigen Inhalten begegnen, die Sie noch nicht gleich verstehen. Keine Sorge, das ist normal. Mit etwas Übung wird Ihnen bald alles schnell von der Hand gehen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errrstkontakt",
    "href": "020-R.html#errrstkontakt",
    "title": "3  Daten einlesen",
    "section": "\n3.2 Errrstkontakt",
    "text": "3.2 Errrstkontakt\n\n3.2.1 Warum R?\nGründe, die für den Einsatz von R (R Core Team, 2024) sprechen:\n\n🆓 R ist kostenlos, andere Softwarepakete für Datenanalyse sind teuer. 💸\n📖 R und R-Befehle sind quelloffen, d.\\(\\,\\)h. man kann sich die zugrundeliegenden Computerbefehle anschauen. Jeder kann prüfen, ob R vernünftig arbeitet. Alle können beitragen.\n🆕 R hat die neuesten Methoden.\n🫂 R hat eine große Community.\n🪡 R ist maßgeschneidert für Datenanalyse.\n\nAllerdings gibt es auch abweichende Meinungen, s. Abbildung 3.2.\n\n\n\n\n\nAbbildung 3.2: Manche finden Excel cooler als R, nicht wahr, Bill Gates? (imgflip, 2024a)\n\n\n\n3.2.2 R und Reproduzierbarkeit\n\nDefinition 3.1 (Reproduzierbarkeit) Ein (wissenschaftlicher) Befunde ist reproduzierbar, wenn andere Personen mit der Analysemethodik zum gleichen Ergebnis (wie in der ursprünglichen Analyse) kommen (Plesser, 2018). \\(\\square\\)\n\n\nDefinition 3.1 ist, etwas überspitzt, in Abbildung 3.3 wiedergegeben.\n\n\n\n🔢 + 🤖 + 🔬 = 🤩\n\n\n\nAbbildung 3.3: Daten + Syntax + genaue Beschreibung der Messungen = reproduzierbar\n\n\n\nBeispiel 3.1 (Aus der Forschung: Reproduzierbarkeit in der Psychologie)  \n\n🧑‍🎓 Wie steht es um die Reproduzierbarkeit in der Psychologie? Sind die Befunde zuverlässig?\n\nObels et al. (2020) haben die Reproduzierbarkeit in psychologischen Studien untersucht. Sie berichten folgendes Ergebnis (S. 229):\n\nWe examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles.\n\nInsgesamt war also etwa jede dritte Studie reproduzierbar. Da gibt es noch viel Luft nach oben! \\(\\square\\)\n\n\n\n3.2.3 R & RStudio\nWenn wir sagen, “wir arbeiten mit R”, dann heißt das in unserem Fall, wir arbeiten mit R und mit RStudio.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 3.4: R und eine GUI wie RStudio arbeiten gut zusammen.\n\n\nIsmay & Kim (2020) zeigen in einer schönen Analogie, was den Unterschied von R und RStudio ausmacht, s. Abbildung 3.5. (Streng genommen ist RStudio für die Datenanalyse irrelevant, aber RStudio ist praktisch, Sie werden es nicht missen wollen.)\n\n\n\n\n\nAbbildung 3.5: R vs. RStudio: R macht die Arbeit, RStudio ist für Komfort und Übersicht zuständig (Ismay & Kim, 2020).\n\n\nKurz gesagt: Das eigentlich Arbeiten besorgt R. Für den Komfort die Übersicht ist RStudio zuständig. Auch eine Art von Arbeitsteilung!\n\n\n\n\n\n\nHinweis\n\n\n\n\nR: 🏋️‍♀️\nRStudio: 💅 \\(\\square\\)\n\n\n\n\nHier sehen Sie einen Screenshot von der Oberfläche von RStudio, s. Abbildung 3.6.\n\n\n\n\n\nAbbildung 3.6: So sieht RStudio aus",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-install-r",
    "href": "020-R.html#sec-install-r",
    "title": "3  Daten einlesen",
    "section": "\n3.3 Installation von R und RStudio",
    "text": "3.3 Installation von R und RStudio\n\n3.3.1 Installation von R\nR ist ein Softwarepaket für statistische Berechnungen. Laden Sie es für Ihr Betriebssytem herunter unter https://cloud.r-project.org. Wenn Sie beim Herunterladen gefragt werden, dass Sie einen “Mirror” auswählen sollen, heißt das, Sie sollen einen Computer (Server) wählen, von dem Sie R herunterladen. Der sollte möglichst nicht zu weit weg stehen, dann spart es vielleicht etwas Zeit und Bandbreite. Wenn Sie die Installationsdatei heruntergeladen haben, öffnen Sie diese Datei (Doppelklick) und Sie werden durch die Installation geführt. (Sie benötigen Admin-Rechte auf Ihrem Computer.)\n\nWindows\nMacOS\nLinux\n\n3.3.2 Installation von RStudio Desktop\nRStudio ist eine graphische Benutzeroberfläche (graphical user interface, GUI) für R, plus ein paar Goodies (in Form einer intergrierten Entwicklungsumgebung (integrated development environment, IDE). Laden Sie die Desktop-Version von RStudio herunter für Ihr Betriebssystem (Windows, MacOS, Linux) vom Anbieter (Posit) herunter.1 Wenn Sie die Installationsdatei heruntergeladen haben, öffnen Sie diese Datei (Doppelklick) und Sie werden durch die Installation geführt. (Sie benötigen u. U. Admin-Rechte auf Ihrem Computer.)\n\n3.3.3 Posit/RStudio Cloud\nPosit Cloud bzw. RStudio Cloud (https://rstudio.cloud/) ist ein Webdienst von Posit (zum Teil kostenlos), also ein RStudio online: Man kann damit online mit R arbeiten. Sie können es als Alternative zur Installation von RStudio Desktop (was auf Ihrem Computer läuft) verwenden. Ein Vorteil von RStudio Cloud ist, dass man als Nutzer nichts installieren muss und dass es auch auf Tablets läuft (im Gegensatz zur Desktop-Version von RStudio). Ein Nachteil ist, dass es etwas langsamer ist und nur für ein gewisses Zeitvolumen kostenlos. Sie müssen sich erst ein Konto beim Anbieter anlegen, um den Dienst nutzen zu können.\nDie Oberfläche RStudio Cloud ist praktisch identisch zur Desktop-Version, s. Abbildung 3.7.\n\n\n\n\n\nAbbildung 3.7: So sieht RStudio Cloud aus. Fast genau wie RStudio Desktop\n\n\nWenn Ihnen jemand (z.\\(\\,\\)B. eine Lehrkraft) einen RStudio-Cloud-Projektordner bzw. einen Link dazu bereitstellt, ist das komfortabel, da die Lehrkraft dann schon Pakete installieren, Daten bereitstellen und andere Nettigkeit vorbereiten kann für Sie. Allerdings müssen Sie den Projektordner in Ihrem eigenen Konto abspeichern, wenn Sie etwas speichern möchten, da Sie vermutlich keine Schreibrechte im Projektordner dieser nettern Person (Ihrer Lehrkraft) haben. Klicken Sie dazu auf “Save a permanent copy”, s. Abbildung 3.8.\n\n\n\n\n\nAbbildung 3.8: Einen Projektordner im eigenen Konto abspeichern, um Schreibrechte zu haben\n\n\nSie können auch von der Cloud exportieren, also Ihre Syntaxdatei herunterladen. Klicken Sie dazu im Reiter “Files” auf More &gt; Export.\n\n\n\n\n\n\nHinweis\n\n\n\nRStudio starten, nicht R. \\(\\square\\)\n\n\nWir verwenden beide Programme (R und RStudio). Aber wir öffnen nur RStudio. RStudio findet selbständig R und öffnet dieses “heimlich”. Öffnen Sie nicht noch extra R (sonst wäre R zweifach geöffnet). Anstelle von RStudio Desktop (auf Ihrem Computer/Desktop) können Sie auch die RStudio Cloud (die Online-Version) starten",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-r-pckgs",
    "href": "020-R.html#sec-r-pckgs",
    "title": "3  Daten einlesen",
    "section": "\n3.4 R-Pakete",
    "text": "3.4 R-Pakete\nTypisch für R ist sein modularer Aufbau: Man kann eine große Zahl an Erweiterungen (“Pakete”, engl. packages) installieren, alle kostenlos. In R Paketen “wohnen” R-Befehle, also Dinge, die R kann, “Skills” sozusagen. Außerdem können in R-Paketen auch Daten bereitgestellt werden. Damit man die Inhalte eines R-Pakets nutzen kann, muss man es zuerst installieren und dann verfügbar machen (“starten”). Man kann sich daher ein R-Paket vorstellen wie ein Buch: Wenn R es gelesen hat, dann kennt es die Inhalte. Diese Inhalte könnten irgendwelche Formeln, also Berechnungen sein. Es könnte aber die “Bauanleitung” für ein schönes Diagramm sein. Ist ein spezielles R-Paket auf Ihrem Computer installiert, so können Sie diese Funktionalität nutzen. Die Anzahl der R-Pakete ist groß; allein auf dem “offiziellen Web-Store” (nennt sich “CRAN”) von R gibt es ca. 20,000 Pakete (Hornik et al., 2023). Und es kommen immer mehr dazu.\nErweiterungen kennt man von vielen Programmen, sie werden auch Add-Ons, Plug-Ins oder sonstwie genannt. Man siehe zur Verdeutlichung Erweiterungen beim Broswer Chrome, Abbildung 3.9.\n\n\n\n\n\nAbbildung 3.9: Erweiterungen beim Browser Chrome\n\n\nWie jede Software muss man Pakete (Erweiterungen für R) erst einmal installieren, bevor man sie verwenden kann. Übrigens, einmal installieren reicht. Das Installieren geht komfortabel, wenn man beim Reiter Packages auf Install klickt und dann den Namen des zu installierenden Pakets eingibt.\nAbbildung 3.11 verdeutlicht, wo Sie in RStudio klicken müssen, um Pakete zu installieren.\n\n\n\n\n\nAbbildung 3.10: Geben Sie den Namen des zu installierenden R-Pakets in dieser Maske ein\n\n\n\n\n\n\n\nAbbildung 3.11: So kann man R-Pakete installieren in RStudio\n\n\n\n🧑‍🎓 Welche R-Pakete sind denn schon installiert?\n\n\n🧑‍🏫 Im Reiter Packages können Sie nachschauen, welche Pakete auf Ihrem Computer schon installiert sind.\n\nDiese Pakete brauchen Sie logischerweise dann nicht noch mal installieren, s. Abbildung 3.12; es sei denn, Sie wollen das Paket updaten.\n\n\n\n\n\nAbbildung 3.12: So sehen Sie, ob ein bestimmtes R-Paket auf Ihrem System installiert ist\n\n\nAlternativ können Sie zum Installieren von Paketen auch den Befehl install.packages() verwenden. Also zum Beispiel install.packages(tidyverse), um das Paket tidyverse zu installieren.\n\n🧑‍🎓 Ja, aber welche R-Pakete “soll” ich denn installieren, welche brauche ich denn?\n\n\n\n🧑‍🏫 Im Moment sollten Sie die folgenden Pakete installiert haben: tidyverse und easystats.\n\n\nWenn Sie die noch nicht installiert haben sollten, dann können Sie das jetzt nachholen. Übrigens sind tidyverse (Wickham et al., 2019) und easystats (Lüdecke et al., 2022) Pakete, die nur dafür da sind, mehrere Pakete zu installieren. So gehören z.\\(\\,\\)B. zu tidyverse die Pakete ggplot (Daten verbildlichen) und dplyr (Datenjudo). Damit wir nicht alle Pakete einzeln installieren und starten müssen, bietet uns das Paket tidyverse den Komfort, alle die Pakete dieser “Sammlung” auf einmal zu starten. Praktisch.\nBevor Sie ein R-Paket (oder überhaupt irgendwelche Software) installieren/updaten, sollten Sie das entsprechende R-Paket schließen/beenden. Sonst schrauben Sie sozusagen an einem elektrischen Gerät herum, das noch unter Strom steht (nicht gut). Die einfachste Art, alle Pakete zu beenden ist, Session &gt; Restart R zu klicken (in RStudio).\nWenn Sie ein Softwareprogramm installiert haben, müssen Sie es noch starten, bevor Sie es nutzen können. Sie erkennen leicht, ob ein Paket bereitgestellt (gestartet) ist, wenn Sie ein Häkchen vor dem Namen des Pakets in der Paketliste (Reiter Packages) sehen. Ein bestimmtes R-Paket muss man nur einmalig installieren. Aber man muss es jedes Mal neu starten, wenn man R (bzw. RStudio) startet.\nDieses Video verdeutlicht den Unterschied zwischen Installation und Starten eines R-Pakets.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#mit-r-arbeiten",
    "href": "020-R.html#mit-r-arbeiten",
    "title": "3  Daten einlesen",
    "section": "\n3.5 Mit R arbeiten",
    "text": "3.5 Mit R arbeiten\n\n3.5.1 Projekte in R\nEin Projekt in RStudio ist letztlich ein Ordner, der als “Basis” für eine Reihe von zusammengehörigen Dateien verwendet wird. Sagen wir, Sie nennen Ihr Projekt cool_stuff. RStudio legt uns diesen Ordner an einem von uns gewählten Platz auf unserem Computer an. Das ist ganz praktisch, weil man dann sagen kann “Hey R, nimm die Datei ‘daten.csv’”, ohne, dass man dabei einen Pfad angeben müsste. Vorausgesetzt, die Datei liegt auch im Projektordner (cool_stuff). RStudio-Projekte kann anlegen mit Klick auf das Icon, das einen Quader mit dem Buchstaben R darin anzeigen. Nutzen Sie RStudio-Projekte, das macht Ihr Leben leichter. RStudio-Projekte zu nutzen ist praktischer als das Arbeitsverzeichnis von Hand zu wählen oder mit Pfaden herumzubasteln.\nHier sehen Sie Beispiele für RStudio-Projekte, s. Abbildung 3.13.\n\n\n\n\n\nAbbildung 3.13: RStudio-Projekte, Beispiele\n\n\n\n3.5.2 Skriptdateien\nDie R-Befehle (“Syntax”) schreiben Sie am besten in eine speziell dafür vorgesehene Textdatei in RStudio. Eine Sammlung von (R-)Computer-Befehlen nennt man auch ein Skript, daher spricht man bei Dateien, die Syntax enthalten, von einer Skriptdatei.\nUm eine neue R-Skriptdatei zu erstellen, gibt es mehrere Wege. Einer ist: klicken Sie auf das Icon, das ein weißes Blatt mit einem grünen Pluszeichen zeigt, s. Abbildung 3.14.\n\n\n\n\n\n\n\n\n\n(a) Klick auf Icon\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Auswahl im Menu\n\n\n\n\n\n\nAbbildung 3.14: Es gibt verschiedene Wege, um eine neue R-Skript-Datei in RStudio zu öffnen. (a) Per Klick auf das Icon. (b) Im Menü File, auf R Script klicken.\n\n\nVergessen Sie nicht zu speichern, wenn Sie ein tolles Skript geschrieben haben. Dafür gibt es mehrere Möglichkeiten:\n\nTastaturkürzel Strg+S\n\nMenü: File &gt; Save\n\nKlick auf das Icon mit der Diskette, s. Abbildung 3.14.\n\nEine existierende Skriptdatei können Sie in typischer Manier öffnen:\n\nTastaturkürzel Strg+O\n\nMenü: File &gt; Open File …\n\nKlick auf das Icon mit der Akte und dem grünen Pfeil, s. Abbildung 3.14\n\n\n3.5.3 Quarto-Dokumente\nQuarto2 ist ein (kostenloses) Programm zum Erstellen von PDF-, HTML- oder anderen Dokumentformaten, in die man R-Syntax einfügen kann. Die Ausgaben der R-Befehle werden dann direkt ins Ausgabedokument eingebunden. Quarto ist in RStudio integriert. Quarto ist eine komfortable und leistungsfähige Methode, um Dokumente mit R-Syntax zu anzreichern. Sie sind aber nicht verpflichtet, Quarto zu nutzen. Stattdessen können Sie Ihre Syntax auch in Skriptdateien schreiben.\nAbbildung 3.15 zeit ein Beispiel für ein Quarto-Dokument.\n\n\n\n\n\nAbbildung 3.15: Dokumente schreiben mit Quarto. Quelle: Posit\n\n\nWenn Sie Quarto nutzen möchten, müssen Sie es zunächst installieren, d.\\(\\,\\)h. herunterladen. Dann können Sie in RStudio Quarto-Dateien erstellen. Ein neues Quarto-Dokument können Sie erstellen mit Klick auf File &gt; New File &gt; Quarto Document.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#errisch-für-einsteiger",
    "href": "020-R.html#errisch-für-einsteiger",
    "title": "3  Daten einlesen",
    "section": "\n3.6 Errisch für Einsteiger",
    "text": "3.6 Errisch für Einsteiger\n\n3.6.1 Variablen\nIn jeder Programmiersprache kann man Variablen definieren, so auch in R:\n\nrichtige_antwort = 42\nfalsche_antwort = 43\ntyp = \"Antwort\"\nist_korrekt = TRUE  # wahr\nist_falsch = FALSE  # falsch\n\nAlternativ zum Gleichheitszeichen = können Sie auch (synonym) den Zuweisungspfeil &lt;- verwenden (Kleiner-Als-Zeichen gefolgt vom Minus-Zeichen). Beides führt zum gleichen Ergebnis. Allerdings ist der Zuweisungspfeil präziser, und sollte daher bevorzugt werden. Der Zuweisungspfeil &lt;- bzw. das Gleichheitszeichen = definiert eine neue Variable (oder überschreibt den Inhalt, wenn die Variable schon existiert).\n\n\nrichtige_antwort &lt;- 42\n\nSie können sich eine Variable wie einen Becher oder Behälter vorstellen, der bestimmte Werte enthält, z.\\(\\,\\)B. den Wert “9” (für 9\\(\\,\\)° Celsius. Auf dem Becher steht die Bezeichnung des Bechers geschrieben, z.\\(\\,\\)B. “Temperatur”. Natürlich können Sie die Werte aus dem Becher entfernen und sie durch neue ersetzen (vgl. Abbildung 3.16).\n\n\n\n\n\nAbbildung 3.16: Variablen zuweisen: Der Variable mit dem Namen temp weisen wir den Wert 9 zu.\n\n\nR kann übrigens auch rechnen. Probieren Sie es doch gleich mal hier aus!\n\ndie_summe &lt;- falsche_antwort + richtige_antwort\n\nAber was ist jetzt der Wert, der “Inhalt” der Variable die_summe?\nUm den Wert, d.\\(\\,\\)h. den Inhalt einer Variablen in R auszulesen, geben wir einfach den Namen des Objekts ein:\n\ndie_summe\n## [1] 85\n\nWas passiert wohl, wenn wir die_summe jetzt wie folgt definieren?\n\ndie_summe &lt;- falsche_antwort + richtige_antwort + 1\n\nWer hätt’s geahnt:\n\ndie_summe\n## [1] 86\n\nVariablen können auch “leer” sein:\n\nalter &lt;- NA  # NA wie \"not available\", nicht vorhanden\nalter\n## [1] NA\n\nNA steht für not available, nicht verfügbar und macht deutlich, dass hier ein Wert fehlt.\n\n🧑‍🎓 Wozu brauche ich bitte fehlende Werte?!\n\nFehlende Werte sind ein häufiges Problem in der Praxis. Vielleicht hat sich die befragte Person geweigert, ihr Alter anzugeben (Datenschutz!). Oder als Sie die Daten in Ihren Computer eingeben wollten, ist Ihre Katze über die Tastatur gelaufen und alles war futsch…\n\n3.6.2 Funktionen (“Befehle”)\nDas, was R kann, ist in “Funktionen” hinterlegt. Genauer gesagt ist ein “Befehl” an R eine Funktion.\n\nDefinition 3.2 (Funktion) Eine Funktion ist eine Regel, die jedem Eingabewert (auch Argument genannt) einen Ausgabewert zuordnet. Man kann sich Funktionen als Maschinen vorstellen, die Eingabedaten in Ausgabedaten umwandeln, vgl. Abbildung 3.17. \\(\\square\\)\n\nEin Beispiel für eine solche Funktion könnte sein: “Berechne den Mittelwert dieser Datenreihe” (schauen wir uns gleich an). Das geht so:\n\nAntworten &lt;- c(42, 43)\n\nDer Befehl c (c wie combine) fügt mehrere Werte zusammen zu einer “Liste” (einem Vektor). (Streng genommen sollte man nicht von einer Liste sprechen, da es in R noch einen anderen Objekttyp gibt, der list heißt, und eine verallgemeinerte Form eines Vektors ist.) Mit dem Zuweisungspfeil geben wir diesem Vektor einen Namen, hier Antworten. Dieser Vektor besteht aus zwei Werten, zuerst 42, dann kommt 43. Zwei wichtige Typen von Vektoren sind numerische Vektoren (reelle Zahlen; in R auch als numeric oder double bezeichnet) und Textvektoren, in R auch als String oder character bezeichnet.\n\nDefinition 3.3 (Vektor) Als Vektor (Datenreihe) bezeichnen wir eine geordnete Folge von Werten. In R kann man sie mit der Funktion c erstellen. Die Werte eines Vektors bezeichnet man als Elemente. \\(\\square\\)\n\n\nBeispiel 3.2 (Beispiele für Vektoren) Vektoren können (praktisch) beliebig lang sein, z.\\(\\,\\)B. drei Elemente.\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 3)  # x und y sind ungleich (Reihenfolge der Werte)\nz &lt;- c(3.14, 2.71)  \nnamen &lt;- c(\"Anni\", \"Bert\", \"Charlie\") # Text-Vektor\n\n\n\nBeispiel 3.3 Weitere Beispiel für Funktionen sind:\n\n“Erstelle eine Liste (Vektor) von Werten”.\n“Lade dieses R-Paket.”\n“Gib den größten Wert dieser Datenreihe aus.” \\(\\square\\)\n\n\n\n\n3.6.3 Unsere erste statistische Funktion\nJetzt wird’s ernst. Jetzt kommt die Statistik. 🧟 Berechnen wir also unsere erste statistische Funktion: Den Mittelwert. Puh.\n\nmean(Antworten)\n## [1] 42\n\nSie hätten Antworten auch durch c(42, 43) ersetzen können, so haben Sie ja die Variable Antworten im letzten Abschnitt definiert.\nR arbeitet so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: mean(Antworten)\n⬇️ \nSchritt 1: mean(c(42, 43))\n⬇️ \nSchritt 2: 42.5\nAbbildung 3.17 stellt eine Funktion schematisch dar.\n\n\n\n\n\nAbbildung 3.17: Schema einer Funktion\n\n\nEine Funktion hat einen oder mehrere Eingaben (Argumente, Inputs; s. Abbildung 3.17), das sind Daten oder Verarbeitungshinweise, die man in die Funktion fun eingibt, bevor die Funktion loslegt. Eine Funktion hat immer (genau) eine Ausgabe (Output), in der das Ergebnis der Funktion ausgegeben wird.\nSo hat die Funktion mean z.\\(\\,\\)B. folgende Argumente, s. Listing 3.1.\n\n\nListing 3.1: Die Argumente der R-Funktion mean\n\n\nmean(x, trim = 0, na.rm = FALSE, ...)\n\n\n\n\n\n\nx: das ist der Vektor, für den der Mittelwert berechnet werden soll\n\ntrim = 0: Sollen die extremsten Werte von x lieber “abgeschnitten” werden, also nicht in die Berechnung des Mittelwerts einfließen?\n\nna.rm = FALSE: Wie soll mit fehlenden Werten NA umgegangen werden? Im Standard liefert mean (und viele andere arithmetische Funktionen in R) NA zurück. R schwenkt sozusagen die rote Fahne, um zu signalisieren: Achtung, Mensch, hier ist irgendwas nicht in Ordnung. Setzt man aber na.rm = TRUE, dann entfernt (remove, rm) R die fehlenden Werte und berechnet den Mittelwert, ohne weitere Hinweise zu den fehlenden Werten.\n\n... heißt “sonstiges Zeugs, das manchmal eine Rolle spielen könnte”; darum kümmern wir uns jetzt nicht.\n\nEinige Argumente haben einen Standardwert bzw. eine Voreinstellung (engl. default). So wird bei der Funktion mean im Standard nicht getrimmt (trim = 0) und fehlende Werte werden nicht entfernt (na.rm = FALSE).\nWenn ein R-Befehl ein Argument mit Voreinstellung hat, brauchen Sie dieses Argument nicht zu befüllen. In dem Fall wird auf den Wert der Voreinstellung zurückgegriffen. Argumente ohne Voreinstellung – wie x bei mean – müssen Sie aber auf jeden Fall mit einem Wert befüllen. Man würde also mean zumeist so aufrufen: mean(x).\nBei jedem R-Befehl haben die Argumente eine bestimmte Reihenfolge, etwa bei mean: mean(x, trim = 0, na.rm = FALSE, ...). (Nur) wenn man die Argumente in ihrer vorgegebenen Reihenfolge anspricht, muss man nicht den Namen des Arguments anführen:\n✅ mean(Antworten, 0, FALSE)\nHält man sich aber nicht an die vorgebene Reihenfolge, so weiß R nicht, was zu tun ist und flüchtet sich in eine Fehlermeldung:\n\nmean(Antworten, FALSE, 0)  # FALSCH, DON'T DO IT \n## Error in mean.default(Antworten, FALSE, 0): 'trim' must be numeric of length one\n\nWenn man die Namen der Argumente anspricht, ist die Reihenfolge egal:\n\nmean(na.rm = FALSE, x = Antworten)  # ok\nmean(trim = 0, x = Antworten, na.rm = TRUE)  # ok\n\nÜbrigens: Leerzeichen sind R fast immer egal. Aus Gründen der Übersichtlichkeit sollte man aber Leerzeichen verwenden. In folgenden Fällen sind Leerzeichen nicht erlaubt: In Operatoren wie &lt;- oder &lt;= (und andere logische Operatoren, s. Tabelle 3.1) und in Variablennamen.\n\n3.6.4 Vorsicht bei fehlenden Werten\nSagen wir, wir haben einen fehlenden Wert in unseren Daten:\n\nAntworten &lt;- c(42, 43, NA)\nAntworten\n## [1] 42 43 NA\n\nWenn wir jetzt den Mittelwert berechnen wollen, quittiert R das mit einem schnöden NA. NA steht für not available, ist also ein Hinweis, dass Werte fehlen.\n\nmean(Antworten)\n## [1] NA\n\nR meint es gut mit Ihnen.3 Stellen Sie sich vor, dass R Sie auf dieses Problem aufmerksam machen möchte:\n\n🤖 Achtung, NAs, fehlende Werte, lieber Herr und Gebieter, du hast nicht mehr alle Latten am Zaun, will sagen, alle Daten im Vektor!\n\n(Danke, R.)\nMöchten Sie aber lieber R dieses Verhalten austreiben, so befüllen Sie das Argument na.rm mit dem Wert TRUE (na.rm steht für remove die NA, entferne die fehlenden Werte).\n\nmean(Antworten, na.rm = TRUE)\n## [1] 42\n\n\n3.6.5 Vektorielles Rechnen\n\nDefinition 3.4 (Vektorielles Rechnen) Das Rechnen mit Vektoren in R bezeichnen wir als vektorielles Rechnen. \\(\\square\\)\n\nVektorielles Rechnen ist ein praktische Angelegenheit, man kann z.\\(\\,\\)B. folgende Dinge einfach in R ausrechnen. Gegeben sei x als Vektor (1, 2, 3). Dann können wir die Differenz (Abweichung) jedes Elements von x zum Mittelwert von x komfortabel so ausrechnen:\n\nx - mean(x)\n## [1] -1  0  1\n\nEtwas eleganter ausgedrückt: Wir haben die Funktion mit Namen “Differenz” (“Minus-Rechnen”) auf jedes Element von x angewandt. Im Einzelnen haben wir also folgenden drei Differenzen berechnet:\n\n1 - 2\n2 - 2\n3 - 2\n\nDiese drei Rechenschritte sind symbolisch in Abbildung 3.18 dargestellt.\n\n\n\n\n\n\n\nAbbildung 3.18: Schema des vektoriellen Rechnens: Eine Funktion wird auf jedes Element eines Vektors angewandt. Hier: \\(1-2=-1; 2-2=0; 3-2=1\\)\n\n\n\n\n\n3.6.6 Ich brauche R-Hilfe!\n\n\nWo finde ich Hilfe zu einer bestimmten Funktion, z.\\(\\,\\)B. fun? Geben Sie dazu folgenden R-Befehl ein: help(fun). Alternativ geben Sie den Namen der Funktion in RStudio im Suchfeld beim Reiter Help ein. Oder Googeln.\n\nWenn ich ein R-Paket installiere, fragt mich R manchmal, ob ich auch Pakete installieren, will, die “kompiliert” werden müssen. Soll ich das machen? Nein, das ist zumeist nicht nötig; geben Sie “no” ein.\n\nIn welchem Paket wohnt meine R-Funktion? Suchen Sie nach der Funktion auf der Webseite RDocumentation4.\n\nIch weiß nicht, wie der R-Befehl funktioniert! Vermutlich haben andere Ihr Problem auch, und meistens hat irgendwer das Problem schon gelöst. Am besten suchen Sie mal auf www.stackoverflow.com.\n\nIch muss mal grundlegend verstehen, wozu ein bestimmten R-Paket gut ist. Was tun? Lesen Sie die Dokumenation (“Vignette”) eines R-Pakets durch. Für das Paket dplyr bekommen Sie so einen Überblick über die verfügbaren Vignetten diese Pakets: vignette(package = \"dplyr\"). Dann suchen Sie sich aus der angezeigten Liste eine Vignette raus; mit vignette(\"rowwise\") können Sie sich dann die gewünschte Vignette (z.\\(\\,\\)B. rowwise) anzeigen lassen.\n\nOh nein, ich seh rot, das heißt, R zeigt mir irgendwas in roter Schrift an. Ist jetzt was kaputt? Keine Sorge, R ist in seiner Ausgabe nicht sparsam mit roter Farbe. Solange es nicht als Fehlermeldung (ERROR) erscheint, ist es meist kein Problem.\n\nR hat sich aufgehängt oder bringt einen Fehler an einer Stelle, wo sonst alles funktioniert hat. Probieren Sie auf jeden Fall mal das AEG-Prinzip (Aus-Ein-Gut): Sprich, R neu starten.\n\nIch suche schon seit einer Stunde einen Fehler und finde ihn nicht. Ich habe schon verschiedene Gegenstände vor Wut an die Wand geworfen. Was soll ich tun? Machen Sie eine Pause. Doch, das ist ernst gemeint. Meine Erfahrung: Mit etwas Abstand wird der Kopf klarer und man findet das Problem viel einfacher. (Und manchmal ist einem das Problem danach schlichtweg egal.)\n\nIrgendwie reagiert R komisch, vielleicht hat es sich aufgehängt? Starten Sie R neu. Klicken Sie auf Session &gt; Restart R.\n\nIch muss mal klar Schiff machen und alle (oder einige) Variablen löschen. Wie werd ich das Zeug wieder los? Beim Neustart von R werden alle Objekte (Variablen) gelöscht. Einzelne Objekte können Sie selektiv löschen mit dem Befehl rm, so löscht rm(mariokart) das Objekt namens mariokart.\n\n\n\n\n\n\n\nVorsicht\n\n\n\nR ist penibel: So sind name und Name zwei verschiedene Variablen für R. Groß- und Kleinschreibung wird von R streng beachtet.\n\n\nEine gute Nachricht: Wenn R etwas von WARNING (bzw. Warnung) sagt, können Sie das zumeist ignorieren. Eine Warnung ist kein Fehler (ERROR) und meistens nicht gravierend oder nicht dringend. Ihre Syntax läuft trotzdem durch. Im Zweifel ist Googeln eine gute Idee. Nur wenn R von Error spricht, ist es auch ein Fehler und Ihre Syntax läuft nicht durch.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#mit-daten-arbeiten",
    "href": "020-R.html#mit-daten-arbeiten",
    "title": "3  Daten einlesen",
    "section": "\n3.7 Mit Daten arbeiten",
    "text": "3.7 Mit Daten arbeiten\n\n3.7.1 Wo sind meine Daten?\nDamit Sie eine Datendatei importieren können, müssen Sie wissen, wo die Datei ist. Schauen wir uns zwei Möglichkeiten an, wo Ihre Datei liegen könnte.\n\nIrgendwo im Internet\nIrgendwo auf Ihrem Computer, z.\\(\\,\\)B. in Ihrem R-Projektordner\n\nIn beiden Fällen wird der “Aufenthaltsort” der Datei durch den Pfad und den Namen der Datei definiert. Der Pfad einer Datei gibt an, in welchem Ordner und Unterordner (und Unter-Unterordner) die gesuchte Datei liegt. Ein Pfad könnte z.\\(\\,\\)B. so aussehen: /Users/sebastiansaueruser/github-repos/statistik1/.\n\n\n\n\n\n\nHinweis\n\n\n\nWir werden in diesem Kurs häufiger mit dem Daten mariokart arbeiten; Sie finden ihn online.5\n\n\n\n3.7.2 Gebräuchliche Datenformate\nDaten werden in verschiedenen Formaten im Computer abgespeichert; Tabellen häufig als Excel-Datei (.XSL oder .XLSX) oder als CSV-Datei (.CSV).\nIn der Datenanalyse ist das gebräuchlichste Format für Daten in Tabellenform die CSV-Datei. Der Grund ist die technische Einfachheit dieses Formats.. Für uns Endverbraucher tut das nichts groß zur Sache, die CSV-Datei beherbergt einfach eine brave Tabelle in einer Textdatei, sonst nichts. Daher können Sie jede CSV-Datei mit einem normalen Texteditor öffnen. In diesem Buch werden wir mit einem Datensatz namens mariokart arbeiten.\nHallo Mario, s. Abbildung 3.19!\n\n\n\n\n\nAbbildung 3.19: Hallo, Mario\n\n\n Download CSV   Download XLSX \n\nÜbungsaufgabe 3.1 (CSV-Datei öffnen)  \n\n\nAufgabe\nLösung\n\n\n\nÖffnen Sie die CSV-Datei mariokart.csv mit einem Texteditor (nicht mit Word und auch nicht mit Excel). Schauen Sie sich gut an, was Sie dort sehen und erklären Sie die Datenstruktur.\n\n\nEine CSV-Datei repräsentiert eine Datentabelle. Eine Spaltengrenze wird mittels eines Kommas dargestellt (man kann auch andere Zeichen wählen, um Spalten voneinander abzugrenzen).\nHier sind die ersten paar Zeilen von mariokart.csv:\nV1,id,duration,n_bids,cond,start_pr,ship_pr,total_pr,ship_sp,seller_rate,stock_photo,wheels,title\n1,150377422259,3,20,new,0.99,4,51.55,standard,1580,yes,1,~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND NEW ~~\n2,260483376854,7,13,used,0.99,3.99,37.04,firstClass,365,yes,1,Mariokart Wii Nintendo with wheel - Mario Kart Nintendo\n3,320432342985,3,16,new,0.99,3.5,45.5,firstClass,998,no,1,Mario Kart Wii (Wii)\n4,280405224677,3,18,new,0.99,0,44,standard,7,yes,1,Brand New Mario Kart Wii Comes with Wheel. Free Ship\n5,170392227765,1,20,new,0.01,0,71,media,820,yes,2,BRAND NEW NINTENDO 1 WII MARIO KART WITH 2 WHEELS +GAME\n\n\n\n\n\n3.7.3 Daten importieren\nSie können Daten aus verschiedenen Quellen in R importieren: Aus einem R-Paket, von einer Webseite oder von Ihrem Computer. Dabei ist es egal, ob Sie die Desktop- oder die Cloud-Version von RStudio nutzen.\nIst Ihr Datensatz schon in einem R-Paket gespeichert, können Sie ihn aus diesem R-Paket starten. Das ist die bequemste Option. Zum Beispiel “wohnt” der Datensatz mariokart im R-Paket openintro.\n\n\n\n\n\n\nTipp\n\n\n\nHäufig wird vergessen, dass ein R-Paket vor der Nutzung installiert werden muss.\n\n\nAuf der anderen Seite muss man ein R-Paket (wie andere Software auch) nur ein Mal installieren – Allerdings muss man ein Paket nach jedem Neustart von R bzw. von RStudio mit library starten.\n\ndata(\"mariokart\", package = \"openintro\") # Paket muss installiert sein\n\nEine Data-Dictionary für mariokart findet sich in Anhang B. Online findet sich eine Erklärung (Data-Dictionary) des Datensatzes.6\nDer Befehl read.csv bietet eine Möglichkeit, Daten (in Form einer Tabelle) von einer Webseite (URL) in R zu importieren, s. Listing 3.2.\n\n\n\nListing 3.2: Mariokart-Datensatz importieren (mit read.csv)\n\nmariokart &lt;- read.csv(paste0(\n  \"https://vincentarelbundock.github.io/Rdatasets/\",\n  \"csv/openintro/mariokart.csv\"))\n\n\n\n\nEs liegt bei Ihnen, welchen Namen Sie der Tabelle geben. Ich persönlich wähle oft den Namen d, d die Daten. d ist ein kurzer Namen, muss man nicht so viel tippen. Auf der anderen Seite ist d nicht gerade ein präziser Name. Werfen Sie einen Blick in die Tabelle (engl. to glimpse).\n\nglimpse(d)\n## Rows: 143\n## Columns: 12\n## $ id          &lt;dbl&gt; 1.5e+11, 2.6e+11, 3.2e+11, 2.8e+11, 1.7e+11, 3.6e+11, 1…\n## $ duration    &lt;int&gt; 3, 7, 3, 3, 1, 3, 1, 1, 3, 7, 1, 1, 1, 1, 7, 7, 3, 3, 1…\n## $ n_bids      &lt;int&gt; 20, 13, 16, 18, 20, 19, 13, 15, 29, 8, 15, 15, 13, 16, …\n## $ cond        &lt;fct&gt; new, used, new, new, new, new, used, new, used, used, n…\n## $ start_pr    &lt;dbl&gt; 0.99, 0.99, 0.99, 0.99, 0.01, 0.99, 0.01, 1.00, 0.99, 1…\n## $ ship_pr     &lt;dbl&gt; 4.0, 4.0, 3.5, 0.0, 0.0, 4.0, 0.0, 3.0, 4.0, 4.0, 3.0, …\n## $ total_pr    &lt;dbl&gt; 52, 37, 46, 44, 71, 45, 37, 54, 47, 50, 55, 56, 48, 56,…\n## $ ship_sp     &lt;fct&gt; standard, firstClass, firstClass, standard, media, stan…\n## $ seller_rate &lt;int&gt; 1580, 365, 998, 7, 820, 270144, 7284, 4858, 27, 201, 48…\n## $ stock_photo &lt;fct&gt; yes, yes, no, yes, yes, yes, yes, yes, yes, no, yes, ye…\n## $ wheels      &lt;int&gt; 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2…\n## $ title       &lt;fct&gt; \"~~ Wii MARIO KART &amp; WHEEL ~ NINTENDO Wii ~ BRAND N…\n\nSie können Datendateien von verschiedenen Webseiten herunterladen, s. Abbildung 3.20.\n\n\n\n\n\nAbbildung 3.20: Download einer Datendatei (CSV-Format) von einer Webseite\n\n\nSie können auch von Ihrem Computer aus Daten in RStudio importieren. Gehen wir davon aus, dass sich die Datendatei im gleichen Ordner wie die R-Datei (.R- oder .qmd-Datei) befindet, in der Sie den Befehl zum Importieren schreiben. Dann können Sie die Datei einfach so importieren:\n\nd &lt;- read.csv(\"mariokart.csv\")\n\n\n\n\nDieses Video erklärt die Schritte des Importierens einer Datendatei von Ihrem Computer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDas Importieren von Ihrem Computer zu RStudio Cloud ist identisch zum Importieren von Ihrem Computer in RStudio Desktop. Nur dass Sie die Datendatei vorab hochladen müssen, schließlich ist RStudio Cloud in der Cloud und nicht auf Ihrem Computer. Klicken Sie dazu auf das Icon Upload im Reiter Files, s. Abbildung 3.21. Wählen Sie am besten den Ordner als Ziel, in dem sich auch die R-Datei, von der aus Sie den Befehl zum Daten importieren schreiben, befindet.\n\n\n\n\n\nAbbildung 3.21: Hochladen von Dateien zu RStudio Cloud\n\n\nEs gibt verschiedene Formate, in denen (Tabellen-)Dateien in einem Computer abgespeichert werden. Die gebräuchlichsten sind CSV und XLSX. Es gibt auch mehrere R-Befehle, um Daten in R zu importieren, z.\\(\\,\\)B. read.csv oder data_read. Praktischerweise kann der R-Befehl data_read viele verschiedene Formate automatisch einlesen, so dass wir uns nicht weiter um das Format kümmern brauchen. Der Vorteil von read.csv ist, dass Sie kein Extra-Paket installiert bzw. gestartet haben müssen.\nDie GUI (Benutzeroberfläche) von RStudio erlaubt es Ihnen auch, Daten per Klick, also ohne R-Befehle, zu importieren. Sie können über diese Maske sowohl CSV-Dateien, Excel-Dateien (XLS, XLSX) oder Daten-Dateien aus anderen Statistik-Programmen (z.\\(\\,\\)B. SPSS) importieren auf diese Weise. Zur Erinnerung: CSV-Dateien sind Textdateien, klicken Sie in dem Fall also From Text. Ich empfehle dort die Variante From Text (readr) … zu wählen. In der sich öffnenden Maske können Sie unter Browse die zu importierende Datendatei auswählen. Mit Klick auf Import wird die Datei schließlich in R importiert.\nMan klicke hier, um Daten in RStudio zu importieren, Abbildung 3.22.\n\n\n\n\n\nAbbildung 3.22: Daten importieren per Klick\n\n\n\n3.7.4 Dataframes\nEine in R importierte Tabelle (mit bestimmten Eigenschaften) heißt Dataframe. Dataframes sind in der Datenanalyse von großer Bedeutung. Tabelle 2.2 ist die Tabelle mit den Mariokart-Daten; etwas präziser gesprochen ein Dataframe mit Namen mariokart. Übrigens ist Tabelle 2.2 in Normalform (Tidy-Format), vgl. Definition 2.9.\n\nDefinition 3.5 (Dataframe) Ein Dataframe (engl. data frame; auch “Tibble” genannt; von “tbl” wie Table) ist ein Datenobjekt in R zur Darstellung von Tabellen. Dataframes bestehen aus einer oder mehreren Spalten. Spalten haben einen Namen, sozusagen einen “Spaltenkopf”. Alle Spalten müssen die gleiche Länge haben; anschaulich gesprochen ist eine Tabelle (in R) rechteckig. Jede Spalte einzeln betrachtet kann als Vektor aufgefasst werden. \\(\\square\\)\n\nGeben Sie den Namen eines Dataframes ein, um sich den Inhalt anzeigen zu lassen. Beachten Sie, dass Sie die Daten auf diese Weise nur anschauen, nicht ändern können.\n\n\n\n\n\n\n\n3.7.5 Tabellen in R betrachten\nWenn Sie in R z.\\(\\,\\)B. die Tabelle mariokart in einer Excel-typischen Ansicht betrachten wollen, klicken Sie am besten auf das Tabellen-Icon im Reiter Environment, gleich neben dem Namen mariokart, s. Abbildung 3.23. Alternativ öffnet der Befehl View(mariokart) die gleiche Ansicht.\n\n\n\n\n\nAbbildung 3.23: Per Klick auf das Tabellen-Icon können Sie eine Tabellenansicht der Tabelle mariokart öffnen.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#sec-logic",
    "href": "020-R.html#sec-logic",
    "title": "3  Daten einlesen",
    "section": "\n3.8 Logikprüfung",
    "text": "3.8 Logikprüfung\n\n🧑‍🎓 Wer will schon wieder wen prüfen?!\n\nIn diesem Abschnitt schauen wir uns Logikprüfungen an: Wir lassen R prüfen, ob eine Variable einen bestimmten Wert hat oder größer/kleiner als ein Referenzwert ist. Definieren wir zuerst eine Variable, x.\n\nx &lt;- 42\n\nDann fragen wir R, ob diese Variable den Wert 42 hat.\n\nx == 42\n## [1] TRUE\n\n\n🤖 Hallo, Mensch. Ja, diese Variable hat den Wert 42.\n\nDanke, R. Möchte man mit R prüfen, ob eine Variable x einen bestimmten Wert (“Inhalt”) hat, so schreibt man: x == Wert. Man beachte das doppelte Gleichheitszeichen. Zur Prüfung auf Gleichheit muss man das doppelte Gleichheitszeichen verwenden.\n\n\n\n\n\n\nVorsicht\n\n\n\nEin beliebter Fehler ist es, bei der Prüfung auf Gleichheit, nur ein Gleichheitszeichen zu verwenden, z.\\(\\,\\)B. so: x = 73. Mit einem Gleichheitszeichen prüft man aber nicht auf Gleichheit, sondern man definiert die Variable oder bestimmt ein Funktionsargument, s. Kapitel 3.6.1.\n\n\nTabelle 3.1 gibt einen Überblick über wichtige Logikprüfungen in R. Um das Zeichen für das logische ODER, | auf einer Mac-Tastatur zu erhalten, drückt man Option+7. Bei Windows drückt man Alt Gr + &lt;.\n\n\n\nTabelle 3.1: Logische Prüfungen in R\n\n\n\n\nPrüfung.auf\nR-Syntax\n\n\n\nGleichheit\nx == Wert\n\n\nUngleichheit\nx != Wert\n\n\nGrößer als Wert\nx &gt; Wert\n\n\nGrößer oder gleich Wert\nx &gt;= Wert\n\n\nKleiner als Wert\nx &lt; Wert\n\n\nKleiner oder gleich Wert\nx &lt;= Wert",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#praxisbezug",
    "href": "020-R.html#praxisbezug",
    "title": "3  Daten einlesen",
    "section": "\n3.9 Praxisbezug",
    "text": "3.9 Praxisbezug\n\n🧑‍🎓 R in der Praxis wirklich genutzt? Oder ist R nur der Traum von (vielleicht verwirrten) Profs im Elfenbeinturm?\n\nSchauen wir uns dazu die Suchanfragen bei www.stackoverflow.com an, dem größten FAQ-Forum für Software-Entwicklung. Wir vergleichen Suchanfragen mit dem Tag [r] zu Suchanfragen mit dem Tag [spss] (SPSS ist eine an Hochschulen verbreitete Statistik-Software). Die Ergebnisse sind in Abbildung Abbildung 3.24 dargestellt.7 Das ist grob gerechnet ein Faktor von 200 (der Unterschied von R zu SPSS). Dieses Ergebnis lässt darauf schließen, dass R in der Praxis viel mehr als SPSS gebraucht wird.\n\n\n\n\n\n\n\nAbbildung 3.24: Suchanfragen nach R bzw SPSS, Stand 2022-02-24\n\n\n\n\n\n🧑‍🎓 Aber ist R wirklich ein Werkzeug, das mir im Job hilft?\n\n\n🧑‍🏫 Viele Firmen weltweit nutzen R zur Datenanalyse.8\n\n\n👩‍🎓 R ist der Place-to-be für die Datenanalyse.\n\n\n🧑‍🎓 Aber ist Datenanalyse wirklich etwas, womit ich in Zukunft einen guten Job bekomme?\n\n\n🧑‍🏫 Berufe mit Bezug zu Daten, Datenanalyse oder, allgemeiner, Künstlicher Intelligenz (artificial intelligence) gehören zu den stark wachsenden Berufen (Berger, 2019.)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#aufgaben",
    "href": "020-R.html#aufgaben",
    "title": "3  Daten einlesen",
    "section": "\n3.10 Aufgaben",
    "text": "3.10 Aufgaben\n\nÜbungsaufgabe 3.2 (Statistik-Meme) Suchen Sie ein schönes Meme zum Thema Statistik, Datenanalyse und Data Science. \\(\\square\\)\n\n\nÜbungsaufgabe 3.3 (R-Quiz)  \n\n\n\nIhre R-Muskeln sind gestählt? 💪 Oder noch nicht so ganz? 😤 Macht nichts! Trainieren Sie sich mit dem R-Quiz auf der Datenwerk-Webseite! \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nTyp-Fehler-R-01\nTyp-Fehler-R-02\nTyp-Fehler-R-03\nTyp-Fehler-R-04\nTyp-Fehler-R-06a\nTyp-Fehler-R-07\nTyp-Fehler-R-08-name-clash\nLogikpruefung1\nLogikpruefung2\nthere-is-no-package\nWertberechnen2\nWertzuweisen_mc\nargumente\nimport-mtcars\nWertzuweisen\nWertpruefen\nwrangle1\nrepro1-sessioninfo\nmw-berechnen\n\nNoch nicht genug? Checken Sie alle Aufgaben mit dem Tag R auf dem Datenwerk aus.9\n\n\n\n\n\n\nHinweis\n\n\n\nDie Webseite Datenwerk stellt eine Reihe von Aufgaben zum Thema Statistik bereit. \\(\\square\\)\n\n\nJeder Aufgabe sind im Datenwerk ein oder mehrere Schlagwörter (Tags) zugeordnet. Wenn Sie auf ein Schlagwort klicken, sehen Sie die Liste der Aufgaben mit diesem Schlagwort. Es kann aber sein, dass Sie einige Aufgabe nicht lösen können, da Wissen vorausgesetzt wird, das Sie (noch) nicht haben. Lassen Sie sich davon nicht ins Boxhorn jagen. Ignorieren Sie solche Aufgaben fürs Erste.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#vertiefung",
    "href": "020-R.html#vertiefung",
    "title": "3  Daten einlesen",
    "section": "\n3.11 Vertiefung",
    "text": "3.11 Vertiefung\n\n3.11.1 Alternativen zu read.csv\n\nEine weitere Möglichkeit, um Daten von einem Ordner (egal ob dieser sich im Internet oder auf Ihrem Computer befindet) einzulesen, stellt die Funktion data_read bereit:\n\nlibrary(easystats)  # Das Paket muss installiert sein\nd &lt;- data_read(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nDer Unterschied ist, dass data_read eine Vielzahl an Formaten von Daten (XLSX, CSV, SPSS, …) verkraftet, wohingegen read.csv nur Standard-CSV einlesen kann.\nSchauen wir uns die letzte R-Syntax im Detail an:\nHey R,\nhol das \"Buch\" easystats aus der Bücherei und lies es\ndefiniere als \"d\" die Tabelle,\ndie du unter der angegebenen URL findest.\nIn R gibt es oft viele Möglichkeiten, ein Ziel zu erreichen. Zum Beispiel haben wir hier den Befehl data_read verwendet, um Daten zu importieren. Andere, gebräuchliche Befehle, die CSV-Dateien importieren, heißen read.csv (aus dem Standard-R, kein Extra-Paket nötig) und read_csv (aus dem Meta-Paket tidyverse).\n\n3.11.2 Importieren von Excel-Tabellen\nMit der Funktion data_read aus easystats kann man viele verschiedene Datenformate importieren, auch Excel-Tabellen (.xls, .xlsx).\nAls Beispiel betrachten wir den Datensatz extra aus dem R-Paket pradadata10. In diesem Datensatz werden die Ergebnisse einer Umfrage zu den Korrelaten von Extraversion beschrieben. Details zu der zugrunde liegenden Studie finden Sie hier: https://osf.io/4kgzh.11 Laden Sie die Excel-Datei herunter. Angenommen, Sie speichern die Excel-Datei in einem Unterordner namens daten Ihres aktuellen Projektordners. Dann können Sie die Daten so importieren:\n\nlibrary(easystats)\nextra &lt;- data_read(\"data/extra.xls\")\n\n Download XLS   Download CSV \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCSV-Dateien werden auf vielen Computern als eine Datei erkannt, die Excel öffnen kann und das auch tut, wenn man eine CSV-Datei doppelklickt. Dennoch ist das CSV-Format keine Datei im Excel-Format, sondern eine einfache Text-Datei, die auch mit jedem Text-Editor geöffnet und bearbeitet werden kann. Alternativ können Sie in RStudio auch Excel-Dateien ohne R-Code importieren.\n\n3.11.3 Der Dollar-Operator\nIn Definition 3.4 hatten wir Vektoren definiert. Solche Vektoren fliegen sozusagen frei in Ihrem Environment herum (Schauen Sie mal dort nach!) Die Spalten einer Tabelle sind aber auch Vektoren, nur eben nicht frei im Environment, sondern in eine Tabelle eingebunden. Möchte man diese Vektoren direkt ansprechen, so kann man das mit dem sog. Dollar-Operator $ tun. Angenommen, Sie möchten sich die Verkaufspreise (total_pr) aus der Tabelle mariokart herausziehen, dann können Sie das mit dem Dollar-Operator tun:\n\nmariokart$total_pr |&gt; head()  # nur die ersten paar Werte zeigen\n## [1] 52 37 46 44 71 45\n\nDer Dollar-Operator trennt den Namen der Tabelle vom Namen der Spalte. Natürlich können Sie mit dem resultierenden Vektor beliebig weiterarbeiten, etwa ihn in einem anderen Vektor speichern oder eine Funktion anwenden:\n\nverkaufspreise &lt;- mariokart$total_pr\nmean(verkaufspreise)\nmean(mariokart$total_pr)  # synonym zur obigen Zeile\n## [1] 50\n## [1] 50\n\n\n3.11.4 R-Zertifikat bei LinkedIn\nSie können bei LinkedIn12 (oder anderen Anbietern) ein Zertifikat erhalten, das Ihre R-Kenntnisse dokumentiert.\n\n3.11.5 R-Funktionen verschachteln\nDas Kombinieren von Funktionen kann kompliziert werden:\n\n\n\nListing 3.3: Verschachtelte Funktionen\n\nx &lt;- c(1, 2, 3)\nsum(abs(mean(x)-x)) \n## [1] 2\n\n\n\n\nDie Funktion abs(x) gibt den (Absolut-)Betrag von x zurück (entfernt das Vorzeichen).\nVerschachtelte Ausdrücke lesen sich von innen nach außen (und werden in dieser Reihenfolge abgearbeitet). Für unser Beispiel (Listing 4.2):\n\nBerechne den Mittelwert von x\n\nZiehe vom Mittelwert jeweils die Elemente von x ab\nNimm vom Ergebnis jeweils den Absolutwert\nSummiere diese Werte\n\nKurz gesagt: Hier haben wir die mittlere Absolutabweichung der Elemente von x zum Mittelwert ausgerechnet.\n\n3.11.6 R und Friends updaten\nIrgendwann werden wir mit unsere Version von R und RStudio veraltet sein. Installieren Sie dann einfach die neue Version von R und RStudio wie oben beschrieben, s. Kapitel 3.3.\nSo updaten Sie Ihre R-Pakete: Klicken Sie im Reiter Packages (in RStudio) auf Update. Wenn die Anzahl der zu aktualisierenden Pakete groß ist, dann besser nicht alle auswählen, sondern nur ein paar. Dann die nächsten paar Pakete usw. Denken Sie daran, dass Sie die Software (R, RStudio, R-Paket), die Sie updaten/installieren, nicht gerade laufen darf.\nIhre R-Pakete sollten aktuell sein. Klicken Sie beim Reiter Packages auf “Update”, um Ihre R-Pakete zu aktualisieren. Arnold Schwarzenegger rät, Ihre R-Pakete aktuell zu halten, s. Abbildung 3.25.\n\n\n\n\n\nAbbildung 3.25: R-Pakete sollten stets aktuell sein, so Arnold Schwarzenegger (imgflip, 2024b)\n\n\n\n3.11.7 Benötigte Daten\nSie benötigen in den meisten Kapiteln dieses Buches den Datensatz mariokart, der entweder online13 oder über R-Paket openintro importiert werden kann.\nImport via Download:\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nImport via R-Paket:\n\n# Das Paket 'openintro' muss installiert sein:\ndata(mariokart, package = \"openintro\")",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#literaturhinweise",
    "href": "020-R.html#literaturhinweise",
    "title": "3  Daten einlesen",
    "section": "\n3.12 Literaturhinweise",
    "text": "3.12 Literaturhinweise\n“Warum R? Warum, R?” heißt ein Kapitel in Sauer (2019), das einiges zum Pro und Contra von R ausführt. Kapitel 3 in derselben Quelle enthält Hinweise zum Starten von R. Kapitel 4 erläutert die Grundlagen von “Errisch”. Kapitel 5 führt in die Datenstrukturen von R ein (etwas anspruchsvoller als in diesem Kapitel). Alternativ bietet Kapitel 1 von Ismay & Kim (2020) einen guten und anwenderfreundlichen Überblick. Das Buch hat auch den Vorteil, dass es komplett frei online verfügbar ist. Vergleichbar dazu ist Çetinkaya-Runde & Hardin (2021), vielleicht einen Tick formaler; auf jeden Fall genau das richtige Niveau für Bachelor-Statistik in angewandten nicht-technischen Studiengängen.\n\n\n\n\n\nBerger, G. (2019, Dezember 10). The Jobs of Tomorrow: LinkedIn’s 2020 Emerging Jobs Report. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nHornik, K., Ligges, U., & Zeileis, A. (2023). Changes on CRAN. The R Journal, 15, 295–296.\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024a). Imageflip Bill Gates Meme [Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical Inference via Data Science: A ModernDive into R and the Tidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nLüdecke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., Thériault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A. (2020). Analysis of Open Data and Computational Reproducibility in Registered Reports in Psychology. Advances in Methods and Practices in Psychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability: A Brief History of a Confused Terminology. Frontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nR Core Team. (2024). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "020-R.html#footnotes",
    "href": "020-R.html#footnotes",
    "title": "3  Daten einlesen",
    "section": "",
    "text": "https://posit.co/download/rstudio-desktop/↩︎\nhttps://quarto.org/↩︎\n🤖 Naja, manchmal.↩︎\nhttps://www.rdocumentation.org/↩︎\nAuf dieser Webseite https://vincentarelbundock.github.io/Rdatasets/articles/data.html finden Sie den Datensatz mariokart sowie eine große Zahl an weiteren Datensätzen. Nur für den Fall, dass Ihnen langweilig ist.↩︎\nhttps://vincentarelbundock.github.io/Rdatasets/doc/openintro/mariokart.html↩︎\nDie Daten wurden am 2022-02-24, 17:21 CET, abgerufen.↩︎\nwie diese Liste zeigt: https://www.quora.com/Which-organizations-use-R?share=1 zeigt↩︎\nhttps://sebastiansauer.github.io/Datenwerk/#category=R↩︎\nhttps://github.com/sebastiansauer/pradadata↩︎\nEin Daten-Dictionary findet sich hier: https://github.com/sebastiansauer/statistik1/raw/main/data/extra-dictionary.md.↩︎\nhttps://www.linkedin.com/help/linkedin/answer/a510481↩︎\n über diese Internetadresse: https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Daten einlesen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html",
    "href": "030-aufbereiten.html",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "4.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#einstieg",
    "href": "030-aufbereiten.html#einstieg",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "4.1.1 Lernziele\n\nSie können folgende Verben des Datenjudo anwenden: arrange, filter, select, summarise, group_by, mutate.\nSie können R-Befehle mit der “Pfeife” verketten.\n\n\nÜbungsaufgabe 4.1 (Mariokart importieren) Importieren Sie den Datensatz mariokart, s. Kapitel 3.7.3. Probieren Sie alle in diesem Kapitel vorgestellten Verben des Datenjudos aus, zunächst, indem Sie einfach den R-Code kopieren und selber ausführen. Danach überlegen Sie sich Varianten. \\(\\square\\)\n\n\n4.1.2 R-Code zum Copy-Pasten\nSie finden den R-Code für jedes Kapitel hier. \\(\\square\\)\n\n4.1.3 Frag den Bot\n\n🧑‍🎓 Erkläre einem Fünfjährigen, warum Statistik nützlich ist.\n\n\n🤖 Okay, hör zu. Stell dir vor, du hast viele Spielzeugautos und du willst herausfinden, welches Auto am meisten bespielt wird. Du kannst jeden Tag zählen, wie oft du jedes Auto benutzt hast. Aber das wäre sehr mühsam und könnte schnell durcheinander gebracht werden. Stattdessen kannst du mit Statistik eine einfachere Methode finden. Du kannst zum Beispiel eine Liste machen und jedes Auto mit einer bestimmten Farbe markieren. Dann kannst du jeden Tag einfach zählen, wie oft du jede Farbe verwendet hast. Am Ende kannst du herausfinden, welches Auto am meisten bespielt wurde, indem du siehst, welche Farbe am meisten verwendet wurde. Das ist ein Beispiel dafür, wie Statistik uns dabei helfen kann, Muster in großen Datensätzen zu finden und Entscheidungen zu treffen, ohne alles einzeln zu zählen.1\n\n\n4.1.4 Quiz zum Einstieg\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwa mittels der Plattform antworte.jetzt. Alternativ überlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\nDefinition 4.1 (Datenjudo) Mit Datenjudo meint man den Prozess der Aufbereitens, Umformens oder Zusammenfassen von Daten, sowohl für einzelne Beobachtungen (Zeilen einer Datentabelle) oder Variablen (Spalten einer Datentabelle) oder einer ganzen Datentabelle. \\(\\square\\)\n\n\n4.1.5 Praxisbezug: Aus dem Alltag des Datenwissenschaftlers\nDenkt man an Data Science, stellt man sich coole Leute vor (in San Francisco oder Berlin), die an abgefahrenen Berechnungen mit hoch komplexen statistischen Modellen für gigantische Datenmengen basteln. Laut dem Harvard Business Review, verbringen Data Scientisten allerdings “80\\(\\,\\)%” ihrer Zeit mit dem Aufbereiten von Daten (Bowne-Anderson, 2018). Ja: mit uncoolen Tätigkeiten wie Tippfehler aus Datensätzen entfernen oder die Daten überhaupt nutzbar und verständlich zu machen.\nDas zeigt zumindest, dass das Aufbereiten von Daten a) wichtig ist und b) dass man allein damit schon weit kommen kann. Eine gute Nachricht ist (vielleicht), dass das Aufbereiten von Daten keine aufwändige Mathematik verlangt, stattdessen muss man ein paar Handgriffe und Kniffe kennen. Daher passt der Begriff Datenjudo vielleicht ganz gut. Kümmern wir uns also um das Aufbereiten bzw. Umformen von Daten, um das Datenjudo. 🔢🤹 \\(\\square\\)\n\nBeispiel 4.1 (Beispiel für Datenjudo) Beispiele für typische Tätigkeiten des Datenjudos sind:\n\nZeilen filtern (z.\\(\\,\\)B. nur Studierenden des Studiengangs X)\nZeilen sortieren (z.\\(\\,\\)B. Studierenden mit guten Noten in den oberen Zeilen)\nSpalten wählen (z.\\(\\,\\)B. 100 langweilige Spalten ausblenden)\nSpalten in eine Zahl zusammenfassen (z.\\(\\,\\)B. Notenschnitt der 1. Klausur)\nTabelle gruppieren (z.\\(\\,\\)B. Analyse getrennt nach Standorten)\nWerte aus einer Spalte verändern oder neue Spalte bilden (z.\\(\\,\\)B. Punkte in Prozent-Richtige umrechnen).\n… \\(\\square\\)\n\n\n\n\n4.1.6 Mach’s einfach\nKlingt fast zu schön, um wahr zu sein (s. Abbildung 4.1).\n\n\n\n\n\nAbbildung 4.1: Mach’s einfach (imgflip, 2024a)\n\n\nEs gibt einen (einfachen) Trick, wie man umfangreiche Datenaufbereitung elegant geregelt kriegt. Der Trick besteht darin, komplexe Operationen in mehrere einfache Teilschritte zu zergliedern. (In gewisser Weise besteht das Wesen einer Analyse eben darin: die Zerlegung eines Gegenstands in seine Bestandteile.) Man könnte vom “Lego-Prinzip” sprechen, s. Abbildung 4.2. Im linken Teil von Abbildung 4.2 sieht man ein (recht) komplexes Gebilde. Zerlegt man es aber in seine Einzelteile, so sind es deutlich einfachere geometrische Objekte wie Dreiecke oder Kreise (rechter Teil des Diagramms). Damit Sie es selber einfach machen können, müssen Sie selber Hand anlegen. Importieren Sie daher den Datensatz mariokart, s. Kapitel 3.7.3.\n\n\n\n\n\nAbbildung 4.2: Das Lego-Prinzip (Sauer, 2019)\n\n\nWerfen wir einen Blick hinein (to glimpse):\n\nglimpse(mariokart)\n\n\nBeispiel 4.2 (Der Datenguru in Aktion) Sie arbeiten immer noch bei dem großen Online-Auktionshaus. Mittlerweile haben Sie sich den Ruf des “Datenguru” erworben. Vielleicht, weil Sie behauptet haben, Data Science sei zu 80% Datenjudo, das hat irgendwie Eindruck geschindet … Naja, jedenfalls müssen Sie jetzt mal zeigen, dass Sie nicht nur schlaue Sprüche draufhaben, sondern auch die Daten ordentlich abbürsten können. Sie analysieren dafür im Folgenden den Datensatz mariokart. Na, dann los. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#die-verben-des-datenjudos",
    "href": "030-aufbereiten.html#die-verben-des-datenjudos",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.2 Die Verben des Datenjudos",
    "text": "4.2 Die Verben des Datenjudos\nIm R-Paket dplyr, das wiederum Teil des R-Pakets tidyverse ist, gibt es eine Reihe von R-Befehlen, die das Datenjudo in eine Handvoll einfacher Verben herunterbrechen. (Falls Sie das R-Paket tidyverse noch nicht installiert haben sollten, wäre jetzt ein guter Zeitpunkt dafür.) Die wichtigsten Verben des Datenjudos schauen wir uns im Folgenden an. Wir betrachten dazu im Folgenden einen einfachen (Spielzeug-)Datensatz, an dem wir zunächst die Verben des Datenjudos vorstellen, s. Tabelle 4.1.\n\n\n\nTabelle 4.1: Ein einfacher Datensatz von schlichtem Gemüt\n\n\n\n\nid\nname\ngruppe\nnote\n\n\n\n1\nAnni\nA\n2.7\n\n\n2\nBerti\nA\n2.7\n\n\n3\nCharli\nB\n1.7\n\n\n\n\n\n\n\n\nDie Verben des Datenjudos wohnen im Paket dplyr, welches gestartet wird, wenn Sie library(tidyverse) eingeben. Falls Sie vergessen, das Paket tidyverse zu starten, dann funktionieren diese Befehle nicht.\n\n\n\n\n4.2.1 Tabelle sortieren: arrange\n\nSortieren der Zeilen ist eine einfache, aber häufige Tätigkeit des Datenjudos, s. Abbildung 4.3.\n\n\n\n\n\n\n\nAbbildung 4.3: Sinnbild für das Sortieren einer Tabelle mit arrange: Hier wurden die Noten aufsteigend sortiert.\n\n\n\n\n\nBeispiel 4.3 (Was sind die höchsten Preise?) Sie wollen mal locker anfangen. Daher stellen Sie sich folgende Frage: Was sind denn eigentlich die höchsten Preise, für die das Spiel Mariokart über den Online-Ladentisch geht? Die Spalte für den Verkaufsprei heißt offenbar total_pr (s. Datensatz mariokart). In Excel kann die Spalte, nach der man die Tabelle sortieren möchte, einfach anklicken. Ob das in R auch so einfach geht?\nDie Funktion arrange macht es uns ziemlich einfach, s. Tabelle 4.2.\n\narrange(mariokart, total_pr)\n\n\nTabelle 4.2: Die Datentabelle, (aufsteigend) sortiert nach total_pr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n2.6e+11\n1\n17\nused\n0.99\n0\n29\nstandard\n4982\nyes\n0\n\n\n1.2e+11\n1\n12\nused\n0.01\n0\n30\nstandard\n7284\nyes\n0\n\n\n2.6e+11\n1\n7\nused\n0.99\n0\n31\nstandard\n4982\nyes\n0\n\n\n3.2e+11\n7\n14\nused\n1.99\n0\n31\nmedia\n166\nyes\n0\n\n\n1.8e+11\n10\n3\nused\n30.00\n0\n31\npriority\n19\nno\n0\n\n\n1.1e+11\n1\n16\nused\n0.01\n0\n31\nstandard\n7284\nyes\n0\n\n\n\n\n\n\n\n\nÜbersetzen wir die R-Syntax ins Deutsche:\nHey R,\narrangiere (sortiere) `mariokart` \nnach der Spalte `total_pr` (aufsteigend).\nGar nicht so schwer. \\(\\square\\)\n\nÜbrigens wird in arrange per Voreinstellung aufsteigend sortiert. Setzt man ein Minus vor der zu sortierenden Spalte, wird umgekehrt, also absteigend sortiert:\n\nmario_sortiert &lt;- arrange(mariokart, -total_pr)\n\n\nÜbungsaufgabe 4.2 Sortieren Sie die Mariokart-Daten absteigend nach der Anzahl der beigelegten Lenkräder. \\(\\square\\)\n\n\n4.2.2 Zeilen filtern: filter\n\nZeilen filtern bedeutet, dass man nur bestimmte Zeilen (Beobachtungen) behalten möchte, die restlichen Zeilen brauchen wir nicht, weg mit ihnen. Wir haben also ein Filterkriterium im Kopf, anhand dessen wir die Tabelle filern, s. Abbildung 4.4.\n\n\n\n\n\n\n\nAbbildung 4.4: Sinnbild für das Filtern einer Tabelle mit filter: Gruppe B wurde entfernt, also wurde nach Gruppe A gefiltert.\n\n\n\n\n\nBeispiel 4.4 (Ob ein Foto für den Verkaufspreis nützlich ist?) Als nächstes kommt Ihnen die Idee, mal zu schauen, ob Auktionen mit “Stock-Photo” Ware einen höheren Verkaufspreis erzielen als Auktionen ohne solche Totos.\n\nmariokart_neu &lt;- filter(mariokart, stock_photo == \"yes\")\n\n\nmariokart_neu \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4\n52\nstandard\n1580\nyes\n1\n\n\n2.6e+11\n7\n13\nused\n0.99\n4\n37\nfirstClass\n365\nyes\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4\n45\nstandard\n270144\nyes\n0\n\n\n1.2e+11\n1\n13\nused\n0.01\n0\n37\nstandard\n7284\nyes\n0\n\n\n\n\n\nSie filtern also die Tabelle so, dass nur diese Auktionen im Datensatz verbleiben, welche mind. ein Foto haben, mit anderen Worten, Auktionen (Beobachtungen) bei denen gilt: stock_photo == TRUE. \\(\\square\\)\n\nAngestachelt von Ihren Erfolgen möchten Sie jetzt komplexere Hypothesen prüfen: Erzielen Auktionen von neuen Spielen und zwar mit Foto einen höheren Preis als die übrigen Auktionen? Anders gesagt haben Sie zwei Filterkriterien im Blick: Neuheit cond und Foto stock_photo. Nur diejenigen Auktionen, die sowohl Neuheit als auch Foto erfüllen, möchten Sie näher untersuchen (Filtern mit dem logischen UND):\n\nmario_filter1 &lt;- \n  filter(mariokart,  # \"&\" heißt UND:\n         stock_photo == \"yes\" & cond == \"new\")\n\n\nmario_filter1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4\n52\nstandard\n1580\nyes\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4\n45\nstandard\n270144\nyes\n0\n\n\n3.0e+11\n1\n15\nnew\n1.00\n3\n54\nupsGround\n4858\nyes\n2\n\n\n2.9e+11\n1\n15\nnew\n1.00\n3\n55\nupsGround\n4858\nyes\n2\n\n\n\n\n\nHm. Was ist mit den Auktionen, die entweder über (mind.) ein Foto verfügen oder auch neu sind, oder beides (Filtern mit dem logischen ODER)?\n\nmario_filter2 &lt;- \n  filter(mariokart,  # \"|\" heißt ODER:\n         stock_photo == \"yes\" | cond == \"new\")\n\n\nmario_filter2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nduration\nn_bids\ncond\nstart_pr\nship_pr\ntotal_pr\nship_sp\nseller_rate\nstock_photo\nwheels\n\n\n\n1.5e+11\n3\n20\nnew\n0.99\n4.0\n52\nstandard\n1580\nyes\n1\n\n\n2.6e+11\n7\n13\nused\n0.99\n4.0\n37\nfirstClass\n365\nyes\n1\n\n\n3.2e+11\n3\n16\nnew\n0.99\n3.5\n46\nfirstClass\n998\nno\n1\n\n\n2.8e+11\n3\n18\nnew\n0.99\n0.0\n44\nstandard\n7\nyes\n1\n\n\n1.7e+11\n1\n20\nnew\n0.01\n0.0\n71\nmedia\n820\nyes\n2\n\n\n3.6e+11\n3\n19\nnew\n0.99\n4.0\n45\nstandard\n270144\nyes\n0\n\n\n\n\n\nZur Erinnerung: Logische Operatoren sind in Kapitel 3.8 erläutert.\n\nÜbungsaufgabe 4.3 Hier könnte man noch viele interessante Hypothesen prüfen, denken Sie sich und tun das auch. \\(\\square\\)\n\n\nÜbungsaufgabe 4.4 Filtern Sie die Spiele mit nur einem Lenkrad und ohne Versandkosten. \\(\\square\\)\n\n\nÜbungsaufgabe 4.5 Filtern Sie die Spiele mit nur einem Lenkrad, die einen überdurchschnittlichen Verkaufspreis erzielen. Tipp: Nutzen Sie die Funktion describe_distribution, um den Mittelwert einer Variable des Datensatzes zu erfahren (diese Funktion wohnt im R-Paket easystats). \\(\\square\\)\n\n\n4.2.3 Spalten auswählen mit select\n\nEine Tabelle mit vielen Spalten kann schnell unübersichtlich werden. Da lohnt es sich, eine goldene Regel zu beachten: Mache die Dinge so einfach wie möglich, aber nicht einfacher. Wählen wir also nur die Spalten aus, die uns interessieren und entfernen wir die restlichen, s. Abbildung 4.5 als Beispiel.\n\n\n\n\n\n\n\nAbbildung 4.5: Sinnbild für das Auswählen von Spalten mit select\n\n\n\n\n\nBeispiel 4.5 (Fokus auf nur zwei Spalten) Ob wohl gebrauchte Spiele deutlich geringere Preise erzielen im Vergleich zu neuwertigen Spielen? Sie entschließen sich, mal ein Stündchen auf die relevanten Daten zu starren. Dafür wählen Sie mit select die relevanten Spalten aus. \\(\\square\\)\n\n\nmario_select1 &lt;- select(mariokart, cond, total_pr)\n\nDer Befehl select erwartet als Input eine Tabelle und gibt (als Output) eine Tabelle zurück – genau wie die meisten anderen Befehle des Datenjudos. Auch wenn Sie nur eine Spalte auswählen, bleibt es eine Tabelle, eben eine Tabelle mit nur einer Spalte.\nselect erlaubt Komfort; Sie können Spalten auf mehrere Arten auswählen:\n\nselect(mariokart, 1, 2)  # Spalten 1 und 2\nselect(mariokart, 2:5)  #  Spalten 2 *bis* 5 \nselect(mariokart, -1)  # Alle Spalte *außer* Spalte 1\n\n\nÜbungsaufgabe 4.6 Wählen Sie die Spalten total_pr, cond sowie die zweite Spalte der Tabelle mariokart aus!2 \\(\\square\\)\n\nVertiefte Informationen zum Auswählen von Spalten mit select finden sich auf der Hilfeseite der Funktion.3\n\n4.2.4 Spalten zu einer Zahl zusammenfassen mit summarise\n\n\nBeispiel 4.6 (Was ist der mittlere Verkaufspreis?) Mit summarise, s. Listing 4.1, können wir den mittleren Verkaufspreis der Mariokart-Spiele berechnen (50). \\(\\square\\)\n\nSo eine lange Spalte mit Zahlen – mal ehrlich: Wer blickt da schon durch? Machen wir uns das Leben leichter, indem wir eine lange Spalte mit Zahlen zu einer einzigen Zahl zusammenfassen. Sagen wir, drei Studierende – Anni, Berti, Charli – haben eine Statistikklausur geschrieben. Die Noten waren 2.7, 2.7 und 1.7. Damit lag der Notenschnitt (der Mittelwert) bei 2.4; s. Abbildung 4.6.\n\n\n\n\n\n\n\nAbbildung 4.6: Spalten zu einer einzelnen Zahl zusammenfassen mit summarise: Hier wurden die Noten anhand des Mittelwerts zusammengefasst.\n\n\n\n\nFassen wir als Nächstes die Spalte total_pr zu einer Zahl zusammen, und zwar zum Mittelwert. Dann wissen wir, für welchen Preis ein Spiel im Durchschnitt verkauft wird, s. Listing 4.1.\n\n\n\nListing 4.1: Die R-Funktion summarise fasst einen Vektor zu einer einzelnen Zahl zusammen.\n\nmariokart_mittelwert &lt;- summarise(mariokart,\n                                  preis_mw = mean(total_pr))\nmariokart_mittelwert\n\n\n\n\n\n\npreis_mw\n\n\n50\n\n\n\n\nAha! Etwa 50 Dollar erzielte so eine Auktion im Durchschnitt. Ein bisschen abstrakter gesprochen fasst summarise eine Spalte zu einer (einzelnen) Zahl zusammen, s. Listing 4.1.\nEine Alternative, um eine Spalte zu einer Zahl zusammenzufassen, bietet der “Dollar-Operator” ($): mean(mariokart$total_pr). Der Dollar-Operator trennt hier die Tabelle von der Spalte: tibble$spalte. Im Gegensatz zu den Verben des Tidyverse (die immer einer Tabelle zurückliefern), liefert der Dollar-Operator einen Vektor (Spalte) zurück. (Diese wird von mean dann zu einer einzelnen Zahl zusammengefasst.)\nAuf welche Art zusammengefasst werden soll, z.\\(\\,\\)B. anhand des Mittelwerts oder Maximalwerts, muss noch zusätzlich innerhalb von summarise angegeben werden.\n\n\nÜbungsaufgabe 4.7 Identifizieren Sie den höchsten Kaufpreis eines Mariokart-Spiels!4 \\(\\square\\)\n\n\nÜbungsaufgabe 4.8 Identifizieren Sie den Mittelwert der Versandkostenpauschale!5 \\(\\square\\)\n\n\n4.2.5 Tabelle gruppieren\nEs ist ja gut und schön, zu wissen, was so ein Spiel im Schnitt kostet. Aber viel interessanter wäre es doch, denken Sie sich, zu wissen, ob die neuen Spiele im Schnitt mehr kosten als die alten? Ob R Ihnen so etwas ausrechnen kann?\n\n🧑‍🎓 Hallo R, kannst du mir die mittleren Verkaufspreise von alten und neuen Spielen ausrechnen?\n\n\n🤖 Ich tue fast alles für dich. 🧡\n\nAlso gut, R, dann gruppiere die Tabelle, s. Abbildung 4.7.\n\n\n\n\n\n\n\nAbbildung 4.7: Gruppieren von Datensätzen mit group_by: Hier wurde anhand der Variable gruppe gruppiert.\n\n\n\n\nDurch das Gruppieren wird die Tabelle in “Teiltabellen” – entsprechend der Gruppen – aufgeteilt. Das sieht man der R-Tabelle aber nicht wirklich an. Aber alle nachfolgenden Berechnungen werden für jede Teiltabelle einzeln ausgeführt.\n\nBeispiel 4.7 (Mittlerer Preis pro Gruppe) Gruppieren alleine liefert Ihnen zwei (oder mehrere) Teiltabellen, etwa neue Spiele (Gruppe 1, new) vs. gebrauchte Spiele (Gruppe 2, used). Mit anderen Worten: Wir gruppieren anhand der Variable cond.\n\nmariokart_gruppiert &lt;- group_by(mariokart, cond)\n\nWenn Sie die neue Tabelle betrachte, sehen Sie wenig Aufregendes, nur einen Hinweis, dass die Tabelle gruppiert ist. Jetzt können Sie an jeder Teiltabelle Ihre weiteren Berechnungen vornehmen, etwa die Berechnung des mittleren Verkaufspreises.\n\nsummarise(mariokart_gruppiert, preis_mw = mean(total_pr))\n\n\n\ncond\npreis_mw\n\n\n\nnew\n54\n\n\nused\n47\n\n\n\n\n\nAh, die neuen Spiele sind teuerer, wer hätt’s gedacht! Langsam fühlen Sie sich wie ein Datenchecker … 🥷 🦹‍♀\\(\\square\\)\n\n\nÜbungsaufgabe 4.9  \n\n\nAufgabe\nLösung\n\n\n\nBerechnen Sie den mittleren und maximalen Verkaufspreis getrennt für Spiele mit und ohne Foto!\n\n\n\nmariokart_gruppiert_foto &lt;- group_by(mariokart, stock_photo)\n\nmariokart_verkaufspreis_foto &lt;- \n  summarise(mariokart_gruppiert_foto,\n            total_pr_avg = mean(total_pr),\n            total_pr_max = max(total_pr))\n\nmariokart_verkaufspreis_foto\n\n\n\nstock_photo\ntotal_pr_avg\ntotal_pr_max\n\n\n\nno\n54\n327\n\n\nyes\n48\n75\n\n\n\n\n\n\n\n\nBei Auktionen mit Foto wird im Schnitt ein höherer Preis erzielt als ohne Foto. \\(\\square\\)\n\n\n4.2.6 Spalten verändern mit mutate\n\nImmer mal wieder möchte man Spalten verändern, bzw. deren Werte umrechnen, s. Abbildung 4.8.\n\n\n\n\n\n\n\nAbbildung 4.8: Spalten verändern/neu berechnen mit mutate\n\n\n\n\n\nBeispiel 4.8 Der Hersteller des Computerspiels Mariokart kommt aus Japan; daher erscheint es Ihnen opportun für ein anstehendes Meeting mit dem Hersteller die Verkaufspreise von Dollar in japanische Yen umzurechnen. Nach etwas Googeln finden Sie einen Umrechnungskurs von 1:133.\n\nmariokart_yen &lt;- \n  mutate(mariokart, total_pr_yen = total_pr * 133)\nmariokart_yen &lt;- select(mariokart_yen, total_pr_yen, total_pr)\nmariokart_yen |&gt; head()  # nur die ersten paar Zeilen\n\n\n\ntotal_pr_yen\ntotal_pr\n\n\n\n6856\n52\n\n\n4926\n37\n\n\n6052\n46\n\n\n5852\n44\n\n\n9443\n71\n\n\n5985\n45\n\n\n\n\n\nSicherlich werden Sie Ihre Gesprächspartner beeindrucken. \\(\\square\\)\n\nMit mutate berechnen Sie eine Spalte x (in einer Tabelle) neu. Die Funktion, die Sie in mutate benennen wird für jede Zeile der Spalte x angewendet.\n\nBeispiel 4.9 (Beispiele für Funktionen für mutate) mutate eignet sich, z.\\(\\,\\)B. um Spalten zu addieren, zu multiplizieren oder sonst wie zu transformieren (z.\\(\\,\\)B. den Logarithmus anwenden oder den Mittelwert der Spalte von jeder Zeile abziehen). \\(\\square\\)\n\n\nÜbungsaufgabe 4.10  \n\n\nAufgabe\nLösung\n\n\n\nRechnen Sie die Dauer der Auktionen von Tagen in Wochen um.\n\n\n\nmariokart_duration_wochen &lt;- \n  mutate(mariokart, duration_week = duration / 7)\n\nmariokart_duration_wochen &lt;-\n   select(mariokart_duration_wochen, duration, duration_week)\nmariokart_duration_wochen |&gt; head()  # nur die ersten paar Zeilen\n\n\n\nduration\nduration_week\n\n\n\n3\n0.43\n\n\n7\n1.00\n\n\n3\n0.43\n\n\n3\n0.43\n\n\n1\n0.14\n\n\n3\n0.43\n\n\n\n\n\n\n\n\n\n\nÜbungsaufgabe 4.11  \n\n\nAufgabe\nLösung\n\n\n\nRechnen Sie wieder die Dauer der Auktionen von Tagen in Wochen um, aber runden Sie die Wochen auf ganze Wochen.\n\n\n\nmariokart_duration_wochen &lt;- \n  mutate(mariokart, duration_week = duration / 7)\n\nmariokart_duration_wochen_gerundet &lt;-\n  mutate(mariokart_duration_wochen, duration_week_gerundet =\n           round(duration_week, digits = 0))\n\nmariokart_duration_wochen_schmal &lt;-\n  select(mariokart_duration_wochen_gerundet, duration, \n         duration_week, duration_week_gerundet)\nmariokart_duration_wochen_schmal |&gt; head()\n\n\n\nduration\nduration_week\nduration_week_gerundet\n\n\n\n3\n0.43\n0\n\n\n7\n1.00\n1\n\n\n3\n0.43\n0\n\n\n3\n0.43\n0\n\n\n1\n0.14\n0\n\n\n3\n0.43\n0\n\n\n\n\n\n\n\n\n\n\n🧟‍♀️️ Statist – wann braucht man schon sowas!?\n\n\n🤖 Eigentlich nur dann, wenn man die Fakten gut verstehen will, sonst nicht.\n\n\n4.2.7 Zeilen zählen mit count\n\nArbeitet man mit nominalskalierten Daten, ist (fast) alles, was man mit den Daten tun kann, die entsprechenden Zeilen der Tabelle zu zählen: Man könnte z.\\(\\,\\)B. fragen, wie viele neue und wie viele alte Spiele in der Tabelle (Dataframe) mariokart vorhanden sind.\n\nBeispiel 4.10 Nach der letzten Präsentation Ihrer Analyse hat Ihre Chefin gestöhnt: “Oh nein, alles so kompliziert. Statistik! Himmel hilf! Kann man das nicht einfacher machen?” Anstelle von irgendwelchen komplizierten Berechnungen (Mittelwert?) möchten Sie ihr beim nächsten Treffen nur zeigen, wie viele Computerspiele neu und wie viele gebraucht sind (in Ihrem Datensatz). Schlichte Häufigkeiten also. Hoffentlich ist Ihre Chefin nicht wieder überfordert …\n\nmariocart_counted &lt;- count(mariokart, cond)\nmariocart_counted\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\nAha! Es gibt mehr gebrauchte als neue Spiele. \\(\\square\\)\n\nJetzt könnte man noch den Anteil (engl. proportion) ergänzen: Welcher Anteil (der 143 Spiele in mariokart) ist neu, welcher gebraucht?\n\nmutate(mariocart_counted, Anteil = n / sum(n))\n\n\n\ncond\nn\nAnteil\n\n\n\nnew\n59\n0.41\n\n\nused\n84\n0.59\n\n\n\n\n\n\nÜbungsaufgabe 4.12 Zählen Sie, wie viele der Auktionen ein Stock-Foto enthalten.6 \\(\\square\\)\n\n\nÜbungsaufgabe 4.13 Zählen Sie Sie, wie viele Auktionen ein Foto enthalten – innerhalb der gebrauchten Spiele und innerhalb der neuen Spiele. Anders gesagt: Teilen Sie den Datensatz sowohl nach Zustand als auch nach Foto auf und zählen Sie jeweils, wie viele Spiele/Auktionen in die jeweilige Gruppe gehören.7 \\(\\square\\)\n\n\n4.2.8 Verben am Fließband\nDie Befehle (“Verben”) des Tidyverse sind jeweils für einzelne, typische Aufgaben des Datenaufbereitens (“Datenjudo”) zuständig. Typischerweise erwarten diese Befehle eine Tabelle () als Input und liefern eine Tabelle aus Output zurück, s. Abbildung 4.9. Die Verben des Datenjudos werden beim “Tidydatatutor” anschaulich illustriert.8\n\n\n\n\n\nflowchart LR\n  A[\"▥\"] --&gt; B[tidyverse-Befehl] --&gt; C[\"▥\"] \n\n\n\n\nAbbildung 4.9: Tidyverse-Befehle erwarten normalerweise eine Tabelle (“Tibble”) als Input und geben auch eine Tabelle zurück als Output",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#sec-pipe",
    "href": "030-aufbereiten.html#sec-pipe",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.3 Die Pfeife",
    "text": "4.3 Die Pfeife\n🚬 👈Das ist keine Pfeife, wie René Magritte 1929 in seinem berühmten Bild schrieb, s. Abbildung 4.10.\n\n\n\n\n\n\n\n\n\n\n\n\n%&gt;%\n\n\n\n\n|&gt;\n\n\n\n\n\n\nAbbildung 4.10: So sieht die Pfeife in R aus (Jaja, das ist keine Pfeife, sondern ein Symbol einer Pfeife …). Links: Ein Bild einer Pfeife (M7, 2004). Mitte und Rechts: Die zwei R-Symbole für eine “Pfeife” (pipe).\n\n\n\n4.3.1 Russische Puppen\nComputerbefehle, und im Speziellen R-Befehle, kann man “aufeinander” – oder vielmehr: ineinander – stapeln, so ähnlich wie eine russische Puppe (vgl. Kapitel 3.6.3). Schauen wir uns das in einem Beispiel an. Dazu definieren wir zuerst einen Vektor x aus drei Zahlen:\n\nx &lt;- c(1, 2, 3)\n\nUnd dann kommt unser verschachtelter Befehl:\n\nsum(x - mean(x))\n## [1] 0\n\nWie schon erwähnt, arbeitet R so einen “verschachtelten” Befehl von innen nach außen ab:\nStart: sum(x - mean(x))\n⬇️ \nSchritt 1: sum(x - 2)\n⬇️ \nSchritt 2: sum(-1, 0, 1)\n⬇️ \nSchritt 3: 0. Fertig. Ganz schön kompliziert!\nSoweit kann man noch einigermaßen folgen. Aber das Verschachteln kann man noch extremer machen, dann wird’s wild. Schauen Sie sich mal folgende (Pseudo-)Syntax an:\n\n\nListing 4.2: Eine wild verschachtelte Sequenz von Pseudo-Befehlen\n\nfasse_zusammen(\n  gruppiere(\n    wähle_spalten(\n      filter_zeilen(meine_daten))))\n\n\n\nEin beliebter Fehler ist es übrigens, nicht die richtige Zahl an schließenden Klammern hinzuschreiben, z.\\(\\,\\)B. d(c(b(a(meine_daten)). Falsche Zahl an Klammern!\n\n4.3.2 Die Pfeife zur Rettung\nListing 4.2 ist schon harter Tobak, was für echte Fans. Wäre es nicht einfacher, man könnte Listing 4.2 wie folgt schreiben:\nNimm \"meine_daten\" *und dann*\n  filter die gewünschte Zeilen *und dann*\n  wähle die gewünschte Spalten *und dann*\n  teile in Subgruppen *und dann*\n  fasse diese zusammen.\n\nDefinition 4.2 (Pfeife) “Und dann” heißt auf Errisch %&gt;% oder (synonym) |&gt;. Man nennt diesen Befehl “Pfeife” (engl. pipe). \\(\\square\\)\n\n\n\n\n\n\n\nHinweis\n\n\n\nDer Befehl %&gt;% verknüpft Befehle. Der Shortcut für diesen Befehl ist Strg-Shift-M. Die Pfeife %&gt;% “wohnt” im Paket tidyverse.9\n\n\nMittlerweile (Seit R 4.1) ist auch im Standard-R eine Pfeife eingebaut. Die sieht so aus: |&gt;. Die eingebaute Pfeife funktioniert praktisch gleich zur anderen Pfeife, %&gt;%, hat aber den Vorteil, dass Sie nicht tidyverse starten müssen. Da wir tidyverse aber sowieso praktisch immer starten werden, bringt es uns keinen Vorteil, die neuere Pfeife des Standard-R |&gt; zu verwenden. Aber auch keinen Nachteil. Unter Tools &gt; Global Options … können Sie einstellen, welche der beiden Pfeifen-Varianten der Shortcut Strg-Shift-M verwenden soll.\n\n\n\n\n\nflowchart LR\n  A[\"▥\"] --filter&lt;br&gt;zeilen--&gt;B[\"▥\"] \n  B --wähle&lt;br&gt;spalten--&gt; C[\"▥\"]\n  C --gruppiere--&gt; D[\"▥\"]\n  D --fasse&lt;br&gt;zusammen--&gt; E[\"▥\"]\n\n\n\n\nAbbildung 4.11: Illustration für eine Pfeifensequenz, es geht vorwärts wie am Fließband.\n\n\n\n\n\n\nListing 4.3: Eine Pfeifen-Befehlssequenz (Pseudo-Syntax)\n\nmeine_daten %&gt;%\n  filter_gewünschte_zeilen() %&gt;%\n  wähle_gewünschte_spalten() %&gt;%\n  gruppiere() %&gt;%\n  fasse_zusammen() \n\n\n\nUnd jetzt kommt’s: So eine Art von Befehls-Verkettung gibt es in R. Schauen Sie sich mal Listing 4.3 an im Vergleich zu Listing 4.2. So eine Pfeifen-Befehlsequenz ist ein wie ein Fließband, an dem es mehrere Arbeitsstationen gibt, s. Abbildung 4.11. Unser Datensatz wird am Fließband von Station zu Station weitergereicht und an jeder Stelle weiterverarbeitet. So könnte Ihre “Pfeifen-Sequenz” für den Mariokart-Datensatz aussehen, s. Listing 4.4.\n\n\n\nListing 4.4: Mariokart am Fließband: Die ‘Pfeifen-Syntax’\n\n# Hey R, nimm die Tabelle \"mariokart\":\nmariokart %&gt;%  \n   # filter nur die günstigen Spiele:\n  filter(total_pr &lt; 100) %&gt;% \n  # wähle die zwei Spalten:\n  select(cond, total_pr) %&gt;%  \n  # gruppiere die Tabelle nach Zustand des Spiels:\n  group_by(cond) %&gt;%  \n  # fasse beide Gruppen nach dem mittleren Preis zusammen:\n  summarise(total_pr_mean = mean(total_pr))  \n\n\n\n\n\nEndprodukt einer Pfeifen-Syntax\n\ncond\ntotal_pr_mean\n\n\n\nnew\n54\n\n\nused\n43\n\n\n\n\n\nDie Syntax filter(mariokart, total_pr &lt; 100) und die Syntax mariokart |&gt; filter(total_pr &lt; 100) sind identisch. Allgemeiner: d |&gt; f(x) = f(d, x).",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#beispiele-für-forschungsfragen",
    "href": "030-aufbereiten.html#beispiele-für-forschungsfragen",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.4 Beispiele für Forschungsfragen",
    "text": "4.4 Beispiele für Forschungsfragen\nBevor Sie die Lösungen der folgenden Fallbeispiele lesen, versuchen Sie die Aufgaben selbst zu lösen. Ja, ich weiß, es ist hart, nicht gleich auf die Lösungen zu schauen!\n\nÜbungsaufgabe 4.14 (Das teuerste Spiel?) Sie arbeiten als strategischer Assistent der Geschäftsführerin und sind für Faktenchecks und andere Daten-Aufgaben zuständig. Heute sollen Sie zeigen, was Sie können (Schluck).\n\n👩 Ich würde von Ihnen gerne wissen, was das teuerste Spiel ist, aber jeweils für neue und gebrauchte Spiele. Aber nur für Spiele, die mit Foto verkauft wurden!\n\nLösung\n\nmariokart %&gt;% \n  filter(stock_photo == \"yes\") %&gt;% \n  group_by(cond) %&gt;% \n  summarise(total_pr_max = max(total_pr))\n\n\n\ncond\ntotal_pr_max\n\n\n\nnew\n75\n\n\nused\n62\n\n\n\n\n\nDie Funktion max liefert den größten Wert eines Vektors zurück:\n\nx &lt;- c(1, 2, 10)\nmax(x)\n## [1] 10\n\nDas teuerste Spiel mit Foto kostet 75 Dollar, wenn es neu ist und 62, wenn es gebraucht ist. \\(\\square\\)\n\n\nÜbungsaufgabe 4.15 (Die mittlere Versandpauschale?)  \n\n👩 Ich würde gerne die mittlere Versandpauschale wissen, aber getrennt nach Anzahl der Lenkräder, die dem Spiel beigelegt sind. Und ich will nur Gruppen berücksichtigen, die aus mindestens 10 Spielen bestehen!\n\nLösung\nWenn wir die Anzahl der Spiele zählen in Abhängigkeit der beigelegten Lenkräder (wheels), bekommen wir eine Tabelle mit zwei Spalten: wheels und n. n zählt, wie viele Spiele (Zeilen) in der jeweiligen Gruppe (“Teiltabelle”) von wheels sind.\n\nmariokart %&gt;%\n  count(wheels)\n\n\n\nwheels\nn\n\n\n\n0\n37\n\n\n1\n52\n\n\n2\n51\n\n\n3\n2\n\n\n4\n1\n\n\n\n\n\nAus dieser Tabelle sehen wir, dass 3 oder 4 Lenkräder nur selten (2 bzw. 1 Mal) beigelegt wurden und wir solche Spiele herausfiltern sollten, bevor wir den Mittelwert der Versandkosten ausrechnen:\n\nmariokart %&gt;%\n  filter(wheels &lt; 3) %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(mittlere_versandkosten = mean(ship_pr),\n            anzahl_spiele = n())\n\n\n\nwheels\nmittlere_versandkosten\nanzahl_spiele\n\n\n\n0\n2.7\n37\n\n\n1\n3.6\n52\n\n\n2\n2.9\n51\n\n\n\n\n\nDie Funktion n gibt die Anzahl der Zeilen pro Teiltabelle zurück.\nDie mittleren Versandkosten bewegen sich also zwischen 2.7 Dollar und 3.6 Dollar, je nach Anzahl der beigelegten Lenkräder. \\(\\square\\)\n\n\nÜbungsaufgabe 4.16 (Verkaufspreis in Yen?)  \n\n👩 Ich würde gerne den Verkaufspreis in Yen wissen, nicht in Euro. Dann rechne mal den mittleren Verkaufspreis aus und ziehe 10 % ab, die wir als Provision unseren Verkäufern zahlen müssen.\n\nLösung\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  mutate(total_pr_yen = total_pr * 133) %&gt;% \n  summarise(\n    preis_yen_mw = mean(total_pr_yen),\n    preis_yen_mw_minus_10proz = preis_yen_mw - 0.1*preis_yen_mw)\n\n\n\npreis_yen_mw\npreis_yen_mw_minus_10proz\n\n\n6634\n5971\n\n\n\n\nWie man sieht kann man in summarise auch mehr als eine Berechnung einstellen. In diesem Fall haben wir zwei Berechnungen angestellt: Einmal den Mittelwert und einmal den Mittelwert minus 10% (des Mittelwerts).\n\n\nÜbungsaufgabe 4.17 (Do It Yourself) Denken Sie sich selber ähnliche Forschungsfragen aus. Stellen Sie diese einer vertrauenswürdigen Kommilitonen bzw. einem vertrauenswürdigen Kommilitonen. DIY! Schauen Sie, ob Ihre Aufgabe richtig gelöst wird. Prüfen Sie streng … \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#praxisbezug",
    "href": "030-aufbereiten.html#praxisbezug",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.5 Praxisbezug",
    "text": "4.5 Praxisbezug\nDie Covid19-Epidemie hatte weltweit massive Auswirkungen; auch psychologischer Art wie Vereinsamung, Angst oder Depression. Mulukom et al. (2020) berichten eine Studie, die die psychologischen Auswirkungen untersucht; die Studie ist unter der Projekt-ID tsjnb bei der Open Science Foundation (OSF), &lt;https://osf.io/tsjnb/&gt;, angemeldet. Die Daten wurden mit R ausgewertet. Beispielhaft ist unter https://osf.io/4b9p2 die R-Syntax zu sehen, die die Autoren zur Datenaufbereitung verwendet haben. Einen guten Teil dieser Syntax kennen Sie aus diesem Kapitel. Diese Studie ist, neben einigen vergleichbaren, ein schönes Beispiel, wie Forschung und Praxis ineinander greifen können: Angewandte Forschung als Beitrag zur Lösung eines akuten Problems, der Corona-Pandemie.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "href": "030-aufbereiten.html#wie-man-mit-statistik-lügt",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.6 Wie man mit Statistik lügt",
    "text": "4.6 Wie man mit Statistik lügt\nEin (leider) immer mal wieder zu beobachtender “Trick”, um Daten zu frisieren ist, nur die Daten zu berichten, die einem in den Kram passen.\n\nBeispiel 4.11 Eine Analystin 👩 möchte zeigen, dass der Verkaufspreis von Mariokart-Spielen “viel zu niedrig” ist. Es muss ein höherer Wert rauskommen, findet die Analystin. Der mittlere Verkaufspreis (im Datensatz mariokart) liegt bei 50 Euro.\n\n👩 Kann man den Wert nicht … “kreativ verbessern”? Ein paar Statistik-Tricks anwenden?\n\nUm dieses Ziel zu erreichen, teilt die Analystin den Datensatz in Gruppen nach Anzahl der dem Spiel beigelegten Lenkräder (wheels). Dann wird der Mittelwert pro Gruppe berechnet.\n\nmariokart_wheels &lt;- \nmariokart %&gt;% \n  group_by(wheels) %&gt;% \n  summarise(pr_mean = mean(total_pr),\n            count_n = n())  # `n` gibt die Anzahl der Zeilen pro Gruppe an\n\nmariokart_wheels\n\n\n\nwheels\npr_mean\ncount_n\n\n\n\n0\n41\n37\n\n\n1\n44\n52\n\n\n2\n61\n51\n\n\n3\n70\n2\n\n\n4\n65\n1\n\n\n\n\n\nSchließlich berechnet unsere Analystin den ungewichteten Mittelwert über diese 5 Gruppen:\n\nmariokart_wheels %&gt;% \n  summarise(mean(pr_mean))\n\n\n\nmean(pr_mean)\n\n\n56\n\n\n\n\nUnd das Ergebnis lautet: 56 Euro! Das ist doch schon etwas “besser” als 50 Euro.\nNatürlich ist es falsch und irreführend, hier einen ungewichteten Mittelwert zu berechnen. Der gewichtete Mittelwert würde wiederum zum korrekten Ergebnis, 50 Euro, führen. \\(\\square\\)",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#fallstudien",
    "href": "030-aufbereiten.html#fallstudien",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.7 Fallstudien",
    "text": "4.7 Fallstudien\n\n4.7.1 Die Pinguine\n\n\n\n\n\nAbbildung 4.12: Possierlich: Die Pinguine (Horst, 2024)\n\n\n\nÜbungsaufgabe 4.18 Machen Sie sich zunächst mit dem Pinguin-Datensatz vertraut. Sie finden den Datensatz penguins im R-Paket palmerpenguins, das Sie auf gewohnte Art installieren können (vgl. Kapitel 3.4); im Internet findet man den Datensatz auch als CSV-Datei. Fokussieren Sie Ihre Analyse auf die Zielvariable Gewicht. \\(\\square\\)\n\nDie folgende Datenapp ermöglicht Ihnen, die Verteilung des Körpergewichts zu betrachten, wobei sie die Pinguin-Spezies filtern können sowie eine Mindestlänge des Schnabels verlangen können.\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot\nData\n\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"data/penguins.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})\n\n\n\n\n\n\nBearbeiten Sie die Fallstudie zu Pinguinen von Allison Horst. Sie können die Teile auslassen, die Themen beinhalten, die nicht in diesem Kapitel vorgestellt wurden.\nForschungsfragen:\n\nWas ist das mediane Gewicht von Pinguinen, gruppiert nach Spezies und nach Gewicht?\nWie viele Pinguine gibt es pro Spezies?\nWie viel wiegt der schwerste und der leichteste Pinguin pro Spezies?\n\n4.7.2 Fallstudie COVIDiSTRESS\n\n\n\nStudie COVIDiSTTRESS (Lieberoth et al., 2022)\n\nLesen Sie die Beschreibung der Studie COVIDiSTRESS (Lieberoth et al., 2022). Hier ist ein Abstract:\n\nThe COVIDiSTRESS global survey is an international collaborative undertaking for data gathering on human experiences, behavior and attitudes during the COVID-19 pandemic. In particular, the survey focuses on psychological stress, compliance with behavioral guidelines to slow the spread of Coronavirus, and trust in governmental institutions and their preventive measures, but multiple further items and scales are included for descriptive statistics, further analysis and comparative mapping between participating countries. Round one data collection was concluded May 30. 2020. To gather comparable data swiftly from across the globe, when the Coronavirus started making a critical impact on societies and individuals, the collaboration and survey was constructed as an urgent collaborative process. Individual contributors and groups in the COVIDiSTRESS network (see below) conducted translations to each language and shared online links by their own best means in each country.\n\nDie Daten stehen unter https://osf.io/z39us zur freien Verfügung. Sie können diese echten Daten eigenständig analysieren.\nDiese Datei beinhaltet die finalen, aufbereiteten Daten. Achtung: Die Datei ist recht groß, ca. 90 MB.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#aufgaben",
    "href": "030-aufbereiten.html#aufgaben",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.8 Aufgaben",
    "text": "4.8 Aufgaben\n\n\n\n\n\n\nChatGPT\n\n\n\nNutzen Sie einen Chat-Bot wie ChatGPT, um sich Hilfe für die R-Syntax geben zu lassen.\n\n\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nwrangle3\nwrangle4\nwrangle5\nwrangle7\nwrangle9\nwrangle10\ntidydata1\naffairs-dplyr\ndplyr-uebersetzen\nhaeufigkeit01\nmariokart-mean1\nmariokart-mean2\nmariokart-mean3\nmariokart-mean4\nmariokart-max1\nmariokart-max2\nfilter01\naffairs-dplyr\nsummarise01\nsummarise02\nmutate01\nwrangle3",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#vertiefung",
    "href": "030-aufbereiten.html#vertiefung",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.9 Vertiefung",
    "text": "4.9 Vertiefung\n\n4.9.1 Fortgeschrittenes R\n\n\n\n\n\n\nHinweis\n\n\n\nIn weiterführendem Material werden Sie immer wieder auf Inhalte treffen, die Sie noch nicht kennen, die etwa noch nicht im Unterricht behandelt wurden. Seien Sie unbesorgt: In der Regel können Sie diese Inhalte einfach auslassen, ohne den Anschluss zu verlieren. Einfach ignorieren.\n\n\nHäufig ist es nützlich, die Werte einer Variablen umzukodieren, z.\\(\\,\\)B. “weiblich” in “w” oder in 0. Eine gute Möglichkeit, dies in R umzusetzen, bietet der Befehl case_when; der Befehl wohnt im Tidyverse.10 Im Datenwerk finden Sie dazu Übungen, etwa mutate03.\n\n4.9.2 Hilfe?! Erbie!\nR will nicht, so wie Sie wollen? Sie haben das Gefühl, R verweigert störrisch den Dienst, vermutlich rein aus Boshaftigkeit, rein um Sie zu ärgern? Ausführliches Googeln und ChatGPT befragen hat keine Lösung gebracht? Kurz, Sie brauchen die Hilfe eines kundigen Menschens? Sie sollten Ihren Hilfeschrei so artikulieren, dass er nicht nur gehört, sondern auch verstanden wird und einen anderen Menschen veranlasst und ermöglicht, Ihnen zu helfen.\nAlso: Sie müssen Ihr Problem nachvollziehbar, aber prägnant formulieren. Das nennt man auch ein ERBie: ein einfaches, reproduzierbares Beispiel Ihres Problems mit (R-)Syntax:\n\n\neinfach: die einfachste Syntax, die Ihr Problem bzw. die Fehlermeldung produziert. Es bietet sich an, einen einfachen, allgemein bekannten Datensatz zu verwenden, etwa mtcars\n\n\nreproduzierbar: Code (z.\\(\\,\\)B. als Textdatei oder in einem Post), der die Fehlermeldung entstehen lässt\n\n\nBeispiel 4.12 (Beispiel für ein Erbie) Problem: Ich verstehe nicht, warum folgende Fehlermeldung kommt.\nZiel: Ich möchte die Automatikautos filtern (am = 0).\nWas ich schon versucht habe: Ich habe folgende Posts gelesen …, aber ohne Erfolg.\nErbie:\n\ndata(mtcars)\nlibrary(dplyr)  # nicht \"tidyverse\", denn \"dplyr\" reicht\n\nmtcars %&gt;% \n  filter(am = 0)  # den kürzesten Code, der Ihren Fehler entstehen lässt!\n\nsessionInfo()  # gibt Infos zur R-Version etc. aus\n\nError in `filter()`\nMit dem Paket reprex kann man sich R-Syntax schön formuliert ausgeben lassen. Das ist perfekt, um den Code dann in einem Forum (oder Mail) einzustellen. Dafür müssen Sie nur den Code auswählen, Strg-c drücken und dann reprex::reprex ausführen. Mit Strg-v können Sie die schön formatierte Syntax (sowie die Ausgabe, auch schön formatiert) dann irgendwohin pasten.\n\n\n\n\nHelp me help you (imgflip, 2024b)\n\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\n\nPosten Sie Ihr Erbie bei https://gist.github.com/ als “public gist”. Hier ist ein Beispiel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.9.3 Zertifikate und Online-Kurse\nSie können zu den Inhalten dieses Kapitels Zertifikate erwerben (teilweise kostenlos), indem Sie einen Online-Kurs absolvieren, bei z.\\(\\,\\)B. folgenden Anbietern – Das ist keine Werbung für spezifische Anbieter und kein umfassender Überblick und keine Kaufempfehlung.\n\nLinkedIn: R Courses\nGoogle/Coursera: Data Analysis with R Programming\nDuke University/Coursera: Data Analysis with R Specialization",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#exkurs",
    "href": "030-aufbereiten.html#exkurs",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.10 Exkurs",
    "text": "4.10 Exkurs\nDall-E 2 ist eine KI, die “realistische Bilder und Kunst aus einer Beschreibung in natürlicher Sprache” erstellt.\n\n👨‍🏫 I’d like a mixture between robot und professor, in oil painting\n\n\n🤖 … s. Abbildung 4.13\n\n\n\n\n\n\nAbbildung 4.13: Bild erzeugt von künstlicher Intelligenz, Quelle: DALL-E 2, 2023-02-09\n\n\nDer Nutzen künstlicher Intelligenz für die Datenanalyse ist natürlich breiter: Wenn Sie sich z.\\(\\,\\)B. über die Syntax eines bestimmten Befehls (oder allgemeiner: Vorhabens) nicht sicher sind, fragen Sie sich doch mal einen Bot wie ChatGPT.",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#literaturhinweise",
    "href": "030-aufbereiten.html#literaturhinweise",
    "title": "\n4  Daten umformen\n",
    "section": "\n4.11 Literaturhinweise",
    "text": "4.11 Literaturhinweise\nSauer (2019), Kap. 7, gibt eine Einführung in die Datenaufbereitung (mit Hilfe von R), ähnlich zu den Inhalten dieses Kapitels. Mehr in die Tiefe des “Datenjudo” führen; der Autor Hadley Wickham ist in der R-Community sehr bekannt. Er ist einer der Hauptautoren von beliebten R-Paketen wie dplyr und ggplot2. Wickham & Grolemund (2018) Kap. 5 behandeln (etwas ausführlicher) die Themen dieses Kapitels.\nWer sich tiefer in das Datenjudo mit dem Tidyverse einarbeiten möchte, dem sei z.\\(\\,\\)B. dieser Kurs empfohlen.\n\n\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do, According to 35 Data Scientists. Harvard Business Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024a). Imageflip One does not simply [Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Tom Cruise Meme [Artwork]. https://imgflip.com\n\n\nLieberoth, A., Rasmussen, J., Stoeckli, S., Tran, T., Ćepulić, D.-B., Han, H., Lin, S.-Y., Tuominen, J., Travaglino, G., & Vestergren, S. (2022). COVIDiSTRESS Global Survey. https://doi.org/10.17605/OSF.IO/Z39US\n\n\nM7. (2004). Savinelli’s Italian Smoking Pipe [Artwork]. https://commons.wikimedia.org/wiki/File:Pipa_savinelli.jpg\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, & Farias, M. (2020). Psychological Impact of COVID-19 Pandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., & Grolemund, G. (2018). R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren (F. Langenau, Übers.). O’Reilly. https://r4ds.had.co.nz/index.html",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "030-aufbereiten.html#footnotes",
    "href": "030-aufbereiten.html#footnotes",
    "title": "\n4  Daten umformen\n",
    "section": "",
    "text": "Quelle: ChatGTP 3.5, 2023-02-09↩︎\nselect(mariokart, total_pr, cond, 2)↩︎\nhttps://tidyr.tidyverse.org/reference/tidyr_tidy_select.html↩︎\nsummarise(mariokart, hoechster_preis = max(total_pr))↩︎\nsummarise(mariokart, mw_versand = mean(total_pr))↩︎\ncount(mariokart, stock_photo)↩︎\ncount(mariokart, stock_photo, cond)↩︎\nhttps://tidydatatutor.com↩︎\nGenauer gesagt im Paket magrittr, welches aber von tidyverse geladen wird. Also nichts, um das Sie sich kümmern müssten.↩︎\nhttps://www.statology.org/dplyr-case_when/↩︎",
    "crumbs": [
      "Vorbereiten",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Daten umformen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html",
    "href": "040-verbildlichen.html",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#einstieg",
    "href": "040-verbildlichen.html#einstieg",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5.1.1 Lernziele\n\nSie können erläutern, wann und wozu das Visualisieren statistischer Inhalte sinnvoll ist.\nSie kennen typische Arten von Datendiagrammen.\nSie können typische Datendiagramme mit R visualisieren.\nSie können zentrale Ergebnisse aus Datendiagrammen herauslesen.\n\n5.1.2 Benötigte R-Pakete und Daten\nNeben den üblichen Paketen tidyverse (Wickham et al., 2019) und easystats (Lüdecke et al., 2022) benötigen Sie in diesem Kapitel noch DataExplorer (Cui, 2024) und optional ggpubr (Kassambara, 2023) und ggstatsplot (Patil, 2021). Wir arbeiten wieder mit dem Datensatz mariokart, s. Kapitel 3.7.3.\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(DataExplorer)  # nicht vergessen zu installieren\nlibrary(ggpubr)  # optional, Datenvisualisierung\nlibrary(ggstatsplot)  # optional, Datenvisualisierung\n\n\n5.1.3 Quiz zum Einstieg\n\n\n\nVielleicht fordert Sie die Lehrkraft zu einem Einstiegsquiz auf, etwa mittels der Plattform antworte.jetzt. Alternativ überlegen Sie sich selber 10 Quiz-Aufgaben zum Stoff des letzten Kapitels.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1.4 Wozu das alles?\n\n\nGroße Aufgaben warten … (imgflip, 2024)\n\n\n🥷 Wir müssen die Galaxis retten, Kermit!\n\n\n🐸 Schlock",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "href": "040-verbildlichen.html#ein-dino-sagt-mehr-als-1000-worte",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.2 Ein Dino sagt mehr als 1000 Worte",
    "text": "5.2 Ein Dino sagt mehr als 1000 Worte\nEs heißt, ein Bild sage mehr als 1000 Worte. Schon richtig, aber ein Dinosaurier sagt auch mehr als 1000 Worte (Fitzmaurice, 2017). In Abbildung 5.1 sieht man verschiedene “Bilder”, also Datensätze: etwa einen Dino und einmal einen Kreis. Obwohl die Bilder grundverschieden sind, sind die zentralen statistischen Kennwerte (praktisch) identisch. In dieselbe Bresche schlägt “Anscombes Quartett” (Anscombe, 1973). Es zeigt vier Datensätze, in denen die zentralen Statistiken fast identisch sind, also Mittelwerte, Streuungen, Korrelationen. Aber die Streudiagramme sind grundverschieden. Anscombes Beispiel zeigt (zugespitzt): Eine Visualisierung enthüllt, was der Statistik (als Kennzahl) verhüllt bleibt. Statistische Diagramme können Einblicke geben, die sich nicht (leicht) in grundlegenden Statistiken (Kennwerten) abbilden. Unter visueller Cortex ist sehr leistungsfähig. Wir können ohne Mühe eine große Anzahl an visuellen Informationen aufnehmen und parallel verarbeiten. Aus diesem Grund sind Datendiagramme eine effektive und einfache Art, aus Daten Erkenntnisse zu ziehen. Nutzen Sie Datendiagramme umfassend; sie sind einfach zu verstehen und doch sehr mächtig.\n\n\n\n\n\nAbbildung 5.1: Dinosaurier und Kreis: Gleiche statistische Kennwerte (Fitzmaurice, 2017)\n\n\nAbbildung 5.2 zeigt Anscombes Quartett.\n\n\n\n\n\nAbbildung 5.2: Anscombes Quartet: Gleiche statistischen Kennwerte in vier Datensätzen\n\n\n\nDefinition 5.1 (Datendiagramm) Ein Datendiagramm (kurz: Diagramm) ist ein Diagramm, das Daten und Statistiken zeigt, mit dem Zweck, Erkenntnisse daraus zu ziehen.\n\n\nBeispiel 5.1 (Aus der Forschung: Ein aufwändiges (und ansprechendes) Datendiagramm)  \n\n\nAuf Basis des Korruptionsindex von Transparency International (2017) erstellt Wilke (2024) ein Diagramm zum Zusammenhang vom Entwicklungsindex (Lebenserwartung, Bildung, Einkommen; vgl. Hou et al. (2015)) und Korruption, jeweils auf Landesebene, s. Abbildung 5.3.\nEs finden sich in der Literatur (im Internet) viele weitere Beispiele für handwerklich meisterhaft erstelle Datendiagramme, die in vielen Fällen mit R erstellt werden (vgl. Scherer et al., 2019). \\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 5.3: Der Zusammenhang von Entwicklungindex und und Korruption\n\n\n\n\n\nAbbildung 5.4 zeigt ein Bild mit mehreren (5) Variablen, die jeweils einer “Dimension” entsprechen. Wie man (nicht) sieht, wird es langsam unübersichtlich. Offenbar kann man in einem Bild nicht beliebig viele Variablen sinnvoll reinquetschen. Die “Dimensionalität” eines Diagramms hat ihre Grenzen, vielleicht bei vier bis sechs Variablen. Möchten wir den Zusammenhang von vielen Variablen verstehen, kommen wir mit Bildern oft nicht weiter. Dann brauchen wir andere Werkzeuge: Statistik, komm zu Hilfe. Bei klaren Zusammenhängen und wenig Variablen braucht man keine (aufwändige) Statistik. Ein Bild, also ein Datendiagramm, ist dann oft ausreichend. Man könnte sagen, dass es Statistik nur deshalb gibt, weil unser Auge mit mehr als ca. vier bis sechs Variablen nicht gleichzeitig umgehen kann.\n\n\n\n\n\n\n\nAbbildung 5.4: Ein Diagramm kann nur eine begrenzte Anzahl von Variablen zeigen. Wenn Sie dieses Bild nicht checken: Prima. Genau das soll das Bild zeigen.\n\n\n\n\n\n\nÜbungsaufgabe 5.1 Wie viele Variablen sind in Abbildung 5.4 dargestellt?1",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "href": "040-verbildlichen.html#nomenklatur-von-datendiagrammen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.3 Nomenklatur von Datendiagrammen",
    "text": "5.3 Nomenklatur von Datendiagrammen\nTabelle 5.1 zeigt eine – sehr kurze Nomenklatur – von Datendiagrammen. Weitere Nomenklaturen sind möglich, aber wir halten hier die Sache einfach. Wer an Vertiefung interessiert ist, findet bei data-to-vis einen Überblick über verschiedene Typen an Diagrammen, sogar in Form einer systematischen Nomenklatur: https://www.data-to-viz.com/.\n\n\n\nTabelle 5.1: Ein (sehr kurze) Nomenklatur von Datendiagrammen\n\n\n\n\n\n\n\n\n\nErkenntnisziel\nqualitativ\nquantitativ\n\n\n\nVerteilung\nBalkendiagramm\nHistogramm und Dichtediagramm\n\n\nZusammenhang\ngefülltes Balkendiagramm\nStreudiagramm\n\n\nUnterschied\ngefülltes Balkendiagramm\nBoxplot",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#verteilungen-verbildlichen",
    "href": "040-verbildlichen.html#verteilungen-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.4 Verteilungen verbildlichen",
    "text": "5.4 Verteilungen verbildlichen\n\n5.4.1 Verteilung einer nominalen Variable\n\nDefinition 5.2 (Verteilung) Eine (Häufigkeits-)Verteilung einer Variablen \\(X\\) schlüsselt auf, wie häufig jede Ausprägung von \\(X\\) ist. \\(\\square\\)\n\n\nBeispiel 5.2 Tabelle 5.2 zeigt die Häufigkeitsverteilung von cond (condition, also der Zustand des Artikels, neu oder gebraucht) aus dem Datensatz mariokart. Die Variable hat 2 Ausprägungen; z.\\(\\,\\)B. kommt die Ausprägung new 59 mal vor. \\(\\square\\)\n\n\n\n\nTabelle 5.2: Häufigkeitsverteilung von cond aus dem Datensatz mariokart\n\n\n\n\ncond\nn\n\n\n\nnew\n59\n\n\nused\n84\n\n\n\n\n\n\n\n\nZugegeben, das Datendiagramm von cond ist nicht so aufregend, s. Abbildung 5.5. Wie man sieht, besteht so ein Diagramm aus Balken, daher heißt es Balkendiagramm. Man kann so ein Diagramm um 90\\(\\,\\)° drehen, s. Abbildung 5.5; keine Ausrichtung ist grundsätzlich besser als die andere.\n\nDefinition 5.3 (Balkendiagramm) Ein Balkendiagramm ist eine grafische Darstellung von Werten, zumeist für die Häufigkeiten bestimmter Kategorien, also Ausprägungen nominaler Variablen. Dabei werden rechteckige Balken verwendet, und die Länge eines Balkens ist proportional zur dargestellten Häufigkeit. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) horizontale Balken\n\n\n\n\n\n\n\n\n\n(b) vertikale Balken\n\n\n\n\n\n\nAbbildung 5.5: Häufigkeitsverteilung der Variable cond\n\n\nEs gibt viele Methoden, sich mit R ein Balkendiagramm ausgeben zu lassen. Eine einfache, komfortable ist die mit dem Paket DataExplorer, s. Abbildung 5.5; wir betrachten gleich die Syntax. Zuerst importieren wir die Daten, s. Listing 3.2. Außerdem nicht vergessen, das Paket DataExplorer mit dem Befehl library zu starten. (Natürlich müssen Sie das Paket einmalig installiert haben, bevor Sie es starten können.) In diesem Paket “wohnen” die Befehle, die wir zum Erstellen der Datendiagramme nutzen werden. Listing 5.1 zeigt die Syntax, um ein Balkendiagramm zu erstellen. Auf der Hilfeseite der Funktion finden Sie weitere Details zur Funktion.\n\n\n\nListing 5.1: Syntax zur Erstellung eines Balkendiagramms\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  select(cond) %&gt;% \n  plot_bar()\n\n\n\n\n\n\n\n\n\nAbbildung 5.6: Ein Balkendiagramm. Unglaublich.\n\n\n\n\nDie Syntax ist in Listing 5.1 abgedruckt (Zur Erinnerung: %&gt;% nennt man die “Pfeife und lässt sich als”und dann” übersetzen, vgl. Kapitel 4.3). Übersetzen wir die Syntax ins Deutsche:\nNimm den Datensatz `mariokart` *und dann*\n  wähle die Spalte cond *und dann*\n  zeichne ein Balkendiagramm. Fertig!\n\nÜbungsaufgabe 5.2 (Spalten wählen für das Balkendiagramm) Hätten wir andere Spalten ausgewählt, so würde das Balkendiagramm die Verteilung jener Variablen zeigen. Ja, Sie können auch mehrere Variablen auf einmal auswählen. Probieren Sie das doch mal aus! \\(\\square\\)\n\n\nÜbungsaufgabe 5.3 (Visualisieren Sie die Verteilung von stock_photo!) Erstellen Sie ein geeignetes Diagramm, um die Häufigkeit jeder Ausprägung von stock_photo (Datensatz mariokart) darzustellen.\nLösung\n\nmariokart |&gt; \n  select(stock_photo) |&gt; \n  plot_bar()\n\n\n\n\n\n\n\nMit plot_bar aus DataExplorer kann man Balkendiagramme darstellen. \\(\\square\\)\n\n\n\n5.4.2 Verteilung einer quantitativen Variable\nBei einer quantitativen Variablen mit vielen Ausprägungen wäre ein Balkendiagramm nicht so aussagekräftig, s. Abbildung 5.7 (links). Es gibt einfach zu viele Ausprägungen.\nDie Lösung: Wir reduzieren die Anzahl der Ausprägungen, in dem wir auf ganze Dollar runden. Oder, um noch weniger Ausprägungen zu bekommen, können wir einfach Gruppen definieren, z.\\(\\,\\)B.\n\nGruppe 1: 0-5 Dollar\nGruppe 2: 6-10 Dollar\nGruppe 3: 11-15 Dollar\n…\n\nIn Abbildung 5.7 (rechts) sind z.\\(\\,\\)B. die Ausprägungen des Verkaufspreises (total_pr) in Gruppen der Breite von 5 Dollar aufgeteilt worden. Zusätzlich sind noch die einzelnen Werte als schwarze Punkte gezeigt.\n\n\n\n\n\n\n\n\n\n(a) Balkendiagramm\n\n\n\n\n\n\n\n\n\n(b) Histogramm\n\n\n\n\n\n\nAbbildung 5.7: Balkendiagramm vs. Histogramm für den Gesamtpreis (total_pr)\n\n\n\nDefinition 5.4 (Histogramm) Ein Histogramm ist ein Diagramm zur Darstellung der Häufigkeitsverteilung einer quantitativen Variablen. Die Daten werden in Gruppen (Klassen) eingeteilt, die dann durch einen Balken (pro Klasse) dargestellt werden. Die Höhe der Balken zeigt die Häufigkeit der Daten in dieser Gruppe/in diesem Balken (bei konstanter Balkenbreite).\n\nEs gibt keine klare Regel, in wie viele Balken ein Histogramm gegliedert sein sollte. Nur: Es sollten werder sehr viele noch zu wenige sein, s. Abbildung 5.8 (links) bzw. Abbildung 5.8 (rechts). Zur Erstellung eines Histogramms können Sie die Syntax Listing 5.2 nutzen, vgl. Abbildung 5.9, links.\n\n\n\n\n\n\n\n\n\n(a) Zu viele Gruppen (Balken)\n\n\n\n\n\n\n\n\n\n(b) Zu wenige Gruppen (Balken)\n\n\n\n\n\n\nAbbildung 5.8: Nicht zu wenig und nicht zu viele Balken im Histogramm\n\n\n\n\n\nListing 5.2: Syntax zur Erstellung eines Histogramms\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  filter(total_pr &lt; 100) %&gt;%  # ohne Extremwerte\n  plot_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 5.9: Eine stetige Verteilung verbildlichen\n\n\n\nÜbungsaufgabe 5.4 (Visualisieren Sie die Verteilung von ship_pr anhand eines Histogramms!)  \n\nmariokart |&gt; \n  select(ship_pr) |&gt; \n  plot_histogram()\n\n\n\n\n\n\n\n\nAbbildung 5.10 fügt zum Histogramm ein Dichtediagramm hinzu (durchgezogene Linie). Ein Dichtediagramm ähnelt einem “glattgeschmirgelten” Histogramm.\n\nDefinition 5.5 (Dichtediagramm) Ein Dichtediagramm visualisiert die Verteilung einer stetigen Variablen. Im Gegensatz zum Histogramm wird der Verlauf der Kurve geglättet, so kann Rauschen (Zufallsschwankung) besser ausgeblendet werden. (Mit Dichte ist die relative Anzahl der Beobachtungen pro Einheit der Variablen auf der X-Achse gemeint.)\n\n\n\n\n\n\n\n\nAbbildung 5.10: Histogramm und Dichtediagramm (Linie) für total_pr\n\n\n\n\n\nÜbungsaufgabe 5.5 Erstellen Sie das Diagramm Abbildung 5.9, rechtes Teildiagramm!2\\(\\square\\)\n\nVerteilungen unterscheiden sich z.\\(\\,\\)B. in ihrem “typischen” oder “mittleren” Wert (vgl. Kapitel 6.5), aber auch in ihrer Streuung (vgl. Kapitel 7.3). (Diagramme von) Verteilungen können symmetrisch oder schief (nicht symmetrisch) sein, s. Abbildung 5.11. Abbildung 5.12 zeigt verschiedene Formen von Verteilungen. “Bimodal” meint “zweigipflig” und “multimodal” entsprechend “mehrgipflig”.3\n\n\n\n\n\n\n\n\n\n(a) Symmetrisch (Normal)\n\n\n\n\n\n\n\n\n\n(b) Schief\n\n\n\n\n\n\nAbbildung 5.11: Symmetrische vs. schiefe Verteilung, verbildlicht\n\n\n\n\n\n\n\n\n\nAbbildung 5.12: Verschiedene Verteilungsformen\n\n\n\n\n\nÜbungsaufgabe 5.6 (Verteilungsform von total_pr?) Benennen Sie die am besten passende Verteilungsform für die Variable total_pr.\nLösung\n\nmariokart |&gt; \n  select(total_pr) |&gt; \n  plot_density()\n\n\n\n\n\n\n\nDie Verteilung ist rechtsschief. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#spezialfall-normalverteilung",
    "href": "040-verbildlichen.html#spezialfall-normalverteilung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.5 Spezialfall Normalverteilung",
    "text": "5.5 Spezialfall Normalverteilung\n\n5.5.1 Grundlagen\nEine Normalverteilung ist eine bestimmte Art von Verteilung einer stetigen quantitativen Variablen. Aber sie ist besonders wichtig, und wird daher hier besonders hervorgehoben. Eine Normalverteilung sehen Sie in Abbildung 5.11, links. Die Normalverteilung ist in der Statistik von hoher Bedeutung, da sie sich unter (recht häufigen) Bedingungen zwangsläufig ergeben muss und vielseitig Verwendung findet.\n\nDefinition 5.6 (Normalverteilung) Normalverteilungen haben eine charakteristische symmetrische Glockenform. Normalverteilungen können sich unterscheiden in ihrem Mittelwert \\(\\mu\\) und ihrer Streuung, \\(\\sigma\\). Diese beiden Größen (“Parameter”) determinieren den Graphen einer bestimmten Normalverteilungsfunktion, s. Abbildung 5.13. Sind diese beiden Parameter bekannt, so ist die Dichte jedes beliebigen Datenpunkts (aus dieser Normalverteilung) bestimmt.\\(\\square\\)\n\nEine normalverteilte Zufallsvariable \\(X\\) mit einem bestimmten Mittelwert und einer bestimmten Streuung schreibt man kurz so:\n\\[X \\sim \\mathcal{N}(\\mu, \\sigma)\\]\n\n\n\n\n\nAbbildung 5.13: Beispiele von Normalverteilungen mit verschiedenen Mittelwerten und Streuungen, Quelle: Wikipedia\n\n\n\nBeispiel 5.3 Beispiele für normalverteilte Variablen sind Körpergröße von Männern oder Frauen, IQ-Werte, einige Prüfungsergebnisse, Messfehler, Lebensdauer von Glühbirnen, Gewichte von Brotlaiben, Milchproduktion von Kühen, Brustumfang schottischer Soldaten (Lyon, 2014). \\(\\square\\)\n\n\nDefinition 5.7 (Normalverteilung) Eine Normalverteilung ist eine spezielle Art von Verteilung einer quantitativen Variablen. Sie ist symmetrisch, glockenförmig, stetig, unimodal und ihr Mittelwert, Median und Modus identisch. Sie lässt sich durch zwei Parameter vollständig beschreiben: Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)). \\(\\square\\)\n\n\n\n\n\nAbbildung 5.14 zeigt interaktive Beispiele für Normalverteilung. Wählen Sie einfach Mittelwert (\\(\\mu\\)) und Streuung (\\(\\sigma\\)) anhand der Schieberegler.4\n\n\n\n\nsliders = {\n  let div = d3.create(\"div\");\n\n  let m0 = d3.mean(pts);\n  let s0 = d3.deviation(pts);\n  let mu = Inputs.range([1, 8], {\n    value: m0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\mu:`\n  });\n  let sigma = Inputs.range([0.2, 4], {\n    value: s0,\n    step: 0.001,\n    format: d3.format(\"0.3f\"),\n    label: tex`\\large\\pmb\\sigma:`\n  });\n\n  d3.select(mu).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n  d3.select(sigma).on(\"input\", redraw).select(\"label\").style(\"width\", \"30px\");\n\n  div.append(() =&gt; mu);\n  div.append(() =&gt; sigma);\n\n  return div.node();\n\n  function redraw() {\n    let m = mu.value;\n    let s = sigma.value;\n    d3.select(normal_model).select(\"svg\").remove();\n    let standardized = pts.map((x) =&gt; (x - m0) / s0);\n    let new_pts = standardized.map((z) =&gt; z * s + m);\n    let new_plot = create_plot(new_pts);\n    d3.select(normal_model).append(() =&gt; new_plot);\n  }\n}\n\nviewof steely_dan_says = Inputs.button(\"Neuer Zufallsversuch\")\n\nnormal_model = {\n  let div = d3.create(\"div\");\n  let plot = create_plot(pts);\n\n  d3.select(plot).selectAll(\"circle\").attr(\"opacity\", 0);\n\n  let initials = d3\n    .select(plot)\n    .selectAll(\"rect\")\n    .nodes()\n    .map((r) =&gt; ({ height: r.getAttribute(\"height\"), y: r.getAttribute(\"y\") }));\n  let y_scale = plot.scale(\"y\");\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .attr(\"height\", 0)\n    .attr(\"y\", y_scale.apply(0));\n  d3.select(plot).select(\"path\").attr(\"opacity\", 0);\n  Promises.delay(500).then(function () {\n    d3.select(plot)\n      .selectAll(\"circle\")\n      .attr(\"opacity\", 0)\n      .transition()\n      .duration(1000)\n      .attr(\"opacity\", 0.0);\n  });\n  Promises.delay(1500).then(function () {\n    d3.select(plot)\n      .selectAll(\"rect\")\n      .attr(\"height\", 0)\n      .attr(\"y\", y_scale.apply(0))\n      .transition()\n      .duration(850)\n      .attr(\"height\", (d, i) =&gt; initials[i].height)\n      .attr(\"y\", (d, i) =&gt; initials[i].y);\n  });\n  if (show_curve) {\n    Promises.delay(1500).then(function () {\n      d3.select(plot)\n        .selectAll(\"path\")\n        .attr(\"opacity\", 0)\n        .transition()\n        .duration(1000)\n        .attr(\"opacity\", 0.8);\n    });\n  }\n\n  div.append(() =&gt; plot);\n\n  return div.node();\n}\n\npts = {\n  steely_dan_says;\n  let n = 1000;\n  let m0 = d3.randomUniform(1, 8)();\n  let s0 = d3.randomUniform(1 / 2, 2)();\n  let pts = d3.range(n).map(d3.randomNormal(m0, s0));\n\n  return pts;\n}\n\ncreate_plot = function (pts) {\n  let m = d3.mean(pts);\n  let s = d3.deviation(pts);\n\n  let w = 800;\n  let h = 0.4 * w;\n\n  let f = (x) =&gt;\n    Math.exp((-(x - m) * (x - m)) / (2 * s * s)) / (Math.sqrt(2 * Math.PI) * s);\n\n  let marks = [\n    Plot.rectY(\n      pts,\n      Plot.binX(\n        {\n          y: (a, bin) =&gt; {\n            return a.length / pts.length / (bin.x2 - bin.x1);\n          },\n          title: \"proportion\"\n        },\n        { x: (pt) =&gt; pt, fill: \"#b00\" }\n      )\n    ),\n    Plot.dot(pts, {\n      x: (x) =&gt; x,\n      y: (_) =&gt; 0,\n      stroke: \"black\",\n      fill: \"black\",\n      opacity: 0.2\n    }),\n    Plot.ruleX([0]),\n    Plot.ruleY([0])\n  ];\n  if (show_curve) {\n    marks.push(\n      Plot.line(build_samples(f, -1, 12, { N: 100 }), {\n        strokeWidth: 5,\n        stroke: \"#111\",\n        opacity: 0\n      })\n    );\n  }\n\n  let plot = Plot.plot({\n    x: { domain: [0, 11] },\n    y: { domain: [0, 1] },\n    width: w,\n    height: h,\n    marks: marks\n  });\n\n  d3.select(plot)\n    .selectAll(\"rect\")\n    .on(\"pointerenter\", function () {\n      d3.select(this).attr(\"opacity\", 0.5);\n    })\n    .on(\"pointerleave\", function () {\n      d3.select(this).attr(\"stroke\", null).attr(\"opacity\", null);\n    })\n    .nodes()\n    .forEach((bar) =&gt;\n      tippy(bar, { content: d3.select(bar).select(\"title\").text() })\n    );\n  d3.select(plot).selectAll(\"rect\").select(\"title\").remove();\n  return plot;\n}\n\nshow_curve = true\n\nimport { build_samples } from '@mcmcclur/adaptive-plotter'\n\ntippy = require(\"tippy.js@6\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.14: Interaktives Beispiel für Normalverteilungen.\n\n\n\n5.5.2 Fläche unter der Kurve\nKennt man die beiden Parameter der Normalverteilung, Mittelwert und Streuung (SD, \\(\\sigma\\)), einer Normalverteilung, so kann man einfach angeben, welcher Anteil der Fläche (unter der Kurve) der Normalverteilung sich in einem bestimmten Bereich befindet, s. Abbildung 5.15.\nDavon leitet sich die “68-95-99.7-Prozentregel” ab, die angibt, in welchem Bereich sich welcher Anteil der Fläche befindet:\n\n\n\\(68\\,\\%\\) im Bereich \\(\\mu\\pm 1 \\cdot \\sigma\\)\n\n\n\\(95\\,\\%\\) im Bereich \\(\\mu\\pm 2 \\cdot \\sigma\\)\n\n\n\\(99{.}7\\,\\%\\) im Bereich \\(\\mu\\pm 3 \\cdot \\sigma\\)\n\n\n\n\n\n\n\nAbbildung 5.15: Die Flächeninhalte (Wahrscheinlichkeitsmasse) einer Normalverteilung in Abhängigkeit der Streuung (Ainali, 2007)\n\n\n\n5.5.3 IQ-Verteilung\nDie Verteilung der Zufallsvariablen IQ ist normalverteilt mit einem Mittelwert von 100 und einer Streuung von 15, s. Abbildung 5.16:\n\\(IQ \\sim \\mathcal{N}(100,15)\\)\n\nÜbungsaufgabe 5.7 (Wie schlau muss man (nicht) sein?)  \n\nWie schlau muss man sein, um zu den unteren 75%, 50%, 25%, 5%, 1% zu gehören?\nAnders gesagt: Welcher IQ-Wert wird von 75%, 50%, … der Leute nicht überschritten?\\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 5.16: Visualisierung der theoretischen IQ-Verteilung\n\n\n\n5.5.4 Vertiefung: Entstehung einer Normalverteilung\n\nDefinition 5.8 (Entstehung einer Normalverteilung) Wenn sich eine Variable \\(X\\) als Summe mehrerer, unabhängiger, etwa gleich starker Summanden, dann kann man erwarten, dass sich diese Variable \\(X\\) tendenziell normalverteilt. \\(\\square\\)\n\n\n\n\nDie Entstehhung einer Normalverteilung kann man gut anhand des Galton-Bretts veranschaulichen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "href": "040-verbildlichen.html#zusammenhänge-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.6 Zusammenhänge verbildlichen",
    "text": "5.6 Zusammenhänge verbildlichen\n\n5.6.1 Zusammenhang nominaler Variablen\n\nBeispiel 5.4 (Beispiele für Zusammenhänge bei nominalen Variablen)  \n\nHängt Berufserfolg (Führungskraft ja/nein) mit dem Geschlecht zusammen?\nHängt der Beruf des Vaters mit dem Schulabschluss des Kindes (Abitur, Realschule, Mittelschule) zusammen?\nGibt es einen Zusammenhang zwischen der bevorzugten Automarke und der Präferenz für eine politische Partei? \\(\\square\\)\n\n\n\nSagen wir, Sie arbeiten immer noch beim Online-Auktionshaus und Sie fragen sich, ob ein Produktfoto wohl primär bei neuwertigen Produkten beiliegt, aber nicht bei gebrauchten? Dazu betrachten Sie wieder die mariokart-Daten, s. Abbildung 5.17. Tatsächlich: Es findet sich ein Zusammenhang zwischen der Tatsache, ob dem versteigerten Produkt ein Foto bei lag und ob es neuwertig oder gebraucht war (Abbildung 5.17, links). Bei neuen Spielen war fast immer (ca. 90%) ein Foto dabei; bei gebrauchten Spielen immerhin bei gut der Hälfte der Fälle.\n\n\n\n\n\n\n\n\n\n\n(a) starker Zusammenhang\n\n\n\n\n \n\n\n\n\n\n\n\n(b) schwacher Zusammenhang\n\n\n\n\n\n\nAbbildung 5.17: Zusammenhang zwischen nominalskalierten Variablen verbildlichen. (a) Es findet sich ein Zusammenhang von Foto und Zustand in den Daten. (b) Es findet sich (fast) kein Zusammenhang von wheel und Foto in den Daten\n\n\n\nAnders sieht es aus für die Frage, ob ein (oder mehrere) Lenkräder dem Spiel beilagen (oder nicht) in Zusammenhang mit der Fotofrage Hier gab es fast keinen Unterschied zwischen neuen und alten Spielen, was die Frage nach “Foto des Produkts dabei” betraf (Abbildung 5.17, rechts), der Anteil betrug jeweils ca. 70%. Das zeigt, dass es keinen Zusammenhang zwischen Foto und Neuwertigkeit des Spiels gibt (laut unseren Daten). Bildlich gesprochen: Unterscheiden sich die “Füllhöhe” in den Diagrammen, so gibt es einen Unterschied hinsichtlich “Foto ist dabei” zwischen den beiden Gruppen (linker vs. rechter Balken). Unterscheiden sich die Anteile in den Gruppen (neuwertige vs. gebrauchte Spiele), so spielt z.\\(\\,\\)B. die Variable “Foto dabei” offenbar eine Rolle. Dann hängen Neuwertigkeit und “Foto dabei” also zusammen!\nSo können Sie sich in R ein gefülltes Balkendiagramm ausgeben lassen, z.\\(\\,\\)B. mit plot_bar(mariokart, by = \"cond\") (Paket DataExplorer). Diese Darstellung eignet sich, um Zusammenhänge zwischen zwei zweistufigen nominalskalierten Variablen zu verbildlichen. Die verschiedenen Werte der Füllfarbe werden den Stufen der Variablen cond zugewiesen, s. Listing 5.3.\n\n\n\nListing 5.3: R-Syntax für ein gefülltes Balkendiagramm\n\nmariokart %&gt;% \n  select(cond, stock_photo) %&gt;% \n  plot_bar(by = \"cond\")  # aus dem Paket DataExplorer\n\n\n\n\n\n\n\n\n\nAbbildung 5.18: Ein gefülltes Balkendiagramm zur Untersuchung eines Zusammenhangs zwischen nominalskalierter Variablen\n\n\n\n\nGefüllte Balkendiagramme eignen sich zur Analyse eines Zusammenhangs zwischen nominalskalierten Variablen. Allerdings sollte eine der beiden Variablen nur zwei Ausprägungen aufweisen, sonst sind die Zusammenhänge nicht mehr so gut zu erkennen. Außerdem sollten die Balken auf gleiche Länge (100%) ausgerichtet sein.\n\nÜbungsaufgabe 5.8 (Zusammenhang visualisieren) Visualisieren Sie den Zusammenhang der beiden nominalen Variablen cond und wheels!\n\nmariokart |&gt; \n  # Mache aus einer metrischen eine nominale Variable: \n  mutate(wheels = factor(wheels)) |&gt; \n  select(cond, wheels) |&gt; \n  plot_bar(by = \"cond\")\n\nLösung\nwheels ist als metrische Variable (int: Integer, d.\\(\\,\\)h. Ganzzahl) formatiert im Datensatz mariokart. Wir müssen Sie zunächst als Faktorvariable umformatieren, damit R sie als nominal skalierte Variable erkennt. \\(\\square\\)\n\n\n5.6.2 Zusammenhang bei metrischen Variablen\nDen Zusammenhang zweier metrischer Variablen kann man mit einem Streudiagramm visualisieren (engl. scatterplot). Abbildung 5.19 links untersucht den Zusammenhang des Einstiegpreises (X-Achse) und Abschlusspreises (Y-Achse) von Geboten bei Versteigerungen des Computerspiels Mariokart. In dem Diagramm ist eine “Trendgerade” (Regressionsgerade), um die Art des Zusammenhangs besser zu verdeutlichen. Die Trendgerade steigt an (von links nach recht). Daraus kann man schließen: Es handelt sich um einen gleichsinnigen (positiven) Zusammenhang: Je höher der Startpreis, desto höher der Abschlusspreis, zumindest tendenziell. Diese Gerade verläuft “mittig” in den Daten (wir definieren das später genauer). Diese Trendgerade gibt Aufschluss über “typische” Werte: Welcher Y-Wert ist “typisch” für einen bestimmten X-Wert? Abbildung 5.19 rechts untersucht den Zusammenhang zwischen Anzahl der Gebote (X-Achse) und Abschlusspreises (Y-Achse). Es handelt sich um einen negativen Zusammenhang: Je mehr Gebote, desto geringer der Abschlusspreis (tendenziell). Das erkennt man an der sinkenden Trendgeraden. Die Ellipse zeigt an, wie eng die Daten um die Trendgerade streuen. Daraus kann man ableiten, wie stark der Absolutwert des Zusammenhangs ist, vgl. Abbildung 5.21.\n\n\n\n\n\n\n\n\n\n\n(a) positiver, mittelstarker Zusammenhang\n\n\n\n\n \n\n\n\n\n\n\n\n(b) negativer, schwacher Zusammenhang\n\n\n\n\n\n\nAbbildung 5.19: Streudiagramm zur Darstellung eines Zusammenhangs zweier metrischer Variablen\n\n\n\n\nDefinition 5.9 (Linearer Zusammenhang) Lässt sich die Beziehung zweier Variablen gut mit einer Geraden beschreiben, so spricht man von einem linearen Zusammenhang. Ändert man eine der beiden Variablen um einen bestimmten Wert (z.\\(\\,\\)B. 1), so ändert sich die andere um einen proportionalen Wert (z.\\(\\,\\)B. 0.5). Gleichsinnige (positive) Zusammenhänge erkennt man an aufsteigenden Trendgeraden \\(\\nearrow\\); gegensinnige (negative) Zusammenhänge an absteigenden Trendgeraden \\(\\searrow\\). \\(\\square\\)\n\nNatürlich könnte man auch nicht-lineare Zusammenhänge untersuchen, aber der Einfachheit halber konzentrieren wir uns hier auf lineare; Beispiele für nicht-lineare Zusammenhänge sind in Abbildung 5.20 zu sehen.\n\n\n\n\n\n\n\nAbbildung 5.20: Beispiele nichtlinearer Zusammenhänge\n\n\n\n\nStarke Zusammenhänge erkennt man an schmalen Ellipsen (“Baguette” 🥖); schwache Zusammenhänge an breiten Ellipsen (“Torte” 🥮). Abbildung 5.21 bietet einen Überblick über verschiedene Beispiele von Richtung und Stärke von Zusammenhängen.5 In Abbildung 5.21 ist für jedes Teildiagramm eine Zahl angegeben: der Korrelationskoeffizient. Diese Statistik quantifiziert Richtung und Stärke des Zusammenhangs (mehr dazu in Kap. Kapitel 8). Ein positives Vorzeichen steht für einen positiven Zusammenhang, ein negatives Vorzeichen für einen negativen Zusammenhang. Der (Absolut-)Wert gibt die Stärke des linearen Zusammenhangs an. Cohen (1992) hat folgende Faustregeln angegeben:\n\n\n\\(r\\approx 0\\): Kein Zusammenhang\n\n\\(r \\pm .1\\): schwacher Zusammenhang\n\n\\(r \\pm .3\\): mittlerer Zusammenhang\n\n\\(r \\pm .5\\): starker Zusammenhang\n\n\\(r = 1\\): perfekter Zusammenhang\n\n\n\n\n\n\n\n\nAbbildung 5.21: Lineare Zusammenhänge verschiedener Stärke und Richtung\n\n\n\n\nAbbildung 5.22 hat die gleiche Aussage wie Abbildung 5.21, ist aber plakativer, indem Stärke (schwach, stark) und Richtung (positiv, negativ) gegenübergestellt sind. Man sieht in Abbildung 5.21 und Abbildung 5.22, dass ein negativer Korrelationskoeffizient mit einer absinkenden Trendgerade (synonym: Regressionsgerade; blaue Linie) einhergeht. Umgekehrt geht ein positiver Trend mit einer ansteigenden Trendgerade einher. Zweitens erkennt man, dass starke Zusammenhänge mit einer schmalen Ellipse einhergehen und schwache Zusammenhänge mit einer breiten Ellipse einhergehen.\n\n\n\n\n\n\n\nAbbildung 5.22: Überblick über starke vs. schwache bzw. positive vs. negative Zusammenhänge\n\n\n\n\nAbbildung 5.23 zeigt interaktive Beispiele für (lineare) Zusammenhänge.6\n\n\n\n\nviewof cor_type = select({\n  title: \"Correlation type\",\n  options: [\n    \"A perfect linear relationship\",\n    \"A close to linear relationship\",\n    \"A close to linear, but negative, relationship\",\n    \"A weaker relationship\",\n    \"A nonlinear relationship\",\n    \"No relationship\"\n  ],\n  value: \"A perfect linear relationship\"\n})\n\n\n\n\n\n\n\nviewof redo = Inputs.button(\"Redo\")\n\n\n\n\n\n\n\npic = (redo, graph_from_type(cor_type))\n\n\n\n\n\n\n\nfunction graph_from_type(s) {\n  if (s == \"A perfect linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 0,\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A close to linear, but negative, relationship\") {\n    let a = jstat.uniform.sample(1 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; -a * x + b,\n      (x) =&gt; jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A weaker relationship\") {\n    let a = jstat.uniform.sample(-2 / 3, 2 / 3);\n    let b = jstat.uniform.sample(-6, 6);\n    return make_perturbed_graph(\n      (x) =&gt; a * x + b,\n      (x) =&gt; 4 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"A nonlinear relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; (x - a) * (x - b),\n      (x) =&gt; 0.6 * jstat.randn(),\n      -10,\n      10,\n      100\n    );\n  } else if (s == \"No relationship\") {\n    let a = jstat.uniform.sample(-3, 1);\n    let b = jstat.uniform.sample(1, 3);\n    return make_perturbed_graph(\n      (x) =&gt; 0,\n      (x) =&gt; jstat.uniform.sample(-10, 10),\n      -10,\n      10,\n      100\n    );\n  }\n}\n\n\n\n\n\n\n\nfunction make_perturbed_graph(f, r, a, b, n) {\n  let xs = jstat.arange(n).map(() =&gt; jstat.uniform.sample(a, b));\n  let ys = xs.map((x) =&gt; f(x) + r());\n  let plot = plotter({ width: 500, height: 400, grid: false });\n  jstat.arange(n).forEach((_, i) =&gt; plot.point(xs[i], ys[i]));\n\n  let R = jstat.corrcoeff(xs, ys);\n\n  return html`&lt;div style=\"text-align:center; width:500px\"&gt;R = ${d3.format(\n    \"0.4f\"\n  )(R)}&lt;/div&gt;${plot.node}`;\n}\n\n\n\n\n\n\n\nimport {select} from \"@jashkenas/inputs\"\njstat = require('jstat')\nimport { plotter } from '50dadfdec01c15a8'\nimport { rk4 } from '@mcmcclur/runge-kutta-for-systems-of-odes'\nimport { slider } from \"@jashkenas/inputs\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 5.23: Interaktives Beispiel für Zusammenhangsdiagramme.\n\n\n\nBeispiel 5.5 Sie arbeiten nach wie vor bei einem Online-Auktionshaus, und manchmal gehört Datenanalyse zu Ihren Aufgaben. Daher interessiert Sie, ob welche Variablen mit dem Abschlusspreis (total_pr) im Datensatz mariokart zusammenhängen. Sie verbildlichen die Daten mit R, und zwar nutzen Sie das Paket DataExplorer. Außerdem müssen wir noch die Daten importieren, falls noch nicht getan, s. Listing 3.2. So, jetzt kann die eigentliche Arbeit losgehen. Da Sie sich nur auf einige metrische Variablen konzentrieren wollen, wählen Sie (mit select) nur diese Variablen aus. Dann weisen Sie R an, einen Scatterplot zu malen (plot_scatterplot) und zwar jeweils den Zusammenhang einer der gewählten Variablen mit dem Abschlusspreis (total_pr), da das die Variable ist, die Sie primär interessiert. Das Ergebnis sieht man in Abbildung 5.24. \\(\\square\\)\n\n\nmariokart %&gt;% \n  select(n_bids, start_pr, total_pr) %&gt;% \n  plot_scatterplot(by = \"total_pr\", nrow = 1)\n\n\n\n\n\n\nAbbildung 5.24: Der Zusammenhang einiger metrischer Variablen mit Abschlusspreis\n\n\n\n\nAha. Was sagt uns das Bild? Hm. Es scheint einige Extremwerte zu geben, die dafür sorgen, dass der Rest der Daten recht zusammengequetscht auf dem Bild erscheint. Vielleicht sollten Sie solche Extremwerte lieber entfernen? Sie entscheiden sich, nur Verkäufe mit einem Abschlusspreis von weniger als 100 Dollar anzuschauen (total_pr &lt; 100), s. Listing 5.4.\n\n\n\nListing 5.4: Mariokart ohne Extremwerte\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n\n\n\nDas Ergebnis ist in Abbildung 5.25 zu sehen.\n\nmariokart_no_extreme %&gt;% \n  select(duration, n_bids, start_pr, \n         ship_pr, total_pr, \n         seller_rate, wheels) %&gt;% \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\nAbbildung 5.25: Der Zusammenhang metrischer Variablen mit Abschlusspreis - ohne Extremwerte\n\n\n\n\nOhne Extremwerte schält sich ein deutlicheres Bild hervor: Startpreis (start_pr) und Anzahl der Räder (wheels) scheinen am stärksten mit dem Abschlusspreis zusammenzuhängen. Das Argument by = \"total_pr\" bei plot_scatterplot weist R an, als Y-Variable stets total_pr zu verwenden. Alle übrigen Variablen kommen jeweils einmal als X-Variable vor. \\(\\square\\)\n\nÜbungsaufgabe 5.9  \n\n\nZuammenhang visualisieren\nLösung\n\n\n\nVisualisieren Sie den Zusammenhang der beiden metrischen Variablen start_pr und total_pr. Verwenden Sie den Datensatz ohne Extremwerte wie oben definiert.\n\n\n\nmariokart_no_extreme |&gt; \n  select(start_pr, total_pr) |&gt; \n  plot_scatterplot(by = \"total_pr\")\n\n\n\n\n\n\n\nZuerst wählt man die Spalten (mit select), die man visualisieren möchte, dann ruft man die Funktion plot_scatterplot auf. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#unterschiede-verbildlichen",
    "href": "040-verbildlichen.html#unterschiede-verbildlichen",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.7 Unterschiede verbildlichen",
    "text": "5.7 Unterschiede verbildlichen\n\n5.7.1 Unterschiede bei nominalen Variablen\nGute Nachrichten: Für nominale Variablen bieten sich Balkendiagramme sowohl zur Darstellung von Zusammenhängen als auch von Unterschieden an. Genau genommen zeigt ja Abbildung 5.17 (links) den Unterschied zwischen neuen und gebrauchten Spielen hinsichtlich der Frage, ob Fotos beiliegen. Und wie man in Abbildung 5.17 sieht, ist der Anteil der Spiele mit Foto bei den neuen Spielen höher als bei gebrauchten Spielen.\nAber Freunde lassen Freunde keine Tortendiagramme verwenden.\n\n5.7.2 Unterschiede bei quantitativen Variablen\nEine typische Analysefrage ist, ob sich zwei Gruppen hinsichtlich einer metrischen Zielvariablen deutlich (substanziell) unterscheiden. So untersucht man z.\\(\\,\\)B. oft, ob sich die Mittelwerte zweier Gruppen hinsichtlich der Zielvariablen deutlich unterscheiden. Das hört sich abstrakt an? Am besten wir schauen uns einige Beispiele an, s. Abbildung 5.26.\n\n\n\n\n\n\n\n\n\n(a) Histogramm pro Gruppe\n\n\n\n\n\n\n\n\n\n(b) Boxplot pro Gruppe\n\n\n\n\n\n\nAbbildung 5.26: Unterschiede zwischen zwei Gruppen: Metrische Y-Variable, nominale X-Variable\n\n\nDas linke Teildiagramm von Abbildung 5.26 zeigt das Histogramm von total_pr, getrennt für neue und gebrauchte Spiele, vgl. Abbildung 5.9. Das rechte Teildiagramm zeigt die gleichen Verteilungen, aber mit einer vereinfachten, groberen Darstellungsform, den Boxplot.7 Was ein “deutlicher” (substanzieller, bedeutsamer, relevanter oder signifikanter) Zusammenhang ist, ist keine statistische, sondern inhaltliche Frage, die man mit Sachverstand zum Forschungsgegenstand beantworten muss.\n\n\nDefinition 5.10 (Boxplot) Der Boxplot ist eine Vereinfachung bzw. eine Zusammenfassung eines Histograms. Damit stellt der Boxplot auch eine Verteilung (einer metrischen Variablen) dar. \\(\\square\\)\n\nIn Abbildung 5.27 sieht man die “Übersetzung” von Histogramm (oben) zu einem Boxplot (unten). Ob der Boxplot horizontal oder vertikal steht, ist Ihrem Geschmack überlassen.\n\n\n\n\n\n\n\nAbbildung 5.27: Übersetzung eines Histogramms zu einem Boxplot\n\n\n\n\nSchauen wir uns die “Anatomie” des Boxplots näher an:\n\nDer dicke Strich in der Box zeigt den Median der Verteilung, vgl. Kapitel 6.3.\nDie Enden der Box zeigen das 1. Quartil (41) bzw. das 3. Quartil (54). Damit zeigt die Breite der Box die Streuung der Verteilung an, genauer gesagt die Streuung der inneren 50% der Beobachtungen. Je breiter die Box, desto größer die Streuung. Die Breite der Box nennt man auch den Interquartilsabstand (IQR).\nDie “Antennen” des Boxplots zeigen die Streuung in den kleinsten 25\\(\\,\\)% der Werte (linke Antenne) bzw. die Streuung der größten 25\\(\\,\\)% der Werte (rechte Antenne). Je länger die Antenne, desto größer die Streuung (in den äußeren Vierteln).\nFalls es aber Extremwerte gibt, so sollten die lieber einzeln, separat, außerhalb der Antennen gezeigt werden. Daher ist die Antennenlänge auf die 1.5-fache Länge der Box beschränkt. Werte die außerhalb dieses Bereichs liegen (also mehr als das 1.5-fache der Boxlänge von Q3 entfernt sind) werden mittels eines Punktes dargestellt.\nLiegt der Median-Strich in der Mitte der Box, so ist die Verteilung symmetrisch (bezogen auf die inneren 50\\(\\,\\)% der Werte), liegt der Median-Strich nicht in der Mitte der Box, so ist die Verteilung nicht symmetrisch (d.\\(\\,\\)h. sie ist schief). Gleiches gilt für die Antennenlängen: Sind die Antennen gleich lang, so ist der äußere Teil der Verteilung symmetrisch, andernfalls schief.\n\n\nBeispiel 5.6 In einer vorherigen Analyse haben Sie den Zusammenhang von Abschlusspreis und der Anzahl der Lenkräder untersucht. Jetzt möchten Sie eine sehr ähnliche Fragestellung betrachten: Wie unterscheiden sich die Verkaufspreise je nach Anzahl der beigelegten Lenkräder? Flink erstellen Sie dazu folgendes Diagramm, Abbildung 5.28, links. Es zeigt die Verteilung des Abschlusspreises, aufgebrochen nach Anzahl Lenkräder (by = \"wheels\"). \\(\\square\\)\n\nAber ganz glücklich sind Sie mit dem Diagramm nicht: R hat die Variable wheels komisch aufgeteilt. Es wäre eigentlich ganz einfach, wenn R die Gruppen 0, 1, 2, 3 und 4 aufteilen würde. Aber schaut man sich die Y-Achse (im linken Teildiagramm von Abbildung 5.28) an, so erkennt man, dass R wheels als stetige Zahl betrachtet und nicht in ganze Zahlen gruppiert. Vielleicht wird so gruppiert, dass in jeder Gruppe gleich viele Werte sind? Aber wir möchten jeden einzelnen Wert von wheels (0, 1, 2, 3, 4) als Gruppe verstehen. Mit anderen Worten, wir möchten wheels als nominale Variable definieren. Das kann man mit dem Befehl factor(wheels) erreichen (verpackt in mutate), s. Abbildung 5.28 rechts.\n\nmariokart_no_extreme |&gt; \n  select(total_pr, wheels) %&gt;% \n  # Probieren Sie den Code mit bzw. ohne folgender Zeile:\n  mutate(wheels = factor(wheels)) |&gt;  # wheels als nominale Variable\n  plot_boxplot(by = \"wheels\")  # Boxplot mit \"wheels\" auf der Y-Achse\n\n\n\n\n\n\n\n\n\n\n(a) wheels als metrische Variable\n\n\n\n\n\n\n\n\n\n(b) wheels als nominale Variable\n\n\n\n\n\n\nAbbildung 5.28: Abschlusspreis nach Anzahl von beigelegten Lenkrädern\n\n\nSie schließen aus dem Bild, dass Lenkräder und Preis (positiv) zusammenhängen. Allerdings scheint es wenig Daten für wheels == 4 zu geben. Das prüfen Sie nach:\n\nmariokart_no_extreme %&gt;% \n  count(wheels)\n\n\n  \n\n\n\nTatsächlich gibt es (in mariokart_no_extreme) auch für 3 Lenkräder schon wenig Daten, so dass wir die Belastbarkeit dieses Ergebnisses skeptisch betrachten sollten. Übrigens bezeichnet Sie Ihre Chefin nur noch als “Datengott”.\n\nÜbungsaufgabe 5.10 (Visualisieren Sie den Unterschied im Verkaufspreis zwischen gebrauchten und neuen Spielen.) Es gibt mehrere Diagrammtypen, die sich anbieten; mehrere Lösungen sind also möglich.\nLösung\n\nmariokart_no_extreme |&gt; \n  select(cond, total_pr) |&gt; \n  plot_boxplot(by = \"cond\")\n\n\n\n\n\n\n\nBoxplots sind eine gute Möglichkeit, die Verteilung einer metrischen Variablen, aufgebrochen auf mehrere Gruppen, zu visualisieren. \\(\\square\\)\n\n\n\nÜbungsaufgabe 5.11 (Verkaufspreis im Vergleich) Visualisieren Sie den Unterschied im Verkaufspreis abhängig von ship_pr; betrachten Sie ship_pr als ein Gruppierungsvariable. Interpretieren Sie das Ergebnis.\nLösung\n\nmariokart_no_extreme |&gt; \n  select(ship_pr, total_pr) |&gt; \n  plot_boxplot(by = \"ship_pr\")\n\n\n\n\n\n\n\nplot_boxplot gruppiert metrische Variablen, wie ship_pr automatisch in fünf Gruppen (mit gleichen Ranges). Wir müssen also nichts tun, um die metrische Variable ship_pr in eine Gruppierungsvariable (Faktorvariable) umzuwandeln. Es sieht so aus, als würde der Median zwischen den Gruppen leicht steigen, mit Ausnahme der mittleren Gruppe. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "href": "040-verbildlichen.html#so-lügt-man-mit-statistik",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.8 So lügt man mit Statistik",
    "text": "5.8 So lügt man mit Statistik\nDiagramme werden mitunter eingesetzt, um die Wahrheit “aufzuhübschen”. Achsen zu stauchen, ist ein recht beliebter Trick, s. Abbildung 5.30. Natürlich kann man auch durch “Abschneiden” der Y-Achse einen eindrucksvollen Effekt erzielen, s. Abbildung 5.31. Scheinkorrelationen als “echte”, also kausale Effekte zu verkaufen, ist ein anderer Trick, den man immer mal wieder beobachten kann. Ein Beispiel: Messerli (2012) berichtet von einem Zusammenhang von Schokoladenkonsum und Anzahl von Nobelpreisen (Beobachtungseinheit: Länder), s. Abbildung 5.29. Das ist doch ganz klar: Schoki futtern macht schlau und Nobelpreise! (?) Leider ist hier von einer Scheinkorrelation auszugehen: Auch wenn die beiden Variablen Schokoladenkonsum und Nobelpreise zusammenhängen, heißt das nicht, dass die eine Variable die Ursache und die andere die Wirkung sein muss. So könnte auch eine Drittvariable im Hintergrund die gleichzeitige Ursache von Schokoladenkonsum und Nobelpreise sein, etwa der allgemeine Entwicklungsstand des Landes: In höher entwickelten Ländern wird mehr Schokolade konsumiert und es werden mehr Nobelpreise gewonnen im Vergleich zu Ländern mit geringerem Entwicklungsstand.\n\n\n\n\n\nAbbildung 5.29: Schokoladenkonsum und Nobelpreise\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.30: Strecken und Stauchen der Achse(n), um mit Statistik zu lügen\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Oh nein, dramatischer Einbruch des Umsatzes!\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Kaum der Rede wert, ist nur ein bisschen Schwankung!\n\n\n\n\n\n\nAbbildung 5.31: Abschneiden der Y-Achse, um mit Statistik zu lügen",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#praxisbezug",
    "href": "040-verbildlichen.html#praxisbezug",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.9 Praxisbezug",
    "text": "5.9 Praxisbezug\nEin, wie ich finde, schlagendes Beispiel zur Stärke von Datendiagrammen ist Abbildung 5.32. Das Diagramm zeigt die Häufigkeit von Masern, vor und nach der Einführung der Impfung. Die Daten und die Idee zur Visualisierung gehen auf van Panhuis et al. (2013) zurück.\n\n\n\n\n\nAbbildung 5.32: Häufigkeit von Masern und Impfung in den USA (Moore, 2015)\n\n\nIn der “freien Wildbahn” findet man häufig sog. “Tortendiagramme”. Zwar sind sie beliebt, doch von ihrer Verwendung ist zumeist abzuraten, denn bei Tortenstücken ist es schwer, die Größe zu vergleichen.\nFreunde lassen Freunde keine Tortendiagramme zeichnen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#aufgaben",
    "href": "040-verbildlichen.html#aufgaben",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.10 Aufgaben",
    "text": "5.10 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nboxhist\nmax-corr1\nmax-corr2\nHistogramm-in-Boxplot\nDiamonds-Histogramm-Vergleich2\nBoxplot-Aussagen\nboxplots-de1a\nmovies-vis1\nmovies-vis2\nvis-gapminder\nboxplots-de1a\ndiamonds-histogramm-vergleich\nwozu-balkendiagramm\ndiamonds-histogram\nn-vars-diagram\n\nWeitere Aufgaben zum Thema Datenvisualisierung finden Sie im Datenwerk unter dem Tag vis.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#vertiefung",
    "href": "040-verbildlichen.html#vertiefung",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.11 Vertiefung",
    "text": "5.11 Vertiefung\nMehr Informationen zu DataExplorer finden Sie hier.\n\n5.11.1 Animation\nEine weitere nützliche Art von Visualisierung sind Karten, 3D-Bilder und Animationen. So zeigt z.\\(\\,\\)B. Abbildung 5.33 die Veränderung der Lebenserwartung (in Jahren) über die letzten Dekaden.8\n\n\n\n\n\nAbbildung 5.33: Animation zur Veränderung der Lebenserwartung\n\n\nIn einigen Situation können Animationen zweckdienlich sein. Außerdem sind sie mitunter nett anzuschauen, s. Abbildung 5.34.\n\n\n\n\n\nAbbildung 5.34: Veränderung des Zusammenhangs von Lebenserwartung und Bruttosozialprodukt pro Land, gegliedert nach Kontinenten\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatürlich sind der Fantasie keine Grenzen beim Visualisieren gesetzt, so ist etwa diese Animation ziemlich beeindruckend. 9\n\n5.11.2 Schicke Diagramme\nEin Teil der Diagramme dieses Kapitels wurden mit dem R-Paket ggpubr erstellt. Mit diesem Paket lassen sich einfach ansprechende Datendiagramme erstellen.\n\nlibrary(ggpubr)  # einmalig instalieren nicht vergessen\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\")\n\nMöchte man Mittelwerte vergleichen, so sind Boxplots nicht ideal, da diese ja nicht den Mittelwert, sondern den Median herausstellen. Eine Abhilfe (also eine Darstellung des Mittelwerts) schafft man (z.\\(\\,\\)B.) mit ggpubr und der Funktion ggviolin, s. Abbildung 5.35.\n\nggviolin(mariokart_no_extreme, \n         x = \"cond\", y = \"total_pr\", add = \"mean_sd\") \n\n\n\n\n\n\nAbbildung 5.35: Vergleich der Verteilungen zweier Gruppen mit Mittelwert und Standardabweichung pro Gruppe hervorgehoben\n\n\n\n\nWeitere Varianten zum Violinenplot mit ggpubr finden sich hier.10\nEin “Violinenplot” hat die gleiche Aussage wie ein Dichtediagramm: Je breiter die “Violine”, desto mehr Beobachtungen gibt es an dieser Stelle. Übrigens sind Modelle – und Diagramme sind Modelle – immer eine Vereinfachung, lassen also Informationen weg. Manchmal auch wichtige Informationen.\nDieses Beispiel zeigt, wie etwa Histogramme wichtige Informationen unter den Tisch fallen lassen.11 Ein weiteres R-Paket zur Erstellung ansprechender Datenvisualisierung heißt ggstatsplot.12 Abbildung 5.36 zeigt ein Histogramm, das mit ggstatsplot erstellt wurde.13\n\nlibrary(ggstatsplot)\n\ngghistostats(\n  data       = mariokart_no_extreme,\n  x          = total_pr,\n  xlab       = \"Verkaufspreis\" \n  # results.subtitle = FALSE   # unterdrückt statist. Details\n)\n\n\n\n\n\n\nAbbildung 5.36: Ein Histogramm mit ggstatsplot\n\n\n\n\nDie Menge der statistischen Kennzahlen bei ggstatsplot schindet ordentlich Eindruck. Möchte man auf die Kennzahlen verzichten, so nutzt man den Schalter results.subtitle = FALSE. (Weitere Hinweise finden sich auf der Hilfeseite der Funktion der Funktion.)\n\n👩‍🏫 Ich würde gerne mal Beispiele von schlechten Datendiagrammen sehen.\n\n\n🧑‍🎓 Auf der Seite von Flowingdata findet sich eine nette Liste mit schlechten Datendiagrammen.14\n\n\n5.11.3 Farbwahl\nEinige Überlegungen zur Farbwahl findet sich bei Wilke (2019), Kap. 4. Die Farbpalette von Okabe und Ito ist (vgl. Ichihara et al., 2008) empfehlenswert, das sie über über optisch gut unterscheidbarer und klar benennbare Farben verfügt. Außerdem erlaubt sie bei Sehschwächen die Farben noch recht gut zu unterscheiden, s. Abbildung 5.37. Möchte man sie für Schwarz-Weiß-Druck verwenden, kann man angeben, dass als erste Farbe Schwarz verwendet werden soll; dazu nutzt man den Paramter palette = \"black_first\". Alternativ kann man händisch eine helle Farbe und eine dunkle Farbe als Kontrast aussuchen.\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  ggboxplot(x = \"cond\", y = \"total_pr\", fill = \"cond\", notch = TRUE) +\n  scale_fill_okabeito(palette = \"black_first\")\n  #scale_fill_manual(values = c(\"#0072B2\", \"#E69F00\"))\n\n\n\n\n\n\nAbbildung 5.37: Die Farbpalette von Okabe und Ito: Geeignet bei Farbseh-Schwächen. Außerdem nett anzuschauen. Die Einkerbungen (engl. notches) zeigen ein 95%-Konfidenzintervall für den Median.\n\n\n\n\nMit fill = cond erreicht man, dass die Füllfarbe der Variable cond zugeordnet wird: Jeder Wert von cond (new/used) bekommt eine eigene Farbe. Welche das ist, hängt vom verwendeten Farbschema ab. Hier wird das Farbscheme von Okabe und Ito verwendet (Ichihara et al., 2008).\n\nÜbungsaufgabe 5.12 Schauen Sie sich die Farbpalette von Okabe und Ito einmal näher an, z.\\(\\,\\) so:\n\nlibrary(scales)\nlibrary(see)\nshow_col(okabeito_colors())\n\nDie Füllfarbe eines Diagramms, z.\\(\\,\\) in Abbildung 5.37, können Sie ändern, indem Sie scale_fill_okabeito ersetzen durch scale_fill_manual(values = c(\"#0072B2\", \"#E69F00\")). Probieren Sie dabei verschiedene Farben aus. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#literaturhinweise",
    "href": "040-verbildlichen.html#literaturhinweise",
    "title": "\n5  Daten verbildlichen\n",
    "section": "\n5.12 Literaturhinweise",
    "text": "5.12 Literaturhinweise\nSowohl ggpubr (Kassambara, 2023) als auch DataExplorer (Cui, 2024) (und viele andere R-Pakete) bauen auf dem R-Paket ggplot2 (Wickham, 2016) auf. ggplot2 ist eines der am weitesten ausgearbeiteten Softwarepakete zur Erstellung von Datendiagrammen. Das Buch zur Software (vom Autor von ggplot2) ist empfehlenswert (Wickham, 2016). Eine neuere, gute Einführung in Datenvisualisierung findet sich bei Wilke (2019). Beide Bücher sind kostenfrei online lesbar. Wilke (2019) gibt einen hervorragenden Überblick über praktische Aspekte der Datenvisualisierung; gut geeignet, wenn man mit R arbeitet. In ähnlicher Richtung geht Fisher & Meyer (2018).\nHier ist eine Liste von Büchern zum Thema; dort können Sie bei Interesse tiefer suchen.\n\n\n\n\nAinali. (2007). Standard Deviation Diagram Micro [Artwork]. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17–21.\n\n\nCohen, J. (1992). A Power Primer. Psychological Bulletin, 112(1), 155–159.\n\n\nCui, B. (2024). DataExplorer: Automate Data Exploration and Treatment. https://CRAN.R-project.org/package=DataExplorer\n\n\nFisher, D., & Meyer, M. (2018). Making Data Visual: A Practical Guide to Using Visualization for Insight. O’Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The Dynamics of Human Development Index. The Social Science Journal, 52(3), 331–347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito, K. (2008). Color Universal Design: The Selection of Four Easily Distinguishable Colors for All Color Vision Types. Color Imaging XIII: Processing, Hardcopy, and Applications, 6807, 206–213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024). Imageflip Kermit Meme [Artwork]. https://imgflip.com\n\n\nInternational, T. (2017, Januar 25). Corruption Perceptions Index 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nKassambara, A. (2023). ggpubr: ’ggplot2’ Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr\n\n\nLüdecke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., Thériault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nMoore, B. (2015, April 9). Recreating the Vaccination Heatmaps in R. Benomics. https://benjaminlmoore.wordpress.com/2015/04/09/recreating-the-vaccination-heatmaps-in-r/\n\n\nPatil, I. (2021). Visualizations with statistical details: The ’ggstatsplot’ approach. Journal of Open Source Software, 6(61), 3167. https://doi.org/10.21105/joss.03167\n\n\nScherer, C., Radchuk, V., Staubach, C., Müller, S., Blaum, N., Thulke, H., & Kramer‐Schadt, S. (2019). Seasonal Host Life‐history Processes Fuel Disease Dynamics at Different Spatial Scales. Journal of Animal Ecology, 88(11), 1812–1824. https://doi.org/10.1111/1365-2656.13070\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross, A., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., & Burke, D. S. (2013). Contagious Diseases in the United States from 1888 to the Present. New England Journal of Medicine, 369(22), 2152–2158. https://doi.org/10.1056/NEJMms1215400\n\n\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWilke, C. (2019). Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. O’Reilly. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/Practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "040-verbildlichen.html#footnotes",
    "href": "040-verbildlichen.html#footnotes",
    "title": "\n5  Daten verbildlichen\n",
    "section": "",
    "text": "5↩︎\nGrob gesagt: mariokart %&gt;% plot_density().↩︎\nQuelle: ifes/FOM Hochschule, https://github.com/FOM-ifes/VL-Vorlesungsfolien↩︎\nQuelle: https://observablehq.com/@mcmcclur/the-normal-model↩︎\nQuelle: Aufbauend auf FOM/ifes, Autor: Norman Markgraf↩︎\nQuelle: https://observablehq.com/d/bb7ad3ecfb1ac2a6↩︎\nÜbrigens: Freunde lassen Freunde nicht Balkendiagramme verwenden, um Mittelwerte darzustellen: https://github.com/cxli233/FriendsDontLetFriends#1-friends-dont-let-friends-make-bar-plots-for-means-separation.↩︎\nDer Quellcode der Animation ist hier zu finden: https://gist.github.com/rafapereirabr/0d68f7ccfc3af1680c4c8353cf9ab345.↩︎\nhttps://www.tylermw.com/wp-content/uploads/2019/06/featuredmeasles.mp4↩︎\nhttps://rpkgs.datanovia.com/ggpubr/reference/ggviolin.html↩︎\nhttps://www.autodesk.com/research/publications/same-stats-different-graphs↩︎\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md↩︎\nhttps://github.com/IndrajeetPatil/ggstatsplot/blob/main/README.md#gghistostats↩︎\nhttps://flowingdata.com/category/visualization/ugly-visualization/↩︎",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten verbildlichen</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html",
    "href": "050-zusammenfassen.html",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benötigen Sie die üblichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.\nlibrary(tidyverse)\nlibrary(easystats)\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#einstieg",
    "href": "050-zusammenfassen.html#einstieg",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "6.1.1 Lernziele\n\nSie können gängige Arten von Lagemaße definieren.\nSie können erläutern, inwiefern man ein Lagemaß als ein Modell verstehen kann.\nSie können Lagemaße mit R berechnen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-mw",
    "href": "050-zusammenfassen.html#sec-mw",
    "title": "6  Punktmodelle 1",
    "section": "\n6.2 Mittelwert als Modell",
    "text": "6.2 Mittelwert als Modell\nDer “klassische” Mittelwert (das arithmetische Mittel) ist ein prototypisches Beispiel für ein Modell in der Statistik.\n\nÜbungsaufgabe 6.1 Welche Vorstellung haben Sie, wenn Sie hören, dass der “typische deutsche Mann” 1.80 m groß ist (vgl. Roser et al., 2013)?\n\nDie Hälfte der Männer ist größer als 1.80\\(\\,\\)m, die andere Hälfte kleiner.\nDas arithmetische Mittel der Männer beträgt 1.80\\(\\,\\)m.\nDie meisten Männer sind 1.80\\(\\,\\)m groß.\nEtwas anderes.\nKeine Ahnung! \\(\\square\\)\n\n\n\n\nÜbungsaufgabe 6.2 Laut dem Statistischen Bundesamt (2023-003-27) beträgt der Wert der mittleren Größe deutscher Frauen etwa 1.66\\(\\,\\)m, also 14\\(\\,\\)cm weniger als bei Männern.1 \\(\\square\\)\n\n\nFrage\nAntwort\n\n\n\nIst das viel?\n\nja\nnein\nkommt drauf an\nweiß nicht \\(\\square\\)\n\n\n\n\nAuf diese Frage gibt es keine Antwort, zumindest nicht ohne weitere Annahmen. So könnte man z.\\(\\,\\)B. sagen, “mehr als 5 cm sind viel”. So eine Entscheidung ist aber keine statistische Angelegenheit, sondern eine inhaltliche.\n\n\n\n\n\nBeispiel 6.1 (Beispiel zum Mittelwert) Ein Statistikkurs besteht aus drei Studentinnen: Anna, Berta und Carla. Sie haben gerade ihre Noten in der Klausur erfahren. Anna hat eine 1, Berta eine 2 und Carla eine 3. Der Durchschnitt (das arithmetische Mittel, \\(\\varnothing\\)) beträgt: 2. \\(\\square\\)\n\n\n🧑‍🎓 Zu easy!\n\n\n🧑‍🏫 Schon gut! Chill mal. Wird gleich spannender.\n\nDie Rechenregel zum Mittelwert lautet:\n\nAddiere alle Werte\nTeile durch die Anzahl der Werte\nFertig!\n\nEtwas abstrakter kann man Beispiel 6.1 in folgendem Schaubild darstellen, s. Abbildung 6.1.\n\n\n\n\n\nAbbildung 6.1: Visualisierung von Beispiel 6.1\n\n\nDas Beispiel zeigt uns: Der Mittelwert eines Vektors \\(X\\) ist die Zahl, die \\(n\\) mal multipliziert, gleich ist mit der Summe der \\(n\\) Elemente von \\(X\\). Der Nutzen des Mittelwerts liegt darin, dass er uns ein Bild gibt (ein Modell ist!) für die “typische Note” im Statistikkurs, s. Abbildung 6.5.\n\n\n\n\n\n\n\n\nAbbildung 6.2: Der Mittelwert als “typisches Element” eines Vektors\n\n\n\nDer Nutzen des Mittelwerts liegt darin, dass er einen Vektor (eine “Datenreihe”) zu einen “typischen Vertreter” zusammenfasst. Er ist typisch in dem Sinne, als dass die Werte aller Merkmalsträger in gleichem Maße einfließen. Er gibt uns eine (mögliche) Vorstellung (ein Modell!), wie wir uns die Werte der Datenreihe vorstellen sollen. Eine nützliche Anschauung zum Mittelwert ist die Vorstellung des Mittelwerts als eine ausbalancierte Wippe, s. Abbildung 6.3. In “Mathe-Sprech” bezeichnet man den Mittelwert häufig mit \\(\\bar{x}\\) und schreibt die Rechenregel so, s. Gleichung 6.1.\n\n\n\n\n\nAbbildung 6.3: Mittelwert als ausbalancierte Wippe mit Mittelwert 3 (Maphry, 2009)\n\n\n\\[\\bar {x} :=\\frac{1}{n} \\sum_{i=1}^{n}{x_{i}}=\\frac {x_{1}+x_{2}+\\dotsb +x_{n}} {n} \\tag{6.1}\\]\n\nDefinition 6.1 (Mittelwert) Der Mittelwert (MW, mean) von \\(X\\) (präziser: das arithmetische Mittel des Merkmals \\(X\\)) ist definiert als die Summe der Elemente von \\(X\\) geteilt durch deren Anzahl, \\(n\\). Den Mittelwert von \\(X\\) bezeichnet man auch mit \\(\\bar {x}\\). \\(\\square\\)\n\n\nBeispiel 6.2 Angenommen, wir haben eine Reihe von Noten: 1, 2, 3. Der Mittelwert der Noten beträgt dann 2: \\(\\bar{X} = \\frac{1}{3}\\sum (1+2+3) = 6/3 = 2\\). \\(\\square\\)\n\nDa der Mittelwert eine zentrale Rolle spielt in der Statistik, sollten wir ihn uns noch etwas genauer anschauen. In s. Abbildung 6.4 sehen wir die Noten von (dieses Mal) vier Studentinnen. Die gestrichelte horizontale Linie zeigt den Mittelwert der vier Noten. Die schwarzen Punkte sind die Daten, in dem Fall die einzelnen Noten. Die vertikalen Linien zeigen die Abweichungen der Noten zum Mittelwert.\nBezeichnen wir die Abweichung – auch als “Fehler”, “Rest” oder “Residuum” bezeichnet – der \\(i\\)-ten Person mit \\(\\color{errorcol}{\\text{e}_i}\\) (e wie engl. error, Fehler) und die \\(i\\)-te Note mit \\(\\color{ycol}{y_i}\\), so können wir mit Gleichung 6.2 festhalten:\n\\[\\color{ycol}{\\text{y}_i} \\color{black}{ = } \\color{modelcol}{\\;\\bar{x}\\;} + \\color{errorcol}{\\;\\text{e}_i} \\tag{6.2}\\]\nAnders ausgedrückt (s. Gleichung 6.3):\n\\[\\color{ycol}{\\text{Daten}} \\color{black}{ = } \\color{modelcol}{\\text{Modell}} +\n\\color{errorcol}{\\text{Rest}} \\tag{6.3}\\]\nDer Mittelwert ist hier unser Modell der Daten. Wie gesagt: Ein Modell ist eine vereinfachte (zusammengefasste) Beschreibung einer Datenreihe. Um Modelle darzustellen, wird in der Datenanalyse häufig folgende Art von Modellgleichung verwendet, s. Gleichung 6.4.\n\\[\\color{modelcol}{\\hat{y}} \\sim \\color{xcol}{\\text{ x}} \\tag{6.4}\\]\nLies: “Der Modellwert \\(\\color{modelcol}{\\hat{y}}\\) ist eine Funktion der Variable \\(\\color{xcol}{\\text{x}}\\)”. Der Kringel “~” soll also hier heißen “ist eine Funktion von”. Das “Kringel” oder die “Welle” ~ nennt man auch “Tilde”.\nMit \\(\\color{modelcol}{\\hat{y}}\\) ist die vorhergesagte bzw. die zu erklärende Variable (synonym: AV, Output-Variable, Zielvariable) gemeint. Das “Dach” über dem \\(\\color{ycol}{\\text{y}}\\) bedeutet “vorhergesagter Y-Wert” oder “Y-Wert laut dem Modell”. Der tatsächliche, beobachtete Wert \\(\\color{ycol}{\\text{y}}\\) setzt sich zusammen aus dem Modellwert \\(\\color{modelcol}{\\text{m}}\\) plus einem Fehler \\(\\color{errorcol}{\\text{e}}\\), s. Gleichung 6.5.\n\\[\\color{ycol}{y} \\color{black}{\\, = \\,} \\color{modelcol}{\\text{m}} + \\color{errorcol}{\\text{e}} \\tag{6.5}\\]\nAnstelle von \\(\\color{modelcol}{\\text{m}}\\) schreibt man auch \\(\\color{modelcol}{\\hat{y}}\\) (“y-Dach”). In diesem Fall ist das Modell einfach gleich dem Mittelwert (und nicht irgendeiner Funktion des Mittelwerts), so dass wir mit Gleichung 6.6 schreiben können:\n\\[\\color{ycol}{y}  \\color{black}{\\, =\\, } \\color{modelcol}{\\bar{x}} + \\color{errorcol}{e} \\tag{6.6}\\]\nDie Zielvariable \\(\\color{ycol}{\\text{y}}\\) wird also durch ihren eigenen Mittelwert erklärt, außer gehen wir von einem Fehler \\(\\color{errorcol}e\\) in unseren Modellvorhersagen aus. Nobody is perfect. In späteren Kapiteln werden wir andere Variablen heranziehen, um die Zielvariable zu erklären. Würden wir z.\\(\\,\\)B. sagen wollen, dass wir \\(\\color{ycol}{\\text{y}}\\) als Funktion einer Variable \\(\\color{xcol}{X}\\) erklären, so würden wir schreiben (s. Gleichung 6.7):\n\\[\\color{modelcol}{\\bar{y}} \\color{black}  {\\, \\sim \\,} \\color{xcol}{\\text{ x}} \\tag{6.7}\\]\nDa wir im Moment aber keine andere Variablen bemühen, um \\(\\color{ycol}{\\text{y}}\\) zu erklären, schreibt man mit Gleichung 6.8 auch:\n\\[\\color{modelcol}{\\bar{y}}\\;\\;  \\color{black}{\\sim \\; 1} \\tag{6.8}\\]\nDiese Schreibweise sieht anfangs verwirrend aus. Die \\(1\\) soll aber nur zeigen, dass wir keine andere Variable zur Erklärung von \\(\\color{ycol}{\\text{y}}\\) verwenden, daher steht hier kein Buchstabe, sondern eine einfache \\(1\\). Der mathematische Hintergrund liegt in der Art, wie man Matrizen multipliziert.\n\nBeispiel 6.3 (Noten, Mittelwert und Abweichung) Vier Studentinnen – Anna, Berta, Carl, Dani – haben ihre Statistik-Klausur zurückbekommen (Schluck). Die Noten sehen Sie in Abbildung 6.4; gar nicht so schlecht ausgefallen. Außerdem ist der Mittelwert (gestrichelte horizontale Linie) sowie die Abweichungen Residuen, Fehler; häufig mit \\(e\\) wie error bezeichnet) der einzelnen Noten vom Mittelwert eingezeichnet. \\(\\square\\)\n\nSchauen Sie sich die Abweichungsbalken in Abbildung 6.4 einmal genauer an. Jetzt stellen Sie sich vor, Sie würden die vom Mittelwert nach oben ragenden Balkenlängen aneinanderlegen (das sind die gestrichelten. Können Sie sich das vorstellen? Jetzt legen Sie auch noch die Abweichungsbalken, die nach unten ragen, aneinander (die mit den durchgezogenen Linien). Wer viel Phantasie hat, erkennt (sieht), dass die Gesamtlänge der “nach oben ragenden Balken” identisch ist zur Gesamtlänge der nach “unten ragenden Balken”. Gleichung 6.9 drückt das präziser und ohne Ihre Phantasie zu strapazieren aus.\n\\[\\sum_{i=1}^n (x_i-\\bar{x})=\\sum_{i=1}^n x_i - \\sum_{i=1}^n \\bar{x} = n\\cdot \\bar{x} - n\\cdot \\bar{x}=0 \\tag{6.9}\\]\nWie man in Gleichung 6.9 sieht, ist die Summe der Abweichungen vom Mittelwert Null.\n\n\n\n\n\n\n\nAbbildung 6.4: Der Mittelwert als horizontale (gestrichelte) Linie. Die vertikalen Linien zeigen die Abweichungen der einzelnen Werte zum Mittelwert. Die Abweichungen summieren sich zu Null auf.\n\n\n\n\n\nÜbungsaufgabe 6.3 Was schätzen Sie, wie hoch das mittlere Vermögen (arithmetisches Mittel) der Haushalte in Deutschland in etwa ist (im Jahr 2021 auf Basis einer Umfrage) (Bundesbank, 2023)?2 \\(\\square\\)\n\n50.000 Euro\n100.000 Euro\n150.000 Euro\n200.000 Euro\n300.000 Euro\n\n\n\nBeispiel 6.4 (Der wertvollste Fußballer der Welt in Ihrem Hörsaal) Kommt der wertvollste Fußballspieler der Welt in Ihren Hörsaal, sagen wir, es ist Kylian Mbappé (Transfermarkt, 2024). Sein Jahreseinkommen (2023) liegt bei ca. 120 Millionen Euro (Arad, 2024). Der Fußballer ist gut gelaunt:\n\n🦹 Hey Leute, wie geht’s denn so! Wie viel Kohle habt ihr eigentlich so?\n\n\n🧑‍🎓 Äh, wir studieren und verdienen fast nix!\n\nDie 100 Studis im Hörsaal schauen verdattert aus der Wäsche: Was ist das für eine komische Frage!? Aber zumindest verteilt der Fußballspieler Autogramme.\n\n\nÜbungsaufgabe 6.4 (Mittleres Einkommen im Hörsaal, mit Kylian Mbappé) Schätzen Sie – im Kopf – das mittlere Vermögen im Hörsaal, gehen Sie davon aus, dass alle der 100 Studierenden jeweils 1000 Euro im Jahr verdienen. \\(\\square\\)\n\nIn R kann man das mittlere Einkommen (präziser: das arithmetische Mittel des Einkommens) wie folgt berechnen, s. Listing 6.1. (Die Details der Syntax, z.\\(\\,\\)B. der Befehl rep, sind von geringer Bedeutung.)\n\n\nListing 6.1: Wir simulieren Einkommen von 100 Studis plus Mbappé.\n\n\nset.seed(42)  # Zufallszahlen festlegen, hier nicht so wichtig\neinkommen_studis &lt;- rep(x = 1000, times = 100)  # \"rep\" wie \"repeat\": wiederhole 1000 USD 100-mal\neinkommen &lt;- c(einkommen_studis, 120*1e6)  # 100 Studis mit 1000, 1 Mbappé mit 120 Mio\neinkommen_mw &lt;- mean(einkommen)\neinkommen_mw\n## [1] 1189109\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\n1 Million hat 6 Nullen hinter der führenden Eins: 1000000. In Taschenrechner- oder Computerschreibweise: 1 Mio = 1e6, das 1e6 ist zu lesen als “1 Mal 10 hoch 6, also mit 6 im Exponenten”.\n\n\nDer Mittelwert im Hörsaal beträgt also 1,189,109 Euro, etwas mehr als eine Million. Ist das ein gutes Modell für das typische Vermögen im Hörsaal?3\n\n6.2.1 Der Mittelwert als lineares Modell\nMan kann den Mittelwert als Gerade einzeichnen, s. Abbildung 6.5, bzw. als Gerade begreifen. Insofern kann man vom Mittelwert auch als lineares Modell sprechen.\n\nDefinition 6.2 (Lineares Modell) Ein lineares Modell beschreibt die Daten durch eine Gerade. Es erklärt die Daten anhand einer Geraden. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Mit Extremwerten\n\n\n\n\n\n\n\n\n\n(b) Ohne Extremwerte (&lt;100 Euro)\n\n\n\n\n\n\nAbbildung 6.5: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet; einmal mit Extremwerte (a), einmal ohne (b).\n\n\nAbbildung 6.5 zeigt den Mittelwert des Verkaufspreises der Mariokart-Spiele (total_pr), einmal mit (farbig markierten) Extremwerten (a) bzw. einmal ohne Extremwerte (b).\n\nDefinition 6.3 (Extremwert) Ein Extremwert (Ausreißer; outlier) ist eine Beobachtung, deren Wert deutlich vom Großteil der anderen Beobachtungen im Datensatz abweicht, z.\\(\\,\\)B. viel größer ist. \\(\\square\\)\n\nBerechnen wir mal den Mittelwert von einkommen mit R mit dem Befehl lm.\n\nlm(einkommen ~ 1)  # lm wie \"lineares Modell\" oder engl. \"linear model\"\n## \n## Call:\n## lm(formula = einkommen ~ 1)\n## \n## Coefficients:\n## (Intercept)  \n##     1189109\n\nDer Befehl lm gibt hier mit der Ausgabe Coeffients (Koeffizient) einen einzelnen Wert zurück und zwar den Mittelwert von einkommen, vgl. auch Listing 6.1. Dieser Wert wird als Achsenabschnitt (engl. intercept) bezeichnet. Das wird verständlich, wenn man z.\\(\\,\\)B. in Abbildung 6.5 sieht, dass die Gerade (des Mittelwerts) genau an diesem Punkt die Y-Achse schneidet. Die Syntax des Befehls lm() sieht etwas merkwürdig aus. Ignorieren Sie das fürs Erste, wir besprechen das später (Kapitel 9) ausführlich. lm steht übrigens für “lineares Modell”.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-median",
    "href": "050-zusammenfassen.html#sec-median",
    "title": "6  Punktmodelle 1",
    "section": "\n6.3 Der Median als Modell",
    "text": "6.3 Der Median als Modell\n\n🧑‍🎓 Hey, der Mittelwert ist doch Quatsch! Das ist gar kein typischer Wert für die Menschen im Hörsaal. Weder für Mbappé, noch für uns Studis!\n\n\n🧑‍🏫 Ja, da habt ihr Recht.\n\n\n⚽ Die Welt ist schon ungerecht!\n\nAbbildung 6.6 stellt die Verteilung des Einkommens im Hörsaal dar. Zur Erinnerung: 4.0+e07 bedeutet \\(4 \\cdot 10^{07} = 40000000\\), eine 4 gefolgt von 7 Nullen.  \n\n\n\n\n\n\n\n\nAbbildung 6.6: Die Einkommensverteilung im Hörsaal\n\n\n\n\n\nDer Mittelwert ist Hörsaal ist nicht typisch für die Menschen im Hörsaal: Weder für Mbappé, noch für die Studis. Genau genommen ist der Mittelwert in diesem Fall ziemlich nutzlos. Der Mittelwert ist anfällig für Extremwerte: Gibt es einen Extremwert in einer Datenreihe, so spiegelt der Mittelwert stark diesen Wert wider und weniger die Mehrheit der gemäßigten Werte. Man sagt, der Mittelwert ist nicht robust (gegenüber Extremwerten).\n\n\n\n\n\n\nWichtig\n\n\n\nBei (sehr) schiefen Verteilungen (s. Abbildung 6.6) ist der Mittelwert (sehr) wenig aussagekräftig, da er nicht mehr “typische” Werte für die Merkmalsträger beschreibt.\n\n\n\nBeispiel 6.5 (Das Median-Einkommen einiger Studentinnen) Fünf Studentinnen tauschen sich über ihr Einkommen aus, s. Abbildung 6.7, links. Es handelt sich um eine schiefe Verteilung. Wir könnten jetzt behaupten, dass Carla das typische Einkommen (für diese Datenreihe) aufweist, da es genauso viele Studentinnen gibt, die mehr verdienen, wie solche, die weniger verdienen. \\(\\square\\)\n\n\n\n\n\n\n\n\n\nAbbildung 6.7: Das Einkommen einiger Studentinnen sowie der Mittelwert (MW) ihres Einkommens\n\n\n\n\n\n\nDefinition 6.4 (Median) Die Merkmalsausprägung, die bei (aufsteigend) sortierten Beobachtungen in der Mitte liegt, nennt man Median. \\(\\square\\)\n\n\nÜbungsaufgabe 6.5 (Alle mal aufstehen) Auf Geheiß der Lehrkraft stehen jetzt alle Studis bitte auf und sortieren sich der Größe nach im Raum, schön in einer Reihe aufgestellt. Die Körpergröße der Person in der Mitte der Reihe, zu der also gleich viele Personen zu links wie zu rechts stehen, das ist der Medien dieser Datenreihe, vgl. Abbildung 6.8. \\(\\square\\)\n\nDer Median ist robust gegenüber Extremwerten: Fügt man Extremwerte zu einer Verteilung hinzu, ändert sich der Median zumeist (deutlich) weniger als der Mittelwert. Abbildung 6.8 stellt den Median schematisch dar.\n\n\n\n\n\n\n1.60 m\n\n\n\n\n\n1.72 m\n\n\n\n\n\n1.79 m\n\n\n\n\n\n1.94\n\n\n\n\n\n2.12 m\n\n\n\n\n\nAbbildung 6.8: Der Median als der Wert des “mittleren” Objekts, wenn die Objekte aufsteigend sortiert sind. Es gibt genauso viele Objekte mit kleinerem Wert wie mit größerem Wert als der Median. In dieser Abbildung ist der Median (1.79 m) farbig markiert.\n\n\nBei geradem \\(n\\) werden die beiden mittleren Werte betrachtet und das arithmetische Mittel aus diesen beiden Werten gebildet.\n\nBeispiel 6.6 Bei der Messreihe 1,2,3 beträgt der Median 2. Bei der Messreihe 1, 2 beträgt der Median 1.5. \\(\\square\\)\n\n\nÜbungsaufgabe 6.6 (Emma wird reich) Durch ein geniales Patent wird Emma steinreich. Ihr Einkommen erhöht sich um das Hundertfache. Wie verändert sich der Median?4 \\(\\square\\)\n\n\nÜbungsaufgabe 6.7 (Wer ist mehr “mittel”? Median oder Mittelwert?)  \n\n🧑‍🎓 Das arithmetische Mittel sollte Mittelwert heißen, weil es die Mitte des Abstands zweier Zahlen widerspiegelt, also z.\\(\\,\\)B. von 1 und 10 ist die Mitte 5.5 – also genau beim Mittelwert!\n\n\n👩 Moment! Der Median und nur der Median zeigt den mittleren Messwert! Links und rechts sind gleich viele Messwerte, wenn man die Werte der Größe nach sortiert. Also liegt der Median genau in der Mitte!\n\nNehmen Sie Stellung zu dieser Diskussion! \\(\\square\\)\n\n\nBeispiel 6.7 (Ein “mittlerer” Preis für Mariokart) Der Mittelwert (das arithmetische Mittel) und der Median für das Start-Gebot (start_pr) von Mariokart-Spielen sind nicht gleich, der Mittelwert ist höher als der Median.\n\nmariokart %&gt;% \n  summarise(price_mw = mean(start_pr),\n            price_md = median(start_pr))\n\n\n\nprice_mw\nprice_md\n\n\n8.8\n1\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 6.9: Das Startgebot bei Mariokart-Spielen ist schief verteilt: Median und Mittelwert sind unterschiedlich\n\n\n\n\nWie man sieht, ist der Mittelwert größer als der Median, s. Abbildung 6.9. \\(\\square\\)\n\nKlaffen Mittelwert und Median auseinander, so liegt eine schiefe Verteilung vor. Ist der Mittelwert größer als der Median, so nennt man die Verteilung rechtsschief. Bei schiefen Verteilungen ist der Median dem Mittelwert als Modell für den “typischen Wert” vorzuziehen.\n\nÜbungsaufgabe 6.8 (Mariokart ohne Extremwerte) Im Datensatz mariokart gibt es einige wenige Spiele, die für einen vergleichsweise hohen Preis verkauft wurden. Diese Extremwerte verzerren den mittleren Verkaufspreis möglicherweise über die Gebühr.\nEntfernen Sie diese Werte und berechnen Sie dann Mittelwert und Median erneut. Vergleichen Sie die Ergebnisse.\nLösung\n\nmariokart_no_extreme &lt;- \nmariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n# mit Extremwerten:\nmariokart |&gt; \n  summarise(total_pr_mittelwert = mean(total_pr),\n            total_pr_median = median(total_pr))\n\n# ohne Extremwerte:\nmariokart_no_extreme |&gt; \n  summarise(total_pr_mittelwert_no_extreme = mean(total_pr),\n            total_pr_median_no_extreme = median(total_pr))\n\n\n\ntotal_pr_mittelwert\ntotal_pr_median\n\n\n50\n46\n\n\n\n\ntotal_pr_mittelwert_no_extreme\ntotal_pr_median_no_extreme\n\n\n47\n46\n\n\n\n\nWie man sieht, verändert sich der Mittelwert, wenn man die Extremwerte entfernt. Für den Median trifft das nicht zu, er bleibt, wo er ist. \\(\\square\\)\n\n\nÜbungsaufgabe 6.9 (Das mediane Vermögen in Deutschland) Was schätzen Sie, wie hoch das mediane Vermögen der Haushalte in Deutschland im Jahr 2021 in etwa war (Bundesbank, 2023)?5\n\n50 Tsd Euro\n100 Tsd Euro\n150 Tsd Euro\n200 Tsd Euro\n300 Tsd Euro\\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#quantile",
    "href": "050-zusammenfassen.html#quantile",
    "title": "6  Punktmodelle 1",
    "section": "\n6.4 Quantile",
    "text": "6.4 Quantile\nDer Median teilt eine Verteilung in eine untere und ein obere Hälfte. Er markiert sozusagen eine “50-Prozent-Marke” (der aufsteigend sortierten Werte). Betrachten wir einmal nur alle Spiele, die für weniger als 100 Euro verkauft wurden (total_pr, finales Verkaufsgebot), s. Abbildung 6.10. 50\\(\\,\\)% dieser Spiele wurden für weniger als ca. 46 Euro verkauft und 50% für mehr als 46 Euro. Der Median beträgt als 46 Euro.\nJetzt könnten wir nur die günstigere Hälfte betrachten und wieder nach dem Median fragen (d.\\(\\,\\)h. total_pr &lt; 46). Dieser “Median der billigeren Hälfte” grenzt damit das insgesamt billigste Viertel vom Rest der Verkaufsgebote ab. In unserem Datensatz liegt dieser Wert bei ca. 41 Euro. Entsprechend kann man nach dem Wert fragen, der das oberste Viertel vom Rest der Verkaufsgebote abtrennt. Dieser Wert liegt bei ca. 54 Euro. Jetzt könnte man sagen, hey, warum nur in 25\\(\\,\\)%-Stücke die Verteilung aufteilen? Warum nicht in 10\\(\\,\\)%-Schritten? Oder vielleicht in 1\\(\\,\\)%-Schritten oder in sonstigen Schritten? Wo die Quartile in 25\\(\\,\\)%-Schritten aufteilen, teilt ein Quantil in \\(p\\)-Prozent-Schritten auf. S. Abbildung 6.11 dazu.\n\nDefinition 6.5 (Quartile) Sortiert man die Daten aufsteigend, so nennt man den Wert, der das Viertel mit den kleisten Wert vom Rest der Daten trennt das erste Quartil (Q1, 25\\(\\,\\)%). Den Median nennt man das zweite Quartil (Q2, 50\\(\\,\\)%). Entsprechend heißt der Wert, der die drei Viertel kleinsten Werte vom oberen Viertel abtrennt, das dritte Quartil (Q3, 75\\(\\,\\)%). \\(\\square\\)\n\n\nBeispiel 6.8 (Quartile des Verkaufsgebot) Abbildung 6.10 zeigt die Quartile für das Verkaufsgebot. \\(\\square\\)\n\n\nDefinition 6.6 (Dezile) Die neun Quantile \\(p= 0.1, 0.2, \\ldots, 1\\), die die Verteilung in 10 gleich große Teile unterteilen, nennt man Dezile. “Gleich groß” heißt, dass in jedem Dezil gleich viele Werte (nämlich 10 %) liegen. \\(\\square\\)\n\nAbbildung 6.10 zeigt das 1. (Q1), das 2. (Median) und das 3. Quartil für den Datensatz mariokart2.\n\n\n\n\n\n\n\nAbbildung 6.10: Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro) in einem Dichtediagramm\n\n\n\n\n\nDefinition 6.7 (Quantile) Ein \\(p\\)-Quantil ist der Wert, der von \\(p\\) Prozent der Werte nicht überschritten wird. Ein Quantil ist ein Oberbegriff für Quartile, Dezile etc. \\(\\square\\)\n\nQuantile kann man in R mit dem Befehl quantile berechnen:\n\nmariokart %&gt;% \n  filter(total_pr &lt; 100) %&gt;% \n  summarise(\n    q25 = quantile(total_pr, .25),  # 1. Quartil\n    q50 = quantile(total_pr, .50),  # 2. Quartil\n    q75 = quantile(total_pr, .75))  # 3. Quartil\n\nAbbildung 6.11 stellt einige Quantile animiert dar.\n\n\n\n\n25%-Schritte: Quartile\n10%-Schritte: Dezile\nPercentile: 1%-Schritte\n\n\n\n\n\nQuartile\n\n\n\n\n\nDezile\n\n\n\n\n\nPerzentile\n\n\n\n\n\n\nAbbildung 6.11: Verschiedene Quantile animiert\n\n\nAbbildung 6.12 visualisiert verschiedene Quantile. Man beachte, dass alle Regionen gleichgroße Flächen aufweisen.\n\n\n\n\n\n\n\n\n\n(a) 10%-Schritte: Dezile\n\n\n\n\n\n\n\n\n\n(b) 1%-Schritte: Perzentile\n\n\n\n\n\n\nAbbildung 6.12: Verschiedene Quantile visualisiert\n\n\n\n6.4.1 Beispiel: Quantile der IQ-Verteilung\nZur Erinnerung: Die Verteilung des IQ wird gewöhnlich als normalverteilt mit Mittelwert gleich 100 und Streuung gleich 15 angenommen.\nBetrachten wir einige häufig verwendete Quantile für die IQ-Verteilung, s. Abbildung 6.13.\n\n\n\n\n\n\n\nAbbildung 6.13: Verschiedene Quantile der Normalverteilung",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#sec-lage",
    "href": "050-zusammenfassen.html#sec-lage",
    "title": "6  Punktmodelle 1",
    "section": "\n6.5 Lagemaße",
    "text": "6.5 Lagemaße\n\n🧑‍🎓 Was ist der Oberbegriff für Median, Mittelwert und so weiter?\n\n\n🧑‍🏫 Gute Frage! Wie würden Sie ihn nennen?\n\n\nDefinition 6.8 (Lagemaß) Ein Lagemaß (synonym: Maß der zentralen Tendenz) für eine Verteilung gibt einen Vorschlag, welchen Wert der Verteilung wir als typisch, normal, erwartbar, repräsentativ oder “mittel” ansehen sollten. \\(\\square\\)\n\nGebräuchliche Lagemaße sind:\n\nMittelwert (arithmetisches Mittel)\nMedian\nQuantile wie z.\\(\\,\\)B. Quartile\nMinimum (kleinster Wert)\nMaximum (größter Wert)\nModus (häufigster Wert)\n\nBerechnen wir Lagemaße für den Mariokart-Datensatz, z.\\(\\,\\)B. mit describe_distribution(mariokart), s. Listing 6.2. Es ist übrigens egal, wie Sie die Variablen benennen, die Sie berechnen: mw oder mittelwert oder mean oder mein_krasser_variablenname – alles okay!\n\n\n\nListing 6.2: Syntax zur Berechnung von Lagemaßen\n\ndescribe_distribution(mariokart) |&gt;  \n  # Einige Spalten interessieren uns hier nicht:\n  select(-Skewness, -Kurtosis, -n, n_Missing)\n\n\n\n\nHäufig möchte man Statistiken wie Lagemaße für mehrere Teilgruppen – z.\\(\\,\\)B. Mittlere Körpergröße von Frauen vs. mittlere Körpergröße von Männern – berechnen und dann vergleichen. Die zugrundeliegende stehende Forschungsfrage könnte lauten: “Unterscheidet sich der Mittelwert der Körpergröße von Frauen und Männern?” Oder vielleicht: “Hängt das Geschlecht mit der Körpergröße zusammen?” Anders ausgedrückt: Körpergröße \\(y\\) ist eine Funktion des Geschlechts \\(G\\). Die Modellformel könnte also lauten: \\({y} \\;{ \\sim } \\; {G}\\). Gruppierte Lagemaße lassen sich in R z.\\(\\,\\)B. so berechnen, s. Listing 6.3.\n\n\n\nListing 6.3: Gruppierte Lagemaße\n\nmariokart_lagemaße_gruppiert &lt;-\n  mariokart %&gt;% \n  group_by(wheels) %&gt;%  # neue Zeile, der Rest ist gleich!\n  summarise(mw = mean(total_pr))\n\n\n\n\n\n\n\nTabelle 6.1: Gruppierte Mittelwerte\n\n\n\n\nwheels\nmw\n\n\n\n0\n41\n\n\n1\n44\n\n\n2\n61\n\n\n3\n70\n\n\n4\n65\n\n\n\n\n\n\n\n\nAbbildung 6.15 zeigt ein Beispiel für ungruppierte (links) bzw. gruppierte (rechts) Mittelwerte; vgl. Abbildung 6.5. Wie man in dem Diagramm sieht, kann das Residuum kleiner werden bei einer Gruppierung (im Vergleich zu einem ungruppierten, “globalen” Mittelwert): Innerhalb der Gruppe ohne Lenkräder und innerhalb der Gruppe mit 2 Lenkrädern sind die Abweichungen zu ihrem Gruppen-Mittelwert relativ gering – im Vergleich zu den Abweichungen der Preise zum ungruppierten Mittelwert.\n\nDefinition 6.9 (Punktmodell) Ein Modell, welches für alle Beobachtungen ein und denselben Wert annimmt (vorhersagt), heißt Punktmodell. Anders gesagt, fasst ein Punktmodell eine Wertereihe (häufig ist das eine Tabellenspalte) zu einer einzelnen Zahl zusammen, einem “Punkt” in diesem Sinne, s. Abbildung 6.14. \\(\\square\\)\n\n\n\n\n\n\nAbbildung 6.14: Die deskriptive Statistik fasst eine Spalte zu einer einzelnen Zahl zusammen.\n\n\nMittelwert, Median und Quartile sind Beispiele für Punktmodelle: Sie fassen eine Verteilung zu einem einzelnen Wert zusammen und geben uns ein “Bild” der Daten, machen sie uns verständlich – sie sind uns also ein Modell.\n\n\n\n\n\n\n\n\n\n\n(a) ungruppiert\n\n\n\n\n \n\n\n\n\n\n\n\n(b) gruppiert\n\n\n\n\n\n\nAbbildung 6.15: Der mittlere Preis von Mariokart-Spielen als horizontale Gerade eingezeichnet. (a) ungruppiert; (b) gruppiert nach Anzahl der Lenkräder.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "href": "050-zusammenfassen.html#wie-man-mit-statistik-lügt",
    "title": "6  Punktmodelle 1",
    "section": "\n6.6 Wie man mit Statistik lügt",
    "text": "6.6 Wie man mit Statistik lügt\nEs heißt, mit Statistik könne man vortrefflich lügen. Woran liegt das? Der Grund ist, dass die Statistik Freiheitsgrade lässt: Es gibt nicht nur einen richtigen Weg, um eine statistische Analyse durchzuführen. Viele Wege führen nach Rom (aber nicht alle). Um Manipulationsversuche abzuwehren oder einfache Fehler und Unschärfen ohne böse Absicht aufzudecken, gibt es ein probates Gegenmittel: Transparenz. Analysen sollten transparent sein: Das Vorgehen und die zugrundeliegenden Entscheidungen sollte man offenlegen. Hier ist eine (nicht abschließende!) Checkliste, was Sie nachprüfen sollten, um die Belastbarkeit einer Analyse sicherzustellen Wicherts et al. (2016):\n\nWurde die Art und die Zeitdauer der Datenerhebung vorab festgelegt und berichtet?\nWurden ausreichend Daten gesammelt (z.\\(\\,\\)B. mind. 20 Beobachtungen pro Gruppe)?\nWurden alle untersuchten Variablen berichtet?\nWurden alle durchgeführten Interventionen berichtet?\nWurden Daten aus der Analyse entfernt? Wenn ja, gibt es eine (stichhaltige) Begründung?\n\n\nStellen Sie hohe Anforderungen an die Transparenz einer statistischen Analyse. Nur durch Nachprüfbarkeit können Sie sich von der Stichhaltigkeit der Ergebnisse und deren Interpretation überzeugen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#vertiefung",
    "href": "050-zusammenfassen.html#vertiefung",
    "title": "6  Punktmodelle 1",
    "section": "\n6.7 Vertiefung",
    "text": "6.7 Vertiefung\n\nBeispiel 6.9 (Survival-Tipp) Eine Studentin aus dem Bachelorstudiengang Angewandte Medien- und Wirtschaftspsychologie mit Schwerpunkt Data Science berichtet ihre “Survival-Tipps” für Statistik.\n\nWenn man mal nicht weiterkommt, hilft es auch mal ein paar Tage Abstand von R und Statistik zu nehmen.\nEs hilft, sich während des Semesters neue Begriffe und ihre Erklärung zusammenschreiben.\nGut ist auch, sich mit KommilitonInnen auszutauschen oder in höheren Semestern nach Tipps zu fragen. \\(\\square\\)\n\n\n\n\n🧑‍🎓 Irgendwie kann ich mir R-Code so schlecht merken.\n\n\n🧑‍🏫 Frag doch mal ChatGPT oder einen anderen Chatbot – dort bekommt man auch R-Code ausgegegeben.\n\n\nÜbungsaufgabe 6.10 (Übungsfragen vom Chat-Bot) Fragen Sie einen Chat-Bot wie ChatGPT nach Übungsaufgaben. Sie können sich an folgenden Prompt orientieren. Empfehlenswert ist mit verschiedenen Prompts zu experimentieren.\n\n🧑‍🎓 Ich bin Student in einem Bachelor-Studiengang. Gerade bereite ich mich auf die Klausur im Fach “Grundlagen der Statistik” vor. Bitte schreibe mir Aufgaben, die mir helfen, mich auf die Prüfung vorzubereiten. Die Fragen sollten folgende Themen beinhalten: Maße der zentralen Tendenz, Grundlagen von R, Skalenniveau (z.\\(\\,\\)B. Nominalskala vs. Intervallskala), Verteilungsformen, Normalverteilungen, z-Werte. Bitte schreibe die Aufgabe im Stil von Richtig-Falsch-Aufgaben. Schreibe ca. 10 Aufgaben. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#aufgaben",
    "href": "050-zusammenfassen.html#aufgaben",
    "title": "6  Punktmodelle 1",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\nEin Teil der folgenden Aufgaben kann Stoff beinhalten, den Sie noch nicht kennen, aber später kennenlernen. Ignorieren Sie daher Aufgaben(teile) mit (noch) unbekanntem Stoff.\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nKennwert-robust\nmw-berechnen\nmariokart-max2\nnasa01\nmariokart-mean1\nwrangle10\nsummarise01\nmariokart-max1\nSchiefe1\nmariokart-mean2\nsummarise03\nmariokart-mean4\nmariokart-mean3\nsummarise02\n\nSchauen Sie sich auch mal auf datenwerk.netlify.app die Aufgaben zu z.\\(\\,\\)B. dem Tag EDA an.\n\nÜbungsaufgabe 6.11 Mittlerweile verfügen Sie einige wesentliche Werkzeuge des Datenjudo. Hier finden Sie einen Überblick an Datensätze, die Sie nach Herzenslust analysieren können.6 \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#literaturhinweise",
    "href": "050-zusammenfassen.html#literaturhinweise",
    "title": "6  Punktmodelle 1",
    "section": "\n6.9 Literaturhinweise",
    "text": "6.9 Literaturhinweise\nEs gibt viele Lehrbücher zu den Grundlagen der Statistik; die Inhalte dieses Kapitels gehören zu den Grundlagen der Statistik. Vielleicht ist es am einfachsten, wenn Sie einfach in Ihrer Bibliothek des Vertrauens nach einem typischen Lehrbuch schauen. Beispiel für Lehrbücher sind Mittag & Schüller (2020) oder Oestreich & Romberg (2014); ein Klassiker ist Bortz & Schuster (2010). Einen Fokus auf R legt Sauer (2019). Wer vor Englisch nicht zurückschreckt, ist mit Çetinkaya-Runde & Hardin (2021) oder Poldrack (2023) gut beraten. Beide Bücher sind online verfügbar. Tipp: Mit dem Browser lässt sich englischer Text auf einer Webseite auf auf Deutsch übersetzen.\n\n\n\n\nArad, C. (2024, Juni 5). Kylian Mbappe: Gehalt und Vermögen im Überblick (2024). ftd.de. https://www.ftd.de/vermoegen/mbappe-gehalt-vermoegen/\n\n\nBortz, J., & Schuster, C. (2010). Statistik Für Human- und Sozialwissenschaftler. Springer. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBundesamt, S. (2023-003-272023-003-27). Körpermaße nach Altersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household Wealth and Finances in Germany: Results of the 2021 Household Wealth Survey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nMaphry. (2009). Seesaw with Mean [Artwork]. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung mit interaktiven Elementen. Springer. https://doi.org/10.1007/978-3-662-61912-4\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!: Erfolg und Spaß im Horrorfach nichttechnischer Studiengänge. Springer. https://doi.org/10.1007/978-3-658-04605-7\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height [Data set]. In Our World in Data. https://ourworldindata.org/human-height\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011). False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant. Psychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nTransfermarkt. (2024). Die wertvollsten Fußball-Spieler. https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop/spielerposition_id/8/page/12\n\n\nWicherts, J. M., Veldkamp, C. L. S., Augusteijn, H. E. M., Bakker, M., Aert, R. C. M. van, & Assen, M. A. L. M. van. (2016). Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking. Frontiers in Psychology, 7. https://doi.org/10.3389/fpsyg.2016.01832",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "050-zusammenfassen.html#footnotes",
    "href": "050-zusammenfassen.html#footnotes",
    "title": "6  Punktmodelle 1",
    "section": "",
    "text": "https://en.wikipedia.org/wiki/Average_human_height_by_country↩︎\n316 Tsd Euro↩︎\nNein. Es beschreibt weder das Vermögen der Studierenden noch das des Fußballers gut.↩︎\nEr bleibt gleich, verändert sich also nicht: Der Median ist robust, er verändert sich nicht oder kaum, wenn Extremwerte vorliegen.↩︎\nca. 84 Tsd Euro↩︎\nhttps://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/↩︎",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Punktmodelle 1</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html",
    "href": "060-modellguete.html",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benötigen Sie die üblichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.\nlibrary(tidyverse)\nlibrary(easystats)\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#einstieg",
    "href": "060-modellguete.html#einstieg",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "7.1.1 Lernziele\n\nSie kennen gängige Maße der Streuung einer Stichprobe und können diese definieren und anhand von Beispielen erläutern.\nSie können gängige Maße der Streuung einer Stichprobe mit R berechnen.\nSie können die Bedeutung von Streuung für die Güte eines Modells erläutern.\n\n\nÜbungsaufgabe 7.1 (Freiwillige vor!) Für diese kleine Live-Demonstration brauchen wir einige Freiwillige. Die Lehrkraft teilt die Freiwilligen in zwei Gruppen ein: Gruppe Gleich-Groß und Gruppe Verschieden-Groß. Erkennen Sie, dass die Unterschiedlichkeit der Größe in Gruppe Gleich-Groß gering ist, aber in Gruppe Verschieden-Groß hoch? \\(\\square\\)\n\n\n7.1.2 Die Schlankheitspille von Prof. Weiss-Ois\nProf. Weiss-Ois hat eine Erfindung gemacht, eine Schlankheitspille💊 (flaticon, 2024).\n\n\n\n\n\n\nWas er sagt: “Ich habe eine Schlankheitspille entwickelt, die pro Einnahme das Gewicht im Schnitt um 1\\(\\,\\)kg reduziert!”\n\n\n\n \n\n\n\n\nWas er NICHT sagt: “Allerdings streuten die Werte der Gewichtsveränderung um 10\\(\\,\\)kg um den Mittelwert herum.”\n\n\n\n\n\nAbbildung 7.1: Prof. Weiss-Oiss präsentiert seine neue Schlankheitspille. Würden Sie Sie einnehmen?\n\n\nWürden Sie die Pille von Prof. I. Ch. Weiss-Ois nehmen? Auf jeden Fall? Wenn Sie 1000\\(\\,\\)Euro bekommen? Nur, wenn man Ihnen Geld zahlt? Auf keinen Fall?\nWie sehr die Werte eines Modells streuen, ist eine wichtige Information: Bei Prof. Weiss-Ois’ Pille kann es sein, dass Sie 10\\(\\,\\)kg zunehmen, wenn Sie die Pille einnehmen.\n\n7.1.3 Wie man seine Kuh über den Fluss bringt\nTreffen sich zwei Bauern, Fritz Furchenzieher und Karla Kartoffelsack. Fritz will mit seiner Kuh einen Fluss überqueren, nur kann die Kuh nicht schwimmen (ob Fritz es kann, ist nicht überliefert).\n\n👨‍🌾 (Fritz): Sag mal, Karla, ist der Fluss tief?\n\n\n👩‍🌾 (Karla): Nö, im Schnitt nur einen Meter.\n\nAlso führt Fritz seine Kuh durch den Fluss, leider kam die Kuh nicht am anderen Ufer an, da im Floß ersoffen, s. Abbildung 7.2.\n\n\n\n\n\nAbbildung 7.2: Der Fluss ist im Schnitt nur einen Meter tief, trotzdem ist die Kuh ersoffen.\n\n\n\n👩‍🌾 (Karla): Übrigens: Lagemaße sagen nicht alles, Fritz.\n\n\n👨‍🌾 (Fritz): Läuft die Kuh durch den Fluss, kann sie schwimmen oder ’s ist Schluss.\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Streuung ihrer Daten zu kennen, ist eine wesentliche Information. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "href": "060-modellguete.html#woran-erkennt-man-ein-gutes-modell",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.2 Woran erkennt man ein gutes Modell?",
    "text": "7.2 Woran erkennt man ein gutes Modell?\nAbbildung 7.3 zeigt ein einfaches Modell (Mittelwert) mit wenig Streuung (links) vs. ein einfaches Modell mit viel Streuung (rechts). Links ist die Streuung der Schlankheitspille Dicktableitin und rechts von der Schlankheitspille Pfundafliptan abgetragen. Die vertikalen Balken in Abbildung 7.3 kennzeichnen den (absoluten) Abstand von jeweils einem Datenpunkt zum Mittelwert (horizontale Linie). Je länger die vertikalen ‘Abstandsbalken’ insgesamt, desto größer die Streuung. Die X-Achse (id) reiht die Versuchspersonen auf.\n\n\n\n\n\n\n\nAbbildung 7.3: Wenig (links) vs. viel Streuung (rechts).\n\n\n\n\nBei einem Modell mit wenig Streuung liegen die tatsächlichen, beobachtete Werte (\\(y\\)) nah an den Modellwerten (vorhergesagten Werten, \\(\\hat{y}\\)); die Abweichungen \\(e = y - \\hat{y}\\) sind also gering (der Modellfehler ist klein). Bei einem Modell mit viel Streuung ist der Modellfehler \\(e\\) (im Vergleich dazu) groß.\n\nBeispiel 7.1 (Daten zur Schlankheitskur von Prof. Weiss-Ois) In Abbildung 7.3 sind die Daten zu der Gewichtsveränderung nach Einnahme von “Schlankheitspillen” zweier verschiedener Präparate. Wie man sieht, unterscheidet sich die typische (vorhergesagte, mittlere) Gewichtsveränderung zwischen den beiden Präparaten kaum. Die Streuung allerdings schon. Links sieht man die Gewichtsveränderungen nach Einnahme des Präparats “Dickableibtin extra mild” und rechts das Präparat von Prof. Weiss-Ois’ “Pfundafliptan Forte”. Welches Präparat würden Sie lieber einnehmen?\\(\\square\\)\n\nWir wollen ein präzises Modell, also kurze Fehlerbalken: Das Modell soll die Daten gut erklären, also wenig vom tatsächlichen Wert abweichen. Jedes Modell sollte Informationen über die Präzision des Modellwerts bzw. der Modellwerte (Vorhersagen) angeben. Ein Modell ohne Angaben der Modellgüte, d.\\(\\,\\)h. der Präzision der Schätzung des Modellwerts, ist wenig nütze.\n\n🧑‍🎓 Ich frage mich, ob man so ein Modell nicht verbessern kann?\n\n\n🧑‍🏫 Die Frage ist, was wir mit “verbessern” meinen?\n\n\n🧑‍🎓 Naja, kürzere Fehlerbalken, ist doch klar!\n\nIm Beispiel von Mariokart: Da die Anzahl der Lenkräder mit dem Verkaufspreis zusammenhängt, könnte es vielleicht sein, dass wir die Lenkräder-Anzahl zur Vorhersage nutzen könnten. Das sollten wir ausprobieren. Abbildung 7.4 zeigt, dass die Fehlerbalken kürzer werden, wenn wir ein (sinnvolles) komplexeres Modell finden. Innerhalb jeder der beiden Gruppen (mit 2 Lenkrädern vs. mit 0 Lenkrädern) sind die Fehlerbalken jeweils im Durchschnitt kürzer (rechtes Teildiagramm) als im Modell ohne Gruppierung (linkes Teildiagramm). Aus Gründen der Übersichtlichkeit wurden nur Autos mit Verkaufsgebot von weniger als 100 Euros berücksichtigt und nur Spiele mit 0 oder mit 2 Lenkrädern.\n\n\n\n\n\n\n\n\n\n(a) Einfaches Modell\n\n\n\n\n\n\n\n\n\n(b) Komplexeres Modell\n\n\n\n\n\n\nAbbildung 7.4: Fehlerbalken in einem einfachen und komplexeren Modell. (a) Fehlerbalken im einfachen Modell. Ein Mittelwert; viel Streuung insgesamt, y ~ 1. (b) Fehlerbalken im komplexeren Modell. Zwei Mittelwerte; weniger Streuung in jeder Gruppe, y ~ G. Die geringere Streuung erkennt man daran, dass die vertikalen Abstandsbalken im Schnitt kürzer sind als im einfachen Modell.\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDurch sinnvolle, komplexere Modelle sinkt die Fehlerstreuung eines Modells. \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#sec-streuung",
    "href": "060-modellguete.html#sec-streuung",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.3 Streuungsmaße",
    "text": "7.3 Streuungsmaße\n\nDefinition 7.1 (Streuungsmaße) Ein Streuungsmaß quantifiziert die Variabilität (Unterschiedlichkeit, Streuung) eines Merkmals. \\(\\square\\)\n\n\nDefinition 7.2 (Spannweite) Ein einfaches Streuungsmaß ist die Spannweite (Range) \\(R\\), definiert als Differenz von größtem und kleinsten Wert eines Merkmals X: \\(R := X_{max} - X_{min}. \\square\\)\n\n\nBeispiel 7.2 Angenommen, wir haben einen Datensatz zum Merkmal “Alter” mit den Werte 1, 23, 42, 100. Dann beträgt der Range: \\(R = 100 - 1 = 99\\). Das bedeutet, dass die Werte des Merkmals sich über 99 Einheiten (Jahre in diesem Fall) verteilen. \\(\\square\\)\n\nDie Spannweite ist aber nicht robust (gegenüber Extremwerten) und sollte daher nur mit Einschränkung verwendet werden.\n\n7.3.1 Der mittlere Abweichungsbalken\n\n🧑‍🎓 Wir müssen jetzt mal präziser werden! Wie können wir die Streuung berechnen?\n\n\n🧑‍🏫 Gute Frage! Am einfachsten ist es, wenn wir die mittlere Länge eines Abweichungsbalkens ausrechnen.\n\nLegen wir (gedanklich) alle Abweichungsbalken \\(e\\) aneinander und teilen durch die Anzahl \\(n\\) der Balken, so erhalten wir den “mittleren Abweichungsbalken”, den wir mit \\(\\bar{e}\\) (“e quer”) bezeichnen könnten. Diesen Kennwert bezeichnet man als Mean Absolute Error (MAE) bzw. als mittlere Absolutabweichung (MAA), s. Gleichung 7.1.\n\nDefinition 7.3 (Mittlere Absolutabweichung) Die Mittlere Absolutabweichung (MAA, MAE) ist definiert als die Summe der Absolutwerte der Differenzen eines Messwerts zum Mittelwert, geteilt durch die Anzahl der Messwerte. (Wenn man solche Sätze liest, fühlt sich die Formel fast einfacher an.)\n\\[{\\displaystyle \\mathrm {MAE} :={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-\\bar{y}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}=\\bar{e}.  \\; \\square} \\tag{7.1}\\]\n\n\nBeispiel 7.3 Abbildung 7.5 visualisiert ein einfaches Beispiel zum MAE. Rechnen wir den MAE für das Beispiel von Abbildung 7.5 aus:\n\\(MAE = \\frac{1 + |- 3| + 1 + 1}{4} = 6/4 = 1.5 \\; \\square\\)\n\n\n\n\n\n\n\n\nAbbildung 7.5: Abweichungsbalken und der MAE\n\n\n\n\nNatürlich können wir R auch die Rechenarbeit überlassen.\n\n🤖 Loving it!\n\nSchauen Sie: Den Mittelwert (s. Abbildung 7.5) kann man doch mit Fug und Recht als ein lineares Modell, eine Gerade, betrachten, oder nicht? Schließlich erklären wir \\(y\\) anhand einer Gerade (die parallel zur X-Achse verläuft). In R gibt es einen Befehl, um ein lineares Modell zu berechnen, er heißt lm. Die Syntax von lm() lautet: lm(y ~ 1, data = meine_daten).\nIn Worten:\n\nHey R, berechne mit ein lineares Modell zur Erklärung von Y. Aber verwende keine andere Variable zur Erklärung von Y, sondern nimm den Mittelwert von Y.\n\n\nlm_ohne_x_var &lt;- lm(y ~ 1, data = d)\n\nDen MAE können wir uns jetzt so ausgeben lassen:\n\nmae(lm_ohne_x_var)  # aus dem Paket easystats\n## [1] 1.5\n\n\n7.3.2 Der Interquartilsabstand\nDer Interquartilsabstand (IQA; engl. inter quartile range, IQR) ist ein Streuungsmaß, das nicht auf dem Mittelwert aufbaut. Der IQR ist robuster als z.\\(\\,\\)B. der MAA oder die Varianz und die Standardabweichung. Abbildung 7.6 stellt den IQR (und einige Quantile) für den Verkaufspreise von Mariokart-Spielen dar.\n\nDefinition 7.4 (Interquartilsabstand) Der Interquartilsabstand ist definiert als die (absolute) Differenz des 3. Quartils und 1. Quartils: \\(IQR := Q_3-Q_1. \\; \\square\\)\n\n\nBeispiel 7.4 (IQR im Hörsaal) In einem Statistikkurs betragen die Quartile der Körpergröße: Q1: 1.65m, Q2 (Median): 1.70m, Q3: 1.75m. Der IQR beträgt dann: \\(IQR = Q_3-Q_1 = 1.75\\,m - 1.65\\,m = 0.10\\,m\\), d.\\(\\,\\)h. 10\\(\\,\\)cm. \\(\\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Histogramm\n\n\n\n\n\n\n\n\n\n(b) Dichtediagramm\n\n\n\n\n\n\nAbbildung 7.6: IQR, Q1, Q2 und Q3 für das Schlussgebot (nur Spiele für weniger als 100 Euro)\n\n\n\n7.3.3 Streuungsmaße für Normalverteilungen\nNormalverteilungen sind recht häufig anzutreffen in der Praxis der Datenanalyse. Daher lohnt es sich, zu überlegen, wie man diese Verteilungen kompakt zusammenfasst. Man kann zeigen, dass eine Normalverteilung sich komplett über ihren Mittelwert sowie ihre Standardabweichung beschreiben lässt (Lyon, 2014). Außerdem gilt: Sind Ihre Daten normalverteilt, dann sind die Abweichungen vom Mittelwert auch normalverteilt. Denn wenn man eine Konstante zu einer Verteilung addiert (bzw. subtrahiert), “verschiebt man den Berg” nur zur Seite, ohne die Form zu verändern, s. Abbildung 7.7.\n\n\n\n\n\n\n\nAbbildung 7.7: Die Abweichungen zum Mittelwert (MW) einer normalverteilten Variable sind selber normalverteilt. Rechts: unzentrierte Verteilung; links: zentriert.\n\n\n\n\nHat man normalverteilte Variablen, so ist die Standardabweichung (engl. standard deviation, SD, \\(\\sigma, s\\)) eine geeignete Maßeinheit der Streuung, denn damit lässt sich die Streuung (Abweichung vom Mittelwert, Residuen) der Normalverteilung gut beschreiben.\n\n🧑‍🎓 Aber wie berechnet man jetzt diese Standardabweichung?\n\n\n🧑‍🏫 Moment, noch ein kurzer Exkurs zur Varianz …\n\n\n🧑‍🎓 (seufzt)\n\n\n7.3.4 Varianz\nDie Varianz einer Variable (z.\\(\\,\\)B. Verkaufspreis von Mariokart) ist der mittlere quadrierte Abstand jedes Verkaufspreises vom Mittelwert.\n\n\n\nAbbildung 7.10 illustriert die Varianz als “mittlerer Quadratfehler”:\n\nMan gehe von der Häufigkeitsverteilung der Daten aus.\nBetrachtet man die Daten als Gewichte auf einer Wippe, so ist der Schwerpunkt der Wippe der Mittelwert.\nMan zeichnet für jeden Datenpunkt ein Quadrat mit einer Kantenlänge, die seinem Abstand zum Mittelwert entspricht.\nDiese Quadrate werden, wo nötig, in Rechtecke umgeformt (bei gleichbleibender Fläche) und so angeordnet, dass sie ein Rechteck mit den Seitenlängen \\(n\\) und \\(\\sigma^2\\) bilden.\n\n\n\n\n\n\n\n\nAbbildung 7.8: Varianz (Cmglee, 2015)\n\n\n\n\n\nAbbildung 7.9 visualisiert die Varianz für Beispiel 7.3.1 Links sind die Abweichungsquadrate dargestellt, rechts die Varianz als “typisches Abweichungsquadrat”. Die Varianz ist also ein Maß, das die typische quadrierte Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst.\n\n\n\n\n\n\n\n\n\n(a) Quadrierte Fehlerbalken\n\n\n\n\n\n\n\n\n\n(b) Varianz als ‘typischer’ Fehlerbalken\n\n\n\n\n\n\nAbbildung 7.9: Sinnbild zur Varianz als typischer Fehlerbalken\n\n\n\nBeispiel 7.5 Sie arbeiten immer noch bei einem Online-Auktionshaus und untersuchen den Verkauf von Videospielen. Natürlich mit dem Ziel, dass Ihre Firma mehr von dem Zeug verkaufen kann. Dazu berechnen Sie die Streuung in den Verkaufspreisen, s. Listing 7.1 bzw. Tabelle 7.1. \\(\\square\\)\n\n\n\n\nListing 7.1: Berechnung der Streuung des Verkaufspreises als Indikator für die Modellgüte des Mittelwerts\n\nmariokart_no_extreme &lt;-\n  mariokart %&gt;%\n  filter(total_pr &lt; 100)  # ohne Extremwerte\n\nm_summ &lt;- \n  mariokart_no_extreme %&gt;% \n  summarise(\n    pr_mw = mean(total_pr),\n    pr_iqr = IQR(total_pr),\n    pr_maa = mean(abs(total_pr - mean(total_pr))),\n    pr_var = var(total_pr),\n    pr_sd = sd(total_pr))\n\n\n\n\n\n\n\nTabelle 7.1: Kennwerte der Streuung für den Mariokart-Datensatz\n\n\n\n\npr_mw\npr_iqr\npr_maa\npr_var\npr_sd\n\n\n47\n13\n7.2\n83\n9.1\n\n\n\n\n\n\n\nStatistiken sind ja schön … aber Bilder sind auch gut, s. Abbildung 7.10. Datendiagramme eignen sich gut, um (grob) die Streuung einer Variable zu erfassen.\n\nmariokart %&gt;% \n  mariokart_no_extreme %&gt;%   # ohne Extremwerte\n  select(total_pr) %&gt;% \n  plot_density()  # oder plot_violin\n\n\n\n\n\n\n\n\n\n\n(a) Dichtediagramm\n\n\n\n\n\n\n\n\n\n(b) Violindiagramm\n\n\n\n\n\n\nAbbildung 7.10: Die Verteilung des Verkaufspreises von Mariokart-Spielen mit MW±SD farblich markiert\n\n\nWer sich die Berechnung von Hand für pr_maa sparen möchte (s. Listing 7.1), kann die Funktion MeanAD aus dem Paket DescTools nutzen. Um die Standardabweichung zu berechnen, berechnet man zunächst die Varianz, \\(s^2\\) abgekürzt. Hier ist ein “Kochrezept” (Algorithmus) zur Berechnung der Varianz:\n\nFür alle Datenpunkte \\(x_i\\): Berechne die Abweichungen vom Mittelwert, \\(\\bar{x}\\).\nQuadriere diese Werte.\nSummiere dann auf.\nTeile durch die Anzahl \\(n\\) der Werte.\n\nAls Formel ausgedrückt lautet die Definition der Varianz von \\(Y\\) bei einer Stichprobe der Größe \\(n\\) wie folgt, s. Gleichung 7.2. (Hier geht es um die sog. unkorrigierte Stichprobenvarianz; um anhand einer Stichprobe die Varianz der zugehörigen Population zu schätzen, teilt man nicht durch \\(n\\), sondern durch \\(n-1\\).)\n\\[{\\displaystyle s^{2}:={\\frac {1}{n}}\\sum _{i=1}^{n}\\left(y_{i}-{\\bar {y}}\\right)^{2}={\\frac {1}{n}}\\sum _{i=1}^{n}e_i^{2}.} \\tag{7.2}\\]\n\nDefinition 7.5 (Varianz) Die Varianz von \\(Y\\) (\\(s^2, \\sigma^2\\)) ist definiert als der Mittelwert der quadrierten Abweichungen (vom Mittelwert von \\(Y\\)), \\(e_i^2\\). \\(\\square\\)\n\nDie Varianz steht im engen Verhältnis zur Kovarianz, s. Kapitel 8.3. Die Varianz kann auch verstehen als den mittleren Quadratfehler (Mean Squared Error, MSE) eines Modells, s. Gleichung 7.3.\n\\[{\\displaystyle MSE:={\\frac {1}{n}}\\sum _{i=1}^{N}\\left(y_{i}-{\\hat {y}}\\right)^{2}.} \\tag{7.3}\\]\nIm Fall eines Punktmodells ist der Mittelwert der vorhergesagte Wert eines Modells: \\(\\hat{y} = \\bar{y}\\).\n\n7.3.5 Die Standardabweichung\n\nDefinition 7.6 (Standardabweichung) Die Standardabweichung (SD, s, \\(\\sigma\\)) ist definiert als die Quadratwurzel der Varianz, s. Gleichung 7.4.\n\\[s := \\sqrt{s^2} \\square \\tag{7.4}\\]\n\nKennt man die Varianz, so lässt sich die Standardabweichung einfach als Quadratwurzel der Varianz berechnen. Durch das Wurzelziehen besitzt die Standardabweichung wieder in etwa die gleiche Größenordnung wie die Daten (im Gegensatz zur Varianz, die durch das Quadrieren sehr groß werden kann). Die Standardabweichung ist also ein Maß, das grob (!) gesagt die “typische” Abweichung der Beobachtungen vom Mittelwert in eine Zahl fasst. Aus einem Modellierungsblickwinkel kann man die SD definieren als die Wurzel von MSE. Dann nennt man sie Root Mean Squared Error (RMSE): \\(RMSE := \\sqrt{MSE}\\).\n\n\n\n\n\n\nHinweis\n\n\n\nDie SD ist i.d.R. ungleich zur MAE, aber (fast) gleich zur RMSE. Entsprechend ist die Varianz (fast) gleich zur MSE. \\(\\square\\)\n\n\n\nBeispiel 7.6 Sie arbeiten weiter an Ihrem Mariokart-Projekt. Da Sie heute keine Lust auf viel Tippen haben, nutzen Sie das R-Paket easystats mit der Funktion describe_distribution, s. Tabelle 7.2.\n\nlibrary(easystats)\n\nmariokart %&gt;% \n  select(total_pr) %&gt;% \n  describe_distribution()\n\n\n\n\nTabelle 7.2: Ausgabe der Funktion describe_distribution (Auszug)\n\n\n\n\nVariable\nMean\nSD\nIQR\nn\n\n\ntotal_pr\n50\n26\n13\n143\n\n\n\n\n\n\n\n\n🧑‍🎓 Ah! Das war einfach. Reicht auch mal für heute. \\(\\square\\)\n\n\n\nBeispiel 7.7 Ihr Job als Datenanalyst ist anstrengend, aber auch mitunter interessant. So war auch der heutige Tag. Bevor Sie nach Hause gehen, möchten Sie noch eine Sache anschauen. In einer früheren Analyse (s. Abbildung 7.4) fanden Sie heraus, dass die Fehlerbalken kürzer werden, wenn man ein geschickteres und komplexeres Modell findet. Das wollen Sie natürlich prüfen. Sie überlegen: “Okay, ich will ein einfaches Modell, in dem der Mittelwert das Modell des Verkaufspreis sein soll.”\nDas spezifizieren Sie so:\n\nlm_mario_ohne_x_var &lt;- lm(total_pr ~ 1, data = mariokart)\nmae(lm_mario_ohne_x_var)  # Modellgüte bzw. Modellfehler\n## [1] 10\n\nIm nächsten Schritt spezifizieren Sie ein Modell, in dem der Verkaufspreis eine Funktion der Anzahl der Lenkräder ist (ähnlich wie in Abbildung 7.4):\n\nlm_wheels &lt;- lm(total_pr ~ wheels, data = mariokart)\nmae(lm_wheels)\n## [1] 7.4\n\nAh! Sehr schön, Sie haben mit lm2 ein besseres Modell als einfach nur den Mittelwert gefunden. Ab nach Hause! \\(\\square\\)\n\n\n🧑‍🎓 Der “gesunde Menschenverstand” würde den mittleren Absolutabstand (MAA oder MAE) der Varianz (oder der Standardabweichung, SD) vorziehen. Warum brauche ich dann die SD?\n\n\n\n🧑‍🏫 Ja, die MAA ist anschaulicher und insofern nützlicher als die Varianz und die SD. Wenn es nur um deskriptive Statistik geht, braucht man die Varianz (oder die SD) nicht unbedingt. Allerdings ist die SD nützlich zur Beschreibung der Normalverteilung. Außerdem wird die Varianz häufig verwendet bzw. in Forschungsarbeiten berichtet, daher hilft es Ihnen, wenn Sie die Varianz kennen. Liegen Extremwerte vor, kann es vorteilhafter sein, den IQR vorzuziehen gegenüber Mittelwert basierten Streuungsmaßen (MAA, Varianz, SD).",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#streuung-als-modellfehler",
    "href": "060-modellguete.html#streuung-als-modellfehler",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.4 Streuung als Modellfehler",
    "text": "7.4 Streuung als Modellfehler\nWenn wir den Mittelwert als Punktmodell des Verkaufspreises auffassen, so kann man die verschiedenen Kennwerte der Streuung als verschiedene Kennwerte der Modellgüte auffassen.\nDefinieren wir zunächst als Punktmodell auf Errisch:\n\nlm_mario_ohne_x_var &lt;- lm(total_pr ~ 1, data = mariokart)\n\nZur Erinnerung: Wir modellieren total_pr ohne UV (Prädiktoren), sondern als Punktmodell, und zwar schätzen wir den Mittelwert mit den Daten mariokart. Modelle ohne UV nennt man auch “Nullmodell”. Das (Meta-)Paket easystats bietet komfortable Befehle, um die Modellgüte zu berechnen:\n\nmae(lm_mario_ohne_x_var)  # Mean absolute error\nmse(lm_mario_ohne_x_var)  # Mean squared error\nrmse(lm_mario_ohne_x_var)  # Root mean squared error\n## [1] 10\n## [1] 655\n## [1] 26",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#die-z-transformation",
    "href": "060-modellguete.html#die-z-transformation",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.5 Die z-Transformation",
    "text": "7.5 Die z-Transformation\nSie arbeiten immer noch als Datenknecht, Moment, Datenhecht bei dem Online-Auktionshaus. Heute untersuchen Sie, wie gut sich die Verkaufspreise mit einer einzigen Zahl, dem mittleren Verkaufspreis, beschreiben lassen. Einige widerspenstige Werte haben Sie dabei einfach des Datensatzes verwiesen. Schon ist das Leben leichter, s. Listing 7.2.\n\n\n\nListing 7.2: Mariokart ohne Extremwerte\n\nmariokart_no_extreme &lt;- \n  mariokart %&gt;% \n  filter(total_pr &lt; 100)\n\n\n\n\nAbbildung 7.11 (links) zeigt, dass es einige Streuung um den Mittelwert herum gibt. Abbildung 7.11 (rechts) zeigt die (um den Mittelwert) zentrierten Daten.\n\n\n\n\n\n\n\n\n\n\n(a) Wie nah drängen sich die Verkaufspreise um ihren Mittelwert?\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Abweichungen vom Mittelwert: zentrierte Daten\n\n\n\n\n\n\nAbbildung 7.11: Verteilung von mariokart_no_extreme\n\n\n\nTja, das ist doch etwas Streuung um den Mittelwert herum.\n\n\n\n\n\n\nWichtig\n\n\n\nJe weniger Streuung um den Mittelwert (ca. 47 Euro) herum, desto besser eignet sich der Mittelwert als Modell für die Daten und desto höher ist die Modellgüte.\n\n\nJa, es ist etwas Streuung, aber wie viel? Kann man das genau angeben? Sie überlegen … und überlegen. Da! Eine Idee!\nMan könnte vielleicht angeben, wie viel Euro jedes Spiel vom Mittelwert entfernt ist. Je größer diese Abweichung, desto schlechter die Modellgüte! Also rechnen Sie diese Abweichung aus, Listing 7.3.\n\n\n\nListing 7.3: Zentrieren einer Variablen\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw = 47.4 - total_pr) # zentriert = messwert - mittelwert\n\n\n\n\nAnders gesagt: Wir haben die Verkaufspreise zentriert.\n\nDefinition 7.7 (Zentrieren) Zentrieren bedeutet, von jedem Wert einer Verteilung \\(X\\) den Mittelwert zu subtrahieren. Daher ist der neue Mittelwert (der zentrierten Verteilung) gleich Null. \\(\\square\\)\n\nAber irgendwie sind Sie noch nicht am Ziel Ihrer Überlegungen: Woher weiß man, ob 10 Euro oder 20 Euro “viel” Abweichung vom Verkaufspreis ist? Man müsste die Abweichung eines Verkaufspreises zu irgendetwas in Bezug setzen. Wieder! Ein Geistesblitz! Man könnte doch die jeweilige Abweichung in Bezug setzen zur mittleren (absoluten) Abweichung (MAA)! Ein alternativer, ähnlicher Kennwert zur MAA ist die SD. Sie haben gehört, dass die SD gebräuchlicher sei als die MAA. Um sich als Checker zu präsentieren, berechnen Sie also auch die SD; die beiden Koeffizienten sind ja ähnlich.\nAlso: Wenn ein Spiel 10 Dollar vom Mittelwert abweicht und die SD 10 Dollar betragen sollte, dann hätten wir eine “standardisierte” (abgekürzt manchmal mit std) Abweichung von 1, weil 10/10=1. Begeistert über Ihre Geistesblitze machen Sie sich ans Werk.\n\nmariokart_no_extreme &lt;-\n  mariokart_no_extreme %&gt;% \n  mutate(abw_std = abw / sd(abw),  # std wie \"standardisiert\"\n         abw_std2 = abw / mean(abs(abw)))  \n\nZufrieden betrachten Sie Ihr Werk, s. Abbildung 7.12. In Abbildung 7.12 sieht man oben die Rohwerte und unten die transformierten Werte, die wir hier als z-standardisiert bezeichnen, da wir sie in Bezug zur “typischen Abweichung”, der SD, gesetzt haben.\n\n\n\n\n\n\n\nAbbildung 7.12: Standardisierung von Abweichungswerten bzw. einer Verteilung; der vertikale Balken zeigt den Mittelwert\n\n\n\n\nWir fassen die Schritte unserer Umrechnung (“Transformation”) zusammen wie in einem Kochrezept:\n\nNimm die Verteilung der Verkaufspreise\nBerechne die Abweichungen vom mittleren Verkaufspreis (Differenz Mittelwert und jeweiliger Verkaufspreis)\nTeile die Abweichungen (aus Schritt 2) durch die SD\n\nDiese Art von Transformation bezeichnet man als z-Transformation und die resultierenden Werte als z-Werte.\n\nDefinition 7.8 (z-Werte) z-Werte sind das Resultat der z-Transformation. Für die Variable \\(X\\) berechnet sich der z-Wert der \\(i\\)-ten Beobachtung so: \\(z_i := \\frac{x_i - \\bar{x}}{sd_x}.\\;\\square\\)\n\nz-Werte sind nützlich, weil sie die “relative” Abweichung einzelner Beobachtungen vom Mittelwert anzeigen. Nach einer Faustregel spricht man von extremen Abweichungen (Extremwerten, Ausreißern), wenn \\(z_i \\ge 2.5\\) (Shimizu, 2022).\n\nDefinition 7.9 (Standardnormalverteilung) Eine Standardnormalverteilung ist eine Normalverteilung mit Mittelwert gleich 0 und Standardabweichung gelich 1. Man schreibt kurz: \\(X \\sim \\mathcal{N}(0, 1)\\quad \\square\\).\n\nMan kann jeder Normalverteilung in eine Standardnormalverteilung überführen mit der z-Transformation.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#aufgaben",
    "href": "060-modellguete.html#aufgaben",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.6 Aufgaben",
    "text": "7.6 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nmariokart-sd2\nmariokart-sd3\nKennwert-robust\nsummarise04\nsummarise05\nvis-mariokart-variab\nsd-vergleich\nnasa01\nStreuung-Histogramm\nmariokart-sd1\nsummarise06\nmariokart-desk01\n\n\nÜbungsaufgabe 7.2 (Analysieren Sie den Datensatz zur Handynutzung)  \n\n\n\nDie Forschungsfrage einer Studie fragt, ob Handynutzung die Konzentrationsfähigkeit verringert. Nehmen Sie ggf. an der Studie (Umfrage) teil (sie ist anonym und dauert drei Minuten).\n\n\n\n\n\n\n\n\n\n\n\n\n\nLaden Sie den Datensatz zur Handynutzung von Google-Docs herunter.2 Berechnen Sie dann gängige deskriptive Statistiken und visualisieren Sie sie. \\(\\square\\)\nLösung: Daten importieren\nSie können die Daten entweder selber herunterladen oder aber die folgende Version des Datensatzes verwenden. In beiden Fällen ist es nützlich, den (absoluten oder relativen) Pfad anzugeben:\n\ndata_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/Smartphone-Nutzung%20(Responses)%20-%20Form%20responses%201.csv\"\n\n\n\n\n\n\n\n\n\nDann können Sie die Daten wie gewohnt importieren:\n\nsmartphone_raw &lt;- read.csv(data_path)\n\nLösung: Daten aufbereiten\nDie Spaltennamen sind sehr unschön. Lassen Sie uns daher die Spaltennamen umbenennen (aber vorab sichern):\n\nitem_labels &lt;- names(smartphone_raw)\n\nnames(smartphone_raw) &lt;- paste0(\"item\",1:ncol(smartphone_raw))\n\nCheck:\n\nglimpse(smartphone_raw)\n## Rows: 70\n## Columns: 18\n## $ item1  &lt;chr&gt; \"21/03/2024 15:36:52\", \"05/04/2024 10:24:58\", \"05/04/2024 10…\n## $ item2  &lt;chr&gt; \"15:31:00\", \"10:23:00\", \"10:40:00\", \"11:14:00\", \"12:33:00\", …\n## $ item3  &lt;int&gt; 3, 4, 3, 3, 5, 5, 5, 5, 1, 2, 5, 3, 2, 2, 2, 5, 3, 1, 2, 4, …\n## $ item4  &lt;int&gt; 5, 3, 3, 3, 4, 3, 3, 6, 2, 4, 5, 1, 1, 2, 3, 3, 4, 3, 2, 4, …\n## $ item5  &lt;int&gt; 3, 3, 1, 5, 1, 3, 2, 4, 3, 2, 1, 1, 1, 4, 1, 2, 2, 1, 1, 1, …\n## $ item6  &lt;int&gt; 4, 2, 4, 3, 5, 4, 6, 3, 2, 5, 6, 4, 2, 6, 5, 5, 5, 5, 5, 4, …\n## $ item7  &lt;int&gt; 4, 3, 2, 3, 3, 1, 3, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 2, 2, 2, …\n## $ item8  &lt;int&gt; 1, 3, 1, 2, 3, 1, 1, 2, 2, 2, 1, 1, 2, 4, 1, 1, 2, 2, 1, 2, …\n## $ item9  &lt;int&gt; 2, 6, 1, 3, 6, 5, 5, 2, 2, 5, 6, 1, 1, 5, 4, 6, 2, 4, 3, 4, …\n## $ item10 &lt;int&gt; 2, 5, 5, 3, 4, 3, 1, 5, 1, 5, 3, 4, 3, 5, 4, 4, 4, 5, 3, 2, …\n## $ item11 &lt;int&gt; 5, 6, 6, 5, 6, 6, 5, 6, 4, 3, 6, 4, 4, 5, 3, 6, 6, 4, 4, 5, …\n## $ item12 &lt;int&gt; 1, 3, 1, 2, 5, 2, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, …\n## $ item13 &lt;int&gt; 4, 3, 4, 2, 4, 2, 5, 3, 1, 1, 4, 1, 3, 4, 1, 3, 5, 2, 1, 4, …\n## $ item14 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item15 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item16 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ item17 &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", …\n## $ item18 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\n7.6.1 Komplette Lösung\n😁\n\n\n\n7.6.2 Fallstudie zur Lebenszufriedenheit\nDie OECD führt eine weltweite Studie zur Lebenszufriedenheit durch.3 Arbeiten Sie die die Fallstudie “oecd-yacsda” im Datenwerk durch, um ein tieferes Verständnis für die Lebenszufriedenheit in verschiedenen Ländern der Welt zu bekommen.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#literaturhinweise",
    "href": "060-modellguete.html#literaturhinweise",
    "title": "\n7  Modellgüte\n",
    "section": "\n7.7 Literaturhinweise",
    "text": "7.7 Literaturhinweise\nAllen Downey (2023) stellt in seinem vergnüglich zu lesenden Buch eine kurzweilige Einführung in die Statistik vor; auch Streuungsmaße haben dabei einen Auftritt. Wer mehr “Lehrbuch-Feeling” sucht, wird bei Çetinkaya-Runde & Hardin (2021) fündig (das Buch ist online frei verfügbar). Es ist kein Geheimnis, dass Streuungsmaße keine ganz neuen Themen in der Statistik sind. Aber hey, Oldie is Goldie, ohne Streuungsmaße geht’s nicht. Jedenfalls werden Sie in jedem Statistik-Lehrbuch, dass Sie in der Bib (oder sonst wo) aus dem Regal ziehen, fündig werden zu diesem Thema. Die Bücher unterscheiden sich meist “nur” in ihrem Anspruch bzw. der didaktischen Aufmachung; für jeden Geschmack ist da was dabei.\n\n\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCmglee. (2015). English: Geometric Visualisation of the Variance of the Example Distribution (2, 4, 4, 4, 5, 5, 7, 9) on w:Standard Deviation. [Artwork]. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nDowney, A. (2023). Probably Overthinking It: How to Use Data to Answer Questions, Avoid Statistical Traps, and Make Better Decisions. The University of Chicago Press.\n\n\nflaticon. (2024). Professor [Artwork]. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nLyon, A. (2014). Why Are Normal Distributions Normal? The British Journal for the Philosophy of Science, 65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nShimizu, Y. (2022). Multiple Desirable Methods in Outlier Detection of Univariate Data With R Source Codes. Frontiers in Psychology, 12, 819854. https://doi.org/10.3389/fpsyg.2021.819854",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "060-modellguete.html#footnotes",
    "href": "060-modellguete.html#footnotes",
    "title": "\n7  Modellgüte\n",
    "section": "",
    "text": "Die Abweichungsquadrate wirken optisch nicht quadratisch, da die X-Achse breiter skaliert dargestellt ist als die Y-Achse. Trotzdem sind es Quadrate, nur nicht optisch, wenn Sie wissen, was ich meine …↩︎\nhttps://docs.google.com/spreadsheets/d/1SWMj4rIIIJdAsfsSKQHSg8jHr_OuKLpJx_0XV4LGnH0/edit?usp=sharing↩︎\nhttps://www.oecd.org/wise/measuring-well-being-and-progress.htm↩︎",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Modellgüte</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html",
    "href": "070-zusammenhaenge.html",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1 Einstieg\nIn diesem Kapitel benötigen Sie die üblichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#einstieg",
    "href": "070-zusammenhaenge.html#einstieg",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "8.1.1 Lernziele\n\nSie können die Begriffe Kovarianz und Korrelation definieren und ihren Zusammenhang erläutern.\nSie können die Stärke einer Korrelation einschätzen.\n\n\nlibrary(tidyverse)\nlibrary(easystats)\n\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\n8.1.2 Zum Einstieg\n\nÜbungsaufgabe 8.1  \n\nSuchen Sie sich eine vertrauenswürdige Partnerin oder einen vertrauenswürdigen Partner. Im Zweifel reicht die erste Person, die Sie sehen. 😁\n\nFragne Sie diese Person nach je zwei Variablen, die wie folgt zusammenhängen:\n\n\ngleichsinnig (Viel von dem einen, viel von dem anderen)\ngegensinnig (viel von dem einen, wenig von dem anderen)\nScheinzusammenhang (hängt zusammen, ist aber nicht “echt” bzw. kausal) \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "href": "070-zusammenhaenge.html#zusammenfassen-zum-zusammenhang",
    "title": "8  Punktmodelle 2",
    "section": "\n8.2 Zusammenfassen zum Zusammenhang",
    "text": "8.2 Zusammenfassen zum Zusammenhang\nIn Kapitel 6 haben wir gelernt, dass das Wesen eines Punktmodells als Zusammenfassung einer Spalte (eines Vektors) zu einer einzelnen Zahl, zu einem “Punkt” sozusagen, zusammengefasst werden kann. In diesem Kapitel fassen wir zwei Spalten zusammen, wieder zu einer Zahl, s. Abbildung 8.1. Während wir in Kapitel 6 eine Variable mit Hilfe eines Lagemaßes beschrieben (bzw. dargestellt, zusammengefasst, modelliert) haben, tun wir hier das Gleiche für zwei Variablen. Beschreibt man aber zwei Variablen, so geht es um die Frage, was die beiden Variablen miteinander zu tun haben: Wie die beiden Variablen voneinander (statistisch) abhängen bzw. miteinander (in welcher Form auch immer) zusammenhängen. Wir begrenzen uns auf metrische Variablen.\n\n\n\n\n\nAbbildung 8.1: Zwei Spalten werden zu einer Zahl zusammengefasst\n\n\n\n\n\n\n\n\n\n\n\nDie Verbildlichung (Visualisierung) zweier metrischer Variablen haben wir bereits in Kapitel 5.6.2 kennengelernt. Zur Verdeutlichung wie ein Zusammenhang zweier metrischer Variablen aussehen kann, hilft noch einmal Abbildung 8.2.\n\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm mit Trendlinie\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Verwackeltes Streudiagramm\n\n\n\n\n\n\nAbbildung 8.2: Visualisierung des Zusammenhangs von wheels und total_pr. (a) Streudiagramm mit Trendlinie (und Ellipse zur Verdeutlichung). (b) ‘Verwackeltes’ Streudiagramm, um die einzelnen Punkte besser zu erkennen",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#sec-cov",
    "href": "070-zusammenhaenge.html#sec-cov",
    "title": "8  Punktmodelle 2",
    "section": "\n8.3 Abweichungsrechtecke",
    "text": "8.3 Abweichungsrechtecke\nDie Stärke des linearen Zusammenhangs zweier metrischer Variablen kann man gut mithilfe von Abweichungsrechtecken veranschaulichen. Los geht’s!\n\n8.3.1 Noten und Abweichungsrechtecke\n\nBeispiel 8.1 (Wieder Statistiknoten) Anton, Bert, Carl und Daniel haben ihre Statistikklausur zurückbekommen. Die Lernzeit \\(X\\) scheint mit der erreichten Punktzahl \\(Y\\) (0-100, je mehr desto besser) zusammenzuhängen.1 Gar nicht so schlecht ausgefallen wie gedacht …, s. Tabelle 8.1. \\(\\square\\)\n\n\n\n\nTabelle 8.1: Punkte in der Statistikklausur (x, 0-100) und Lernzeit (y, 0-100)\n\n\n\n\nid\ny\nx\n\n\n\n1\n72\n70\n\n\n2\n44\n40\n\n\n3\n39\n35\n\n\n4\n50\n67\n\n\n\n\n\n\n\n\nZeichnen wir uns die Daten als Streudiagramm, s. Abbildung 8.3. Dabei zeichnen wir noch Abweichungsrechtecke ein.\n\nDefinition 8.1 (Abweichungsrechteck) Im zweidimensionalen Fall spannt sich ein Abweichungsrechteck vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) und genauso für \\(Y\\). Wir bezeichnen mit \\(dx_i\\) die Distanz (Abweichung) vom Mittelwert \\(\\bar{x}\\) bis zum Messwert \\(x_i\\) (und analog \\(dy_i\\)), also \\(dx_i = x_i - \\bar{x}\\). Die Fläche des Abweichungsrechtecks ist dann das Produkt der Abweichungen: \\(dx_i \\cdot dy_i\\). \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 8.3: Die Kovarianz als mittleres Abweichungsrechteck. In jedem der vier Quadranten (Q1, Q2, Q3, Q4) ist das Vorzeichen der Abweichungsrechtecke dargestellt. Die Farben der Abweichungsrechtecke spiegeln das Vorzeichen wider.\n\n\n\n\nStellen Sie sich vor, wir legen alle Rechtecke zusammen aus Abbildung 8.3. Nennen wir das resultierende Rechteck das “Summenrechteck”. Ja, ich weiß, ich strapaziere mal wieder Ihre Phantasie. Jetzt kommt’s: Je größer die Fläche des Summenrechtecks ist, desto stärker der (lineare) Zusammenhang. Beachten Sie, dass die Flächen Vorzeichen haben, positiv oder negativ (Plus oder Minus), je nachdem, in welchem der vier Quadranten sie stehen. Die Füllfarben der Rechtecke verdeutlichen dies, s. Abbildung 8.3. Das Vorzeichen der Summe zeigt an, ob der Zusammenhang positiv (gleichsinnig, ansteigende Trendlinie) oder negativ (gegensinnig, absinkende Trendlinie) ist. So zeigt Abbildung 8.4 links eine positive Summe der Abweichungsrechtecke und rechts eine negative Summe. Man sieht im linken Teildiagramme, dass die Summe der Rechtecke mit positivem Vorzeigen (oben-rechts und unten-links) überwiegt; im rechten Teildiagramm ist es umgekehrt: Die Rechtecke in Quadranten mit negativem Vorzeichen überwiegen (oben-links und unten-rechts).\n\n\n\n\n\n\n\n\n\n\n(a) Positive Vorzeichen (Quadranten rechts-oben und links-unten) überwiegen, was in einer positiven Kovarianz resultiert\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Negative Vorzeichen (Quadranten links-oben und rechts-unten) überwiegen, was in einer negativen Kovarianz resultiert\n\n\n\n\n\n\nAbbildung 8.4: Positive und negative Kovarianz: Einmal resultiert eine positive Summe, einmal eine negative Summe, wenn man die Flächen der Abweichungsrechtecke addiert.\n\n\n\nWir können das Summenrechteck noch durch die Anzahl der Datenpunkte teilen, das ändert nichts an der Aussage, aber der Mittelwert hat gegenüber der Summe den Vorteil, dass er in seiner Aussage unabhängig ist von der Anzahl der eingegangenen Datenpunkte. Das resultierende Rechteck nennen wir das mittlere Abweichungsrechteck. Ein Maß für den Zusammenhang von Lernzeit und Klausurpunkte ist also die Fläche des mittleren Abweichungsrechtecks, s. Abbildung 8.5.\n\n\n\n\n\nAbbildung 8.5: Die Kovarianz als mittleres Abweichungsrechteck. Die Fläche der Rechtecks entspricht dem Wert der Kovarianz.\n\n\n\n8.3.2 Kovarianz\n\nDefinition 8.2 (Kovarianz) Die Kovarianz ist definiert als die Fläche des mittleren Abweichungsrechtecks. Sie ist ein Maß für die Stärke und Richtung des linearen Zusammenhangs zweier metrischer Variablen, s. Abbildung 8.5. \\(\\square\\)\n\n\n🧑‍🎓 Zu viele Bilder! Ich brauch Zahlen.\n\n\n🧑‍🏫 Kommen gleich!\n\nTabelle 8.2 zeigt beispielhaft, wie sich die Kovarianz berechnet. Berechnen wir als Nächstes das mittlere Abweichungsrechteck, die Kovarianz, für die Noten und Lernzeit der vier Studierenden aus Tabelle 8.1. Sie beträgt 162.\nWenn Sie die Werte selber nachrechnen wollen, finden Sie den Noten-Datensatz in der Datei noten.csv.\n\n\n\nTabelle 8.2: Werte der Abweichungsrechtecke. avg: average (Mittelwert), cov_sign: Vorzeichen der Kovarianz,_pos: positiver Wert auf der entsprechenden Achse (x/y), xy_area: Produkt von x_delta und y_delta\n\n\n\n\nid\ny\nx\nx_avg\ny_avg\nx_delta\ny_delta\ncov_sign\nxy_area\n\n\n\n1\n72\n70\n53\n51\n17\n20.8\n1\n353\n\n\n2\n44\n40\n53\n51\n-13\n-7.2\n1\n94\n\n\n3\n39\n35\n53\n51\n-18\n-12.2\n1\n220\n\n\n4\n50\n67\n53\n51\n14\n-1.2\n-1\n-18\n\n\n\n\n\n\n\n\n\nd %&gt;%\n  summarise(kovarianz = mean(xy_area))\n\n\n  \n\n\n\nDie Formel der Kovarianz lautet, s. Gleichung 8.1:\n\\[\\text{cov(xy)} = s_{xy}:=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{1}{n}\\sum_{i=1}^n dx_i\\cdot dy_i \\tag{8.1}\\]\nGleichung 8.1 in Worten ausgedrückt:\n\nRechne für jedes \\(x_i\\) die Abweichung vom Mittelwert, \\(\\bar{x}\\), aus, \\(dx_i\\).\nRechne für jedes \\(y_i\\) die Abweichung vom Mittelwert, \\(\\bar{y}\\), aus, \\(dy_i\\).\nMultipliziere für alle \\(i\\) \\(dx_i\\) mit \\(xy_i\\), um die Abweichungsrechtecke \\(dx_i dy_i\\) zu erhalten.\nAddiere die Flächen der Abweichungsrechtecke.\nTeile durch die Anzahl der Beobachtungen \\(n\\).\n\n\nBeispiel 8.2 (Variablen mit positiver Kovarianz)  \n\nGröße und Gewicht\nLernzeit und Klausurerfolg\nDistanz zum Ziel und Reisezeit\nTemperatur und Eisverkauf \\(\\square\\)\n\n\n\n\nBeispiel 8.3 (Variablen mit negativer Kovarianz)  \n\nLernzeit und Freizeit\nAlter und Restlebenszeit\nTemperatur und Schneemenge\nLebenszufriedenheit und Depressivität\\(\\square\\)\n\n\n\nZwei Extrembeispiele für Kovarianz-Werte sind in Abbildung 8.6 dargestellt.\n\n\n\n\n\n\n\n\n\n\n(a) kein Zusammenhang\n\n\n\n\n \n\n\n\n\n\n\n\n(b) perfekter (positiver) Zusammenhang\n\n\n\n\n\n\nAbbildung 8.6: Verschiedene Werte der Kovarianz\n\n\n\nBei einer Kovarianz von (ungefähr) Null ist die Gesamt-Fläche der Abweichungsrechtecke, wenn man sie pro Quadrant aufsummiert, (ungefähr) gleich groß, s. Abbildung 8.7. Zur Erinnerung: Bei der Varianz waren es Quadrate; bei der Kovarianz sind es jetzt Rechtecke.\nAddiert man die Abweichungsrechtecke (unter Beachtung der Vorzeichen), so beträgt die Summe in etwa (bzw. genau) Null. Damit ist die Kovarianz in diesem Fall etwa (bzw. genau) Null, s. Gleichung 8.2: Wenn die Summe der Aweichungsrechtecke Null ist, dann ist auch ihr Mittelwert (MW) Null. Damit ist die Kovarianz Null.\n\\[\\begin{aligned}\n\\sum \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{MW} \\left(dX \\cdot dY \\right) &= 0\\\\\n\\Leftrightarrow \\text{cov}(X, Y) &= 0\n\\end{aligned} \\tag{8.2}\\]\n\n\n\n\n\n\n\n\n\n\n(a) 4 Abweichungsrechtecke\n\n\n\n\n \n\n\n\n\n\n\n\n(b) 200 Abweichungsrechtecke\n\n\n\n\n\n\nAbbildung 8.7: Wenn die Kovarianz 0 ist, gleichen sich die Abweichungsrechtecke auf 0 aus; ihre Fläche addiert zu 0.\n\n\n\n\n8.3.3 Die Kovarianz ist schwer zu interpretieren\nDie Kovarianz hat den Nachteil, dass sie abhängig ist von der Skalierung. So steigt die Kovarianz z.\\(\\,\\)B. um den Faktor 100, wenn man eine Variable (z.\\(\\,\\)B. Einkommen) anstelle von Euro in Cent bemisst. Das ist nicht wünschenswert, denn der Zusammenhang zwischen z.\\(\\,\\)B. Einkommen und Lebenszufriedenheit ist unabhängig davon, ob man Einkommen in Euro, Cent oder Dollar misst. Außerdem hat die Kovarianz keinen Maximalwert, der einen perfekten Zusammenhang anzeigt. Insgesamt ist die Kovarianz schwer zu interpretieren und wird in der praktischen Anwendung nur wenig verwendet.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#korrelation",
    "href": "070-zusammenhaenge.html#korrelation",
    "title": "8  Punktmodelle 2",
    "section": "\n8.4 Korrelation",
    "text": "8.4 Korrelation\n\n8.4.1 Korrelation als mittleres z-Produkt\nDer Korrelationskoeffizient \\(r\\) nach Karl Pearson (1896) löst das Problem, dass die Kovarianz schwer interpretierbar ist. Der Wertebereich von \\(r\\) reicht von -1 (perfekte negative lineare Korrelation) bis +1 (perfekte positive lineare Korrelation). Eine Korrelation von \\(r = 0\\) bedeutet kein linearer Zusammenhang.\nDie Korrelation berechnet sich wie folgt:\n\nTeile alle \\(x_i\\) durch ihre Standardabweichung, \\(s_x\\)\n\nTeile alle \\(y_i\\) durch ihre Standardabweichung, \\(s_y\\)\n\nBerechne mit diesen Werten die Kovarianz\n\nTeilt man nämlich alle \\(x_i\\) bzw. \\(y_i\\) durch ihre Standardabweichung, so führt man mit \\(X\\) bzw. \\(Y\\) eine z-Transformation durch. Daher kann man den Korrelationskoeffizienten \\(r\\) definieren wie in Definition 8.3.\n\nDefinition 8.3 (Korrelationskoeffizient \\(r\\)) Der Korrelationskoeffizient \\(r\\) (nach Pearson) ist definiert als das mittlere Produkt der z-Wert-Paare, s. Gleichung 8.3, vgl. Cohen et al. (2003). Er ist ein Maß des linearen Zusammenhangs zweier metrischer Variablen. Der Wertebereich ist \\([-1;1]\\), wobei 0 keinen linearen Zusammenhang anzeigt und \\(|r|=1\\) perfekten linearen Zusammenhang. \\(\\square\\)\n\n\\[r_{xy}=\\frac{1}{n}\\sum_{i=1}^n z_{x_i} z_{y_i} \\tag{8.3}\\]\nMan beachte, dass eine Korrelation (genauso wie eine Kovarianz) nur für metrische Variablen definiert ist. Aus dem Korrelationskoeffizienten können Sie zwei Informationen ableiten:\n\n\nVorzeichen: Ein positives Vorzeichen bedeutet positiver (gleichsinniger) linearer Zusammenhang (und umgekehrt: negatives Vorzeichen, negativer, also gegensinniger linearer Zusammenhang).\n\nAbsolutwert der Korrelation: Der Absolutwert (Betrag) des Korrelationskoeffizienten gibt die Stärke des linearen Zusammenhangs an. Je näher der Wert bei 1 liegt, desto stärker ist der (lineare) Zusammenhang.\n\nEine Zuordnung des Korrelationskoeffizienten zum Profil des Streudiagramms zeigt Abbildung 8.8.\n\n\n\n\n\nAbbildung 8.8: Verschiedene Streudiagramme, die sich in ihrem Korrelationskoeffizienten unterscheiden (DenisBoigelot, 2011)\n\n\nDie untere Zeile von Abbildung 8.8 zeigt Beispiele für nicht-lineare Zusammenhänge. Wie man sieht, liegt in diesen Beispielen kein linearer Zusammenhang vor (\\(r=0\\)), obwohl ein starker nicht-linearer Zusammenhang besteht.\n\nÜbungsaufgabe 8.2 (Korrelationsspiel) Spielen Sie das Korrelationsspiel2: Sie Sehen ein Streudiagramm und müssen den richtigen Korrelationskoeffizienten eingeben. \\(\\square\\)\n\n\nÜbungsaufgabe 8.3 (Interaktive Visualisierung der Korrelation) Auf der Seite von RPsychologist3 findet sich eine ansprechende dynamische Visualisierung der Korrelation. Nutzen Sie sie, um Ihr Gefühl für die Stärke des Korrelationskoeffizienten zu entwickeln. \\(\\square\\)\n\nEine Korrelation von \\(r = 0\\) bedeutet, dass es keinen linearen Zusammenhang gibt; eine Korrelation von \\(|r| = 1\\) meint einen perfekten linearen Zusammenhang. Aber was ist ein “schwacher”, “mittlerer” oder “starker” Zusammenhang? Cohen (1988) hat dazu grobe (!) Richtlinien vorgeschlagen, s. Tabelle 8.3.\n\n\nTabelle 8.3: Interpretation von (absoluten) Korrelationskoeffizienten\n\n\n\n\\(|r|\\)\nGrobe Interpretation\n\n\n\n0.01 – 0.09\nsehr schwach\n\n\n0.10 – 0.29\nschwach\n\n\n0.30 – 0.49\nmittel\n\n\n≥0.50\nstark\n\n\n\n\n\n\n\n8.4.2 Korrelation mit R berechnen\nOb der Verkaufspreis (total_pr) wohl mit der Dauer der Auktion (duration) oder mit der Anzahl der Gebote (n_bids) (linear) zusammenhängt? Schauen wir nach! Die Funktion correlation (aus dem Paket easystats) erledigt das Rechnen für uns, s. Tabelle 8.4.\n\nmariokart |&gt; \n  select(total_pr, duration, n_bids) |&gt; \n  correlation()  |&gt;  # aus `easystats`\n  summary()\n\n\n\n\nTabelle 8.4: Korrelation berechnen mittels der Funktion correlation aus easystats\n\n\n\n\nParameter\nn_bids\nduration\n\n\n\ntotal_pr\n0.13\n-0.04\n\n\nduration\n-0.12\n\n\n\n\n\n\n\n\n\nSie können auch auf die letzte Zeile, also dem Befehl summary verzichten. Dann ist die Ausgabe ausführlicher.\n\n8.4.3 Korrelation ist nicht Kausation\nEine Studie fand eine starke Korrelation zwischen der (Höhe des) Schokoladenkonsums eines Landes und (Anzahl der) Nobelpreise eines Landes (Messerli, 2012), s. Abbildung 8.9.\n\n\n\n\n\nAbbildung 8.9: Schoki futtern macht schlau? (Messerli, 2012)\n\n\nKorrelation (bzw. Zusammenhang) ist ungleich Kausation! Korrelation kann bedeuten, dass eine Kausation vorliegt, aber es muss auch nicht sein, dass Kausation vorliegt. Liegt Korrelation ohne Kausation vor, so spricht man von einer Scheinkorrelation.\n\n8.4.4 Korrelation misst nur linearen Zusammenhang\n\nBeispiel 8.4 (Scheinkorrelation: Störche und Babys) Ein Mythos besagt: Die Anzahl der Störche pro Landkreis korreliert mit der Anzahl der Babys in diesem Landkreis (vgl. Matthews, 2000). Eine mögliche Erklärung für dieses (nur scheinbare) Paradoxon ist, dass die “Naturbelassenheit” des Landkreises die gemeinsame Ursache von Störchen ist (Störche lieben Natur) und Babys ist (die Gegebenheiten bei hoher Naturbelassenheit begünstigteine höhere Zahl von Kindern pro Frau). Wir müssen die Erklärung keinesfalls glauben; sie soll das Beispiel nur konkreter machen. Uns geht es hier nur um die Erkennung von Scheinkorrelation. \\(\\square\\)\n\n\nBeispiel 8.5 (Glatze macht Corona?) Kahle Männer aufgepasst! Macht eine Glatze krank? Männer mit Glatze bekommen häufiger Corona (Goren et al., 2020): “Bald men at higher risk of severe case of Covid-19, research finds”. Eine alternative Erklärung lautet, dass Alter einen Effekt hat auf Glatze (je älter ein Mann, desto wahrscheinlicher ist es, dass er eine Glatze hat) und auf die Schwere des Corona-Verlaufs (ältere Menschen haben deutlich schwerere Corona-Verläufe). \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "href": "070-zusammenhaenge.html#wie-man-mit-statistik-lügt",
    "title": "8  Punktmodelle 2",
    "section": "\n8.5 Wie man mit Statistik lügt",
    "text": "8.5 Wie man mit Statistik lügt\n\n8.5.1 Einschränkung der Spannweite\nDurch (nicht-randomisierte) Einschränkung (Restriktion) der Spannweite einer (oder beider) Variablen sinkt die Stärke (der Absolutwert) einer Korrelation, vgl. Cohen et al. (2003); s. Abbildung 8.10.\nErstellen wir uns dazu zwei Datensätze mit je zwei Variablen, \\(X\\) und \\(Y\\) und mit Umfang \\(n=100\\). Einer der beiden Datensätze sei mit Einschränkung der Spannweite und einer ohne. \\(X\\) und \\(Y\\) seien normalverteilt mit \\(\\mu=0\\) (Mittelwert) und \\(\\sigma=1\\) (Streuung); s. Datensatz d in Listing 8.1. Man kann sich mit dem Befehl rnorm(n, m, sd) \\(n\\) normalverteilte Variablen mit Mittelwert \\(m\\) und Streuung \\(sd\\) von R erzeugen lassen. Wir schränken dann den Wertebereich von \\(X\\) ein auf, sagen wir, auf \\([-0.5, .5]\\) (Datensatz d_filtered), s. Listing 8.1.\n\n\n\nListing 8.1: Korrelation mit eingeschränkter Spannweite\n\nn &lt;- 1e2\nd &lt;- tibble(x = rnorm(n = n, mean = 0, sd = 1),\n            e = rnorm(n = n, mean = 0, sd = .5),\n            y = x + e)\n\nx_min &lt;- -0.5\nx_max &lt;- 0.5\n\nd_filtered &lt;-  # Range-Einschränkung:\nd |&gt; filter(between(x, x_min, x_max))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Ohne Einschränkung des Range: Starke Korrelation\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Mit Einschränkung des Range: Schwächere Korrelation\n\n\n\n\n\n\nAbbildung 8.10: Schränkt man den Range einer (oder beider) Variablen ein, so sinkt die Stärke der Korrelation\n\n\n\n\nÜbungsaufgabe 8.4 (Berechnen Sie die Korrelation) Glauben Sie nicht, prüfen Sie nach! Berechnen Sie die Korrelation von \\(X\\) und \\(Y\\) im Datensatz d und d_filtered! \\(\\square\\)",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallbeispiel",
    "href": "070-zusammenhaenge.html#fallbeispiel",
    "title": "8  Punktmodelle 2",
    "section": "\n8.6 Fallbeispiel",
    "text": "8.6 Fallbeispiel\nIn Ihrer Arbeit beim Online-Auktionshaus analysieren Sie, welche Variablen mit dem Verkaufspreis von Computerspielen zusammenhängen. Falls der Datensatz auf Ihrem Computer (am besten in Ihrem Projektverzeichnis in RStudio) abgelegt ist, können Sie die Daten so (in mittlerweile gewohnter Manier) importieren: mariokart &lt;- read.csv(\"mariokart.csv\") Falls der Datensatz im Unterordner mit Namen “Mein_Unterordner” liegt, so würden Sie folgenden Pfad eingeben: mariokart &lt;- read.csv(\"Mein_Unterordner/mariokart.csv\"). Man beachte, dass solche sog. relativen Pfade, wie Mein_Unterordner/, die relativ zu Ihrem Arbeitsverzeichnis, d.\\(\\,\\)h. Ihr Projektverzeichnis in R-Studio, liegen, nicht mit einem Schrägstrich (Slash) beginnen. Falls Sie die Daten nicht auf Ihrem Computer haben, können Sie sie bequem von z.\\(\\,\\)B. der Webseite von Vincent Arel-Bundock herunterladen. Den Pfad hatten wir in Listing 1.1 definiert.\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\nSie wählen die Variablen von mariokart, die Sie in diesem Fall interessieren – natürlich nur die metrischen – und lassen sich mit cor die Korrelation aller Variablen untereinander ausgeben:\n\nmariokart %&gt;%  \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  cor() %&gt;% \n  round(2) # Runden auf zwei Dezimalen\n##             duration n_bids start_pr ship_pr total_pr seller_rate wheels\n## duration        1.00  -0.12     0.13    0.27    -0.04       -0.15  -0.30\n## n_bids         -0.12   1.00    -0.63    0.03     0.13       -0.11  -0.08\n## start_pr        0.13  -0.63     1.00    0.03     0.07        0.28   0.16\n## ship_pr         0.27   0.03     0.03    1.00     0.54       -0.02   0.05\n## total_pr       -0.04   0.13     0.07    0.54     1.00        0.01   0.33\n## seller_rate    -0.15  -0.11     0.28   -0.02     0.01        1.00  -0.15\n## wheels         -0.30  -0.08     0.16    0.05     0.33       -0.15   1.00\n\nAchtung, Namensverwechslung! Es kann vorkommen, dass Sie zwei R-Pakete geladen haben, in denen es jeweils z.\\(\\,\\)B. eine Funktion mit Namen select gibt. R wird in dem Fall diejenige Funktion verwenden, deren Paket Sie als letztes gestartet haben. Das kann dann das falsche select sein. In dem Fall resultiert eine verwirrende Fehlermeldung, die sinngemäß sagt: “Hey Mensch, du hast Argumente in der Funktion verwendet, die du gar nicht verwenden darfst, da es sie nicht gibt.” Auf Errisch: Error in select(., duration, n_bids, start_pr, ship_pr, total_pr, seller_rate,  : unused arguments (duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels). Eine einfache Abhilfe ist es, R zu sagen: “Hey R, nimm gefälligst select aus dem Paket dplyr, dort”wohnt” nämlich select. Auf Errisch spricht sich das so: dplyr::select(...).\nEtwas schöner sieht die Ausgabe mit dem Befehl correlation aus easystats aus, s. Tabelle 8.5.\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) |&gt; \n  correlation() |&gt; \n  summary()\n\n\n\n\nTabelle 8.5: Korrelationstabelle (tidy) im Datensatz mariokart\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nwheels\nseller_rate\ntotal_pr\nship_pr\nstart_pr\nn_bids\n\n\n\nduration\n-0.30**\n-0.15\n-0.04\n0.27*\n0.13\n-0.12\n\n\nn_bids\n-0.08\n-0.11\n0.13\n0.03\n-0.63***\n\n\n\nstart_pr\n0.16\n0.28*\n0.07\n0.03\n\n\n\n\nship_pr\n0.05\n-0.02\n0.54***\n\n\n\n\n\ntotal_pr\n0.33**\n0.01\n\n\n\n\n\n\nseller_rate\n-0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Sternchen in Tabelle 8.5 geben die sog. statistische Signifikanz der Korrelation an; ein Thema, das wir einfach gekonnt ignorieren.\nMöchte man nur einzelne Korrelationskoeffizienten ausrechnen, können wir die Idee des Zusammenfassens, s. Abbildung 8.1, nutzen: mariokart %&gt;% summarise(korrelation = cor(total_pr, wheels)).\nIm Falle von fehlenden Werte müssen Sie den Befehl cor aus seiner schüchternen Vorsicht befreien und ermutigen, trotz fehlender Werte einen Korrelationskoeffizienten auszugeben. Das geht mit dem Argument use = \"complete.obs\" in cor.\n\nmariokart %&gt;% \n  summarise(cor_super_wichtig = cor(total_pr, wheels, use = \"complete.obs\"))\n\n\n🧑‍🎓 Immer so viele Zahlen! Ich brauch Bilder.\n\nMit dem Befehl plot_correlation aus dem R-Paket dataExplorer bekommt man eine ansehnliche Heatmap zur Verdeutlichung der Korrelationswerte, s. Abbildung 8.11.\n\nlibrary(DataExplorer)\n\nmariokart %&gt;% \n  dplyr::select(duration, n_bids, start_pr, ship_pr, total_pr, seller_rate, wheels) %&gt;% \n  plot_correlation()\n\n\n\n\n\n\nAbbildung 8.11: Heatmap zu den Korrelationen im Datensatz mariokart.",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#aufgaben",
    "href": "070-zusammenhaenge.html#aufgaben",
    "title": "8  Punktmodelle 2",
    "section": "\n8.7 Aufgaben",
    "text": "8.7 Aufgaben\nSchauen Sie sich auch mal auf der Webseite Datenwerk4 die Aufgaben zu dem Tag association an.\n\nnasa02\nmariokart-korr1\nmariokart-korr2\nmariokart-korr3\nmariokart-korr4\nkorr01\nkorr02\n\n\n\n\nTesten Sie Ihr Wissen mit einem Quiz zur deskriptiven Statistik (Maße der zentralen Tendenz, Variabilität, Verteilungsformen, Normalverteilung, Korrelation).",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#fallstudien",
    "href": "070-zusammenhaenge.html#fallstudien",
    "title": "8  Punktmodelle 2",
    "section": "\n8.8 Fallstudien",
    "text": "8.8 Fallstudien\nBitte verstehen Sie die folgenden Fallstudien als eine Auswahl. Es ist nicht nötig, dass Sie alle Fallstudien bearbeiten. Sehen Sie die Fallstudien eher als Angebot zur selektiven Vertiefung und Übung, dort, wo Sie es nötig haben.\n\n\nYACSDA: EDA zu Flugverspätungen5 im Datenwerk unter dem Tag flights-yacsda-eda zu finden.\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinige der Fallstudien oder Übungsaufgaben können theoretische Inhalte (Konzepte der Statistik) oder praktische Inhalte (R-Befehle) enthalten, die Sie (noch) nicht kennen. In dem Fall: Einfach ignorieren. Oder Sie suchen nach einer Lösung anhand von Konzepten bzw. R-Befehlen, die Sie kennen. \\(\\square\\)\n\n\n\n\nYACSDA: Topgear6\n\n\nDatensatz flights: Finde den Tag mit den meisten Abflügen7\n\n\nTidyverse Case Study: Exploring the Billboard Charts8",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#literaturhinweise",
    "href": "070-zusammenhaenge.html#literaturhinweise",
    "title": "8  Punktmodelle 2",
    "section": "\n8.9 Literaturhinweise",
    "text": "8.9 Literaturhinweise\nAuch die Korrelation ist ein Allzeit-Favorit in der Statistik; entsprechend wird Ihnen jedes typische Statistik-Buch die Grundlagen erläutern. Schauen Sie doch mal, was Ihre Bibliothek Ihnen zu bieten hat. Wer eine unorthodoxe (geometrische!) Herangehensweise an die Korrelation (und Regression) sucht, darf sich auf eine Menge Aha-Momente bei Kaplan (2009) freuen. Ein schönes, modernes Statistikbuch bietet Poldrack (2023); auch dieses Buch ist frei online verfügbar. Tipp: Nutzen Sie die Übersetzungfunktion Ihres Browsers, wenn Sie das Buch nicht in Englisch lesen wollen. Ein Klassiker, wenn auch nicht mehr ganz frisch, ist Cohen et al. (2003); immer noch sehr empfehlenswert, aber etwas höheren Anspruchs. Was ist Scheinkorrelation und was ist “echte” Korrelation? Dieser Unterschied – der für die Wissenschaft zentral ist – wird von Pearl & Mackenzie (2018) auf entspannte Art erläutert; nebenbei lernt man einiges zur Geschichte der Wissenshaft.\nHier finden Sie weitere Beispiele für Scheinkorrelationen. Dieser TED-Vortrag informiert zum Thema Scheinkorrelation.\n\n\n\n\nCohen, J. (1988). Statistical Power Analysis for the Behavioral Sciences. Routledge. http://dx.doi.org/10.4324/9780203771587\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed. Lawrence Erlbaum.\n\n\nDenisBoigelot. (2011). English: Redesign File:Correlation_examples.Png Using Vector Graphics (SVG File) [Artwork]. https://commons.wikimedia.org/w/index.php?curid=15165296\n\n\nGoren, A., Vaño-Galván, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur, A., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H., Kovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K. (2020). A Preliminary Observation: Male Pattern Hair Loss among Hospitalized COVID-19 Patients in Spain – A Potential Clue to the Role of Androgens in COVID-19 Severity. Journal of Cosmetic Dermatology, 19(7), 1545–1547. https://doi.org/10.1111/jocd.13443\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nMesserli, F. H. (2012). Chocolate Consumption, Cognitive Function, and Nobel Laureates. New England Journal of Medicine, 367(16), 1562–1564. https://doi.org/10.1056/NEJMon1211064\n\n\nPearl, J., & Mackenzie, D. (2018). The Book of Why: The New Science of Cause and Effect. Basic Books.\n\n\nPearson, K. (1896). VII. Mathematical Contributions to the Theory of Evolution.—III. Regression, Heredity, and Panmixia. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 187, 253–318. https://doi.org/10.1098/rsta.1896.0007\n\n\nPoldrack, R. A. (2023). Statistical Thinking: Analyzing Data in an Uncertain World. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "070-zusammenhaenge.html#footnotes",
    "href": "070-zusammenhaenge.html#footnotes",
    "title": "8  Punktmodelle 2",
    "section": "",
    "text": "🧑‍🎓 Typisches Lehrerbeispiel!↩︎\nhttps://gallery.shinyapps.io/correlation_game/↩︎\nhttps://rpsychologist.com/correlation/↩︎\nhttps://sebastiansauer.github.io/Datenwerk/↩︎\nhttps://sebastiansauer.github.io/Datenwerk/posts/flights-yacsda-eda↩︎\nhttps://data-se.netlify.app/2021/02/11/yacda-topgear/↩︎\nhttps://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/↩︎\nhttps://www.njtierney.com/post/2017/11/07/tidyverse-billboard/↩︎",
    "crumbs": [
      "Grundlagen des Modellieren",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Punktmodelle 2</span>"
    ]
  },
  {
    "objectID": "080-regression1.html",
    "href": "080-regression1.html",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1 Einstieg\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\nIn diesem Kapitel benötigen Sie die üblichen R-Pakete (tidyverse, easystats) und Daten (mariokart), s. Kapitel 3.7.3 und Kapitel 3.4.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#einstieg",
    "href": "080-regression1.html#einstieg",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "9.1.1 Lernziele\n\nSie können ein Punktmodell von einem Geradenmodell begrifflich unterscheiden.\nSie können die Bestandteile eines Geradenmodells aufzählen und erläutern.\nSie können die Güte eines Geradenmodells anhand von Kennzahlen bestimmen.\nSie können Geradenmodelle sowie ihre Modellgüte in R berechnen.\n\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#vorhersagen",
    "href": "080-regression1.html#vorhersagen",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.2 Vorhersagen",
    "text": "9.2 Vorhersagen\nVorhersagen sind eine nützliche Sache, unter (mindestens) folgenden Voraussetzungen: 1. Sie sind präzise; 2. Wir wissen, wie präzise; 3. Jemand interessiert sich für die Vorhersage. Die Methode des Vorhersagens, die wir hier betrachten, nennt man auch lineare Regression.\n\n9.2.1 Vorhersagen ohne UV\n\nBeispiel 9.1 Nach intensiver Beschäftigung mit Statistik sind Sie allgemein als Daten-Checker bekannt. Viele Studierende fragen Sie um Rat. Eines Tages kommt eine Studentin zu Ihnen, Toni, und fragt: “Welche Statistiknote kann ich in der Klausur erwarten?” Sie entgegnen: “Wie viel hast du denn gelernt?”. Die Antwort: “Sage ich nicht.” Nach kurzem Überlegen geben Sie den Notenschnitt der letzten Klausur als Prognose für diese Person. Dazu rechnen Sie schnell den Notenschnitt (Mittelwert) aus.\nZuerst importieren Sie die Daten der letzten Klausur. Die Syntax in Listing 9.1 wird bei Ihnen nur funktionieren, wenn auf Ihrem Computer dieser Ordner mit dieser Datei existiert. Andernfalls müssen Sie die Daten erst herunterladen1:\n\n\n\nListing 9.1: Wenn der Datensatz ‘noten2’ im Unterordner ‘Noten’ liegt.\n\nnoten2 &lt;- read.csv(\"data/noten2.csv\")\n\n\n\n\n Download \n\nnoten2 %&gt;% \n  summarise(mw = mean(y))  # y ist der Punktwert in der Klausur\n\n\n\nmw\n\n\n91\n\n\n\n\nIhre Überlegung: “Im Schnitt haben die Studis bei der letzten Klausur ungefähr 91.12 erzielt. Diesen Wert kannst du erwarten. Solange ich keine genaueren Infos habe, z.\\(\\,\\)B. wie viel du gelernt hast, kann ich dir keine genauere Vorhersage machen. Sorry!” \\(\\square\\)\n\nOhne Kenntnis einer UV (Prädiktor) (wie z.\\(\\,\\)B. Lernzeit) ist der Mittelwert ein geeigneter Vorhersagewert für jede Beobachtung, s. Abbildung 9.1. Wir nutzen den Mittelwert als Punktmodell für den Klausurerfolg. \\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 9.1: Mittelwert als Vorhersagewert, bzw. Mittelwert als Punktmodell\n\n\n\n\n\nDefinition 9.1 (Nullmodell (Punktmodell)) Modelle ohne UV, Punktmodelle also, kann man so bezeichnen: y ~ 1. Da das Modell null UV hat, nennt man es auch manchmal Nullmodell. \\(\\square\\)\n\nAuf Errisch kann man dieses Nullmodell so spezifizieren:\n\n# results: show\nlm0 &lt;- lm(y ~ 1, data = noten2)\nlm0\n## \n## Call:\n## lm(formula = y ~ 1, data = noten2)\n## \n## Coefficients:\n## (Intercept)  \n##        91.1\n\nlm steht für “lineares Modell”, die 1 sagt, dass es keine Prädiktoren gibt. In dem Fall wird der Mittelwert, 91, als Gerade verwendet. Der zurückgemeldete Koeffizient (Intercept) ist in diesem Fall der einzige Koeffizient des Modells. Da es ein Punktmodell ist, sagt es für alle Beobachtungen (hier Studierenden) den gleichen Wert vorher, nämlich 91.\n\n9.2.2 Vorhersagen mit UV\n\nBeispiel 9.2 (Toni verrät die Lernzeit) Toni entschließt sich dann doch noch, die Lernzeit zu verraten: “Okay, also ich hab insgesamt 42 Stunden gelernt, insgesamt.” Jetzt müssen Sie erstmal nachdenken: “Wie viele Klausurpunkte sage ich vorher, wenn Toni 42 Stunden gelernt hat?”\nSie visualisieren sich zur Hilfe die vorliegenden Daten, s. Abbildung 9.2, (a).\n\nlibrary(DataExplorer)\nnoten2 %&gt;% \n  plot_scatterplot(by = \"y\")  # Y-Variable muss angegeben werden\n\nAuf dieser Basis antworten Sie Toni: “Bei 42 Stunden Lernzeit solltest du so 83 Punkte bekommen. Könnte mit dem Bestehen eng werden.” Toni ist nicht begeistert von Ihrer Prognose und zieht von dannen. \\(\\square\\)\n\nDer “Trend” (im Sinne eines linearen Zusammenhangs) von Lernzeit und Klausurpunkte ist deutlich zu erkennen: Je mehr Lernzeit, desto mehr Klausurpunkte. Mit einem Lineal könnte man eine entsprechende Gerade in das Streudiagramm einzeichnen, s. Abbildung 9.2, (b).\n\n\n\n\n\n\n\n\n\n(a) Streudiagramm\n\n\n\n\n\n\n\n\n\n(b) Streudigramm mit ‘Trendgerade’\n\n\n\n\n\n\nAbbildung 9.2: Noten und Lernzeit: Rohdaten (a) und mit Modell (b). Mittelwerte sind mit gestrichelten Linien eingezeichnet. Tonis Vorhersage ist mit einem Punkt markiert.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#geradenmodelle",
    "href": "080-regression1.html#geradenmodelle",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.3 Geradenmodelle",
    "text": "9.3 Geradenmodelle\n\n9.3.1 Achsenabschnitt und Steigung definieren eine Gerade\nWir verwenden eine Gerade als Modell für die Daten, s. Abbildung 9.2, b. Anders gesagt: Wir modellieren die Daten (bzw. deren Zusammenhang) mit einer Geraden. Ein Geradenmodell ist eine Verallgemeinerung des Punktmodells: Ein Punktmodell sagt für alle Beobachtungen den gleichen Wert vorher. Abbildung 9.1 und Abbildung 9.2 stellen ein Punktmodell einem Geradenmodell gegenüber.\nIn einem Geradenmodell wird nicht mehr (notwendig) für jede Beobachtung die gleiche Vorhersage \\(\\hat{y}\\) gemacht (wie das bei einem Punktmodell der Fall ist).\n\nDefinition 9.2 (Gerade) Eine Gerade ist das, was man bekommt, wenn man eine lineare Funktion in ein Koordinatensystem einzeichnet. Man kann sie durch durch zwei Koeffizienten festlegen: Achsenabschnitt (engl. intercept), und Steigung (engl. slope). \\(\\square\\)\n\nManchmal wird (z.\\(\\,\\)B. im Schulunterricht) der Achsenabschnitt mit \\(t\\) und die Steigung mit \\(m\\) bezeichnet:\n\n\\(f(\\color{xcol}{x})=\\color{ycol}{y}={m} \\color{xcol}{x} + \\color{beta0col}{t}\\).\nIn der Statistik wird folgende Nomenklatur bevorzugt: \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}=\\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\color{xcol}{x}\\) oder \\(f(\\color{xcol}{x})=\\color{ycol}{\\hat{y}}= \\color{beta0col}{b_0} + \\color{beta1col}{b_1} \\color{xcol}{x}\\) .\nDie Nomenklatur mit \\(\\color{beta0col}{b_0}, \\color{beta1col}{b_1}\\) hat den Vorteil, dass man das Modell einfach erweitern kann: \\(b_2, b_3, \\ldots\\). Anstelle von \\(b\\) liest man auch oft \\(\\beta\\). Griechische Buchstaben werden meist verwendet, um zu zeigen, dass man an einer Aussage über eine Population, nicht nur über eine Stichprobe, machen möchte.\nDas “Dach” über y, \\(\\color{modelcol}{\\hat{y}}\\) (sprich: “y-Dach”), drückt aus, dass es sich den den geschätzten, bzw. vom Modell vorhergesagten (“modellierten”) Wert für \\(\\color{ycol}{y}\\) handelt, nicht der tatsächliche (empirische, beobachtete) Wert von \\(\\color{ycol}{y}\\). Abbildung 9.3 skizziert die Elemente einer Regression.\n\n\n\n\n\nAbbildung 9.3: Achsenabschnitt (\\(\\beta_0\\)) und Steigung (\\(\\beta_1\\)) einer Regressionsgeraden (Menk, 2014)\n\n\n\n\nDefinition 9.3 (Das einfache lineare Modell) Das einfache lineare Modell beschreibt den Wert einer abhängigen metrischen Variablen, \\(\\color{ycol}{y}\\), als lineare Funktion von einer (oder mehreren) unabhängigen Variablen, \\(\\color{xcol}{x}\\), plus einem Fehlerterm, \\(\\color{errorcol}{e}\\) bzw. \\(\\color{errorcol}{\\epsilon}\\), s. Gleichung 9.1. \\(\\square\\)\n\n\\[\\begin{aligned}\n\\color{ycol}{y} &= f(\\color{xcol}{x}) + \\color{errorcol}{\\epsilon} \\\\\n\\color{ycol}{y_i} &= \\color{beta0col}{\\beta_0} + \\color{beta1col}{\\beta_1} \\cdot \\color{modelcol}{x_i} + \\color{errorcol}{\\epsilon_i} \\square\n\\end{aligned} \\tag{9.1}\\]\nDie Variablen in Gleichung 9.1 haben folgende Bedeutung:\n\n\n\\(\\color{beta0col}{\\beta_0}\\): geschätzter y-Achsenabschnitt laut Modell (engl. intercept)\n\n\\(\\color{beta1col}{\\beta_1}\\): geschätzte Steigung (Regressionsgewicht) laut Modell (engl. slope)\n\n\\(\\color{errorcol}{\\epsilon}\\): Fehler des Modells\n\nIn Gleichung 9.1 schreiben wir \\(\\color{ycol}{y}\\) und nicht \\(\\color{modelcol}{\\hat{y}}\\), weil wir den tatsächlichen, beobachteten Wert von \\(\\color{ycol}{y}\\) als Summe von vorhergesagtem Wert, \\(\\color{modelcol}{\\hat{y}}\\) und Modellfehler, \\(\\color{errorcol}{\\epsilon}\\) beschreiben.\nJe nach Datenlage können sich Regressionsgeraden in Steigung oder Achsenabschnitt unterscheiden, s. Abbildung 9.4.\n\n\n\n\n\n\n\n\n\n(a) Datensatz 1\n\n\n\n\n\n\n\n\n\n(b) Datensatz 2\n\n\n\n\n\n\nAbbildung 9.4: Regressionsanalysen mit verschiedenen Koeffizienten, aber gleicher Modellgüte\n\n\nAbbildung 9.5 zeigt ein interaktives Beispiel einer linearen Funktion. Sie können Punkte per Klick/Touch hinzufügen.\n\n\n\n\nresetButton = {\n  const resetButton = Inputs.button(\"Reset\");\n\n  d3.select(resetButton).on(\"input\", () =&gt; {\n\n    regressionPlot.reset();\n  });\n\n  return resetButton;\n}\n\n\n\n\n\n\n\nviewOptions = {\n  const viewOptions = Inputs.radio(\n    [\"None\", \"Absolute Error\", \"Squared Error\"],\n    { label: \"View\", value: \"Absolute Error\" }\n  );\n\n  d3.select(viewOptions).on(\"input\", () =&gt; {\n    regressionPlot.updateView(viewOptions.value);\n  });\n\n  return viewOptions;\n}\n\n\n\n\n\n\n\nrSquaredPlot = RSquaredPlot({ width: width })\n\n\n\n\n\n\n\nregressionPlot = {\n  const regressionPlot = RegressionPlot(data.slice(0, 1), {\n    width: width,\n    xDomain: [0, d3.max(data, ([x]) =&gt; x) + 5],\n    yDomain: [0, d3.max(data, ([_, y]) =&gt; y) + 5],\n    r: 6,\n    showGrid: true\n  });\n  // Attach listener\n  d3.select(regressionPlot).on(\"input\", function () {\n    rSquaredPlot.update(this.value, this.transition);\n  });\n\n  rSquaredPlot.update(regressionPlot.value);\n\n  return regressionPlot;\n}\n\n\n\n\n\n\n\nwidth = 800\ndata = {\n  const numPoints = 15;\n  const xScale = 10;\n  const xShift = 5;\n  const yScale = 6;\n  const yShift = 0;\n\n  const data = d3.range(numPoints).map((i) =&gt; {\n    const xCoord = xShift + xScale * d3.randomUniform()();\n    const yCoord = yShift + xCoord + yScale * d3.randomUniform()();\n\n    return [xCoord, yCoord];\n  });\n\n  return data;\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nanimation = {\n  // Perform opening animation\n  const totalTime = 6_000;\n  const ease = d3.easeQuadOut;\n\n  d3.range(1, data.length).forEach((i) =&gt; {\n    setTimeout(() =&gt; {\n      const [xCoord, yCoord] = data[i];\n\n      regressionPlot.updateDatapoint(xCoord, yCoord);\n    }, totalTime * ease(i / data.length));\n  });\n}\n\n\n\n\n\n\n\nfunction RSquaredPlot({\n  data,\n  marginTop = 0, // top margin, in pixels\n  marginRight = 30, // right margin, in pixels\n  marginBottom = 0, // bottom margin, in pixels\n  marginLeft = 53, // left margin, in pixels\n  width = 640, // outer width, in pixels\n  height = 20, // outer height, in pixels\n  barHeight = 25, // height of bar, in pixels\n  titleSize = 20, // fontsize of title text\n  labelSize = 12 // fontsize of label text\n} = {}) {\n  if (data === undefined) data = 0;\n\n  const xScale = d3\n    .scaleLinear()\n    .domain([0, 1])\n    .range([marginLeft, width - marginRight]);\n\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw title.\n  const titleGroup = svg.append(\"g\");\n\n  // titleGroup\n  //   .append(\"line\")\n  //   .attr(\"stroke\", \"black\")\n  //   .attr(\"x1\", xScale(0))\n  //   .attr(\"x2\", xScale(0))\n  //   .attr(\"y1\", 0)\n  //   .attr(\"y2\", height);\n\n  titleGroup\n    .append(\"text\")\n    .attr(\"fill\", \"black\")\n    .attr(\"text-anchor\", \"end\")\n    .attr(\"dominant-baseline\", \"middle\")\n    .attr(\"font-family\", \"serif\")\n    .attr(\"font-size\", titleSize)\n    .attr(\"x\", xScale(0))\n    .attr(\"dx\", -10)\n    .attr(\"y\", height / 2)\n    .text(\"R²\");\n\n  // Draw whole bar.\n  svg\n    .append(\"g\")\n    .append(\"rect\")\n    .attr(\"fill\", \"gainsboro\")\n    .attr(\"x\", xScale(0))\n    .attr(\"y\", marginTop)\n    .attr(\"width\", width - marginLeft - marginRight)\n    .attr(\"height\", height - marginTop - marginBottom);\n\n  // Draw bar.\n  const bar = updateBar(svg.append(\"g\").selectAll(\"rect\"), 0);\n\n  // Draw label\n  const labelFormat = d3.format(\".2f\");\n  const label = updateLabel(svg.append(\"g\").selectAll(\"text\"), 0);\n\n  // Update according to data.\n  update(data);\n\n  function updateBar(rect, data, transition = true) {\n    return rect.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"rect\")\n          .attr(\"fill\", \"black\")\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", marginTop)\n          .attr(\"width\", 0)\n          .attr(\"height\", height - marginTop - marginBottom),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          if (transition) update = update.transition();\n\n          update.attr(\"width\", (d) =&gt; xScale(isNaN(d) ? 0 : d) - xScale(0));\n        })\n    );\n  }\n\n  function updateLabel(text, data, transition = true) {\n    return text.data([data]).join(\n      (enter) =&gt;\n        enter\n          .append(\"text\")\n          .attr(\"dominant-baseline\", \"middle\")\n          .attr(\"font-family\", \"sans-serif\")\n          .attr(\"font-size\", labelSize)\n          .attr(\"font-weight\", \"bold\")\n          .attr(\"fill\", \"black\")\n          .attr(\"text-anchor\", \"start\")\n          .attr(\"dx\", 10)\n          .attr(\"x\", xScale(0))\n          .attr(\"y\", height / 2)\n          .text(labelFormat(\"0\")),\n      (update) =&gt;\n        update.call((update) =&gt; {\n          // Check if bar is too short\n          const check = (d) =&gt; d &lt; 0.1;\n\n          if (transition) update = update.transition();\n\n          update\n            .attr(\"x\", (d) =&gt; xScale(d))\n            .text((d) =&gt; labelFormat(d))\n            .attr(\"fill\", (d) =&gt; (check(d) ? \"black\" : \"white\"))\n            .attr(\"text-anchor\", (d) =&gt; (check(d) ? \"start\" : \"end\"))\n            .attr(\"dx\", (d) =&gt; (check(d) ? 10 : -10));\n        })\n    );\n  }\n\n  // Main function for data updates.\n  function update(data, transition = true) {\n    updateBar(bar, data, transition);\n    updateLabel(label, data, transition);\n  }\n\n  return Object.assign(svg.node(), { update });\n}\n\n\n\n\n\n\n\n// to draw lines at the origin (to show intercept and stuff)\n// create voronoi overlay? for dragging points\n// viz error / squared error\n// make the error lines look like a weight\n// show other metrics like R^2 etc.\nfunction RegressionPlot(\n  data,\n  {\n    x = ([x]) =&gt; x, // accessor function for x-coordinate\n    y = ([, y]) =&gt; y, // accessor function for y-coordinate\n    r = 6, // radius of dots, in pixels\n    marginTop = 20, // top margin, in pixels\n    marginRight = 30, // right margin, in pixels\n    marginBottom = 30, // bottom margin, in pixels\n    marginLeft = 40, // left margin, in pixels\n    inset = r * 2, // inset the default range, in pixels\n    insetTop = inset, // inset the default y-range\n    insetRight = inset, // inset the default x-range\n    insetBottom = inset, // inset the default y-range\n    insetLeft = inset, // inset the default x-range\n    width = 640, // outer width, in pixels\n    height = 500, // outer height, in pixels\n    xType = d3.scaleLinear, // type of x-scale\n    xDomain, // [xmin, xmax]\n    xRange = [marginLeft + insetLeft, width - marginRight - insetRight], // [left, right]\n    yType = d3.scaleLinear, // type of y-scale\n    yDomain, // [ymin, ymax]\n    yRange = [height - marginBottom - insetBottom, marginTop + insetTop], // [bottom, top]\n    showGrid = true // whether to show grid lines\n  } = {}\n) {\n  const errorColor = d3.schemeSet3[3];\n\n  let errorLinesOpacity = 1;\n  let errorSquaresOpacity = 0;\n\n  // Init drag object.\n  const drag = d3\n    .drag()\n    // .on(\"start\", dragstarted)\n    .on(\"drag\", dragged);\n  // .on(\"end\", dragended);\n\n  // To give each data point a unique id\n  let idCounter = 0;\n\n  // Compute data values.\n  data = data.map((d) =&gt; ({\n    xCoord: x(d),\n    yCoord: y(d),\n    id: idCounter++\n  }));\n\n  // Store copy of initial data object\n  const initData = data.map((d) =&gt; ({ ...d }));\n\n  // Compute default domains.\n  // if (xDomain === undefined) xDomain = d3.extent(data, (d) =&gt; d.xCoord);\n  if (xDomain === undefined) xDomain = [0, d3.max(data, (d) =&gt; d.xCoord)];\n  if (yDomain === undefined) yDomain = [0, d3.max(data, (d) =&gt; d.yCoord)];\n\n  // Init linear regressor.\n  const linearRegression = d3\n    .regressionLinear()\n    .x((d) =&gt; d.xCoord)\n    .y((d) =&gt; d.yCoord)\n    .domain(xDomain);\n\n  // Construct scales and axes.\n  const xScale = xType(xDomain, xRange);\n  const yScale = yType(yDomain, yRange);\n  const xAxis = d3.axisBottom(xScale).ticks(width / 80);\n  const yAxis = d3.axisLeft(yScale).ticks(height / 80);\n\n  // Draw svg.\n  const svg = d3\n    .create(\"svg\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"viewBox\", [0, 0, width, height])\n    .attr(\"style\", \"max-width: 100%; height: auto; height: intrinsic;\");\n\n  // Draw xAxis.\n  const axisOpacity = 1;\n\n  const xGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(0,${height - marginBottom})`)\n    .attr(\"opacity\", axisOpacity)\n    .call(xAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  // Draw grid lines\n  xGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"y2\", marginTop + marginBottom - height)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw yAxis.\n  const yGroup = svg\n    .append(\"g\")\n    .attr(\"transform\", `translate(${marginLeft},0)`)\n    .attr(\"opacity\", axisOpacity)\n    .call(yAxis)\n    .call((g) =&gt; g.select(\".domain\").remove());\n  yGroup\n    .selectAll(\".tick line\")\n    .clone()\n    .attr(\"x2\", width - marginLeft - marginRight)\n    // Draw line at origin\n    .attr(\"stroke-opacity\", (d) =&gt; {\n      if (d == 0) {\n        return axisOpacity;\n      } else {\n        return showGrid ? 0.1 : 0;\n      }\n    });\n\n  // Draw error squares.\n  let errorSquares = updateErrorSquares(\n    svg.append(\"g\").selectAll(\"rect\"),\n    data\n  );\n\n  // Draw error lines.\n  let errorLines = updateErrorLines(svg.append(\"g\").selectAll(\"line\"), data);\n\n  // Draw regression line.\n  const regressionLineGroup = svg\n    .append(\"g\")\n    .attr(\"stroke\", \"black\")\n    .attr(\"stroke-width\", 2);\n  // .attr(\"stroke-dasharray\", \"20,20\");\n\n  const regressionLine = updateRegressionLine(\n    regressionLineGroup.selectAll(\"line\"),\n    data\n  );\n\n  // Draw space for plot interactions.\n  const plotRect = svg\n    .append(\"rect\")\n    .attr(\"width\", width)\n    .attr(\"height\", height)\n    .attr(\"opacity\", 0)\n    .on(\"click\", addDatapoint);\n\n  // Draw data points.\n  const circlesGroup = svg.append(\"g\").attr(\"fill\", \"black\");\n  let circles = updateCircles(circlesGroup.selectAll(\"circle\"), data);\n\n  // Drag interactions for circles.\n  function dragstarted(event, d) {\n    d3.select(this).raise().attr(\"stroke\", \"red\");\n  }\n  function dragged(event, d) {\n    d3.select(this)\n      // Update data point, as well as its position on the plot\n      .attr(\"cx\", () =&gt; {\n        d.xCoord = xScale.invert(event.x);\n        return event.x;\n      })\n      .attr(\"cy\", () =&gt; {\n        d.yCoord = yScale.invert(event.y);\n        return event.y;\n      });\n\n    updateRegressionLine(regressionLine, data, false);\n    errorSquares = updateErrorSquares(errorSquares, data, false);\n    errorLines = updateErrorLines(errorLines, data, false);\n  }\n  function dragended(event, i) {\n    d3.select(this).attr(\"stroke\", null);\n  }\n\n  // Click interaction for circles.\n  function removeDatapoint(event, dCurr) {\n    if (event.defaultPrevented) return; // dragged\n\n    // Remove data point; faster way to do this?\n    data = data.filter((d) =&gt; d.id !== dCurr.id);\n\n    update(data);\n  }\n\n  // Click interaction for plot.\n  function addDatapoint(event) {\n    const [xm, ym] = d3.pointer(event);\n\n    updateDatapoint(xScale.invert(xm), yScale.invert(ym));\n  }\n\n  // Helper function for regression line update.\n  function updateRegressionLine(line, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    // Dispatch event and R^2 value\n    svg.node().value = regressionData.rSquared;\n    svg.node().transition = transition;\n    svg.dispatch(\"input\", { bubbles: true });\n\n    return line\n      .data([regressionData])\n      .join(\"line\")\n      .call((line) =&gt; {\n        if (transition) line = line.transition();\n        line\n          .attr(\"x1\", (d) =&gt; xScale(d[0][0]))\n          .attr(\"x2\", (d) =&gt; xScale(d[1][0]))\n          .attr(\"y1\", (d) =&gt; yScale(d[0][1]))\n          .attr(\"y2\", (d) =&gt; yScale(d[1][1]));\n      });\n  }\n\n  // Helper function to update circles based on new data.\n  function updateCircles(circles, data) {\n    return circles\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"circle\")\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord))\n            // To transition from 0 radius\n            .attr(\"r\", 0)\n            // Attach interactions\n            .call(drag)\n            .on(\"click\", removeDatapoint)\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .ease(d3.easeBackOut.overshoot(1.7))\n                .attr(\"r\", r)\n            ),\n        (update) =&gt;\n          update\n            .transition()\n            .attr(\"cx\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"cy\", (d) =&gt; yScale(d.yCoord)),\n        (exit) =&gt;\n          exit\n            .transition()\n            .ease(d3.easeBackIn.overshoot(1.7))\n            .attr(\"r\", 0)\n            .remove()\n      );\n  }\n\n  // Helper function to update error lines based on new data.\n  function updateErrorLines(lines, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    return lines\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"line\")\n            .attr(\"stroke\", errorColor)\n            .attr(\"stroke-width\", 2)\n            .attr(\"opacity\", errorLinesOpacity)\n            // Start at data point\n            .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            // Add transition\n            .call((enter) =&gt;\n              enter\n                .transition()\n                .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)))\n            ),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            if (transition) update = update.transition();\n            update\n              .attr(\"x1\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y1\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"x2\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y2\", (d) =&gt; yScale(regressionData.predict(d.xCoord)));\n          }),\n        (exit) =&gt;\n          exit\n            .transition()\n            .attr(\"y2\", (d) =&gt; yScale(d.yCoord))\n            .remove()\n      );\n  }\n\n  // Helper function to update error squares based on new data.\n  function updateErrorSquares(rects, data, transition = true) {\n    const regressionData = linearRegression(data);\n\n    const computeHeight = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n\n      return Math.abs(yScale(yCoordPred) - yScale(d.yCoord));\n    };\n    // Compute which direction the box should face\n    const computeTransform = (d) =&gt; {\n      const yCoordPred = regressionData.predict(d.xCoord);\n      const check = yScale(yCoordPred) - yScale(d.yCoord) &lt; 0;\n      const deg = check ? -90 : 90;\n\n      return `rotate(${deg}, ${xScale(d.xCoord)}, ${yScale(d.yCoord)})`;\n    };\n\n    return rects\n      .data(data, (d) =&gt; d.id)\n      .join(\n        (enter) =&gt;\n          enter\n            .append(\"rect\")\n            .attr(\"stroke\", \"none\")\n            .attr(\"fill\", errorColor)\n            .attr(\"opacity\", errorSquaresOpacity)\n            .attr(\"transform\", computeTransform)\n            // Start at data point\n            .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n            .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n            .attr(\"width\", 0)\n            .attr(\"height\", 0)\n            // Add transition\n            .call((enter) =&gt; {\n              enter\n                .transition()\n                .attr(\"width\", computeHeight)\n                .attr(\"height\", computeHeight);\n            }),\n        (update) =&gt;\n          update.call((update) =&gt; {\n            update.attr(\"transform\", computeTransform);\n\n            if (transition) update = update.transition();\n\n            update\n              .attr(\"x\", (d) =&gt; xScale(d.xCoord))\n              .attr(\"y\", (d) =&gt; yScale(d.yCoord))\n              .attr(\"width\", computeHeight)\n              .attr(\"height\", computeHeight);\n          }),\n        (exit) =&gt; exit.transition().attr(\"width\", 0).attr(\"height\", 0).remove()\n      );\n  }\n\n  // Resets the plot to the initial data\n  function reset() {\n    update(initData, true);\n  }\n\n  // Updates which error type to show\n  function updateView(option) {\n    if (option === \"None\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Absolute Error\") {\n      errorLinesOpacity = 1;\n      errorSquaresOpacity = 0;\n\n      errorLines.transition().attr(\"opacity\", 1);\n      errorSquares.transition().attr(\"opacity\", 0);\n    } else if (option === \"Squared Error\") {\n      errorLinesOpacity = 0;\n      errorSquaresOpacity = 0.5;\n\n      errorLines.transition().attr(\"opacity\", 0);\n      errorSquares.transition().attr(\"opacity\", 0.5);\n    }\n  }\n\n  // Adds a new datapoint and updates the plot\n  function updateDatapoint(xCoord, yCoord) {\n    // Add datapoint\n    data = [...data, { xCoord, yCoord, id: idCounter++ }];\n\n    update(data);\n  }\n\n  // Main function that updates the plot based on new data\n  function update(newData, transition = true) {\n    // Upate local data object\n    data = newData.map((d) =&gt; ({ ...d }));\n\n    updateRegressionLine(regressionLine, data, transition);\n    circles = updateCircles(circles, data);\n    errorSquares = updateErrorSquares(errorSquares, data, transition);\n    errorLines = updateErrorLines(errorLines, data, transition);\n  }\n\n  return Object.assign(svg.node(), {\n    update,\n    updateDatapoint,\n    updateView,\n    reset\n  });\n}\n\n\n\n\n\n\n\nd3 = require(\"d3-regression\", \"d3\")\n\n\n\n\n\n\n\n\n\nAbbildung 9.5: Interaktives Beispiel für eines lineares Modell. Fügen Sie Punkte per Klick/Touch hinzu.\n\n\n\nBeispiel 9.3 (Toni will es genau wissen) Da Toni Sie als Statistik-Profi abgespeichert hat, werden Sie wieder konsultiert: “Okay, ich hab noch zwei Fragen. Erstens: Wie viele Punkte bekomme ich, wenn ich gar nicht lerne? Zweitens, wie viele Punkte bekomme ich pro gelernte Stunde? Ist immerhin meine Lebenszeit, krieg ich nicht zurück!” Das sind gute Fragen. Den \\(\\color{ycol}{Y}\\)-Wert (Klausurpunkte) bei \\(\\color{xcol}{x}=0\\) gibt der Achsenabschnitt zurück. Schnell skizzieren Sie dazu ein Diagramm, s. Abbildung 9.6. Puh, die Antwort wird Toni nicht gefallen … \\(\\square\\)\n\n\n\n\n\n\n\n\nAbbildung 9.6: Der Achsenabschnitt: Wie viele Punkte kann Toni erwarten bei 0 Lernstunden? (roter Punkt bei x=0)\n\n\n\n\nAnstelle auf Abbildung 9.6 zu schauen, können Sie sich auch von R Tonis Klausurerfolg vorhersagen (to predict) lassen:\n\n🧑‍🏫 Hey R, predicte mir mal auf Basis vom Modell “lm_toni” den Lernerfolg für Toni, wenn der x=0 Stunden lernt.\n\n\n🤖 Okay, ich predicte mit Modell “lm_toni” und nehme als neue Datentabelle Tonis Lernzeit (x=0)!\n\n\ntonis_lernzeit &lt;- tibble(x = 0)  # `tibble` erstellt einen Dataframe\n\n\npredict(lm_toni, newdata = tonis_lernzeit)\n##  1 \n## 46\n\npredict erwartet für das Argument newdata einen Dataframe. In diesem Beispiel heißt er tonis_lernzeit.\n\n9.3.2 Spezifikation eines Geradenmodells\nEin Geradenmodell kann man im einfachsten Fall spezifizieren wie Gleichung 9.2 dargestellt.\n\\[\\color{ycol}{\\hat{y}} \\sim \\color{xcol}{\\text{x}} \\tag{9.2}\\]\nLies: “Laut meinem Modell ist mein vorhergesagtes \\(\\color{ycol}{\\hat{y}}\\) irgendeine Funktion von \\(\\color{xcol}{\\text{x}}\\)”. Wir erinnern uns, dass \\(\\color{ycol}{Y}\\) die \\(\\color{ycol}{AV}\\) und \\(\\color{xcol}{X}\\) die \\(\\color{xcol}{UV}\\) ist: \\(\\color{ycol}{AV} \\sim \\color{xcol}{UV}\\).\nWir werden als Funktion nur Geraden verwenden. Die genauen Werte der Gerade lassen wir uns vom Computer ausrechnen. Gleichung 9.2 können Sie so ins Errische übersetzen: lm(y ~ x, data = meine_daten).\nlm steht für “lineares Modell”, also eine Gerade als Modell. Die Gerade nennt man auch Regressionsgerade (an anderer Stelle in diesem Buch unscharf als “Trendgerade” bezeichnet).\n\nBeispiel 9.4 (Zahlen für Toni) Toni ist nicht zufrieden mit Ihren Vorhersagen: “Jetzt hör mal auf mit deinem Lineal hier herum zu malen. Ich will es genau wissen, sage mir präzise Zahlen!”.\n\n\nlm_toni &lt;- lm(y ~ x, data = noten2)\nlm_toni\n## \n## Call:\n## lm(formula = y ~ x, data = noten2)\n## \n## Coefficients:\n## (Intercept)            x  \n##      46.191        0.879\n\nR gibt Ihnen die beiden Koeffizienten für die Gerade aus. Den Namen des Objekts können Sie frei aussuchen, z.\\(\\,\\)B. mein_erstes_lm. Die Regressionsgleichung lautet demnach: y_pred = 8.6 + 0.88*x.\n8.6 ist der Achsenabschnitt, d.\\(\\,\\)h. der Wert von \\(\\color{ycol}{Y}\\) wenn \\(\\color{xcol}{x}=0\\). 0.88 ist das Regressionsgewicht, d.\\(\\,\\)h. die Steigung der Regressionsgeraden: Für jede Stunde Lernzeit steigt der vorhergesagte Klausurerfolg um 0.88 Punkte.\nMit Kenntnis der beiden Koeffizienten kann man beliebige \\(\\color{ycol}{Y}\\)-Werte ausrechnen, gegeben bestimmte \\(\\color{xcol}{X}\\)-Werte. Hat jemand zum Beispiel 73 Stunden gelernt, würden wir folgendes Klausurergebnis vorhersagen:\n\nlernzeit &lt;- 73\ny_pred &lt;- 46 + 0.88*lernzeit\ny_pred\n## [1] 110\n\n\nBeispiel 9.5 (Vorhersage für Klausurerfolg, nächster Versuch) Sie versuchen, noch etwas Gutes für Toni zu tun. R hilft Ihnen dabei und rechnet die erwartete Punktzahl aus, wenn Toni 73 Stunden lernt. Sie dürfen es aber auch selber rechnen, wenn Ihnen das lieber ist.\n\n\ntonis_lernzeit2 &lt;- tibble(x = 73)  \n\ntonis_lernzeit2 ist eine Tabelle mit einer Zeile und einer Spalte:\n\ntonis_lernzeit2\n\n\n\nx\n\n\n73\n\n\n\n\n\npredict(lm_toni, newdata = tonis_lernzeit2)\n##   1 \n## 110\n\nDie Syntax von predict lautet:\npredict(modell, newdata = tabelle_mit_prädiktorwerten)\nDie Funktion predict liefert eine Vorhersage für ein ein Modell, z.\\(\\,\\)B. lm_toni, und für einen bestimmten Dataframe (der die Werte der UV enthalten muss).\n\n9.3.3 Vorhersagefehler\nDie Differenz zwischen vorhergesagtem Wert für eine (neue) Beobachtung, \\(\\color{modelcol}{\\hat{y_0}}\\) und ihrem tatsächlichen Wert nennt man Vorhersagefehler (error, \\(e\\)) oder Residuum: \\(\\color{errorcol}{e_i} = \\color{ycol}{y_i} - \\color{modelcol}{\\hat{y}_i}\\).\n\n\n\n\n\n\n\n\n\n(a) Geradenmodell (lm_toni)\n\n\n\n\n\n\n\n\n\n(b) Punktmodell (lm0)\n\n\n\n\n\n\nAbbildung 9.7: Vorhersagefehler als Abweichungsbalken. (a) Beim Geradenmodell, sind die Vorhersagefehler (Abweichungsbalken) kleiner (kürzer) als in (b), beim Punktmodell.\n\n\nWie ist es mit den Vorhersagefehlern von beiden Modellen bestellt? Lassen wir uns von R die Streuung (Residuen) in Form der mittleren Absolutabweichung (MAE) ausgeben (aus dem Paket easystats):\n\nmae(lm0)\nmae(lm_toni)\n## [1] 11\n## [1] 8\n\nVergleichen wir MAE im Nullmodell mit MAE in lm_toni:\n\nverhaeltnis_fehler_mae &lt;- mae(lm_toni) / mae(lm0)\nverhaeltnis_fehler_mae\n## [1] 0.71\n\nAh! Das Geradenmodell ist viel besser: Von lm0 zu lm_toni haben die mittlere Absolutlänge des Fehlerbalkens auf 71 Prozent verbessert. Nicht schlecht!\n\nDefinition 9.4 (Fehlerstreuung) Als Fehlerstreuung bezeichnen wir die Verteilung der Abweichungen der beobachteten Werte (\\(y_i\\)) vom vorhergesagten Wert (\\(\\hat{y}_i\\)). \\(\\square\\)\n\nZur Berechnung der Fehlerstreuung gibt es mehrere Kenngrößen wie MAE oder MSE. Ein Geradenmodell ist immer besser als ein Punktmodell (im Hinblick auf die Verringerung der Fehlerstreuung), solange X mit Y korreliert ist. Natürlich können wir – in Analogie zur Varianz – auch den mittleren Quadratfehlerbalken (Mean Squared Error, MSE) berechnen. Wer mag, kann den MSE auch von Hand berechnen: mean((noten2$y - mean(noten2$y))^2).\n\nmse(lm0)\nmse(lm_toni)\n## [1] 193\n## [1] 106\n\n\nverhaeltnis_fehler_mse &lt;- mse(lm_toni)/mse(lm0)\nverhaeltnis_fehler_mse\n## [1] 0.55\n\nBetrachtet man die MSE, so kann man eine Verbesserung um 0.45 auf 0.55 feststellen.\n\n9.3.4 Berechnung der Modellkoeffizienten\nAber wie legt man die Regressionsgerade in das Streudiagramm, bildlich gesprochen? Die Regressionskoeffizienten (hier synonym: Modellparameter) \\(\\beta_0\\) und \\(\\beta_1\\) wählt man so, dass die Residuen minimal sind. Genauer gesagt wird die Summe der quadrierten Residuen minimiert, s. Gleichung 9.3.\nAbbildung 9.8 veranschaulicht die Minimierung der Residuen (Vorhersagefehler).\n\n\n\n\nMinimierung der Residuen\nMinimierung der quadrierten Residuen\n\n\n\n\n\nBerechnung der Modellkoeffizienten durch Minimierung der Residuen\n\n\n\n\n\nMinimierung der quadrierten Residuen\n\n\n\n\n\n\nAbbildung 9.8: Bildquelle: Karsten Lübke, FOM Hochschule\n\n\n\\[\\text{min}\\sum_i \\color{errorcol}{e_i}^2 \\tag{9.3}\\]\nEs gibt verschiedene Methoden, um die Koeffizienten zu berechnen (die aber nicht in diesem Buch zu finden sind). Eine schöne Darstellung dazu findet sich bei Kaplan (2009).\n“Von Hand” können Sie die Optimierung von \\(\\beta_0\\) und \\(\\beta1\\) in dieser App der FOM-Hochschule2 ausprobieren.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#r2-als-maß-der-modellgüte",
    "href": "080-regression1.html#r2-als-maß-der-modellgüte",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.4 \\(R^2\\) als Maß der Modellgüte",
    "text": "9.4 \\(R^2\\) als Maß der Modellgüte\nDas Modell lm_toni weist noch 0.55 der Fehlerstreuung (MSE) des Nullmodells auf. Anders gesagt, wir haben uns ( (bzw. das Modell hat sich) um \\(1 - 0.55\\) verbessert.\n\n1 - verhaeltnis_fehler_mse\n## [1] 0.45\n\n\nDefinition 9.5 (\\(R^2\\)-Quadrat) Der Anteil der Verringerung (als Anteil) der Fehlerstreuung der Zielvariablen zwischen lm0 und dem gerade untersuchten Modell nennt man R-Quadrat (\\(R^2\\)). Das R-Quadrat (\\(R^2\\)) eines Modells \\(m\\) ist definiert als die Verringerung der Streuung, wenn man das Modell \\(m\\) mit dem Nullmodell \\(m_0\\) vergleicht: \\(R^2 =1-  \\frac{\\text{MSE}_{m}}{\\text{MSE}_{m0}}\\). R-Quadrat ist ein Maß der Modellgüte: Je größer \\(R^2\\), desto besser ist die Vorhersage. Da es ein Anteilsmaß ist, liegt der Wertebereich zwischen 0 und 1. Im Nullmodell beträgt R-Quadrat per Definition Null. Im Fall von Modellen des Typs \\(y\\sim x\\) gilt: \\(R^2 = r_{xy}^2\\). \\(\\square\\)\n\nEinfach gesagt: \\(R^2\\) gibt an, wie gut (zu welchem Anteil) ein Modell die Zielvariable, \\(y\\), erklärt. Wir können R-Quadrat (\\(R^2\\)) uns von R z.\\(\\,\\)B. so ausgeben lassen:\n\nr2(lm_toni)\n## # R2 for Linear Regression\n##        R2: 0.448\n##   adj. R2: 0.442\n\nBei einer perfekten Korrelation ist \\(r=1\\), daher ist dann auch \\(R^2 = 1\\), vgl. Abbildung 9.9.\n\n\n\n\n\n\n\n\n\n\n(a) Keine Korrelation\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Perfekte Korrelation\n\n\n\n\n\n\nAbbildung 9.9: Extremfälle von \\(R^2\\): 0 und 1. (a) Keine Korrelation, r = 0 und R2 = 0. Prognose durch Mittelwert; die Regressionsgerade ist (ungefähr) parallel zur X-Achse. (b) Perfekte Korrelation, r = 1 und \\(R^2\\) = 1: Die Prognose ist gleich dem beobachtetem Wert.\n\n\n\nBei einer perfekten Korrelation \\(R^2=1\\) liegen die Punkte auf der Geraden. Im gegenteiligen Extremfall von \\(R^2=0\\) ist die Vorhersage genauso gut, wie wenn man für jedes \\(y\\) den Mittelwert, \\(\\color{ycol}{\\bar{y}}\\) , vorhersagen würde. Je größer R-Quadrat, desto besser passt das Modell zu den Daten; desto besser “erklärt” das Modell die Daten (desto besser der “Fit” des Modells zu den Daten, sagt man).\nDiese App der FOM-Hochschule erlaubt es Ihnen mit der Größe der Residuen eines linearen Modells zu spielen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#sec-interpret-reg-mod",
    "href": "080-regression1.html#sec-interpret-reg-mod",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.5 Interpretation eines Regressionsmodells",
    "text": "9.5 Interpretation eines Regressionsmodells\n\n9.5.1 Modellgüte\nDie Residuen (Vorhersagefehler) bestimmen die Modellgüte: Sind die Residuen im Schnitt groß, so ist die Modellgüte gering (schlecht), und umgekehrt. Verschiedenen Koeffizienten stehen zur Verfügung: \\(R^2\\), \\(r\\) (als Korrelation von tatsächlichem \\(y\\) und vorhergesagten \\(\\hat{y}\\)), MSE, RMSE, MAE, …\n\n9.5.2 Koeffizienten\nDie Modellkoeffizienten, also Achsenabschnitt (\\(\\beta_0\\)) und Steigung (\\(\\beta_1\\)) sind nur eingeschränkt zu interpretieren, wenn man die zugrundeliegenden kausalen Abhängigkeiten nicht kennt. Allein aufgrund eines statistischen Zusammenhangs darf man keine kausalen Abhängigkeiten annehmen. Ohne eine zugrundeliegende Theorie für eine Kausalbehauptung kann man kann nur deskriptiv argumentieren. Oder sich mit der Modellgüte und den Vorhersagen begnügen. Was auch was wert ist.\nIm Modell lm_toni liegt der Achsenabschnitt bei \\(\\textcolor{ycol}{y}=46.19\\). Beobachtungen mit \\(\\color{xcol}{x}=0\\) können also diesen \\(\\textcolor{ycol}{Y}\\)-Wert erwarten, laut lm_toni. Leider ist es häufig so, dass UV mit Wert 0 in der Praxis nicht realistisch sind, so dass der Achsenabschnitt dann wenig nützt.\n\nBeispiel 9.6 (Regression Größe und Gewicht) Nutzt man Körpergröße und das Gewicht von Menschen vorherzusagen, ist der Achsenabschnitt von Körpergröße wenig nützlich, da es keine Menschen gibt der Größe 0. \\(\\square\\)\n\nSo interpretiert man die Geradensteigung, \\(\\beta_1\\): “Im Modell lm_toni beträgt der Regressionskoeffizient \\(\\beta_1 = 0.88\\). Zwei Studentinnen, deren Lernzeit sich um eine Stunde unterscheidet, unterscheiden sich laut Modell um den Wert von \\(\\beta_1\\)”.\n\n\n\n\n\n\nVorsicht\n\n\n\nHäufig liest man, der “Effekt der UV” auf die AV betrage z.\\(\\,\\)B. \\(0.88\\). “Effekt” ist aber ein Wort, das man leicht kausal verstehen kann. Ohne weitere Absicherung kann man aber Regressionskoeffizienten nicht kausal verstehen. Daher sollte man das Wort “Effekt” mit Vorsicht genießen. Manche sprechen daher auch von einem “statistischen Effekt”, um zu verdeutlichen, dass keine Kausalaussage impliziert ist. \\(\\square\\)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#wie-man-mit-statistik-lügt",
    "href": "080-regression1.html#wie-man-mit-statistik-lügt",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.6 Wie man mit Statistik lügt",
    "text": "9.6 Wie man mit Statistik lügt\nDer Unterschied in Modellgüte zwischen, sagen wir, \\(r=.1\\) und \\(r=.2\\) ist viel kleiner als zwischen \\(r=.7\\) und \\(r=.8\\). \\(R^2\\) ist ein (lineares) Maß der Modellgüte und da \\(r = \\sqrt{R^2}\\), dürfen Unterschiede in \\(r\\) nicht auf die gleiche Weise interpretiert werden wie Unterschiede in \\(R^2\\). Abbildung 9.10 zeigt den Zusammenhang von \\(r\\) und \\(R^2\\).\n\n\n\n\n\n\n\nAbbildung 9.10: Der Zusammenhang von r und R-Quadrat ist nicht linear.\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nUnterschiede zwischen Korrelationsdifferenzen dürfen nicht linear interpretiert werden. \\(\\square\\)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallbeispiel-mariokart",
    "href": "080-regression1.html#fallbeispiel-mariokart",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.7 Fallbeispiel Mariokart",
    "text": "9.7 Fallbeispiel Mariokart\n\n9.7.1 Der Datenwahrsager legt los\nAls mittlerweile anerkannter Extrem-Datenanalyst in dem Online-Auktionshaus, in dem Sie arbeiten, haben Sie sich neue Ziele gesetzt. Sie möchten eine genaue Vorhersage von Verkaufspreisen erzielen. Als Sie von diesem Plan berichteten, leuchteten die Augen Ihrer Chefin. Genaue Vorhersagen sind von hoher betriebswirtschaftlicher Relevanz. Mariokart-Daten laden, am besten ohne Extremwerte, s. Listing 5.4 und los geht’s (und die üblichen Pakete starten, nicht vergessen)!\n\nmariokart &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\")\n\n\nlm2 &lt;- lm(total_pr ~ start_pr, data = mariokart)\nr2(lm2)\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: -0.002\n\nOh nein! Unterirdisch schlecht. Anstelle von bloßem Rumprobieren überlegen Sie und schauen dann nach, welche Variable am stärksten korreliert mit total_pr; es resultiert lm3. Dann lassen Sie sich die Modellparameter ausgeben, s. Tabelle 9.1.\n\nlm3 &lt;- lm(total_pr ~ ship_pr, data = mariokart)\n\n\n\n\nTabelle 9.1: Modellparameter von lm3\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(141)\np\n\n\n\n(Intercept)\n36.25\n2.54\n(31.23, 41.26)\n14.28\n&lt; .001\n\n\nship pr\n4.34\n0.57\n(3.22, 5.46)\n7.67\n&lt; .001\n\n\n\n\n\n\n\n\nDer Achsenabschnitt liegt bei ca. 36 Dollar, wie man in Tabelle 9.1 sieht: Ein Spiel, das mit null Dollar Preis startet, kann laut lm3 etwa 36 Dollar finaler Verkaufspreis erwarten. Pro Dollar an Versandkosten (ship_pr) steigt der zu erwartende finale Verkaufspreis um ca. 4 Dollar. (Die Spalte 95 CI gibt einen Schätzbereich für den jeweiligen Modellkoeffizienten an, denn es handelt sich bei den Koeffizienten um Schätzwerte; der wahre Wert in der Population ist unbekannt. Wir kennen schließlich nur eine Stichprobe der Größe \\(n = 143\\).) Die Regressionsgleichung von lm3 lautet demnach: total_pr_pred = 36 + 4*ship_pr.\nIn Worten:\n\nDer vorhergesagte Gesamptreis eines Spiels liegt bei 36 Dollar “Sockelbetrag” plus 4 mal die Versandkosten.\n\n\n9.7.2 Vertiefung\nMan kann sich die erwarteten Werte (“expectations”) des Verkaufspreises in Abhängigkeit vom Wert der UV (ship_pr) auch schätzen (“to estimate”) lassen, und zwar so mit estimate_expectation(lm3), s. Tabelle 9.2.\n\n\n\nTabelle 9.2: Die vorhergesagten (predicted) Werte und die Abweichungen vom vorhergesagten Wert (Residuals)\n\n\n\nModel-based Predictions\n\nship_pr\nPredicted\nSE\n95% CI\nResiduals\n\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-2.04\n\n\n3.99\n53.55\n1.87\n(49.85, 57.25)\n-16.51\n\n\n3.50\n51.43\n1.82\n(47.82, 55.03)\n-5.93\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n7.75\n\n\n0.00\n36.25\n2.54\n(31.23, 41.26)\n34.75\n\n\n4.00\n53.59\n1.87\n(49.89, 57.30)\n-8.59\n\n\n\nVariable predicted: total_pr\n\n\n\n\n\n“Ah, bei 4 Dollar Versandkosten ist laut dem Modell knapp 54 Dollar Verkaufspreis zu erwarten”, fassen Sie sich die Ausgabe zusammen.\n\n🤖 Das sieht man in der Spalte Predicted, dort steht der vorhersagte Wert für total_pr für einen bestimmten Wert von ship_pr.\n\n\n🧑‍🎓 Kann ich auch predict benutzen? Ich würde gerne den Verkaufspreis wissen, wenn die Versandkosten bei 1 und bei 4 Dollar liegen.\n\n\n🤖 Ja, klar!\n\n\nneue_daten &lt;- tibble(\n  ship_pr = c(1, 4)) # zwei Werte zum Vorhersagen\n\n\npredict(lm3, newdata = neue_daten)\n##  1  2 \n## 41 54\n\nAber nützlich wäre noch, das Modell (bzw. die Schätzung der erwarteten Werte) als Diagramm zu bekommen. Das erreicht man z.\\(\\,\\)B. so, s. Abbildung 10.10.\n\nestimate_prediction(lm3, by = \"ship_pr\") %&gt;% plot()\n\n\n\n\n\n\nAbbildung 9.11: Verbildlichung der erwarteteten Werte laut lm3\n\n\n\n\nestimate_expectation heißt sinngemäß “schätze den zu erwartenden Wert”. Kurz gesagt: Wir wollen eine Vorhersage von R.\nAm wichtigsten ist Ihnen aber im Moment die Frage, wie “gut” das Modell ist, spricht wie lang oder kurz die (absoluten) Vorhersagefehler-Balken sind:\n\nmae(lm3)\n## [1] 13\n\nDas Modell erklärt einen Anteil von ca. 0.29 der Gesamtstreuung.\n\nr2(lm3)\n## # R2 for Linear Regression\n##        R2: 0.294\n##   adj. R2: 0.289\n\n\nmae(lm3)\n## [1] 13\n\nIm nächsten Meeting erzählen Sie Ihrer Chefin “Ich kann den Verkaufspreis von Mariokart-Spielen im Schnitt auf 13 Dollar genau vorhersagen!”. Hört sich gut an. Allerdings hätte es Ihre Chefin gerne genauer. Kann man da noch was machen?",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#fallstudie-immobilienpreise",
    "href": "080-regression1.html#fallstudie-immobilienpreise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.8 Fallstudie Immobilienpreise",
    "text": "9.8 Fallstudie Immobilienpreise\n\n\n\n\n\n\n\nVorsicht\n\n\n\nDiese Fallstudie führt in die Prüfungsleistung “Prognosewettbewerb” ein. Es empfiehlt sich für Sie, diese Fallstudie sorgsam zu bearbeiten. \\(\\square\\)\n\n\n\n9.8.1 Hintergrund\nIn dieser Fallstudie geht es darum, die Preise von Immobilien vorherzusagen. Kurz gesagt: Sagen Sie die Hauspreise vorher, und reichen Sie Ihre Vorhersagen als CSV bei kaggle.com ein. Kaggle ist eine Webseite, die Prognosewettbewerbe veranstaltet. In dieser Fallstudie nehmen Sie teil an der Kaggle-Competition “House Prices - Advanced Regression Techniques”, die Sie auf der Kaggle-Webseite finden. Dort finden Sie auch eine nähere Beschreibung, das Ziel und die Spielregeln des Wettbewerbs.\n\nBeschreibung\nZiel/Aufgabe\nSpielregeln\n\n9.8.2 Daten\nSie können die Daten von www.kaggle.com herunterladen. Im Einzelnen müssen Sie folgende Dateien herunterladen:\n\n\nData_description.txt: Codebook, d.\\(\\,\\)h. Beschreibung der Variablen im Datensatz\n\ntrain.csv: Daten von Häusern, die Sie nutzen, um Modelle zu erstellen\n\ntest.csv: Daten von Häusern, von denen Sie den Kaufpreis vorhersagen sollen\n\nsample_submission.csv: Beispielhafte Prognosedatei, die Datei also, mit der Sie Ihre Vorhersagen einreichen, s. Tabelle 9.3\n\n\nSie können auch über das Github-Repo statistik1, Ordner data auf die Daten zugreifen:\n\nd_train_path_online &lt;- paste0(\n    \"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-train.csv\")\n\nd_test_path_online &lt;- paste0(\n\"https://raw.githubusercontent.com/sebastiansauer/statistik1/\",\n    \"refs/heads/main/data/kaggle-test.csv\")\n\nd_train &lt;- read.csv(d_train_path_online)\nd_test &lt;- read.csv(d_test_path_online)\n\nLaden Sie diese Daten am besten herunter und speichern Sie sie in einem passenden Unterverzeichnis (Ihres Projektordners in RStudio) ab. Importieren wir die Daten aus dem Unterordner data in R (davon ausgehend, dass der Unterordner data ein Unterordner Ihres aktuellen R-Projekts ist):\n\nd_train_path &lt;- \"data/kaggle-train.csv\"\nd_test_path &lt;- \"data/kaggle-test.csv\"\nd_train &lt;- read.csv(d_train_path)\nd_test &lt;- read.csv(d_test_path)\n\nWenn das Importieren von Ihrem Computer nicht klappen sollte … Es ist zwar hilfreich, wenn man Daten von der eigenen Festplatte importieren kann. Aber fürs Erste können Sie die Daten auch von oben angegeben Online-Pfad importieren.\n\n9.8.3 Prognosedatei\nDie Prognosedatei ist die Datei, die Ihre Vorhersagen (Prognosen) enthält. Sie soll prinzipiell so aussehen wie in Tabelle 9.3 dargestellt.\n\n\n\nTabelle 9.3: Beispiel für den Aufbau der Prognose-Datei\n\n\n\n\nid\nSalePrice\n\n\n\n1461\n169277\n\n\n1462\n187758\n\n\n1463\n183584\n\n\n\n\n\n\n\n\nDie Prognosedatei besteht also aus zwei Spalten: der Spalte id und der Spalte Saleprice. Die Spalte id gibt an, welches Haus in einer bestimmten Zeile Ihrer Prognosedatei gemeint ist – für welches Haus Sie also gerade einen Kaufpreis vorhersagen. die Spalte SalePrice enthält Ihre Vorhersage für den Kaufpreis das Hauses mit der Id, die in der betreffenden Zeile steht. Insgesamt soll die Prognosedatei genau so viele Zeilen haben wie der Test-Datensatz, also die Tabelle, die die vorherzusagenden Werte angibt. Alles klar? Los geht’s!\n\n9.8.4 Ein erster Blick in die Daten\nSchauen Sie sich zu Beginn einmal die Verteilung der metrischen Variablen, z.\\(\\,\\)B. mit describe_distribution(d_train) an.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nRange\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\nId\n730.50\n421.61\n730.50\n(1.00, 1460.00)\n0.00\n-1.20\n1460\n0\n\n\nMSSubClass\n56.90\n42.30\n50.00\n(20.00, 190.00)\n1.41\n1.58\n1460\n0\n\n\nLotFrontage\n70.05\n24.28\n21.00\n(21.00, 313.00)\n2.16\n17.45\n1201\n259\n\n\nLotArea\n10516.83\n9981.26\n4060.00\n(1300.00, 2.15e+05)\n12.21\n203.24\n1460\n0\n\n\nOverallQual\n6.10\n1.38\n2.00\n(1.00, 10.00)\n0.22\n0.10\n1460\n0\n\n\nOverallCond\n5.58\n1.11\n1.00\n(1.00, 9.00)\n0.69\n1.11\n1460\n0\n\n\nYearBuilt\n1971.27\n30.20\n46.00\n(1872.00, 2010.00)\n-0.61\n-0.44\n1460\n0\n\n\nYearRemodAdd\n1984.87\n20.65\n37.00\n(1950.00, 2010.00)\n-0.50\n-1.27\n1460\n0\n\n\nMasVnrArea\n103.69\n181.07\n166.00\n(0.00, 1600.00)\n2.67\n10.08\n1452\n8\n\n\nBsmtFinSF1\n443.64\n456.10\n712.75\n(0.00, 5644.00)\n1.69\n11.12\n1460\n0\n\n\nBsmtFinSF2\n46.55\n161.32\n0.00\n(0.00, 1474.00)\n4.26\n20.11\n1460\n0\n\n\nBsmtUnfSF\n567.24\n441.87\n585.00\n(0.00, 2336.00)\n0.92\n0.47\n1460\n0\n\n\nTotalBsmtSF\n1057.43\n438.71\n503.50\n(0.00, 6110.00)\n1.52\n13.25\n1460\n0\n\n\nX1stFlrSF\n1162.63\n386.59\n509.75\n(334.00, 4692.00)\n1.38\n5.75\n1460\n0\n\n\nX2ndFlrSF\n346.99\n436.53\n728.00\n(0.00, 2065.00)\n0.81\n-0.55\n1460\n0\n\n\nLowQualFinSF\n5.84\n48.62\n0.00\n(0.00, 572.00)\n9.01\n83.23\n1460\n0\n\n\nGrLivArea\n1515.46\n525.48\n649.75\n(334.00, 5642.00)\n1.37\n4.90\n1460\n0\n\n\nBsmtFullBath\n0.43\n0.52\n1.00\n(0.00, 3.00)\n0.60\n-0.84\n1460\n0\n\n\nBsmtHalfBath\n0.06\n0.24\n0.00\n(0.00, 2.00)\n4.10\n16.40\n1460\n0\n\n\nFullBath\n1.57\n0.55\n1.00\n(0.00, 3.00)\n0.04\n-0.86\n1460\n0\n\n\nHalfBath\n0.38\n0.50\n1.00\n(0.00, 2.00)\n0.68\n-1.08\n1460\n0\n\n\nBedroomAbvGr\n2.87\n0.82\n1.00\n(0.00, 8.00)\n0.21\n2.23\n1460\n0\n\n\nKitchenAbvGr\n1.05\n0.22\n0.00\n(0.00, 3.00)\n4.49\n21.53\n1460\n0\n\n\nTotRmsAbvGrd\n6.52\n1.63\n2.00\n(2.00, 14.00)\n0.68\n0.88\n1460\n0\n\n\nFireplaces\n0.61\n0.64\n1.00\n(0.00, 3.00)\n0.65\n-0.22\n1460\n0\n\n\nGarageYrBlt\n1978.51\n24.69\n41.00\n(1900.00, 2010.00)\n-0.65\n-0.42\n1379\n81\n\n\nGarageCars\n1.77\n0.75\n1.00\n(0.00, 4.00)\n-0.34\n0.22\n1460\n0\n\n\nGarageArea\n472.98\n213.80\n244.50\n(0.00, 1418.00)\n0.18\n0.92\n1460\n0\n\n\nWoodDeckSF\n94.24\n125.34\n168.00\n(0.00, 857.00)\n1.54\n2.99\n1460\n0\n\n\nOpenPorchSF\n46.66\n66.26\n68.00\n(0.00, 547.00)\n2.36\n8.49\n1460\n0\n\n\nEnclosedPorch\n21.95\n61.12\n0.00\n(0.00, 552.00)\n3.09\n10.43\n1460\n0\n\n\nX3SsnPorch\n3.41\n29.32\n0.00\n(0.00, 508.00)\n10.30\n123.66\n1460\n0\n\n\nScreenPorch\n15.06\n55.76\n0.00\n(0.00, 480.00)\n4.12\n18.44\n1460\n0\n\n\nPoolArea\n2.76\n40.18\n0.00\n(0.00, 738.00)\n14.83\n223.27\n1460\n0\n\n\nMiscVal\n43.49\n496.12\n0.00\n(0.00, 15500.00)\n24.48\n701.00\n1460\n0\n\n\nMoSold\n6.32\n2.70\n3.00\n(1.00, 12.00)\n0.21\n-0.40\n1460\n0\n\n\nYrSold\n2007.82\n1.33\n2.00\n(2006.00, 2010.00)\n0.10\n-1.19\n1460\n0\n\n\nSalePrice\n1.81e+05\n79442.50\n84075.00\n(34900.00, 7.55e+05)\n1.88\n6.54\n1460\n0\n\n\n\n\n\n\n9.8.5 Ein erstes Vorhersagemodell\nEine einfache Antwort auf die Frage, welche Variablen sich zur Vorhersage eignen, ist, die Korrelation aller UV mit der AV zu berechnen, s.  Listing 9.2.\n\n\n\nListing 9.2: Welche Variablen korrelieren stärker als .3?\n\nd_train %&gt;% \n  select(-Id) %&gt;% \n  correlation() %&gt;%  # berechne Korrelationen\n  filter(Parameter2 == \"SalePrice\") %&gt;%   # aber nur, wo die zweite Variable \"SalesPrice\" ist\n  arrange(-abs(r)) %&gt;%   # sortiere absteigend nach der Höhe des Korrelationskoeffizienten r\n  filter(abs(r) &gt; .3)  # nur |r| &gt; .3\n\n\n\n\n\n\nTabelle 9.4: Korrelation der UV mit der AV\n\n\n\n\n\n\n\nAha! Ein Menge Information … Wenn Sie Teile der Ausgabe der Tabelle nicht verstehen: Im Zweifel einfach ignorieren. Wenn Sie die R-Syntax nicht verstehen: Führen Sie die Syntax schrittweise aus. Zuerst d_train ausführen und das Ergebnis betrachten. Dann d_train %&gt;% select(-Id) ausführen, wieder die Ausgabe betrachten, usw. Die als Output von Listing 9.2 aufgeführten Variablen sind einigermaßen stark mit unserer Zielvariablen SalePrice korreliert. Nutzen wir also diese Variablen (oder einige von ihnen) zur Vorhersage. Tabelle 9.5 zeigt die Parameter von lm_immo1.\nIm ersten Modell gehen wir davon aus, dass der Verkaufspreis im Großen und Ganzen durch den Zustand der Immobilie (OverallQual) vorhergesagt werden kann. Diese Variable ist am stärksten mit der Zielvariable korreliert und daher ein guter Kandidat für die Vorhersage.\n\nlm_immo1 &lt;- lm(SalePrice ~ OverallQual, data = d_train)\nparameters(lm_immo1)  # aus easystats\n\n\n\n\nTabelle 9.5: Parameter von lm_immo1\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-96206.08\n\n\nOverallQual\n45435.80\n\n\n\n\n\n\n\n\nWie gut ist das Modell?\n\nrmse(lm_immo1)  # aus easystats\n## [1] 48589\n\nIm Schnitt liegen wir 4.86^{4} Dollar daneben. Ob das viel oder weniger ist, wird sich im Vergleich mit anderen Modellen zeigen.\nR-Quadrat liefert einen anderen Blick auf die Modellgüte:\n\nr2(lm_immo1)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.626\n##   adj. R2: 0.625\n\nMan kann mehrere UV in ein Regressionsmodell aufnehmen. Dazu trennt man sie mit einem Pluszeichen in lm():\n\nmein_modell &lt;- lm(av ~ uv1 + uv2 + ... + uv_n, data = meine_daten)\n\nDabei ist das Pluszeichen kein arithmetischer Operator, sondern sagt nur “als UV nimm UV1 und UV2 und …”. Berechnen wir als nächstes ein Modell mit mehreren UV, lm_immo2.\n\nlm_immo2 &lt;- lm(SalePrice ~ OverallQual + GrLivArea + GarageCars, data = d_train)\nparameters(lm_immo2)\n\nTabelle 9.6 zeigt die Koeffizienten von lm_immo2.\n\n\n\nTabelle 9.6: Modellparameter von lm_immo2\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-98832.49\n\n\nOverallQual\n27104.83\n\n\nGrLivArea\n50.67\n\n\nGarageCars\n21298.96\n\n\n\n\n\n\n\n\nWie gut sind die Vorhersagen des Modells lm_immo2 für die Daten von d_train?\n\nrmse(lm_immo2)\n## [1] 40566\n\nIm Schnitt liegen unsere Vorhersagen 4.06^{4} Dollar daneben. Ist das gut? Betrachten wir noch \\(R^2\\):\n\nr2(lm_immo2)\n## # R2 for Linear Regression\n##        R2: 0.739\n##   adj. R2: 0.739\n\nOb die Modellgüte (R-Quadrat, RMSE, etc.) “gut” bzw. “hoch” ist, beantwortet man am besten relativ, also im Vergleich zu anderen Modellen.\nZum Vergleich berechnen wir das maximal einfache Modell: ohne UV. Man nennt es das Nullmodell. In diesem Modell sagen wir für jedes Haus einfach den mittleren Preis aller Häuser vorher.\n\nm0 &lt;- lm(SalePrice ~ 1, data = d_train)\n\nWie gut ist die Vorhersage des Nullnodells?\n\nrmse(m0)\n## [1] 79415\n\nBeim Nullmodell liegen wir ca. 80 Tausend Dollar daneben. Das R-Quadrat der Nullmodells ist per Definition null:\n\nr2(m0)\n## # R2 for Linear Regression\n##        R2: 0.000\n##   adj. R2: 0.000\n\n\n9.8.6 Vorhersagen im Test-Datensatz mit lm_immo2\n\nWir haben jetzt unseren Champion, lm_immo2. Alle Hoffnung ruht auf diesem Modell. Ob die Vorhersagen im Test-Sample präzise sein werden? Oder himmelweit daneben? Enttäusche uns nicht! Hier sind die Vorhersagen:\n\nlm_immo2_pred &lt;- predict(lm_immo2, newdata = d_test)\nhead(lm_immo2_pred)\n##      1      2      3      4      5      6 \n## 103395 152441 161838 187676 225467 190260\n\n\n1\n\nErstelle eine Vorhersage anhand der Regressionsgerade von lm_immo1 und zwar anhand der Daten aus d_test.\n\n2\n\nZeige den “Kopf” der Vorhersagen (lm_immo1_pred), d.\\(\\,\\)h. die ersten paar Vorhersagen.\n\n\n\n\nDie Vorhersagen fügen wir jetzt dem Test-Sample hinzu:\n\nd_test &lt;- \n  d_test %&gt;% \n  mutate(SalePrice = lm_immo2_pred)\n\n\n9.8.7 Einreichen!\nSo, wir haben unsere Vorhersagen! Jetzt reichen wir diese Vorhersagen ein. Für die Prognosedatei (submission file) brauchen wir nur die Spalten id und SalePrice:\n\nlm_immo2_subm &lt;-\n  d_test %&gt;% \n  select(Id, SalePrice)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiesen Tibble speichern wir als CSV-Datei an geeigneter Stelle ab. Es bietet sich an write_csv zu verwenden, da write.csv automatisch (ungefragt) noch eine Id-Spalte ohne Namen einfügt (mit den Zeilennummern), das mag aber Kaggle nicht. Kaggle erwartet exakt zwei Spalten und zwar mit den Namen Id und SalePrice.\n\nwrite_csv(lm_immo2_subm, \"data/ames-kaggle/lm_immo2_subm.csv\")\n\nUnd dann laden Sie diese Datei, lm2_subm.csv bei Kaggle hoch und hoffen auf einen Hauptgewinn. Das Modell erzielte einen Score von 0.55521.\nDiese Fallstudie hat ein einfaches Prognosemodell vorgestellt. Sicherlich gibt es viele Ansätze, dieses Modell zu verbessern. Hier sind einige Fragen, die Sie sich dazu stellen können:\n\nWelche UV sollte ich in das Modell aufnehmen?\nWie gehe ich mit fehlenden Werten um?\nWenn eine UV schief ist, sollte ich ihn dann log-transformieren?\nVielleicht sollte man manche UV quadrieren?\nWie gehe ich mit nominalskalierten Variablen um, wenn diese viele Stufen haben?\n…\n\nViel Spielraum für Ihre Kreativität!",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#aufgaben",
    "href": "080-regression1.html#aufgaben",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.9 Aufgaben",
    "text": "9.9 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\nAussagen-einfache-Regr\ninterpret-koeff-lm\nkorr-als-regr\nLinearitaet1a\nlm1\nmtcars-regr01\nnichtlineare-regr1\npenguins-regr02\nregression1\nregression1b\nRegression3\nRegression4\nRegression5\nRegression6\names-kaggle1\n\nSchauen Sie sich auch weitere Aufgaben des Datenwerks an, vor allem mit den Tags regression und lm.\nNicht alle Aufgaben aus dieser Sammlung passen zum Stoff dieses Kapitels; vielleicht können Sie einige Aufgaben nicht lösen. Ignorieren Sie einfach diese Aufgaben.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#literaturhinweise",
    "href": "080-regression1.html#literaturhinweise",
    "title": "9  Geradenmodelle 1",
    "section": "\n9.10 Literaturhinweise",
    "text": "9.10 Literaturhinweise\nGelman et al. (2021) liefert eine deutlich umfassendere Einführung in die Regressionsanalyse als dieses Kapitel es tut. Eine moderne, R-orientierte Einführung in Statistik inklusive der Regressionsanalyse findet sich bei Çetinkaya-Runde & Hardin (2021). Ein Klassiker mit viel Aha-Potenzial ist Cohen et al. (2003).\n\n\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to Modern Statistics. https://openintro-ims.netlify.app/\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, 3rd Ed. Lawrence Erlbaum.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nKaplan, D. T. (2009). Statistical Modeling: A Fresh Approach. CreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nMenk. (2014, Juli 29). Linear Regression [Computer Code]. https://texample.net/tikz/examples/linear-regression/",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "080-regression1.html#footnotes",
    "href": "080-regression1.html#footnotes",
    "title": "9  Geradenmodelle 1",
    "section": "",
    "text": "https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/noten.csv↩︎\nhttps://fomshinyapps.shinyapps.io/KleinsteQuadrate/↩︎",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geradenmodelle 1</span>"
    ]
  },
  {
    "objectID": "090-regression2.html",
    "href": "090-regression2.html",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1 Einstieg",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#einstieg",
    "href": "090-regression2.html#einstieg",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "10.1.1 Lernziele\n\nSie können Regressionsmodelle für Forschungsfragen mit binärer, nominaler und metrischer UV erläutern und in R anwenden.\nSie können Interaktionseffekte in Regressionsmodellen erläutern und in R anwenden.\nSie können den Anwendungszweck von Zentrieren und z-Transformationen zur besseren Interpretation von Regressionsmodellen erläutern und in R anwenden.\n\n10.1.2 Benötigte R-Pakete\nNeben den üblichen Paketen tidyverse (Wickham et al., 2019) und easystats (Lüdecke et al., 2022) benötigen Sie in diesem Kapitel noch yardstick (Kuhn et al., 2024) und optional ggpubr (Kassambara, 2023).\n\nlibrary(tidyverse)\nlibrary(yardstick)  # für Modellgüte im Test-Sample\nlibrary(easystats)\nlibrary(ggpubr)  # Daten visualisieren, optional\n\n\\[\n\\definecolor{ycol}{RGB}{230,159,0}\n\\definecolor{modelcol}{RGB}{86,180,233}\n\\definecolor{errorcol}{RGB}{0,158,115}\n\\definecolor{beta0col}{RGB}{213,94,0}\n\\definecolor{beta1col}{RGB}{0,114,178}\n\\definecolor{xcol}{RGB}{204,121,167}\n\\]\n\n10.1.3 Benötigte Daten\nDieses Mal arbeiten wir nicht nur mit den Mariokartdaten, sondern auch mit Wetterdaten.\n\nmariokart_path &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv\"\nmariokart &lt;- read.csv(mariokart_path)\n\nwetter_path &lt;- paste0(\n  \"https://raw.githubusercontent.com/sebastiansauer/\",\n  \"statistik1/main/data/wetter-dwd/precip_temp_DWD.csv\")\nwetter &lt;- read.csv(wetter_path)\n\n Download \nDie Wetterdaten stammen vom DWD (2025a, 2025b) Ein Data-Dictionary für den Datensatz können Sie hier herunterladen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "href": "090-regression2.html#forschungsbezug-gläserne-kunden",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.2 Forschungsbezug: Gläserne Kunden",
    "text": "10.2 Forschungsbezug: Gläserne Kunden\nLineare Modelle (synonym: Regressionsanalysen) sind ein altes, aber mächtiges Werkzeug. Sie gehören immer noch zum Standard-Repertoire moderner Analystinnen und Analysten. Die Wirkmächtigkeit von linearen Modellen zeigt sich (leider?!) in folgendem Beispiel.\n\nBeispiel 10.1 (Wie gut kann man Ihre Persönlichkeit auf Basis Ihrer Social-Media-Posts vorhersagen?) In einer Studie mit viel Medienresonanz untersuchten Kosinski et al. (2013), wie gut Persönlichkeitszüge durch Facebook-Daten (Likes etc.) vorhergesagt werden können. Die Autoren resümieren im Abstract:\n\nWe show that easily accessible digital records of behavior, Facebook Likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender.\n\nDie Autoren berichten über eine hohe Modellgüte (gemessen mit dem Korrelationskoeffizienten \\(r\\)) zwischen den tatsächlichen persönlichen Attributen und den vorhergesagten Werten Ihres Modells, s. Abbildung 10.1. Das eingesetzte statistische Modell beruht auf einem linearen Modell, also ähnlich den in diesem Kapitel vorgestellten Methoden. Neben der analytischen Stärke der Regressionsanalyse zeigt das Beispiel auch, wie gläsern man im Internet ist! \\(\\square\\)\n\n\n\n\n\n\nAbbildung 10.1: Prediction accuracy of regression for numeric attributes and traits expressed by the Pearson correlation coefficient between predicted and actual attribute values (Kosinski et al., 2013)",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wetter-in-deutschland",
    "href": "090-regression2.html#wetter-in-deutschland",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.3 Wetter in Deutschland",
    "text": "10.3 Wetter in Deutschland\n\nBeispiel 10.2 (Wetterdaten) Nachdem Sie einige Zeit als Datenanalyst bei dem Online-Auktionshaus gearbeitet haben, stand Ihnen der Sinn nach etwas Abwechslung. Viel Geld verdienen ist ja schon ganz nett, aber dann fiel Ihnen ein, dass Sie ja zu Generation Z gehören, und daher den schnöden Mammon nicht so hoch schätzen sollten. Sie entschließen sich, Ihre hochgeschätzten Analyse-Skills für etwas einzusetzen, das Ihnen sinnvoll erscheint: Die Analyse des Klimawandels. \\(\\square\\)\n\nBeim Deutschen Wetterdienst, DWD, haben Sie sich Wetterdaten von Deutschland heruntergeladen. Nach etwas Datenjudo, auf das wir hier nicht eingehen wollen, resultiert ein schöner Datensatz, den Sie jetzt analysieren möchten. (Im Datensatz ist die Temperatur ist in Grad Celsius angegeben; der Niederschlag (precip) in mm Niederschlag pro Quadratmeter.) Hervorragend! An die Arbeit!\n\nAbbildung 10.2 zeigen die Wetterdaten animiert.\n\n\n\n\nTemperaturverlauf\nNiederschlagsverlauf\nMonatstemperaturverlauf\n\n\n\n\n\nTemperatur (Grad Celsius) im Verlauf der Jahre\n\n\n\n\n\nNiederschlag (mm) im Verlauf der Jahre\n\n\n\n\n\nVeränderung der Temperatur pro Monat in Deutschland im Zeitverlauf (10-Jahres-Mittelwerte\n\n\n\n\n\n\nAbbildung 10.2: Veränderung der Temperatur und Niederschlag (10-Jahres-Mittel) in Deutschland im Verlauf des 20. Jahrhunderts\n\n\n\n10.3.1 Metrische UV\nIn diesem Abschnitt untersuchen wir lineare Modelle mit einer oder mehreren metrischen UV (und einer metrischen AV).\nSie stellen sich nun folgende Forschungsfrage:\n\n🧑‍🏫 Um wieviel ist die Temperatur in Deutschland pro Jahr gestiegen, wenn man die letzten ca. 100 Jahre betrachtet?\n\nDie Modellparameter von lm_wetter1 sind in Tabelle 10.1 zu sehen.\n\nlm_wetter1 &lt;- lm(temp ~ year, data = wetter)\nparameters(lm_wetter1)\n\n\n\n\nTabelle 10.1: Modellparameter von lm_wetter1\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n-14.25\n(-17.87, -10.63)\n\n\nyear\n0.01\n(9.80e-03, 0.01)\n\n\n\n\n\n\n\n\nLaut dem Modell wurde es pro Jahr im Schnitt um 0.01\\(\\,\\)°C wärmer, pro Jahrzehnt also 0.1\\(\\,\\)°C und pro Jahrhundert 1\\(\\,\\)°C.\n\n🧑‍🎓 Das ist sicherlich nicht linear! Vermutlich ist die Temperatur bis 1950 konstant geblieben und jetzt knallt sie durch die Decke!\n\n\n🧑‍🏫 Mit der Ruhe, das schauen wir uns später an.\n\nIn Tabelle 10.1 finden sich zwei Arten von Information für den Wert des Achsenabschnitts (\\(\\beta_0\\)) und des Regressionsgewichts von year (\\(\\beta _1\\)):\n\nPunktschätzungen In der Spalte Coefficient sehen Sie den “Best-Guess” (Punktschätzer) für den entsprechenden Koeffizienten in der Population. Das ist sozusagen der Wert, für den sich das Modell festlegen würde, wenn es sonst nichts sagen dürfte.\nBereichschätzungen Cleverer als Punktschätzungen sind Bereichsschätzungen (Intervallschätzungen): Hier wird ein Bereich plausibler Werte für den entsprechenden Koeffizienten angegeben. In der Spalte CI sehen Sie die untere bzw. die obere Grenze eines “Bereichs plausibler Werte”. Dieser Schätzbereich wird auch als Konfidenzintervall (engl. confidence interval, CI) bezeichnet. Ein Konfidenzintervall ist mit einer Sicherheit zwischen 0 und 1 angegeben, z.B. 95\\(\\,\\)% (0.95). Grob gesagt bedeutet ein 95\\(\\,\\)%-Kondidenzintervall, dass wir uns (laut Modell) zu 95\\(\\,\\)% sicher sein können, dass der wahre Werte sich in diesem Bereich befindet. In Tabelle 10.1 können wir ablesen, dass das Regressionsgewicht von year irgendwo zwischen praktisch Null (0.009) und ca. 0.01 Grad geschätzt wird. Je schmaler das Konfidenzintervall, desto genauer wird der Effekt geschätzt (unter sonst gleichen Umständen).\n\n\nDefinition 10.1 (Konfidenzintervall) Ein Konfidenzintervall (confidence interval, CI) gibt einen Schätzbereich plausibler Werte für einen Populationswert an, auf Basis der Schätzung, die uns die Stichprobe liefert. \\(\\square\\)\n\nDas Modell lm_wetter1, bzw. die Schätzungen zu den erwarteten Werten, kann mich sich so ausgeben lassen, s. Abbildung 10.3, links. Allerdings sind das zu viele Datenpunkte. Wir sollten es vielleicht anders visualisieren, s. Abbildung 10.3, rechts. Dazu aggregieren wir die Messwerte eines Jahres zu jeweils einem Mittelwert. Auf dieser Basis erstellen wir ein neues lineares Modell, lm_wetter1_pro_jahr, s. Tabelle 10.2.\n\nwetter_summ &lt;-\n  wetter %&gt;% \n  group_by(year) %&gt;% \n  summarise(temp = mean(temp),\n            precip = mean(precip))  # precipitation: engl. für Niederschlag\n\n\n# Summierte Daten (nach Jahr), aber gleiche Modellformel:\nlm_wetter1_pro_jahr &lt;- lm(temp ~ year, data = wetter_summ) \nparameters(lm_wetter1_pro_jahr) |&gt; \n  select(Parameter, Coefficient)\n\n\n\n\nTabelle 10.2: Modellparameter von lm_wetter1a\n\n\n\nFixed Effects\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n-14.14\n\n\nyear\n0.01\n\n\n\n\n\n\n\n\nKomfortabel ist es, das Modell lm_wetter1_pro_jahr mit plot(estimate_relation(lm_wetter1_pro_jahr)) zu plotten.\n\n\n\n\n\n\n\n\n\n\n(a) Ein Punkt pro Tag\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Ein Punkt pro Jahr\n\n\n\n\n\n\nAbbildung 10.3: Die Veränderung der mittleren Temperatur in Deutschland im Zeitverlauf [DWD2025]. Links: Jeder Punkt ist ein Tag (viel Overplotting, wenig nützlich). Rechts: Jeder Punkt ist ein Jahr (wetter_summ). Außerdem ist die Regressionsgerade dargestellt.\n\n\n\n\n🧑‍🎓 Moment mal, der Achsenabschnitt liegt bei etwa -14 Grad! Was soll das bitte bedeuten?\n\n\n10.3.2 UV zentrieren\nZur Erinnerung: Der Achsenabschnitt (\\(\\beta_0\\); engl. intercept) ist definiert als der \\(Y\\)-Wert an der Stelle \\(x=0\\), s. Kapitel 9.5.\nIn den Wetterdaten wäre Jahr=0 Christi Geburt. Da unsere Wetteraufzeichnung gerade mal ca. 150 Jahre in die Vergangenheit reicht, ist es vollkommen vermessen, dass Modell 2000 Jahre in die Vergangenheit zu extrapolieren, ganz ohne, dass wir dafür Daten haben, s. https://xkcd.com/605/. Sinnvoller ist es da, z.\\(\\,\\)B. einen Referenzwert festzulegen, etwa 1950. Wenn wir dann von allen Jahren 1950 abziehen, wird das Jahr 1950 zum neuen Jahr Null. Damit bezöge sich der Achsenabschnitt auf das Jahr 1950, was Sinn macht, denn für dieses Jahr haben wir Daten. Hat man nicht einen bestimmten Wert, der sich als Referenzwert anbietet, so ist es nützlich den Mittelwert (der UV) als Referenzwert zu nehmen. Diese Transformation bezeichnet man als Zentrierung (engl. centering) der Daten, s. Definition 7.7 und Listing 7.3.\n\n\n\n\n\nAbbildung 10.4: Du sollst nicht ein Modell weit außerhalb seines Datenbereichs extrapolieren\n\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(year_c = year - mean(year))  # \"c\" wie centered\n\nDas mittlere Jahr in unserer Messwertereihe ist übrigens 1951, wie etas Datenjudo zeigt: wetter %&gt;% summarise(mean(year))\nDie Steigung (d.\\(\\,\\)h. der Regressionskoeffizient für year_c) bleibt durch das Zentrieren unverändert, nur der Achsenabschnitt ändert sich, s. Tabelle 10.3.\n\nlm_wetter1_zentriert &lt;- lm(temp ~ year_c, data = wetter)\nparameters(lm_wetter1_zentriert) |&gt; \n  select(Coefficient, Parameter, CI_low, CI_high)\n\n\n\n\nTabelle 10.3: Modellparameter von lm_wetter1_zentriert\n\n\n\nFixed Effects\n\nCoefficient\nParameter\nCI\n\n\n\n8.49\n(Intercept)\n(8.42, 8.57)\n\n\n0.01\nyear_c\n(9.80e-03, 0.01)\n\n\n\n\n\n\n\n\nJetzt ist die Interpretation des Achsenabschnitts komfortabel: Im Jahr 1951 (x=0) lag die mittlere Temperatur in Deutschland (laut DWD) bei ca. 8.5\\(\\,\\)°C. Die Regressionsgleichung lautet: temp_pred = 8.49 + 0.01*year_c. In Worten: Wir sagen eine Temperatur vorher, die sich als Summe von 8.49\\(\\,\\)°C plus 0.01 mal das Jahr (in zentrierter Form) berechnet.\nWie gut erklärt unser Modell die Daten?\n\nr2(lm_wetter1_zentriert)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.005\n##   adj. R2: 0.005\n\nViel Varianz des Wetters erklärt das Modell mit year_c aber nicht. (year und year_c sind gleich stark mit temp korreliert, daher wird sich die Modellgüte nicht unterscheiden.). Macht auch Sinn: Abgesehen von der Jahreszahl spielt z.\\(\\,\\)B. die Jahreszeit eine große Rolle für die Temperatur. Das haben wir nicht berücksichtigt.\n\n🧑‍🎓 Wie warm ist es laut unserem Modell dann im Jahr 2051?\n\n\npredict(lm_wetter1_zentriert, newdata = tibble(year_c = 100))\n##   1 \n## 9.7\n\n\n🧑‍🎓 Moment! Die Vorhersage ist doch Quatsch! Schon im Jahr 2022 lag die Durchschnittstemperatur bei 10,5° Celsius (Wilke, 2013).\n\n\n🧑‍🏫 Wir brauchen ein besseres Modell! Zum Glück haben wir ambitionierten Wissenschaftsnachwuchs.\n\nDie Veränderung der auf fünf Jahre gemittelten Abweichung der Lufttemperatur zum Mittel von von 1951 bis 1980 ist in Abbildung 10.5 dargestellt. Links ist eine grobe Temperaturrasterung zu sehen (Daten ab 1753)1; rechts eine feinere (Daten ab 1881)2.\n\n\n\n\nTemperaturverlauf in Deutschland von 1753 bis 2020 (Habitator terrae, 2021)\n\n\n\nAbbildung 10.5: \n\n\n10.3.3 Binäre UV\n\nDefinition 10.2 (Binäre Variable) Eine binäre UV, auch Indikatorvariable oder Dummyvariable genannt, hat nur zwei Ausprägungen: 0 und 1. \\(\\square\\)\n\n\nBeispiel 10.3 (Binäre Variablen) Das sind zum Beispiel weiblich mit den Ausprägungen 0 (nein) und 1 (ja) oder before_1950 mit 1 für Jahre früher als 1950 und 0 ansonsten. \\(\\square\\)\n\n\nBeispiel 10.4 Hier interessiert Sie folgende Forschungsfrage:\n\n🧑‍🎓 Ob es in der zweiten Hälfte des 20. Jahrhunderts wohl wärmer war, im Durchschnitt, als vorher? \\(\\square\\)\n\n\nAber wie erstellen Sie eine Variable after_1950, um die zweite Hälfte des 20. Jahrhunderts (und danach) zu fassen? Nach einigem Überlegen kommen Sie auf die Idee, das vektorisierte Rechnen von R (s. Kapitel 3.6.5) auszunutzen:\n\nyear &lt;- c(1940, 1950, 1960)\nafter_1950 &lt;- year &gt; 1950  # prüfe, ob as Jahr größer als 1950 ist\nafter_1950\n## [1] FALSE FALSE  TRUE\n\nDie ersten zwei Jahre von year sind nicht größer als 1950, das dritte schon. Ja, so könnte das klappen! Diese Syntax übertragen Sie auf Ihre wetter-Daten:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(after_1950 = year &gt; 1950) %&gt;% \n  filter(region != \"Deutschland\")  # ohne Daten für Gesamt-Deutschland\n\nScheint zu klappen! Jetzt ein lineares Modell dazu berechnen, s. Tabelle 10.4.\n\nlm_wetter_bin_uv &lt;- lm(temp ~ after_1950, data = wetter)\n\n\n\n\nTabelle 10.4: Parameter von lm_wetter_bin_uv\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n8.18\n(8.06, 8.29)\n\n\nafter_1950TRUE\n0.64\n(0.48, 0.80)\n\n\n\n\n\n\n\n\nDie Parameterwerte des Modells lassen darauf schließen, dass es tatsächlich wärmer geworden ist nach 1950, und zwar offenbar ein gutes halbes Grad, s. Abbildung 10.6.\n\n\n\n\n\n\n\n\n\n\n(a) Mittelwertsunterschied als Regressionsparameter\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Mittelwertsunterschied als Verteilungsvergleich\n\n\n\n\n\n\nAbbildung 10.6: Modell: temp ~ after_1950, (a) Der Schätzbereich für den Parameter reicht von ca. 0.5 bis 0.8 Grad Unterschied. (b) Der Unterschied sieht in dieser Darstellung nicht groß aus.\n\n\n\nLeider zeigt ein Blick zum Ergebnis der Funktion r2, dass die Vorhersagegüte des Modells zu wünschen übrig lässt (r2(lm_wetter_bin_uv)). Wir brauchen ein besseres Modell.\nUm die Koeffizienten eines linearen Modells auszurechnen, benötigt man eine metrische UV und eine metrische AV. Hier haben wir aber keine richtige metrische UV, sondern eine logische Variable mit den Werten TRUE und FALSE. Um die UV in eine metrische Variable umzuwandeln, gibt es einen einfachen Trick, den R für uns ohne viel Ankündigung durchführt: Umwandling in eine oder mehrere binäre Variablen, s. Definition 10.2.\nHat eine nominale UV zwei Stufen, so überführt (synonym: transformiert) lm diese Variable in eine binäre Variable. Da eine binäre Variable wie eine metrische angesehen werden kann, kann die Regression in gewohnter Weise durchgeführt werden. Wenn Sie die Ausgabe der Parameter betrachten, so sehen Sie die neu erstellte binäre Variable (s. Tabelle 10.4). Man beachte, dass der ursprüngliche Datensatz nicht geändert wird, nur während der Analyse von lm wird die Umwandlung der Variable durchgeführt.\nIn unserem Fall liegt mit after_1950 eine logische Variable mit den Werten TRUE und FALSE vor. TRUE und FALSE werden von R automatisch als 1 bzw. als 0 verstanden. Also: Eine logische Variable ist schon eine binäre Variable.\n\n🤖 Eine 1 kannst du als “Ja! Richtig!” verstehen und eine 0 als “Nein! Falsch!”\n\n\nBeispiel 10.5 (Beispiel: ‘Geschlecht’ in eine binäre Variable umwandeln.) Angenommen wir haben eine Variable geschlecht mit den zwei Stufen Frau und Mann und wollen diese in eine Indikatorvariable umwandeln. Da “Frau” alphabetisch vor “Mann” kommt, nimmt R “Frau” als erste Stufe bzw. als Referenzgruppe. “Mann” ist dann die zweite Stufe, die in der Regression dann in Bezug zur Referenzgruppe gesetzt wird. lm wandelt uns diese Variable in geschlechtMann um mit den zwei Stufen 0 (kein Mann, also Frau) und 1 (Mann). \\(\\square\\)\n\n\n\n\n\n\n\n\nid\ngeschlecht\n\n\n\n1\nMann\n\n\n2\nFrau\n\n\n\n\n\n\n\n\\(\\qquad \\rightarrow\\)\n\n\n\n\n\n\nid\ngeschlechtMann\n\n\n\n1\n1\n\n\n2\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nEin lineares Modell mit binärer UV zeigt nichts anderes als die Differenz der Gruppenmittelwerte. \\(\\square\\)\n\n\n\nwetter %&gt;% \n  group_by(after_1950) %&gt;% \n  summarise(temp_mean = mean(temp))\n\n\n\nafter_1950\ntemp_mean\n\n\n\nFALSE\n8.2\n\n\nTRUE\n8.8\n\n\n\n\n\nDie Interpretation eines linearen Modells mit binärer UV veranschaulicht Abbildung 10.7: Der Achsenabschnitt (\\(\\beta_0\\)) entspricht dem Mittelwert der 1. Gruppe. Der Mittelwert der 2. Gruppe entspricht der Summe aus Achsenabschnitt und dem Koeffizienten der zweiten Gruppe. (Abbildung 10.7 zeigt nur die Daten für den Monat Juli im Bundesland Bayern, der Einfachheit und Übersichtlichkeit halber.)\n\n\n\n\n\n\n\nAbbildung 10.7: Sinnbild zur Interpretation eines linearen Modells mit binärer UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben)\n\n\n\n\nFassen wir die Interpretation der Koeffizienten für das Modell mit binärer UV zusammen:\n\nMittelwert der 1. Gruppe (bis 1950): Achsenabschnitt (\\(\\beta_0\\))\n\nMittelwert der 2. Gruppe (nach 1950): Achsenabschnitt (\\(\\beta_0\\)) + Steigung der Regressionsgeraden (\\(\\beta_1\\))\n\n\nFür die Modellwerte \\(\\color{modelcol}{\\hat{y}}\\) gilt also:\n\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} = 17.7\\)\nTemperatur laut Modell bis 1950: \\(\\color{modelcol}{\\hat{y}} = \\color{beta0col}{\\beta_0} +  \\color{beta1col}{\\beta_1}= \\color{beta0col}{17.7} + \\color{beta1col}{0.6} = 18.3\\)\n\nBei nominalen (und auch bei binären) Variablen kann man \\({\\beta_1}\\) als einen Schalter verstehen; bei metrischen Variablen als einen Dimmer.3 \\(\\square\\)\n\n10.3.4 Nominale UV\nIn diesem Abschnitt betrachten wir ein lineares Modell (für uns synonym: Regressionsmodell) mit einer mehrstufigen (nominalskalierten) UV. So ein Modell ist von den Ergebnissen her praktisch identisch zu einer Varianzanalyse mit einer einzigen UV.\n\nBeispiel 10.6 Ob es wohl substanzielle Temperaturunterschiede zwischen den Bundesländern gibt?\n\nBefragen wir dazu ein lineares Modell; in Tabelle 10.5 sind für jeden Parameter der Punktschätzer (Koeffizient) und der zugehörige Schätzbereich (Konfidenzintervall) mit Ober- und Untergrenze angegeben.\n\nlm_wetter_region &lt;- lm(temp ~ region, data = wetter)\n\n\n\n\nTabelle 10.5: Modellparameter für lm_wetter_region\n\n\n\nFixed Effects\n\nParameter\nCoefficient\nCI\n\n\n\n(Intercept)\n8.25\n(7.93, 8.56)\n\n\nregionBayern\n-0.63\n(-1.07, -0.19)\n\n\nregionBrandenburg\n0.57\n(0.13, 1.02)\n\n\nregionBrandenburg/Berlin\n0.58\n(0.14, 1.03)\n\n\nregionHessen\n0.11\n(-0.33, 0.56)\n\n\nregionMecklenburg-Vorpommern\n0.08\n(-0.37, 0.52)\n\n\nregionNiedersachsen\n0.52\n(0.07, 0.96)\n\n\nregionNiedersachsen/Hamburg/Bremen\n0.52\n(0.08, 0.96)\n\n\nregionNordrhein-Westfalen\n0.80\n(0.35, 1.24)\n\n\nregionRheinland-Pfalz\n0.46\n(0.02, 0.90)\n\n\nregionSaarland\n0.71\n(0.27, 1.16)\n\n\nregionSachsen\n-0.04\n(-0.48, 0.40)\n\n\nregionSachsen-Anhalt\n0.55\n(0.11, 1.00)\n\n\nregionSchleswig-Holstein\n0.17\n(-0.27, 0.62)\n\n\nregionThueringen\n-0.48\n(-0.92, -0.03)\n\n\nregionThueringen/Sachsen-Anhalt\n0.10\n(-0.34, 0.54)\n\n\n\n\n\n\n\n\nHat die nominalskalierte UV mehr als zwei Stufen, so transformiert lm sie in mehr als eine Indikatorvariable um. Genauer gesagt ist es immer eine Indikatorvariable weniger als es Stufen in der nominalskalierten Variablen gibt. Allgemein gilt: Hat eine nominale Variable \\(k\\) Stufen, so wird diese Variable von lm in \\(k-1\\) binäre Variablen umgewandelt.\nBetrachten wir ein einfaches Beispiel, eine Tabelle mit der Spalte Bundesland – aus Gründen der Einfachheit hier nur mit drei Bundesländern. Damit lm arbeiten kann, wird Bundesland in zwei Indikatorvariablen umgewandelt.\n\n\n\n\n\n\n\nid\nBundesland\n\n\n\n1\nBaWü\n\n\n2\nBayern\n\n\n3\nBrandenburg\n\n\n\n\n\n\n\n\\(\\quad \\rightarrow\\)\n\n\n\n\n\n\nid\nBL_Bayern\nBL_Bra\n\n\n\n1\n0\n0\n\n\n2\n1\n0\n\n\n3\n0\n1\n\n\n\n\n\n\n\n\nAuch im Fall mehrerer Ausprägungen einer nominalen Variablen gilt die gleiche Logik der Interpretation wie bei binären Variablen:\n\nMittelwert der 1. Gruppe: Achsenabschnitt (\\(\\beta_0\\))\nMittelwert der 2. Gruppe: Achsenabschnitt (\\(\\beta_0\\)) + Steigung der 1. Regressionsgeraden (\\(\\beta_1\\))\nMittelwert der 3. Gruppe: Achsenabschnitt (\\(\\beta_0\\)) + Steigung der 2. Regressionsgeraden (\\(\\beta_2\\))\nusw.\n\nEs kann nervig sein, dass das Bundesland, welches als Referenzgruppe (sprich als Gruppe des Achsenabschnitts) ausgewählt wurde nicht explizit in der Ausgabe angegeben ist. Der Wert der Referenzgruppe findet seinen Niederschlag im Achsenabschnitt. Bei einer Variable vom Typ character wählt R den alphabetisch ersten Wert als Referenzgruppe für ein lineares Modell aus. Bei einer Variable vom Typ factor ist die Reihenfolge bereits festgelegt, vgl. Kapitel 10.3.5. Der Mittelwert dieser Gruppe entspricht dem Achsenabschnitt.\n\nBeispiel 10.7 (Achsenabschnitt in wetter_lm2) Da Baden-Württemberg das alphabetisch erste Bundesland ist, wird es von R als Referenzgruppe ausgewählt, dessen Mittelwert als Achsenabschnitt im linearen Modell hergenommen wird. \\(\\square\\)\n\nAm einfachsten verdeutlicht sich lm_wetter_region vielleicht mit einem Diagramm, s. Abbildung 10.8.\n\n\n\n\n\n\n\nAbbildung 10.8: Sinnbild zur Interpretation eines linearen Modells mit nominaler UV (reingezoomt, um den Mittelwertsunterschied hervorzuheben).\n\n\n\n\n\nBeispiel 10.8 (Niederschlagsmenge im Vergleich der Monate) Eine weitere Forschungsfrage, die Sie nicht außer acht lassen wollen, ist die Frage nach den jahreszeitlichen Unterschieden im Niederschlag (engl. precipitation). Los R, rechne! \\(\\square\\)\n\n\n🤖 Endlich geht’s weiter! Ergebnisse findest du in Tabelle 10.6!\n\n\nlm_wetter_month &lt;- lm(precip ~ month, data = wetter)\nparameters(lm_wetter_month)\n\n\n\n\nTabelle 10.6: Modellparameter für lm_wetter_month\n\n\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(27166)\np\n\n\n\n(Intercept)\n53.27\n0.41\n(52.46, 54.08)\n128.76\n&lt; .001\n\n\nmonth\n1.14\n0.06\n(1.03, 1.25)\n20.29\n&lt; .001\n\n\n\n\n\n\n\n\nJa, da scheint es deutliche Unterschiede im Niederschlag zu geben. Wir brauchen ein Diagramm zur Verdeutlichung, s. Abbildung 10.9, links (plot(estimate_expectation(lm_wetter_month)). Oh nein: R betrachtet month als numerische Variable! Aber “Monat” bzw. “Jahreszeit” sollte nominal sein.\n\n🤖 Aber month ist als Zahl in der Tabelle hinterlegt. Jede ehrliche Maschine verarbeitet eine Zahl als Zahl, ist doch klar!\n\n\n👩 Okay, R, wir müssen month in eine nominale Variable transformieren. Wie geht das?\n\n\n🤖 Dazu kannst du den Befehl factor nehmen. Damit wandelst du eine numerische Variable in eine nominalskalierte Variable (Faktorvariable) um. Faktisch heißt das, dass dann eine Zahl als Text gesehen wird.\n\n\nBeispiel 10.9 Transformiert man 42 mit factor, so wird aus 42 \"42\". Aus der Zahl wird ein Text. Alle metrischen Eigenschaften gehen verloren; die Variable ist jetzt auf nominalen Niveau. \\(\\square\\)\n\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = factor(month))\n\nJetzt berechnen wir mit der faktorisierten Variablen ein lineares Modell, s. Tabelle 10.7.\n\nlm_wetter_month_factor &lt;- lm(precip ~ month_factor, data = wetter)\nparameters(lm_wetter_month_factor) |&gt; \n  select(Parameter, Coefficient)\n\n\n\n\nTabelle 10.7: Modellparameter von lm_wetter_month_factor (nur die ersten paar Parameter)\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n57.0\n\n\nmonth_factor2\n-9.9\n\n\nmonth_factor3\n-7.8\n\n\nmonth_factor4\n-8.5\n\n\nmonth_factor5\n4.7\n\n\nmonth_factor6\n14.3\n\n\n\n\n\n\n\n\nSehr schön! Jetzt haben wir eine Referenzgruppe (Monat 1, d.\\(\\,\\)h. Januar) und 11 Unterschiede zum Januar, s. Abbildung 10.9.\n\nÜbungsaufgabe 10.1 In ähnlicher Form zu Abbildung 10.9 könnten Sie auch die Regressionsgewichte wie folgt plotten: parameters(lm_wetter_month_factor) |&gt; plot(). Was sind die Unterschiede zu Abbildung 10.9?4 \\(\\square\\)\n\n\nggerrorplot(data = wetter,\n            x = \"month_factor\",\n            y = \"precip\",\n            desc_stat = \"mean_sd\")\n\n\n\n\n\n\nAbbildung 10.9: Niederschlagsmengen nach Monaten (Mittelwerte plus SD)\n\n\n\n\nMöchte man die Referenzgruppe eines Faktors ändern, kann man dies mit relevel tun:\n\nwetter &lt;-\n  wetter %&gt;% \n  mutate(month_factor = relevel(month_factor, ref = \"7\"))\n\nSo sieht dann die geänderte Reihenfolge aus:5\n\nlevels(wetter$month_factor)\n##  [1] \"7\"  \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"8\"  \"9\"  \"10\" \"11\" \"12\"\n\n\n10.3.5 Binäre plus metrische UV\nIn diesem Abschnitt untersuchen wir ein lineares Modell mit zwei UV: einer zweistufigen (binären) UV plus einer metrischen UV. Ein solches Modell kann auch als Kovarianzanalyse (engl. analysis of covariance, ANCOVA) bezeichnet werden.\n\nBeispiel 10.10 Ob sich die Niederschlagsmenge wohl unterschiedlich zwischen den Monaten entwickelt hat in den letzten gut 100 Jahren? Der Einfachheit halber greifen Sie sich nur zwei Monate heraus (Januar und Juli).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) \n\n\n🧑‍🏫 Ich muss mal kurz auf eine Sache hinweisen …\n\nEine Faktorvariable ist einer der beiden Datentypen in R, die sich für nominalskalierte Variablen anbieten: Textvariablen (character) und Faktor-Variablen (factor). Ein wichtiger Unterschied ist, dass die erlaubten Ausprägungen (“Faktorstufen”) bei einer Faktor-Variable mitgespeichert werden, bei der Text-Variable nicht. Das kann praktisch sein, denn bei einer Faktorvariable ist immer klar, welche Ausprägungen in Ihrer Variable möglich sind. \\(\\square\\)\n\n\nBeispiel 10.11 (Beispiele für Faktorvariablen)  \n\ngeschlecht &lt;- c(\"f\", \"f\", \"m\")\ngeschlecht_factor &lt;- factor(geschlecht)\ngeschlecht_factor\n## [1] f f m\n## Levels: f m\n\n\nFiltern verändert die Faktorstufen nicht. Wenn Sie von der Faktorvariablen6 geschlecht das 3. Element (\"m\") herausfiltern, so dass z.\\(\\,\\)B. nur die ersten beiden Elemente übrig bleiben mit allein der Ausprägung \"f\", merkt sich R trotzdem, dass die Variable laut Definition zwei Faktorstufen besithzt (\"f\" und \"m\").\nGenau so ist es, wenn Sie aus wetter nur die Monate \"1\" und \"7\" herausfiltern: R merkt sich, dass es 12 Faktorstufen gibt. Möchten Sie die herausgefilterten Faktorstufen “löschen”, so können Sie einfach die Faktorvariable neu definieren (mit factor).\n\nwetter_month_1_7 &lt;-\n  wetter %&gt;% \n  filter(month == 1  | month == 7) %&gt;% \n  # Faktor (und damit die Faktorstufen) neu definieren:\n  mutate(month_factor = factor(month))\n\nHat man mehrere (“multiple”) X-Variablen (Prädiktoren, unabhängige Variablen), so trennt man sich mit einem Plus-Zeichen in der Regressionsformel, z.\\(\\,\\)B. temp ~ year_c + month.\n\nDefinition 10.3 (Multiple Regression) Eine multiple Regression beinhaltet mehr als eine X-Variable. Die Modellformel spezifiziert man so:\n\\(y \\sim x_1 + x_2 + \\ldots + x_n \\qquad \\square\\)\n\nDie Veränderung der monatlichen Temperatur (10-Jahres-Mittel) ist in Abbildung 10.2, c) dargestellt (aber mit allen 12 Monaten, sieht schöner aus).\nDas Pluszeichen hat in der Modellgleichung (synonym: Regressionsformel) keine arithmetische Funktion. Es wird nichts addiert. In der Modellgleichung sagt das Pluszeichen nur “und noch folgende UV …”.\nDie Modellgleichung von lm_year_month liest sich also so:\n\nTemperatur ist eine Funktion von der (zentrierten) Jahreszahl und des Monats\n\n\nlm_year_month &lt;- lm(precip ~ year_c + month_factor, \n                    data = wetter_month_1_7)\n\nDie Modellparameter sind in Tabelle 10.8 zu sehen.\n\n\n\nTabelle 10.8: Modellparameter von lm_year_month\n\n\n\nFixed Effects\n\nCoefficient\nParameter\nCI\n\n\n\n56.94\n(Intercept)\n(55.60, 58.27)\n\n\n0.03\nyear_c\n(5.59e-03, 0.05)\n\n\n24.37\nmonth_factor7\n(22.48, 26.27)\n\n\n\n\n\n\n\n\nDie Modellkoeffizienten sind so zu interpretieren:\n\nAchsenabschnitt (\\(\\beta_0\\), Intercept): Im Referenzjahr (1951) im Referenzmonat Januar lag die Niederschlagsmenge bei 57\\(\\,\\)mm pro Quadratmeter.\nRegressionskoeffizient für Jahr (\\(\\beta_1\\), year_c): Pro Jahr ist die Niederschlagsmenge im Schnitt um 0.03\\(\\,\\)mm an (im Referenzmonat).\nRegressionskoeffizient für Monat (\\(\\beta_2\\), month_factor7) Im Monat 7 (Juli) lag die mittlere Niederschlagsmenge (im Referenzjahr) knapp 25\\(\\,\\)mm über dem mittleren Wert des Referenzmonats (Januar).\n\nDie Regressiongleichung von lm_year_month lautet: precip_pred = 56.94 + 0.03*year_c + 24.37*month_factor_7. Im Monat Juli ist month_factor_7 = 1, ansonsten (Januar) ist month_factor = 0. Demnach erwarten wir laut Modell lm_year_month im Juli des Referenzjahres 81.31\\(\\,\\)mm Niederschlag. Die Werte der Regressionskoeffizienten sind Tabelle 10.8 entnommen.\n\n🧑‍🎓 Puh, kompliziert!\n\n\n🧑‍🏫 Es gibt einen Trick, man kann sich von R einfach einen beliebigen Y-Wert berechnen lassen, s. Beispiel 10.12.\n\n\nBeispiel 10.12 (Niederschlag laut Modell Im Juli 2020?) Hey R, berechne uns anhand neuer Daten den laut Modell zu erwartenden Niederschlag für Juli im Jahr 2020!\n\nneue_daten &lt;- tibble(year_c = 2020-1951,\n                     month_factor = factor(\"7\"))\npredict(lm_year_month, newdata = neue_daten)\n##  1 \n## 83\n\nDas Modell erwartet Niederschlag in Höhe von 83.3\\(\\,\\)mm. Mit predict kann man sich Vorhersagen eines Modells ausgeben lassen. \\(\\square\\)\n\nAlle Regressionskoeffizienten beziehen sich auf die AV unter der Annahme, dass alle übrigen UV den Wert Null (bzw. Referenzwert) aufweisen.\nVisualisieren wir uns die geschätzten Erwartungswert pro Wert der UV, s. Abbildung 10.10: plot(estimate_expectation(lm_year_month))\n\n\n\n\n\n\n\nAbbildung 10.10: Niederschlag für Januar (month 1) und Juli (month 7) im Verlauf der Jahre. Man beachte, dass die Regressionsgeraden parallel sind.\n\n\n\n\nMit scale_color_okabeito haben wir die Standard-Farbpalette durch die von Okabe & Ito (2023) ersetzt (s. Barrett, 2021). Das ist nicht unbedingt nötig, aber robuster bei Sehschwächen, vgl. Kapitel 5.11.3. Die erklärte Varianz von lm_year_month liegt bei:\n\nr2(lm_year_month)\n## # R2 for Linear Regression\n##        R2: 0.124\n##   adj. R2: 0.124\n\n\n10.3.6 Interaktion\nEine Modellgleichung der Form temp ~ year + month zwingt die Regressionsgeraden dazu, parallel zu verlaufen. Aber vielleicht würden sie besser in die Punktewolken passen, wenn wir ihnen erlauben, auch nicht parallel verlaufen zu dürfen? Nicht-parallele Regressionsgeraden erlauben wir, indem wir das Regressionsmodell wie folgt spezifizieren und visualisieren, s. Listing 10.1.\n\n\n\nListing 10.1: Ein Interaktionsmodell spezifiziert man in dieser Art: y ~ x1 + x2 + x1:x2\n\nlm_year_month_interaktion &lt;- lm(\n  precip ~ year_c + month_factor + year_c:month_factor, \n  data = wetter_month_1_7)\n\n\n\n\nVisualisiert ist das Modell in Abbildung 10.11.\n\nplot(estimate_relation(lm_year_month_interaktion)) \n\n\n\n\n\n\n\n\nAbbildung 10.11: Niederschlag im Jahresverlauf und Monatsvergleich mit Interaktionseffekt: Die Veränderung im Verlauf der Jahre ist unterschiedlich für die Monate (Januar vs. Juli). Die beiden Regressionsgeraden sind nicht parallel.\n\n\n\n\nDer Doppelpunkt-Operator (:) fügt der Regressionsgleichung einen Interaktionseffekt hinzu, in diesem Fall die Interaktion von Jahr (year_c) und Monat (month_factor):\nprecip ~ year_c + month_factor + year_c:month_factor\n\nDefinition 10.4 (Interaktionseffekt) Einen Interaktionseffekt von x1 und x2 kennzeichnet man in R mit dem Doppelpunkt-Operator, x1:x2:\ny ~ x1 + x2 + x1:x2 \\(\\square\\)\n\nIn Worten:\n\ny wird modelliert als eine Funktion von x1 und x2 und dem Interaktionseffekt von x1 mit x2.\n\nWie man in Abbildung 10.11 sieht, sind die beiden Regressionsgeraden nicht parallel. Sind die Regressionsgeraden von zwei (oder mehr) Gruppen nicht parallel, so liegt ein Interaktionseffekt vor. In diesem Fall ist der Interaktionsffekt ungleich Null. \\(\\square\\)\n\nBeispiel 10.13 (Interaktionseffekt von Niederschlag und Monat) Wie ist die Veränderung der Niederschlagsmenge (Y-Achse) im Verlauf der Jahre (X-Achse)? Das kommt darauf an, welchen Monat man betrachtet. Der Effekt der Zeit ist unterschiedlich für die Monate: Im Juli nahm der Niederschlag ab, im Januar zu. \\(\\square\\)\n\nLiegt ein Interaktionseffekt vor, kann man nicht mehr von “dem” (statistischen) Effekt einer UV (auf die AV) sprechen. Vielmehr muss man unterscheiden: Je nach Gruppe (z.\\(\\,\\)B. Monat) unterscheidet der Effekt des Jahres auf die Niederschlagsmenge. (“Effekt” ist hier immer statistisch, nie kausal gemeint.) Betrachten wir die Parameterwerte des Interaktionsmodells, s. Tabelle 10.9.\n\n\n\nTabelle 10.9: Modellparameter von lm_year_month_interaktion\n\n\n\n\nParameter\nCoefficient\nCI_low\nCI_high\n\n\n\n(Intercept)\n56.91\n55.59\n58.24\n\n\nyear_c\n0.13\n0.10\n0.16\n\n\nmonth_factor7\n24.37\n22.50\n26.25\n\n\nyear_c:month_factor7\n-0.20\n-0.25\n-0.16\n\n\n\n\n\n\n\n\nNeu bei der Ausgabe zu diesem Modell ist die unterste Zeile für den Parameter year c × month factor [7]. Sie gibt die Stärke des Interaktionseffekts an.  Die Zeile zeigt, wie unterschiedlich sich die die Niederschlagsmenge zwischen den beiden Monaten im Verlauf der Jahre ändert: Pro Jahr ist die Zunahme an Niederschlag um 0.20\\(\\,\\)mm geringer als im Referenzmonat (Januar). Damit resultiert für Juli insgesamt ein positiver Effekt: 0.13 - -0.20 = 0.07. Insgesamt lautet die Regressionsgleichung: precip_pred = 56.91 + 0.13 * year_c + 24.37 * month_factor_7 - 0.20 * year_c:month_factor_7.\n\n\n\n\n\n\nWichtig\n\n\n\nDer Achsenabschnitt gibt den Wert der AV an unter der Annahme, dass alle UV den Wert Null aufweisen. \\(\\square\\)\n\n\nWenn eine Beobachtung in allen UV den Wert 0 hat, so gibt der Achsenabschnitt den Niederschlag für den Januar des Jahres 1951 an. Die Regressionskoeffizienten geben die Zunahme in der AV an, wenn der jeweilige Wert der UV um 1 steigt, die übrigen UV aber den Wert 0 aufweisen.\nDas \\(R^2\\) von lm_year_month_interaktion beträgt übrigens nur geringfügig mehr als im Modell ohne Interaktion:\n\nr2(lm_year_month_interaktion)  # aus `{easystats}`\n## # R2 for Linear Regression\n##        R2: 0.139\n##   adj. R2: 0.138\n\nDa man Modelle so einfach wie möglich halten sollte, könnten wir auf den Interaktionseffekt im Modell verzichten. Der Interaktionseffekt verbessert die Modellgüte nur geringfügig. Falls wir aber von einer starken Theorie ausgehen, die den Interaktionseffekt verlangt, hätten wir einen triftigen Grund, den Interaktionseffekt im Modell zu belassen.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#modelle-mit-vielen-uv",
    "href": "090-regression2.html#modelle-mit-vielen-uv",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.4 Modelle mit vielen UV",
    "text": "10.4 Modelle mit vielen UV\n\n10.4.1 Zwei metrische UV\nEin Modell mit zwei metrischen UV kann man sich im 3D-Raum visualisieren, s. Abbildung 10.12, oder im 2D-Raum, s. Abbildung 10.13. Im 3D-Raum wird die Regressionsgerade zu einer Regressionsebene.\n\n\n\n\n\n\nWinkel 1\n\n\n\n\n\nWinkel 2\n\n\n\n\n\nWinkel 3\n\n\n\n\n\nAbbildung 10.12: Ein lineares Modell, y ~ x1 + x2 mit zwei UV im 3D-Raum.\n\n\n\n\n\n\n\n\n\nAbbildung 10.13: 2D-Diagramm für 3D-Modell\n\n\n\n\n\n\n\n\n3D-Animation\n2D-Diagramm für 3D-Modell\n\n\n\n\n\n\n\n\n(a) Animation eines Regeressionsmodells mit zwei metrischen UV, x1 und x2; y wird gut von den beiden UV erklärt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 10.14\n\n\nGrundsätzlich kann man viele UV in ein (lineares) Modell aufnehmen. Betrachten wir z.\\(\\,\\)B. folgendes lineares Modell mit zwei metrischen UV, lm_mario_2uv.\n\nlm_mario_2uv &lt;- lm(total_pr ~ start_pr + ship_pr, \n                   data = mariokart %&gt;% filter(total_pr &lt; 100))\n\n\n10.4.2 Viele UV ins Modell?\nWir könnten im Prinzip alle Variablen unserer Datentabelle als UV in das Regressionsmodell aufnehmen. Die Frage ist nur: Macht das Sinn? Hier sind einige Richtlinien, die helfen, welche Variablen (und wie viele) man als UV in ein Modell aufnehmen sollte [Gelman et al. (2021);. S. 199], wenn das Ziel eine möglichst hohe Modellgüte ist:\n\nMan sollte alle Variablen aufnehmen, von denen anzunehmen ist, dass Sie Ursachen für die Zielvariablen sind.\nBei UV mit starken (absoluten) Effekten kann es Sinn machen, ihre Interaktionseffekte auch mit in das Modell aufzunehmen.\nUV, die vergleichsweise exakt geschätzt werden (der Bereich 95 CI ist klein), sollten tendenziell im Modell belassen werden, da sie die Modellgüte verbessern.\n\nIst das Ziel hingegen, eine Theorie bzw. ein wissenschaftliches Modell zu überprüfen, so sollte man genau die UV in das Modell aufnehmen, die die Theorie verlangt.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallbeispiel-zur-prognose",
    "href": "090-regression2.html#fallbeispiel-zur-prognose",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.5 Fallbeispiel zur Prognose",
    "text": "10.5 Fallbeispiel zur Prognose\n\nBeispiel 10.14 (Prognose des Verkaufspreis) Ganz können Sie von Business-Welt und ihren Gratifikationen nicht lassen, trotz Ihrer wissenschaftlichen Ambitionen. Sie haben den Auftrag bekommen, den Verkaufspreis von Mariokart-Spielen möglichst exakt vorherzusagen. Also gut, das Honorar ist phantastisch, Sie sind jung und brauchen das Geld. \\(\\square\\)\n\n\n10.5.1 Modell “all-in”\nUm die Güte Ihrer Vorhersagen zu prüfen, teilt Ihre Chefin den Datensatz in zwei zufällige Teile.\n\n👩‍💼 Ich teile den Datensatz mariokart zufällig in zwei Teile. Den ersten Teil kannst du nutzehn, um Modelle zu berechnen (“trainieren”) und ihre Güte zu prüfen. Den Teil nenne ich “Train-Sample”, hört sich cool an, oder? Im Train-Sample ist ein Anteil (fraction) von 70% der Daten, okay? Die restlichen Daten behalte ich. Wenn du ein gutes Modell hast, kommst du und wir berechnen die Güte deiner Vorhersagen in dem verbleibenden Teil, die übrigen 30% der Daten. Diesen Teil nennen wir Test-Sample, alles klar?\n\nWenn die Daten in Ihrem Computer zu finden sind, z.\\(\\,\\)B. im Unterordner data, dann können Sie sie von dort importieren:\n\nmariokart_train &lt;- read.csv(\"data/mariokart_train.csv\")\n\nAlternativ können Sie sie auch von diesem Pfad von einem Rechner in der Cloud herunterladen:\n\nmariokart_train &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_train.csv\")\n\nDann importieren wir auf gleiche Weise Test-Sample in R:\n\nmariokart_test &lt;- read.csv(\"https://raw.githubusercontent.com/sebastiansauer/statistik1/main/data/mariokart_test.csv\")\n\nAlso los. Sie probieren mal die “All-in-Strategie”: Alle Variablen rein in das Modell. Viel hilft viel, oder nicht?\n\nlm_allin &lt;- lm(total_pr ~ ., data = mariokart_train)\nr2(lm_allin)  # aus easystats\n## # R2 for Linear Regression\n##        R2: 0.994\n##   adj. R2: 0.980\n\nDer Punkt in total_pr ~ . heißt “alle Variablen in der Tabelle (außer total_pr)”.\n\n👩‍💼 Hey! Das ist ja fast perfekte Modellgüte!\n\n\n🦹‍♀️️ Vorsicht: Wenn ein Angebot aussieht wie “too good to be true”, dann ist es meist auch too good to be true.\n\nDer Grund für den fast perfekten Modellfit ist die Spalte Title. Unser Modell hat einfach den Titel jeder Auktion auswendig gelernt. Weiß man, welcher Titel zu welcher Auktion gehört, kann man perfekt die Auktion aufsagen bzw. das Verkaufsgebot perfekt vorhersagen. Leider nützen die Titel der Auktionen im Train-Sample nichts für andere Auktionen. Im Test-Sample werden unsere Vorhersagen also grottenschlecht sein, wenn wir uns auf die Titel der Auktionen im Test-Sample stützen. Merke: Höchst idiografische Informationen wie Namen, Titel etc. sind nicht nützlich, um allgemeine Muster zu erkennen und damit exakte Prognosen zu erstellen.\nProbieren wir also die Vorhersage im Test-Sample:\n\npredict(lm_allin, newdata = mariokart_test)\n## Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$xlevels): factor title has new levels MARIO KART FOR NINTENDO Wii WITH 2 WHEELS + GAME, Mario Kart Wii (Wii) COMPLETE , Mario Kart Wii (Wii) game , Mario Kart Wii (Wii) game and 2 wheels!, Mario Kart Wii (Wii) Game and Steering Wheel, Mario Kart Wii (Wii) Includes Steering Wheel!, MarioKart (Wii) w/ wheel\n\nOh nein! Was ist los!? Eine Fehlermeldung!\nNominalskalierte UV mit vielen Ausprägungen, wie title sind problematisch. Kommt eine Ausprägung von title im Test-Sample vor, die es nicht im Train-Sample gab, so resultiert ein Fehler beim predicten. Häufig ist es ohnehin sinnvoll, auf diese Variable zu verzichten, da diese Variablen oft zu Overfitting führen.\n\n10.5.2 Modell “all-in”, ohne Titelspalte\nOkay, also auf die Titelspalte sollten wir vielleicht besser verzichten. Nächster Versuch.\n\nmariokart_train2 &lt;-\n  mariokart_train %&gt;% \n  select(-c(title, id))\n\nlm_allin_no_title_no_id &lt;- lm(total_pr ~ ., data = mariokart_train2)\nr2(lm_allin_no_title_no_id) \n## # R2 for Linear Regression\n##        R2: 0.521\n##   adj. R2: 0.441\n\nDas R-Quadrat ist durchaus ordentlich.\n\n🤖 Das haben wir gut gemacht!\n\n\nperformance::rmse(lm_allin_no_title_no_id)\n## [1] 20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSie rennen zu Ihrer Chefin, die jetzt die Güte Ihrer Vorhersagen in den restlichen Daten bestimmen soll.\n\n👩‍💼 Da wir dein Modell in diesem Teil des Komplett-Datensatzes testen, nennen wir diesen Teil das “Test-Sample”.\n\nIhre Chefin schaut sich die Verkaufspreise im Test-Sample an:\n\nmariokart_test %&gt;% \n  select(id, total_pr) %&gt;% \n  head()\n\n\n\nid\ntotal_pr\n\n\n\n1.2e+11\n37\n\n\n2.9e+11\n55\n\n\n1.8e+11\n56\n\n\n1.8e+11\n56\n\n\n3.5e+11\n65\n\n\n1.1e+11\n46\n\n\n\n\n\n\n👩‍💼️ Okay, hier sind die ersten paar echten Verkaufspreise. Jetzt mach mal deine Vorhersagen auf Basis deines besten Modells!\n\nBerechnen wir die Vorhersagen (engl. predictions; to predict: vorhersagen):\n\nlm_allin_predictions &lt;- predict(lm_allin_no_title_no_id, newdata = mariokart_test)\n\nHier sind die ersten paar Vorhersagen:\n\nhead(lm_allin_predictions)\n##  1  2  3  4  5  6 \n## 29 54 53 54 42 47\n\nDiese Vorhersagen fügen wir noch der Ordnung halber in die Tabelle mit den Test-Daten ein:\n\nmariokart_test &lt;-\n  mariokart_test %&gt;% \n  mutate(lm_allin_predictions = predict(lm_allin_no_title_no_id, \nnewdata = mariokart_test))\n\n👩‍💼️ Okay, was ist jetzt der mittlere Vorhersagefehler?\nUm die Vorhersagegüte im Test-Sample auszurechnen (wir verwenden dazu die Funktionen mae und rsq, nutzen wir die Funktionen des R-Paketes yardstick (welches Sie vielleicht noch installieren müssen):\n\nlibrary(yardstick)\n\nyardstick::mae(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\nyardstick::rmse(data = mariokart_test,\n               truth = total_pr,  # echter Verkaufspreis\n               estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nmae\nstandard\n10\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrmse\nstandard\n13\n\n\n\n\nIhr mittlerer Vorhersagefehler (RMSE) liegt bei ca. 13 Euro. Übrigens haben wir hier yardstick::rmse geschrieben und nicht nur rmse, da es sowohl im Paket performance ( Teil des Metapakets easystats) als auch im Paket yardstick (Teil des Metapakets tidymodels) einen Befehl des Namens rmse gibt. Name-Clash-Alarm! R könnte daher den anderen rmse meinen als Sie, was garantiert zu Verwirrung führt. (Entweder bei R oder bei Ihnen.)\n\n👩‍💼 Ganz okay.\n\nWie ist es um das R-Quadrat Ihrer Vorhersagen bestellt?\n\n# `rsq ` ist auch aus dem Paket yardstick:\nrsq(data = mariokart_test,\n    truth = total_pr,  # echter Verkaufspreis\n    estimate = lm_allin_predictions)  # Ihre Vorhersage\n\n\n\n\n\n.metric\n.estimator\n.estimate\n\n\nrsq\nstandard\n0.17\n\n\n\n\n\n👴️ 17%, nicht berauschend, aber immerhin!\n\nWie das Beispiel zeigt, ist die Modellgüte im Test-Sample (leider) oft geringer als im Train-Sample. Die Modellgüte im Train-Sample ist mitunter übermäßig optimistisch. Dieses Phänomen bezeichnet man als Overfitting (Gelman et al., 2021). Bevor man Vorhersagen eines Modells bei der Chefin einreicht, bietet es sich, die Modellgüte in einem neuen Datensatz, also einem Test-Sample, zu überprüfen.\nWir haben hier die Funktion rsq aus dem Paket yardstick verwendet, da r2 nur die Modellgüte im Train-Sample ausrechnen kann. rsq kann die Modellgüte für beliebige Vorhersagewerte berechen, also sowohl aus dem Train- oder dem Test-Sample.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "href": "090-regression2.html#vertiefung-das-aufteilen-ihrer-daten",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.6 Vertiefung: Das Aufteilen Ihrer Daten",
    "text": "10.6 Vertiefung: Das Aufteilen Ihrer Daten\n\n10.6.1 Analyse- und Assessment-Sample\nWenn Sie eine robuste Schätzung der Güte Ihres Modells erhalten möchten, bietet sich folgendes Vorgehen an (vgl. Abbildung 10.15):\n\nTeilen Sie Ihren Datensatz (das Train-Sample) in zwei Teile: Das sog. Validation-Sample und das sog. Assessment-Sample.\nBerechnen Sie Ihr Modell im ersten Teil Ihres Datensatzes (dem Validation-Sample).\nPrüfen Sie die Modellgüte im zweiten Teil Ihres Datensatzes (dem Assessment-Sample)\n\nDiese Aufteilung Ihres Datensatzatzes in diese zwei Teile nennt man auch Validierungsaufteilung (validation split); Sie können sie z.\\(\\,\\)B. so bewerkstelligen:\n\nlibrary(rsample)  # ggf. noch installieren\nmariokart &lt;- read_csv(\"data/mariokart.csv\")  # Wenn die CSV-Datei in einem Unterordner mit Namen \"data\" liegt\n\nmeine_aufteilung &lt;- initial_split(mariokart, strata = total_pr)\n\ninitial_split wählt für jede Zeile (Beobachtung) zufällig aus, ob diese Zeile in das Analyse- oder in das Assessment-Sample kommen soll. Im Standard werden 75% der Daten in das Analyse- und 25% in das Assessment-Sample eingeteilt;7 das ist eine sinnvolle Aufteilung. Das Argument strata sorgt dafür, dass die Verteilung der AV in beiden Stichproben gleich ist. Es wäre nämlich blöd für Ihr Modell, wenn im Train-Sample z.\\(\\,\\)B. nur die teuren, und im Test-Sample nur die günstigen Spiele landen würde. Anderes Beispiel: In den ersten Zeilen stehen nur Kunden aus Land A und in den unteren Zeilen nur aus Land B. In so einem Fall würde sich Ihr Modell unnötig schwer tun. Im nächsten Schritt können Sie anhand anhand der von initial_split bestimmten Aufteilung die Daten tatsächlich aufteilen. initial_split sagt nur, welche Zeile in welche der beiden Stichproben kommen soll. Die eigentliche Aufteilung wird aber noch nicht durchgeführt.\n\nmariokart_train &lt;- \n  training(meine_aufteilung)  # Analyse-Sample\nmariokart_test &lt;- \n  testing(meine_aufteilung)  # Assessment-Sample\n\ntraining wählt die Zeilen aus, die in das Train-Sample ihres Train-Samples, d.h. Ihr Analyse-Sample, kommen sollen. testing wählt die Zeilen aus, die in das Test-Sample ihres Train-Samples, d.h. Ihr Assessment-Sample, kommen sollen.\nIch persönliche nenne die Tabelle mit den Daten gerne d_analysis bzw. d_assess, das ist kürzer zu tippen und einheitlich. Sie können aber auch ein eigenes Namens-Schema nutzen; was aber hilfreich ist, ist Konsistenz in der Benamung, außerdem Kürze und aussagekräftige Namen.\n\n10.6.2 Train- vs. Test-Sample\nDas Train-Sample stellt die bekannten Daten dar; aus denen können wir lernen, d.\\(\\,\\)h. unser Modell berechnen. Das Test-Sample stellt das Problem der wirklichen Welt dar: Neue Beobachtungen, von denen man (noch) nicht weiß, was der Wert der AV ist. Der Zusammenhang dieser verschiedenen, aber zusammengehörigen Arten von Stichproben ist in Abbildung 10.15 dargestellt.\n\nDefinition 10.5 (Train-Sample) Den Datensatz, für die Sie sowohl UV als auch AV vorliegen haben, nennt man Train-Sample. \\(\\square\\)\n\n\nDefinition 10.6 (Test-Sample) Den Datensatz, für den Sie nur Daten der UV, aber nicht zu der AV vorliegen haben, nennt man Test-Sample. \\(\\square\\)\n\n\n\n\n\n\nflowchart TD\n  S[Samples] \n  TS[Train-Sample]\n  TT[Test-Sample]\n  AS[Analyse-Sample]\n  AssS[Assessment-Sample]\n\n  S--&gt;TT\n  S--&gt;TS\n  TS--&gt;AS\n  TS--&gt;AssS\n  \n\n\n\n\nAbbildung 10.15: Verschiedene Arten von zusammengehörigen Stichprobenarten im Rahmen einer Prognosemodellierung",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#praxisbezug",
    "href": "090-regression2.html#praxisbezug",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.7 Praxisbezug",
    "text": "10.7 Praxisbezug\nEin Anwendungsbezug von moderner Datenanalyse ist es vorherzusagen, welche Kunden “abwanderungsgefährdet” sind, also vielleicht in Zukunft bald nicht mehr unsere Kunden sind (“customer churn”). Es gibt eine ganze Reihe von Untersuchungen dazu, z.\\(\\,\\)B. die von Lalwani et al. (2022). Das Forschungsteam versuchen anhand von Daten und u.\\(\\,\\)a. auch der linearen Regression vorherzusagen, welche Kunden abgewandert sein werden. Die Autoren berichten von einer Genauigkeit von über 80\\(\\,\\)% im (besten) Vorhersagemodell.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#wie-man-mit-statistik-lügt",
    "href": "090-regression2.html#wie-man-mit-statistik-lügt",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.8 Wie man mit Statistik lügt",
    "text": "10.8 Wie man mit Statistik lügt\n\n10.8.1 Pinguine drehen auf\nEin Forscher-Team untersucht Pinguine von der Palmer Station, Antarktis. Das Team ist am Zusammenhang von Schnabellänge (bill length) und Schnabeltiefe (bill depth) interessiert, s. Abbildung 10.16.\n\n\n\n\n\nAbbildung 10.16: Schnabellänge und Schnabeltiefe; Horst (2024)\n\n\nDas Team hat in schweißtreibender (eiszapfentreibender) Arbeit \\(n=344\\) Tiere vermessen bei antarktischen Temperaturen. Hier sind die Daten:\n\npenguins &lt;- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\")\n\n\n10.8.2 Analyse 1: Gesamtdaten\nMan untersucht, rechnet und überlegt. Ah! Jetzt haben wir es! Klarer Fall: Ein negativer Zusammenhang von Schnabellänge und Schnabeltiefe, s. Abbildung 10.17. Das ist bestimmt einen Nobelpreis wert Schnell publizieren!\n\nggscatter(penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\", \n          add = \"reg.line\")  # aus `ggpubr`\n\n\n\n\n\n\nAbbildung 10.17: Negativer Zusammenhang von Schanbellänge und Schnabeltiefe\n\n\n\n\nHier sind die statistischen Details, s. Tabelle 10.10.\n\nlm_ping1 &lt;- lm(bill_depth_mm ~ bill_length_mm, data = penguins)\n\n\n\n\nTabelle 10.10: Koeffizienten des Modells 1: Negativer Effekt von bill_length_mm\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n20.89\n\n\nbill_length_mm\n-0.09\n\n\n\n\n\n\n\n\n\n10.8.3 Analyse 2: Aufteilung in Arten (Gruppen)\nKurz darauf veröffentlicht eine andere Forscherin auch einen Aufsatz zum gleichen Thema. Gleiche Daten. Aber mit gegenteiligem Ergebnis: Bei jeder Rasse von (untersuchten) Pinguinen gilt: Es gibt einen positiven Zusammenhang von Schnabelllänge und Schnabeltiefe, s. Abbildung 10.18.\n\n\n\n\n\n\n\nAbbildung 10.18: Der Zusammenhang von Schnabelllänge und Schnabeltiefe pro Gruppe von Pinguinen: Die Regressionsgruppe pro Gruppe steigt. Hingegen sinkt die Regressionsgerade ohne Beachtung der Gruppen (schwarze gestrichelte Linie)\n\n\n\n\nOh nein! Was ist hier nur los? Daten lügen nicht?! Oder doch?!\nHier sind die statistischen Details der zweiten Analyse, s. Tabelle 10.11. Im zweiten Modell (lm2) kam species als zweite UV neu ins Modell (zusätzlich zur Schnabellänge).\n\nlm_ping2 &lt;- lm(bill_depth_mm ~ bill_length_mm + species, data = penguins)\n\n\n\n\nTabelle 10.11: Koeffizienten des Modells 2: Positiver Effekt von bill_length_mm\n\n\n\n\nParameter\nCoefficient\n\n\n\n(Intercept)\n10.6\n\n\nbill_length_mm\n0.2\n\n\nspeciesChinstrap\n-1.9\n\n\nspeciesGentoo\n-5.1\n\n\n\n\n\n\n\n\nOhne Hintergrundwissen oder ohne weitere Analysen kann nicht entschieden werden, welche Analyse – Gesamtdaten oder Subgruppen – die richtige ist. Nicht-exprimentelle Studien können zu grundverschiedenen Ergebnissen führen, je nachdem, ob weitere UV dem Modell hinzugefügt oder weggenommen werden.\n\n10.8.4 Vorsicht bei der Interpretation von Regressionskoeffizienten\n\n\n\n\n\n\nWichtig\n\n\n\nInterpretiere Modellkoeffizienten nur kausal, wenn du ein Kausalmodell hast. \\(\\square\\)\n\n\nNur wenn man die Ursache-Wirkungs-Beziehungen in einem System kennt, macht es Sinn, die Modellkoeffizienten kausal zu interpretieren. Andernfalls lässt man besser die Finger von der Interpretation der Modellkoeffizienten und begnügt sich mit der Beschreibung der Modellgüte und mit Vorhersage (synonym: Prognose). Wer das nicht glaubt, der betrachte Abbildung 10.19, links. Ein Forscher stellt das Modell m1: y ~ x auf und interpretiert dann b1: “Ist ja klar, X hat einen starken positiven Effekt auf Y!” In der nächsten Studie nimmt der Forscher dann eine zweite Variable, group (z.\\(\\,\\)B. Geschlecht) in das Modell auf: m2: y ~ x + g. Oh Schreck! Jetzt ist b1 auf einmal nicht mehr stark positiv, sondern praktisch Null, und zwar in jeder Gruppe, s. Abbildung 10.19, rechts! Dieses Umschwenken der Regressionskoeffizienten kann nicht passieren, wenn der Effekt “echt”, also kausal, ist. Handelt es sich aber um “nicht echte”, also nicht-kausale Zusammenhänge, um Scheinzusammenhänge also, so können sich die Modellkoeffizienten dramatisch verändern, wenn man das Modell verändert, also Variablen hinzufügt oder aus dem Modell entfernt. Sogar das Vorzeichen des Effekts kann wechseln; das nennt man dann Simpsons Paradox (Gelman et al., 2021), Wenn man die kausalen Abhängigkeiten nicht kennt, weiß man also nicht, ob die Zusammenhänge kausal oder nicht-kausal sind. Dann bleibt unklar, ob die Modellkoeffizienten belastbar, robust, stichhaltig sind oder nicht.\n\n\n\n\n\n\n\n\n\n\n(a) Modell: y ~ x, starker positiver Zusammenhang\n\n\n\n\n \n\n\n\n\n\n\n\n(b) Modell: y ~ x + g, kein Zusammenhang in beiden Gruppe\n\n\n\n\n\n\nAbbildung 10.19: Fügt man in ein Modell eine Variable hinzu, können sich die Koeffizienten massiv ändern. In beiden Diagrammen wurden die gleichen Daten verwendet. (a) starker positiver Zusammenhang, (b) kein Zusammenhang in beiden Gruppen\n\n\n\nMan könnte höchstens sagen, dass man (wenn man die Kausalstruktur nicht kennt) die Modellkoeffizienten nur deskriptiv interpretiert, z.\\(\\,\\)B. “Dort wo es viele Störche gibt, gibt es auch viele Babys” (Matthews, 2000).8 Leider ist unser Gehirn auf kausale Zusammenhänge geprägt: Es fällt uns schwer, Zusammenhänge nicht kausal zu interpretieren. Daher werden deskriptive Befunde immer wieder unzulässig kausal interpretiert – von Laien und Wissenschaftlern ebenfalls.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#was-war-noch-mal-das-erfolgsgeheimnis",
    "href": "090-regression2.html#was-war-noch-mal-das-erfolgsgeheimnis",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.9 Was war noch mal das Erfolgsgeheimnis?",
    "text": "10.9 Was war noch mal das Erfolgsgeheimnis?\nWenn Sie dran bleiben an der Statistik, wird der Erfolg sich einstellen, s. Abbildung 10.20.\n\n\n\n\n\n\n\n\n\n(a) Sie gestern\n\n\n\n\n\n\n\n\n\n(b) Sie morgen\n\n\n\n\n\n\nAbbildung 10.20: Statistik, Sie und Party: Gestern und (vielleicht) morgen. Wenn Sie dran bleiben, wird die Statistik Ihre beste Freundin (imgflip, 2024).",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#fallstudien",
    "href": "090-regression2.html#fallstudien",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\nDie folgenden Fallstudien zeigen auf recht anspruchsvollem Niveau (bezogen auf diesen Kurs) beispielhalft zwei ausführlichere Entwicklungen eines Prognosemodells.\nNutzen Sie diese Fallstudien, um sich intensiver mit der Entwicklung eines Prognosemodells auseinander zu setzen.\n\n10.10.1 New Yorker Flugverspätungen 2023\n\nSource\nVorhersage von Flugverspätungen\n\n10.10.2 Filmerlöse\nVorhersagen von Filmerlösen",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#vertiefung",
    "href": "090-regression2.html#vertiefung",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.11 Vertiefung",
    "text": "10.11 Vertiefung\nAllison Horst erklärt die lineare Regression mit Hilfe von Drachen. 🐉 Sehenswert.",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#aufgaben",
    "href": "090-regression2.html#aufgaben",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.12 Aufgaben",
    "text": "10.12 Aufgaben\nDie Webseite datenwerk.netlify.app stellt eine Reihe von einschlägigen Übungsaufgaben bereit. Sie können die Suchfunktion der Webseite nutzen, um die Aufgaben mit den folgenden Namen zu suchen:\n\ninterpret-koeff-lm\nAussagen-einfache-Regr\ninterpret-koeff\nregression1b\nmtcars-regr01\nregression1a\nlm1\nRegression5\nRegression6\nlm-mario1\nlm-mario2\nlm-mario3\nausreisser1\nmario-compare-models",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#literaturhinweise",
    "href": "090-regression2.html#literaturhinweise",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "\n10.13 Literaturhinweise",
    "text": "10.13 Literaturhinweise\nEin empfehlenswertes Buch für Regressionsanalyse ist das Buch von Andrew Gelman zum Thema “Regression und andere Geschichten” (Gelman et al., 2021). Sein Buch ist für Sozialwissenschaftler geschrieben, also nicht für typische Nerds, hat aber deutlich mehr Anspruch als dieses Kapitel. Eine Alternative bietet Sauer (2019).\n\n\n\n\nBarrett, M. (2021). Ggokabeito: ’Okabe-Ito’ Scales for ’Ggplot2’ and ’Ggraph’ [Manual]. https://CRAN.R-project.org/package=ggokabeito\n\n\nDeutscher Wetterdienst. (2025a). Regional averages DE, monthly air temperature mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/air_temperature_mean/.\n\n\nDeutscher Wetterdienst. (2025b). Regional averages DE, monthly precipitation mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/precipitation/.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and Other Stories. Cambridge University Press.\n\n\nHabitator terrae. (2021). Deutsch: Fünfjährig Gemittelte Abweichung Der Lufftemperatur in Deutschland Vom Langjährigem Mittel 1951 Bis 1980 [Diagramm]. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nimgflip. (2024). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nKassambara, A. (2023). ggpubr: ’ggplot2’ Based Publication Ready Plots. https://CRAN.R-project.org/package=ggpubr\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private Traits and Attributes Are Predictable from Digital Records of Human Behavior. Proceedings of the National Academy of Sciences, 110(15), 5802–5805. https://doi.org/10.1073/pnas.1218772110\n\n\nKuhn, M., Vaughan, D., & Hvitfeldt, E. (2024). yardstick: Tidy Characterizations of Model Performance. https://CRAN.R-project.org/package=yardstick\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022). Customer Churn Prediction System: A Machine Learning Approach. Computing, 104(2), 271–294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLüdecke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E., Thériault, R., & Makowski, D. (2022). easystats: Framework for Easy Statistical Modeling, Visualization, and Reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nMatthews, R. (2000). Storks Deliver Babies (P= 0.008). Teaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design (CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWilke, S. (2013, Juni 26). Trends der Lufttemperatur [Bericht]. Umweltbundesamt; Umweltbundesamt. https://www.umweltbundesamt.de/daten/klima/trends-der-lufttemperatur",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "090-regression2.html#footnotes",
    "href": "090-regression2.html#footnotes",
    "title": "\n10  Geradenmodelle 2\n",
    "section": "",
    "text": "Quelle: https://de.wikipedia.org/wiki/Zeitreihe_der_Lufttemperatur_in_Deutschland#cite_ref-3↩︎\nQuelle: https://opendata.dwd.de/climate_environment/CDC/grids_germany/monthly/air_temperature_mean/↩︎\nIch danke Karsten Lübke für diese Idee.↩︎\nIn Abbildung 10.9? wird nicht der Schätzbereich für die Regressionsgewichte dargestellt, sondern stattdessen die SD der AV.↩︎\nZum Dollar-Operator s. Kapitel 3.11.3↩︎\nsynonym: nominalskalierte Variable↩︎\nvgl. help(initial_split)↩︎\nDas Störche-Babys-Beispiel passt auch zu Abbildung 10.19.↩︎",
    "crumbs": [
      "Geradenmodelle",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geradenmodelle 2</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Ainali. (2007). Standard deviation diagram micro [Artwork]. https://commons.wikimedia.org/w/index.php?curid=3141713\n\n\nAnscombe, F. J. (1973). Graphs in statistical analysis. The American\nStatistician, 27(1), 17–21.\n\n\nArad, C. (2024, June 5). Kylian Mbappe: Gehalt und Vermögen im\nÜberblick (2024). ftd.de. https://www.ftd.de/vermoegen/mbappe-gehalt-vermoegen/\n\n\nBarrett, M. (2021). Ggokabeito: ’Okabe-Ito’\nScales for ’Ggplot2’ and ’ggraph’ [Manual]. https://CRAN.R-project.org/package=ggokabeito\n\n\nBerger, G. (2019, December 10). The Jobs of\nTomorrow: LinkedIn’s 2020 Emerging Jobs\nReport. https://www.linkedin.com/blog/member/career/the-jobs-of-tomorrow-linkedins-2020-emerging-jobs-report\n\n\nBortz, J., & Schuster, C. (2010). Statistik für\nHuman- und Sozialwissenschaftler.\nSpringer. https://doi.org/10.1007/978-3-642-12770-0\n\n\nBowne-Anderson, H. (2018). What Data Scientists Really Do,\nAccording to 35 Data Scientists. Harvard\nBusiness Review. https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists\n\n\nBroman, K. W., & Woo, K. H. (2018). Data Organization\nin Spreadsheets. The American Statistician,\n72(1), 2–10. https://doi.org/10.1080/00031305.2017.1375989\n\n\nBundesamt, S. (2023-003-272023-003-27). Körpermaße nach\nAltersgruppen und Geschlecht. Statistisches Bundesamt. https://www.destatis.de/DE/Themen/Gesellschaft-Umwelt/Gesundheit/Gesundheitszustand-Relevantes-Verhalten/Tabellen/liste-koerpermasse.html\n\n\nBundesbank, D. (2023). Household wealth and finances in\nGermany: Results of the 2021 household wealth\nsurvey. Deutsche Bundesbank. https://www.bundesbank.de/resource/blob/908924/3ef9d9a4eaeae8a8779ccec3ac464970/mL/2023-04-vermoegensbefragung-data.pdf\n\n\nÇetinkaya-Runde, M., & Hardin, J. (2021). Introduction to\nModern Statistics. https://openintro-ims.netlify.app/\n\n\nÇetinkaya-Rundel, M., Diez, D., Bray, A., Kim, A. Y., Baumer, B., Ismay,\nC., Paterno, N., & Barr, C. (2024). Openintro: Datasets and\nsupplemental functions from ’OpenIntro’ textbooks and labs. https://CRAN.R-project.org/package=openintro\n\n\nCmglee. (2015). English: Geometric visualisation of the\nvariance of the example distribution (2, 4, 4, 4, 5, 5, 7, 9) on\nw:Standard deviation. [artwork]. https://commons.wikimedia.org/w/index.php?curid=39472834\n\n\nCohen, J. (1992). A power primer. Psychological Bulletin,\n112(1), 155–159.\n\n\nCohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003).\nApplied multiple regression/correlation analysis for the behavioral\nsciences, 3rd ed. Lawrence Erlbaum.\n\n\nCui, B. (2024). DataExplorer: Automate data exploration and\ntreatment. https://CRAN.R-project.org/package=DataExplorer\n\n\nDenisBoigelot. (2011). English: Redesign\nFile:Correlation_examples.png using vector\ngraphics (SVG file) [Artwork]. https://commons.wikimedia.org/w/index.php?curid=15165296\n\n\nDeutscher Wetterdienst. (2025a). Regional averages DE, monthly air\ntemperature mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/air_temperature_mean/.\n\n\nDeutscher Wetterdienst. (2025b). Regional averages DE, monthly\nprecipitation mean. https://opendata.dwd.de/climate_environment/CDC/regional_averages_DE/monthly/precipitation/.\n\n\nDowney, A. (2023). Probably overthinking it: How to use data to\nanswer questions, avoid statistical traps, and make better\ndecisions. The University of Chicago Press.\n\n\nFisher, D., & Meyer, M. (2018). Making data visual: A practical\nguide to using visualization for insight. O’Reilly.\n\n\nFitzmaurice, G. (2017). Same Stats, Different\nGraphs: Generating Datasets with Varied\nAppearance and Identical Statistics through\nSimulated Annealing. Autodesk Research. https://www.research.autodesk.com/publications/same-stats-different-graphs/\n\n\nflaticon. (2024). Professor [Artwork]. https://www.flaticon.com/de/kostenlose-icons/professor\n\n\nGelman, A., Hill, J., & Vehtari, A. (2021). Regression and other\nstories. Cambridge University Press.\n\n\nGoren, A., Vaño-Galván, S., Wambier, C. G., McCoy, J., Gomez-Zubiaur,\nA., Moreno-Arrones, O. M., Shapiro, J., Sinclair, R. D., Gold, M. H.,\nKovacevic, M., Mesinkovska, N. A., Goldust, M., & Washenik, K.\n(2020). A preliminary observation: Male pattern hair loss\namong hospitalized COVID-19 patients in Spain\n– A potential clue to the role of androgens in\nCOVID-19 severity. Journal of Cosmetic\nDermatology, 19(7), 1545–1547. https://doi.org/10.1111/jocd.13443\n\n\nHabitator terrae. (2021). Deutsch: Fünfjährig gemittelte\nAbweichung der Lufftemperatur in\nDeutschland vom langjährigem Mittel 1951 bis\n1980 [diagramm]. https://commons.wikimedia.org/wiki/File:%C3%84nderung_der_Lufttemperatur_in_Deutschland.gif\n\n\nHaug, S., Castro, R. P., Kwon, M., Filler, A., Kowatsch, T., &\nSchaub, M. P. (2015). Smartphone use and smartphone addiction among\nyoung people in Switzerland. Journal of Behavioral\nAddictions, 4(4), 299–307. https://doi.org/10.1556/2006.4.2015.037\n\n\nHornik, K., Ligges, U., & Zeileis, A. (2023). Changes on CRAN.\nThe R Journal, 15, 295–296.\n\n\nHorst, A. (2023). Tidy Data [Artwork]. https://allisonhorst.com/\n\n\nHorst, A. (2024). Statistics Artwork [Artwork]. https://allisonhorst.com/\n\n\nHou, J., Walsh, P. P., & Zhang, J. (2015). The dynamics of\nHuman Development Index. The Social Science\nJournal, 52(3), 331–347. https://doi.org/10.1016/j.soscij.2014.07.003\n\n\nIchihara, Y. G., Okabe, M., Iga, K., Tanaka, Y., Musha, K., & Ito,\nK. (2008). Color universal design: The selection of four easily\ndistinguishable colors for all color vision types. Color\nImaging XIII: Processing,\nHardcopy, and Applications,\n6807, 206–213. https://doi.org/10.1117/12.765420\n\n\nimgflip. (2024a). Imageflip Bill Gates Meme\n[Artwork]. https://imgflip.com\n\n\nimgflip. (2024b). Imageflip Kermit Meme [Artwork].\nhttps://imgflip.com\n\n\nimgflip. (2024c). Imageflip Meme [Artwork]. https://imgflip.com\n\n\nimgflip. (2024d). Imageflip One does not\nsimply [Artwork]. https://imgflip.com\n\n\nimgflip. (2024e). Imageflip Tom Cruise Meme\n[Artwork]. https://imgflip.com\n\n\nimgflip. (2024f). Yoda Jealous Girl Friend Meme\n[Artwork]. https://imgflip.com\n\n\nInternational, T. (2017, January 25). Corruption Perceptions\nIndex 2016. Transparency.org. https://www.transparency.org/en/news/corruption-perceptions-index-2016\n\n\nIsmay, C., & Kim, A. Y.-S. (2020). Statistical inference via\ndata science: A ModernDive into R and the\nTidyverse. CRC Press / Taylor & Francis Group. https://moderndive.com/\n\n\nKaplan, D. T. (2009). Statistical modeling: A fresh approach.\nCreateSpace. https://dtkaplan.github.io/SM2-bookdown/\n\n\nKassambara, A. (2023). Ggpubr: ’ggplot2’ based publication ready\nplots. https://CRAN.R-project.org/package=ggpubr\n\n\nKosinski, M., Stillwell, D., & Graepel, T. (2013). Private traits\nand attributes are predictable from digital records of human behavior.\nProceedings of the National Academy of Sciences,\n110(15), 5802–5805. https://doi.org/10.1073/pnas.1218772110\n\n\nKuhn, M., Vaughan, D., & Hvitfeldt, E. (2024). Yardstick: Tidy\ncharacterizations of model performance. https://CRAN.R-project.org/package=yardstick\n\n\nKwon, M., Kim, D.-J., Cho, H., & Yang, S. (2013). The smartphone\naddiction scale: Development and validation of a short version for\nadolescents. PloS One, 8(12), e83558. https://doi.org/10.1371/journal.pone.0083558\n\n\nLalwani, P., Mishra, M. K., Chadha, J. S., & Sethi, P. (2022).\nCustomer churn prediction system: A machine learning approach.\nComputing, 104(2), 271–294. https://doi.org/10.1007/s00607-021-00908-y\n\n\nLieberoth, A., Rasmussen, J., Stoeckli, S., Tran, T., Ćepulić, D.-B.,\nHan, H., Lin, S.-Y., Tuominen, J., Travaglino, G., & Vestergren, S.\n(2022). COVIDiSTRESS global survey. https://doi.org/10.17605/OSF.IO/Z39US\n\n\nLovett, M. C., & Greenhouse, J. B. (2000). Applying Cognitive\nTheory to Statistics Instruction. The American\nStatistician, 54(3), 196–206. https://doi.org/10.1080/00031305.2000.10474545\n\n\nLüdecke, D., Ben-Shachar, M. S., Patil, I., Wiernik, B. M., Bacher, E.,\nThériault, R., & Makowski, D. (2022). Easystats: Framework for easy\nstatistical modeling, visualization, and reporting. CRAN. https://doi.org/10.32614/CRAN.package.easystats\n\n\nLyon, A. (2014). Why are Normal Distributions Normal?\nThe British Journal for the Philosophy of Science,\n65(3), 621–649. https://doi.org/10.1093/bjps/axs046\n\n\nM7. (2004). Savinelli’s Italian smoking pipe\n[Artwork]. https://commons.wikimedia.org/wiki/File:Pipa_savinelli.jpg\n\n\nMacKay, R. J., & Oldford, R. W. (2000). Scientific\nMethod, Statistical Method and the\nSpeed of Light. Statistical Science,\n15(3), 254–278. https://doi.org/10.1214/ss/1009212817\n\n\nMaphry. (2009). Seesaw with mean [Artwork]. https://commons.wikimedia.org/w/index.php?curid=79390659\n\n\nMarks-Anglin, Arielle and Chen, Yong. (2020). A historical review of\npublication bias. Research Synthesis Methods, 11(6),\n725–742. https://doi.org/10.1002/jrsm.1452\n\n\nMatthews, R. (2000b). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nMatthews, R. (2000a). Storks Deliver Babies (p= 0.008).\nTeaching Statistics, 22(2), 36–38. https://doi.org/10.1111/1467-9639.00013\n\n\nMenk. (2014, July 29). Linear regression [computer code]. https://texample.net/tikz/examples/linear-regression/\n\n\nMesserli, F. H. (2012). Chocolate Consumption,\nCognitive Function, and Nobel Laureates.\nNew England Journal of Medicine, 367(16), 1562–1564.\nhttps://doi.org/10.1056/NEJMon1211064\n\n\nMittag, H.-J., & Schüller, K. (2020). Statistik: Eine Einführung\nmit interaktiven Elementen. Springer. https://doi.org/10.1007/978-3-662-61912-4\n\n\nMoore, B. (2015, April 9). Recreating the vaccination heatmaps in\nR. Benomics. https://benjaminlmoore.wordpress.com/2015/04/09/recreating-the-vaccination-heatmaps-in-r/\n\n\nMulukom, V. van, Muzzulini, B., Rutjens, B., Lissa, C. J. van, &\nFarias, M. (2020). Psychological impact of COVID-19\npandemic. https://doi.org/10.17605/OSF.IO/TSJNB\n\n\nObels, P., Lakens, D., Coles, N. A., Gottfried, J., & Green, S. A.\n(2020). Analysis of Open Data and Computational\nReproducibility in Registered Reports in\nPsychology. Advances in Methods and Practices in\nPsychological Science, 3(2), 229–237. https://doi.org/10.1177/2515245920918872\n\n\nOestreich, M., & Romberg, O. (2014). Keine Panik vor Statistik!:\nErfolg und Spaß im Horrorfach nichttechnischer Studiengänge.\nSpringer. https://doi.org/10.1007/978-3-658-04605-7\n\n\nOkabe, M., & Ito, K. (2023). Color Universal Design\n(CUD) / Colorblind Barrier Free. https://jfly.uni-koeln.de/color/\n\n\nPatil, I. (2021). Visualizations with statistical\ndetails: The ’ggstatsplot’ approach.\nJournal of Open Source Software, 6(61),\n3167. https://doi.org/10.21105/joss.03167\n\n\nPearl, J., & Mackenzie, D. (2018). The book of why: The new\nscience of cause and effect. Basic Books.\n\n\nPearson, K. (1896). VII. Mathematical\ncontributions to the theory of evolution.—III.\nRegression, heredity, and panmixia. Philosophical\nTransactions of the Royal Society of London. Series A, Containing Papers\nof a Mathematical or Physical Character, 187, 253–318. https://doi.org/10.1098/rsta.1896.0007\n\n\nPlesser, H. E. (2018). Reproducibility vs. Replicability:\nA Brief History of a Confused Terminology.\nFrontiers in Neuroinformatics, 11, 76. https://doi.org/10.3389/fninf.2017.00076\n\n\nPoldrack, R. A. (2023). Statistical thinking: Analyzing data in an\nuncertain world. Princeton University Press. https://statsthinking21.github.io/statsthinking21-core-site/\n\n\nR Core Team. (2024). R: A language and environment for statistical\ncomputing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nRoser, M., Appel, C., & Ritchie, H. (2013). Human Height [Data set]. In Our World in\nData. https://ourworldindata.org/human-height\n\n\nRothstein, H. R. (2014). Publication Bias. In Wiley\nStatsRef: Statistics Reference Online.\nJohn Wiley. https://doi.org/10.1002/9781118445112.stat07071\n\n\nSauer, S. (2017). Dataset ’predictors of performance in stats\ntest’ [Data set]. Open Science Framework. https://doi.org/10.17605/OSF.IO/SJHUY\n\n\nSauer, S. (2019). Moderne Datenanalyse mit R: Daten einlesen,\naufbereiten, visualisieren und modellieren. Springer. https://www.springer.com/de/book/9783658215866\n\n\nScherer, C., Radchuk, V., Staubach, C., Müller, S., Blaum, N., Thulke,\nH., & Kramer‐Schadt, S. (2019). Seasonal host life‐history processes\nfuel disease dynamics at different spatial scales. Journal of Animal\nEcology, 88(11), 1812–1824. https://doi.org/10.1111/1365-2656.13070\n\n\nShimizu, Y. (2022). Multiple Desirable Methods in\nOutlier Detection of Univariate Data With R Source\nCodes. Frontiers in Psychology, 12, 819854. https://doi.org/10.3389/fpsyg.2021.819854\n\n\nSimmons, J. P., Nelson, L. D., & Simonsohn, U. (2011).\nFalse-Positive Psychology: Undisclosed\nFlexibility in Data Collection and Analysis\nAllows Presenting Anything as Significant.\nPsychological Science, 22(11), 1359–1366. https://doi.org/10.1177/0956797611417632\n\n\nSpurzem, L. (2017). VW 1303 von Wiking in\n1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG\n\n\nStigler, S. M. (2016). The seven pillars of statistical wisdom.\nHarvard University Press.\n\n\nTransfermarkt. (2024). Die wertvollsten Fußball-Spieler. https://www.transfermarkt.de/spieler-statistik/wertvollstespieler/marktwertetop/spielerposition_id/8/page/12\n\n\nvan Panhuis, W. G., Grefenstette, J., Jung, S. Y., Chok, N. S., Cross,\nA., Eng, H., Lee, B. Y., Zadorozhny, V., Brown, S., Cummings, D., &\nBurke, D. S. (2013). Contagious Diseases in the\nUnited States from 1888 to the Present.\nNew England Journal of Medicine, 369(22), 2152–2158.\nhttps://doi.org/10.1056/NEJMms1215400\n\n\nWard, A. F., Duke, K., Gneezy, A., & Bos, M. W. (2017). Brain\nDrain: The Mere Presence of One’s\nOwn Smartphone Reduces Available Cognitive Capacity.\nJournal of the Association for Consumer Research,\n2(2), 140–154. https://doi.org/10.1086/691462\n\n\nWickham, H. (2016). ggplot2: Elegant graphics for data\nanalysis. Springer-Verlag New York. https://ggplot2.tidyverse.org\n\n\nWickham, H. (2023). Tidy-Data-Sinnbild [Artwork].\nhttps://r4ds.hadley.nz/data-tidy#fig-tidy-structure\n\n\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D.,\nFrançois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M.,\nPedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J.,\nRobinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to\nthe tidyverse. Journal of Open Source\nSoftware, 4(43), 1686. https://doi.org/10.21105/joss.01686\n\n\nWickham, H., & Grolemund, G. (2018). R für Data Science: Daten\nimportieren, bereinigen, umformen, modellieren und visualisieren\n(F. Langenau, Trans.). O’Reilly. https://r4ds.had.co.nz/index.html\n\n\nWilke, C. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures. O’Reilly. https://clauswilke.com/dataviz/\n\n\nWilke, C. (2024). Wilkelab/practicalgg. Wilke Lab. https://github.com/wilkelab/practicalgg\n\n\nWilke, S. (2013, June 26). Trends der Lufttemperatur [Bericht].\nUmweltbundesamt; Umweltbundesamt. https://www.umweltbundesamt.de/daten/klima/trends-der-lufttemperatur\n\n\nWorld Economic Forum. (2020). The Future of Jobs\nReport 2020. World Economic Forum. https://www3.weforum.org/docs/WEF_Future_of_Jobs_2020.pdf",
    "crumbs": [
      "Geradenmodelle",
      "Literatur"
    ]
  },
  {
    "objectID": "110-definitions.html",
    "href": "110-definitions.html",
    "title": "Anhang A — Definitionen",
    "section": "",
    "text": "Abweichungsrechteck: Definition 8.1, s. S. \nAusprägung: Definition 2.8, s. S. \nBalkendiagramm: Definition 5.3, s. S. \nBeobachtungseinheit: Definition 2.6, s. S. \nBinäre Variable: Definition 10.2, s. S. \nBoxplot: Definition 5.10, s. S. \nData-Dictionary: Definition 2.4, s. S. \nDataframe: Definition 3.5, s. S. \nDaten: Definition 2.3, s. S. \nDatendiagramm: Definition 5.1, s. S. \nDatenjudo: Definition 4.1, s. S. \nDezile: Definition 6.6, s. S. \nDichtediagramm: Definition 5.5, s. S. \nDas einfache lineare Modell: Definition 9.3, s. S. \nExtremwert: Definition 6.3, s. S. \nFehlerstreuung: Definition 9.4, s. S. \nFunktion: Definition 3.2, s. S. \nGerade: Definition 9.2, s. S. \nHistogramm: Definition 5.4, s. S. \nInteraktionseffekt: Definition 10.4, s. S. \nInterquartilsabstand: Definition 7.4, s. S. \nKonfidenzintervall: Definition 10.1, s. S. \nKovarianz: Definition 8.2, s. S. \nLagemaß: Definition 6.8, s. S. \nLinearer Zusammenhang: Definition 5.9, s. S. \nLineares Modell: Definition 6.2, s. S. \nMittlere Absolutabweichung: Definition 7.3, s. S. \nMedian: Definition 6.4, s. S. \nModelle: Definition 2.11, s. S. \nMultiple Regression: Definition 10.3, s. S. \nMittelwert: Definition 6.1, s. S. \nNormalverteilung: Definition 5.7, s. S. \nEntstehung einer Normalverteilung: Definition 5.8, s. S. \nNullmodell (Punktmodell): Definition 9.1, s. S. \nPfeife: Definition 4.2, s. S. \nPunktmodell: Definition 6.9, s. S. \nQuantile: Definition 6.7, s. S. \nQuartile: Definition 6.5, s. S. \nKorrelationskoeffizient \\(r\\): Definition 8.3, s. S. \n\\(R^2\\)-Quadrat: Definition 9.5, s. S. \nSpannweite: Definition 7.2, s. S. \nReproduzierbarkeit: Definition 3.1, s. S. \nResiduum: Definition 2.2, s. S. \nStandardabweichung: Definition 7.6, s. S. \nSkalenniveau: Definition 2.10, s. S. \nStatistik: Definition 2.1, s. S. \nStreuungsmaße: Definition 7.1, s. S. \nTest-Sample: Definition 10.6, s. S. \nTidy Data: Definition 2.9, s. S. \nTrain-Sample: Definition 10.5, s. S. \nVariable: Definition 7.5, s. S. \nVarianz: Definition 7.5, s. S. \nVektorielles Rechnen: Definition 3.4, s. S. \nVektor: Definition 3.3, s. S. \nVerteilung: Definition 5.2, s. S. \nWert: Definition 2.7, s. S. \nz-Werte: Definition 7.8, s. S. \nZentrieren: Definition 7.7, s. S.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Definitionen</span>"
    ]
  },
  {
    "objectID": "120-mariokart.html",
    "href": "120-mariokart.html",
    "title": "Anhang B — Data-Dictionary für Mariokart",
    "section": "",
    "text": "In diesem Datensatz werden Auktionen zum Videospiel Wii Mario Kart beim Online-Auktionshaus Ebay dargestellt. Die Daten wurden im Oktober 2009 gesammelt. Es handelt sich um einen Dataframe mit 143 Beobachtungen (Auktionen) und 12 Spalten (Variablen). Die Preise sind in US-Dollar angegeben. Die Quelle des Datensatzes ist das R-Paket openintro (Çetinkaya-Rundel et al., 2024). Alternativ ist der Datensatz online zu finden: https://vincentarelbundock.github.io/Rdatasets/csv/openintro/mariokart.csv. Mit help(mariokart) wird die Hilfeseite zum Datensatz geöffnet (dazu muss das Paket openintro bereitgestellt sein).\nTabelle B.1 zeigt das Data-Dictionary.\n\n\n\nTabelle B.1: Data-Dictionary für Mariokart\n\n\n\n\nVariable\nErklärung\n\n\n\nid\nID der Auktion\n\n\nduration\nDauer der Auktion in Tagen\n\n\nn_bids\nAnzahl der Gebote\n\n\ncond\nZustand (new/used)\n\n\nstart_pr\nAnfangspreis bei der Auktion\n\n\nship_pr\nVersangebühr\n\n\ntotal_pr\nGesamtpreis (inkl. Versandgebühr)\n\n\nship_sp\nVersandmethode bzw. -geschwindigkeit\n\n\nseller_rate\nBewertung des Verkäufers; das ist die Differenz zwischen positiven und negativen Bewertungen\n\n\nstock_photo\nLag der Auktion ein \"stock photo\" bei? Wenn ein Foto in vielen Auktionen benutzt wurde, wird es \"stock photo\" genannt.\n\n\nwheels\nAnzahl der enthaltenen Wii-Räder\n\n\ntitle\nName der Auktion\n\n\n\n\n\n\n\n\n\n\n\n\nÇetinkaya-Rundel, M., Diez, D., Bray, A., Kim, A. Y., Baumer, B., Ismay, C., Paterno, N., & Barr, C. (2024). openintro: Datasets and Supplemental Functions from ’OpenIntro’ Textbooks and Labs. https://CRAN.R-project.org/package=openintro",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Data-Dictionary für Mariokart</span>"
    ]
  },
  {
    "objectID": "130-autor.html",
    "href": "130-autor.html",
    "title": "Anhang C — Zum Autor",
    "section": "",
    "text": "Professor Dr. habil. Sebastian Sauer arbeitet als Hochschullehrer an der Hochschule Ansbach und unterrichtet dort Statistik und verwandte Fächer. Sein Interesse gilt den Neuentwicklungen an statistischen Analyseverfahren und deren Anwendung auf sozialwissenschaftliche Probleme. Neben dem “Wie” der Datenanalyse beschäftigen ihn die Grenzen und Gefahren, die die moderne Datenwissenschaft für den Einzelnen und die Zivilgesellschaft mit sich bringt. Außerdem interessiert er sich für die Frage, wie die Psychologie zur Klärung von Problemen mit gesellschaftlicher Relevanz beitragen kann. Er ist Autor einiger Fachbücher und Fachartikel.",
    "crumbs": [
      "Anhang",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Zum Autor</span>"
    ]
  }
]